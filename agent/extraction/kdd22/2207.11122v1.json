{
    "meta_info": {
        "title": "Solving the Batch Stochastic Bin Packing Problem in Cloud: A  Chance-constrained Optimization Approach",
        "abstract": "This paper investigates a critical resource allocation problem in the first\nparty cloud: scheduling containers to machines. There are tens of services and\neach service runs a set of homogeneous containers with dynamic resource usage;\ncontainers of a service are scheduled daily in a batch fashion. This problem\ncan be naturally formulated as Stochastic Bin Packing Problem (SBPP). However,\ntraditional SBPP research often focuses on cases of empty machines, whose\nobjective, i.e., to minimize the number of used machines, is not well-defined\nfor the more common reality with nonempty machines. This paper aims to close\nthis gap. First, we define a new objective metric, Used Capacity at Confidence\n(UCaC), which measures the maximum used resources at a probability and is\nproved to be consistent for both empty and nonempty machines, and reformulate\nthe SBPP under chance constraints. Second, by modeling the container resource\nusage distribution in a generative approach, we reveal that UCaC can be\napproximated with Gaussian, which is verified by trace data of real-world\napplications. Third, we propose an exact solver by solving the equivalent\ncutting stock variant as well as two heuristics-based solvers -- UCaC best fit,\nbi-level heuristics. We experimentally evaluate these solvers on both synthetic\ndatasets and real application traces, demonstrating our methodology's advantage\nover traditional SBPP optimal solver minimizing the number of used machines,\nwith a low rate of resource violations.",
        "author": "Jie Yan, Yunlei Lu, Liting Chen, Si Qin, Yixin Fang, Qingwei Lin, Thomas Moscibroda, Saravan Rajmohan, Dongmei Zhang",
        "link": "http://arxiv.org/abs/2207.11122v1",
        "category": [
            "math.OC",
            "cs.AI",
            "90-00, 90C11",
            "G.1.6"
        ],
        "additionl_info": "To appear in SIGKDD 2022 as Research Track paper"
    },
    "latex_extraction": {
        "content": {
            "section 1": {
                "name": "Introduction",
                "content": "\n\\label{sec:introduction}\n\nNowadays most large web companies run their services in containers~\\cite{microservices, containerization}, and adopt Kubernetes-like systems~\\cite{k8s, brendan2016, borg, borg-next} to orchestrate containers and manage resources in modern cloud platforms. One major challenge for the platform is container scheduling. In order to increase utilization, the platform consolidates multiple containers into a machine, where the sum of maximum resources required by containers may exceed the machine capacity. However, this also introduces risks of machine resource violations, which lead to container performance degradation or even service unavailability, resulting in financial loss for the application owner.\n\n\n\n\nThe container scheduling can be naturally modeled as the {\\em Stochastic Bin Packing Problem} (SBPP) \\citep{cohen2019, jeffrey2019} to seek an optimal resource utilization satisfying the constraint of keeping violations under a desired low level. To the best of our knowledge, previous research on SBPP assumes that all machines (also referred to as bins) are empty before allocation, and those approaches are evaluated in terms of the number of used bins. However, in practice, total resources required by a service change diurnally and weekly, as shown in Fig.~\\ref{fig:ts_cores}. Thus, in order to increase resource utilization, the service often requests to allocate and delete a batch of containers every day. In the platform side, most machines often already have hosted a few containers when new allocation comes in. In the case when nonempty machines can host all or most requested containers, the previous metric, i.e., the number of used bins, fails to differentiate the goodness of allocation strategies. \n\nWe propose a unified approach to the SBPP on both empty and nonempty machines. In particular, we consider the CPU resource utilization as the optimization objective and other types of resources (e.g., memory, storage) as constraints, since the main cloud providers charge for their resources by CPU core usage. As other optimization research work \\citep{cohen2019, jeffrey2019}, we further focus on the SBPP of one type of resources (i.e., CPU). However, memory and storage resources as deterministic constraints can be easily processed if necessary. Our main contributions are summarized as follows:\n\n$\\bullet$ Reformulate the SBPP by introducing a new metric {\\em Used Capacity at Confidence (UCaC)} as the optimization objective. {\\em UCaC} is well-defined on both empty and nonempty machines. We prove in theory that for the SBPP on empty machines, minimizing {\\em UCaC} is approximately consistent with minimizing the number of used machines.\n\n$\\bullet$ Approximate the chance constraints with Gaussian distributions. By modeling the workload process in a generative approach, we show that container resource usage distribution is naturally Gaussian when traffics are enough, and independent to other containers. Our analysis on traces of real web services empirically proves our assumptions.\n\n$\\bullet$ Propose three algorithms for the new {\\em UCaC}-based SBPP formulation -- online best-fit heuristics, offline bi-level heuristics, and offline solver with cutting stock approach. \nExperiments with both synthetic data and real traces show that our {\\em UCaC}-based algorithms perform better or equally well with respect to both {\\em UCaC} and traditional metrics of used machines. In particular, when nonempty machines can host all or most containers in requests, our {\\em UCaC}-based algorithms show a significant advantage.\n\n\n%%\n"
            },
            "section 2": {
                "name": "Preliminaries",
                "content": "\n\\label{sec:preliminaries}\n\n",
                "subsection 2.1": {
                    "name": "Container Scheduling in Cloud",
                    "content": "\n\\label{sub:app-scenarios}\n% Cluster\n% machine\n% Container\n% Container-machine mapping\n% - Consider only one resource bin packing.\n% - Violation and CPU throttling\n\nOur work targets general industrial infrastructures, such as Google's Borg\\cite{borg, borg-next}, Kubernetes\\cite{k8s}, and Microsoft AKS\\cite{aks}. Without loss of generality, we use an abstract cluster with a minimum set of concepts. {\\em Machine} is the bin that holds containers, and its resource capacity is a constant $V$. {\\em Cluster} is the collection of $N$ machines. {\\em Container} is the resource set (e.g., CPU and Memory) that a service instance is run on. For the container indexed by $j$, its resource usage is a random variable $A_j$. In our setting, the container size is dynamic and the same as its resource usage. We specify the maximum resource that a container can use as {\\it limit}; once a container's resource usage reaches {\\it limit}, it is throttled. {\\em Service} is a container type, which runs a set of homogeneous containers. The number of services is denoted as $K$, and the service $k$ has $m_k$ containers. These concepts are also illustrated in Appendix (Fig.~\\ref{fig:cluster}).\n\nA cluster may run many services. Each service owner submits the request of allocating or deleting a number of containers to the cluster {\\em scheduler}, which manages the set of machines and decides which containers should be on which machine. The scheduling algorithm is critical for resource utilization and is the target of this paper. We focus on the case that containers of the same service follow the same distribution of resource usage; If not, they should be further divided into more services. This is representative especially for first-party applications of web services (e.g., online meetings, news media, social networks).\n\n\n"
                },
                "subsection 2.2": {
                    "name": "Chance Constraints",
                    "content": "\n\\label{sub:chance-constraints}\n\nTo increase utilization, the scheduler often places multiple containers into one machine, where the sum of resources used by containers is required to not exceed the machine's capacity with confidence $\\alpha$ whose value corresponds to a business SLA (Service Level Agreement)\\cite{wieder2011service}. When solving the container scheduling problem, it is natural to define feasible solutions with {\\em chance constraint}s. Formally, it is defined as follows: \n\\begin{equation*}\n\\Pr\\left(g(x; \\theta) \\leq c \\right) \\geq \\alpha,\n\\end{equation*}\nwhere $x$ is the decision variable, parameter $\\theta$ is some prior random variable, and the constraint $g(x;\\theta) \\leq c$ satisfies with at least the probability $\\alpha \\in (0.0, 1.0]$.\n\nWhen $g(x; \\theta)$ follows a distribution that has low order moments as fully statistics, e.g., Gaussian, the chance constraint can be translated into a deterministic one in the form of mean plus uncertainties as $\\overline{g}{(x;\\theta)} + D(\\alpha) \\mathcal{U}_g(x;\\theta) \\leq c$. Here $D(\\alpha)$ is a constant depending on $\\alpha$. For Gaussian distributed $g(x)$, $D(\\alpha) = \\Phi^{-1}(\\alpha)$ is the $\\alpha$-quantile of the standard normal distribution.\n\n\n"
                },
                "subsection 2.3": {
                    "name": "Stochastic Bin Packing Problem (SBPP)",
                    "content": "\n\\label{sub:sbpp}\n\n% The classic bin packing problem is defined as follows.\n% \\begin{equation}\n% \\begin{aligned}\n%   &\\min_{x, y}{\\sum_{i=1}^{N}{y_i}}\\\\\n%   s.t., & \\Pr(\\sum_{j=1}^N {A_j x_{i, j}} \\leq V y_i) \\geq \\alpha, \\forall i \\in [N] \\\\\n%         & \\sum_{i=1}^M {x_{i, j}} = 1, \\forall j \\in [M]\n% \\end{aligned}\n% \\end{equation}\nContainer scheduling is modeled as a bin packing problem in our setting. Throughout this paper, machine and container are equivalent to bin and item in the bin packing problem respectively.\n\nSuppose there are $M$ containers to be scheduled onto $N$ machines. We consider one type of resources -- CPU cores. Assume CPU resource usage of containers is random variables $\\{ A_1, A_2, \\dots, A_M\\}$. The classic stochastic bin packing problem then is defined as the following 0-1 integer programming problem.\n\\begin{equation}\n\\label{eq:sbpp}\n\\begin{aligned}\n  &\\min_{x, y}{\\sum_{i=1}^{N}{y_i}} \\\\\n  s.t., \\Pr( & \\sum_{j=1}^M {A_j x_{i, j}} \\leq V y_i) \\geq \\alpha, \\quad i \\in [N] \\\\\n        % & \\color{blue}{\\sum_{j=1}^M {A'_j x_{i, j}} \\leq V' y_i, \\quad i \\in [N]} \\\\\n        & \\sum_{i=1}^M {x_{i, j}} = 1, \\quad j \\in [M] \\\\\n        & x_{i, j} \\in \\{0, 1\\},  ~ y_i \\in \\{0, 1\\}, \\quad i \\in [N], j \\in [M] \\\\\n\\end{aligned}\n\\end{equation}\nwhere the decision variable $x_{i,j}$ denotes whether or not container $j$ is  running on machine $i$, while $y_i$ denotes whether or not machine $i$ is used. Here $[N]$ denotes the set of integers $\\{1, 2, \\dots, N\\}$.\n\nNow we consider the chance constraints. Suppose the container's CPU usage is independent with others, and follows Gaussian distribution or, more loosely, a distribution with bounded support, as discussed in previous work~\\cite{cohen2019}, the chance constraints in Eq.~\\ref{eq:sbpp} can be translated into the following deterministic form.\n\\begin{equation}\n\\label{eq:deterministic-constraint-pre}\n    \\sum_{j=1}^{M} \\mu_{j} x_{i,j}+D(\\alpha) \\sqrt{\\sum_{j=1}^{M} b_{j} x_{i,j}} \\leq V y_{i}, \\quad x_{i, j} \\in \\{0, 1\\}\n\\end{equation}\nwhere $\\mu_j$ is the mean of $A_j$, and $b_j$ is any uncertainty metric of $A_j$ (e.g., variance for Gaussian).\n\n{\\bf K-service SBPP.}~In the classic bin packing problem, the decision variable is for each pair of {\\em(machine, container)}, leading to a decision space of $N \\times M$ scale. There are often thousands of containers and hundreds of machines in reality, and the problem is quickly no longer solvable in a reasonable time using a commercial solver. In this paper, as stated before, we consider the scenario in which there are $K$ services, and containers of the same service are homogeneous and follow the same resource usage distribution.\nThen the decision variable can be alternatively defined on {\\em (machine, service)} pair, where the decision variable $x'_{i,j}$ denotes the number of containers of service $j$ placed on machine $i$. \nIn reality, $K \\ll M$, indicating that the SBPP is expected to be solved by commercial solvers. \nWith the assumption that CPU usages of containers in the same service are iid (identical and independent distributed), as echoed in Observation \\ref{obs:obv-1} and Observation \\ref{obs:obv-2}, chance constraints and the SBPP formulation can be equivalently rewritten as follows:\n\\begin{equation}\n\\label{eq:sbp-k-services}\n\\begin{aligned}\n\\min_{x, y} & \\sum_{i=1}^{N} y_{i} \\\\\n% \\text { s.t. } & \\Pr \\left(\\sum_{j=1}^K {A_j x_{i, j}} \\leq V y_i \\right) \\geq \\alpha, \\quad \\forall i \\in [N] \\\\\n\\text { s.t. } & \\sum_{j=1}^{K} \\mu_{j} x_{i,j}+D(\\alpha) \\sqrt{\\sum_{j=1}^{K} b_{j} x_{i,j}} \\leq V y_{i}, \\quad i \\in [N] \\\\\n%& \\sum_{j=1}^K {A'_j x_{i, j}} \\leq V' y_i, \\quad \\forall i \\in [N] \\\\\n%&\\sum_{j=1}^K {B_j x_{i, j}} \\leq M_e y_i\\\\\n& \\sum_{i=1}^{N} x_{i,j} = m_j, \\quad j \\in [K] \\\\\n& x_{i, j} \\in \\I, ~ y_{i} \\in\\{0,1\\}, \\quad i \\in [N], ~j \\in [K]\n\\end{aligned}\n\\end{equation}\nwhere $x_{i,j}$ denotes the number of service $j$ running on machine $i$ and $y_i$ denotes whether or not machine $i$ is used. Here, $\\I$ is the set of non-negative integers.\n\nWe mainly consider the Gaussian distributed container resource usage, since through broad analysis of real trace data, the empirical distribution is approximately Gaussian or Sub-Gaussian with truncation, as detailed in Section~\\ref{sec:resource-usage-dist}. Note that, however, this assumption on distributions is not necessary for our work in Section~\\ref{sec:formulation} and ~\\ref{sec:methodology}.\n\n\n\n%%\n"
                }
            },
            "section 3": {
                "name": "Modeling container resource usage",
                "content": "\n\\label{sec:resource-usage-dist}\n\nWe explore the trace data collected from a set of web application services running on a cluster. Results reveal that their CPU resource usage approximately follows the Gaussian distribution. Further, by developing a generative model to identify the internal cause process, we conclude that the assumption of Gaussian distribution should be common in most web services.\n\n",
                "subsection 3.1": {
                    "name": "Exploring Data Analysis on Real Traces",
                    "content": "\n\\label{sub:eda}\nWe take three representative services as examples to analyze the distributions of container CPU usage at peak time. In Fig.~\\ref{fig:dist_containers}, we compare the data distribution and fitted Gaussian distribution with the same mean and variance, in forms of the histogram and CDF (cumulative density function). As shown, the data distributions show the following characteristics.\n\n$\\bullet$ All three services are approximately Gaussian. A and B services have relatively large variances, while C service's distribution is very narrow. To the best of our experience, such diversity in distributions widely exists in real-world applications.\n\n$\\bullet$ The tails of data distributions decay faster than the fitted Gaussian distribution. Strictly speaking, empirical distributions are Sub-Gaussian, and their high quantifies are dominated by Gaussian. This means that the Gaussian assumption in our chance constraints formulation is more conservative than that of real data. \n\n$\\bullet$ On the left side of the figures of service A and B, there are observed higher masses around zero. This is because the application manually reserves some container resources for tolerating accidental traffics.\n\n$\\bullet$ The tails of empirical distributions are bounded or truncated. This is because as depicted in section \\ref{sub:app-scenarios}, one container can use resource in a range of $(0, \\textit{limit})$ where {\\it limit} is a per-service defined constant.\n\n\n\n"
                },
                "subsection 3.2": {
                    "name": "Explanation in a Generative View",
                    "content": "\n\\label{sub:resource-usage-dist}\n\nResource usage is a time series generated by a stochastic process driven by workloads assigned to the container. To solve SBPP, we are interested in the distribution of container resource usages {\\em at the workload peak time}.\n\nWe use a generative view to analyze the container resource usage at a given time point. A container processes the assigned workloads of one service. For simplicity but without loss of generality, we assume the container resource usage is the sum of the assigned workloads' resource usage. Suppose that the workload of service $k$ follows the distribution $P_k$ and the container has $n$ such workloads. Then the container resource usage distribution $Y^{(n)}$ can be described as follows.\n\\begin{equation}\n\\label{eq:generative-usage}\n\\begin{aligned}\n  & X_i \\sim P_k,\n  \\quad &Y^{(n)} = \\sum_{i=1}^{n}{X_i},\n\\end{aligned}    \n\\end{equation}\nwhere $P_k$ is a distribution with $\\mathbb{E}[X_i] = \\mu$ and $Var[X_i]=\\sigma^2 < \\infty$.\n\n\\begin{observation}\n\\label{obs:obv-1}\nAt a given time $t$, resource usages of containers of the same service are independent and identically distributed (i.i.d).\n\\end{observation}\n\nThis observation holds in our situation because in service the workload scheduler allocates incoming workloads randomly to containers in round-robin or suchlike, which makes container usage distribution independent. Besides, since all containers of the same service are homogeneous, with roughly the same assigned workloads, their resource usage should be identical in distribution.\n\n\\begin{observation}\n\\label{obs:obv-2}\nFor a set of containers from different services, at a given time $t$, their resource usages are independently distributed.\n\\end{observation}\n\nSimilarly, because of the randomization in workload assignment, workloads of different containers are independent, and thus distributions of container resource usages.\n\n\\begin{corollary}[Gaussian distribution of container resource usage]\nFor Equation~\\ref{eq:generative-usage}, $\\lim_{n \\to \\infty} Y^{(n)} = \\sum_{i=1}^{n}{X_i}$ approximately follows a Gaussian distribution.\n\\end{corollary}\n\\begin{proof}\nSince $\\{X_1, \\ldots, X_n\\}$ are independent and identically distributed random variables, by Central Limit Theorem we have $\\frac{1}{n} Y^{(n)} \\sim \\mathcal{N}(\\mu, \\sigma^2/n)$. Thus, $Y^{(n)} \\sim \\mathcal{N}(n\\mu, n\\sigma^2)$.\n\\end{proof}\n\n%In appendix~\\ref{app:dist-simulation}, we simulate different raw distributions of $P_k$ and resulted distribution $Y$. Results verify our above analysis well.\n\nNote that at workload peaks, the number of workloads per container, $n$, is typically very large; thus, Gaussian distribution widely exists in our real-world traces. With bigger $n$, the container resource usage distribution is also more stationary. The support from the above generative mechanism, rather than only empirical statistics observed from limited data, makes methods based on Gaussian assumption perform more stable in reality.\n\n%%\n"
                }
            },
            "section 4": {
                "name": "Problem Formulation",
                "content": "\n\\label{sec:formulation}\nIn the classic bin packing problem, the objective is to minimize the number of used machines. However, for cases with nonempty machines, the objective is no longer well-defined. \nTo address this issue, we define a new metric {\\em UCaC} and then reformulate the SBPP with the objective of minimizing {\\em UCaC}. \nMoreover, we prove that with relaxed real-value decision variables, minimizing {\\em UCaC} leads to the minimum number of used machines.\nWith integer decision variables, though minimizing {\\em UCaC} does not necessarily lead to the minimum number of machines, we provide a constant factor guarantee from the minimum used machines.\n\n",
                "subsection 4.1": {
                    "name": "A New Metric: Used Capacity at Confidence",
                    "content": "\n\\label{sub:sbp-metrics}\n\n%We define a new metric that works for stochastic bin packing on non-empty machines. \n\\begin{definition}\n({\\em UCaC}, Used Capacity at Confidence)\n  Suppose on a machine there are $M$ containers sharing resources, and their resource usages are random variables $\\{ X_i \\sim P_i, i \\in [M] \\}$. The {\\em UCaC} at confidence level $\\alpha$ is defined as the minimum value of $U$ that satisfies $\\Pr\\left( \\sum_{i=1}^{M}{X_i} \\leq U \\right) \\geq \\alpha$.\n\\end{definition}\n\nFor notation simplicity, we use the operator $U_{\\alpha}(x)$ to denote the computation of {\\em UCaC} of a vector of random variables $x = \\{X_i \\}$ at confidence $\\alpha$. Suppose resource usages of the $M$ containers are Gaussian distributed, i.e., $X_i \\sim N(\\mu_i, \\sigma_i^2$), then {\\em UCaC} of the machine can be further written as follows:\n$ U_{\\alpha}(x) = \\sum_{i=1}^{M} \\mu_{i} + D(\\alpha) \\sqrt{\\sum_{i=1}^{M} {\\sigma_i^2}}.$\n\nThe new metric {\\em UCaC} measures the maximum machine level resource usage at the confidence $\\alpha$. \nFor example, a machine runs three containers whose resource usages ${x_1, x_2, x_3}$ follow distributions $\\mathcal{N}(2, 0.5), \\mathcal{N}(2, 1)$, and $\\mathcal{N}(3, 1.5) $ respectfully, with confidence level $\\alpha =0.99$ ($D(0.99) = 2.576$), {\\em UCaC} of this machine is calculated as:  $(2 + 2 + 3) + 2.576 * \\sqrt{0.5 + 1 + 1.5} = 11.46$.\n\nNaturally, we can extend to measure the resource usage of a cluster using {\\em UCaC}, whether its machines are empty or nonempty.\n\\begin{definition}[{\\em UCaC} of a cluster]\n  A cluster's {\\em UCaC} is the sum of {\\em UCaC} of all its machines.\n\\end{definition}\n\nHence, {\\em UCaC} is a well-defined metric for the SBPP with both empty and nonempty machines.\n\nThe final question is: what does lower {\\em UCaC} mean in practice? The answer is the capability to serve more containers without increasing the number of nonempty machines in the cluster. \nNote that the estimated available capacity is the total capacity minus the {\\em UCaC}.\nThus, less {\\em UCaC} for existing containers means more capacity for future demands.\n\n\n%As we shall prove in Theorem~\\ref{th:relaxed-consistency}, for stochastic bin packing on empty machines, minimizing {\\em UCaC} of a cluster leads to minimize used bins when relaxing decision variables to non-negative real values, which is consistent with classic problem formulation. \n\n\n"
                },
                "subsection 4.2": {
                    "name": "Stochastic Bin Packing Reformulation",
                    "content": "\n\\label{sub:sbp-reformulation}\nUsing the new objective {\\em UCaC}, the SBPP on both empty and nonempty machines can be formulated as follows: \n\\begin{equation}\n\\label{eq:initial}\n\\begin{aligned}\n  \\min_{x} ~& {\\sum_{i=1}^{N}{ \\left \\{\\sum_{j=1}^{K}{(z_{i,j} + x_{i, j})\\mu_j} + D(\\alpha) \\sqrt{\\sum_{j=1}^{K}{(z_{i, j} + x_{i, j}) b_j}}\\right \\}}}\\\\\n  s.t. ~& \\sum_{j=1}^{K}{(z_{i,j} + x_{i, j})\\mu_j} + D(\\alpha) \\sqrt{\\sum_{j=1}^{K}{(z_{i, j} + x_{i, j}) b_j}} \\leq V, \\\\\n       & \\sum_{i=1}^{N}{x_{i, j}=m_j},  \\quad x_{i, j} \\in \\I, \\quad i \\in [N], \\quad j\\in[K],\n\\end{aligned}\n\\end{equation}\nwhere $z_{i, j}$ denotes initial number of containers of service $j$ on machine $i$. \nGiven number of requested containers of service $j$, $m_j$, this formulation aims to minimize {\\em UCaC} of the cluster after allocation while satisfying the capacity constraint at confidence level $\\alpha$.\n\nNote that the deterministic term $\\sum_{i=1}^{N}{ \\sum_{j=1}^{K}{(z_{i,j} + x_{i, j})\\mu_j}}$ in the objective is a constant, thus minimizing {\\em UCaC} is equivalent to minimizing the uncertainty term $\\sum_{i=1}^{N}{D(\\alpha) \\sqrt{\\sum_{j=1}^{K}{(x_{i, j}+z_{i, j}) b_j}}}$. \nWith simple variable replacement and equivalence transformation, we get the following final problem formulation.\n\\begin{equation}\n\\label{eq:reformulation}\n\\begin{aligned}\n  \\min_{x} ~& \\sum_{i=1}^{N}{D(\\alpha) \\sqrt{\\sum_{j=1}^{K}{x_{i, j} b_j} + B_i}}\\\\\n  s.t. ~& \\sum_{j=1}^{K}{x_{i, j}\\mu_j} + D(\\alpha) \\sqrt{\\sum_{j=1}^{K}{x_{i, j} b_j} + B_i} \\leq V - C_i, \\quad i \\in [N] \\\\\n       & \\sum_{i=1}^{N}{x_{i, j}=m_j},  \\quad x_{i, j} \\in \\I, \\quad i \\in [N], \\quad j\\in[K],\n\\end{aligned}\n\\end{equation}\nwhere $B_j = \\sum_{j=1}^{K}{z_{i, j} b_j}$ and $C_i = \\sum_{j=1}^{K}{z_{i, j} \\mu_j}$.\n\nWe can prove that for the SBPP on empty machines, our {\\em UCaC}-based formulation is consistent with traditional SBPP that optimizes the number of used machines.\n\n\\begin{theorem}[Relaxed Consistency] \n\\label{th:relaxed-consistency}\nRelax decision variable $x_{i,j}$ to real value, and suppose that $b_j > 0, ~\\forall j \\in [K], i \\in [N]$ in Eq.~\\ref{eq:reformulation} and Eq.~\\ref{eq:sbp-k-services}. \nThen, minimizing {\\em UCaC} leads to the least number of used bins in stochastic bin packing on empty machines.\n\\end{theorem}\n\n\n\\begin{proposition}\n\\label{th:marginal-decrease}\nConsider the function $y = \\sqrt{x}$ with $\\text{\\em dom}(x) = \\R^+$. Since $\\frac{\\partial y}{\\partial x} = \\frac{1}{2\\sqrt{x}}$ is monotonically decreasing, the marginal change $\\Delta y$ by $\\Delta x$ decreases. That means for any $0 < x_1 < x_2$ and $\\Delta x > 0$, $\\sqrt{x_1 + \\Delta x} - \\sqrt{x_1} > \\sqrt{x_2 + \\Delta x} - \\sqrt{x_2}$ holds.\n\\end{proposition}\n\n\\begin{proof}[Proof of Theorem~\\ref{th:relaxed-consistency}]\n\nWe first prove that \\textit{at the optimal UCaC, there is at most one machine is not full.} Otherwise, we can always find two non-full machines, say $i$ and $i'$. Suppose their uncertainty terms satisfy $\\sqrt{\\sum_{j=1}^{K}{x_{i,j} b_j}} \\leq \\sqrt{\\sum_{j=1}^{K}{x_{i',j} b_j}}$. Then by Proposition~\\ref{th:marginal-decrease}, after moving some amount of $i$'s container to $i'$, say $\\Delta x_{i,j'}b_{j'}$, we have \n%\\begin{displaymath}\n$\n\\sqrt{\\sum_{j=1}^{K}{x_{i,j} b_j - \\Delta x_{i,j'} b_{j'}}} + \\sqrt{\\sum_{j=1}^{K}{x_{i',j} b_j} + \\Delta x_{i,j'} b_{j'}} < \\sqrt{\\sum_{j=1}^{K}{x_{i,j} b_j}} + \\sqrt{\\sum_{j=1}^{K}{x_{i',j} b_j}}\n$\n%\\end{displaymath}\nholds; given that $\\sum_{j=1}^{K}{x_{i, j}\\mu_j} + D(\\alpha) \\sqrt{\\sum_{j=1}^{K}{x_{i, j} b_j} + B_i} < V - C_i$, it is always possible to find such $\\Delta x_{i,j'} $ that satisfies\n%\\begin{displaymath}\n$\n\\sum_{j=1}^{K}{x_{i, j}\\mu_j}+\\Delta x_{i,j'} \\mu_{j'} + D(\\alpha) \\sqrt{\\sum_{j=1}^{K}{x_{i, j} b_j} +\\Delta x_{i,j'}b_{j'} + B_i} \\leq  V - C_i.\n$\n%\\end{displaymath}\nThat means {\\em UCaC} of this cluster can be reduced, which contradicts our assumption of optimal $UCaC$.\n\n\nWe then prove that \\textit{at the optimal UCaC, the number of used machines is equal to the least used machines.} Otherwise, we assume the optimality of Eq.~\\ref{eq:sbp-k-services} is $n_1$ machines and  the optimal solution  of Eq.~\\ref{eq:reformulation} corresponds to $n_2$ machines. By definitions, $n_1 \\leq n_2$ and $U_1 \\geq U_2$ holds, where $U_1$ and $U_2$ are {\\em UCaC} of the optimal solutions of Eq.~\\ref{eq:sbp-k-services} and \\ref{eq:reformulation} in respect. \nNow we assume $n_1 < n_2$. Let $\\Delta_1$ and $\\Delta_2$ be the unused capacity of th solutions corresponding to optimal used bins  and UCaC. Since there is at most one machine is not full, $ (V-\\Delta_2)>0$. Then $U_2 - U_1 = (n_2 V  - \\Delta_2) - (n_1 V  - \\Delta_1) = (n_2 - n_1) V - (\\Delta_2 - \\Delta_1) > (V - \\Delta_2) + \\Delta_1 > 0$ which contradicts the fact of $U_1 \\geq U_2$. Thus, $n_1 = n_2$.\n\\end{proof}\n\nFor the integer type decision variables, however, minimizing {\\em UCaC} does not necessarily lead to a minimum number of used machines, especially in the extreme case when the ratio of variance against the mean of the resource usage $A_j$ is zero. \nThe following theorem guarantees that the number of used machines corresponding to {\\em UCaC} minimized can be bounded by the minimum number of used machines.\n\n\\begin{theorem}[Bounded Number of Used Machines] \n\\label{th:bound}\nThe optimal solution of Eq.~\\ref{eq:reformulation} that minimizes {\\em UCaC} on empty machines uses at most $\\frac{8}{3}N^*$ machines, where $N^*$ is the optimal number of used machines by solving Eq.~\\ref{eq:sbp-k-services}.\n\\end{theorem}\nThe proof is given in Appendix \\ref{app:proof-of-th5}.\n\n\n\n%%\n"
                }
            },
            "section 5": {
                "name": "Methodology",
                "content": "\n\\label{sec:methodology}\n\nIn this section, we propose three algorithms for the SBPP that optimizes {\\em UCaC} -- online Best-Fit heuristic, offline bi-level heuristic and offline suboptimal solver using a cutting stock approach.\n\n",
                "subsection 5.1": {
                    "name": "Online Best-Fit Heuristic Algorithm",
                    "content": "\n\\label{sub:solve-online-heuristic}\n\n{\\em Best-Fit} is a greedy algorithm for the bin packing problem. For the SBPP that optimizes cluster {\\em UCaC}, the Best-Fit heuristic allocates the new container to the machine that is with maximum {\\em UCaC} after allocation and can fit the container. If no such machine exists, the new container is allocated to a new empty machine. Let $x_i$ be the allocation on machine $i$ and $\\Delta x$ denote the new container, \nthe Best-Fit heuristic selects machine $i^* = \\argmax_{i \\in [N], U_\\alpha (x_i + \\Delta x) \\leq V} \\{ U_\\alpha (x_i + \\Delta x)  \\}$ for the new container if such machine exists.\n\nIn classic deterministic bin packing, the intuition of Best-Fit is to fit containers with the least resulted fragment at the decision time. It can be concluded that in our SBPP formulation, Best-Fit greedily minimizes {\\em UCaC}.\nIn the online setting where container requests are processed sequentially, the Best-Fit heuristic is one of the most robust and efficient methods in practice to our knowledge.\n\n\n"
                },
                "subsection 5.2": {
                    "name": "Offline Heuristic Algorithm",
                    "content": " \n\\label{sub:solve-offline-heuristic} \n\nIn the cloud applications, when a batch of containers of multiple services needs to be allocated simultaneously, the information of containers in the batch is known at decision time. Thus, offline algorithms can be utilized since they generally have better performance than online algorithms. We therefore propose a bi-level offline heuristic (Algorithm \\ref{alg:solver-bilevel-heuristics}) in this subsection and a sub-optimal offline algorithm with better optimality in Section \\ref{sub:solve-offline-cuttingstock}.\n\nThe details of the proposed bi-level heuristic is given in Appendix (Alg.~\\ref{alg:solver-bilevel-heuristics}). The main intuitions are as follows.\n\\begin{itemize}\n    \\item Sort machines by cumulative uncertainty $\\{B_i\\}$ non-increasingly. The\n    machine with larger \\textit{uncertainty} term $B_i$ is preferred,\n    since {\\em UCaC} is a submodular function and allocating new containers on the machine with larger $B_i$ minimizes cluster {\\em UCaC}.\n    % The machine with bigger used capacity (i.e., smaller left capacity) is preferred, such that the bin packing is more tighter and use less number of bins. \n    The underlying motivation is the same with the best-fit heuristics.\n    \\item Sort containers by metric $\\{{b_j}/{\\mu_j}\\}$ non-increasingly.\n    Container with larger \\textit{normalized uncertainty} (${b_j}/{\\mu_j}$) is preferred,\n    % The container with bigger variance is preferred, such that the cluster {\\em UCaC} is greedily optimized. \n    since allocating containers with larger \\textit{normalized uncertainty} greedily optimizes cluster {\\em UCaC}.\n\\end{itemize}\nThe insights above are motivated by the proof of Theorem~\\ref{th:relaxed-consistency}.\n\n% Alg.~\\ref{alg:solver-bilevel-heuristics} presents the algorithm based on the above bi-level heuristics.\n\n\n"
                },
                "subsection 5.3": {
                    "name": "Offline Algorithm: Cutting Stock Approach",
                    "content": "\n\\label{sub:solve-offline-cuttingstock}\n\nIn the case where the number of services $K$ is not too large, and there is enough historical data of different services, the bin packing problem with empty machines can be efficiently solved as a cutting stock problem (CSP, detailed in Appendix \\ref{app:solve-sbp-empty}).\nIn this subsection, we propose a cutting stock formulation of the SBPP for nonempty machines and a corresponding offline algorithm (Algorithm \\ref{alg:solver-cutting-stock}).\n\n",
                    "subsubsection 5.3.1": {
                        "name": "The  CSP formulation",
                        "content": "\nThe CSP is solved by generating patterns iteratively.\nA \\textit{pattern} $p_j\\in \\R^K$ is a combination of containers in each service that satisfies the constraints\n\\begin{align}\n& \\sum_{k=1}^{K} \\mu_{k} p_{kj} + D(\\alpha) \\sqrt{\\sum_{k=1}^{K} b_{k} p_{kj}} \\leq V, ~ p_{kj}\\in \\I, \\quad k \\in [K] \\label{eq:pattern1}.\n\\end{align}\nConstraint (\\ref{eq:pattern1}) guarantees that the pattern is feasible.\nFor the SBPP with empty bins, one can optimize the continuous relaxation of the CSP (\\ref{eq:cutting-stock-relax}) by finding a pattern set $P\\in\\R^{K\\times L}$ using the column generation method (detailed in Appendix \\ref{app:solve-sbp-empty}). \nThe column generation method is a procedure that adds a single pattern (column) to $P$ at each iteration until no patterns can be generated by this method.\n\nThe following proposition shows that given a proper pattern set, the SBPP with either nonempty or empty bins can be efficiently solved by the CSP formulation (\\ref{eq:cutting-stock-generalized}) that optimizes {\\em UCaC}.\n\\begin{proposition}\n\\label{proposition:non-empty-cutting-stock}\n  Given service distributions $(\\mu_k, b_k)$,  requests $m_k$ for $k \\in [K]$, and a  pattern set $P$, \n  suppose containers in all nonempty machines can be covered by some patterns in $P$, i.e., the number of containers of each service in each nonempty machine is not larger than the number of containers of this pattern,  then the cluster UCaC can be optimized by optimizing the  following cutting stock problem:\n  \\begin{equation}\n    \\label{eq:cutting-stock-generalized}\n    \\begin{aligned}\n    \\min_{v, w} ~& \\sum_{j \\in [P]} v_j u_j = \\text{{\\em UCaC}} \\\\\n    \\text{s.t.} ~& (p_j - z_i) w_{ij} \\geq 0,  \\quad i, j \\in [N]\\times [P] \\\\\n            & \\sum_{j \\in [P]} p_{k j} v_j \\geq m_k + \\sum_{i\\in[N]} z_{ik}, \\quad k \\in [K]\\\\\n            & \\sum_{i=1}^{n} w_{ij} = v_j,  \\quad j \\in [P] \\\\\n            & \\sum_{j \\in [P]} w_{ij} = 1,  \\quad i \\in [N_0] \\\\\n            & \\sum_{j \\in [P]} w_{ij} \\leq 1,  \\quad i \\notin [N_0] \\\\\n            & w_{ij} \\in \\{0, 1\\}, \\quad v_j \\in \\I,\n    \\end{aligned}\n  \\end{equation}\n  where $v_j$ is the number of times pattern $p_j$ is used, $u_j$ is the UCaC of pattern $p_j$, \n  $w_{ij} = 1$ only if pattern $p_j$ is used in machine $i$, \n  $[n_0]$ is the index set of nonempty machines and $[P]$ is the index set of patterns.\n\\end{proposition}\n\n"
                    },
                    "subsubsection 5.3.2": {
                        "name": "Solving the CSP",
                        "content": "\nWe now propose the framework to solve the CSP (\\ref{eq:cutting-stock-generalized}).\nThe proposed Algorithm \\ref{alg:solver-cutting-stock} consists of three separated parts: generating a feasible pattern set (\\texttt{PatternGen}), solving the generalized CSP (\\texttt{SolveCSP}) and compute the container placement.\n\\begin{algorithm}\n\\DontPrintSemicolon\n\\caption{CSP Algorithm for SBPP}\n\\label{alg:solver-cutting-stock}\n\\SetAlgoVlined\n\\SetKwInOut{Input}{Input}\n\\SetKwInOut{Output}{Output}\n\\SetKw{KwBy}{by}\n\\Input{Request $m \\in \\I^K$}\n\\Input{Parameters of Equation \\ref{eq:reformulation}: $\\{ \\{(\\mu_j, b_j) \\}, z, V, \\alpha\\}$}\n\\Output{Mapping of containers to machines $x \\in I^{N \\times K}$}\n\\sf{\n\\Begin{\n    \\tcp{Pattern Generation}\n    \\nl $P \\gets $ PatternGen ($ \\{(\\mu_j, b_j) \\}, z, V, \\alpha $); \\\\\n    \n    \\tcp{Solve the CSP (\\ref{eq:cutting-stock-generalized})}\n    \\nl   $w \\gets $ SolveCSP $\\left(\\{(\\mu_j, b_j) \\}, z, V, \\alpha, P \\right) $;\\\\\n    \n    \\tcp{Compute Container Placement}\n    \\nl $x \\gets $ PatternCombinationToContainerPlacement ($w, P$); \\\\ \n} % begin-end\n} %sf\n\\end{algorithm}\n\n% \\textbf{Analysis of PatternGen} \nThe first part of the algorithm (\\texttt{PatternGen}) can be computed ahead of the container resource usage peaks, \nsince generating a pattern set by the column generation method can be computationally expensive compared to solving the CSP.\n\n\\texttt{SolveCSP} solves the generalized CSP (\\ref{eq:cutting-stock-generalized}). \nNote that the optimization problem is a  mixed-integer linear programming problem, which can be efficiently solved by commercial solvers that give better sub-optimal solutions than online or offline heuristics. \n\nIn the end, the container placement $x_{ij}$ for new requests is computed from $w_{ij}$ output by \\texttt{SolveCSP}.\nThus, $x_{i} = p_j - z_i$ when pattern $p_j$ is used to cover machine $i$.\n\n\n%%\n"
                    }
                }
            },
            "section 6": {
                "name": "Experiments",
                "content": "\n\\label{sec:experiments}\nIn this section, we evaluate the performance of our proposed methods for the {\\em UCaC}-based SBPP formulation on both synthetic datasets and real cloud traces. We refer to the three algorithms in Section \\ref{sec:methodology} as: {\\bf BF-UCaC} (best-fit with {\\em UCaC}), {\\bf BiHeu} (offline bi-level heuristics) and {\\bf CSP-UCaC} (solving cutting stock problem minimizing {\\em UCaC}). We compare with two baselines: {\\bf BF-n$\\sigma$} and {\\bf CSP-Mac}. BF-n$\\sigma$ is the deterministic Best-Fit algorithm, in which the container size is a deterministic value estimated by the n-Sigma method ($n = \\Phi^{-1}(\\alpha)$). CSP-Mac minimizes the number of used {\\bf machines}, and is implemented in the same algorithmic framework as CSP-UCaC.\n\nIn CSP-UCaC and CSP-Mac, Gurobi 9.5~\\cite{gurobi} is used to solve the optimization problems in Section \\ref{sub:solve-offline-cuttingstock}. \nFor all experiments, we use a simulated cluster where 4,000 machines run on and machine capacity is 31.58 CPU cores. \n\n",
                "subsection 6.1": {
                    "name": "Experiments on Synthetic Datasets",
                    "content": "\n\\label{sub:experiments-sync}\n\nThe synthetic datasets are generated as follows. (1) The per-service container resource usage distributions are sampled from a pool of 17 Gaussian distributions summarized from real traces and then multiplying the standard deviation with a random factor, i.e., $(\\mu, \\sigma' = \\sigma \\times \\mathcal{U}(0.9, 1.1))$. \n(2) The instances of container resource usages are sampled by the per-service distributions independently and then truncated to $(0, \\text{limit})$, which are used to estimate the violations.\n(3) The nonempty container layout is generated like this: stochastic bin packing on empty machines and then randomly delete about half containers. \n(4) The requests are generated by computing the difference between the target container layout -- a predefined initial layout multiplying a scale factor to each service container number, and the current layout.\n\n\n",
                    "subsubsection 6.1.1": {
                        "name": "Experiments on nonempty cluster",
                        "content": "\n\nWe test two cases on non-empty cluster layout, named scale-up and scale-down.\nThe nonempty cluster layout (i.e., the mapping of containers to machines) is constructed as follows. We first randomly generate the per-service container resource usage distributions.\nThen, we build an {\\em initial layout} by solving with bf CSP-UCaC. \nFinally, we evict part of the containers from the layout according to the rate given in Table~\\ref{tab:synthetic_stats}. \n\nIn the scale-down (scale-up) case, after allocating the requested containers, the number of containers is smaller (larger) than that of the {\\em initial layout}. \nTo make results with different initial layouts comparable, we normalize the {\\em UCaC} and the number of used machines (\\#Mac) with the value of BF-n$\\sigma$.\nWe perform 5 runs of tests with different random seeds and report the average values. \\\\\n\\textbf{Results:} ~ \nTable~\\ref{tab:perf-scale-down} and \\ref{tab:perf-scale-up} show detailed performance comparison for different number of services $K$ and confidence level $\\alpha$ in the scale-down and scale-up cases.\n\nCompared to the deterministic best fit BF-n$\\sigma$, our three {\\em UCaC}-based algorithms have lower {\\em UCaC} and less \\#machines in every test case.\nAlthough the violation rates are higher for the three algorithms, they are still less than the given risk $1-\\alpha$ in most cases, showing less resource usage with a satisfying confidence level.\n\\footnote{For rare cases in $K=10$ and $K=15$, the violation rate is more than $1-\\alpha$; this is because of the container resource usage truncation, which leads to a minor positive bias of empirical mean and variances from that of the sampling distributions.} \nThe results also show that our proposed algorithms have similar performance over different test cases.\n\nCompared to CSP-Mac, which optimizes \\#machines, our proposed methods have similar performance on {\\em UCaC} and used machines for the scale-up case (Table~\\ref{tab:perf-scale-up}).\nHowever, for the scale-down case (Table~\\ref{tab:perf-scale-down}) in which all new requests can be allocated into existing nonempty machines, our proposed methods achieve lower {\\em UCaC}, indicating lower resource usage on the cluster.\nThe results in the scale-down case demonstrate the effectiveness of the metric {\\em UCaC} and the {\\em UCaC}-based SBPP formulation.\n\n\n\n\n\n\n"
                    },
                    "subsubsection 6.1.2": {
                        "name": "Experiments on empty cluster",
                        "content": "\nWe also test on the empty cluster.\nAs shown in Theorem~\\ref{th:relaxed-consistency} and ~\\ref{th:bound}, optimizing {\\em UCaC} induces optimizing the number of used machines. \nThus, we compare the performance of CSP-UCaC and CSP-Mac.\\\\\n\\textbf{Results:} ~ \nThe results are shown in Table \\ref{tab:relaxed-consistency}. \nCompared to CSP-Mac, CSP-UCaC has lower {\\em UCaC} in every test case, and \\#machines are the same or slightly larger as expected.\nThis empirically verifies that for empty cluster machines, our {\\em UCaC}-based methods are consistent with the SBPP that optimizes the number of used machines.\nFor the violation rates, the two methods have similar performance and satisfy the given confidence levels in most cases.\n\n\n\n"
                    },
                    "subsubsection 6.1.3": {
                        "name": "Comprehensive comparison",
                        "content": "\nFig.~\\ref{fig:bp-visual} shows the machine {\\em UCaC} usages visualization of the solution given by different algorithms in the nonempty and empty cluster cases.  \nThe results are from the same initial cluster state with $K=20$ and $\\alpha=0.999$.\n% the underlying data are from some experiments of Table 1-3. \n\nAs shown in Fig.~\\ref{subfig:scale-down}, BF-n$\\sigma$ uses much more machines than others, although its per-machine {\\em UCaC} is lower.\nFor CSP-Mac, almost all used machines have higher {\\em UCaC}, as the algorithm fails to optimize the resource usage.\nIn contrast, our three {\\em UCaC}-based algorithms can effectively optimize both the {\\em UCaC} in both nonempty and empty machines cases, as optimizing {\\em UCaC} is able to take full advantage of the risk-pooling effect to optimize the cluster resource usage.\n\nAs shown in Fig.~\\ref{subfig:scale-up} and Fig.~\\ref{subfig:empty}, the CSP-UCaC and CSP-Mac show similar machine {\\em UCaC} usage distributions in the scale-up case of nonempty cluster and the case of empty cluster.\nThis indicates that when new machines are needed to allocate containers, optimizing {\\em UCaC} and \\#machines leads to close solutions. \nIn conclusion, our proposed {\\em UCaC}-based problem formulation and solving algorithms give overall better performance on all three cases.\n\n\n"
                    },
                    "subsubsection 6.1.4": {
                        "name": "Scalability analysis.",
                        "content": " \nIn the real practice of SBPP, especially in the area of cloud service, one major concern is the solving time. Consider the algorithm complexity. Suppose $K$, $M$, $N$ are the number of services, the number of requested containers, and the number of machines in respective, and $|P|$ is the number of patterns used in CSP solvers. Best-Fit heuristics algorithms including BF-n$\\sigma$ and BF-UCAC have complexity $O(MN)$, while BiHeu has $O(K\\log K + N\\log N + MN)$ where the first terms are for sorting services and machines respectively. For CSP methods, there are two computing phases -- columns generation and cutting stock problem optimization; among which the first phase depends on whether we have good predefined initial patterns as well as the generation algorithm which is hard to estimate, while the second phase's complexity is rough $O(a * |P|N)$ where $a$ depends on the used solver. \nIn our experiments, with a platform of 8 cores of Intel Xeon E5-2690 and 128GiB memory, the run time is as follows. For the largest container requests $M=14,213$, BF-UCaC and BiHeu consume 14 and 0.7$s$ in respect, while BF-n$\\sigma$ consumes 0.4$s$. With respect to CSP-UCaC, our most time-consuming experiments is for $K=20, \\alpha=0.999$, where the pattern generation (column generation) with strict convergence consumes 14,697$s$, the cutting stock solving consumes 154$s$. However, for most cases, especially when $K \\leq 15$, the pattern generation typically consumes tens of seconds, and the solving cutting stock consumes less than 1$s$. \n\n%\n"
                    }
                },
                "subsection 6.2": {
                    "name": "Experiments on Real Traces",
                    "content": "\n\\label{sub:experiments-real}\nWe evaluate the proposed methods on a 9-day regional trace data of a first-party application. The dataset contains 17 main services and over 10,000 containers at peak time in total; the details are given in Appendix \\ref{app:dataset}. Since the focus of this paper is on the container allocation at usage peaks, we directly summarize the empirical peak resource usage distribution from data. Also, we exclude 2 weekend days in the 9-day period, as at weekends workloads are significantly low and no nontrivial container allocation was happened.\n\nIn all, we compare our proposed methods with two baselines (BF-n$\\sigma$ and CSP-Mac) on container allocations of 7 days with only the first day initialized as an empty cluster. Three metrics are used for evaluation: UCaC at confidence $99.9\\%$, the average \\#machines, and total machine capacity violations in the 7-day period. We perform 5 tests with different random seeds and report the average values.\n\nThe results are shown in Table \\ref{tab:experiments-real}.\nFor the BF-$n\\sigma$ methods, the BF-$3.09\\sigma$ uses more machines and has higher {\\em UCaC} than all other methods. The performance of BF-$n\\sigma$ can be improved by changing $n$ (or $\\alpha$), and the best $n$ is 1.23 ($\\alpha=0.89$) through our experiments, while the performance is still worse than {\\em UCaC} based methods.\n\nCompared to CSP-Mac, the best method that optimizing the number of used machines under chance constraints, our {\\em UCaC}-based methods have significantly lower UCaC and even less number of used machines averaged on 7 days, with only a slight increase of cumulative violations in 7 days. For the better cumulative performance on the number of used machines, the primary reason is that UCaC-based methods explicitly consider the effect of non-empty machines while CSP-Mac can not do that. In summary, in practice of continuous container allocations our {\\em UCaC}-based methods should be able offer better allocation strategies that can balance resource usage and violations than the baselines.\n\n\n\n\n"
                }
            },
            "section 7": {
                "name": "Related work",
                "content": "\n\\label{sec:related-work}\n%In this section, we briefly discuss the related works from both operational research on stochastic bin packing problem, recent system research on resource over-commitment optimization in cloud services, and the recent trend to incorporate exact solvers in the system community.\n\n\\textbf{Stochastic Bin Packing Problem.} Bin packing Problem (BPP) is a classic combinatorial optimization problem and has been thoroughly investigated through the past two decades; see \\cite{delorme2016bin} and \\cite{christensen2016multidimensional} for detailed review. Our work specifically focuses on the stochastic bin packing problem (SBPP), an extension of the classic BPP, where the item sizes are stochastic. The physical capacity constraint may be violated with a small probability, providing the chance of over-commitment. Note that the term SBPP was also used to denote other extensions to the BPP, such as the item profits when being taken \\cite{perboli2012stochastic}, which is not our concerning scope. \\citet{coffman1980stochastic} study a stochastic model in which an arbitrary distribution of item sizes is assumed. They obtained an asymptotic expected bin occupancy  for the next-fit algorithm. Different from this work which assumed the item size to be a known random variable, \\citet{cohen2019} study the case that the item size follows unknown distribution and focus on computing a solution that is feasible with high probability before observing the actual sizes. They model it as chance constraints and propose a formulation that transforms each chance constraint into a sub-modular function. They developed a family of online algorithms and provided a constant factor guarantee from optimal. \\citet{martinovic2021} derive several (improved) lower and upper bounds and study their worst-case performance metrics. They also describe various linearization techniques to overcome the drawback of nonlinearity in the original model proposed by \\citet{cohen2019}. Besides,  \\citet{kuccukyavuz2021chance} gives a broader survey on applications of chance-constrained optimization.\n\n% the aim is to assign the items to a minimum number of unit capacity bins while over-loading a bin is allowed up to a given tolerable limit. \n\\textbf{Resource over-commitment and virtual machine consolidation in cloud.} Overcommitment [\\citealp{jin2020improving,sun2018rose}] in which the sum of allocated resources to multiple containers is larger than physical capacity, is proposed to increase the resource utilization in recent cloud architecture like Borg \\cite{borg}. With proper consolidation of multiple containers~\\cite{borg-next}, statistical multiplexing to over-commit resources can avoid almost all resource violations. Such consolidation algorithms can also relate to research on virtual machine consolidation~\\cite{roytman2013algorithm}, which searches the optimal combination of workloads or containers to avoid shared resource contention. Orthogonal to better scheduling, others focus on the prediction of container utilization. \\citet{noman2021} propose peak oracle, which is the maximum idle capacity that a machine can advertise without violating any performance. Autopilot \\cite{rzadca2020autopilot} uses a decision-focused prediction approach to do vertical scaling to automatically set the resource to match the containers future peak. Besides, \\citet{util-pred} is an earlier work that advises container scheduling based on prediction on container's future resource usage. \n\n\\textbf{Adoption of Solvers in Resource allocation}\nRecently, integrating solvers for mathematical programming into resource allocation has become popular in system communities \\cite{narayanan2021solving, ras2021}.\n\\citet{narayanan2021solving} noticed that many allocation problems in the computer system are granular and proposed an efficient new method that splits the problem into\nsmaller problems that can be solved by exact solvers. RAS (\\cite{ras2021}) is integrated with exact solvers to scale\nresource allocation to problems with a larger size.\n\n\n"
            },
            "section 8": {
                "name": "Conclusions",
                "content": "\nIn this paper, we introduce and formulate the problem of stochastic bin packing on nonempty machines, which was not well realized in existing operational research. In particular, by introducing a new optimization metric {\\em UCaC}, we propose a unified problem formulation for the SBPP with both empty and nonempty machines. Further, we designed solving algorithms of both heuristics and cutting-stock based exact algorithms. Extensive experiments on both synthetic and real cloud traces demonstrate that our {\\em UCaC}-based optimization methodology performs better than existing approaches that optimize the number of used machines. Recently, integrating solvers for mathematical programming into scheduling has become popular in system communities \\cite{narayanan2021solving, ras2021}. As part of this trend, this paper makes the very first step for the stochastic bin packing on nonempty machines, which is an important problem in cloud resource scheduling.\n\n%\n\\begin{acks}\nWe thank Fangkai Yang, Jue Zhang, Tao Shen, Rahul Mohana Narayanamurthy, Terry Yang, Chetan Bansal, Senthil kumaran Baladhandayutham, Victor Rhle, Randy Lehner, Jim Kleewein, Silvia Yu and Andrew Zhou for the insights and discussions on this work and their support throughout the project.\n\\end{acks}\n\n%%\n\\bibliographystyle{ACM-Reference-Format}\n\\bibliography{references}\n\n\n%%%\n\\clearpage\n\\appendix\n\n"
            },
            "section 9": {
                "name": "th:bound",
                "content": "\n\\label{app:proof-of-th5}\n\n\\begin{proof}\nLet $N$ be the number of machines that the formulation with UCaC minimized purchases when serving all $J$ items.\nFor any machine $1 \\leq i \\leq N$, $S_i$ is defined to be the set of jobs assigned to machine $i$. \nFor any pair of machines $i  \\neq i_0 $, when the solution is optimal, the set $S_i \\cup  S_{i_0}$ is infeasible for the modified capacity constraint, i.e., the items in machine  $S_i $ and $ S_{i_0}$  could not be assigned to one machine when the UCaC used is minimized. Otherwise, since $ \\sqrt{\\sum_{j \\in S_i \\cup {S_{i_0}}} b_j}< \\sqrt{\\sum_{j \\in S_i} b_j}+\\sqrt{\\sum_{j \\in S_{i_0}} b_j}$, we can place the items in $S_i $ and  $ S_{i_0}$ in machine $i$ (or $i_0$) and reduce the UCaC, which contradicts the assumption that the UCaC used is optimized. By taking $b_j{^*} = \\frac{b_j D(\\alpha)^2}{V^2 }, \\mu_{j}{^*} = \\frac{\\mu_{j}}{V} $, the modified capacity constraint can be normalized as $\\sum_{j=1}^{K}{x_{i, j}\\mu_j^*} +  \\sqrt{\\sum_{j=1}^{K}{x_{i, j} b_j^*} } \\leq 1 $.\n\n\\begin{lemma}\nFor any infeasible item set $T$, we have $\\sum_{j\\in{T}}(\\mu_j^*+b_j^*)>\\frac{3}{4}$\n\\end{lemma}\n\n\\begin{proof}{Proof}\nFor any infeasible set T, we have by definition $\\sum_{j\\in T}u_j^*+\\sqrt{\\sum_{j \\in T}b_j^*}$ > 1. We denote $x=\\sum_{j \\in T} u_j^*$, and $y=\\sqrt{\\sum_{j\\in T}b_j^*}$. Then  $y > 1-x$. If $x>1$, this lemma holds. Otherwise, we obtain :\n\\begin{equation}\n    x+y^2>x+(1-x)^2=x^2-x+1=(x-\\frac{1}{2})^2+\\frac{3}{4}\\geq \\frac{3}{4}\n\\end{equation}\n\\end{proof}\n\nGiven $S_i \\cup {S_{i_0}}$, we have $\\sum_{j\\in{S_i \\cup {S_{i_0}}}}(\\mu_j^*+b_j^*)>\\frac{3}{4}$. By summing up this inequality for all pairs of machines i and $i_0$, we obtain:\n\\begin{equation}\n    \\sum_{1\\leq i \\leq N, 1\\leq i_0 \\leq N, i \\neq i_0} \\sum_{j \\in S_i \\cup S_{i_0}}(u_j^* +b_j^*) >\\frac{3}{4}\\tbinom{N}{2} \\times 2\n\\end{equation}\n The left hand side of this inequality is equal to $2(N-1)\\sum_{1\\leq j \\leq J }(u_j^* +b_j^*)$. This is because that for each machine $i$, it appears  $2(N-1)$ times, thus the items in each machine also appear $2(N-1)$ times. Therefore, \n\\begin{equation}\n    \\frac{3}{8}N<\\sum_{1 \\leq j \\leq J} (u_j^*+b_j^*)\n\\end{equation}\n\nFor the optimal assignment, we use $S_i^*$ to denote the set of containers in machine i. For containers in  $S_i^*$, we have $\\sum_{j\\in S_i^*}u_j^*+\\sqrt{\\sum_{j \\in S_i^*}b_j^*}$ <1. Since $u_j^*$ >0 and $b_j^* >0$, we have that $\\sum_{j \\in S_i^*}b_j^*<1$. Therefore $\\sum_{j\\in S_i^*}u_j^*+\\sum_{j \\in S_i^*}b_j^* < \\sum_{j\\in S_i^*}u_j^*+\\sqrt{\\sum_{j \\in S_i^*}b_j^*} <1$. Summing up for all of the machine $i$, we have:\n\\begin{equation}\n  \\sum_{1 \\leq j \\leq J} (u_j^*+b_j^*)=\\sum_{1\\leq i \\leq N^*}(\\sum_{j\\in S_i^*}u_j^*b_j^*)< N^* \n\\end{equation}\nTherefore, we obtain that $ \\frac{3}{8}N< N^*$, that is $N<\\frac{8}{3}N^*$.\n\\end{proof}\n\n\n"
            },
            "section 10": {
                "name": "Details of Bi-Heuristics Algorithm",
                "content": "\nAlgorithm ~\\ref{alg:solver-bilevel-heuristics} descibes the detailed procedures of our proposed online bi-heustics in Section~\\label{sub:solve-offline-heuristic}.\n\n\\begin{algorithm}\n\\DontPrintSemicolon\n\\caption{Bi-level Heuristic for SBPP}\n\\label{alg:solver-bilevel-heuristics}\n\n\\SetAlgoVlined\n\\SetKwInOut{Input}{Input}\n\\SetKwInOut{Output}{Output}\n\\SetKw{KwBy}{by}\n\n\\Input{Request $m \\in \\I^K$}\n\\Input{Parameters of Equation \\ref{eq:reformulation}: $\\{ (\\mu_j, b_j), z, V, \\alpha\\}$}\n\\Output{Mapping of containers to machines $x \\in I^{N \\times K}$}\n\n\\sf{\n\\Begin{\n    \\tcp{Presort}\n    \\nl Sort machines in non-increasing order of $B_i, ~ i \\in [N]$; \\\\\n    \\nl Sort services in non-increasing order of $b_j / \\mu_j, ~ j \\in [K]$;\\\\\n    \n    \\nl $r \\gets m \\in \\I^K$; \\\\\n    \n    \\tcp{Allocate machine for containers}\n    \\nl \\ForEach{$i = 1 \\to N$}{\n        \\nl \\ForEach{$j = 1 \\to K$}{\n            \\nl {$x_{i, j} \\gets \\max_{w \\in I, 0 \\leq w \\leq r_j}{w}$, \\\\ \n                \\quad \\quad \\quad s.t.~ $w \\mu_j + D(\\alpha) \\sqrt{w b_j + B_j} \\leq V - C_i$};\\\\\n            \\nl {$B_i \\gets B_i + x_{i,j} b_j$};\\\\\n            \\nl {$C_i \\gets C_i + x_{i,j} \\mu_j$};\\\\\n            \\nl {$r_j \\gets r_j - x_{i,j}$};\\\\\n            \n            \\nl \\If{$V-C_i \\leq \\sigma$}{\n                \\nl Break; \\\\\n            }\n        }\n    }\n}\n}\n\\end{algorithm}\n\n\n"
            },
            "section 11": {
                "name": "sub:solve-offline-cuttingstock",
                "content": "\n\\label{app:solve-sbp-empty}\n\nIn this appendix, we show details of the cutting stock formulation and the column generation method to generate the pattern set.\n\n",
                "subsection 11.1": {
                    "name": "The cutting stock problem",
                    "content": "\nThe cutting stock formulation (\\ref{eq:cutting-stock}) can be used to solve the bin packing problem by finding a pattern set $P$ using the column generation technique \\cite{delorme2016bin}. \nA pattern $p\\in \\R^K$ in  $P$ is a combination of items that satisfies the capacity constraint.\nLet $P \\in \\R^{K \\times L}$ be the pattern set containing $L$ patterns, $m\\in \\R^K$ be the requests of the $K$ services and $v_j$ be the number of times each pattern $p_j$ is used.\n\nThe cutting stock problem is defined as follows,\n\\begin{equation}\n\\label{eq:cutting-stock}\n\\begin{aligned}\n\\min_{v} & \\sum_{j=1}^{L} v_j \\\\\n\\text{ s.t. } & \\sum_{j=1}^{L} p_{kj} v_j \\geq m_k, \\quad k \\in [K] \\\\\n& v_j \\in \\I, \\quad j \\in [L], \n\\end{aligned}\n\\end{equation}\nwhere $P \\in \\R^{K \\times L}$ is the pattern set, each column of $P$ is a single pattern and $v_j$ is the number of times pattern $p_j$ is used. \nFor each bin, the items are allocated according to the pattern.\nThus, the number of patterns used ($\\sum_{j=1}^{L} v_j$) is equivalent to the number of bins used.\n\nThe relaxation of the cutting stock problem is defined as\n\\begin{equation}\n\\label{eq:cutting-stock-relax}\n\\begin{aligned}\n\\min_{x} & \\sum_{j=1}^{L} v_j \\\\\n\\text{ s.t. } & \\sum_{j=1}^{L} p_{kj} v_j \\geq m_k, \\quad k \\in [K] \\\\\n& v_j \\geq 0,  v_j \\in \\R, \\quad j \\in [L].\n\\end{aligned}\n\\end{equation}\n\n"
                },
                "subsection 11.2": {
                    "name": "The column generation method",
                    "content": "\nThe column generation method solves the relaxation of the cutting stock problem (\\ref{eq:cutting-stock-relax}) and generates a pattern set $P$ iteratively.\nThe relaxation of the cutting stock problem (\\ref{eq:cutting-stock-relax}) is called the restricted master problem (RMP) in the column generation method.\n\nThe dual of RMP is given by:\n\\begin{equation}\n\\label{eq:cutting-stock-relax-dual}\n\\begin{aligned}\n\\max_{\\pi} ~& \\pi ^\\top m \\\\\n\\text{ s.t. } ~& \\sum_{i=1}^{K}\\pi_i p_{ij} \\leq 1, \\quad j \\in [L] \\\\\n& \\pi_i \\geq 0, \\quad i \\in [K].\n\\end{aligned}\n\\end{equation}\nLet $\\bar \\pi$ be the optimal solution of the dual problem (\\ref{eq:cutting-stock-relax-dual}).\nA pattern $v$ is computed by solving the subproblem:\n\\begin{equation}\n\\label{eq:cutting-stock-sub}\n\\begin{aligned}\n\\min_{v} ~& c = 1 - \\bar\\pi^\\top v \\\\\n\\text{ s.t. } ~& v \\in \\mathcal{F} \\\\\n\\end{aligned}\n\\end{equation}\nwhere $\\mathcal{F}$ is the set of feasible patterns.\n\\begin{remark}\nIn our setting, $\\mathcal{F}$ is the set of patterns that satisfies the \ncapacity constraint of CPU usage (\\ref{eq:pattern1}).\nThe cloud provider can also add constraints of other resources (memory, etc.) into $\\mathcal{F}$.\n\\end{remark}\n\nThe column generation method starts with a given pattern set $P^{(0)}$, which can be initialized as a diagonal matrix.\nIn our setting, $P^{(0)}_{ii}$ is set to the maximum number of containers of service $i$ that can fit into the machine.\n\nAt each iteration, the column generation method first solves the dual of RMP with the pattern set $P$.\nThen, the subproblem (\\ref{eq:cutting-stock-sub}) is solved using the solution from the dual.\nIf the reduced cost $c = 1 - \\bar \\pi^\\top v^* < 0$, then the new pattern $v^*$ is added to the pattern set $P$.\nThe procedure is iterated until no new pattern with negative reduced cost can be found.\n\n\n%%\n"
                }
            },
            "section 12": {
                "name": "Illustration of Cluster",
                "content": "\n\\label{app:cluster}\n\nFig.~\\ref{fig:cluster} illustrates a simple cluster layout, where 6 containers of 3 services (say A, B, and C) are allocated to machine 1 and machine 2, while machine 3 is still empty (i.e., has no assigned containers).\n\n\n\n%%\n"
            },
            "section 13": {
                "name": "Dataset details",
                "content": "\n\\label{app:dataset}\n%Note that for data compliance, we have done some re-sampling and re-normalization on the real traces without loss of statistic representation. Thus, with respect to {\\em real traces}, we indeed mean the data after processing rather than the raw information.\n\n",
                "subsection 13.1": {
                    "name": "Real traces",
                    "content": "\nOur used dataset is sampled from a real workload which consists of 17 main services. For data privacy compliance, we can't release the full data. Instead, we give the summary of necessary statistics closely related to our experiments. Fig.~\\ref{fig:peak_ts_stats} presents the mean cpu core usage of 17 services at {\\em peak} time of each day, as well as the ratio of standard deviation against mean value of cpu core usage. As shown, for most services, the cpu usage on weekends is very low and the relative deviation is high, while in weekdays the mean cpu usage is high with a relatively reasonable deviation. Note that in our experiments of section \\ref{sub:experiments-real} the container bin packing is only done on 7 weekdays.\n\n\n\n\n\n"
                },
                "subsection 13.2": {
                    "name": "Synthetic datasets",
                    "content": "\n\\label{sub:synthetic_datasets}\nThe base per-service container distributions and numbers are summarized from a weekday of the real trace, {\\em with some re-scaling for data privacy requirements}. Their statistics are given in Table~\\ref{tab:synthetic_stats} where each column is for a service. Besides, the table also provides other parameters for simulation, including the number of containers per service in the base layout, and the rates that used to remove containers per service to construct the initial nonempty layout.\n\n"
                }
            }
        },
        "tables": {
            "tab:perf-scale-down": "\\begin{table}\n\\centering\n\\scalebox{0.75} \n{\n\\begin{tabular}{ccccc|ccc}%\n\\toprule\n& & \\multicolumn{3}{c}{$\\alpha = 99.9\\%$} & \\multicolumn{3}{c}{$\\alpha = 99\\%$}  \\\\\n\\cmidrule(lr){3-5} \\cmidrule(lr){6-8} \n$K$   & Alg.         & UCaC & \\#Mac & Violation (\\%) & UCaC & \\#Mac & Violation (\\%) \\\\\n\\midrule\n& BF-n$\\sigma$ & 1.00 & 1.00 & 0.00 & 1.00 & 1.00 & 0.03 \\\\\n& BF-UCaC & 0.94 & 0.71 & 0.04 & 0.96 & 0.75 & 0.47 \\\\\n5 & BiHeu & 0.94 & 0.71 & 0.02 & 0.96 & 0.75 & 0.62 \\\\\n& CSP-UCaC & 0.94 & 0.71 & 0.02 & 0.96 & 0.75 & 0.46 \\\\\n& CSP-Mac & 1.02 & 0.71 & 0.06 & 1.04 & 0.75 & 0.90 \\\\\n\\midrule\n& BF-n$\\sigma$ & 1.00 & 1.00 & 0.00 & 1.00 & 1.00 & 0.01 \\\\\n& BF-UCaC & 0.94 & 0.70 & 0.04 & 0.96 & 0.73 & 0.52 \\\\\n10 & BiHeu & 0.93 & 0.70 & 0.07 & 0.95 & 0.73 & 0.79 \\\\\n& CSP-UCaC & 0.94 & 0.70 & 0.07 & 0.95 & 0.73 & 0.80 \\\\\n& CSP-Mac & 1.01 & 0.70 & 0.06 & 1.04 & 0.73 & 0.82 \\\\\n\\midrule\n& BF-n$\\sigma$ & 1.00 & 1.00 & 0.00 & 1.00 & 1.00 & 0.02 \\\\\n& BF-UCaC & 0.94 & 0.70 & 0.06 & 0.96 & 0.76 & 0.69 \\\\\n15 & BiHeu & 0.93 & 0.70 & 0.04 & 0.95 & 0.76 & 0.57 \\\\\n& CSP-UCaC & 0.93 & 0.70 & 0.11 & 0.95 & 0.76 & 0.26 \\\\\n& CSP-Mac & 1.0 & 0.70 & 0.15 & 1.03 & 0.76 & 0.57 \\\\\n\\midrule\n& BF-n$\\sigma$ & 1.00 & 1.00 & 0.00 & 1.00 & 1.00 & 0.00 \\\\\n& BF-UCaC & 0.94 & 0.74 & 0.04 & 0.96 & 0.77 & 0.51 \\\\\n20 & BiHeu & 0.93 & 0.74 & 0.07 & 0.95 & 0.77 & 0.69 \\\\\n& CSP-UCaC & 0.94 & 0.74 & 0.02 & 0.96 & 0.77 & 0.26 \\\\\n& CSP-Mac & 1.01 & 0.74 & 0.00 & 1.05 & 0.77 & 0.53 \\\\\n\\bottomrule\n\\end{tabular}\n}\n\\caption{Performance comparison in the scale-down case. \n% {\\em UCaC} and \\#machines are normalized to that of BF-nSigma. All values are averaged in 5 evaluations with different seeds.\n}\n\\label{tab:perf-scale-down}\n\\end{table}",
            "tab:perf-scale-up": "\\begin{table}\n\\centering\n\\scalebox{0.75} \n{\n\\begin{tabular}{ccccc|ccc}%\n\\toprule\n& & \\multicolumn{3}{c}{$\\alpha = 99.9\\%$} & \\multicolumn{3}{c}{$\\alpha = 99\\%$}  \\\\\n\\cmidrule(lr){3-5} \\cmidrule(lr){6-8} \n$K$   & Alg.         & UCaC & \\#Mac & Violation (\\%) & UCaC & \\#Mac & Violation (\\%) \\\\\n\\midrule\n& BF-n$\\sigma$ & 1.00 & 1.00 & 0.00 & 1.00 & 1.00 & 0.00 \\\\\n& BF-UCaC & 0.94 & 0.66 & 0.06 & 0.96 & 0.70 & 0.79 \\\\\n5 & BiHeu & 0.94 & 0.65 & 0.07 & 0.95 & 0.69 & 0.60 \\\\\n& CSP-UCaC & 0.93 & 0.64 & 0.06 & 0.95 & 0.68 & 0.97 \\\\\n& CSP-Mac & 0.93 & 0.64 & 0.09 & 0.95 & 0.68 & 0.85 \\\\\n\\midrule\n& BF-n$\\sigma$ & 1.00 & 1.00 & 0.00 & 1.00 & 1.00 & 0.00 \\\\\n& BF-UCaC & 0.93 & 0.64 & 0.03 & 0.95 & 0.67 & 0.76 \\\\\n10 & BiHeu & 0.93 & 0.64 & 0.08 & 0.95 & 0.67 & 0.79 \\\\\n& CSP-UCaC & 0.92 & 0.63 & 0.13 & 0.94 & 0.66 & 0.86 \\\\\n& CSP-Mac & 0.92 & 0.63 & 0.14 & 0.94 & 0.66 & 1.13 \\\\\n\\midrule\n& BF-n$\\sigma$ & 1.00 & 1.00 & 0.00 & 1.00 & 1.00 & 0.00 \\\\\n& BF-UCaC & 0.93 & 0.66 & 0.07 & 0.95 & 0.69 & 0.66 \\\\\n15 & BiHeu & 0.93 & 0.65 & 0.08 & 0.94 & 0.68 & 0.80 \\\\\n& CSP-UCaC & 0.92 & 0.64 & 0.12 & 0.95 & 0.69 & 0.42 \\\\\n& CSP-Mac & 0.92 & 0.64 & 0.12 & 0.95 & 0.69 & 0.56 \\\\\n\\midrule\n& BF-n$\\sigma$ & 1.00 & 1.00 & 0.00 & 1.00 & 1.00 & 0.00 \\\\\n& BF-UCaC & 0.94 & 0.66 & 0.03 & 0.95 & 0.69 & 0.52 \\\\\n20 & BiHeu & 0.93 & 0.65 & 0.00 & 0.95 & 0.68 & 0.96 \\\\\n& CSP-UCaC & 0.94 & 0.68 & 0.07 & 0.95 & 0.70 & 0.70 \\\\\n& CSP-Mac & 0.94 & 0.68 & 0.03 & 0.96 & 0.70 & 0.51 \\\\\n\\bottomrule\n\\end{tabular}\n}\n\\caption{Performance comparison in the scale-up case.\n% {\\em UCaC} and \\#machines are normalized to that of BF-nSigma. All values are averaged in 5 evaluations with different seeds.\n}\n\\label{tab:perf-scale-up}\n\\end{table}",
            "tab:relaxed-consistency": "\\begin{table}\n\\centering\n\\scalebox{0.75} \n{\n\\begin{tabular}{ccccc|ccc}%\n\\toprule\n& & \\multicolumn{3}{c}{$\\alpha = 99.9\\%$} & \\multicolumn{3}{c}{$\\alpha = 99\\%$}  \\\\\n\\cmidrule(lr){3-5} \\cmidrule(lr){6-8} \n$K$   & Alg.         & UCaC & \\#Mac & Violation (\\%) & UCaC & \\#Mac & Violation (\\%) \\\\\n\\midrule\n5 & CSP-UCaC & 32360 & 1035 & 0.1 & 29604 & 942 & 0.9 \\\\\n& CSP-Mac & 32366 & 1035 & 0.1 & 29614 & 941 & 1.1 \\\\\n\\midrule\n10 & CSP-UCaC & 33156 & 1056 & 0.2 & 30160 & 958 & 0.8 \\\\\n& CSP-Mac & 33177 & 1054 & 0.1 & 30163 & 957 & 1.0 \\\\\n\\midrule\n15 & CSP-UCaC & 33708 & 1070 & 0.1 & 30670 & 1008 & 0.5 \\\\\n& CSP-Mac & 33713 & 1069 & 0.1 & 30721 & 1005 & 0.5 \\\\\n\\midrule\n20 & CSP-UCaC & 33413 & 1118 & 0.0 & 30255 & 995 & 0.4 \\\\\n& CSP-Mac & 33456 & 1110 & 0.1 & 30295 & 994 & 0.7 \\\\\n\\bottomrule\n\\end{tabular}\n}\n\\caption{Performance of bin packing on the empty cluster.}\n\\label{tab:relaxed-consistency}\n\\end{table}",
            "tab:experiments-real": "\\begin{table}[]\n\\centering\n\\scalebox{0.75} \n{\n    \\begin{tabular}{l|c|c|c|}\n    \\toprule\n        Algorithm & UCaC$_{99.9\\%}$ & \\#Machines & TotalViolations \\\\\n        \\midrule\n        %BestFit($1.04\\sigma$) & 40962.1 & 1252 & 9.2 \\\\\n        BF-$1.15\\sigma$ & 41293.5 & 1305 & 4.4 \\\\\n        %BestFit($1.28\\sigma$) & 41718.0 & 1363 & 1.4 \\\\\n        BF-$1.23\\sigma$ & 41558.8 & 1337 & 3.8 \\\\\n        BF-$3.09\\sigma$ & 46038.3 & 2144 & 0.0 \\\\\n        CSP-Mac & 42582.0 & 1395 & 1.9 \\\\\n        \\midrule\n        BF-UCaC & 41738.5 & 1350 & 2.6 \\\\\n        BiHeu & 41450.4 & 1333 & 2.4 \\\\\n        CSP-UCaC & 41402.3 & 1332 & 2.0 \\\\\n    \\bottomrule\n    \\end{tabular}\n}\n\\caption{Performance of 7-day continuous experiments on a real trace, averaged on 5 simulations with different seeds.}\n\\label{tab:experiments-real}\n\\end{table}",
            "tab:synthetic_stats": "\\begin{table}\n    \\centering\n    \\scalebox{0.75} \n    {\n    \\begin{tabular}{c|ccccccccc}\n        \\toprule\n        Mean &  6.18 & 2.47 & 1.07 & 4.12 & 1.06 & 0.73 & 1.94 & 2.48 & 2.42\\\\\n        Std & 1.73 & 0.47 & 0.43 & 2.69 & 0.85 & 0.19 & 0.9 & 0.82 & 0.97\\\\\n        \\#Containers & 270 & 55 & 1618 & 904 & 576 & 1085 & 1035 & 118 & 1450\\\\\n        \\midrule\n        Remove Rate & 0.5 & 0.3 & 0.8 & 0.5 & 0.8 & 0.8 & 0.5 & 0.5 & 0.5\\\\\n        \\midrule\n        \\midrule\n        Mean &  2.49 & 0.97 & 2.46 & 2.52 & 1.06 & 2.59 & 1.96 & 3.33 & \\\\\n        Std & 0.62 & 0.31 & 0.62 & 0.84 & 0.57 & 0.7 & 0.55 & 0.9 & \\\\\n        \\#Containers & 313 & 44 & 544 & 697 & 427 & 363 & 360 & 701 & \\\\\n        \\midrule\n        Remove Rate & 0.5 & 0.8 & 0.3 & 0.5 & 0.8 & 0.3 & 0.3 & 0.5 & \\\\\n        \\bottomrule\n    \\end{tabular}\n    }\n    \\caption{Per-service statistics in the synthetic dataset.}\n    \\label{tab:synthetic_stats}\n\\end{table}"
        },
        "figures": {
            "fig:ts_cores": "\\begin{figure} %{.5 \\textwidth}\n  \\centering\n  \\includegraphics[width=.95\\linewidth]{figures/ts-service-resource-usage.pdf}\n  \\caption{Total CPU core usage of three services in 8 days.}\n  \\label{fig:ts_cores}\n\\end{figure}",
            "fig:dist_containers": "\\begin{figure}\n\\centering\n\\includegraphics[width=.98\\linewidth]{figures/all_useast_0407_14-45.pdf}\n\\caption{Container CPU usage in percentage at a peak time.}\n\\label{fig:dist_containers}\n\\end{figure}",
            "fig:bp-visual": "\\begin{figure}\n    \\begin{subfigure}{0.4\\textwidth}\n      \\centering\n      \\includegraphics[width=.9\\linewidth]{figures/ucac_exp1_k20_a999.pdf}\n      \\caption{Nonempty cluster case: Scale-down}\n      \\label{subfig:scale-down}\n    \\end{subfigure}%\n    \\\\\n    \\begin{subfigure}{0.4\\textwidth}\n      \\centering\n      \\includegraphics[width=.9\\linewidth]{figures/ucac_exp2_k20_a999.pdf}\n      \\caption{Nonempty cluster case: Scale-up}\n      \\label{subfig:scale-up}\n    \\end{subfigure}%\n    \\\\\n    \\begin{subfigure}{0.4\\textwidth}\n      \\centering\n      \\includegraphics[width=.9\\linewidth]{figures/ucac_exp3_k20_a999.pdf}\n      \\caption{Empty cluster case}\n      \\label{subfig:empty}\n    \\end{subfigure}%\n\\caption{Comparison by visualizing UCaC on machines.}\n\\label{fig:bp-visual}\n\\end{figure}",
            "fig:cluster": "\\begin{figure} %{.5 \\textwidth}\n  \\centering\n  \\includegraphics[width=.65\\linewidth]{figures/cluster-2.pdf}\n  \\caption{Abstract cluster, machines, containers and services.}\n  \\label{fig:cluster}\n\\end{figure}",
            "fig:peak_ts_stats": "\\begin{figure}\n\\begin{subfigure}{.45\\textwidth}\n  \\centering\n  \\includegraphics[width=.9\\linewidth]{figures/real_peak_core_usage_mean.pdf}\n  \\caption{Mean CPU core usage at peaks}\n  \\label{fig:peak_ts_mean}\n\\end{subfigure}%\n\\\\\n\\begin{subfigure}{.45\\textwidth}\n  \\centering\n  \\includegraphics[width=.9\\linewidth]{figures/real_peak_core_usage_std_per_mean.pdf}\n  \\caption{Ratio of Standard Deviation against Mean at peaks}\n  \\label{fig:peak_ts_ratio}\n\\end{subfigure}\n\\caption{Per-service statistics at daily Peaks in real traces}\n\\label{fig:peak_ts_stats}\n\\end{figure}"
        },
        "equations": {
            "eq:1": "\\begin{equation*}\n\\Pr\\left(g(x; \\theta) \\leq c \\right) \\geq \\alpha,\n\\end{equation*}",
            "eq:2": "\\begin{equation}\n\\label{eq:sbpp}\n\\begin{aligned}\n  &\\min_{x, y}{\\sum_{i=1}^{N}{y_i}} \\\\\n  s.t., \\Pr( & \\sum_{j=1}^M {A_j x_{i, j}} \\leq V y_i) \\geq \\alpha, \\quad i \\in [N] \\\\\n        % & \\color{blue}{\\sum_{j=1}^M {A'_j x_{i, j}} \\leq V' y_i, \\quad i \\in [N]} \\\\\n        & \\sum_{i=1}^M {x_{i, j}} = 1, \\quad j \\in [M] \\\\\n        & x_{i, j} \\in \\{0, 1\\},  ~ y_i \\in \\{0, 1\\}, \\quad i \\in [N], j \\in [M] \\\\\n\\end{aligned}\n\\end{equation}",
            "eq:3": "\\begin{equation}\n\\label{eq:deterministic-constraint-pre}\n    \\sum_{j=1}^{M} \\mu_{j} x_{i,j}+D(\\alpha) \\sqrt{\\sum_{j=1}^{M} b_{j} x_{i,j}} \\leq V y_{i}, \\quad x_{i, j} \\in \\{0, 1\\}\n\\end{equation}",
            "eq:4": "\\begin{equation}\n\\label{eq:sbp-k-services}\n\\begin{aligned}\n\\min_{x, y} & \\sum_{i=1}^{N} y_{i} \\\\\n% \\text { s.t. } & \\Pr \\left(\\sum_{j=1}^K {A_j x_{i, j}} \\leq V y_i \\right) \\geq \\alpha, \\quad \\forall i \\in [N] \\\\\n\\text { s.t. } & \\sum_{j=1}^{K} \\mu_{j} x_{i,j}+D(\\alpha) \\sqrt{\\sum_{j=1}^{K} b_{j} x_{i,j}} \\leq V y_{i}, \\quad i \\in [N] \\\\\n%& \\sum_{j=1}^K {A'_j x_{i, j}} \\leq V' y_i, \\quad \\forall i \\in [N] \\\\\n%&\\sum_{j=1}^K {B_j x_{i, j}} \\leq M_e y_i\\\\\n& \\sum_{i=1}^{N} x_{i,j} = m_j, \\quad j \\in [K] \\\\\n& x_{i, j} \\in \\I, ~ y_{i} \\in\\{0,1\\}, \\quad i \\in [N], ~j \\in [K]\n\\end{aligned}\n\\end{equation}",
            "eq:5": "\\begin{equation}\n\\label{eq:generative-usage}\n\\begin{aligned}\n  & X_i \\sim P_k,\n  \\quad &Y^{(n)} = \\sum_{i=1}^{n}{X_i},\n\\end{aligned}    \n\\end{equation}",
            "eq:6": "\\begin{equation}\n\\label{eq:initial}\n\\begin{aligned}\n  \\min_{x} ~& {\\sum_{i=1}^{N}{ \\left \\{\\sum_{j=1}^{K}{(z_{i,j} + x_{i, j})\\mu_j} + D(\\alpha) \\sqrt{\\sum_{j=1}^{K}{(z_{i, j} + x_{i, j}) b_j}}\\right \\}}}\\\\\n  s.t. ~& \\sum_{j=1}^{K}{(z_{i,j} + x_{i, j})\\mu_j} + D(\\alpha) \\sqrt{\\sum_{j=1}^{K}{(z_{i, j} + x_{i, j}) b_j}} \\leq V, \\\\\n       & \\sum_{i=1}^{N}{x_{i, j}=m_j},  \\quad x_{i, j} \\in \\I, \\quad i \\in [N], \\quad j\\in[K],\n\\end{aligned}\n\\end{equation}",
            "eq:7": "\\begin{equation}\n\\label{eq:reformulation}\n\\begin{aligned}\n  \\min_{x} ~& \\sum_{i=1}^{N}{D(\\alpha) \\sqrt{\\sum_{j=1}^{K}{x_{i, j} b_j} + B_i}}\\\\\n  s.t. ~& \\sum_{j=1}^{K}{x_{i, j}\\mu_j} + D(\\alpha) \\sqrt{\\sum_{j=1}^{K}{x_{i, j} b_j} + B_i} \\leq V - C_i, \\quad i \\in [N] \\\\\n       & \\sum_{i=1}^{N}{x_{i, j}=m_j},  \\quad x_{i, j} \\in \\I, \\quad i \\in [N], \\quad j\\in[K],\n\\end{aligned}\n\\end{equation}",
            "eq:8": "\\begin{align}\n& \\sum_{k=1}^{K} \\mu_{k} p_{kj} + D(\\alpha) \\sqrt{\\sum_{k=1}^{K} b_{k} p_{kj}} \\leq V, ~ p_{kj}\\in \\I, \\quad k \\in [K] \\label{eq:pattern1}.\n\\end{align}",
            "eq:9": "\\begin{equation}\n\\label{eq:cutting-stock}\n\\begin{aligned}\n\\min_{v} & \\sum_{j=1}^{L} v_j \\\\\n\\text{ s.t. } & \\sum_{j=1}^{L} p_{kj} v_j \\geq m_k, \\quad k \\in [K] \\\\\n& v_j \\in \\I, \\quad j \\in [L], \n\\end{aligned}\n\\end{equation}",
            "eq:10": "\\begin{equation}\n\\label{eq:cutting-stock-relax}\n\\begin{aligned}\n\\min_{x} & \\sum_{j=1}^{L} v_j \\\\\n\\text{ s.t. } & \\sum_{j=1}^{L} p_{kj} v_j \\geq m_k, \\quad k \\in [K] \\\\\n& v_j \\geq 0,  v_j \\in \\R, \\quad j \\in [L].\n\\end{aligned}\n\\end{equation}",
            "eq:11": "\\begin{equation}\n\\label{eq:cutting-stock-relax-dual}\n\\begin{aligned}\n\\max_{\\pi} ~& \\pi ^\\top m \\\\\n\\text{ s.t. } ~& \\sum_{i=1}^{K}\\pi_i p_{ij} \\leq 1, \\quad j \\in [L] \\\\\n& \\pi_i \\geq 0, \\quad i \\in [K].\n\\end{aligned}\n\\end{equation}",
            "eq:12": "\\begin{equation}\n\\label{eq:cutting-stock-sub}\n\\begin{aligned}\n\\min_{v} ~& c = 1 - \\bar\\pi^\\top v \\\\\n\\text{ s.t. } ~& v \\in \\mathcal{F} \\\\\n\\end{aligned}\n\\end{equation}"
        }
    }
}