{
    "meta_info": {
        "title": "Towards Unified Conversational Recommender Systems via  Knowledge-Enhanced Prompt Learning",
        "abstract": "Conversational recommender systems (CRS) aim to proactively elicit user\npreference and recommend high-quality items through natural language\nconversations. Typically, a CRS consists of a recommendation module to predict\npreferred items for users and a conversation module to generate appropriate\nresponses. To develop an effective CRS, it is essential to seamlessly integrate\nthe two modules. Existing works either design semantic alignment strategies, or\nshare knowledge resources and representations between the two modules. However,\nthese approaches still rely on different architectures or techniques to develop\nthe two modules, making it difficult for effective module integration.\n  To address this problem, we propose a unified CRS model named UniCRS based on\nknowledge-enhanced prompt learning. Our approach unifies the recommendation and\nconversation subtasks into the prompt learning paradigm, and utilizes\nknowledge-enhanced prompts based on a fixed pre-trained language model (PLM) to\nfulfill both subtasks in a unified approach. In the prompt design, we include\nfused knowledge representations, task-specific soft tokens, and the dialogue\ncontext, which can provide sufficient contextual information to adapt the PLM\nfor the CRS task. Besides, for the recommendation subtask, we also incorporate\nthe generated response template as an important part of the prompt, to enhance\nthe information interaction between the two subtasks. Extensive experiments on\ntwo public CRS datasets have demonstrated the effectiveness of our approach.",
        "author": "Xiaolei Wang, Kun Zhou, Ji-Rong Wen, Wayne Xin Zhao",
        "link": "http://arxiv.org/abs/2206.09363v1",
        "category": [
            "cs.CL",
            "cs.AI",
            "cs.IR"
        ],
        "additionl_info": "Accepted by KDD 2022. Code: https://github.com/RUCAIBox/UniCRS"
    },
    "latex_extraction": {
        "content": {
            "section 1": {
                "name": "Introduction",
                "content": "\nWith the widespread of intelligent assistants, conversational recommender systems (CRSs) have become an emerging research topic, which provide the recommendation service to users through natural language conversations~\\cite{christakopoulou2016towards,li2018towards}.\nFrom the perspective of functions, CRSs should be able to fulfill two major subtasks, \\emph{a recommendation subtask} that predicts items from a candidate set to users and \\emph{a conversation subtask} that generates appropriate questions or responses.\n\nTo fulfill these two subtasks, existing methods~\\cite{chen2019towards,zhou2020improving,li2021seamlessly} usually set up two separate modules for each subtask, namely the recommendation module and the conversation module.\nSince the two subtasks are highly coupled, it has been widely recognized that a capable CRS should be able to seamlessly integrate these two modules~\\cite{chen2019towards,zhou2020improving,li2021seamlessly,wang2022barcor}, in order to share useful features or knowledge between them.\nOne line of works incorporate shared knowledge resources (\\eg knowledge graphs~\\cite{chen2019towards} and reviews~\\cite{lu2021revcore}) and their representations to enhance the semantic interaction.\nAnother line of works design special representation alignment strategies, such as pre-training tasks and regularization terms (\\eg mutual information maximization~\\cite{zhou2020improving} and contrastive learning~\\cite{zhou2022c2}), to guarantee the semantic consistency of the two modules.\n\n\n\nDespite the progress of existing CRS methods, the fundamental issue of semantic inconsistency between the recommendation and conversation modules has not been well addressed.\nFigure~\\ref{tab:intro} shows an inconsistent case of the prediction from a representative CRS model, KGSF~\\cite{zhou2020improving}, which utilizes mutual information maximization to align the semantic representations.\nAlthough the recommendation module predicts the movie \\textit{``Frozen 2 (2019)''}, the conversation module seems to be unaware of such a recommendation result and generates a mismatched response that contains another movie \\textit{``Pretty Woman (1990)''}.\nEven if we can utilize heuristic constraints to enforce the generation of the recommended movie, it cannot fundamentally resolve the semantic inconsistency of the two modules.\nIn essence, such a problem is caused by two major issues in existing methods. \nFirst, most of these methods develop the two modules with different architectures or techniques. \nEven with some shared knowledge or components, it is still difficult to effectively associate the two modules seamlessly. \nSecond, results from one module cannot be perceived and utilized by the other. \nFor example, there is no way to leverage the generated response when predicting the recommendation results in KGSF~\\cite{zhou2020improving}.\nTo summarize, the root of semantic inconsistency is the different architecture designs and working mechanisms of the two modules. \n\nTo address the above issues, we aim to develop a more effective CRS that implements both the recommendation and conversation modules in a unified manner. \nOur approach is inspired by the great success of pre-trained language models (PLMs)~\\cite{jiang2020can,gao2021making,brown2020language}, which have been shown effective as a general solution to a variety of tasks even in very different settings. \nIn particular, the recently proposed paradigm \\emph{prompt learning}~\\cite{brown2020language,gao2021making,wang2021finetuning} further unifies the use of PLMs on different tasks in a simple yet flexible manner. \nGenerally speaking, prompt learning augments or extends the original input of PLMs by prepending explicit or latent tokens, which might contain demonstrations, instructions, or learnable embeddings.\nSuch a paradigm can unify different task formats or data forms to a large extent.\nFor CRSs, since the two subtasks aim to fulfill specific goals based on the same conversational semantics, it is feasible to develop a unified CRS approach based on prompt learning.\n\nTo this end, in this paper, we propose a novel unified CRS model based on knowledge-enhanced prompt learning, namely \\textbf{UniCRS}. \nFor the base PLM, we utilize DialoGPT~\\cite{zhang2020dialogpt} since it has been pre-trained on a large-scale dialogue corpus. \nIn our approach, the base PLM is \\emph{fixed} in solving the two subtasks, without fine-tuning or continual pre-training. \nTo better inject the task knowledge into the base PLM, we first design a semantic fusion module that can capture the semantic association between words from dialogue texts and entities from knowledge graphs~(KGs).\nThe major technical contribution of our approach lies in that we formulate the two subtasks in the form of prompt learning, and design specific prompts for each subtask.\nIn our prompt design, we include the dialogue context (\\emph{specific tokens}), task-specific soft tokens (\\emph{latent vectors}), and fused knowledge representations (\\emph{latent vectors}), which can provide sufficient semantic information about the dialogue context, task instructions, and background knowledge. \nMoreover, for recommendation, we incorporate the generated response templates from the conversation module into the prompt, which can further enhance the information interaction between the two subtasks.\n\nTo validate the effectiveness of our approach, we conduct experiments on two public CRS datasets. \nExperimental results show that our UniCRS outperforms several competitive methods on both the recommendation and conversation subtasks, especially when training data is limited. Our main contributions are summarized as:\n\n(1) To the best of our knowledge, it is the first time that a unified CRS has been developed in a general prompt learning way.\n\n(2) Our approach formulates the subtasks of CRS into a unified form of prompt learning, and designs task-specific prompts with corresponding optimization methods.\n\n(3) Extensive experiments on two public CRS datasets have demonstrated the effectiveness of our approach in both the recommendation and conversation tasks.\n"
            },
            "section 2": {
                "name": "Related Work",
                "content": "\nOur work is related to the following two research directions, namely conversational recommendation and prompt learning.\n\n",
                "subsection 2.1": {
                    "name": "Conversational Recommendation",
                    "content": "\nWith the rapid development of dialogue systems~\\cite{chen2017survey,zhang2020dialogpt}, conversational recommender systems~(CRSs) have emerged as a research topic, which aim to provide accurate recommendations through conversational interactions with users~\\cite{christakopoulou2016towards,sun2018conversational,gao2021advances}.\n%it is promising to dynamically learn user intents and preferences from conversations. Based on it, conversational recommender systems~(CRSs) have emerged as a research topic, which aim to provide accurate recommendations through conversational interactions with users~\\cite{christakopoulou2016towards,sun2018conversational,gao2021advances}.\nA major category of CRS studies rely on pre-defined actions (\\eg intent slots or item attributes) to interact with users~\\cite{christakopoulou2016towards,sun2018conversational,zhou2020leveraging}.\nThey focus on accomplishing the recommendation task within as few turns as possible.\nThey adopt the multi-armed bandit model~\\cite{christakopoulou2016towards,xie2021comparison} or reinforcement learning~\\cite{sun2018conversational} to find the optimal interaction strategy.\nHowever, methods that belong to this category mostly rely on pre-defined actions and templates to generate responses, which largely limit their usage in various scenarios.\nAnother category of CRS studies aim to generate both accurate recommendations and human-like responses~\\cite{li2018towards,zhou2020towards,hayati2020inspired}.\nTo achieve this, these works usually devise a recommendation module and a conversation module to implement the two functions, respectively.\nHowever, such a design raises the issue of semantic inconsistency, and it is essential to seamlessly integrate the two modules as a system.\nExisting works mostly either share the knowledge resources and their representations~\\cite{chen2019towards,lu2021revcore}, or design semantic alignment pre-training tasks~\\cite{zhou2020improving} and regularization terms~\\cite{zhou2022c2}.\nHowever, it is still difficult for the effective integration of the two modules due to their different architectures or techniques. \nFor example, it has been pointed out that the generated responses from the conversation module do not always match the predicted items from the recommendation module~\\cite{liang2021learning}.\nOur work follows the latter category and adopts prompt learning based on pre-trained language models (PLM) to unify the recommendation and conversation subtasks.\nIn this way, the two subtasks can be formulated in a unified manner with elaborately designed prompts.\n\n"
                },
                "subsection 2.2": {
                    "name": "Prompt Learning",
                    "content": "\nRecent years have witnessed the remarkable performance of PLMs on a variety of tasks~\\cite{devlin2019bert,lewis2020bart}.\nMost of PLMs are pre-trained with the objective of language modeling but are fine-tuned on downstream tasks with quite different objectives.\nTo overcome the gap between pre-training and fine-tuning, prompt learning (\\aka prompt-tuning) has been proposed~\\cite{liu2021pre,gu2021ppt}, which relies on carefully designed prompts to reformulate the downstream tasks as the pre-training task.\nEarly works mostly incorporate manually crafted discrete prompts to guide the PLM~\\cite{brown2020language,raffel2020exploring}.\nRecently, a surge of works focus on automatically optimizing discrete prompts for specific tasks~\\cite{gao2021making,jiang2020can} and achieving comparable performance with manual prompts.\nHowever, these methods still rely on generative models or complex rules to control the quality of prompts.\nIn contrast, some works propose to use learnable continuous prompts that can be directly optimized~\\cite{li2021prefix,lester2021power}.\nOn top of this, several works devise prompt pre-training tasks~\\cite{gu2021ppt} or knowledgeable prompts~\\cite{hu2021knowledgeable} to improve the quality of the continuous prompts.\nIn this work, we reformulate both the recommendation and conversation subtasks as the pre-training task of a PLM by prompt learning.\nIn addition, to provide the PLM with task-related knowledge of CRS, we enhance the prompts with the information from an external KG and perform semantic fusion for prompt learning.\n"
                }
            },
            "section 3": {
                "name": "Problem Statement",
                "content": "\nConversational recommender systems (CRSs) aim to conduct item recommendation through multi-turn natural language conversations.\nAt each turn, the system either makes recommendations or asks clarification questions, based on the currently learned user preference.\nSuch a process ends until the user accepts the recommended items or leaves.\nTypically, a CRS consists of two modules, \\ie the recommender module and the conversation module, which are responsible for the recommendation and the response generation tasks, respectively.\nThese two modules should be seamlessly integrated to generate consistent results, in order to fulfill the conversational recommendation task.\n\nFormally, let $u$ denote a user, $i$ denote an item from the item set $\\mathcal{I}$, and $w$ denote a word from the vocabulary $\\mathcal{V}$.\nA conversation is denoted as $C=\\{s_t\\}_{t=1}^n$, where $s_t$ denotes the utterance at the $t$-th turn and each utterance $s_t=\\{w_j\\}_{j=1}^m$ consists of a sequence of words from the vocabulary $\\mathcal{V}$.\n\nWith the above definitions, the task of conversational recommendation is defined as follows.\nAt the $t$-th turn, given the dialogue history $C=\\{s_j\\}_{j=1}^{t-1}$ and the item set $\\mathcal{I}$, the system should (1) select a set of candidate items $\\mathcal{I}_t$ from the entire item set $\\mathcal{I}$ to recommend, and (2) generate the response $R=s_{t}$ that includes the items in $\\mathcal{I}_t$.\nNote that $\\mathcal{I}_t$ might be empty, when there is no need for recommendation.\n"
            },
            "section 4": {
                "name": "Approach",
                "content": "\n\n\n\nIn this section, we present a unified CRS approach with knowledge-enhanced prompt learning based on a PLM, namely \\textbf{UniCRS}. \nWe first give an overview of our approach, then discuss how to fuse semantics from words and entities as part of the prompts, and finally present the knowledge-enhanced prompting approach to the CRS task. \nThe overall architecture of our proposed model is presented in Figure~\\ref{fig:approach}.\n\n",
                "subsection 4.1": {
                    "name": "Overview of the Approach",
                    "content": "\nPrevious studies on CRS~\\cite{li2018towards,chen2019towards,zhou2020improving} usually develop specific modules for the recommendation and conversation subtasks respectively, and they need to connect the two modules in order to fulfill the task goal of CRS.\nDifferent from existing CRS methods, we aim to develop a unified approach with prompt learning based on PLM.\n\n\\paratitle{The Base PLM}.\nIn our approach, we take DialoGPT~\\cite{zhang2020dialogpt} as our base PLM.\nDialoGPT adopts a Transformer-based autoregressive architecture and is pre-trained on a large-scale dialogue corpus extracted from Reddit.\nIt has been shown that DialoGPT can generate coherent and informative responses, making it a suitable base model for the CRS task~\\cite{wang2021finetuning,liang2021learning}. \nLet $f(\\cdot \\mid \\Theta_{plm})$ denote the base PLM parameterized by $\\Theta_{plm}$, taking a token sequence as input and producing contextualized representations for each token.\nUnless otherwise specified, we will use the representation of the last token from DialoGPT for subsequent prediction or generation tasks.\n\n\\paratitle{A Unified Prompt-Based Approach to CRS}. \nGiven the dialogue history $\\{s_j\\}_{j=1}^{t-1}$ at the $t$-th turn, we concatenate each utterance into a text sequence $C=\\{w_k\\}_{k=1}^{n_W}$.\nThe basic idea is to encode the dialogue history $C$, obtain its contextualized representations, and solve the recommendation and conversation subtasks via \\emph{generation} (\\ie generating either \\emph{the recommended items} or \\emph{the response utterance}), with the base PLM.\nIn this way, the two subtasks can be fulfilled in a unified approach.\nHowever, since the base PLM is fixed, it is difficult to achieve satisfactory performance compared with fine-tuning due to lack of task adaptation.\nTherefore, we adopt the prompting approach~\\cite{gao2021making,gu2021ppt}, where the original dialogue history is prepended with elaborately designed or learned \\emph{prompt tokens}, denoted by $\\{p_k\\}_{k=1}^{n_P}$ ($n_P$ is the number of prompt tokens).\nIn practice, prompt tokens can be either explicit tokens or latent vectors.\nIt has been shown that prompting is an effective paradigm to leverage the knowledge of PLMs to solve various tasks without fine-tuning~\\cite{brown2020language,gao2021making}.\n\n\\paratitle{Prompt-augmented Dialogue Context}.\nBy incorporating the prompts, the original dialogue history $C$ can be extended to a longer sequence (called \\emph{context sequence}), denoted as $\\widetilde{C}$:\n\\begin{equation}\n    \\widetilde{C} \\rightarrow \\underbrace{p_1,\\dots, p_{n_P},}_{\\text{prompt tokens}} \\underbrace{w_{1}\\cdots w_{n_W}}_{\\text{word tokens}}.\n\\end{equation}\n\nAs before, we utilize the base PLM to obtain contextualized representations of the context sequence for solving the recommendation and conversation subtasks.\nIn order to better adapt to the task characteristics, we can construct and learn different prompts, and obtain corresponding context sequences denoted as $\\widetilde{C}_{rec}$ for recommendation and $\\widetilde{C}_{con}$ for conversation.\n\nTo implement such a unified approach, we identify two major problems to solve: (1) how to fuse conversational semantics and related knowledge semantics in order to adapt the base PLM for CRS (Section~\\ref{sec-sf}), and (2) how to design and learn suitable prompts for the recommendation and conversation subtasks (Section~\\ref{sec-4.3}).  \nIn what follows, we will introduce the two parts in detail. \n\n"
                },
                "subsection 4.2": {
                    "name": "Semantic Fusion for Prompt Learning",
                    "content": "\n\\label{sec-sf}\nSince DialoGPT is pre-trained on a general dialogue corpus, it lacks the specific capacity for the CRS task and cannot be directly used.\nFollowing previous studies~\\cite{chen2019towards,zhou2020improving}, we incorporate KGs as the task-specific knowledge resources, since it involves useful knowledge about entities and items mentioned in the dialogue.\nHowever, it has been found that there is a large semantic gap between the semantic spaces of dialogues and KGs~\\cite{zhou2020improving,zhou2022c2}. \nWe need to first fuse the two semantic spaces for effective knowledge alignment and enrichment.\nSpecially, the purpose of this step is to fuse the token and entity embeddings from different encoders.\n\n\\paratitle{Encoding Word Tokens and KG Entities.} \nGiven a dialogue history $C$, we first separately encode the dialogue words and KG entities that appear in $C$ into word embeddings and entity embeddings.  \nTo complement our base PLM DialoGPT~(a unidirectional decoder), we employ another fixed PLM RoBERTa~\\cite{liu2019roberta}~(a bi-directional encoder) to derive the word embeddings.\nThe contextualized token representations derived from the fixed encoder RoBERTa are concatenated into a word embedding matrix, \\ie $\\mathbf{T}=[\\bm{h}_1^T; \\dots; \\bm{h}_{n_W}^T]$. \nFor entity embeddings, following previous works~\\cite{chen2019towards,zhou2020improving}, we first perform entity linking based on an external KG DBpedia~\\cite{auer2007dbpedia}, and then obtain the corresponding entity embeddings via a relational graph neural networks~(RGCN)~\\cite{schlichtkrull2018modeling}, which can model the relational semantics through information propagation and aggregation over the KG.\nSimilarly, the derived entity embedding matrix is denoted as $\\mathbf{E}=[\\bm{h}_1^E; \\dots; \\bm{h}_{n_E}^E]$, where $n_E$ is the number of mentioned entities in the dialogue history.\n\n\\paratitle{Word-Entity Semantic Fusion.}\nIn order to bridge the semantic gap between words and entities, we use a cross interaction mechanism to associate the two kinds of semantic representations via a bilinear transformation:\n%Above, we obtain the text-level representations and KG-level representations for a dialogue, which are denoted as $\\mathbf{D}$ and $\\mathbf{E}$, respectively.\n%In order to fuse their semantics for a comprehensive understanding of user preferences, we use the co-attention mechanism~\\cite{} to connect the text-level representations and word-level representations:\n\\begin{align}\n    \\mathbf{A}              & =\\mathbf{T}^{\\top}\\mathbf{W} \\mathbf{E},    \\label{eq-A} \\\\ \n    \\widetilde{\\mathbf{T}}  & =\\mathbf{T}+\\mathbf{E}\\mathbf{A},             \\label{eq-T}  \\\\ \n    \\widetilde{\\mathbf{E}}  & =\\mathbf{E}+\\mathbf{T}\\mathbf{A}^{\\top},      \\label{eq-E}\n\\end{align}\nwhere $\\mathbf{A}$ is the affinity matrix between the two representations, $\\mathbf{W}$ is the transformation matrix, $\\widetilde{\\mathbf{T}}$ is the fused word representations, and $\\widetilde{\\mathbf{E}}$ is the fused entity representations.\nHere we use the bilinear transformation between $\\mathbf{T}$ and $ \\mathbf{E}$ for simplicity, and leave the further exploration of complex interaction mechanisms for future work.\n\n\\paratitle{Pre-training the Fusion Module}.\nAfter semantic fusion, we can establish the semantic association between words and entities. \nHowever, such a module involves additional learnable parameters, denoted as $\\Theta_{fuse}$. \nTo better optimize the parameters of the fusion module, we propose a prompt-based pre-training approach that leverages the self-supervision signals from the dialogues.\nSpecifically, we prepend the fused entity representations $\\widetilde{\\mathbf{E}}$ (Eq.~\\ref{eq-E}) and append the response to the dialogue context, namely $\\widetilde{C}_{pre}=[\\widetilde{\\mathbf{E}}; C; R]$, where we use the \\underline{\\emph{bold font}} to denote the \\emph{latent vectors} ($\\widetilde{\\mathbf{E}}$) and the \\underline{\\emph{plain font}} to denote the \\emph{explicit tokens} ($C, R$).\nFor this pre-training task, we simply utilize the prompt-augmented context sequence $\\widetilde{C}_{pre}$ to predict the entities appearing in the response.\nThe prediction probability of the entity $e$ is formulated as:\n\\begin{align}\n    \\label{eq:rec-ent}\n    \\text{Pr}(e \\mid \\widetilde{C}_{pre}) & =\\text{Softmax}(\\bm{h}_u \\cdot\\bm{h}_e),\n\\end{align}\nwhere $\\bm{h}_u= \\text{Pooling}[ f(\\widetilde{C}_{pre} \\mid \\Theta_{plm}; \\Theta_{fuse}) ]$ is the learned representation of the context by pooling the contextualized representations of all the tokens in $\\widetilde{C}_{pre}$, and $\\bm{h}_e$ is the fused entity representation for the entity $e$.\nNote that only the parameters of the fusion module $\\Theta_{fuse}$ are required to optimize, while the parameters of the base PLM $\\Theta_{plm}$ are fixed.\nWe adopt the cross-entropy loss for the pre-training task.\n\nAfter semantic fusion, we obtain the fused knowledge representations for words and entities from the dialogue history, namely $\\widetilde{\\mathbf{T}}$ (Eq.~\\ref{eq-T}) and $\\widetilde{\\mathbf{E}}$ (Eq.~\\ref{eq-E}), respectively. \nThese representations are subsequently used as part of prompts, as shown in Section~\\ref{sec-4.3}.\n\n"
                },
                "subsection 4.3": {
                    "name": "Subtask-specific Prompt Design",
                    "content": "\n\\label{sec-4.3}\nThough the base PLM is fixed without fine-tuning, we can design specific prompts to adapt it to different subtasks of CRS. \nFor each subtask (either \\emph{recommendation} or \\emph{conversation}), the major design of prompting consists of three parts, namely the dialogue history, subtask-specific soft tokens, and fused knowledge representations.\nFor recommendation, we further incorporate the generated response templates as additional prompt tokens. \nNext, we describe the specific prompting designs for the two subtasks in detail.\n\n",
                    "subsubsection 4.3.1": {
                        "name": "Prompt for Response Generation",
                        "content": "\nThe subtask of response generation aims to generate informative utterances in order to clarify user preferences or reply to users' utterances.\nThe prompting design mainly enhances the textual semantics for better dialogue understanding and response generation.\n\n\\paratitle{The Prompt Design}. \nThe prompt for response generation consists of the original dialogue history (in the form of \\emph{word tokens}  $C$), generation-specific soft tokens (in the form of \\emph{latent vectors} $\\mathbf{P}_{gen}$) and fused textual context (in the form of \\emph{latent vectors} $\\widetilde{\\mathbf{T}}$), which is formally denoted as:\n\\begin{equation}\n\\widetilde{C}_{gen} \\rightarrow [\\text{~}\\widetilde{\\mathbf{T}}; \\text{~~~~~}\\mathbf{P}_{gen}; \\text{~~~~~} C\\text{~} ],\n\\label{eq-gen-prompt}\n\\end{equation}\nwhere we use the \\emph{bold} and \\emph{plain} fonts to denote soft and hard token sequences, respectively.\nIn this design, the subtask-specific prompts $\\mathbf{P}_{gen}$ instruct the PLM by the signal from the generation task, the KG-enhanced textual representations $\\widetilde{\\mathbf{T}}$ (Eq.~\\ref{eq-T}), and the original dialogue history $C$.\n\n\\paratitle{Prompt Learning}. \nIn the above prompting design, the only tunable parameters are the fused textual representations $\\widetilde{\\mathbf{T}}$ that have been pre-trained, and generation-specific soft tokens $\\mathbf{P}_{gen}$.\nThey are denoted as $\\Theta_{gen}$. \nWe use the prompt-augmented context $\\widetilde{C}_{gen}$ to derive the prediction loss for learning $\\Theta_{gen}$, which is formally given as:\n\\begin{align}\n    L_{gen}(\\Theta_{gen})   &= -\\frac{1}{N}\\sum_{j=1}^N\\log \\text{Pr}(R_j \\mid \\widetilde{C}_{gen}^{(j)} ; \\Theta_{gen})    \\notag \\\\\n                            &= -\\frac{1}{N}\\sum_{i=1}^N\\sum_{j=1}^{l_i}\\log \\text{Pr}(w_{i,j} \\mid \\widetilde{C}_{gen}^{(j)} ; \\Theta_{gen} ; w_{<j}),\n \\label{eq:conv-loss-p}\n\\end{align}\nwhere $N$ is the number of training instances (a pair of the context and target utterances), and $l_i$ is the length of the $i$-th target utterance, and $w_{<j}$ denotes the words proceeding the $j$-th position.\n\n\\paratitle{Response Template Generation}. \nBesides sharing the base PLM, we find that it is also important to share intermediate results of different subtasks to achieve more consistent final results.\nFor example, given the generated response of the conversation task, the PLM might be able to predict more relevant recommendations according to such extra contextual information.\nBased on this intuition, we propose to include response templates as part of the prompt for the recommendation subtask.\nSpecifically, we add a special token $\\texttt{[ITEM]}$ into the vocabulary $\\mathcal{V}$ of the base PLM and replace all the items that appear in the response with the $\\texttt{[ITEM]}$ token.\nAt each time step, the PLM generates either the special token $\\texttt{[ITEM]}$ or a general token from the original vocabulary.\nAll the slots will be filled after the recommended items are generated. \n\n"
                    },
                    "subsubsection 4.3.2": {
                        "name": "Prompt for Item Recommendation",
                        "content": "\nThe subtask of recommendation aims to predict items that a user might be interested in.\nThe prompting design mainly enhances the user preference semantics, in order to predict more satisfactory recommendations.\n\n\\paratitle{The Prompt Design}. \nThe item recommendation prompts consist of the original dialogue history $C$ (in the form of \\emph{word tokens}), recommendation-specific soft tokens $\\mathbf{P}_{rec}$ (in the form of \\emph{latent vectors}), fused entity context $\\widetilde{\\mathbf{E}}$ (in the form of \\emph{latent vectors}), and the response template $S$ (in the form of \\emph{word tokens}), formally described as:\n\\begin{equation}\n\\widetilde{C}_{rec} \\rightarrow [\\text{~}\\widetilde{\\mathbf{E}}; \\text{~~~~~}\\mathbf{P}_{rec}; \\text{~~~~~} C; \\text{~~~~~} S \\text{~} ],\n\\label{eq-rec-prompt}\n\\end{equation}\nwhere the subtask-specific prompts $\\mathbf{P}_{rec}$ instruct the PLM by the signal from the recommendation task, the KG-enhanced entity representations $\\widetilde{\\mathbf{E}}$ (Eq.~\\ref{eq-E}), the original dialogue history $C$, and the response template $S$.\n\nA key difference between the prompts of the two subtasks is that we utilize entity representations for \\emph{recommendation}, and word representations for \\emph{generation}. This is because their prediction targets are items and sentences, respectively. \nBesides, we have a special design for recommendation, where we include the response template as part of the prompts.\nThis can enhance the subtask connections and alleviate the risk of semantic inconsistency.\n\n\\paratitle{Prompt Learning}. \nIn the above prompting design, the only tunable parameters are the fused entity representations $\\widetilde{\\mathbf{E}}$ that have been pre-trained, and recommendation-specific soft tokens $\\mathbf{P}_{gen}$.\nThey are denoted as $\\Theta_{rec}$. \nWe utilize the prompt-augmented context $\\widetilde{C}_{rec}$ to derive the prediction loss for learning $\\Theta_{rec}$, which is formally given as:\n\\begin{equation}\n    \\label{eq:rec-loss-p}\n    \\small\n    L_{rec}(\\Theta_{rec})=-\\sum_{j=1}^N\\sum_{i=1}^M\\big[y_{j,i}\\cdot\\log\\text{Pr}_{j}(i)+(1-y_{j,i})\\cdot\\log(1-\\text{Pr}_{j}(i))\\big],\n\\end{equation}\nwhere $N$ is the number of training instances (a pair of the context and a target item), $M$ is the total number of items, $y_{j,i}$ denotes a binary ground-truth label which is equal to 1 when item $i$ is the correct label for the $j$-th training instance, and $\\text{Pr}_{j}(i)$ is an abbreviation of $\\text{Pr}(i \\mid \\widetilde{C}_{rec}^{(j)} ; \\Theta_{rec})$, which is computed following a similar way in Eq.~\\ref{eq:rec-ent} by first pooling contextualized representations and then computing the softmax score.\n\n"
                    }
                },
                "subsection 4.4": {
                    "name": "Parameter Learning",
                    "content": "\nThe parameters of our model consist of four groups, namely the base PLM, the semantic fusion module, and the subtask-specific soft tokens for recommendation and conversation.\nThey are denoted as $\\Theta_{plm}$, $\\Theta_{fuse}$, $\\Theta_{rec}$ and $\\Theta_{gen}$, respectively.\n\nDuring the overall training process, the parameters of the base PLM $\\Theta_{plm}$ are always fixed, and we only optimize the rest parameters.\nFirst, we pre-train the parameters of the semantic fusion module $\\Theta_{fuse}$. \nGiven the dialogue history and KG, we encode the dialogue tokens with a fixed text encoder RoBERTa and the KG entities with a learnable graph encoder RGCN.\nThen, we perform semantic fusion to obtain the fused word representations $\\widetilde{\\mathbf{T}}$ using Eq.~\\ref{eq-T} and entity representations $\\widetilde{\\mathbf{E}}$ using Eq.~\\ref{eq-E}.\nAfter that, we optimize $\\Theta_{fuse}$ based on the self-supervised entity prediction task.\nNext, we randomly initialize the parameters of the subtask-specific soft tokens $\\Theta_{rec}$ and $\\Theta_{gen}$, and compose the response generation prompts using Eq.~\\ref{eq-gen-prompt}.\nWe utilize the supervised signal from the conversation task to learn $\\Theta_{gen}$ using Eq.~\\ref{eq:conv-loss-p} and generate the response template.\nFinally, we compose the item recommendation prompts using Eq.~\\ref{eq-rec-prompt} and leverage the supervised signal from the recommendation task to learn $\\Theta_{rec}$ using Eq.~\\ref{eq:rec-loss-p}."
                }
            },
            "section 5": {
                "name": "Experiment",
                "content": "\n\nIn this section, we first set up the experiments, and then report the results and give detailed analysis.\n\n",
                "subsection 5.1": {
                    "name": "Experimental Setup",
                    "content": "\n\n\n\n\\paratitle{Datasets.}\nTo evaluate the performance of our model, we conduct experiments on the \\textsc{ReDial}~\\cite{li2018towards} and \\textsc{INSPIRED}~\\cite{hayati2020inspired} datasets.\nThe \\textsc{ReDial} dataset is an English CRS dataset about movie recommendations, and is constructed through crowd-sourcing workers on Amazon Mechanical Turk (AMT).\nSimilar to \\textsc{ReDial}, the \\textsc{INSPIRED} dataset is also an English CRS dataset about movie recommendations, but with a smaller size.\nThese two datasets are widely used for evaluating CRS models. \n% Besides the similar instructions, the workers of \\textsc{INSPIRED} are also required to use pre-defined sociable recommendation strategies when chatting.\nThe statistics of both datasets are summarized in Table~\\ref{tab:datasets}.\n\n\\paratitle{Baselines.}\nFor CRS, we consider two major subtasks for evaluation, namely recommendation and conversation.\nFor comparison, we select several representative methods (including both CRS models and adapted PLMs) tailored to each subtask.\n\n\\textbullet~\\underline{\\textbf{ReDial}}~\\cite{li2018towards}:\nIt is proposed along with the \\textsc{ReDial} dataset, which incorporates a conversation module based on HRED~\\cite{subramanian2018learning} and a recommendation module based on auto-encoder~\\cite{sedhain2015autorec}.\n\n\\textbullet~\\underline{\\textbf{KBRD}}~\\cite{chen2019towards}:\nIt utilizes an external KG to enhance the semantics of entities mentioned in the dialogue history, and adopts a self-attention based recommendation module and a Transformer-based conversation module.\n\n\\textbullet~\\underline{\\textbf{KGSF}}~\\cite{zhou2020improving}:\nIt incorporates two KGs to enhance the semantic representations of words and entities, and utilizes the Mutual Information Maximization method to align the semantic spaces of the two KGs.\n\n\\textbullet~\\underline{\\textbf{GPT-2}}~\\cite{radford2019language}:\nIt is an auto-regressive PLM. \nWe concatenate the historical utterances of a conversation as the input, and take the generated text as the response and the representation of the last token for recommendation.\n\n\\textbullet~\\underline{\\textbf{DialoGPT}}~\\cite{zhang2020dialogpt}:\nIt is an auto-regressive model pre-trained on a large-scale dialogue corpus. \nSimilar to GPT-2, we also adopt the generated text and the last token representation for the conversation and recommendation tasks, respectively.\n\n\\textbullet~\\underline{\\textbf{BERT}}~\\cite{devlin2019bert}:\nIt is pre-trained via the masked language model task on a large-scale general corpus. \nWe utilize the representation of the $[CLS]$ token for recommendation.\n\n\\textbullet~\\underline{\\textbf{BART}}~\\cite{lewis2020bart}:\nIt is a seq2seq model pre-trained with the denoising auto-encoding task on a large-scale general corpus.\nWe also adopt the generated text and the last token representation for the conversation and recommendation tasks, respectively.\n\nAmong these baselines, ReDial~\\cite{li2018towards}, KBRD~\\cite{chen2019towards} and KGSF~\\cite{zhou2020improving} are conversational recommendation methods, where the latter two incorporate external knowledge graphs;\nBERT~\\cite{devlin2019bert}, GPT-2~\\cite{radford2019language}, BART~\\cite{lewis2020bart}, and DialoGPT~\\cite{zhang2020dialogpt} are pre-trained language models, where BERT, GPT-2 and BART are pre-trained on a general corpus, and DialoGPT is pre-trained on a dialogue corpus.\n\n\\paratitle{Evaluation Metrics.}\nFollowing previous CRS works~\\cite{li2018towards,zhou2020improving}, we adopt different metrics to evaluate the recommendation and conversation task separately.\nFor the recommendation task, following~\\cite{chen2019towards,zhou2020improving}, we use Recall@$k$ ($k$=1,10,50) for evaluation.\nFor the conversation task, following~\\cite{chen2019towards,zhou2020improving}, we adopt Distinct-$n$ ($n$=2,3,4) at the word level to evaluate the diversity of the generated responses.\nBesides, following KGSF~\\cite{zhou2020improving}, we invite three annotators to score the generated responses of our model and baselines from two aspects, namely \\emph{Fluency} and \\emph{Informativeness}. The range of scores is 0 to 2.\nFor all the above metrics, we calculate and report the average scores on all test examples.\n\n\\paratitle{Implementation Details.}\nWe select the DialoGPT-small model as the base PLM, which is pre-trained on 147M dialogues collected from Reddit.\nIt consists of 12 transformer layers, and the dimension of its embeddings is 768.\nWe freeze all its parameters during the overall training process.\nTo be consistent with DialoGPT-small, the hidden size of our designed prompts is also set to 768.\nIn the semantic fusion module, we utilize a fixed RoBERTa-base model for encoding the input tokens, and set the layer number of R-GCN to 1 following KGSF~\\cite{zhou2020improving}.\nBesides, we set the length of soft prompt tokens to 10 for the recommendation task and 50 for the conversation task according to our parameter tuning results.\nWe use AdamW~\\cite{loshchilov2018decoupled} with the default parameter setting to optimize the tunable parameters in our approach.\nThe batch size is set to 64 for the recommendation subtask and 8 for the conversation subtask, and the learning rate is 0.0005 for prompt pre-training and 0.0001 for the two subtasks.\nWe implement all baseline models using the open-source toolkit CRSLab~\\cite{zhou2021crslab}~\\footnote{https://github.com/RUCAIBox/CRSLab}, which contains comprehensive conversational recommendation models and benchmark datasets.\n\n"
                },
                "subsection 5.2": {
                    "name": "Evaluation on Recommendation Task",
                    "content": "\nIn this part, we conduct experiments to evaluate the effectiveness of our model on the recommendation task.\n\n\n\n\n\n\\paratitle{Automatic Evaluation.}\nTable~\\ref{tab:rec-table} shows the performance of different methods on the recommendation task.\nFor the three CRS methods, the performance order is consistent cross all datasets, \\ie \\emph{KGSF > KBRD > ReDial}.\nKGSF and KBRD both incorporate external KGs into their recommendation modules, which can enrich the semantics of entities mentioned in the dialogue history to better capture user intents and preferences.\nBesides, KGSF also adopts the mutual information maximization method to further improve the entity representations.\nFor the four pre-trained models, we can see that BERT and BART perform better than GPT-2 and DialoGPT. The reason might be that GPT-2 and DialoGPT are based on unidirectional Transformer architecture, which limits their capacity of dialogue understanding.\nFurthermore, we can see that BART achieves comparable performance and even outperforms BERT on the \\textsc{ReDial} dataset. It indicates that BART can also understand the dialogue semantics well for the recommendation task.\n\nFinally, we can see that our model outperforms all the baselines by a large margin. \nWe utilize specially designed prompts to guide the base PLM, and incorporate KGs to improve the quality of prompts with a pre-training task.\nSuch a way can effectively endow the PLM with the background knowledge for better performance on the recommendation task.\nBesides, we also use the response template generated by the conversation module as part of the prompt, which further improves the recommendation performance.\nNote that our approach only tunes a few parameters compared with full parameter fine-tuning, hence it is also much more efficient than those PLM-based methods.\n\n\\paratitle{Ablation Study.}\nOur approach designs a set of prompt components to improve the performance of CRS.\nTo verify the effectiveness of each component, we conduct the ablation study on the \\textsc{ReDial} dataset, and report the results of Recall@10 and Recall@50.\nWe consider removing the pre-training task of the semantic fusion module, token or entity information in the fused knowledge representations, task-specific soft tokens, and the response template, respectively.\n\nThe results are shown in Figure~\\ref{fig:ablation-rec}.\nWe can see that removing any component would lead to performance degradation.\nIt indicates that all the components in our model are useful to improve the performance of the recommendation task.\nAmong them, the performance decreases the most after removing the pre-training task in the semantic fusion module. It indicates that such a pre-training process is important in our approach, since it can learn the semantic correlations between entities and tokens, which enforces the entity semantics to be aligned with the base PLM.\n\n"
                },
                "subsection 5.3": {
                    "name": "Evaluation on Conversation Task",
                    "content": "\nIn this part, we conduct experiments to verify the effectiveness of our model on the conversation task.\n\n\n\n\n\n\n\n\\paratitle{Automatic Evaluation.}\nWe show the evaluation results of automatic metrics about different methods in Table~\\ref{tab:conv-table}.\nAs we can see, among the three CRS methods, the performance order is also consistent with \\emph{KGSF > KBRD > ReDial}. It is because KBRD adopts KG-based token bias to promote the probabilities of low-frequency tokens, and KGSF devises KG-enhanced cross-attention layers to improve the feature interactions of entities and tokens in the generation process.\nBesides, we can see that PLMs achieve better performance than the three CRS methods. The possible reason is that they have been pre-trained with generative tasks on a large-scale general corpus, so they can quickly adapt to the CRS task and generate diverse responses after fine-tuning.\nAmong these PLMs, DialoGPT achieves the best performance. Since DialoGPT has been continually pre-trained on a large-scale dialogue corpus, it is more capable of generating informative responses in the CRS scenario.\n\nFinally, compared with these baselines, our model also consistently performs better.\nIn our approach, we perform semantic fusion and prompt pre-training.\nIn this way, we can effectively inject task-specific knowledge into the PLM, and help generate informative responses.\nBesides, since we only tune a few parameters compared with full parameter fine-tuning, we can alleviate the catastrophe forgetting problem of the PLM.\n\n\\paratitle{Human Evaluation.}\nTo further verify the effectiveness of our method, we conduct the human evaluation following previous works~\\cite{zhou2020improving}. Table~\\ref{tab:human-table} presents the results of human evaluation for the conversation task on the \\textsc{ReDial} dataset.\n\nFirst, among the three CRS methods, KGSF performs the best in both metrics, since it utilizes a KG-enhanced Transformer decoder that performs cross attention between the entity and word representations.\nBesides, among the three PLM models, we can see that DialoGPT achieves the best performance. A possible reason is that DialoGPT has been continually pre-trained on a large-scale dialogue corpus, which endows it with a better capacity to generate high-quality responses.\nFinally, our approach also outperforms all the baseline models. In our approach, we perform semantic fusion to inject the task-specific knowledge into DialoGPT, and also design a pre-training strategy to further enhance the prompt.\nIn this way, our model can effectively understand the dialogue history, and generate fluent and informative responses.\n\n\\paratitle{Ablation Study.}\nIn our approach, our proposed prompt design can also improve the performance of the conversation task.\nTo verify the effectiveness of each component, we conduct the ablation study on the \\textsc{ReDial} dataset to analyze the contribution of each part.\nWe adopt Distinct-3 and Distinct-4 as the evaluation metrics, and consider removing the pre-training task of the semantic fusion module, token or entity information in the fused knowledge representations, and task-specific soft tokens, respectively.\n\nThe ablation results are shown in Figure~\\ref{fig:ablation-conv}. \nWe can see that removing any component would lead to a decrease in the model performance. It shows the effectiveness of all these components in our approach. \nBesides, the entity information seems to be more important than others, which yields a larger performance drop after being removed.  These entities contain domain-specific knowledge about items, which is helpful for our model to generate more informative responses.\n\n"
                },
                "subsection 5.4": {
                    "name": "Performance Comparison w.r.t. Different Amount of Training Data",
                    "content": "\n\n\n\nLearning the parameters of CRSs requires a considerable amount of training data.\nHowever, in real-world applications, it is likely to suffer from the cold start issue caused by insufficient data, which may increase the risk of overfitting.\nFortunately, since our approach only needs to optimize a few parameters in the prompt and incorporates a prompt pre-training strategy, the risk of overfitting can be reduced to some extent.\nTo validate this, we simulate a data scarcity scenario by sampling different proportions of the training data, and report the results of Recall@10 and Recall@50 on the \\textsc{ReDial} dataset.\n\nFigure~\\ref{fig:few-shot} shows the evaluation results in different data scarcity settings.\nAs we can see, the performance of baseline models substantially drops with less available training data, while our method is consistently better than all the baseline models in all cases.\nIt indicates that our model can efficiently utilize the limited data and alleviate the cold start problem.\nWith extremely limited data (\\ie 20\\%), we find that our model still achieves a comparable performance with the best baseline that is trained with full data. It further indicates the effectiveness of our model in the cold start scenario.\n\n"
                }
            },
            "section 6": {
                "name": "Conclusion",
                "content": "\nIn this paper, we proposed a novel conversational recommendation model named \\textbf{UniCRS} to fulfill both the recommendation and conversation subtasks in a unified approach.  \nFirst, taking a fixed PLM (\\ie DialoGPT) as the backbone, we utilized a knowledge-enhanced prompt learning paradigm to reformulate the two subtasks.\nThen, we designed multiple effective prompts to support both subtasks, which include fused knowledge representations generated by a pre-trained semantic fusion module, task-specific soft tokens, and the dialogue context.\nWe also leveraged the generated response template from the conversation subtask as an important part of the prompt to enhance the recommendation subtask.\nThe above prompt design can provide sufficient information about the dialogue context, task instructions, and background knowledge.\nBy only optimizing these prompts, our model can effectively accomplish both the recommendation and conversation subtasks.\nExtensive experimental results have shown that our approach outperforms several competitive CRS and PLM methods, especially when only limited training data is available.\n\nIn the future, we will apply our model to more complicated scenarios, such as topic-guided CRS~\\cite{zhou2020towards} and multi-modal CRS~\\cite{yu2020towards}.\nWe will also consider devising more effective prompt pre-training strategies for quick adaptation to various CRS scenarios.\n\n"
            },
            "section 7": {
                "name": "Acknowledgement",
                "content": "\nThis work was partially supported by Beijing Natural Science Foundation under Grant No. 4222027,  National Natural Science Foundation of China under Grant No. 61872369, and Beijing Outstanding Young Scientist Program under Grant No. BJJWZYJH012019100020098.\nThis work is also partially supported by Beijing Academy of Artificial Intelligence(BAAI).\nXin Zhao is the corresponding author.\n\n\\bibliographystyle{ACM-Reference-Format}\n\\bibliography{ref}\n\n% \\appendix\n% \\input{sec-appendix}\n\n"
            }
        },
        "tables": {
            "tab:intro": "\\begin{table}[t]\n    \\centering\n    \\caption{\n        An illustrative case of the semantic inconsistency between the recommendation and conversation modules in existing CRS methods.\n        The mentioned movies and entities are marked in italic blue and red, respectively.\n        Compared with the baseline, the generated response of our model is more consistent with the predicted recommendation.\n    }\n    \\label{tab:intro}\n    \\resizebox{\\linewidth}{!}{%\n        \\begin{tabular}{p{0.2\\linewidth}p{0.8\\linewidth}}\n            \\toprule\n            \\textbf{USER:}     & Hello! I am looking for some movies.\\\\\n            \\textbf{HUMAN:}    & What kinds of movie do you like? I like \\textcolor{red}{animated} movies such as \\textcolor{blue}{\\textit{Frozen (2013)}}.\\\\\n            \\textbf{USER:}     & I do not like \\textcolor{red}{animated} films. I would love to see a movie like \\textcolor{blue}{\\textit{Pretty Woman (1990)}} starring \\textcolor{red}{Julia Roberts}. Know any that are similar? \\\\\n            \\midrule\n            \\textbf{KGSF:} &\n            \\begin{tabular}[c]{@{}p{\\linewidth}@{}}\n                \\textbf{Recommendation:} Frozen 2 (2019)\\\\\n                \\textbf{Response:} \\textcolor{blue}{\\textit{Pretty Woman (1990)}} is a great movie.\n            \\end{tabular}\\\\\n            \\midrule\n            \\textbf{OURS:}     &\n            \\begin{tabular}[c]{@{}p{\\linewidth}@{}}\n                \\textbf{Recommendation:} My Best Friend's Wedding (1997)\\\\\n                \\textbf{Response:} Have you seen \\textcolor{blue}{\\textit{My Best Friend's Wedding (1997)}}? \\textcolor{red}{Julia Roberts} also stars in it.\n            \\end{tabular}\\\\\n            \\midrule\n            \\textbf{HUMAN:}    & \\textcolor{blue}{\\textit{Pretty Woman (1990)}} was a good one. If you are in it for \\textcolor{red}{Julia Roberts} you can try \\textcolor{blue}{\\textit{Runaway Bride (1999)}}.\\\\\n            \\bottomrule\n        \\end{tabular}%\n    }\n\\end{table}",
            "tab:datasets": "\\begin{table}[t]\n    \\centering\n    \\caption{Statistics of the datasets after preprocessing.}\n    \\small\n    \\label{tab:datasets}\n    \\begin{tabular}{crrr}\n        \\toprule\n        \\textbf{Dataset} & \\textbf{\\#Dialogs} & \\textbf{\\#Utterances} & \\textbf{\\#Items} \\\\\n        \\midrule\n        INSPIRED         & 1,001              & 35,811                & 1,783            \\\\\n        ReDial           & 10,006             & 182,150               & 51,699           \\\\\n        \\bottomrule\n    \\end{tabular}\n\\end{table}",
            "tab:rec-table": "\\begin{table}[t]\n    \\centering\n    \\caption{\n        Results on the recommendation task.\n        Numbers marked with * indicate that the improvement is statistically significant compared with the best baseline (t-test with p-value < 0.05).\n    }\n    \\label{tab:rec-table}\n    \\resizebox{\\linewidth}{!}{%\n        \\begin{tabular}{lcccccc}\n            \\toprule\n            Datasets & \\multicolumn{3}{c}{ReDial} & \\multicolumn{3}{c}{INSPIRED}                                                                         \\\\\n            \\midrule\n            Models   & R@1                        & R@10                         & R@50            & R@1             & R@10            & R@50            \\\\\n            \\midrule\n            ReDial   & 0.023                      & 0.129                        & 0.287           & 0.003           & 0.117           & 0.285           \\\\\n            KBRD     & 0.033                      & 0.175                        & 0.343           & 0.058           & 0.146           & 0.207           \\\\\n            KGSF     & 0.035                      & 0.177                        & 0.362           & 0.058           & 0.165           & 0.256           \\\\\n            \\midrule\n            GPT-2    & 0.023                      & 0.147                        & 0.327           & 0.034           & 0.112           & 0.278           \\\\\n            DialoGPT & 0.030                      & 0.173                        & 0.361           & 0.024           & 0.125           & 0.247           \\\\\n            BERT     & 0.030                      & 0.156                        & 0.357           & 0.044           & 0.179           & 0.328           \\\\\n            BART     & 0.034                      & 0.174                        & 0.377           & 0.037           & 0.132           & 0.247           \\\\\n            \\midrule\n            UniCRS   & \\textbf{0.051}*            & \\textbf{0.224}*              & \\textbf{0.428}* & \\textbf{0.094}* & \\textbf{0.250}* & \\textbf{0.410}* \\\\\n            \\bottomrule\n        \\end{tabular}%\n    }\n\\end{table}",
            "tab:conv-table": "\\begin{table}[t]\n    \\centering\n    \\caption{\n        Automatic evaluation results on the conversation task.\n        We abbreviate Distinct-2,3,4 as Dist-2,3,4.\n        Numbers marked with * indicate that the improvement is statistically significant compared with the best baseline (t-test with p-value < 0.05).\n    }\n    \\label{tab:conv-table}\n    \\resizebox{\\linewidth}{!}{%\n        \\begin{tabular}{lcccccc}\n            \\toprule\n            Datasets & \\multicolumn{3}{c}{ReDial} & \\multicolumn{3}{c}{INSPIRED}                                                                         \\\\\n            \\midrule\n            Models   & Dist-2                     & Dist-3                       & Dist-4          & Dist-2          & Dist-3          & Dist-4          \\\\\n            \\midrule\n            ReDial   & 0.225                      & 0.236                        & 0.228           & 0.406           & 1.226           & 2.205           \\\\\n            KBRD     & 0.281                      & 0.379                        & 0.439           & 0.567           & 2.017           & 3.621           \\\\\n            KGSF     & 0.302                      & 0.433                        & 0.521           & 0.608           & 2.519           & 4.929           \\\\\n            \\midrule\n            GPT-2    & 0.354                      & 0.486                        & 0.441           & 2.347           & 3.691           & 4.568           \\\\\n            DialoGPT & 0.476                      & 0.559                        & 0.486           & 2.408           & 3.720           & 4.560           \\\\\n            BART     & 0.376                      & 0.490                        & 0.435           & 2.381           & 2.964           & 3.041           \\\\\n            \\midrule\n            UniCRS   & \\textbf{0.492}*            & \\textbf{0.648}*              & \\textbf{0.832}* & \\textbf{3.039}* & \\textbf{4.657}* & \\textbf{5.635}* \\\\\n            \\bottomrule\n        \\end{tabular}%\n    }\n\\end{table}",
            "tab:human-table": "\\begin{table}[t]\n    \\centering\n    \\caption{Human evaluation results about the conversation task on the \\textsc{ReDial} dataset. \n    Numbers marked with * indicate that the improvement is statistically significant compared with the best baseline (t-test with p-value < 0.05).}\n    \\label{tab:human-table}\n        \\begin{tabular}{lcc}\n            \\toprule\n            \\textbf{Models} & \\textbf{Fluency} & \\textbf{Informativeness} \\\\\n            \\midrule\n            ReDial          & 1.31             & 0.98                     \\\\\n            KBRD            & 1.21             & 1.16                     \\\\\n            KGSF            & 1.49             & 1.39                     \\\\\n            \\midrule\n            GPT-2           & 1.62             & 1.48                     \\\\\n            DialoGPT        & 1.68             & 1.56                     \\\\\n            BART            & 1.63             & 1.43                     \\\\\n            \\midrule\n            UniCRS          & \\textbf{1.72}$^{*}$             & \\textbf{1.64}$^{*}$                     \\\\\n            \\bottomrule\n        \\end{tabular}%\n\\end{table}"
        },
        "figures": {
            "fig:approach": "\\begin{figure*}\n\t\\includegraphics[width=\\textwidth]{img/model.pdf}\n\t\\centering\n\t\\caption{\n\t    The overview of the proposed framework UniCRS.\n\t    Blocks in grey indicate that their parameters are frozen, while other parameters are tunable.\n\t    We first perform pre-training to fuse semantics from both words and entities, then prompt the PLM to generate the response template and use the template as part of the prompt for recommendation. \n\t    Finally, the recommended items are filled into the template as a complete response.\n    }\n\t\\label{fig:approach}\n\\end{figure*}",
            "fig:ablation-rec": "\\begin{figure}[t]\n    \\centering\n    \\includegraphics[width=0.49\\linewidth]{img/ablation-recall10.pdf}\n    \\includegraphics[width=0.49\\linewidth]{img/ablation-recall50.pdf}\n    \\caption{\n        Ablation study on the \\textsc{ReDial} dataset about the recommendation task. \n        PT denotes the pre-training task of semantic fusion. \n        Word and entity refer to two kinds of data signals in the fusion module. \n        SP and template refer to task-specific soft tokens and response templates, respectively.\n    }\n    \\label{fig:ablation-rec}\n\\end{figure}",
            "fig:ablation-conv": "\\begin{figure}[t]\n    \\centering\n    \\includegraphics[width=0.49\\linewidth]{img/ablation-dist3.pdf}\n    \\includegraphics[width=0.49\\linewidth]{img/ablation-dist4.pdf}\n    \\caption{\n        Ablation study on the \\textsc{ReDial} dataset about the conversation task.\n        PT denotes the pre-training task of sematic fusion.\n        Word and entity refer to two kinds of data signals in the fusion module. \n        SP refers to task-specific soft tokens.\n    }\n    \\label{fig:ablation-conv}\n\\end{figure}",
            "fig:few-shot": "\\begin{figure}[t]\n    \\centering\n    \\includegraphics[width=0.49\\linewidth]{img/few-shot_recall-10.pdf}\n    \\includegraphics[width=0.49\\linewidth]{img/few-shot_recall-50.pdf}\n    \\caption{Performance comparison w.r.t. different amount of training data on \\textsc{ReDial} dataset.}\n    \\label{fig:few-shot}\n\\end{figure}"
        },
        "equations": {
            "eq:1": "\\begin{equation}\n    \\widetilde{C} \\rightarrow \\underbrace{p_1,\\dots, p_{n_P},}_{\\text{prompt tokens}} \\underbrace{w_{1}\\cdots w_{n_W}}_{\\text{word tokens}}.\n\\end{equation}",
            "eq:2": "\\begin{align}\n    \\mathbf{A}              & =\\mathbf{T}^{\\top}\\mathbf{W} \\mathbf{E},    \\label{eq-A} \\\\ \n    \\widetilde{\\mathbf{T}}  & =\\mathbf{T}+\\mathbf{E}\\mathbf{A},             \\label{eq-T}  \\\\ \n    \\widetilde{\\mathbf{E}}  & =\\mathbf{E}+\\mathbf{T}\\mathbf{A}^{\\top},      \\label{eq-E}\n\\end{align}",
            "eq:3": "\\begin{align}\n    \\label{eq:rec-ent}\n    \\text{Pr}(e \\mid \\widetilde{C}_{pre}) & =\\text{Softmax}(\\bm{h}_u \\cdot\\bm{h}_e),\n\\end{align}",
            "eq:4": "\\begin{equation}\n\\widetilde{C}_{gen} \\rightarrow [\\text{~}\\widetilde{\\mathbf{T}}; \\text{~~~~~}\\mathbf{P}_{gen}; \\text{~~~~~} C\\text{~} ],\n\\label{eq-gen-prompt}\n\\end{equation}",
            "eq:5": "\\begin{align}\n    L_{gen}(\\Theta_{gen})   &= -\\frac{1}{N}\\sum_{j=1}^N\\log \\text{Pr}(R_j \\mid \\widetilde{C}_{gen}^{(j)} ; \\Theta_{gen})    \\notag \\\\\n                            &= -\\frac{1}{N}\\sum_{i=1}^N\\sum_{j=1}^{l_i}\\log \\text{Pr}(w_{i,j} \\mid \\widetilde{C}_{gen}^{(j)} ; \\Theta_{gen} ; w_{<j}),\n \\label{eq:conv-loss-p}\n\\end{align}",
            "eq:6": "\\begin{equation}\n\\widetilde{C}_{rec} \\rightarrow [\\text{~}\\widetilde{\\mathbf{E}}; \\text{~~~~~}\\mathbf{P}_{rec}; \\text{~~~~~} C; \\text{~~~~~} S \\text{~} ],\n\\label{eq-rec-prompt}\n\\end{equation}",
            "eq:7": "\\begin{equation}\n    \\label{eq:rec-loss-p}\n    \\small\n    L_{rec}(\\Theta_{rec})=-\\sum_{j=1}^N\\sum_{i=1}^M\\big[y_{j,i}\\cdot\\log\\text{Pr}_{j}(i)+(1-y_{j,i})\\cdot\\log(1-\\text{Pr}_{j}(i))\\big],\n\\end{equation}"
        },
        "git_link": "https://github.com/RUCAIBox/UniCRS"
    }
}