{
    "meta_info": {
        "title": "TimeMixer: Decomposable Multiscale Mixing for Time Series Forecasting",
        "abstract": "Time series forecasting is widely used in extensive applications, such as\ntraffic planning and weather forecasting. However, real-world time series\nusually present intricate temporal variations, making forecasting extremely\nchallenging. Going beyond the mainstream paradigms of plain decomposition and\nmultiperiodicity analysis, we analyze temporal variations in a novel view of\nmultiscale-mixing, which is based on an intuitive but important observation\nthat time series present distinct patterns in different sampling scales. The\nmicroscopic and the macroscopic information are reflected in fine and coarse\nscales respectively, and thereby complex variations can be inherently\ndisentangled. Based on this observation, we propose TimeMixer as a fully\nMLP-based architecture with Past-Decomposable-Mixing (PDM) and\nFuture-Multipredictor-Mixing (FMM) blocks to take full advantage of\ndisentangled multiscale series in both past extraction and future prediction\nphases. Concretely, PDM applies the decomposition to multiscale series and\nfurther mixes the decomposed seasonal and trend components in fine-to-coarse\nand coarse-to-fine directions separately, which successively aggregates the\nmicroscopic seasonal and macroscopic trend information. FMM further ensembles\nmultiple predictors to utilize complementary forecasting capabilities in\nmultiscale observations. Consequently, TimeMixer is able to achieve consistent\nstate-of-the-art performances in both long-term and short-term forecasting\ntasks with favorable run-time efficiency.",
        "author": "Shiyu Wang, Haixu Wu, Xiaoming Shi, Tengge Hu, Huakun Luo, Lintao Ma, James Y. Zhang, Jun Zhou",
        "link": "http://arxiv.org/abs/2405.14616v1",
        "category": [
            "cs.LG",
            "cs.AI"
        ],
        "additionl_info": ""
    },
    "latex_extraction": {
        "content": {
            "section 1": {
                "name": "Introduction",
                "content": "\n% backgournd: forecasting usage, deep models for forecasting \nTime series forecasting has been studied with immense interest in extensive applications, such as economics \\citep{granger2014forecastingeeenconomic}, energy \\citep{martin2010predictionsolarenergy,qian2019reviewwindenergy}, traffic planning \\citep{Chen2001FreewayPM, Yin2021DeepLO} and weather prediction~\\citep{wu2023corrformer}, which is to predict future temporal variations based on past observations of time series~\\citep{wu2022timesnet}. However, due to the complex and non-stationary nature of the real world or systems, the observed series usually present intricate temporal patterns, where the multitudinous variations, such as increasing, decreasing, and fluctuating, are deeply mixed, bringing severe challenges to the forecasting task.\n\n\nRecently, deep models have achieved promising progress in time series forecasting. The representative models capture temporal variations with well-designed architectures, which span a wide range of foundation backbones, including CNN \\citep{wang2023micn,wu2022timesnet,hewage2020temporaltcn}, RNN~\\citep{lstnet,qin2017dualrnn, Flunkert2017DeepARPF}, Transformer \\citep{NIPS2017_3f5ee243,haoyietal-informer-2021,wu2021autoformer,zhou2022fedformer,patchtst} and MLP \\citep{dlinear,lightts, oreshkin2019nbeats,challu2022nhits}. In the development of elaborative model architectures, to tackle intricate temporal patterns, some special designs are also involved in these deep models. The widely-acknowledged paradigms primarily include series decomposition and multiperiodicity analysis. As a classical time series analysis technology, decomposition is introduced to deep models as a basic module by \\citep{wu2021autoformer}, which decomposes the complex temporal patterns into more predictable components, such as seasonal and trend, and thereby benefiting the forecasting process \\citep{dlinear,zhou2022fedformer,wang2023micn}. Furthermore, multiperiodicity analysis is also involved in time series forecasting \\citep{wu2022timesnet,zhou2022film} to disentangle mixed temporal variations into multiple components with different period lengths. Empowered with these designs, deep models are able to highlight inherent properties of time series from tanglesome variations and further boost the forecasting performance.\n\nGoing beyond the above mentioned designs, we further observe that time series present distinct temporal variations in different sampling scales, e.g., the hourly recorded traffic flow presents traffic changes at different times of the day, while for the daily sampled series, these fine-grained variations disappear but fluctuations associated with holidays emerge. On the other hand, the trend of macro-economics dominates the yearly averaged patterns. These observations naturally call for a multiscale analysis paradigm to disentangle complex temporal variations, where fine and coarse scales can reflect the micro- and the macro-scopic information respectively. Especially for the time series forecasting task, it is also notable that the future variation is jointly determined by the variations in multiple scales. Therefore, in this paper, we attempt to design the forecasting model from a novel view of multiscale-mixing, which is able to \\emph{take advantage of both disentangled variations and complementary forecasting capabilities from multiscale series simultaneously}.\n\nTechnically, we propose \\emph{TimeMixer} with a multiscale mixing architecture that is able to extract essential information from past variations by \\emph{Past-Decomposable-Mixing} (PDM) blocks and then predicts the future series by the \\emph{Future-Multipredictor-Mixing} (FMM) block. Concretely, TimeMixer first generates multiscale observations through average downsampling. Next, PDM adopts a decomposable design to better cope with distinct properties of seasonal and trend variations, by mixing decomposed multiscale seasonal and trend components in fine-to-coarse and coarse-to-fine directions separately.  With our novel design, PDM is able to successfully aggregate the detailed seasonal information starting from the finest series and dive into macroscopic trend components along with the knowledge from coarser scales. In the forecasting phase, FMM ensembles multiple predictors to utilize complementary forecasting capabilities from multiscale observations. With our meticulous architecture, TimeMixer achieves the consistent state-of-the-art performances in both long-term and short-term forecasting tasks with superior efficiency across all of our experiments, covering extensive well-established benchmarks. Our contributions are summarized as follows:\n% \\vspace{-5pt}\n\\begin{itemize}\n    \\item Going beyond previous methods, we tackle intricate temporal variations in series forecasting from a novel view of multiscale mixing, taking advantage of disentangled variations and complementary forecasting capabilities from multiscale series simultaneously.\n    \\item \\revise{We propose TimeMixer as a simple but effective forecasting model, which enables the combination of the multiscale information in both history extraction and future prediction phases, empowered by our tailored decomposable and multiple-predictor mixing technique.}\n    \\item TimeMixer achieves consistent state-of-the-art in performances in both long-term and short-term forecasting tasks with superior efficiency on a wide range of benchmarks.\n\\end{itemize}\n\n\\vspace{-5pt}\n"
            },
            "section 2": {
                "name": "Related Work",
                "content": "\n",
                "subsection 2.1": {
                    "name": "Temporal Modeling in Deep Time Series Forecasting",
                    "content": "\n\nAs the key problem in time series analysis \\citep{wu2022timesnet}, temporal modeling has been widely explored. According to foundation backbones, deep models can be roughly categorized into the following four paradigms: RNN-, CNN-, Transformer- and MLP-based methods. Typically, CNN-based models employ the convolution kernels along the time dimension to capture temporal patterns \\citep{wang2023micn,hewage2020temporaltcn}. And RNN-based methods adopt the recurrent structure to model the temporal state transition~\\citep{lstnet,LSTMnetwork}. However, both RNN- and CNN-based methods suffer from the limited receptive field, limiting the long-term forecasting capability. Recently, benefiting from the global modeling capacity, Transformer-based models have been widely-acknowledged in long-term series forecasting \\citep{haoyietal-informer-2021,wu2021autoformer,Liu2022NonstationaryTR,kitaev2020reformer,patchtst}, which can capture the long-term temporal dependencies adaptively with attention mechanism. Furthermore, multiple layer projection (MLP) is also introduced to time series forecasting \\citep{oreshkin2019nbeats,challu2022nhits,dlinear}, which achieves favourable performance in both forecasting performance and efficiency. \n\nAdditionally, several specific designs are proposed to better capture intricate temporal patterns, including series decomposition and multi-periodicity analysis. Firstly, for the series decomposition, Autoformer \\citep{wu2021autoformer} presents the series decomposition block based on moving average to decompose complex temporal variations into seasonal and trend components. Afterwards, FEDformer \\citep{zhou2022fedformer} enhances the series decomposition block with multiple kernels moving average. DLinear \\citep{dlinear} utilizes the series decomposition as the pre-processing before linear regression. MICN~\\citep{wang2023micn} also decomposes input series into seasonal and trend terms, and then integrates the global and local context for forecasting. As for the multi-periodicity analysis, N-BEATS \\citep{oreshkin2019nbeats} fits the time series with multiple trigonometric basis functions. FiLM \\citep{zhou2022film} projects time series into Legendre Polynomials space, where different basis functions correspond to different period components in the original series. Recently, TimesNet \\citep{wu2022timesnet} adopts Fourier Transform to map time series into multiple components with different period lengths and presents a modular architecture to process decomposed components.\n\nUnlike the designs mentioned above, this paper explores the multiscale mixing architecture in time series forecasting. Although there exist some models with temporal multiscale designs, such as Pyraformer \\citep{liu2021pyraformer} with pyramidal attention and SCINet \\citep{liu2022scinet} with a bifurcate downsampling tree, their future predictions do not make use of the information at different scales extracted from the past observations simultaneously. In TimeMixer, we present a new multiscale mixing architecture with Past-Decomposable-Mixing to utilize the disentangled series for multiscale representation learning and Future-Multipredictor-Mixing to ensemble the complementary forecasting skills of multiscale series for better prediction.\n\n% \\vspace{-5pt}\n"
                },
                "subsection 2.2": {
                    "name": "Mixing Networks",
                    "content": " \n\nMixing is an effective way of information integration and has been applied to computer vision and natural language processing. For instance, MLP-Mixer \\citep{tolstikhin2021mlpmixer} designs a two-stage mixing structure for image recognition, which mixes the channel information and patch information successively with linear layers. FNet \\citep{lee2021fnet} replaces attention layers in Transformer with simple Fourier Transform, achieving the efficient token mixing of a sentence. In this paper, we further explore the mixing structure in time series forecasting. Unlike previous designs, TimeMixer presents a decomposable multi-scale mixing architecture and distinguishes the mixing methods in both past information extraction and future prediction phases.\n\n% \\vspace{-5pt}\n"
                }
            },
            "section 3": {
                "name": "TimeMixer",
                "content": "\n\nGiven a series $\\mathbf{x}$ with one or multiple observed variates, the main objective of time series forecasting is to utilize past observations (length-$P$) to obtain the most probable future prediction (length-$F$).\nAs mentioned above, the key challenge of accurate forecasting is to tackle intricate temporal variations. In this paper, we propose \\textit{TimeMixer} of multiscale-mixing, benefiting from disentangled variations and complementary forecasting capabilities from multiscale series. Technically, TimeMixer consists of a \\emph{multiscale mixing architecture} with \\emph{Past-Decomposable-Mixing} and \\emph{Future-Multipredictor-Mixing} for past information extraction and future prediction respectively.\n\n",
                "subsection 3.1": {
                    "name": "Multiscale Mixing Architecture",
                    "content": "\\label{sec:method_downsample}\n\nTime series of different scales naturally exhibit distinct properties, where fine scales mainly depict detailed patterns and coarse scales highlight macroscopic variations \\citep{Mozer1991InductionOM}. This multiscale view can inherently disentangle intricate variations in multiple components, thereby benefiting temporal variation modeling. It is also notable that, especially for the forecasting task, multiscale time series present different forecasting capabilities, due to their distinct dominating temporal patterns \\citep{Ferreira2006MultiscaleAH}. Therefore, we present TimeMixer in a \\textit{multiscale mixing architecture} to utilize multiscale series with distinguishing designs for past extraction and future prediction phases. \n\nAs shown in Figure~\\ref{fig:overall}, to disentangle complex variations, we first downsample the past observations $\\mathbf{x}\\in\\mathbb{R}^{P\\times C}$ into $M$ scales by average pooling and finally obtain a set of multiscale time series\n$\\mathcal{X}=\\{\\mathbf{x}_{0}, \\cdots, \\mathbf{x}_{M}\\}$, where $\\mathbf{x}_{m}\\in\\mathbb{R}^{\\lfloor\\frac{P}{2^m}\\rfloor\\times C}, m\\in\\{0,\\cdots, M\\}$, $C$ denotes the variate number. The lowest level series $\\mathbf{x}_{0}=\\mathbf{x}$ is the input series, which contains the finest temporal variations, while the highest-level series $\\mathbf{x}_{M}$ is for the macroscopic variations. Then we project these multiscale series into deep features $\\mathcal{X}^0$ by the embedding layer, which can be formalized as $\\mathcal{X}^0=\\operatorname{Embed}(\\mathcal{X})$. With the above designs, we obtain the multiscale representations of input series.\n\n\nNext, we utilize stacked Past-Decomposable-Mixing (PDM) blocks to mix past information across different scales.\nFor the $l$-th layer, the input is $\\mathcal{X}^{l-1}$ and the process of PDM can be formalized as:\n\\begin{equation}\\label{equ:equ1}\n  \\begin{split}\n\\mathcal{X}^{l} = \\operatorname{PDM}(\\mathcal{X}^{l-1}), \\ \\ l\\in\\{0,\\cdots, L\\},\\\\\n  \\end{split}\n\\end{equation}\nwhere $L$ is the total layer and $\\mathcal{X}^l=\\{\\mathbf{x}_{0}^l, \\cdots, \\mathbf{x}_{M}^l\\}, \\mathbf{x}_{m}^l\\in\\mathbb{R}^{\\lfloor\\frac{P}{2^m}\\rfloor\\times d_{\\text{model}}}$ denotes the mixed past representations with $d_{\\text{model}}$ channels. More details of PDM are described in the next section.\n\nAs for the future prediction phase, we adopt the Future-Multipredictor-Mixing (FMM) block to ensemble extracted multiscale past information $\\mathcal{X}^L$ and generate future predictions, which is:\n\\begin{equation}\\label{equ:equ2}\n  \\begin{split}\n    \\widehat{\\mathbf{x}} = \\operatorname{FMM}(\\mathcal{X}^L),\\\\\n  \\end{split}\n\\end{equation}\nwhere $\\widehat{\\mathbf{x}}\\in\\mathbb{R}^{F\\times C}$ represents the final prediction. With the above designs, TimeMixer can successfully capture essential past information from disentangled multiscale observations and predict the future with benefits from multiscale past information.\n\n\n %todo \u66f4\u65b0\u4e00\u4e0b\u7ed3\u6784\uff0c\u66f4\u65b0\u989c\u8272\uff0c\u589e\u52a0\u4fe1\u606f\u91cf % fine and coarse \n\n"
                },
                "subsection 3.2": {
                    "name": "Past Decomposable Mixing",
                    "content": "\n\\label{sec:sec3.2}\n\nWe observe that for past observations, due to the complex nature of real-world series, even the coarsest scale series present mixed variations. As shown in Figure \\ref{fig:overall}, the series in the top layer still present clear seasonality and trend simultaneously. It is notable that the seasonal and trend components hold distinct properties in time series analysis \\citep{cleveland1990stl}, which corresponds to short-term and long-term variations or stationary and non-stationary dynamics respectively. Therefore, instead of directly mixing multiscale series as a whole, we propose the Past-Decomposable-Mixing (PDM) block to mix the decomposed seasonal and trend components in multiple scales separately.\n\nConcretely, for the $l$-th PDM block, we first decompose the multiscale time series $\\mathcal{X}_{l}$ into seasonal parts $\\mathcal{S}^l=\\{\\mathbf{s}_{0}^l, \\cdots, \\mathbf{s}_{M}^l\\}$ and trend parts $\\mathcal{T}^l=\\{\\mathbf{t}_{0}^l, \\cdots, \\mathbf{t}_{M}^l\\}$ by series decomposition block from Autoformer \\citep{wu2021autoformer}. As the above analyzed, taking the distinct properties of seasonal-trend parts into account, we apply the mixing operation to seasonal and trend terms separately to interact information from multiple scales. Overall, the $l$-th PDM block can be formalized as:\n\\begin{equation}\\label{equ:equ3}\n  \\begin{split}\n    \\mathbf{s}_{m}^{l},\\mathbf{t}_{m}^{l}&=\\operatorname{SeriesDecomp}(\\mathbf{x}_{m}^{l}), m\\in\\{0,\\cdots, M\\}, \\\\\n    \\mathcal{X}^l = \\mathcal{X}^{l-1} + &\\operatorname{FeedForward}\\bigg(\\operatorname{S-Mix}\\big(\\{\\mathbf{s}_{m}^{l}\\}_{m=0}^{M}\\big)+\\operatorname{T-Mix}\\big(\\{\\mathbf{t}_{m}^{l}\\}_{m=0}^{M}\\big)\\bigg), \\\\\n  \\end{split}\n\\end{equation}\nwhere $\\operatorname{FeedForward}(\\cdot)$ contains two linear layers with intermediate GELU activation function for information interaction among channels, $\\operatorname{S-Mix}(\\cdot), \\operatorname{T-Mix}(\\cdot)$ denote seasonal and trend mixing.\n\n\\paragraph{Seasonal Mixing}\nIn seasonality analysis \\citep{Box1970TimeSA}, larger periods can be seen as the aggregation of smaller periods, such as the weekly period of traffic flow formed by seven daily changes, addressing the importance of detailed information in predicting future seasonal variations.\n\nTherefore, in seasonal mixing, we adopt the bottom-up approach to incorporate information from the lower-level fine-scale time series upwards, which can supplement detailed information to the seasonality modeling of coarser scales. Technically, for the set of multiscale seasonal parts $\\mathcal{S}^l=\\{\\mathbf{s}_{0}^l, \\cdots, \\mathbf{s}_{M}^l\\}$, we use the \\revise{Bottom-Up-Mixing} layer for the $m$-th scale in a residual way to achieve bottom-up seasonal information interaction, which can be formalized as:\n\\begin{equation}\\label{equ:season_mxiing} \\\n  \\begin{split}\n\\mathrm{for}\\  m\\mathrm{:}\\ 1\\to M \\ \\mathrm{do}\\mathrm{:}\\ \\ \\ \\ \\mathbf{s}_{m}^{l} = \\mathbf{s}_{m}^{l} + \\revise{\\operatorname{Bottom-Up-Mixing}}(\\mathbf{s}_{m-1}^{l}).\n  \\end{split}\n\\end{equation}\nwhere $\\revise{\\operatorname{Bottom-Up-Mixing}}(\\cdot)$ is instantiated as two linear layers with an intermediate GELU activation function along the temporal dimension, whose input dimension is $\\lfloor\\frac{P}{2^{m-1}}\\rfloor$ and output dimension is $\\lfloor\\frac{P}{2^m}\\rfloor$. See Figure \\ref{fig:components} for an intuitive understanding. \n\n\\vspace{-5pt}\n\\paragraph{Trend Mixing}\nContrary to seasonal parts, for trend items, the detailed variations can introduce noise in capturing macroscopic trend. Note that the upper coarse scale time series can easily provide clear macro information than the lower level. Therefore, we adopt a top-down mixing method to utilize the macro knowledge from coarser scales to guide the trend modeling of finer scales.\n\nTechnically, for multiscale trend components $\\mathcal{T}^l=\\{\\mathbf{t}_{0}^l, \\cdots, \\mathbf{t}_{M}^l\\}$, we adopt the \\revise{Top-Down-Mixing} layer for the $m$-th scale in a residual way to achieve top-down trend information interaction:\n\\begin{equation}\\label{equ:trend_mixing} \n  \\begin{split}\n\\mathrm{for}\\  m\\mathrm{:}\\ (M-1)\\to 0\\ \\mathrm{do}\\mathrm{:}\\ \\ \\ \\ \\mathbf{t}_{m}^{l} = \\mathbf{t}_{m}^{l} + \\revise{\\operatorname{Top-Down-Mixing}}(\\mathbf{t}_{m+1}^{l}),\n  \\end{split}\n\\end{equation}\nwhere $\\revise{\\operatorname{Top-Down-Mixing}}(\\cdot)$ is two linear layers with an intermediate GELU activation function, whose input dimension is $\\lfloor\\frac{P}{2^{m+1}}\\rfloor$ and output dimension is $\\lfloor\\frac{P}{2^m}\\rfloor$ as shown in Figure \\ref{fig:components}. \n\nEmpowered by seasonal and trend mixing, PDM progressively aggregates the detailed seasonal information from fine to coarse and dive into the macroscopic trend information with prior knowledge from coarser scales, eventually achieving the multiscale mixing in past information extraction.\n\n\n\n"
                },
                "subsection 3.3": {
                    "name": "Future Multipredictor Mixing",
                    "content": "\nAfter $L$ PDM blocks, we obtain the multiscale past information as $\\mathcal{X}^L=\\{\\mathbf{x}_{0}^L, \\cdots, \\mathbf{x}_{M}^L\\}, \\mathbf{x}_{m}^L\\in\\mathbb{R}^{\\lfloor\\frac{P}{2^m}\\rfloor\\times d_{\\text{model}}}$. Since the series in different scales presents different dominating variations, their predictions also present different capabilities. To fully utilize the multiscale information, we propose to aggregate predictions from multiscale series and present Future-Multipredictor-Mixing block as:\n\\begin{equation}\\label{equ:fmm} \n  \\begin{split}\n   \\widehat{\\mathbf{x}}_{m}=\\operatorname{Predictor}_{m}(\\mathbf{x}_{m}^L),\\ m\\in\\{0,\\cdots,M\\}, \\  \\widehat{\\mathbf{x}}=\\sum_{m=0}^{M} \\widehat{\\mathbf{x}}_{m},\\\\\n  \\end{split}\n\\end{equation}\nwhere $\\widehat{\\mathbf{x}}_{m}\\in\\mathbb{R}^{F\\times C}$ represents the future prediction from the $m$-th scale series and the final output is $\\widehat{\\mathbf{x}}\\in\\mathbb{R}^{F\\times C}$. \\revise{$\\operatorname{Predictor}_{m}(\\cdot)$ denotes the predictor of the $m$-th scale series}, which firstly adopts one single linear layer to directly regress length-$F$ future from length-$\\lfloor\\frac{P}{2^m}\\rfloor$ extracted past information (Figure~\\ref{fig:components}) and then projects deep representations into $C$ variates. \\revise{Note that FMM is an ensemble of multiple predictors, where different predictors are based on past information from different scales, enabling FMM to integrate complementary forecasting capabilities of mixed multiscale series.}% \u89e3\u91ca\u4e00\u4e0bpredictor \u672a\u6765\u9884\u6d4b\u957f\u5ea6\u90fd\u4e00\u81f4\n\n\\vspace{-5pt}\n"
                }
            },
            "section 4": {
                "name": "Experiments",
                "content": "\n\\vspace{-5pt}\nWe conduct extensive experiments to evaluate the performance and efficiency of TimeMixer, covering long-term and short-term forecasting, including 18 real-world benchmarks and 15 baselines. The detailed model and experiment configurations are summarized in Appendix \\ref{sec:detail}.\n\n\\vspace{-5pt}\n\\paragraph{Benchmarks}\nFor long-term forecasting, we experiment on 8 well-established benchmarks: ETT datasets (including 4 subsets: ETTh1, ETTh2, ETTm1, ETTm2), Weather, Solar-Energy, Electricity, and Traffic following \\citep{haoyietal-informer-2021,wu2021autoformer,liu2022scinet}. For short-term forecasting, we adopt the PeMS \\citep{Chen2001FreewayPM} which contains four public traffic network datasets (PEMS03, PEMS04, PEMS07, PEMS08), and M4 dataset which involves 100,000 different time series collected in different frequencies. Furthermore, we measure the forecastability \\citep{goerg2013forecastable} of all datasets. It is observed that ETT, M4, and Solar-Energy exhibit relatively low forecastability, indicating the challenges in these benchmarks. More information is summarized in Table~\\ref{tab:summary_dataset}.\n\n\n\n\\vspace{-8pt}\n\\paragraph{Baselines} We compare TimeMixer with 15 baselines, which comprise the state-of-the-art long-term forecasting model PatchTST \\citeyearpar{patchtst} and advanced short-term forecasting models TimesNet~\\citeyearpar{wu2022timesnet} and SCINet \\citeyearpar{liu2022scinet}, as well as other competitive models including Crossformer \\citeyearpar{zhang2023crossformer}, MICN \\citeyearpar{wang2023micn}, FiLM \\citeyearpar{zhou2022film}, DLinear \\citeyearpar{dlinear}, LightTS \\citeyearpar{lightts} ,FEDformer \\citeyearpar{zhou2022fedformer}, Stationary \\citeyearpar{Liu2022NonstationaryTR}, Pyraformer \\citeyearpar{liu2021pyraformer}, Autoformer \\citeyearpar{wu2021autoformer}, Informer \\citeyearpar{haoyietal-informer-2021}, N-HiTS \\citeyearpar{challu2022nhits} and N-BEATS \\citeyearpar{oreshkin2019nbeats}. \n\n\\vspace{-8pt}\n\\paragraph{Unified experiment settings}\nNote that experimental results reported by the above mentioned baselines cannot be compared directly due to different choices of input length and hyper-parameter searching strategy. For fairness, we make a great effort to provide two types of experiments. In the main text, we align the input length of all baselines and report results averaged from three repeats (see Appendix \\ref{sec:error_bar} for error bars). In Appendix, to compare the upper bound of models, we also conduct a comprehensive hyperparameter searching and report the best results in Table \\ref{tab:long_full_forecasting_results} of Appendix.\n\n\\vspace{-8pt}\n\\paragraph{Implementation details}\nAll the experiments are implemented in PyTorch \\citep{Paszke2019PyTorchAI} and conducted on a single NVIDIA A100 80GB GPU. We utilize the L2 loss for model training. The number of scales $M$ is set according to the time series length to trade off performance and efficiency. %The detailed model and experiment configurations are summarized in Table \\ref{tab:model_config} of Appendix.\n\n\\vspace{-5pt}\n",
                "subsection 4.1": {
                    "name": "Main Results",
                    "content": "\n\\paragraph{Long-term forecasting}\nAs shown in Table~\\ref{tab:long_term_forecasting_results}, TimeMixer achieves consistent state-of-the-art performance in all benchmarks, covering a large variety of series with different frequencies, variate numbers and real-world scenarios. Especially, TimeMixer outperforms PatchTST by a considerable margin, with a 9.4\\% MSE reduction in Weather and a 24.7\\% MSE reduction in Solar-Energy. It is worth noting that TimeMixer exhibits good performance even for datasets with low forecastability, such as Solar-Energy and ETT, further proving the generality and effectiveness of TimeMixer.\n\n\n\n\n\n\\paragraph{Short-term forecasting}\n\nTimeMixer also shows great performance in short-term forecasting under both multivariate and univariate settings (Table~\\ref{tab:PEMS_results}-\\ref{tab:M4_results}). For PeMS benchmarks that record multiple time series of citywide traffic networks, due to the complex spatiotemporal correlations among multiple variates, many advanced models degenerate a lot in this task, such as PatchTST \\citeyearpar{patchtst} and DLinear \\citeyearpar{dlinear}, which adopt the channel independence design. In contrast, TimeMixer still performs favourablely in this challenging problem, verifying its effectiveness in handling complex multivariate time series forecasting. As for the M4 dataset for univariate forecasting, it contains various temporal variations under different sampling frequencies, including hourly, daily, weekly, monthly, quarterly, and yearly, which exhibits low predictability and distinctive characteristics across different frequencies. Remarkably, Timemixer consistently performs best across all frequencies, affirming the multiscale mixing architecture's capacity in modeling complex temporal variations. %These results demonstrate the model's capacity in complex series forecasting.\n\n\n\n\n\n\n\\vspace{-5pt}\n"
                },
                "subsection 4.2": {
                    "name": "Model Analysis",
                    "content": "\n\n\\paragraph{Ablations} \nTo verify the effectiveness of each component of TimeMixer, \\revise{we provide detailed ablation study on every possible design in both Past-Decomposable-Mixing and Future-Multipredictor-Mixing blocks on all 18 experiment benchmarks.} From Table~\\ref{tab:ablation_main_text}, we have the following observations.\n\nThe exclusion of Future-Multipredictor-Mixing in ablation \\ding{173} results in a significant decrease in the model's forecasting accuracy for both short and long-term predictions. This demonstrates that mixing future predictions from multiscale series can effectively boost the model performance.\n\nFor the past mixing, we verify the effectiveness by removing or replacing components gradually. In ablations \\ding{174} and \\ding{175} that remove seasonal mixing and trend mixing respectively, also cause a decline of performance. This illustrates that solely relying on seasonal or trend information interaction is insufficient for accurate predictions.\nFurthermore, in both ablations \\ding{176} and \\ding{177}, we employed the same mixing approach for both seasons and trends. However, it cannot bring better predictive performance. \\revise{Similar situation occurs in \\ding{178} that adopts opposite mixing strategies to our design. These results demonstrate the effectiveness of our design in both bottom-up seasonal mixing and top-down trend mixing.} Concurrently, in ablations \\ding{179} and \\ding{180}, we opted to eliminate the decomposition architecture and mix the multiscale series directly. However, without decomposition, neither bottom-up nor top-down mixing method can achieve a good performance, indicating the necessity of season-trend separate mixing. Furthermore, in ablations \\ding{181}, eliminating the entire Past-Decomposable-Mixing block causes a serious drop in the model's predictive performance. The above findings highlight the substantial influence of an appropriate past mixing method on the final performance of the model. Starting from the insights in time series, TimeMixer presents the best mixing method in past information extraction.\n\n\n% todo: seasonal mixing, trend mixing\n\n\n\n\\vspace{-5pt}\n\\paragraph{Seasonal and trend mixing visualization} \nTo provide an intuitive understanding of PDM, we visualize temporal linear weights for seasonal mixing and trend mixing in Figure~\\ref{fig:visual_weights}(a)$\\sim$(b). We find that the seasonal and trend items present distinct mixing properties, where the seasonal mixing layer presents periodic changes (repeated blue lines in (a)) and the trend mixing layer is dominated by local aggregations (the dominating diagonal yellow line in (b)). This also verifies the necessity of adopting separate mixing techniques for seasonal and trend terms. Furthermore, Figure~\\ref{fig:visual_weights}(c) shows the predictions of season and trend terms in fine (scale 0) and coarse (scale 3) scales. We can observe that the seasonal terms of fine-scale and trend parts of coarse-scale are crucial for accurate predictions. This observation provides insights for our design in utilizing bottom-up mixing for seasonal terms and top-down mixing for trend components.\n\n\n\\vspace{-5pt}\n\\paragraph{Multipredictor visualization}\nTo provide an intuitive understanding of the forecasting skills of multiscale series, we plot the forecasting results from different scales for qualitative comparison. Figure \\ref{fig:visual}(a) presents the overall prediction of our model with Future-Multipredictor-Mixing, which indicates accurate prediction according to the future variations using mixed scales.  To study the component of each individual scale, we demonstrate the prediction results for each scale in Figure \\ref{fig:visual}(b)$\\sim$(e).  Specifically, prediction results from fine-scale time series concentrate more on the detailed variations of time series and capture seasonal patterns with greater precision. In contrast, as shown in Figure \\ref{fig:visual}(c)$\\sim$(e), with multiple downsampling, the predictions from coarse-scale series focus more on macro trends. The above results also highlight the benefits of Future-Multipredictor-Mixing in utilizing complementary forecasting skills from multiscale series. \n\n\n\n\n\n\n\n\n\\vspace{-5pt}\n\\paragraph{Efficiency analysis}\nWe compare the running memory and time against the latest state-of-the-art models in Figure~\\ref{fig:model_analysis} under the training phase, where TimeMixer consistently demonstrates favorable efficiency, in terms of both GPU memory and running time, for various series lengths (ranging from 192 to 3072), in addition to the consistent state-of-the-art performances for both long-term and short-term forecasting tasks.  \n\n\\vspace{-5pt}\n\\paragraph{Analysis on number of scales} \\label{sec:sensitivity}\nWe explore the impact from the number of scales ($M$) in Figure~\\ref{fig:scale_sensitivity} under different series lengths. Specifically, when $M$ increases, the performance gain declines for shorter prediction lengths. In contrast, for longer prediction lengths, the performance improves more as $M$ increases. Therefore, we set $M$ as 3 for long-term forecast and 1 for short-term forecast to trade off performance and efficiency.\n\n"
                }
            },
            "section 5": {
                "name": "Conclusion",
                "content": "\nWe presented TimeMixer with a multiscale mixing architecture to tackle the intricate temporal variations in time series forecasting. Empowered by Past-Decomposable-Mixing and Future-Multipredictor-Mixing blocks, TimeMixer took advantage of both disentangled variations and complementary forecasting capabilities. In all of our experiments, TimeMixer achieved consistent state-of-the-art performances in both long-term and short-term forecasting tasks. Moreover, benefiting from the fully MLP-based architecture, TimeMixer demonstrated favorable run-time efficiency. Detailed visualizations and ablations are included to provide insights for our design.\n\n"
            },
            "section 6": {
                "name": "Ethics Statement",
                "content": "\nOur work only focuses on the scientific problem, so there is no potential ethical risk.\n\n\n"
            },
            "section 7": {
                "name": "Reproducibility Statement",
                "content": "\nWe involve the implementation details in Appendix \\ref{sec:detail}, including dataset descriptions, metric calculation and experiment configuration. The source code is provided in \\underline{supplementary materials} and public in GitHub (\\href{https://github.com/kwuking/TimeMixer}{https://github.com/kwuking/TimeMixer}) for reproducibility.\n\n"
            },
            "section 8": {
                "name": "Acknowledgments",
                "content": "\nThis work was supported by Ant Group through CCF-Ant Research Fund.\n\n\n\\bibliography{iclr2024_conference}\n\\bibliographystyle{iclr2024_conference}\n\n\\appendix\n"
            },
            "section 9": {
                "name": "Implementation Details",
                "content": "\\label{sec:detail}\n\nWe summarized details of datasets, evaluation metrics, experiments and visualizations in this section.\n\n\\paragraph{Datasets details}\nWe evaluate the performance of different models for long-term forecasting on 8 well-established datasets, including Weather, Traffic, Electricity, Solar-Energy, and ETT datasets (ETTh1, ETTh2, ETTm1, ETTm2). Furthermore, we adopt PeMS and M4 datasets for short-term forecasting.\nWe detail the descriptions of the dataset in Table \\ref{tab:dataset}.  \n\n\n\n\n\\paragraph{Metric details}\nRegarding metrics, we utilize the mean square error (MSE) and mean absolute error (MAE) for long-term forecasting. In the case of short-term forecasting, we follow the metrics of SCINet \\citep{liu2022scinet} on the PeMS datasets, including mean absolute error (MAE), mean absolute percentage error (MAPE), root mean squared error (RMSE). As for the M4 datasets, we follow the methodology of N-BEATS \\citep{oreshkin2019nbeats} and implement the symmetric mean absolute percentage error (SMAPE), mean absolute scaled error (MASE), and overall weighted average (OWA) as metrics. It is worth noting that OWA is a specific metric utilized in the M4 competition. The calculations of these metrics are:\n\\begin{align*} \\label{equ:metrics}\n    \\text{RMSE} &= (\\sum_{i=1}^F (\\mathbf{X}_{i} - \\widehat{\\mathbf{X}}_{i})^2)^{\\frac{1}{2}},\n    &\n    \\text{MAE} &= \\sum_{i=1}^F|\\mathbf{X}_{i} - \\widehat{\\mathbf{X}}_{i}|,\\\\\n    \\text{SMAPE} &= \\frac{200}{F} \\sum_{i=1}^F \\frac{|\\mathbf{X}_{i} - \\widehat{\\mathbf{X}}_{i}|}{|\\mathbf{X}_{i}| + |\\widehat{\\mathbf{X}}_{i}|},\n    &\n    \\text{MAPE} &= \\frac{100}{F} \\sum_{i=1}^F \\frac{|\\mathbf{X}_{i} - \\widehat{\\mathbf{X}}_{i}|}{|\\mathbf{X}_{i}|}, \\\\\n    \\text{MASE} &= \\frac{1}{F} \\sum_{i=1}^F \\frac{|\\mathbf{X}_{i} - \\widehat{\\mathbf{X}}_{i}|}{\\frac{1}{F-s}\\sum_{j=s+1}^{F}|\\mathbf{X}_j - \\mathbf{X}_{j-s}|},\n    &\n    \\text{OWA} &= \\frac{1}{2} \\left[ \\frac{\\text{SMAPE}}{\\text{SMAPE}_{\\textrm{Na\u00efve2}}}  + \\frac{\\text{MASE}}{\\text{MASE}_{\\textrm{Na\u00efve2}}}  \\right],\n\\end{align*}\nwhere $s$ is the periodicity of the data. $\\mathbf{X},\\widehat{\\mathbf{X}}\\in\\mathbb{R}^{F\\times C}$ are the ground truth and prediction results of the future with $F$ time pints and $C$ dimensions. $\\mathbf{X}_{i}$ means the $i$-th future time point.\n\n\\paragraph{Experiment details}\nAll experiments were run three times, implemented in Pytorch \\citep{Paszke2019PyTorchAI}, and conducted on a single NVIDIA A100 80GB GPU. We set the initial learning rate as $10^{-2}$ or $10^{-3}$ and used the ADAM optimizer \\citep{DBLP:journals/corr/KingmaB14adam} with L2 loss for model optimization. And the batch size was set to be 8 between 128. By default, TimeMixer contains 2 Past Decomposable Mixing blocks. We choose the number of scales $M$ according to the length of the time series to achieve a balance between performance and efficiency. To handle longer series in long-term forecasting, we set $M$ to 3. As for short-term forecasting with limited series length, we set $M$ to 1. Detailed model configuration information is presented in Table~\\ref{tab:model_config}.\n\n\\paragraph{\\revise{Visualization details}} \\revise{To verify complementary forecasting capabilities of multiscale series, we fix the PDM and train a new predictor for the feature at each scale with the ground truth future as supervision in Figure \\ref{fig:visual}; Figure \\ref{fig:visual_weights}(c) also utilizes the same operations.} \\revisenew{Especially for Figure \\ref{fig:visual}, we also provide the visualization of directly plotting the output of each predictor, i.e. $\\widehat{\\mathbf{x}}_{m},\\ m\\in\\{0,\\cdots,M\\}$ in Eq.~\\ref{equ:fmm}. Note that in FMM, we adopt the sum ensemble $\\widehat{\\mathbf{x}}=\\sum_{m=0}^{M}\\widehat{\\mathbf{x}}_{m}$ as the final output, the scale of each plotted cure is around $\\frac{1}{M+1}$ of ground truth, while we can still observe the distinct forecasting capability of series in different scales. For clearness, we also plot the $(M+1)\\times \\widehat{\\mathbf{x}}_{m}$ in the second row of Figure \\ref{fig:visual_2_new}, where the visualizations are similar to Figure \\ref{fig:visual}.}\n\n\n\n\n\n\n"
            },
            "section 10": {
                "name": "Efficiency Analysis",
                "content": "\nIn the main text, we have ploted the curve of efficiency in Figure \\ref{fig:model_analysis}. Here we present the quantitive results in Table~\\ref{tab:cost}. It should be noted that TimeMixer's outstanding efficiency advantage over Transformer-based models, such as PatchTST, FEDformer, and Autoformer, is attributed to its fully MLP-based network architecture. \n\n\n\n\n"
            },
            "section 11": {
                "name": "Error bars",
                "content": "\\label{sec:error_bar}\nIn this paper, we repeat all the experiments three times. Here we report the standard deviation of our model and the second best model, as well as the statistical significance test in Table~\\ref{tab:errorbar_long},~\\ref{tab:errorbar_pems},~\\ref{tab:errorbar_m4}.\n\n\n\n\n\n\n\n\n"
            },
            "section 12": {
                "name": "Hyperparamter Sensitivity",
                "content": "\nIn the main text, we have explored the effect of number of scales $M$. Here, we further evaluate the number of layers $L$. As shown in Table~\\ref{tab:sensitivity}, we can find that in general, increasing the number of layers ($L$) will bring improvements across different prediction lengths. Therefore, we set to 2 to trade off efficiency and performance.\n\n\n\n\n"
            },
            "section 13": {
                "name": "Full Results",
                "content": "\\label{appdix:full_search}\nTo ensure a fair comparison between models, we conducted experiments using unified parameters and reported results in the main text, including aligning all the input lengths, batch sizes, and training epochs in all experiments. Here, we provide the full results for each forecasting setting in Table~\\ref{tab:full_forecasting_results}. \n\nIn addition, considering that the reported results in different papers are mostly obtained through hyperparameter search, we provide the experiment results with the full version of the parameter search. We searched for input length among 96, 192, 336, and 512, learning rate from $10^{-5}$ to 0.05, encoder layers from 1 to 5, the $d_{\\text{model}}$ from 16 to 512, training epochs from 10 to 100. The results are included in Table~\\ref{tab:long_full_forecasting_results}, which can be used to compare the upper bound of each forecasting model. \n\n\\revise{We can find that the relative promotion of TimesMixer over PatchTST is smaller under comprehensive hyperparameter search than the unified hyperparameter setting.  It is worth noticing that TimeMixer runs much faster than PatchTST according to the efficiency comparison in Table \\ref{tab:cost}. Therefore, considering perfromance, hyperparameter-search cost and efficiency, we believe TimeMixer is a practical model in real-world applications and is valuable to deep time series forecasting community.}\n\n\n\n"
            },
            "section 14": {
                "name": "Full Ablations",
                "content": "\\label{appendix:ablations}\n\n\\revise{Here we provide the complete results of ablations and alternative designs for TimeMixer.}\n\n",
                "subsection 14.1": {
                    "name": "Ablations of Each Design in TimeMixer",
                    "content": "\nTo verify the effectiveness of our design in TimeMixer, we conduct comprehensive ablations for all benchmarks. All the results are provided in Table \\ref{tab:ablation_long},~\\ref{tab:ablation_m4},~\\ref{tab:ablation_pems} as a supplement to Table \\ref{tab:ablation_main_text} of main text.\n\n\n\n\n\n\n\n\\paragraph{\\revise{Implementations}} We implement the following 10 types of ablations:\n\\begin{itemize}\n    \\item Offical design in TimeMixer (case \\ding{172}). \n    \\item Ablations on Future Mixing (case \\ding{173}): In this case, we only adopt a single predictor to the finest scale features, that is $\\hat{\\mathbf{x}}=\\operatorname{Predictor}_{0}(\\mathbf{x}_{0}^{L})$.\n    \\item Ablations on Past Mixing (case \\ding{174}-\\ding{178}): Firstly, we remove the mixing operation of TimeMixer in seasonal and trend parts respectively (case \\ding{174}-\\ding{175}), that is removing $\\operatorname{Bottom-Up-Mixing}$ or $\\operatorname{Top-Down-Mixing}$ layer. Then, we reverse the mixing directions for seasonal and trend parts (case \\ding{176}-\\ding{178}), which means adopting $\\operatorname{Bottom-Up-Mixing}$ layer to trend and $\\operatorname{Top-Down-Mixing}$ layer to seasonal part.\n    \\item Ablations on Decomposition (case \\ding{179}-\\ding{181}): In these cases, we do not adopt the decomposition, which means that there is only one single feature for each scale. Thus, we can only try one single mixing direction for these features, that is bottom-up mixing in case \\ding{179}, top-down mixing in case \\ding{180}. Besides, we also test the case that is without mixing in \\ding{181}, where the interactions among multiscale features are removed.\n\\end{itemize}\n\n\n\\paragraph{\\revise{Analysis}} In all ablations, we can find that the official design in TimeMixer performs best, which provides solid support to our insights in special mixing approaches. Notably, it is observed that completely reversing mixing directions for seasonal and trend parts (case \\ding{178}) leads to a seriously performance drop. This may come from that the essential microscopic information in finer-scale seasons and macroscopic information in coarser-scale trends are ruined by unsuitable mixing approaches.\n\n"
                },
                "subsection 14.2": {
                    "name": "Alternative Decomposition Methods",
                    "content": "\n\nIn this paper, we adopt the moving-average-based season-trend decomposition, which is widely used in previous work, such as Autoformer \\citep{wu2021autoformer}, FEDformer \\citep{zhou2022fedformer} and DLinear \\citep{dlinear}. It is notable that Discrete Fourier Transformer (DFT) have been widely recognized in time series analysis. Thus, we also try the DFT-based decomposition as a substitute. Here we present two types of experiments.\n\nThe first one is \\emph{DFT-based high- and low-frequency decomposition}. We treat the high-frequency part like the seasonal part in TimeMixer and the low-frequency part like the trend part. The results are shown in Table \\ref{tab:abla_decomp}. It observed that DFT-based decomposition performs worse than our design in TimeMixer. Since we only explore the proper mixing approach for decomposed seasonal and trend parts in the paper, the bottom-up and top-down mixing strategies may be not suitable for high- and low-frequency parts. New visualizations like Figure \\ref{fig:visual_weights} and \\ref{fig:visual} are expected to provide insights to the model design. Thus, we would like to leave the exploration of DFT-based high- and low-frequency decomposition methods as the future work.\n\nThe second one is to enhance season-trend decomposition with DFT. Here we present the \\emph{DFT-based season-trend decomposition}. Firstly, we transform the raw series into a frequency domain by DFT and then extract the most significant frequencies. After transforming the selected frequencies by inverse DFT, we obtain the seasonal part of the time series. Then the trend part is the raw series minus the seasonal part. We can find that this superior decomposition method surpasses the moving-average design. However, since moving average is quite simple and easy to implement with PyTorch, we eventually chose the moving-average-based season-trend decomposition in TimeMixer, which can also achieve a favorable balance between performance and efficiency.\n\n\n\n"
                },
                "subsection 14.3": {
                    "name": "Alternative Downsampling Methods",
                    "content": "\n\nAs we stated in Section \\ref{sec:method_downsample}, we adopt the average pooling to obtain the multiscale series. Here we replace this operation with 1D convolutions. From Table \\ref{tab:abla_sampling}, we can find that the complicated 1D-convolution-based outperforms average pooling slightly. But considering both performance and efficiency, we eventually use average pooling in TimeMixer.\n\n\n\n"
                },
                "subsection 14.4": {
                    "name": "Alternative Ensemble Strategies",
                    "content": "\n\n\\revisenew{In the main text, we sum the outputs from multiple predictors towards the final result (Eq.~\\ref{equ:fmm}). Here we also try the average strategy. Note that in TimeMixer, the loss is calculated based on the ensemble results, not for each predictor, that is $\\|\\mathbf{x}-\\hat{\\mathbf{x}}\\|=\\|\\mathbf{x}-\\sum_{m=0}^{M}\\hat{\\mathbf{x}}_{m}\\|$. When we change the ensemble strategy as average, the loss will be $\\|\\mathbf{x}-\\hat{\\mathbf{x}}\\|=\\|\\mathbf{x}-\\frac{1}{M+1}\\sum_{m=0}^{M}\\hat{\\mathbf{x}}_{m}\\|$. Obviously, the difference between average and mean strategies is only a constant multiple.}\n\n\\revisenew{It is common sense in the deep learning community that deep models can easily fit constant multiple. For example, if we replace the ``sum'' with ``average'', under the same supervision, the deep model can easily fit this change by learning the parameters of each predictor equal to the $\\frac{1}{M+1}$ of the ``sum'' case, which means these two designs are equivalent in learning the final prediction under the deep model aspect. Besides, we also provide the experiment results in Table \\ref{tab:abla_ensemble}, where we can find that the performances of these two strategies are almost the same.}\n\n\n\n\n\n\n\n\n\n"
                },
                "subsection 14.5": {
                    "name": "Ablations on Larger Scales and Larger Input Length Settings",
                    "content": "\n\\revisenew{In the previous section (Table \\ref{tab:ablation_long},~\\ref{tab:ablation_m4},~\\ref{tab:ablation_pems}), we have conducted comprehensive ablations under the unified configuration presented in Table~\\ref{tab:model_config}, which $M$ is set to 1 for short-term forecasting and input length is set to 96 for short-term forecasting. To further evaluate the effectiveness of our proposed module, we also provide additional ablations on larger scales for short-term forecasting and larger input length settings in Table \\ref{tab:ablation_main_text_additional} as a supplement to Table \\ref{tab:ablation_main_text} of the main text. Besides, we also provide a detailed analysis of relative promotion (Table \\ref{tab:ablation_main_text_additional_relative}), where we can find the following observations:}\n\\begin{itemize}\n    \\item \\revisenew{All the designs of TimeMixer are effective in both hyperparameter settings. Especially, the seasonal mixing (case \\ding{174}) and proper mixing directions (case \\ding{178}) are essential.}\n    \\item \\revisenew{As shown in Table \\ref{tab:ablation_main_text_additional_relative}, in large $M$ and longer input length situations, the relative promotions brought by seasonal and trend mixing in PDM and FMM are more significant in most cases, which further verifies the effectiveness of our design.}\n    \\item \\revisenew{It is observed that the seasonal mixing direction contribution (case \\ding{176}) is much more significant in the longer-input setting on the ETTm1 dataset. This may come from that input-96 only corresponds to one day in 15-minutely sampled ETTm1, while input-336 maintains 3.5 days of information (around 3.5 periods). Thus, the bottom-up mixing direction will benefit from sufficient microscopic seasonal information under the longer-input setting.}\n\\end{itemize}\n\n\n"
                }
            },
            "section 15": {
                "name": "Additional Baselines",
                "content": "\nDue to the limitation of the main text, we also include three advanced baselines here: the general multi-scale framework Scaleformer \\citep{scaleformer}, two concurrent MLP-based model MTSMixer \\citep{li2023mtsmixers} and TSMixer \\citep{chen2023tsmixer}. Since the latter two baselines were not officially published during our submission, we adopted their public code and reproduced them with \\revisenew{both unified hyperparameter setting and the hyperparameter searching settings}. As presented in Table~\\ref{tab:full_forecasting_results_additional},~\\ref{tab:PEMS_results_additional},~\\ref{tab:M4_results_additional}, TimeMixer still performs best in comparison with these baselines. Showcases of these additional baselines are also provided in Appendix \\ref{appendix:showcase} for an intuitive comparison.\n\n\n\n\n\n\n\n\n\n"
            },
            "section 16": {
                "name": "Spectral Analysis of Model Predictions",
                "content": "\nTo demonstrate the advancement of TimeMixer, we plot the spectrum of ground truth and model predictions. It is observed that TimeMixer captures different frequency parts precisely.\n\n\n"
            },
            "section 17": {
                "name": "Showcases",
                "content": "\\label{appendix:showcase}\nIn order to evaluate the performance of different models, we conduct the qualitative comparison by plotting the final dimension of forecasting results from the test set of each dataset (Figures~\\ref{fig:visual_etth1},~\\ref{fig:visual_ecl},~\\ref{fig:visual_traffic},~\\ref{fig:visual_weather},~\\ref{fig:visual_solar},~\\ref{fig:visual_pems},~\\ref{fig:visual_m4}). Among the various models, TimeMixer exhibits superior performance.\n\n\n"
            },
            "section 18": {
                "name": "Limitations and Future Work",
                "content": "\nTimeMixer has shown favorable efficiency in GPU memory and running time as we presented in the main text. However, it should be noted that as the input length increases, the linear mixing layer may result in a larger number of model parameters, which is inefficient for mobile applications. To address this issue and improve TimeMixer's parameter efficiency, we plan to investigate alternative mixing designs, such as attention-based or CNN-based in future research. \\revise{In addition, we only focus on the temporal dimension mixing in this paper, and also plan to incorporate the variate dimension mixing into model design in our future work. Furthermore, as an application-oriented model, we made a great effort to verify the effectiveness of our design with experiments and ablations. The theoretical analysis to verify the optimality and completeness of our design is also a promising direction.}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"
            }
        },
        "tables": {
            "tab:summary_dataset": "\\begin{table}[t]\n  \\vspace{0pt}\n  \\caption{Summary of benchmarks. Forecastability is one minus the entropy of Fourier domain.}\\label{tab:summary_dataset}\n  \\vspace{3pt}\n  \\centering\n  % \\resizebox{\\columnwidth}{!}{\n  \\begin{threeparttable}\n  \\begin{small}\n  \\renewcommand{\\multirowsetup}{\\centering}\n  \\setlength{\\tabcolsep}{2.5pt}\n  \\begin{tabular}{c|c|c|c|c|c|c}\n    \\toprule\n    Tasks & Dataset  & Variate & Predict Length  & Frequency &Forecastability%$\\ast$\n    & Information\\\\\n    \\toprule\n     &\\makecell[c]{ETT (4 subsets) } & 7 & 96$\\sim$720 & 15 mins &0.46 &Temperature\\\\\n    \\cmidrule{2-7}\n    Long-term  & Weather & 21 & 96$\\sim$720  & 10 mins &0.75 & Weather\\\\\n    \\cmidrule{2-7}\n    forecasting & Solar-Energy & 137& 96$\\sim$720  & 10min &0.33 & Electricity\\\\\n    \\cmidrule{2-7}\n    & Electricity  & 321 & 96$\\sim$720 & Hourly  &0.77 &Electricity\\\\\n    \\cmidrule{2-7}\n    & Traffic & 862 & 96$\\sim$720 & Hourly &0.68  &Transportation\\\\\n    \\midrule\n    Short-term & PEMS (4 subsets) & 170$\\sim$883\n      & 12 & 5min &0.55 &Traffic network\\\\\n    \\cmidrule{2-7}\n    forecasting & M4 (6 subsets) & 1 & 6$\\sim$48 & Hourly$\\sim$Yearly  &0.47 & Database \\\\ \n    \\bottomrule\n    \\end{tabular}\n    % \\begin{tablenotes}\n    %     \\item $\\ast$ The forecastability is calculated by one minus the entropy of Fourier domain \\citep{goerg2013forecastable}.\n    % \\end{tablenotes}\n    \\end{small}\n  \\end{threeparttable}\n  % }\n  \\vspace{-15pt}\n\\end{table}",
            "tab:long_term_forecasting_results": "\\begin{table}[b]\n  \\vspace{-20pt}\n  \\caption{Long-term forecasting results. All the results are averaged from 4 different prediction lengths, that is $\\{96,192,336,720\\}$. A lower MSE or MAE indicates a better prediction. We fix the input length as 96 for all experiments. See Table \\ref{tab:full_forecasting_results} in Appendix for the full results.}\\label{tab:long_term_forecasting_results}\n  \\centering\n  \\vspace{3pt}\n  \\resizebox{\\columnwidth}{!}{\n  \\begin{threeparttable}\n  \\renewcommand{\\multirowsetup}{\\centering}\n  \\setlength{\\tabcolsep}{1.4pt}\n  \\begin{tabular}{c|cc|cc|cc|cc|cc|cc|cc|cc|cc|cc|cc}\n    \\toprule\n    \\multicolumn{1}{c}{\\multirow{2}{*}{Models}} &\n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{1.0}{\\textbf{TimeMixer}}}} &\n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{1.0}{PatchTST}}} &\n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{1.0}{TimesNet}}} &\n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{1.0}{Crossformer}}} &\n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{1.0}{MICN}}} &\n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{1.0}{FiLM}}} & \n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{1.0}{DLinear}}} &\n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{1.0}{FEDformer}}} & \n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{1.0}{Stationary}}} & \n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{1.0}{Autoformer}}} &\n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{1.0}{Informer}}} \\\\\n    \\multicolumn{1}{c}{} & \\multicolumn{2}{c}{\\scalebox{1.0}{(\\textbf{Ours})}} &\n    \\multicolumn{2}{c}{\\scalebox{1.0}{\\citeyearpar{patchtst}}}&\n    \\multicolumn{2}{c}{\\scalebox{1.0}{\\citeyearpar{wu2022timesnet}}}&\n    \\multicolumn{2}{c}{\\scalebox{1.0}{\\citeyearpar{zhang2023crossformer}}}&\n    \\multicolumn{2}{c}{\\scalebox{1.0}{\\citeyearpar{wang2023micn}}}&\n    \\multicolumn{2}{c}{\\scalebox{1.0}{\\citeyearpar{zhou2022film}}}&\n    \\multicolumn{2}{c}{\\scalebox{1.0}{\\citeyearpar{dlinear}}}&\n    \\multicolumn{2}{c}{\\scalebox{1.0}{\\citeyearpar{zhou2022fedformer}}}&\n    \\multicolumn{2}{c}{\\scalebox{1.0}{\\citeyearpar{Liu2022NonstationaryTR}}}&\n    \\multicolumn{2}{c}{\\scalebox{1.0}{\\citeyearpar{wu2021autoformer}}}&\n    \\multicolumn{2}{c}{\\scalebox{1.0}{\\citeyearpar{haoyietal-informer-2021}}}\n    \n    \\\\\n    \\cmidrule(lr){2-3} \\cmidrule(lr){4-5}\\cmidrule(lr){6-7} \\cmidrule(lr){8-9}\\cmidrule(lr){10-11}\\cmidrule(lr){12-13}\\cmidrule(lr){14-15}\\cmidrule(lr){16-17}\\cmidrule(lr){18-19} \\cmidrule(lr){20-21} \\cmidrule(lr){22-23}\n    \\multicolumn{1}{c|}{Metric} & \\scalebox{1.00}{MSE} & \\scalebox{1.00}{MAE} & \\scalebox{1.00}{MSE} & \\scalebox{1.00}{MAE} & \\scalebox{1.00}{MSE} & \\scalebox{1.00}{MAE} & \\scalebox{1.00}{MSE} & \\scalebox{1.00}{MAE} & \\scalebox{1.00}{MSE} & \\scalebox{1.00}{MAE} & \\scalebox{1.00}{MSE} & \\scalebox{1.00}{MAE} & \\scalebox{1.00}{MSE} & \\scalebox{1.00}{MAE} & \\scalebox{1.00}{MSE} & \\scalebox{1.00}{MAE} & \\scalebox{1.00}{MSE} & \\scalebox{1.00}{MAE} & \\scalebox{1.00}{MSE} & \\scalebox{1.00}{MAE} & \\scalebox{1.00}{MSE} & \\scalebox{1.00}{MAE}\\\\\n    \\toprule\n\n    \\scalebox{1}{Weather}\n     &\\boldres{\\scalebox{1.00}{0.240}}&\\boldres{\\scalebox{1.00}{0.271}}&\\scalebox{1.00}{0.265}&\\secondres{\\scalebox{1.00}{0.285}}&\\secondres{\\scalebox{1.00}{0.251}}&\\scalebox{1.00}{0.294}&\\scalebox{1.00}{0.264}&\\scalebox{1.00}{0.320}&\\scalebox{1.00}{0.268}&\\scalebox{1.00}{0.321}&\\scalebox{1.00}{0.271}&\\scalebox{1.00}{0.291}&\\scalebox{1.00}{0.265}&\\scalebox{1.00}{0.315} &\\scalebox{1.00}{0.309} &\\scalebox{1.00}{0.360} &\\scalebox{1.00}{0.288} &\\scalebox{1.00}{0.314} &\\scalebox{1.00}{0.338} &\\scalebox{1.00}{0.382} &\\scalebox{1.00}{0.634} &\\scalebox{1.00}{0.548} \\\\\n    \\midrule\n\n    \\scalebox{1}{Solar-Energy}\n     &\\boldres{\\scalebox{1.00}{0.216}}&\\boldres{\\scalebox{1.00}{0.280}}&\\scalebox{1.00}{0.287}&\\secondres{\\scalebox{1.00}{0.333}}&\\scalebox{1.00}{0.403}&\\scalebox{1.00}{0.374}&\\scalebox{1.00}{0.406}&\\scalebox{1.00}{0.442}&\\secondres{\\scalebox{1.00}{0.283}}&\\scalebox{1.00}{0.358}&\\scalebox{1.00}{0.380}&\\scalebox{1.00}{0.371}&\\scalebox{1.00}{0.330}&\\scalebox{1.00}{0.401}&\\scalebox{1.00}{0.328} &\\scalebox{1.00}{0.383} &\\scalebox{1.00}{0.350} &\\scalebox{1.00}{0.390} &\\scalebox{1.00}{0.586} &\\scalebox{1.00}{0.557} &\\scalebox{1.00}{0.331} &\\scalebox{1.00}{0.381}\\\\\n    \\midrule\n    \n    \\scalebox{1}{Electricity} \n    &\\boldres{\\scalebox{1.00}{0.182}}&\\boldres{\\scalebox{1.00}{0.272}}&\\scalebox{1.00}{0.216}&\\scalebox{1.00}{0.318}&\\secondres{\\scalebox{1.00}{0.193}}&\\scalebox{1.00}{0.304}&\\scalebox{1.00}{0.244}&\\scalebox{1.00}{0.334}&\\scalebox{1.00}{0.196}&\\scalebox{1.00}{0.309}&\\scalebox{1.00}{0.223}&\\scalebox{1.00}{0.302}&\\scalebox{1.00}{0.225}&\\scalebox{1.00}{0.319} &\\scalebox{1.00}{0.214} &\\scalebox{1.00}{0.327} &\\secondres{\\scalebox{1.00}{0.193}} &\\secondres{\\scalebox{1.00}{0.296}}&\\scalebox{1.00}{0.227} &\\scalebox{1.00}{0.338} &\\scalebox{1.00}{0.311} &\\scalebox{1.00}{0.397}\\\\\n    \\midrule\n    \n    \\scalebox{1}{Traf\ufb01c}\n    &\\boldres{\\scalebox{1.00}{0.484}}&\\boldres{\\scalebox{1.00}{0.297}}&\\secondres{\\scalebox{1.00}{0.529}}&\\scalebox{1.00}{0.341}&\\scalebox{1.00}{0.620}&\\secondres{\\scalebox{1.00}{0.336}}&\\scalebox{1.00}{0.667}&\\scalebox{1.00}{0.426}&\\scalebox{1.00}{0.593}&\\scalebox{1.00}{0.356}&\\scalebox{1.00}{0.637}&\\scalebox{1.00}{0.384}&\\scalebox{1.00}{0.625}&\\scalebox{1.00}{0.383} &\\scalebox{1.00}{0.610} &\\scalebox{1.00}{0.376} &\\scalebox{1.00}{0.624} &\\scalebox{1.00}{0.340} &\\scalebox{1.00}{0.628} &\\scalebox{1.00}{0.379} &\\scalebox{1.00}{0.764} &\\scalebox{1.00}{0.416}\\\\\n    \\midrule\n\n\n    \\scalebox{1}{ETTh1}\n    &\\boldres{\\scalebox{1.00}{0.447}}&\\boldres{\\scalebox{1.00}{0.440}}&\\scalebox{1.00}{0.516}&\\scalebox{1.00}{0.484}&\\scalebox{1.00}{0.495}&\\secondres{\\scalebox{1.00}{0.450}}&\\scalebox{1.00}{0.529}&\\scalebox{1.00}{0.522}&\\scalebox{1.00}{0.475}&\\scalebox{1.00}{0.480}&\\scalebox{1.00}{0.516}&\\scalebox{1.00}{0.483}&\\secondres{\\scalebox{1.00}{0.461}}&\\scalebox{1.00}{0.457}&\\scalebox{1.00}{0.498} &\\scalebox{1.00}{0.484} &\\scalebox{1.00}{0.570} &\\scalebox{1.00}{0.537} &\\scalebox{1.00}{0.496} &\\scalebox{1.00}{0.487} &\\scalebox{1.00}{1.040} &\\scalebox{1.00}{0.795}\\\\\n    \\midrule\n\n    \\scalebox{1}{ETTh2}\n    &\\boldres{\\scalebox{1.00}{0.364}}&\\boldres{\\scalebox{1.00}{0.395}}&\\secondres{\\scalebox{1.00}{0.391}}&\\secondres{\\scalebox{1.00}{0.411}}&\\scalebox{1.00}{0.414}&\\scalebox{1.00}{0.427}&\\scalebox{1.00}{0.942}&\\scalebox{1.00}{0.684}&\\scalebox{1.00}{0.574}&\\scalebox{1.00}{0.531}&\\scalebox{1.00}{0.402}&\\scalebox{1.00}{0.420}&\\scalebox{1.00}{0.563}&\\scalebox{1.00}{0.519} &\\scalebox{1.00}{0.437} &\\scalebox{1.00}{0.449} &\\scalebox{1.00}{0.526} &\\scalebox{1.00}{0.516} &\\scalebox{1.00}{0.450} &\\scalebox{1.00}{0.459} &\\scalebox{1.00}{4.431} &\\scalebox{1.00}{1.729}\\\\\n    \\midrule\n\n    \\scalebox{1}{ETTm1}\n    &\\boldres{\\scalebox{1.00}{0.381}}&\\boldres{\\scalebox{1.00}{0.395}}&\\secondres{\\scalebox{1.00}{0.406}}&\\scalebox{1.00}{0.407}&\\secondres{\\scalebox{1.00}{0.400}}&\\secondres{\\scalebox{1.00}{0.406}}&\\scalebox{1.00}{0.513}&\\scalebox{1.00}{0.495}&\\scalebox{1.00}{0.423}&\\scalebox{1.00}{0.422}&\\scalebox{1.00}{0.411}&\\secondres{\\scalebox{1.00}{0.402}}&\\scalebox{1.00}{0.404}&\\scalebox{1.00}{0.408}  &\\scalebox{1.00}{0.448} &\\scalebox{1.00}{0.452} &\\scalebox{1.00}{0.481} &\\scalebox{1.00}{0.456} &\\scalebox{1.00}{0.588} &\\scalebox{1.00}{0.517} &\\scalebox{1.00}{0.961} &\\scalebox{1.00}{0.734}\\\\\n    \\midrule\n\n    \\scalebox{1}{ETTm2}  \n    &\\boldres{\\scalebox{1.00}{0.275}}&\\boldres{\\scalebox{1.00}{0.323}}&\\scalebox{1.00}{0.290}&\\scalebox{1.00}{0.334}&\\scalebox{1.00}{0.291}&\\scalebox{1.00}{0.333}&\\scalebox{1.00}{0.757}&\\scalebox{1.00}{0.610}&\\scalebox{1.00}{0.353}&\\scalebox{1.00}{0.402}&\\secondres{\\scalebox{1.00}{0.287}}&\\secondres{\\scalebox{1.00}{0.329}}&\\scalebox{1.00}{0.354}&\\scalebox{1.00}{0.402} &\\scalebox{1.00}{0.305} &\\scalebox{1.00}{0.349} &\\scalebox{1.00}{0.306} &\\scalebox{1.00}{0.347} &\\scalebox{1.00}{0.327} &\\scalebox{1.00}{0.371} &\\scalebox{1.00}{1.410} &\\scalebox{1.00}{0.810}\\\\\n    \\bottomrule\n  \\end{tabular}\n    % \\end{small}\n  \\end{threeparttable}\n   }\n   \\vspace{-10pt}\n\\end{table}",
            "tab:PEMS_results": "\\begin{table}[tbp]\n\\caption{\\update{Short-term forecasting results in the PEMS datasets with multiple variates.} All input lengths are 96 and prediction lengths are 12. A lower MAE, MAPE or RMSE indicates a better prediction.}\\label{tab:PEMS_results}\n  \\vspace{3pt}\n  \\centering\n  \\resizebox{\\columnwidth}{!}{\n  \\begin{threeparttable}\n  \\begin{small}\n  \\renewcommand{\\multirowsetup}{\\centering}\n  \\setlength{\\tabcolsep}{0.7pt}\n  \\begin{tabular}{c|c|c|c|c|c|c|c|c|c|c|c|c|c}\n    \\toprule\n    \\multicolumn{2}{c}{\\multirow{2}{*}{Models}} &\n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{\\textbf{TimeMixer}}}} &\n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{SCINet}}} &\n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{Crossformer}}} &\n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{PatchTST}}} &\n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{TimesNet}}} &\n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{MICN}}} &\n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{FiLM}}} &\n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{DLinear}}} &\n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{FEDformer}}} & \n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{Stationary}}} & \n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{Autoformer}}} &   \n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{Informer}}} \n    \\\\\n    \\multicolumn{2}{c}{}&\\multicolumn{1}{c}{\\scalebox{0.95}{(\\textbf{Ours})}} &\n    \\multicolumn{1}{c}{\\scalebox{0.95}{\\citeyearpar{liu2022scinet}}} &\n    \\multicolumn{1}{c}{\\scalebox{0.95}{\\citeyearpar{zhang2023crossformer}}} &\n    \\multicolumn{1}{c}{\\scalebox{0.95}{\\citeyearpar{patchtst}}} &\n    \\multicolumn{1}{c}{\\scalebox{0.95}{\\citeyearpar{wu2022timesnet}}} &\n    \\multicolumn{1}{c}{\\scalebox{0.95}{\\citeyearpar{wang2023micn}}} &\n    \\multicolumn{1}{c}{\\scalebox{0.95}{\\citeyearpar{zhou2022film}}} &\n    \\multicolumn{1}{c}{\\scalebox{0.95}{\\citeyearpar{dlinear}}} &\n    \\multicolumn{1}{c}{\\scalebox{0.95}{\\citeyearpar{zhou2022fedformer}}} &\n    \\multicolumn{1}{c}{\\scalebox{0.95}{\\citeyearpar{Liu2022NonstationaryTR}}}&\n    \\multicolumn{1}{c}{\\scalebox{0.95}{\\citeyearpar{wu2021autoformer}}} &\n    \\multicolumn{1}{c}{\\scalebox{0.95}{\\citeyearpar{haoyietal-informer-2021}}}\n    \\\\\n    \\toprule\n    \n    \\multirow{3}{*}{\\scalebox{1.0}{\\rotatebox{0}{PEMS03}}} \n    & \\scalebox{1.0}{MAE} & \\boldres{\\scalebox{1.0}{14.63}} & \\scalebox{1.0}{15.97}  & \\secondres{\\scalebox{1.0}{15.64}} & \\scalebox{1.0}{18.95} & \\scalebox{1.0}{16.41} &\\scalebox{1.0}{15.71} & \\scalebox{1.0}{21.36} &\\scalebox{1.0}{19.70} & \\scalebox{1.0}{19.00} &\\scalebox{1.0}{17.64} & \\scalebox{1.0}{18.08} &\\scalebox{1.0}{19.19}\n    \\\\\n    & \\scalebox{1.0}{MAPE} & \\boldres{\\scalebox{1.0}{14.54}} & \\scalebox{1.0}{15.89} & \\scalebox{1.0}{15.74} & \\scalebox{1.0}{17.29} &\n    \\secondres{\\scalebox{1.0}{15.17}}  & \\scalebox{1.0}{15.67} & \\scalebox{1.0}{18.35} &\\scalebox{1.0}{18.35}  & \\scalebox{1.0}{18.57} &\\scalebox{1.0}{17.56} & \\scalebox{1.0}{18.75} &\\scalebox{1.0}{19.58}\n    \\\\\n    & \\scalebox{1.0}{RMSE} & \\boldres{\\scalebox{1.0}{23.28}} & \\secondres{\\scalebox{1.0}{25.20}} & \\scalebox{1.0}{25.56} & \\scalebox{1.0}{30.15} &\n    \\scalebox{1.0}{26.72}  & \\scalebox{1.0}{24.55} & \\scalebox{1.0}{35.07} &\\scalebox{1.0}{32.35} & \\scalebox{1.0}{30.05} &\\scalebox{1.0}{28.37} & \\scalebox{1.0}{27.82} &\\scalebox{1.0}{32.70}\n    \\\\\n    \\midrule\n    \\multirow{3}{*}{\\scalebox{1.0}{\\rotatebox{0}{PEMS04}}} \n    & \\scalebox{1.0}{MAE} & \\boldres{\\scalebox{1.0}{19.21}} & \\secondres{\\scalebox{1.0}{20.35}} & \\scalebox{1.0}{20.38} & \\scalebox{1.0}{24.86} &\n    \\scalebox{1.0}{21.63}  & \\scalebox{1.0}{21.62} &\n    \\scalebox{1.0}{26.74}  & \\scalebox{1.0}{24.62} &\n    \\scalebox{1.0}{26.51}  & \\scalebox{1.0}{22.34} &\n    \\scalebox{1.0}{25.00}  & \\scalebox{1.0}{22.05}\n    \\\\\n    & \\scalebox{1.0}{MAPE} & \\boldres{\\scalebox{1.0}{12.53}} & \\secondres{\\scalebox{1.0}{12.84}} & \\secondres{\\scalebox{1.0}{12.84}} & \\scalebox{1.0}{16.65} &\n    \\scalebox{1.0}{13.15}  & \\scalebox{1.0}{13.53} &\n    \\scalebox{1.0}{16.46}  & \\scalebox{1.0}{16.12} &\n    \\scalebox{1.0}{16.76}  & \\scalebox{1.0}{14.85} &\n    \\scalebox{1.0}{16.70}  & \\scalebox{1.0}{14.88}\n    \\\\\n    & \\scalebox{1.0}{RMSE} & \\boldres{\\scalebox{1.0}{30.92} }& \\secondres{\\scalebox{1.0}{32.31}} & \\scalebox{1.0}{32.41} & \\scalebox{1.0}{40.46} &\n    \\scalebox{1.0}{34.90}  & \\scalebox{1.0}{34.39} &\n    \\scalebox{1.0}{42.86}  & \\scalebox{1.0}{39.51} &\n    \\scalebox{1.0}{41.81}  & \\scalebox{1.0}{35.47} &\n    \\scalebox{1.0}{38.02}  & \\scalebox{1.0}{36.20}\n    \\\\\n\n    \\midrule\n    \\multirow{3}{*}{\\scalebox{1.0}{\\rotatebox{0}{PEMS07}}} \n    & \\scalebox{1.0}{MAE} & \\boldres{\\scalebox{1.0}{20.57}} & \\scalebox{1.0}{22.79} & \\secondres{\\scalebox{1.0}{22.54}} & \\scalebox{1.0}{27.87} \n    &\\scalebox{1.0}{25.12} &\\scalebox{1.0}{22.28}\n    &\\scalebox{1.0}{28.76} &\\scalebox{1.0}{28.65}\n    &\\scalebox{1.0}{27.92} &\\scalebox{1.0}{26.02}\n    &\\scalebox{1.0}{26.92} &\\scalebox{1.0}{27.26}\n    \\\\\n    & \\scalebox{1.0}{MAPE} & \\boldres{\\scalebox{1.0}{8.62}} & \\scalebox{1.0}{9.41} & \\secondres{\\scalebox{1.0}{9.38}} & \\scalebox{1.0}{12.69} \n    &\\scalebox{1.0}{10.60} &\\scalebox{1.0}{9.57}\n    &\\scalebox{1.0}{11.21} &\\scalebox{1.0}{12.15}\n    &\\scalebox{1.0}{12.29} &\\scalebox{1.0}{11.75}\n    &\\scalebox{1.0}{11.83} &\\scalebox{1.0}{11.63}\n    \\\\ \n    & \\scalebox{1.0}{RMSE} & \\boldres{\\scalebox{1.0}{33.59}} & \\scalebox{1.0}{35.61} & \\scalebox{1.0}{35.49} & \\scalebox{1.0}{42.56} \n    &\\scalebox{1.0}{40.71} &\\secondres{\\scalebox{1.0}{35.40}}\n    &\\scalebox{1.0}{45.85} &\\scalebox{1.0}{45.02}\n    &\\scalebox{1.0}{42.29} &\\scalebox{1.0}{42.34}\n    &\\scalebox{1.0}{40.60} &\\scalebox{1.0}{45.81}\n    \\\\\n\n    \\midrule\n    \\multirow{3}{*}{\\scalebox{1.0}{\\rotatebox{0}{PEMS08}}} \n    & \\scalebox{1.0}{MAE} & \\boldres{\\scalebox{1.0}{15.22}} & \\secondres{\\scalebox{1.0}{17.38}}  & \\scalebox{1.0}{17.56}  & \\scalebox{1.0}{20.35}\n    &\\scalebox{1.0}{19.01} &\\scalebox{1.0}{17.76}\n    &\\scalebox{1.0}{22.11} &\\scalebox{1.0}{20.26}\n    &\\scalebox{1.0}{20.56} &\\scalebox{1.0}{19.29}\n    &\\scalebox{1.0}{20.47} &\\scalebox{1.0}{20.96}\n    \\\\\n    & \\scalebox{1.0}{MAPE} & \\boldres{\\scalebox{1.0}{9.67}} & \\scalebox{1.0}{10.80} & \\scalebox{1.0}{10.92} & \\scalebox{1.0}{13.15} \n    &\\scalebox{1.0}{11.83} &\\secondres{\\scalebox{1.0}{10.76}}\n    &\\scalebox{1.0}{12.81} &\\scalebox{1.0}{12.09}\n    &\\scalebox{1.0}{12.41} &\\scalebox{1.0}{12.21}\n    &\\scalebox{1.0}{12.27} &\\scalebox{1.0}{13.20}\n    \\\\\n    & \\scalebox{1.0}{RMSE} & \\boldres{\\scalebox{1.0}{24.26}} & \\scalebox{1.0}{27.34} & \\secondres{\\scalebox{1.0}{27.21}} & \\scalebox{1.0}{31.04} \n    &\\scalebox{1.0}{30.65} &\\scalebox{1.0}{27.26}\n    &\\scalebox{1.0}{35.13} &\\scalebox{1.0}{32.38}\n    &\\scalebox{1.0}{32.97} &\\scalebox{1.0}{38.62}\n    &\\scalebox{1.0}{31.52} &\\scalebox{1.0}{30.61}\n    \\\\\n    \n    \\bottomrule\n  \\end{tabular}\n    \\end{small}\n  \\end{threeparttable}\n  }\n  \\vspace{-10pt}\n\\end{table}",
            "tab:M4_results": "\\begin{table}[tbp]\n  \\caption{Short-term forecasting results in the M4 dataset with a single variate. All prediction lengths are in $\\left[ 6,48 \\right]$. A lower SMAPE, MASE or OWA indicates a better prediction. $\\ast.$ in the Transformers indicates the name of $\\ast$former. \\emph{Stationary} means the Non-stationary Transformer.}\\label{tab:M4_results}\n  \\centering\n  \\vspace{3pt}\n  \\resizebox{\\columnwidth}{!}{\n  \\begin{threeparttable}\n  \\begin{small}\n  \\renewcommand{\\multirowsetup}{\\centering}\n  \\setlength{\\tabcolsep}{0.7pt}\n  \\begin{tabular}{cc|c|cccccccccccccccccccc}\n    \\toprule\n    \\multicolumn{3}{c}{\\multirow{2}{*}{Models}} & \n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{\\textbf{TimeMixer}}}}& \n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{TimesNet}}} &\n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{{N-HiTS}}}} &\n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{{N-BEATS$^\\ast$}}}} &\n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{SCINet}}} &\n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{PatchTST}}} &\n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{MICN}}} &\n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{FiLM}}} &\n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{LightTS}}} &\n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{DLinear}}} &\n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{FED.}}} & \n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{Stationary}}} & \n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{Auto.}}} & \n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{Pyra.}}} &  \n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{In.}}} & \n    \\\\\n    \\multicolumn{1}{c}{}&\\multicolumn{1}{c}{} &\\multicolumn{1}{c}{} & \n    \\multicolumn{1}{c}{\\scalebox{0.95}{(\\textbf{Ours})}} &\n    \\multicolumn{1}{c}{\\scalebox{0.95}{\\citeyearpar{wu2022timesnet}}} &\n    \\multicolumn{1}{c}{\\scalebox{0.95}{\\citeyearpar{challu2022nhits}}} &\n    \\multicolumn{1}{c}{\\scalebox{0.95}{\\citeyearpar{oreshkin2019nbeats}}} &\n    \\multicolumn{1}{c}{\\scalebox{0.95}{\\citeyearpar{liu2022scinet}}} &\n    \\multicolumn{1}{c}{\\scalebox{0.95}{\\citeyearpar{patchtst}}} &\n    \\multicolumn{1}{c}{\\scalebox{0.95}{\\citeyearpar{wang2023micn}}} &\n    \\multicolumn{1}{c}{\\scalebox{0.95}{\\citeyearpar{zhou2022film}}} &\n    \\multicolumn{1}{c}{\\scalebox{0.95}{\\citeyearpar{lightts}}} &\n    \\multicolumn{1}{c}{\\scalebox{0.95}{\\citeyearpar{dlinear}}} &\n    \\multicolumn{1}{c}{\\scalebox{0.95}{\\citeyearpar{zhou2022fedformer}}} &\n    \\multicolumn{1}{c}{\\scalebox{0.95}{\\citeyearpar{Liu2022NonstationaryTR}}} &\n    \\multicolumn{1}{c}{\\scalebox{0.95}{\\citeyearpar{wu2021autoformer}}} &\n    \\multicolumn{1}{c}{\\scalebox{0.95}{\\citeyearpar{liu2021pyraformer}}} &\n    \\multicolumn{1}{c}{\\scalebox{0.95}{\\citeyearpar{haoyietal-informer-2021}}}\n    \\\\\n    \\toprule\n    \\multicolumn{2}{c}{\\multirow{3}{*}{\\rotatebox{90}{\\scalebox{1.0}{Yearly}}}}\n    & \\scalebox{1.0}{SMAPE} &\\boldres{\\scalebox{1.0}{13.206}} &\\secondres{\\scalebox{1.0}{13.387}} &{\\scalebox{1.0}{13.418}} &\\scalebox{1.0}{13.436} &\\scalebox{1.0}{18.605} &\\scalebox{1.0}{16.463} &\\scalebox{1.0}{25.022} &\\scalebox{1.0}{17.431} &\\scalebox{1.0}{14.247} &\\scalebox{1.0}{16.965} &\\scalebox{1.0}{13.728} &\\scalebox{1.0}{13.717} &\\scalebox{1.0}{13.974} &\\scalebox{1.0}{15.530} &\\scalebox{1.0}{14.727} \n    \\\\\n    & & \\scalebox{1.0}{MASE} &\\boldres{\\scalebox{1.0}{2.916}} &\\secondres{\\scalebox{1.0}{2.996}} &\\scalebox{1.0}{3.045} &{\\scalebox{1.0}{3.043}}  &\\scalebox{1.0}{4.471} &\\scalebox{1.0}{3.967} &\\scalebox{1.0}{7.162} &\\scalebox{1.0}{4.043} &\\scalebox{1.0}{3.109} &\\scalebox{1.0}{4.283} &\\scalebox{1.0}{3.048} &\\scalebox{1.0}{3.078} &\\scalebox{1.0}{3.134} &\\scalebox{1.0}{3.711} &\\scalebox{1.0}{3.418} \n    \\\\\n    & & \\scalebox{1.0}{OWA}  &\\boldres{\\scalebox{1.0}{0.776}} &\\secondres{\\scalebox{1.0}{0.786}} &\\scalebox{1.0}{0.793} &\\scalebox{1.0}{0.794} & \\scalebox{1.0}{1.132} & \\scalebox{1.0}{1.003} & \\scalebox{1.0}{1.667} & \\scalebox{1.0}{1.042} &\\scalebox{1.0}{0.827} &\\scalebox{1.0}{1.058} &\\scalebox{1.0}{0.803} &\\scalebox{1.0}{0.807} &\\scalebox{1.0}{0.822} &\\scalebox{1.0}{0.942} &\\scalebox{1.0}{0.881} \n    \\\\\n    \\midrule\n    \\multicolumn{2}{c}{\\multirow{3}{*}{\\rotatebox{90}{\\scalebox{0.9}{Quarterly}}}}\n    & \\scalebox{1.0}{SMAPE} &\\boldres{\\scalebox{1.0}{9.996}} &\\secondres{\\scalebox{1.0}{10.100}} &\\scalebox{1.0}{10.202} &{\\scalebox{1.0}{10.124}} &\\scalebox{1.0}{14.871} &\\scalebox{1.0}{10.644} &\\scalebox{1.0}{15.214} &\\scalebox{1.0}{12.925} &\\scalebox{1.0}{11.364} &\\scalebox{1.0}{12.145} &\\scalebox{1.0}{10.792} &\\scalebox{1.0}{10.958} &\\scalebox{1.0}{11.338} &\\scalebox{1.0}{15.449} &\\scalebox{1.0}{11.360}\n    \\\\\n    & & \\scalebox{1.0}{MASE} &\\boldres{\\scalebox{1.0}{1.166}} &{\\scalebox{1.0}{1.182}} &\\scalebox{1.0}{1.194} &\\secondres{\\scalebox{1.0}{1.169}} &\\scalebox{1.0}{2.054} &\\scalebox{1.0}{1.278} &\\scalebox{1.0}{1.963} &\\scalebox{1.0}{1.664} &\\scalebox{1.0}{1.328} &\\scalebox{1.0}{1.520} &\\scalebox{1.0}{1.283} &\\scalebox{1.0}{1.325} &\\scalebox{1.0}{1.365} &\\scalebox{1.0}{2.350} &\\scalebox{1.0}{1.401}\n    \\\\\n    & & \\scalebox{1.0}{OWA} &\\boldres{\\scalebox{1.0}{0.825}} &{\\scalebox{1.0}{0.890}} &\\scalebox{1.0}{0.899} &\\secondres{\\scalebox{1.0}{0.886}} &\\scalebox{1.0}{1.424} &\\scalebox{1.0}{0.949} &\\scalebox{1.0}{1.407} &\\scalebox{1.0}{1.193} &\\scalebox{1.0}{1.000} &\\scalebox{1.0}{1.106} &\\scalebox{1.0}{0.958} &\\scalebox{1.0}{0.981} &\\scalebox{1.0}{1.012} &\\scalebox{1.0}{1.558} &\\scalebox{1.0}{1.027}\n    \\\\\n    \\midrule\n    \\multicolumn{2}{c}{\\multirow{3}{*}{\\rotatebox{90}{\\scalebox{1.0}{Monthly}}}}\n    & \\scalebox{1.0}{SMAPE} &\\boldres{\\scalebox{1.0}{12.605}} &\\secondres{\\scalebox{1.0}{12.670}} &\\scalebox{1.0}{12.791} &{\\scalebox{1.0}{12.677}} &\\scalebox{1.0}{14.925} &\\scalebox{1.0}{13.399} &\\scalebox{1.0}{16.943} &\\scalebox{1.0}{15.407} &\\scalebox{1.0}{14.014} &\\scalebox{1.0}{13.514} &\\scalebox{1.0}{14.260} &\\scalebox{1.0}{13.917} &\\scalebox{1.0}{13.958} &\\scalebox{1.0}{17.642} &\\scalebox{1.0}{14.062}\n    \\\\\n    & & \\scalebox{1.0}{MASE} &\\boldres{\\scalebox{1.0}{0.919}} &\\secondres{\\scalebox{1.0}{0.933}} &\\scalebox{1.0}{0.969} &{\\scalebox{1.0}{0.937}} &\\scalebox{1.0}{1.131} &\\scalebox{1.0}{1.031} &\\scalebox{1.0}{1.442} &\\scalebox{1.0}{1.298} &\\scalebox{1.0}{1.053} &\\scalebox{1.0}{1.037} &\\scalebox{1.0}{1.102} &\\scalebox{1.0}{1.097} &\\scalebox{1.0}{1.103} &\\scalebox{1.0}{1.913} &\\scalebox{1.0}{1.141} \n    \\\\\n    & & \\scalebox{1.0}{OWA}  &\\boldres{\\scalebox{1.0}{0.869}} &\\secondres{\\scalebox{1.0}{0.878}} &\\scalebox{1.0}{0.899} &{\\scalebox{1.0}{0.880}} &\\scalebox{1.0}{1.027} &\\scalebox{1.0}{0.949} &\\scalebox{1.0}{1.265} &\\scalebox{1.0}{1.144}  &\\scalebox{1.0}{0.981} &\\scalebox{1.0}{0.956} &\\scalebox{1.0}{1.012} &\\scalebox{1.0}{0.998} &\\scalebox{1.0}{1.002} &\\scalebox{1.0}{1.511} &\\scalebox{1.0}{1.024}\n    \\\\\n    \\midrule\n    \\multicolumn{2}{c}{\\multirow{3}{*}{\\rotatebox{90}{\\scalebox{1.0}{Others}}}}\n    & \\scalebox{1.0}{SMAPE} &\\boldres{\\scalebox{1.0}{4.564}} &\\secondres{\\scalebox{1.0}{4.891}} &\\scalebox{1.0}{5.061} &{\\scalebox{1.0}{4.925}}  &\\scalebox{1.0}{16.655} &\\scalebox{1.0}{6.558} &\\scalebox{1.0}{41.985} &\\scalebox{1.0}{7.134} &\\scalebox{1.0}{15.880} &\\scalebox{1.0}{6.709} &\\scalebox{1.0}{4.954} &\\scalebox{1.0}{6.302} &\\scalebox{1.0}{5.485} &\\scalebox{1.0}{24.786} &\\scalebox{1.0}{24.460}\n    \\\\\n    & & \\scalebox{1.0}{MASE} &\\boldres{\\scalebox{1.0}{3.115}} &{\\scalebox{1.0}{3.302}} &\\secondres{\\scalebox{1.0}{3.216}} &\\scalebox{1.0}{3.391}  &\\scalebox{1.0}{15.034} &\\scalebox{1.0}{4.511} &\\scalebox{1.0}{62.734} &\\scalebox{1.0}{5.09} &\\scalebox{1.0}{11.434} &\\scalebox{1.0}{4.953} &\\scalebox{1.0}{3.264} &\\scalebox{1.0}{4.064} &\\scalebox{1.0}{3.865} &\\scalebox{1.0}{18.581} &\\scalebox{1.0}{20.960}\n    \\\\\n    & & \\scalebox{1.0}{OWA} &\\boldres{\\scalebox{1.0}{0.982}} &\\secondres{\\scalebox{1.0}{1.035}} &{\\scalebox{1.0}{1.040}} &\\scalebox{1.0}{1.053}  &\\scalebox{1.0}{4.123} &\\scalebox{1.0}{1.401} &\\scalebox{1.0}{14.313}  &\\scalebox{1.0}{1.553} &\\scalebox{1.0}{3.474} &\\scalebox{1.0}{1.487} &\\scalebox{1.0}{1.036} &\\scalebox{1.0}{1.304} &\\scalebox{1.0}{1.187} &\\scalebox{1.0}{5.538} &\\scalebox{1.0}{5.879} \n    \\\\\n    \\midrule\n    \\multirow{3}{*}{\\rotatebox{90}{\\scalebox{0.9}{Weighted}}}& \n    \\multirow{3}{*}{\\rotatebox{90}{\\scalebox{0.9}{Average}}} \n    &\\scalebox{1.0}{SMAPE} &\\boldres{\\scalebox{1.0}{11.723}} &\\secondres{\\scalebox{1.0}{11.829}} &\\scalebox{1.0}{11.927} &{\\scalebox{1.0}{11.851}} &\\scalebox{1.0}{15.542} &\\scalebox{1.0}{13.152} &\\scalebox{1.0}{19.638} &\\scalebox{1.0}{14.863} &\\scalebox{1.0}{13.525} &\\scalebox{1.0}{13.639} &\\scalebox{1.0}{12.840} &\\scalebox{1.0}{12.780} &\\scalebox{1.0}{12.909} &\\scalebox{1.0}{16.987} &\\scalebox{1.0}{14.086}\n    \\\\\n    & &  \\scalebox{1.0}{MASE} &\\boldres{\\scalebox{1.0}{1.559}} &\\secondres{\\scalebox{1.0}{1.585}} &\\scalebox{1.0}{1.613} &{\\scalebox{1.0}{1.559}} &\\scalebox{1.0}{2.816} &\\scalebox{1.0}{1.945}  &\\scalebox{1.0}{5.947} &\\scalebox{1.0}{2.207} &\\scalebox{1.0}{2.111} &\\scalebox{1.0}{2.095} &\\scalebox{1.0}{1.701} &\\scalebox{1.0}{1.756} &\\scalebox{1.0}{1.771} &\\scalebox{1.0}{3.265} &\\scalebox{1.0}{2.718} \n    \\\\\n    & & \\scalebox{1.0}{OWA}   &\\boldres{\\scalebox{1.0}{0.840}} &\\secondres{\\scalebox{1.0}{0.851}} &\\scalebox{1.0}{0.861} &{\\scalebox{1.0}{0.855}} &\\scalebox{1.0}{1.309} &\\scalebox{1.0}{0.998} &\\scalebox{1.0}{2.279} &\\scalebox{1.0}{1.125}  &\\scalebox{1.0}{1.051} &\\scalebox{1.0}{1.051} &\\scalebox{1.0}{0.918} &\\scalebox{1.0}{0.930} &\\scalebox{1.0}{0.939} &\\scalebox{1.0}{1.480} &\\scalebox{1.0}{1.230}\n    \\\\\n    \\bottomrule\n  \\end{tabular}\n      \\begin{tablenotes}\n        \\footnotesize\n        \\item \\large{$\\ast$ The original paper of N-BEATS \\citeyearpar{oreshkin2019nbeats} adopts a special ensemble method to promote the performance. For fair comparisons, we remove the ensemble and only compare the pure forecasting models.}\n  \\end{tablenotes}\n    \\end{small}\n  \\end{threeparttable}\n  }\n  \\vspace{-15pt}\n\\end{table}",
            "tab:ablation_main_text": "\\begin{table}[t]\n\t\\caption{Ablations on both PDM (\\textit{Decompose}, \\textit{Season Mixing}, \\textit{Trend Mixing}) and FMM blocks in M4, PEMS04 and predict-336 setting of ETTm1. \\ $\\nearrow$ indicates the bottom-up mixing while $\\swarrow$ indicates top-down. A check mark $\\checkmark$ and a wrong mark $\\times$ indicate with and without certain components respectively. \\ding{172} is the official design in TimeMixer \\revise{(See Appendix \\ref{appendix:ablations} for complete ablation results)}.}\n \\label{tab:ablation_main_text}\n  \\centering\n  \\vspace{3pt}\n  \\resizebox{\\columnwidth}{!}{\n  \\begin{small}\n  \\renewcommand{\\multirowsetup}{\\centering}\n  \\setlength{\\tabcolsep}{3.5pt}\n\t\t\\begin{tabular}{c|c|cc|c|ccc|ccc|cc}\n\t\t\\toprule\n\t\t\\multirow{2}{*}{\\scalebox{0.95}{Case}} &\\multirow{2}{*}{\\scalebox{0.95}{Decompose}} & \\multicolumn{2}{c|}{\\scalebox{0.95}{Past mixing}} & \\scalebox{0.95}{Future mixing} & \\multicolumn{3}{c|}{\\scalebox{0.95}{M4}} &\\multicolumn{3}{c}{\\scalebox{0.95}{\\revise{PEMS04}}} &\\multicolumn{2}{c}{\\scalebox{0.95}{ETTm1}} \\\\\n            \\cmidrule(lr){3-4} \\cmidrule(lr){5-5} \\cmidrule(lr){6-8} \\cmidrule(lr){9-11} \\cmidrule(lr){12-13}\n            & & \\scalebox{0.95}{Seasonal} & \\scalebox{0.95}{Trend} & \\scalebox{0.95}{Multipredictor} & \\scalebox{0.95}{SMAPE} & \\scalebox{0.95}{MASE} & \\scalebox{0.95}{OWA} & \\scalebox{0.95}{\\revise{MAE}} & \\scalebox{0.95}{\\revise{MAPE}} & \\scalebox{0.95}{\\revise{RMSE}} & \\scalebox{0.95}{MSE} & \\scalebox{0.95}{MAE} \\\\\n            \\midrule\n            \\ding{172} &$\\checkmark$ & $\\nearrow$ & $\\swarrow$ & $\\checkmark$ & \\boldres{11.723} &\\boldres{1.559} &\\boldres{0.840} &\\boldres{19.21} &\\boldres{12.53} &\\boldres{30.92} &\\boldres{0.390} &\\boldres{0.404} \\\\\n            \\midrule\n            \\ding{173} & $\\checkmark$ & $\\nearrow$ & $\\swarrow$ & $\\times$ &12.503 &1.634 &0.925 &21.67 &13.45 &34.89  &0.402 &0.415 \\\\\n            \\midrule\n            \\ding{174} & $\\checkmark$ &$\\times$ & $\\swarrow$ & $\\checkmark$ &13.051 &1.676 &0.962 &24.49 &16.28 &38.79  &0.411 &0.427 \\\\\n            \\midrule\n            \\ding{175} &$\\checkmark$ &$\\nearrow$ & $\\times$ & $\\checkmark$ &12.911 &1.655 &0.941 &22.91 &15.02 &37.04  &0.405 &0.414 \\\\\n            \\midrule\n            \\ding{176} &$\\checkmark$ &$\\swarrow$ & $\\swarrow$ & $\\checkmark$ &12.008 &1.628 &0.871 &20.78 &13.02 &32.47  &0.392 &0.413 \\\\\n            \\midrule\n            \\ding{177} &$\\checkmark$ &$\\nearrow$ & $\\nearrow$ & $\\checkmark$ &11.978 &1.626 &0.859 &21.09 &13.78 &33.11  &0.396 &0.415 \\\\\n            \\midrule\n            \\revise{\\ding{178}} &\\revise{$\\checkmark$} &\\revise{$\\swarrow$} &\\revise{$\\nearrow$} & \\revise{$\\checkmark$} &\\revise{13.012} &\\revise{1.657} &\\revise{0.954} &\\revise{22.27} &\\revise{15.14} &\\revise{34.67}  &\\revise{0.412} &\\revise{0.429} \\\\\n            \\midrule\n            \\ding{179} &$\\times$ &\\multicolumn{2}{c|}{$\\nearrow$} & $\\checkmark$ &11.975 &1.617 &0.851 &21.51 &13.47 &34.81  &0.395 &0.408 \\\\\n            \\midrule\n            \\ding{180} &$\\times$ &\\multicolumn{2}{c|}{$\\swarrow$}  & $\\checkmark$ &11.973 &1.622 &0.850 &21.79 &14.03 &35.23  &0.393 &0.406 \\\\\n            \\midrule\n            \\ding{181} &$\\times$ &\\multicolumn{2}{c|}{$\\times$}  & $\\checkmark$ &12.468 &1.671 &0.916 &24.87 &16.66 &39.48  &0.405 &0.412 \\\\\n\t\t\\bottomrule\n\t\t\\end{tabular}\n\t\\end{small}\n }\n\t\\vspace{-15pt}\n\\end{table}",
            "tab:dataset": "\\begin{table}[thbp]\n  \\vspace{-10pt}\n  \\caption{Dataset detailed descriptions. The dataset size is organized in (Train, Validation, Test).}\\label{tab:dataset}\n  \\vskip 0.05in\n  \\centering\n   \\resizebox{1.0\\columnwidth}{!}{\n  \\begin{threeparttable}\n  \\begin{small}\n  \\renewcommand{\\multirowsetup}{\\centering}\n  \\setlength{\\tabcolsep}{3.8pt}\n  \\begin{tabular}{c|l|c|c|c|c|c|c}\n    \\toprule\n    Tasks & Dataset & Dim & Series Length & Dataset Size &Frequency &Forecastability$\\ast$ &\\scalebox{0.8}{Information} \\\\\n    \\toprule\n     & ETTm1 & 7 & \\scalebox{0.8}{\\{96, 192, 336, 720\\}} & (34465, 11521, 11521)  & 15min &0.46 &\\scalebox{0.8}{Temperature}\\\\\n    \\cmidrule{2-8}\n    & ETTm2 & 7 & \\scalebox{0.8}{\\{96, 192, 336, 720\\}} & (34465, 11521, 11521)  & 15min &0.55 &\\scalebox{0.8}{Temperature}\\\\\n    \\cmidrule{2-8}\n     & ETTh1 & 7 & \\scalebox{0.8}{\\{96, 192, 336, 720\\}} & (8545, 2881, 2881) & 15 min &0.38 &\\scalebox{0.8}{Temperature} \\\\\n    \\cmidrule{2-8}\n     &ETTh2 & 7 & \\scalebox{0.8}{\\{96, 192, 336, 720\\}} & (8545, 2881, 2881) & 15 min &0.45 &\\scalebox{0.8}{Temperature} \\\\\n    \\cmidrule{2-8}\n    Long-term & Electricity & 321 & \\scalebox{0.8}{\\{96, 192, 336, 720\\}} & (18317, 2633, 5261) & Hourly &0.77 & \\scalebox{0.8}{Electricity} \\\\\n    \\cmidrule{2-8}\n    Forecasting & Traffic & 862 & \\scalebox{0.8}{\\{96, 192, 336, 720\\}} & (12185, 1757, 3509) & Hourly &0.68 & \\scalebox{0.8}{Transportation} \\\\\n    \\cmidrule{2-8}\n     & Weather & 21 & \\scalebox{0.8}{\\{96, 192, 336, 720\\}} & (36792, 5271, 10540)  &10 min &0.75  &\\scalebox{0.8}{Weather} \\\\\n    \\cmidrule{2-8}\n    & Solar-Energy & 137  & \\scalebox{0.8}{\\{96, 192, 336, 720\\}}  & (36601, 5161, 10417)& 10min &0.33 & \\scalebox{0.8}{Electricity} \\\\\n    \\midrule\n    & PEMS03 & 358 & 12 & (15617,5135,5135) & 5min &0.65 & \\scalebox{0.8}{Transportation}\\\\\n    \\cmidrule{2-8}\n    & PEMS04 & 307 & 12 & (10172,3375,3375) & 5min &0.45 & \\scalebox{0.8}{Transportation}\\\\\n    \\cmidrule{2-8}\n    & PEMS07 & 883 & 12 & (16911,5622,5622) & 5min &0.58 & \\scalebox{0.8}{Transportation}\\\\\n    \\cmidrule{2-8}\n    Short-term & PEMS08 & 170 & 12 & (10690,3548,265) & 5min &0.52 & \\scalebox{0.8}{Transportation}\\\\\n    \\cmidrule{2-8}\n    Forecasting & M4-Yearly & 1 & 6 & (23000, 0, 23000) &Yearly &0.43 &\\scalebox{0.8}{Demographic} \\\\\n    \\cmidrule{2-8}\n     & M4-Quarterly & 1 & 8 & (24000, 0, 24000) &Quarterly &0.47 & \\scalebox{0.8}{Finance} \\\\\n    \\cmidrule{2-8}\n    & M4-Monthly & 1 & 18 & (48000, 0, 48000) & Monthly &0.44 & \\scalebox{0.8}{Industry} \\\\\n    \\cmidrule{2-8}\n    & M4-Weakly & 1 & 13 & (359, 0, 359) & Weakly &0.43 & \\scalebox{0.8}{Macro} \\\\\n    \\cmidrule{2-8}\n     & M4-Daily & 1 & 14 & (4227, 0, 4227) &Daily &0.44 & \\scalebox{0.8}{Micro} \\\\\n    \\cmidrule{2-8}\n     & M4-Hourly & 1 &48 & (414, 0, 414) & Hourly &0.46 & \\scalebox{0.8}{Other} \\\\\n    \\bottomrule\n    \\end{tabular}\n     \\begin{tablenotes}\n        \\item $\\ast$ The forecastability is calculated by one minus the entropy of Fourier decomposition of time series \\citep{goerg2013forecastable}. A larger value indicates better predictability.\n    \\end{tablenotes}\n    \\end{small}\n  \\end{threeparttable}\n  }\n  \\vspace{-5pt}\n\\end{table}",
            "tab:model_config": "\\begin{table}[t]\n  \\vspace{-10pt}\n  \\caption{Experiment configuration of TimeMixer. All the experiments use the ADAM \\citeyearpar{DBLP:journals/corr/KingmaB14adam} optimizer with the default hyperparameter configuration for $(\\beta_1, \\beta_2)$ as (0.9, 0.999).  }\\label{tab:model_config}\n  \\vskip 0.05in\n  \\centering\n  \\begin{threeparttable}\n  \\begin{small}\n  \\renewcommand{\\multirowsetup}{\\centering}\n  \\setlength{\\tabcolsep}{4.3pt}\n  \\begin{tabular}{c|c|c|c|c|c|c|c}\n    \\toprule\n    \\multirow{2}{*}{Dataset / Configurations} & \\multicolumn{3}{c}{Model Hyper-parameter} & \\multicolumn{4}{c}{Training Process} \\\\\n    \\cmidrule(lr){2-4} \\cmidrule(lr){5-8}\n    & $M$ (Equ. \\ref{equ:equ1}) & Layers & $d_{\\text{model}}$  & LR$^\\ast$ & Loss & Batch Size & Epochs\\\\\n    \\toprule\n    ETTh1 & 3 & 2 & 16  & $10^{-2}$ & MSE & 128 & 10 \\\\\n    \\midrule\n    ETTh2 & 3 & 2 & 16  & $10^{-2}$ & MSE & 128 & 10 \\\\\n    \\midrule\n    ETTm1 & 3 & 2 & 16  & $10^{-2}$ & MSE & 128 & 10 \\\\\n    \\midrule\n    ETTm2 & 3 & 2 & 32  & $10^{-2}$ & MSE & 128 & 10 \\\\\n    \\midrule\n    Weather & 3 & 2 & 16  & $10^{-2}$ & MSE & 128 & 20 \\\\\n    \\midrule\n    Electricity & 3 & 2 & 16  & $10^{-2}$ & MSE & 32 & 20 \\\\\n    \\midrule\n    Solar-Energy & 3 & 2 & 128  & $10^{-2}$ & MSE & 32 & 20 \\\\\n    \\midrule\n    Traffic & 3 & 2 &32  & $10^{-2}$ & MSE & 8 & 20 \\\\\n    \\midrule\n    PEMS & 1 & 5 & 128 & $10^{-3}$ & MSE & 32 & 10 \\\\\n    \\midrule\n    M4 & 1 & 4 & 32  & $10^{-2}$ & SMAPE & 128 & 50 \\\\\n    \\bottomrule\n    \\end{tabular}\n    \\begin{tablenotes}\n        \\footnotesize\n        \\item[] $\\ast$ LR means the initial learning rate.\n  \\end{tablenotes}\n    \\end{small}\n  \\end{threeparttable}\n  \\vspace{-15pt}\n\\end{table}",
            "tab:cost": "\\begin{table}[htbp]\n  \\caption{The GPU memory (MiB) and speed (running time, s/iter) of each model.}\\label{tab:cost}\n  \\vspace{3pt}\n  \\centering\n     \\resizebox{1.0\\columnwidth}{!}{\n  \\begin{threeparttable}\n  \\begin{small}\n  \\renewcommand{\\multirowsetup}{\\centering}\n  \\setlength{\\tabcolsep}{6pt}\n  \\begin{tabular}{ll|cccccccccc}\n    \\toprule\n     \\multicolumn{2}{l|}{Series Length} &\\multicolumn{2}{c|}{192} &\\multicolumn{2}{c|}{384}  &\\multicolumn{2}{c|}{768}\t&\\multicolumn{2}{c|}{1536} &\\multicolumn{2}{c}{3072} \\\\\n     \\cmidrule(lr){3-4} \\cmidrule(lr){5-5} \\cmidrule(lr){6-8} \\cmidrule(lr){9-10} \\cmidrule(lr){11-12}\n     \\multicolumn{2}{l|}{Models}  & Mem & \\multicolumn{1}{c|}{Speed}  & Mem & \\multicolumn{1}{c|}{Speed}  & Mem & \\multicolumn{1}{c|}{Speed}  & Mem & \\multicolumn{1}{c|}{Speed}  & Mem & Speed  \\\\\n    \\toprule\n    \\multicolumn{2}{l|}{TimeMixer (\\textbf{Ours})}  & 1003 &0.007 &1043 &0.007 & 1075 &0.008 & 1151 &0.009 & 1411 &0.016\\\\\n    \\midrule\n    \\multicolumn{2}{l|}{PatchTST \\citeyearpar{patchtst}} & 1919 &0.018 & 2097 &0.019 & 2749 &0.021 & 5465 &0.032 & 16119 &0.094 \\\\\n    \\midrule\n    \\multicolumn{2}{l|}{TimesNet \\citeyearpar{wu2022timesnet}}  & 1148 &0.028 & 1245 &0.024 & 1585 &0.042 & 2491 &0.045& 2353 &0.073\\\\ \n    \\midrule\n    \\multicolumn{2}{l|}{Crossformer \\citeyearpar{zhang2023crossformer}}  & 1737 &0.027 & 1799 &0.027 & 1895 &0.028 & 2303 &0.033 & 3759 &0.035\\\\\n    \\midrule\n    \\multicolumn{2}{l|}{MICN \\citeyearpar{wang2023micn}}  & 1771 &0.014 & 1801 &0.016 & 1873 &0.017 & 1991 &0.018 & 2239 &0.020 \\\\\n    \\midrule\n    \\multicolumn{2}{l|}{DLinear \\citeyearpar{dlinear}}  & 1001 &0.002 & 1021 & 0.003 & 1041 &0.003 & 1081 &0.0.004 & 1239 &0.015\\\\\n    \\midrule\n    \\multicolumn{2}{l|}{FEDFormer \\citeyearpar{zhou2022fedformer}}  & 2567 &0.132 & 5977 & 0.141 & 7111 &0.143 & 9173 &0.178 & 12485 &0.288\\\\\n    \\midrule\n    \\multicolumn{2}{l|}{Autoformer \\citeyearpar{wu2021autoformer}}  & 1761 &0.028 & 2101 &0.070 & 3209 &0.071 & 5395 &0.129 & 10043 &0.255\\\\\n    \\bottomrule\n  \\end{tabular}\n    \\end{small}\n  \\end{threeparttable}\n  }\n\\end{table}",
            "tab:errorbar_long": "\\begin{table}[h]\n  \\caption{Standard deviation and statistical tests for our TimeMixer method and second-best method (PatchTST) on ETT, Weather, Solar-Energy, Electricity and Traffic datasets. }\\label{tab:errorbar_long}\n  \\vskip 0.05in\n  \\centering\n  \\begin{threeparttable}\n  \\begin{small}\n  \\renewcommand{\\multirowsetup}{\\centering}\n  \\setlength{\\tabcolsep}{5pt}\n  \\begin{tabular}{l|cc|cc|c}\n    \\toprule\n    Model & \\multicolumn{2}{c|}{TimeMixer} & \\multicolumn{2}{c|}{PatchTST \\citeyearpar{patchtst}} & Confidence \\\\\n    \\cmidrule(lr){0-1}\\cmidrule(lr){2-3}\\cmidrule(lr){4-5}\n    Dataset & MSE & MAE & MSE & MAE& Interval\\\\\n    \\midrule\n    Weather & $0.240 \\pm 0.010$ & $0.271 \\pm 0.009$\t& $0.265 \\pm 0.012$ & $0.285 \\pm 0.011$ & 99\\%\\\\\n    Solar-Energy & $0.216 \\pm 0.002$ & $0.280 \\pm 0.022$ &$0.287 \\pm 0.020$ & $0.333 \\pm 0.018$ & 99\\%\\\\\n    Electricity & $0.182 \\pm 0.017$ & $0.272 \\pm 0.006$\t& $0.216 \\pm 0.012$ & $0.318 \\pm 0.015$ & 99\\%\\\\\n    Traffic &$0.484 \\pm 0.015$  & $0.297 \\pm 0.013$ &$0.529 \\pm 0.008$  &$0.341 \\pm 0.002$  & 99\\%\\\\\n    ETTh1 & $0.447 \\pm 0.002$ & $0.440 \\pm 0.005$ &$0.516 \\pm 0.003$ &$0.484 \\pm 0.005$  & 99\\%\\\\\n    ETTh2 & $0.364 \\pm 0.008$ & $0.395 \\pm 0.010$ & $0.391 \\pm 0.005$ & $0.411 \\pm 0.003$  & 99\\%\\\\\n    ETTm1 & $0.381 \\pm 0.003$ & $0.395 \\pm 0.006$ &$0.400 \\pm 0.002$ & $0.407 \\pm 0.005$ & 99\\%\\\\\n    ETTm2 & $0.275 \\pm 0.001$ & $0.323 \\pm 0.003$ &$0.290 \\pm 0.002$ & $0.334 \\pm 0.002$ & 99\\%\\\\\n    \\bottomrule\n  \\end{tabular}\n    \\end{small}\n  \\end{threeparttable}\n  % \\vspace{-10pt}\n\\end{table}",
            "tab:errorbar_pems": "\\begin{table}[ht]\n  \\caption{Standard deviation and statistical tests for our TimeMixer method and second-best method (SCINet) on PEMS dataset.}\\label{tab:errorbar_pems}\n  \\vskip 0.05in\n  \\centering\n  \\begin{threeparttable}\n  \\begin{small}\n  \\renewcommand{\\multirowsetup}{\\centering}\n  \\setlength{\\tabcolsep}{2pt}\n  \\begin{tabular}{l|ccc|ccc|c}\n    \\toprule\n    Model & \\multicolumn{3}{c|}{TimeMixer} & \\multicolumn{3}{c|}{SCINet \\citeyearpar{liu2022scinet}}& Confidence\\\\\n    \\cmidrule(lr){0-1}\\cmidrule(lr){2-4}\\cmidrule(lr){5-7}\n    Dataset & MAE & MAPE & RMSE & MAE & MAPE & RMSE& Interval\\\\\n    \\midrule\n    PEMS03 & \\scalebox{0.9}{$14.63 \\pm 0.112$} & \\scalebox{0.9}{$14.54 \\pm 0.105$} & \\scalebox{0.9}{$23.28 \\pm 0.128$} & \\scalebox{0.9}{$15.97 \\pm 0.153$} & \\scalebox{0.9}{$15.89 \\pm 0.122$} &\\scalebox{0.9}{$25.20 \\pm 0.137$}  & 99\\%\\\\\n    PEMS04 & \\scalebox{0.9}{$19.21 \\pm 0.217$} & \\scalebox{0.9}{$12.53 \\pm 0.154$} & \\scalebox{0.9}{$30.92 \\pm 0.143$} &\t\\scalebox{0.9}{$20.35 \\pm 0.201$} & \\scalebox{0.9}{$12.84 \\pm 0.213$} & \\scalebox{0.9}{$32.31 \\pm 0.178$}& 95\\%\\\\\n    PEMS07 & \\scalebox{0.9}{$20.57 \\pm 0.158$} & \\scalebox{0.9}{$8.62 \\pm 0.112$} & \\scalebox{0.9}{$33.59 \\pm 0.273$}\t& \\scalebox{0.9}{$22.79 \\pm 0.179$} & \\scalebox{0.9}{$9.41 \\pm 0.105$} & \\scalebox{0.9}{$35.61 \\pm 0.112$}& 99\\% \\\\\n    PEMS08 & \\scalebox{0.9}{$15.22 \\pm 0.311$} & \\scalebox{0.9}{$9.67 \\pm 0.101$} &\\scalebox{0.9}{$24.26 \\pm 0.212$}  & \\scalebox{0.9}{$17.38 \\pm 0.332$} &\\scalebox{0.9}{$10.80 \\pm 0.219$}  &\\scalebox{0.9}{$27.34 \\pm 0.178$} & 99\\%\\\\\n    \\bottomrule\n  \\end{tabular}\n    \\end{small}\n  \\end{threeparttable}\n  % \\vspace{-10pt}\n\\end{table}",
            "tab:errorbar_m4": "\\begin{table}[htbp]\n\\vspace{-10pt}\n  \\caption{Standard deviation and statistical tests for our TimeMixer method and second-best method (TimesNet) on M4 dataset.}\\label{tab:errorbar_m4}\n  \\vskip 0.05in\n  \\centering\n  \\begin{threeparttable}\n  \\begin{small}\n  \\renewcommand{\\multirowsetup}{\\centering}\n  \\setlength{\\tabcolsep}{2pt}\n  \\begin{tabular}{l|ccc|ccc|c}\n    \\toprule\n    Model & \\multicolumn{3}{c|}{TimeMixer} & \\multicolumn{3}{c|}{TimesNet \\citeyearpar{wu2022timesnet}} & Confidence\\\\\n    \\cmidrule(lr){0-1}\\cmidrule(lr){2-4}\\cmidrule(lr){5-7}\n    Dataset & SMAPE & MAPE & OWA & SMAPE & MAPE & OWA & Interval\\\\\n    \\midrule\n    Yearly & \\scalebox{0.9}{$13.206 \\pm 0.121$} &\\scalebox{0.9}{$2.916 \\pm 0.022$}  & \\scalebox{0.9}{$0.776 \\pm 0.002$} & \\scalebox{0.9}{$13.387 \\pm 0.112$}\t & \\scalebox{0.9}{$2.996 \\pm 0.017$} & \\scalebox{0.9}{$0.786 \\pm 0.010$}& 95\\%\\\\\n    Quarterly & \\scalebox{0.9}{$9.996 \\pm 0.101$} & \\scalebox{0.9}{$1.166 \\pm 0.015$} & \\scalebox{0.9}{$0.825 \\pm 0.008$} &\\scalebox{0.9}{$10.100 \\pm 0.105$}  & \\scalebox{0.9}{$1.182 \\pm 0.012$} &\\scalebox{0.9}{$0.890 \\pm 0.006$} & 95\\%\\\\\n    Monthly &\\scalebox{0.9}{$12.605 \\pm 0.115$}  &\\scalebox{0.9}{$0.919 \\pm 0.011$}  & \\scalebox{0.9}{$0.869 \\pm 0.003$} & \\scalebox{0.9}{$12.670 \\pm 0.106$}\t & \\scalebox{0.9}{$0.933 \\pm 0.008$} & \\scalebox{0.9}{$0.878 \\pm 0.001$}& 95\\%\\\\\n    Others & \\scalebox{0.9}{$4.564 \\pm 0.114$} & \\scalebox{0.9}{$3.115 \\pm 0.027$} & \\scalebox{0.9}{$0.982 \\pm 0.011$} &\\scalebox{0.9}{$4.891 \\pm 0.120$} & \\scalebox{0.9}{$3.302 \\pm 0.023$} & \\scalebox{0.9}{$1.035 \\pm 0.017$}& 99\\%\\\\\n    Averaged & \\scalebox{0.9}{$11.723 \\pm 0.011$} & \\scalebox{0.9}{$1.559 \\pm 0.022$} & \\scalebox{0.9}{$0.840 \\pm 0.001$} &\\scalebox{0.9}{$11.829 \\pm 0.120$}\t & \\scalebox{0.9}{$1.585 \\pm 0.017$} & \\scalebox{0.9}{$0.851 \\pm 0.003$} & 95\\%\\\\\n    \\bottomrule\n  \\end{tabular}\n    \\end{small}\n% \\vspace{-10pt}\n  \\end{threeparttable}\n\\end{table}",
            "tab:sensitivity": "\\begin{table}[h]\n  \\caption{The MSE results of different number of scales ($M$) and layers ($L$) on the ETTm1 dataset. }\\label{tab:sensitivity}\n  \\vskip 0.05in\n  \\centering\n  \\begin{threeparttable}\n  \\begin{small}\n  \\renewcommand{\\multirowsetup}{\\centering}\n  \\setlength{\\tabcolsep}{6pt}\n  \\begin{tabular}{c|cccc|c|cccc}\n    \\toprule\n    Predict Length & \\multirow{2}{*}{96} & \\multirow{2}{*}{192} & \\multirow{2}{*}{336}\t& \\multirow{2}{*}{720} &Predict Length & \\multirow{2}{*}{96} & \\multirow{2}{*}{192} & \\multirow{2}{*}{336} & \\multirow{2}{*}{720}\\\\\n    Num. of Scales & & & & &Num. of Layers\\\\\n    \\midrule\n    1 &0.326 &0.371 & 0.405 & 0.469 &1 &0.328 &0.369 & 0.405 & 0.467\\\\\n    2 & 0.323 & 0.365 & 0.401 & 0.460 &2 & 0.320 & 0.361 & 0.390 & 0.454\\\\\n    3 & 0.320 & 0.361 & 0.390 & 0.454 &3 & 0.321 & 0.360 & 0.389 & 0.451\\\\\n    4 & 0.321 & 0.360 & 0.388 & 0.454 &4 & 0.318 & 0.361 & 0.385 & 0.452\\\\\n    5 & 0.321 & 0.362 & 0.389 & 0.461 &5 & 0.322 & 0.359 & 0.390 & 0.457\\\\\n    \\bottomrule\n  \\end{tabular}\n    \\end{small}\n  \\end{threeparttable}\n  % \\vspace{-10pt}\n\\end{table}",
            "tab:full_forecasting_results": "\\begin{table}[htbp]\n  \\caption{Unified hyperparameter results for the long-term forecasting task. We compare extensive competitive models under different prediction lengths. \\emph{Avg} is averaged from all four prediction lengths, that is 96, 192, 336, 720.}\\label{tab:full_forecasting_results}\n  \\vskip 0.05in\n  \\centering\n  \\resizebox{1.0\\columnwidth}{!}{\n  \\begin{threeparttable}\n  \\begin{small}\n  \\renewcommand{\\multirowsetup}{\\centering}\n  \\setlength{\\tabcolsep}{1pt}\n  \\begin{tabular}{c|c|cc|cc|cc|cc|cc|cc|cc|cc|cc|cc|cc}\n    \\toprule\n    \\multicolumn{2}{c}{\\multirow{2}{*}{Models}} &\n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{0.8}{\\textbf{TimeMixer}}}} &\n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{0.8}{PatchTST}}} &\n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{0.8}{TimesNet}}} &\n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{0.8}{Crossformer}}} &\n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{0.8}{MICN}}} &\n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{0.8}{FiLM}}} & \n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{0.8}{DLinear}}} &\n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{0.8}{FEDformer}}} & \n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{0.8}{Stationary}}} & \n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{0.8}{Autoformer}}} &\n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{0.8}{Informer}}} \\\\\n    \\multicolumn{2}{c}{} & \\multicolumn{2}{c}{\\scalebox{0.8}{(\\textbf{Ours})}} &\n    \\multicolumn{2}{c}{\\scalebox{0.8}{\\citeyear{patchtst}}} &\n    \\multicolumn{2}{c}{\\scalebox{0.8}{\\citeyear{wu2022timesnet}}}&\n    \\multicolumn{2}{c}{\\scalebox{0.8}{\\citeyear{zhang2023crossformer}}}&\n    \\multicolumn{2}{c}{\\scalebox{0.8}{\\citeyear{wang2023micn}}}&\n    \\multicolumn{2}{c}{\\scalebox{0.8}{\\citeyear{zhou2022film}}}&\n    \\multicolumn{2}{c}{\\scalebox{0.8}{\\citeyear{dlinear}}}&\n    \\multicolumn{2}{c}{\\scalebox{0.8}{\\citeyear{zhou2022fedformer}}}&\n    \\multicolumn{2}{c}{\\scalebox{0.8}{\\citeyear{Liu2022NonstationaryTR}}}&\n    \\multicolumn{2}{c}{\\scalebox{0.8}{\\citeyear{wu2021autoformer}}}&\n    \\multicolumn{2}{c}{\\scalebox{0.8}{\\citeyear{haoyietal-informer-2021}}}\n    \\\\\n    \n    \\cmidrule(lr){3-4} \\cmidrule(lr){5-6}\\cmidrule(lr){7-8} \\cmidrule(lr){9-10}\\cmidrule(lr){11-12}\\cmidrule(lr){13-14}\\cmidrule(lr){15-16}\\cmidrule(lr){17-18}\\cmidrule(lr){19-20} \\cmidrule(lr){21-22} \\cmidrule(lr){23-24}\n    \\multicolumn{2}{c}{Metric} & \\scalebox{0.78}{MSE} & \\scalebox{0.78}{MAE} & \\scalebox{0.78}{MSE} & \\scalebox{0.78}{MAE} & \\scalebox{0.78}{MSE} & \\scalebox{0.78}{MAE} & \\scalebox{0.78}{MSE} & \\scalebox{0.78}{MAE} & \\scalebox{0.78}{MSE} & \\scalebox{0.78}{MAE} & \\scalebox{0.78}{MSE} & \\scalebox{0.78}{MAE} & \\scalebox{0.78}{MSE} & \\scalebox{0.78}{MAE} & \\scalebox{0.78}{MSE} & \\scalebox{0.78}{MAE} & \\scalebox{0.78}{MSE} & \\scalebox{0.78}{MAE} & \\scalebox{0.78}{MSE} & \\scalebox{0.78}{MAE} & \\scalebox{0.78}{MSE} & \\scalebox{0.78}{MAE}\\\\\n    \\toprule\n\n \\multirow{5}{*}{\\rotatebox{90}{\\scalebox{0.95}{Weather}}} \n    & \\scalebox{0.85}{96} &\\boldres{\\scalebox{0.85}{0.163}}&\\boldres{\\scalebox{0.85}{0.209}}&\\scalebox{0.85}{0.186}&\\scalebox{0.85}{0.227}&\\secondres{\\scalebox{0.85}{0.172}}&\\secondres{\\scalebox{0.85}{0.220}}&\\scalebox{0.85}{0.195}&\\scalebox{0.85}{0.271}&\\scalebox{0.85}{0.198}&\\scalebox{0.85}{0.261}&\\scalebox{0.85}{0.195}&\\scalebox{0.85}{0.236}&\\scalebox{0.85}{0.195}&\\scalebox{0.85}{0.252} & \\scalebox{0.85}{0.217} &\\scalebox{0.85}{0.296}& \\scalebox{0.85}{0.173} &\\scalebox{0.85}{0.223} & \\scalebox{0.85}{0.266} &\\scalebox{0.85}{0.336} & \\scalebox{0.85}{0.300} &\\scalebox{0.85}{0.384} \\\\\n    & \\scalebox{0.85}{192} &\\boldres{\\scalebox{0.85}{0.208}}&\\boldres{\\scalebox{0.85}{0.250}}&\\scalebox{0.85}{0.234}&\\scalebox{0.85}{0.265}&\\scalebox{0.85}{0.219}&\\secondres{\\scalebox{0.85}{0.261}}&\\secondres{\\scalebox{0.85}{0.209}}&\\scalebox{0.85}{0.277}&\\scalebox{0.85}{0.239}&\\scalebox{0.85}{0.299}&\\scalebox{0.85}{0.239}&\\scalebox{0.85}{0.271}&\\scalebox{0.85}{0.237}&\\scalebox{0.85}{0.295} & \\scalebox{0.85}{0.276} &\\scalebox{0.85}{0.336} & \\scalebox{0.85}{0.245} &\\scalebox{0.85}{0.285} & \\scalebox{0.85}{0.307} &\\scalebox{0.85}{0.367} & \\scalebox{0.85}{0.598} &\\scalebox{0.85}{0.544}\\\\\n    & \\scalebox{0.85}{336} &\\secondres{\\scalebox{0.85}{0.251}}&\\boldres{\\scalebox{0.85}{0.287}}&\\scalebox{0.85}{0.284}&\\secondres{\\scalebox{0.85}{0.301}}&\\boldres{\\scalebox{0.85}{0.246}}&\\scalebox{0.85}{0.337}&\\scalebox{0.85}{0.273}&\\scalebox{0.85}{0.332}&\\scalebox{0.85}{0.285}&\\scalebox{0.85}{0.336}&\\scalebox{0.85}{0.289}&\\scalebox{0.85}{0.306}&\\scalebox{0.85}{0.282}&\\scalebox{0.85}{0.331} & \\scalebox{0.85}{0.339} &\\scalebox{0.85}{0.380} & \\scalebox{0.85}{0.321} &\\scalebox{0.85}{0.338} & \\scalebox{0.85}{0.359} &\\scalebox{0.85}{0.395} & \\scalebox{0.85}{0.578} &\\scalebox{0.85}{0.523}\\\\\n    & \\scalebox{0.85}{720} &\\boldres{\\scalebox{0.85}{0.339}}&\\boldres{\\scalebox{0.85}{0.341}}&\\scalebox{0.85}{0.356}&\\secondres{\\scalebox{0.85}{0.349}}&\\scalebox{0.85}{0.365}&\\scalebox{0.85}{0.359}&\\scalebox{0.85}{0.379}&\\scalebox{0.85}{0.401}&\\scalebox{0.85}{0.351}&\\scalebox{0.85}{0.388}&\\scalebox{0.85}{0.361}&\\scalebox{0.85}{0.351}&\\secondres{\\scalebox{0.85}{0.345}}&\\scalebox{0.85}{0.382} & \\scalebox{0.85}{0.403} &\\scalebox{0.85}{0.428} & \\scalebox{0.85}{0.414} &\\scalebox{0.85}{0.410} & \\scalebox{0.85}{0.419} &\\scalebox{0.85}{0.428} & \\scalebox{0.85}{1.059} &\\scalebox{0.85}{0.741} \n    \\\\\n    \\cmidrule(lr){2-24}\n    & \\scalebox{0.85}{Avg} &\\boldres{\\scalebox{0.85}{0.240}}&\\boldres{\\scalebox{0.85}{0.271}}&\\scalebox{0.85}{0.265}&\\secondres{\\scalebox{0.85}{0.285}}&\\secondres{\\scalebox{0.85}{0.251}}&\\scalebox{0.85}{0.294}&\\scalebox{0.85}{0.264}&\\scalebox{0.85}{0.320}&\\scalebox{0.85}{0.268}&\\scalebox{0.85}{0.321}&\\scalebox{0.85}{0.271}&\\scalebox{0.85}{0.291}&\\scalebox{0.85}{0.265}&\\scalebox{0.85}{0.315} &\\scalebox{0.85}{0.309} &\\scalebox{0.85}{0.360} &\\scalebox{0.85}{0.288} &\\scalebox{0.85}{0.314} &\\scalebox{0.85}{0.338} &\\scalebox{0.85}{0.382} &\\scalebox{0.85}{0.634} &\\scalebox{0.85}{0.548} \\\\\n    \\midrule\n    \n    \\multirow{5}{*}{\\rotatebox{90}{\\scalebox{0.95}{Solar-Energy}}} \n    & \\scalebox{0.85}{96} &\\boldres{\\scalebox{0.85}{0.189}}&\\boldres{\\scalebox{0.85}{0.259}}&\\scalebox{0.85}{0.265}&\\scalebox{0.85}{0.323}&\\scalebox{0.85}{0.373}&\\scalebox{0.85}{0.358}&\\secondres{\\scalebox{0.85}{0.232}}&\\secondres{\\scalebox{0.85}{0.302}}&\\scalebox{0.85}{0.257}&\\scalebox{0.85}{0.325}&\\scalebox{0.85}{0.333}&\\scalebox{0.85}{0.350}&\\scalebox{0.85}{0.290}&\\scalebox{0.85}{0.378}&\\scalebox{0.85}{0.286}&\\scalebox{0.85}{0.341}&\\scalebox{0.85}{0.321}&\\scalebox{0.85}{0.380}&\\scalebox{0.85}{0.456}&\\scalebox{0.85}{0.446}&\\scalebox{0.85}{0.287}&\\scalebox{0.85}{0.323}\n    \\\\\n    & \\scalebox{0.85}{192} &\\boldres{\\scalebox{0.85}{0.222}}&\\boldres{\\scalebox{0.85}{0.283}}&\\scalebox{0.85}{0.288}&\\secondres{\\scalebox{0.85}{0.332}}&\\scalebox{0.85}{0.397}&\\scalebox{0.85}{0.376}&\\scalebox{0.85}{0.371}&\\scalebox{0.85}{0.410}&\\secondres{\\scalebox{0.85}{0.278}}&\\scalebox{0.85}{0.354}&\\scalebox{0.85}{0.371}&\\scalebox{0.85}{0.372}&\\scalebox{0.85}{0.320}&\\scalebox{0.85}{0.398}&\\scalebox{0.85}{0.291}&\\scalebox{0.85}{0.337}&\\scalebox{0.85}{0.346}&\\scalebox{0.85}{0.369}&\\scalebox{0.85}{0.588}&\\scalebox{0.85}{0.561}&\\scalebox{0.85}{0.297}&\\scalebox{0.85}{0.341}\n    \\\\\n    & \\scalebox{0.85}{336} &\\boldres{\\scalebox{0.85}{0.231}}&\\boldres{\\scalebox{0.85}{0.292}}&\\scalebox{0.85}{0.301}&\\secondres{\\scalebox{0.85}{0.339}}&\\scalebox{0.85}{0.420}&\\scalebox{0.85}{0.380}&\\scalebox{0.85}{0.495}&\\scalebox{0.85}{0.515}&\\secondres{\\scalebox{0.85}{0.298}}&\\scalebox{0.85}{0.375}&\\scalebox{0.85}{0.408}&\\scalebox{0.85}{0.385}&\\scalebox{0.85}{0.353}&\\scalebox{0.85}{0.415}&\\scalebox{0.85}{0.354}&\\scalebox{0.85}{0.416}&\\scalebox{0.85}{0.357}&\\scalebox{0.85}{0.387}&\\scalebox{0.85}{0.595}&\\scalebox{0.85}{0.588}&\\scalebox{0.85}{0.367}&\\scalebox{0.85}{0.429}\\\\\n    & \\scalebox{0.85}{720} &\\boldres{\\scalebox{0.85}{0.223}}&\\boldres{\\scalebox{0.85}{0.285}}&\\secondres{\\scalebox{0.85}{0.295}}&\\secondres{\\scalebox{0.85}{0.336}}&\\scalebox{0.85}{0.420}&\\scalebox{0.85}{0.381}&\\scalebox{0.85}{0.526}&\\scalebox{0.85}{0.542}&\\scalebox{0.85}{0.299}&\\scalebox{0.85}{0.379}&\\scalebox{0.85}{0.406}&\\scalebox{0.85}{0.377}&\\scalebox{0.85}{0.357}&\\scalebox{0.85}{0.413}\n    &\\scalebox{0.85}{0.380}&\\scalebox{0.85}{0.437}&\\scalebox{0.85}{0.375}&\\scalebox{0.85}{0.424}&\\scalebox{0.85}{0.733}&\\scalebox{0.85}{0.633}&\\scalebox{0.85}{0.374}&\\scalebox{0.85}{0.431}\n    \\\\\n    \\cmidrule(lr){2-24}\n    & \\scalebox{0.85}{Avg} &\\boldres{\\scalebox{0.85}{0.216}}&\\boldres{\\scalebox{0.85}{0.280}}&\\scalebox{0.85}{0.287}&\\secondres{\\scalebox{0.85}{0.333}}&\\scalebox{0.85}{0.403}&\\scalebox{0.85}{0.374}&\\scalebox{0.85}{0.406}&\\scalebox{0.85}{0.442}&\\secondres{\\scalebox{0.85}{0.283}}&\\scalebox{0.85}{0.358}&\\scalebox{0.85}{0.380}&\\scalebox{0.85}{0.371}&\\scalebox{0.85}{0.330}&\\scalebox{0.85}{0.401}&\\scalebox{0.85}{0.328} &\\scalebox{0.85}{0.383} &\\scalebox{0.85}{0.350} &\\scalebox{0.85}{0.390} &\\scalebox{0.85}{0.586} &\\scalebox{0.85}{0.557} &\\scalebox{0.85}{0.331} &\\scalebox{0.85}{0.381}\\\\\n    \\midrule\n\n    \\multirow{5}{*}{\\rotatebox{90}{\\scalebox{0.95}{Electricity}}} \n    & \\scalebox{0.85}{96} &\\boldres{\\scalebox{0.85}{0.153}}&\\boldres{\\scalebox{0.85}{0.247}}&\\scalebox{0.85}{0.190}&\\scalebox{0.85}{0.296}&\\secondres{\\scalebox{0.85}{0.168}}&\\secondres{\\scalebox{0.85}{0.272}}&\\scalebox{0.85}{0.219}&\\scalebox{0.85}{0.314}&\\scalebox{0.85}{0.180}&\\scalebox{0.85}{0.293}&\\scalebox{0.85}{0.198}&\\scalebox{0.85}{0.274}&\\scalebox{0.85}{0.210}&\\scalebox{0.85}{0.302} &\\scalebox{0.85}{0.193} &\\scalebox{0.85}{0.308} &\\scalebox{0.85}{0.169} &\\scalebox{0.85}{0.273} &\\scalebox{0.85}{0.201} &\\scalebox{0.85}{0.317} &\\scalebox{0.85}{0.274} &\\scalebox{0.85}{0.368}\\\\\n    & \\scalebox{0.85}{192} &\\boldres{\\scalebox{0.85}{0.166}}&\\boldres{\\scalebox{0.85}{0.256}}&\\scalebox{0.85}{0.199}&\\scalebox{0.85}{0.304}&\\scalebox{0.85}{0.184}&\\scalebox{0.85}{0.322}&\\scalebox{0.85}{0.231}&\\scalebox{0.85}{0.322}&\\scalebox{0.85}{0.189}&\\scalebox{0.85}{0.302}&\\scalebox{0.85}{0.198}&\\secondres{\\scalebox{0.85}{0.278}}&\\scalebox{0.85}{0.210}&\\scalebox{0.85}{0.305} &\\scalebox{0.85}{0.201} &\\scalebox{0.85}{0.315} &\\secondres{\\scalebox{0.85}{0.182}} &\\scalebox{0.85}{0.286}&\\scalebox{0.85}{0.222} &\\scalebox{0.85}{0.334} &\\scalebox{0.85}{0.296} &\\scalebox{0.85}{0.386}\\\\\n    & \\scalebox{0.85}{336} &\\boldres{\\scalebox{0.85}{0.185}}&\\boldres{\\scalebox{0.85}{0.277}}&\\scalebox{0.85}{0.217}&\\scalebox{0.85}{0.319}&\\secondres{\\scalebox{0.85}{0.198}}&\\secondres{\\scalebox{0.85}{0.300}}&\\scalebox{0.85}{0.246}&\\scalebox{0.85}{0.337}&\\secondres{\\scalebox{0.85}{0.198}}&\\scalebox{0.85}{0.312}&\\scalebox{0.85}{0.217}&\\secondres{\\scalebox{0.85}{0.300}}&\\scalebox{0.85}{0.223}&\\scalebox{0.85}{0.319} &\\scalebox{0.85}{0.214} &\\scalebox{0.85}{0.329} &\\scalebox{0.85}{0.200} &\\scalebox{0.85}{0.304} &\\scalebox{0.85}{0.231} &\\scalebox{0.85}{0.443} &\\scalebox{0.85}{0.300} &\\scalebox{0.85}{0.394}\\\\\n    & \\scalebox{0.85}{720} &\\scalebox{0.85}{0.225}&\\boldres{\\scalebox{0.85}{0.310}}&\\scalebox{0.85}{0.258}&\\scalebox{0.85}{0.352}&\\secondres{\\scalebox{0.85}{0.220}}&\\secondres{\\scalebox{0.85}{0.320}}&\\scalebox{0.85}{0.280}&\\scalebox{0.85}{0.363}&\\boldres{\\scalebox{0.85}{0.217}}&\\scalebox{0.85}{0.330}&\\scalebox{0.85}{0.278}&\\scalebox{0.85}{0.356}&\\scalebox{0.85}{0.258}&\\scalebox{0.85}{0.350} &\\scalebox{0.85}{0.246} &\\scalebox{0.85}{0.355} &\\scalebox{0.85}{0.222} &\\scalebox{0.85}{0.321} &\\scalebox{0.85}{0.254} &\\scalebox{0.85}{0.361} &\\scalebox{0.85}{0.373} &\\scalebox{0.85}{0.439}\n    \\\\\n    \\cmidrule(lr){2-24}\n    & \\scalebox{0.85}{Avg} &\\boldres{\\scalebox{0.85}{0.182}}&\\boldres{\\scalebox{0.85}{0.272}}&\\scalebox{0.85}{0.216}&\\scalebox{0.85}{0.318}&\\secondres{\\scalebox{0.85}{0.193}}&\\scalebox{0.85}{0.304}&\\scalebox{0.85}{0.244}&\\scalebox{0.85}{0.334}&\\scalebox{0.85}{0.196}&\\scalebox{0.85}{0.309}&\\scalebox{0.85}{0.223}&\\scalebox{0.85}{0.302}&\\scalebox{0.85}{0.225}&\\scalebox{0.85}{0.319} &\\scalebox{0.85}{0.214} &\\scalebox{0.85}{0.327} &\\secondres{\\scalebox{0.85}{0.193}} &\\secondres{\\scalebox{0.85}{0.296}}&\\scalebox{0.85}{0.227} &\\scalebox{0.85}{0.338} &\\scalebox{0.85}{0.311} &\\scalebox{0.85}{0.397}\\\\\n    \\midrule\n\n    \\multirow{5}{*}{\\rotatebox{90}{\\scalebox{0.95}{Traffic}}} \n    & \\scalebox{0.85}{96} &\\boldres{\\scalebox{0.85}{0.462}}&\\boldres{\\scalebox{0.85}{0.285}}&\\secondres{\\scalebox{0.85}{0.526}}&\\scalebox{0.85}{0.347}&\\scalebox{0.85}{0.593}&\\secondres{\\scalebox{0.85}{0.321}}&\\scalebox{0.85}{0.644}&\\scalebox{0.85}{0.429}&\\scalebox{0.85}{0.577}&\\scalebox{0.85}{0.350}&\\scalebox{0.85}{0.647}&\\scalebox{0.85}{0.384}&\\scalebox{0.85}{0.650}&\\scalebox{0.85}{0.396} &\\scalebox{0.85}{0.587} &\\scalebox{0.85}{0.366} &\\scalebox{0.85}{0.612} &\\scalebox{0.85}{0.338} &\\scalebox{0.85}{0.613} &\\scalebox{0.85}{0.388} &\\scalebox{0.85}{0.719} &\\scalebox{0.85}{0.391}\n    \\\\\n    & \\scalebox{0.85}{192} &\\boldres{\\scalebox{0.85}{0.473}}&\\boldres{\\scalebox{0.85}{0.296}}&\\secondres{\\scalebox{0.85}{0.522}}&\\secondres{\\scalebox{0.85}{0.332}}&\\scalebox{0.85}{0.617}&\\scalebox{0.85}{0.336}&\\scalebox{0.85}{0.665}&\\scalebox{0.85}{0.431}&\\scalebox{0.85}{0.589}&\\scalebox{0.85}{0.356}&\\scalebox{0.85}{0.600}&\\scalebox{0.85}{0.361}&\\scalebox{0.85}{0.598}&\\scalebox{0.85}{0.370} &\\scalebox{0.85}{0.604} &\\scalebox{0.85}{0.373} &\\scalebox{0.85}{0.613} &\\scalebox{0.85}{0.340} &\\scalebox{0.85}{0.616} &\\scalebox{0.85}{0.382} &\\scalebox{0.85}{0.696} &\\scalebox{0.85}{0.379}\n    \\\\\n    & \\scalebox{0.85}{336} &\\boldres{\\scalebox{0.85}{0.498}}&\\boldres{\\scalebox{0.85}{0.296}}&\\secondres{\\scalebox{0.85}{0.517}}&\\scalebox{0.85}{0.334}&\\scalebox{0.85}{0.629}&\\scalebox{0.85}{0.336}&\\scalebox{0.85}{0.674}&\\scalebox{0.85}{0.420}&\\scalebox{0.85}{0.594}&\\scalebox{0.85}{0.358}&\\scalebox{0.85}{0.610}&\\scalebox{0.85}{0.367}&\\scalebox{0.85}{0.605}&\\scalebox{0.85}{0.373} &\\scalebox{0.85}{0.621} &\\scalebox{0.85}{0.383} &\\scalebox{0.85}{0.618} &\\secondres{\\scalebox{0.85}{0.328}} &\\scalebox{0.85}{0.622} &\\scalebox{0.85}{0.337} &\\scalebox{0.85}{0.777} &\\scalebox{0.85}{0.420}\n    \\\\\n    & \\scalebox{0.85}{720} &\\boldres{\\scalebox{0.85}{0.506}}&\\boldres{\\scalebox{0.85}{0.313}}&\\secondres{\\scalebox{0.85}{0.552}}&\\scalebox{0.85}{0.352}&\\scalebox{0.85}{0.640}&\\secondres{\\scalebox{0.85}{0.350}}&\\scalebox{0.85}{0.683}&\\scalebox{0.85}{0.424}&\\scalebox{0.85}{0.613}&\\scalebox{0.85}{0.361}&\\scalebox{0.85}{0.691}&\\scalebox{0.85}{0.425}&\\scalebox{0.85}{0.645}&\\scalebox{0.85}{0.394} &\\scalebox{0.85}{0.626} &\\scalebox{0.85}{0.382} &\\scalebox{0.85}{0.653} &\\scalebox{0.85}{0.355} &\\scalebox{0.85}{0.660} &\\scalebox{0.85}{0.408} &\\scalebox{0.85}{0.864} &\\scalebox{0.85}{0.472} \n    \\\\\n    \\cmidrule(lr){2-24}\n    & \\scalebox{0.85}{Avg} &\\boldres{\\scalebox{0.85}{0.484}}&\\boldres{\\scalebox{0.85}{0.297}}&\\secondres{\\scalebox{0.85}{0.529}}&\\scalebox{0.85}{0.341}&\\scalebox{0.85}{0.620}&\\secondres{\\scalebox{0.85}{0.336}}&\\scalebox{0.85}{0.667}&\\scalebox{0.85}{0.426}&\\scalebox{0.85}{0.593}&\\scalebox{0.85}{0.356}&\\scalebox{0.85}{0.637}&\\scalebox{0.85}{0.384}&\\scalebox{0.85}{0.625}&\\scalebox{0.85}{0.383} &\\scalebox{0.85}{0.610} &\\scalebox{0.85}{0.376} &\\scalebox{0.85}{0.624} &\\scalebox{0.85}{0.340} &\\scalebox{0.85}{0.628} &\\scalebox{0.85}{0.379} &\\scalebox{0.85}{0.764} &\\scalebox{0.85}{0.416}\\\\\n    \\midrule\n\n    \\multirow{5}{*}{\\rotatebox{90}{\\scalebox{0.95}{ETTh1}}} \n    & \\scalebox{0.85}{96} &\\boldres{\\scalebox{0.85}{0.375}}&\\boldres{\\scalebox{0.85}{0.400}}&\\scalebox{0.85}{0.460}&\\scalebox{0.85}{0.447}&\\secondres{\\scalebox{0.85}{0.384}}&\\secondres{\\scalebox{0.85}{0.402}}&\\scalebox{0.85}{0.423}&\\scalebox{0.85}{0.448}&\\scalebox{0.85}{0.426}&\\scalebox{0.85}{0.446}&\\scalebox{0.85}{0.438}&\\scalebox{0.85}{0.433}&\\scalebox{0.85}{0.397}&\\scalebox{0.85}{0.412} \n     &\\scalebox{0.85}{0.395} &\\scalebox{0.85}{0.424} &\\scalebox{0.85}{0.513} &\\scalebox{0.85}{0.491} &\\scalebox{0.85}{0.449} &\\scalebox{0.85}{0.459} &\\scalebox{0.85}{0.865} &\\scalebox{0.85}{0.713}\\\\\n    & \\scalebox{0.85}{192} &\\boldres{\\scalebox{0.85}{0.429}}&\\boldres{\\scalebox{0.85}{0.421}}&\\scalebox{0.85}{0.512}&\\scalebox{0.85}{0.477}&\\secondres{\\scalebox{0.85}{0.436}}&\\secondres{\\scalebox{0.85}{0.429}}&\\scalebox{0.85}{0.471}&\\scalebox{0.85}{0.474}&\\scalebox{0.85}{0.454}&\\scalebox{0.85}{0.464}&\\scalebox{0.85}{0.493}&\\scalebox{0.85}{0.466}&\\scalebox{0.85}{0.446}&\\scalebox{0.85}{0.441} \n     &\\scalebox{0.85}{0.469} &\\scalebox{0.85}{0.470} &\\scalebox{0.85}{0.534} &\\scalebox{0.85}{0.504} &\\scalebox{0.85}{0.500} &\\scalebox{0.85}{0.482} &\\scalebox{0.85}{1.008} &\\scalebox{0.85}{0.792}\n    \\\\\n    & \\scalebox{0.85}{336} &\\boldres{\\scalebox{0.85}{0.484}}&\\boldres{\\scalebox{0.85}{0.458}}&\\scalebox{0.85}{0.546}&\\scalebox{0.85}{0.496}&\\scalebox{0.85}{0.638}&\\scalebox{0.85}{0.469}&\\scalebox{0.85}{0.570}&\\scalebox{0.85}{0.546}&\\scalebox{0.85}{0.493}&\\scalebox{0.85}{0.487}&\\scalebox{0.85}{0.547}&\\scalebox{0.85}{0.495}&\\secondres{\\scalebox{0.85}{0.489}}&\\secondres{\\scalebox{0.85}{0.467}}\n    &\\scalebox{0.85}{0.530} &\\scalebox{0.85}{0.499} &\\scalebox{0.85}{0.588} &\\scalebox{0.85}{0.535} &\\scalebox{0.85}{0.521} &\\scalebox{0.85}{0.496} &\\scalebox{0.85}{1.107} &\\scalebox{0.85}{0.809}\n    \\\\\n    & \\scalebox{0.85}{720} &\\boldres{\\scalebox{0.85}{0.498}}&\\boldres{\\scalebox{0.85}{0.482}}&\\scalebox{0.85}{0.544}&\\scalebox{0.85}{0.517}&\\scalebox{0.85}{0.521}&\\secondres{\\scalebox{0.85}{0.500}}&\\scalebox{0.85}{0.653}&\\scalebox{0.85}{0.621}&\\scalebox{0.85}{0.526}&\\scalebox{0.85}{0.526}&\\scalebox{0.85}{0.586}&\\scalebox{0.85}{0.538}&\\secondres{\\scalebox{0.85}{0.513}}&\\scalebox{0.85}{0.510}\n    &\\scalebox{0.85}{0.598} &\\scalebox{0.85}{0.544} &\\scalebox{0.85}{0.643} &\\scalebox{0.85}{0.616} &\\secondres{\\scalebox{0.85}{0.514}} &\\scalebox{0.85}{0.512}  &\\scalebox{0.85}{1.181} &\\scalebox{0.85}{0.865}\n    \\\\\n    \\cmidrule(lr){2-24}\n    & \\scalebox{0.85}{Avg} &\\boldres{\\scalebox{0.85}{0.447}}&\\boldres{\\scalebox{0.85}{0.440}}&\\scalebox{0.85}{0.516}&\\scalebox{0.85}{0.484}&\\scalebox{0.85}{0.495}&\\secondres{\\scalebox{0.85}{0.450}}&\\scalebox{0.85}{0.529}&\\scalebox{0.85}{0.522}&\\scalebox{0.85}{0.475}&\\scalebox{0.85}{0.480}&\\scalebox{0.85}{0.516}&\\scalebox{0.85}{0.483}&\\secondres{\\scalebox{0.85}{0.461}}&\\scalebox{0.85}{0.457}&\\scalebox{0.85}{0.498} &\\scalebox{0.85}{0.484} &\\scalebox{0.85}{0.570} &\\scalebox{0.85}{0.537} &\\scalebox{0.85}{0.496} &\\scalebox{0.85}{0.487} &\\scalebox{0.85}{1.040} &\\scalebox{0.85}{0.795}\\\\\n    \\midrule\n\n    \\multirow{5}{*}{\\rotatebox{90}{\\scalebox{0.95}{ETTh2}}} \n    & \\scalebox{0.85}{96} &\\boldres{\\scalebox{0.85}{0.289}}&\\boldres{\\scalebox{0.85}{0.341}}&\\secondres{\\scalebox{0.85}{0.308}}&\\secondres{\\scalebox{0.85}{0.355}}&\\scalebox{0.85}{0.340}&\\scalebox{0.85}{0.374}&\\scalebox{0.85}{0.745}&\\scalebox{0.85}{0.584}&\\scalebox{0.85}{0.372}&\\scalebox{0.85}{0.424}&\\scalebox{0.85}{0.322}&\\scalebox{0.85}{0.364}&\\scalebox{0.85}{0.340}&\\scalebox{0.85}{0.394}  &\\scalebox{0.85}{0.358} &\\scalebox{0.85}{0.397} &\\scalebox{0.85}{0.476} &\\scalebox{0.85}{0.458} &\\scalebox{0.85}{0.346} &\\scalebox{0.85}{0.388} &\\scalebox{0.85}{3.755} &\\scalebox{0.85}{1.525} \\\\\n    & \\scalebox{0.85}{192} &\\boldres{\\scalebox{0.85}{0.372}}&\\boldres{\\scalebox{0.85}{0.392}}&\\secondres{\\scalebox{0.85}{0.393}}&\\secondres{\\scalebox{0.85}{0.405}}&\\scalebox{0.85}{0.402}&\\scalebox{0.85}{0.414}&\\scalebox{0.85}{0.877}&\\scalebox{0.85}{0.656}&\\scalebox{0.85}{0.492}&\\scalebox{0.85}{0.492}&\\scalebox{0.85}{0.404}&\\scalebox{0.85}{0.414}&\\scalebox{0.85}{0.482}&\\scalebox{0.85}{0.479} &\\scalebox{0.85}{0.429} &\\scalebox{0.85}{0.439} &\\scalebox{0.85}{0.512} &\\scalebox{0.85}{0.493} &\\scalebox{0.85}{0.456} &\\scalebox{0.85}{0.452}  &\\scalebox{0.85}{5.602} &\\scalebox{0.85}{1.931}\\\\\n    & \\scalebox{0.85}{336} &\\boldres{\\scalebox{0.85}{0.386}}&\\boldres{\\scalebox{0.85}{0.414}}&\\secondres{\\scalebox{0.85}{0.427}}&\\secondres{\\scalebox{0.85}{0.436}}&\\scalebox{0.85}{0.452}&\\scalebox{0.85}{0.452}&\\scalebox{0.85}{1.043}&\\scalebox{0.85}{0.731}&\\scalebox{0.85}{0.607}&\\scalebox{0.85}{0.555}&\\scalebox{0.85}{0.435}&\\scalebox{0.85}{0.445}&\\scalebox{0.85}{0.591}&\\scalebox{0.85}{0.541} &\\scalebox{0.85}{0.496} &\\scalebox{0.85}{0.487} &\\scalebox{0.85}{0.552} &\\scalebox{0.85}{0.551} &\\scalebox{0.85}{0.482} &\\scalebox{0.85}{0.486} &\\scalebox{0.85}{4.721} &\\scalebox{0.85}{1.835}\\\\\n    & \\scalebox{0.85}{720} &\\boldres{\\scalebox{0.85}{0.412}}&\\boldres{\\scalebox{0.85}{0.434}}&\\secondres{\\scalebox{0.85}{0.436}}&\\secondres{\\scalebox{0.85}{0.450}}&\\scalebox{0.85}{0.462}&\\scalebox{0.85}{0.468}&\\scalebox{0.85}{1.104}&\\scalebox{0.85}{0.763}&\\scalebox{0.85}{0.824}&\\scalebox{0.85}{0.655}&\\scalebox{0.85}{0.447}&\\scalebox{0.85}{0.458}&\\scalebox{0.85}{0.839}&\\scalebox{0.85}{0.661} &\\scalebox{0.85}{0.463} &\\scalebox{0.85}{0.474}&\\scalebox{0.85}{0.562} &\\scalebox{0.85}{0.560} &\\scalebox{0.85}{0.515} &\\scalebox{0.85}{0.511}  &\\scalebox{0.85}{3.647} &\\scalebox{0.85}{1.625}\n    \\\\\n    \\cmidrule(lr){2-24}\n    & \\scalebox{0.85}{Avg} &\\boldres{\\scalebox{0.85}{0.364}}&\\boldres{\\scalebox{0.85}{0.395}}&\\secondres{\\scalebox{0.85}{0.391}}&\\secondres{\\scalebox{0.85}{0.411}}&\\scalebox{0.85}{0.414}&\\scalebox{0.85}{0.427}&\\scalebox{0.85}{0.942}&\\scalebox{0.85}{0.684}&\\scalebox{0.85}{0.574}&\\scalebox{0.85}{0.531}&\\scalebox{0.85}{0.402}&\\scalebox{0.85}{0.420}&\\scalebox{0.85}{0.563}&\\scalebox{0.85}{0.519} &\\scalebox{0.85}{0.437} &\\scalebox{0.85}{0.449} &\\scalebox{0.85}{0.526} &\\scalebox{0.85}{0.516} &\\scalebox{0.85}{0.450} &\\scalebox{0.85}{0.459} &\\scalebox{0.85}{4.431} &\\scalebox{0.85}{1.729}\\\\\n    \\midrule\n\n    \\multirow{5}{*}{\\rotatebox{90}{\\scalebox{0.95}{ETTm1}}} \n    & \\scalebox{0.85}{96} &\\boldres{\\scalebox{0.85}{0.320}}&\\boldres{\\scalebox{0.85}{0.357}}&\\scalebox{0.85}{0.352}&\\scalebox{0.85}{0.374}&\\secondres{\\scalebox{0.85}{0.338}}&\\scalebox{0.85}{0.375}&\\scalebox{0.85}{0.404}&\\scalebox{0.85}{0.426}&\\scalebox{0.85}{0.365}&\\scalebox{0.85}{0.387}&\\scalebox{0.85}{0.353}&\\secondres{\\scalebox{0.85}{0.370}}&\\scalebox{0.85}{0.346}&\\scalebox{0.85}{0.374} &\\scalebox{0.85}{0.379} &\\scalebox{0.85}{0.419} &\\scalebox{0.85}{0.386} &\\scalebox{0.85}{0.398} &\\scalebox{0.85}{0.505} &\\scalebox{0.85}{0.475} &\\scalebox{0.85}{0.672} &\\scalebox{0.85}{0.571} \n    \\\\\n    & \\scalebox{0.85}{192} &\\boldres{\\scalebox{0.85}{0.361}}&\\boldres{\\scalebox{0.85}{0.381}}&\\scalebox{0.85}{0.390}&\\scalebox{0.85}{0.393}&\\secondres{\\scalebox{0.85}{0.374}}&\\secondres{\\scalebox{0.85}{0.387}}&\\scalebox{0.85}{0.450}&\\scalebox{0.85}{0.451}&\\scalebox{0.85}{0.403}&\\scalebox{0.85}{0.408}&\\scalebox{0.85}{0.389}&\\secondres{\\scalebox{0.85}{0.387}}&\\scalebox{0.85}{0.382}&\\scalebox{0.85}{0.391} &\\scalebox{0.85}{0.426} &\\scalebox{0.85}{0.441} &\\scalebox{0.85}{0.459} &\\scalebox{0.85}{0.444} &\\scalebox{0.85}{0.553} &\\scalebox{0.85}{0.496} &\\scalebox{0.85}{0.795} &\\scalebox{0.85}{0.669}\n    \\\\\n    & \\scalebox{0.85}{336} &\\boldres{\\scalebox{0.85}{0.390}}&\\boldres{\\scalebox{0.85}{0.404}}&\\scalebox{0.85}{0.421}&\\scalebox{0.85}{0.414}&\\secondres{\\scalebox{0.85}{0.410}}&\\scalebox{0.85}{0.411}&\\scalebox{0.85}{0.532}&\\scalebox{0.85}{0.515}&\\scalebox{0.85}{0.436}&\\scalebox{0.85}{0.431}&\\scalebox{0.85}{0.421}&\\secondres{\\scalebox{0.85}{0.408}}&\\scalebox{0.85}{0.415}&\\scalebox{0.85}{0.415} &\\scalebox{0.85}{0.445} &\\scalebox{0.85}{0.459} &\\scalebox{0.85}{0.495} &\\scalebox{0.85}{0.464} &\\scalebox{0.85}{0.621} &\\scalebox{0.85}{0.537}  &\\scalebox{0.85}{1.212} &\\scalebox{0.85}{0.871}\n    \\\\\n    & \\scalebox{0.85}{720} &\\boldres{\\scalebox{0.85}{0.454}}&\\boldres{\\scalebox{0.85}{0.441}}&\\scalebox{0.85}{0.462}&\\scalebox{0.85}{0.449}&\\scalebox{0.85}{0.478}&\\secondres{\\scalebox{0.85}{0.450}}&\\scalebox{0.85}{0.666}&\\scalebox{0.85}{0.589}&\\scalebox{0.85}{0.489}&\\scalebox{0.85}{0.462}&\\scalebox{0.85}{0.481}&\\boldres{\\scalebox{0.85}{0.441}}&\\secondres{\\scalebox{0.85}{0.473}}&\\scalebox{0.85}{0.451} &\\scalebox{0.85}{0.543} &\\scalebox{0.85}{0.490} &\\scalebox{0.85}{0.585} &\\scalebox{0.85}{0.516} &\\scalebox{0.85}{0.671} &\\scalebox{0.85}{0.561} &\\scalebox{0.85}{1.166} &\\scalebox{0.85}{0.823}\n    \\\\\n    \\cmidrule(lr){2-24}\n    & \\scalebox{0.85}{Avg} &\\boldres{\\scalebox{0.85}{0.381}}&\\boldres{\\scalebox{0.85}{0.395}}&\\scalebox{0.85}{0.406}&\\scalebox{0.85}{0.407}&\\secondres{\\scalebox{0.85}{0.400}}&\\scalebox{0.85}{0.406}&\\scalebox{0.85}{0.513}&\\scalebox{0.85}{0.495}&\\scalebox{0.85}{0.423}&\\scalebox{0.85}{0.422}&\\scalebox{0.85}{0.411}&\\secondres{\\scalebox{0.85}{0.402}}&\\scalebox{0.85}{0.404}&\\scalebox{0.85}{0.408}  &\\scalebox{0.85}{0.448} &\\scalebox{0.85}{0.452} &\\scalebox{0.85}{0.481} &\\scalebox{0.85}{0.456} &\\scalebox{0.85}{0.588} &\\scalebox{0.85}{0.517} &\\scalebox{0.85}{0.961} &\\scalebox{0.85}{0.734}\\\\\n    \\midrule\n\n    \\multirow{5}{*}{\\rotatebox{90}{\\scalebox{0.95}{ETTm2}}} \n    & \\scalebox{0.85}{96} &\\boldres{\\scalebox{0.85}{0.175}}&\\boldres{\\scalebox{0.85}{0.258}}&\\secondres{\\scalebox{0.85}{0.183}}&\\scalebox{0.85}{0.270}&\\scalebox{0.85}{0.187}&\\scalebox{0.85}{0.267}&\\scalebox{0.85}{0.287}&\\scalebox{0.85}{0.366}&\\scalebox{0.85}{0.197}&\\scalebox{0.85}{0.296}&\\secondres{\\scalebox{0.85}{0.183}}&\\secondres{\\scalebox{0.85}{0.266}}&\\scalebox{0.85}{0.193}&\\scalebox{0.85}{0.293}\n    &\\scalebox{0.85}{0.203} &\\scalebox{0.85}{0.287} &\\scalebox{0.85}{0.192} &\\scalebox{0.85}{0.274} &\\scalebox{0.85}{0.255} &\\scalebox{0.85}{0.339} &\\scalebox{0.85}{0.365} &\\scalebox{0.85}{0.453}\n    \\\\\n    & \\scalebox{0.85}{192} &\\boldres{\\scalebox{0.85}{0.237}}&\\boldres{\\scalebox{0.85}{0.299}}&\\scalebox{0.85}{0.255}&\\scalebox{0.85}{0.314}&\\scalebox{0.85}{0.249}&\\scalebox{0.85}{0.309}&\\scalebox{0.85}{0.414}&\\scalebox{0.85}{0.492}&\\scalebox{0.85}{0.284}&\\scalebox{0.85}{0.361}&\\secondres{\\scalebox{0.85}{0.248}}&\\secondres{\\scalebox{0.85}{0.305}}&\\scalebox{0.85}{0.284}&\\scalebox{0.85}{0.361}\n    &\\scalebox{0.85}{0.269} &\\scalebox{0.85}{0.328} &\\scalebox{0.85}{0.280} &\\scalebox{0.85}{0.339} &\\scalebox{0.85}{0.281} &\\scalebox{0.85}{0.340} &\\scalebox{0.85}{0.533} &\\scalebox{0.85}{0.563}\n    \\\\\n    & \\scalebox{0.85}{336} &\\boldres{\\scalebox{0.85}{0.298}}&\\boldres{\\scalebox{0.85}{0.340}}&\\secondres{\\scalebox{0.85}{0.309}}&\\scalebox{0.85}{0.347}&\\scalebox{0.85}{0.321}&\\scalebox{0.85}{0.351}&\\scalebox{0.85}{0.597}&\\scalebox{0.85}{0.542}&\\scalebox{0.85}{0.381}&\\scalebox{0.85}{0.429}&\\secondres{\\scalebox{0.85}{0.309}}&\\secondres{\\scalebox{0.85}{0.343}}&\\scalebox{0.85}{0.382}&\\scalebox{0.85}{0.429}\n    &\\scalebox{0.85}{0.325} &\\scalebox{0.85}{0.366} &\\scalebox{0.85}{0.334} &\\scalebox{0.85}{0.361} &\\scalebox{0.85}{0.339} &\\scalebox{0.85}{0.372} &\\scalebox{0.85}{1.363} &\\scalebox{0.85}{0.887}\n    \\\\\n    & \\scalebox{0.85}{720} &\\boldres{\\scalebox{0.85}{0.391}}&\\boldres{\\scalebox{0.85}{0.396}}&\\scalebox{0.85}{0.412}&\\scalebox{0.85}{0.404}&\\secondres{\\scalebox{0.85}{0.408}}&\\scalebox{0.85}{0.403}&\\scalebox{0.85}{1.730}&\\scalebox{0.85}{1.042}&\\scalebox{0.85}{0.549}&\\scalebox{0.85}{0.522}&\\scalebox{0.85}{0.410}&\\secondres{\\scalebox{0.85}{0.400}}&\\scalebox{0.85}{0.558}&\\scalebox{0.85}{0.525}\n     &\\scalebox{0.85}{0.421} &\\scalebox{0.85}{0.415} &\\scalebox{0.85}{0.417} &\\scalebox{0.85}{0.413} &\\scalebox{0.85}{0.433} &\\scalebox{0.85}{0.432} &\\scalebox{0.85}{3.379} &\\scalebox{0.85}{1.338}\n     \\\\\n    \\cmidrule(lr){2-24}\n    &\\scalebox{0.85}{Avg} &\\boldres{\\scalebox{0.85}{0.275}}&\\boldres{\\scalebox{0.85}{0.323}}&\\scalebox{0.85}{0.290}&\\scalebox{0.85}{0.334}&\\scalebox{0.85}{0.291}&\\scalebox{0.85}{0.333}&\\scalebox{0.85}{0.757}&\\scalebox{0.85}{0.610}&\\scalebox{0.85}{0.353}&\\scalebox{0.85}{0.402}&\\secondres{\\scalebox{0.85}{0.287}}&\\secondres{\\scalebox{0.85}{0.329}}&\\scalebox{0.85}{0.354}&\\scalebox{0.85}{0.402} &\\scalebox{0.85}{0.305} &\\scalebox{0.85}{0.349} &\\scalebox{0.85}{0.306} &\\scalebox{0.85}{0.347} &\\scalebox{0.85}{0.327} &\\scalebox{0.85}{0.371} &\\scalebox{0.85}{1.410} &\\scalebox{0.85}{0.810}\\\\\n    % \\midrule\n    \n    % \\multicolumn{2}{c}{\\scalebox{0.85}{{$1^{\\text{st}}$ Count}}}&\\scalebox{0.85}{65} \\\\\n    \\bottomrule\n  \\end{tabular}\n    \\end{small}\n  \\end{threeparttable}\n  }\n\\end{table}",
            "tab:long_full_forecasting_results": "\\begin{table}[htbp]\n  \\caption{Experiment results under hyperparameter searching for the long-term forecasting task. \\emph{Avg} is averaged from all four prediction lengths.}\\label{tab:long_full_forecasting_results}\n  \\vskip 0.05in\n  \\centering\n  \\resizebox{1.0\\columnwidth}{!}{\n  \\begin{threeparttable}\n  \\begin{small}\n  \\renewcommand{\\multirowsetup}{\\centering}\n  \\setlength{\\tabcolsep}{1pt}\n  \\begin{tabular}{c|c|cc|cc|cc|cc|cc|cc|cc|cc|cc|cc|cc}\n    \\toprule\n    \\multicolumn{2}{c}{\\multirow{2}{*}{Models}} &\n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{0.8}{\\textbf{TimeMixer}}}} &\n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{0.8}{PatchTST}}} &\n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{0.8}{TimesNet}}} &\n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{0.8}{Crossformer}}} &\n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{0.8}{MICN}}} &\n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{0.8}{FiLM}}} & \n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{0.8}{DLinear}}} &\n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{0.8}{FEDformer}}} & \n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{0.8}{Stationary}}} & \n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{0.8}{Autoformer}}} &\n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{0.8}{Informer}}} \\\\\n    \\multicolumn{2}{c}{} & \\multicolumn{2}{c}{\\scalebox{0.8}{(\\textbf{Ours})}} &\n    \\multicolumn{2}{c}{\\scalebox{0.8}{\\citeyear{patchtst}}} &\n    \\multicolumn{2}{c}{\\scalebox{0.8}{\\citeyear{wu2022timesnet}}}&\n    \\multicolumn{2}{c}{\\scalebox{0.8}{\\citeyear{zhang2023crossformer}}}&\n    \\multicolumn{2}{c}{\\scalebox{0.8}{\\citeyear{wang2023micn}}}&\n    \\multicolumn{2}{c}{\\scalebox{0.8}{\\citeyear{zhou2022film}}}&\n    \\multicolumn{2}{c}{\\scalebox{0.8}{\\citeyear{dlinear}}}&\n    \\multicolumn{2}{c}{\\scalebox{0.8}{\\citeyear{zhou2022fedformer}}}&\n    \\multicolumn{2}{c}{\\scalebox{0.8}{\\citeyear{Liu2022NonstationaryTR}}}&\n    \\multicolumn{2}{c}{\\scalebox{0.8}{\\citeyear{wu2021autoformer}}}&\n    \\multicolumn{2}{c}{\\scalebox{0.8}{\\citeyear{haoyietal-informer-2021}}}\n\n    \n    \\\\\n    \\cmidrule(lr){3-4} \\cmidrule(lr){5-6}\\cmidrule(lr){7-8} \\cmidrule(lr){9-10}\\cmidrule(lr){11-12}\\cmidrule(lr){13-14}\\cmidrule(lr){15-16}\\cmidrule(lr){17-18}\\cmidrule(lr){19-20} \\cmidrule(lr){21-22} \\cmidrule(lr){23-24}\n    \\multicolumn{2}{c}{Metric} & \\scalebox{0.78}{MSE} & \\scalebox{0.78}{MAE} & \\scalebox{0.78}{MSE} & \\scalebox{0.78}{MAE} & \\scalebox{0.78}{MSE} & \\scalebox{0.78}{MAE} & \\scalebox{0.78}{MSE} & \\scalebox{0.78}{MAE} & \\scalebox{0.78}{MSE} & \\scalebox{0.78}{MAE} & \\scalebox{0.78}{MSE} & \\scalebox{0.78}{MAE} & \\scalebox{0.78}{MSE} & \\scalebox{0.78}{MAE} & \\scalebox{0.78}{MSE} & \\scalebox{0.78}{MAE} & \\scalebox{0.78}{MSE} & \\scalebox{0.78}{MAE} & \\scalebox{0.78}{MSE} & \\scalebox{0.78}{MAE} & \\scalebox{0.78}{MSE} & \\scalebox{0.78}{MAE}\\\\\n    \\toprule\n\n    \\multirow{5}{*}{\\rotatebox{90}{\\scalebox{0.95}{Weather}}} \n    & \\scalebox{0.78}{96} &\\boldres{\\scalebox{0.78}{0.147}}&\\boldres{\\scalebox{0.78}{0.197}}&\\secondres{\\scalebox{0.78}{0.149}}&\\secondres{\\scalebox{0.78}{0.198}}&\\scalebox{0.78}{0.172}&\\scalebox{0.78}{0.220}&\\scalebox{0.78}{0.232}&\\scalebox{0.78}{0.302}&\\scalebox{0.78}{0.161}&\\scalebox{0.78}{0.229}&\\scalebox{0.78}{0.199}&\\scalebox{0.78}{0.262}&\\scalebox{0.78}{0.176}&\\scalebox{0.78}{0.237}&\\scalebox{0.78}{0.217}&\\scalebox{0.78}{0.296}&\\scalebox{0.78}{0.173}&\\scalebox{0.78}{0.223}&\\scalebox{0.78}{0.266}&\\scalebox{0.78}{0.336}&\\scalebox{0.78}{0.300}&\\scalebox{0.78}{0.384}\\\\\n    & \\scalebox{0.78}{192} &\\boldres{\\scalebox{0.78}{0.189}}&\\boldres{\\scalebox{0.78}{0.239}}&\\secondres{\\scalebox{0.78}{0.194}}&\\secondres{\\scalebox{0.78}{0.241}}&\\scalebox{0.78}{0.219}&\\scalebox{0.78}{0.261}&\\scalebox{0.78}{0.371}&\\scalebox{0.78}{0.410}&\\scalebox{0.78}{0.220}&\\scalebox{0.78}{0.281}&\\scalebox{0.78}{0.228}&\\scalebox{0.78}{0.288}&\\scalebox{0.78}{0.220}&\\scalebox{0.78}{0.282}&\\scalebox{0.78}{0.276}&\\scalebox{0.78}{0.336}&\\scalebox{0.78}{0.245}&\\scalebox{0.78}{0.285}&\\scalebox{0.78}{0.307}&\\scalebox{0.78}{0.367}&\\scalebox{0.78}{0.598}&\\scalebox{0.78}{0.544}\\\\\n    & \\scalebox{0.78}{336} &\\boldres{\\scalebox{0.78}{0.241}}&\\boldres{\\scalebox{0.78}{0.280}}&\\scalebox{0.78}{0.306}&\\secondres{\\scalebox{0.78}{0.282}}&\\secondres{\\scalebox{0.78}{0.246}}&\\scalebox{0.78}{0.337}&\\scalebox{0.78}{0.495}&\\scalebox{0.78}{0.515}&\\scalebox{0.78}{0.278}&\\scalebox{0.78}{0.331}&\\scalebox{0.78}{0.267}&\\scalebox{0.78}{0.323}&\\scalebox{0.78}{0.265}&\\scalebox{0.78}{0.319}&\\scalebox{0.78}{0.339}&\\scalebox{0.78}{0.380}&\\scalebox{0.78}{0.321}&\\scalebox{0.78}{0.338}&\\scalebox{0.78}{0.359}&\\scalebox{0.78}{0.395}&\\scalebox{0.78}{0.578}&\\scalebox{0.78}{0.523}\\\\\n    & \\scalebox{0.78}{720} &\\boldres{\\scalebox{0.78}{0.310}}&\\boldres{\\scalebox{0.78}{0.330}}&\\scalebox{0.78}{0.314}&\\secondres{\\scalebox{0.78}{0.334}}&\\scalebox{0.78}{0.365}&\\scalebox{0.78}{0.359}&\\scalebox{0.78}{0.526}&\\scalebox{0.78}{0.542}&\\secondres{\\scalebox{0.78}{0.311}}&\\scalebox{0.78}{0.356}&\\scalebox{0.78}{0.319}&\\scalebox{0.78}{0.361}&\\scalebox{0.78}{0.323}&\\scalebox{0.78}{0.362}&\\scalebox{0.78}{0.403}&\\scalebox{0.78}{0.428}&\\scalebox{0.78}{0.414}&\\scalebox{0.78}{0.410}&\\scalebox{0.78}{0.419}&\\scalebox{0.78}{0.428}&\\scalebox{0.78}{1.059}&\\scalebox{0.78}{0.741}\n    \\\\\n    \\cmidrule(lr){2-24}\n    & \\scalebox{0.78}{Avg} &\\boldres{\\scalebox{0.78}{0.222}}&\\boldres{\\scalebox{0.78}{0.262}}&\\secondres{\\scalebox{0.78}{0.241}}&\\secondres{\\scalebox{0.78}{0.264}}&\\scalebox{0.78}{0.251}&\\scalebox{0.78}{0.294}&\\scalebox{0.78}{0.406}&\\scalebox{0.78}{0.442}&\\scalebox{0.78}{0.242}&\\scalebox{0.78}{0.299}&\\scalebox{0.78}{0.253}&\\scalebox{0.78}{0.309}&\\scalebox{0.78}{0.246}&\\scalebox{0.78}{0.300}&\\scalebox{0.78}{0.309}&\\scalebox{0.78}{0.360}&\\scalebox{0.78}{0.288}&\\scalebox{0.78}{0.314}&\\scalebox{0.78}{0.338}&\\scalebox{0.78}{0.382}&\\scalebox{0.78}{0.634}&\\scalebox{0.78}{0.548}\\\\\n    \\midrule\n\n    \\multirow{5}{*}{\\rotatebox{90}{\\scalebox{0.95}{Solar-Energy}}} \n    & \\scalebox{0.78}{96}  &\\boldres{\\scalebox{0.78}{0.167}}&\\boldres{\\scalebox{0.78}{0.220}}&\\scalebox{0.78}{0.224}&\\scalebox{0.78}{0.278}&\\scalebox{0.78}{0.219}&\\scalebox{0.78}{0.314}&\\secondres{\\scalebox{0.78}{0.181}}&\\secondres{\\scalebox{0.78}{0.240}}&\\scalebox{0.78}{0.188}&\\scalebox{0.78}{0.252}&\\scalebox{0.78}{0.320}&\\scalebox{0.78}{0.339}&\\scalebox{0.78}{0.289}&\\scalebox{0.78}{0.377}&\\scalebox{0.78}{0.201}&\\scalebox{0.78}{0.304}&\\scalebox{0.78}{0.321}&\\scalebox{0.78}{0.380}&\\scalebox{0.78}{0.456}&\\scalebox{0.78}{0.446}&\\scalebox{0.78}{0.200}&\\scalebox{0.78}{0.247}\n    \\\\\n    & \\scalebox{0.78}{192} &\\boldres{\\scalebox{0.78}{0.187}}&\\boldres{\\scalebox{0.78}{0.249}}&\\scalebox{0.78}{0.253}&\\scalebox{0.78}{0.298}&\\scalebox{0.78}{0.231}&\\scalebox{0.78}{0.322}&\\secondres{\\scalebox{0.78}{0.196}}&\\scalebox{0.78}{0.252}&\\scalebox{0.78}{0.215}&\\scalebox{0.78}{0.280}&\\scalebox{0.78}{0.360}&\\scalebox{0.78}{0.362}&\\scalebox{0.78}{0.319}&\\scalebox{0.78}{0.397}&\\scalebox{0.78}{0.237}&\\scalebox{0.78}{0.337}&\\scalebox{0.78}{0.346}&\\scalebox{0.78}{0.369}&\\scalebox{0.78}{0.588}&\\scalebox{0.78}{0.561}&\\scalebox{0.78}{0.220}&\\secondres{\\scalebox{0.78}{0.251}}\n    \\\\\n    & \\scalebox{0.78}{336} &\\boldres{\\scalebox{0.78}{0.200}}&\\secondres{\\scalebox{0.78}{0.258}}&\\scalebox{0.78}{0.273}&\\scalebox{0.78}{0.306}&\\scalebox{0.78}{0.246}&\\scalebox{0.78}{0.337}&\\secondres{\\scalebox{0.78}{0.216}}&\\boldres{\\scalebox{0.78}{0.243}}&\\scalebox{0.78}{0.222}&\\scalebox{0.78}{0.267}&\\scalebox{0.78}{0.398}&\\scalebox{0.78}{0.375}&\\scalebox{0.78}{0.352}&\\scalebox{0.78}{0.415}&\\scalebox{0.78}{0.254}&\\scalebox{0.78}{0.362}&\\scalebox{0.78}{0.357}&\\scalebox{0.78}{0.387}&\\scalebox{0.78}{0.595}&\\scalebox{0.78}{0.588}&\\scalebox{0.78}{0.260}&\\scalebox{0.78}{0.287}\n    \\\\\n    & \\scalebox{0.78}{720} &\\boldres{\\scalebox{0.78}{0.215}}&\\boldres{\\scalebox{0.78}{0.250}}&\\scalebox{0.78}{0.272}&\\scalebox{0.78}{0.308}&\\scalebox{0.78}{0.280}&\\scalebox{0.78}{0.363}&\\secondres{\\scalebox{0.78}{0.220}}&\\secondres{\\scalebox{0.78}{0.256}}&\\scalebox{0.78}{0.226}&\\scalebox{0.78}{0.264}&\\scalebox{0.78}{0.399}&\\scalebox{0.78}{0.368}&\\scalebox{0.78}{0.356}&\\scalebox{0.78}{0.412}&\\scalebox{0.78}{0.280}&\\scalebox{0.78}{0.397}&\\scalebox{0.78}{0.335}&\\scalebox{0.78}{0.384}&\\scalebox{0.78}{0.733}&\\scalebox{0.78}{0.633}&\\scalebox{0.78}{0.244}&\\scalebox{0.78}{0.301}\n    \\\\\n    \\cmidrule(lr){2-24}\n    & \\scalebox{0.78}{Avg} &\\boldres{\\scalebox{0.78}{0.192}}&\\boldres{\\scalebox{0.78}{0.244}}&\\scalebox{0.78}{0.256}&\\scalebox{0.78}{0.298}&\\scalebox{0.78}{0.244}&\\scalebox{0.78}{0.334}&\\secondres{\\scalebox{0.78}{0.204}}&\\secondres{\\scalebox{0.78}{0.248}}&\\scalebox{0.78}{0.213}&\\scalebox{0.78}{0.266}&\\scalebox{0.78}{0.369}&\\scalebox{0.78}{0.361}&\\scalebox{0.78}{0.329}&\\scalebox{0.78}{0.400}&\\scalebox{0.78}{0.243}&\\scalebox{0.78}{0.350}&\\scalebox{0.78}{0.340}&\\scalebox{0.78}{0.380}&\\scalebox{0.78}{0.593}&\\scalebox{0.78}{0.557}&\\scalebox{0.78}{0.231}&\\scalebox{0.78}{0.272}\\\\\n    \\midrule\n    \n    \\multirow{5}{*}{\\rotatebox{90}{\\scalebox{0.95}{Electricity}}} \n    & \\scalebox{0.78}{96}  \n    &\\boldres{\\scalebox{0.78}{0.129}}&\\secondres{\\scalebox{0.78}{0.224}}&\\boldres{\\scalebox{0.78}{0.129}}&\\boldres{\\scalebox{0.78}{0.222}}&\\scalebox{0.78}{0.168}&\\scalebox{0.78}{0.272}&\\scalebox{0.78}{0.150}&\\scalebox{0.78}{0.251}&\\scalebox{0.78}{0.164}&\\scalebox{0.78}{0.269}&\\scalebox{0.78}{0.154}&\\scalebox{0.78}{0.267}&\\secondres{\\scalebox{0.78}{0.140}}&\\scalebox{0.78}{0.237}&\\scalebox{0.78}{0.193}&\\scalebox{0.78}{0.308}&\\scalebox{0.78}{0.169}&\\scalebox{0.78}{0.273}&\\scalebox{0.78}{0.201}&\\scalebox{0.78}{0.317}&\\scalebox{0.78}{0.274}&\\scalebox{0.78}{0.368}\n    \\\\\n    & \\scalebox{0.78}{192} \n    &\\boldres{\\scalebox{0.78}{0.140}} &\\boldres{\\scalebox{0.78}{0.220}} &\\secondres{\\scalebox{0.78}{0.147}} & \\secondres{\\scalebox{0.78}{0.240}} & \\scalebox{0.78}{0.184} \n    & \\scalebox{0.78}{0.322} &\\scalebox{0.78}{0.161} & \\scalebox{0.78}{0.260}& \\scalebox{0.78}{0.177} & \\scalebox{0.78}{0.285} &\n    \\scalebox{0.78}{0.164} & \\scalebox{0.78}{0.258} & \\scalebox{0.78}{0.153} & \\scalebox{0.78}{0.249} &\\scalebox{0.78}{0.201} & \\scalebox{0.78}{0.315} & \\scalebox{0.78}{0.182} & \\scalebox{0.78}{0.286} &\\scalebox{0.78}{0.222} & \\scalebox{0.78}{0.334} &\\scalebox{0.78}{0.296} & \\scalebox{0.78}{0.386}\n    \\\\\n    & \\scalebox{0.78}{336} \n    &\\boldres{\\scalebox{0.78}{0.161}} &\\boldres{\\scalebox{0.78}{0.255}} &\\secondres{\\scalebox{0.78}{0.163}} &\\secondres{\\scalebox{0.78}{0.259}} & \\scalebox{0.78}{0.198} & \\scalebox{0.78}{0.300} &\\scalebox{0.78}{0.182} & \\scalebox{0.78}{0.281} & \\scalebox{0.78}{0.193} & \\scalebox{0.78}{0.304}  & \\scalebox{0.78}{0.188} & \\scalebox{0.78}{0.283}  & \\scalebox{0.78}{0.169} & \\scalebox{0.78}{0.267} &\\scalebox{0.78}{0.214} & \\scalebox{0.78}{0.329} & \\scalebox{0.78}{0.200}  & \\scalebox{0.78}{0.304} &\\scalebox{0.78}{0.231} & \\scalebox{0.78}{0.338} &\\scalebox{0.78}{0.300} & \\scalebox{0.78}{0.394}\n    \\\\\n    & \\scalebox{0.78}{720} \n    &\\boldres{\\scalebox{0.78}{0.194}} &\\boldres{\\scalebox{0.78}{0.287}} &\\secondres{\\scalebox{0.78}{0.197}} &\\secondres{\\scalebox{0.78}{0.290}} & \\scalebox{0.78}{0.220} & \\scalebox{0.78}{0.320} &\\scalebox{0.78}{0.251} & \\scalebox{0.78}{0.339} & \\scalebox{0.78}{0.212} & \\scalebox{0.78}{0.321} & \\scalebox{0.78}{0.236} & \\scalebox{0.78}{0.332} & \\scalebox{0.78}{0.203} & \\scalebox{0.78}{0.301} &\\scalebox{0.78}{0.246} & \\scalebox{0.78}{0.355} & \\scalebox{0.78}{0.222} & \\scalebox{0.78}{0.321}&\\scalebox{0.78}{0.254} & \\scalebox{0.78}{0.361} &\\scalebox{0.78}{0.373} & \\scalebox{0.78}{0.439} \n    \\\\\n    \\cmidrule(lr){2-24}\n    & \\scalebox{0.78}{Avg} \n    &\\boldres{\\scalebox{0.78}{0.156}} &\\boldres{\\scalebox{0.78}{0.246} } \n    &\\secondres{\\scalebox{0.78}{0.159}} &\\secondres{\\scalebox{0.78}{0.253}} \n    &\\scalebox{0.78}{0.192} &\\scalebox{0.78}{0.295}\n    &\\scalebox{0.78}{0.186} & \\scalebox{0.78}{0.283}  \n    &\\scalebox{0.78}{0.186} & \\scalebox{0.78}{0.295} &\\scalebox{0.78}{0.186} &\\scalebox{0.78}{0.285} &\\scalebox{0.78}{0.166} &\\scalebox{0.78}{0.264} &\\scalebox{0.78}{0.214} &\\scalebox{0.78}{0.321} &\\scalebox{0.78}{0.213} & \\scalebox{0.78}{0.296} &\\scalebox{0.78}{0.227} & \\scalebox{0.78}{0.338}&\\scalebox{0.78}{0.311} & \\scalebox{0.78}{0.397}\\\\\n    \\midrule\n    \\multirow{5}{*}{\\rotatebox{90}{\\scalebox{0.95}{Traf\ufb01c}}} \n    & \\scalebox{0.78}{96}  &\\boldres{\\scalebox{0.78}{0.360}}&\\boldres{\\scalebox{0.78}{0.249}}&\\boldres{\\scalebox{0.78}{0.360}}&\\boldres{\\scalebox{0.78}{0.249}}&\\scalebox{0.78}{0.593}&\\scalebox{0.78}{0.321}&\\scalebox{0.78}{0.514}&\\secondres{\\scalebox{0.78}{0.267}}&\\scalebox{0.78}{0.519}&\\scalebox{0.78}{0.309}&\\scalebox{0.78}{0.416}&\\scalebox{0.78}{0.294}&\\secondres{\\scalebox{0.78}{0.410}}&\\scalebox{0.78}{0.282}&\\scalebox{0.78}{0.587}&\\scalebox{0.78}{0.366}&\\scalebox{0.78}{0.612}&\\scalebox{0.78}{0.338}&\\scalebox{0.78}{0.613}&\\scalebox{0.78}{0.388}&\\scalebox{0.78}{0.719}&\\scalebox{0.78}{0.391}\n    \\\\\n    & \\scalebox{0.78}{192} &\\boldres{\\scalebox{0.78}{0.375}}&\\boldres{\\scalebox{0.78}{0.250}}&\\secondres{\\scalebox{0.78}{0.379}}&\\scalebox{0.78}{0.256}&\\scalebox{0.78}{0.617}&\\scalebox{0.78}{0.336}&\\scalebox{0.78}{0.549}&\\secondres{\\scalebox{0.78}{0.252}}&\\scalebox{0.78}{0.537}&\\scalebox{0.78}{0.315}&\\scalebox{0.78}{0.408}&\\scalebox{0.78}{0.288}&\\scalebox{0.78}{0.423}&\\scalebox{0.78}{0.287}&\\scalebox{0.78}{0.604}&\\scalebox{0.78}{0.373}&\\scalebox{0.78}{0.613}&\\scalebox{0.78}{0.340}&\\scalebox{0.78}{0.616}&\\scalebox{0.78}{0.382}&\\scalebox{0.78}{0.696}&\\scalebox{0.78}{0.379}\n    \\\\\n    & \\scalebox{0.78}{336} \n    &\\boldres{\\scalebox{0.78}{0.385}}&\\secondres{\\scalebox{0.78}{0.270}}&\\secondres{\\scalebox{0.78}{0.392}}&\\boldres{\\scalebox{0.78}{0.264}}&\\scalebox{0.78}{0.629}&\\scalebox{0.78}{0.336}&\\scalebox{0.78}{0.530}&\\scalebox{0.78}{0.300}&\\scalebox{0.78}{0.534}&\\scalebox{0.78}{0.313}&\\scalebox{0.78}{0.425}&\\scalebox{0.78}{0.298}&\\scalebox{0.78}{0.436}&\\scalebox{0.78}{0.296}&\\scalebox{0.78}{0.621}&\\scalebox{0.78}{0.383}&\\scalebox{0.78}{0.618}&\\scalebox{0.78}{0.328}&\\scalebox{0.78}{0.622}&\\scalebox{0.78}{0.337}&\\scalebox{0.78}{0.777}&\\scalebox{0.78}{0.420}\n    \\\\\n    & \\scalebox{0.78}{720} &\\boldres{\\scalebox{0.78}{0.430}}&\\boldres{\\scalebox{0.78}{0.281}}&\\secondres{\\scalebox{0.78}{0.432}}&\\secondres{\\scalebox{0.78}{0.286}}&\\scalebox{0.78}{0.640}&\\scalebox{0.78}{0.350}&\\scalebox{0.78}{0.573}&\\scalebox{0.78}{0.313}&\\scalebox{0.78}{0.577}&\\scalebox{0.78}{0.325}&\\scalebox{0.78}{0.520}&\\scalebox{0.78}{0.353}&\\scalebox{0.78}{0.466}&\\scalebox{0.78}{0.315}&\\scalebox{0.78}{0.626}&\\scalebox{0.78}{0.382}&\\scalebox{0.78}{0.653}&\\scalebox{0.78}{0.355}&\\scalebox{0.78}{0.660}&\\scalebox{0.78}{0.408}&\\scalebox{0.78}{0.864}&\\scalebox{0.78}{0.472}\n    \\\\\n    \\cmidrule(lr){2-24}\n   & \\scalebox{0.78}{Avg} &\\boldres{\\scalebox{0.78}{0.387}}&\\boldres{\\scalebox{0.78}{0.262}}&\\secondres{\\scalebox{0.78}{0.391}}&\\secondres{\\scalebox{0.78}{0.264}}&\\scalebox{0.78}{0.620}&\\scalebox{0.78}{0.336}&\\scalebox{0.78}{0.542}&\\scalebox{0.78}{0.283}&\\scalebox{0.78}{0.541}&\\scalebox{0.78}{0.315}&\\scalebox{0.78}{0.442}&\\scalebox{0.78}{0.308}&\\scalebox{0.78}{0.434}&\\scalebox{0.78}{0.295}&\\scalebox{0.78}{0.609}&\\scalebox{0.78}{0.376}&\\scalebox{0.78}{0.624}&\\scalebox{0.78}{0.340}&\\scalebox{0.78}{0.628}&\\scalebox{0.78}{0.379}&\\scalebox{0.78}{0.764}&\\scalebox{0.78}{0.415}\\\\\n    \\midrule\n\n    % \\multirow{5}{*}{\\rotatebox{90}{\\scalebox{0.95}{Exchange}}} \n    % & \\scalebox{0.78}{96} &\\secondres{\\scalebox{0.78}{0.085}}&\\scalebox{0.78}{0.207}&\\scalebox{0.78}{0.087}&\\scalebox{0.78}{0.211}&\\scalebox{0.78}{0.107}&\\scalebox{0.78}{0.234}&\\scalebox{0.78}{0.256}&\\scalebox{0.78}{0.367}&\\scalebox{0.78}{0.102}&\\scalebox{0.78}{0.235}&\\scalebox{0.78}{0.086}&\\secondres{\\scalebox{0.78}{0.204}}&\\boldres{\\scalebox{0.78}{0.081}}&\\boldres{\\scalebox{0.78}{0.203}}&\\scalebox{0.78}{0.148}&\\scalebox{0.78}{0.278}&\\scalebox{0.78}{0.111}&\\scalebox{0.78}{0.237}&\\scalebox{0.78}{0.197}&\\scalebox{0.78}{0.323}&\\scalebox{0.78}{0.847}&\\scalebox{0.78}{0.752}\\\\\n    % & \\scalebox{0.78}{192} &\\secondres{\\scalebox{0.78}{0.166}}&\\scalebox{0.78}{0.308}&\\scalebox{0.78}{0.182}&\\boldres{\\scalebox{0.78}{0.240}}&\\scalebox{0.78}{0.226}&\\scalebox{0.78}{0.344}&\\scalebox{0.78}{0.469}&\\scalebox{0.78}{0.508}&\\scalebox{0.78}{0.172}&\\scalebox{0.78}{0.316}&\\scalebox{0.78}{0.188}&\\secondres{\\scalebox{0.78}{0.292}}&\\boldres{\\scalebox{0.78}{0.157}}&\\scalebox{0.78}{0.293}&\\scalebox{0.78}{0.271}&\\scalebox{0.78}{0.380}&\\scalebox{0.78}{0.219}&\\scalebox{0.78}{0.335}&\\scalebox{0.78}{0.300}&\\scalebox{0.78}{0.369}&\\scalebox{0.78}{1.204}&\\scalebox{0.78}{0.895}\\\\\n    % & \\scalebox{0.78}{336} &\\scalebox{0.78}{0.313}&\\scalebox{0.78}{0.427}&\\scalebox{0.78}{0.391}&\\scalebox{0.78}{0.458}&\\scalebox{0.78}{0.367}&\\boldres{\\scalebox{0.78}{0.348}}&\\scalebox{0.78}{1.267}&\\scalebox{0.78}{0.882}&\\boldres{\\scalebox{0.78}{0.272}}&\\secondres{\\scalebox{0.78}{0.407}}&\\scalebox{0.78}{0.356}&\\scalebox{0.78}{0.433}&\\secondres{\\scalebox{0.78}{0.305}}&\\scalebox{0.78}{0.414}&\\scalebox{0.78}{0.460}&\\scalebox{0.78}{0.500}&\\scalebox{0.78}{0.421}&\\scalebox{0.78}{0.476}&\\scalebox{0.78}{0.509}&\\scalebox{0.78}{0.524}&\\scalebox{0.78}{1.672}&\\scalebox{0.78}{1.036}\\\\\n    % & \\scalebox{0.78}{720} &\\scalebox{0.78}{0.822}&\\scalebox{0.78}{0.666}&\\scalebox{0.78}{0.936}&\\scalebox{0.78}{0.699}&\\scalebox{0.78}{0.964}&\\scalebox{0.78}{0.746}&\\scalebox{0.78}{1.766}&\\scalebox{0.78}{1.068}&\\secondres{\\scalebox{0.78}{0.714}}&\\secondres{\\scalebox{0.78}{0.658}}&\\scalebox{0.78}{0.727}&\\scalebox{0.78}{0.669}&\\boldres{\\scalebox{0.78}{0.643}}&\\boldres{\\scalebox{0.78}{0.601}}&\\scalebox{0.78}{1.195}&\\scalebox{0.78}{0.841}&\\scalebox{0.78}{1.092}&\\scalebox{0.78}{0.769}&\\scalebox{0.78}{1.447}&\\scalebox{0.78}{0.941}&\\scalebox{0.78}{2.478}&\\scalebox{0.78}{1.310}\\\\\n    % \\cmidrule(lr){2-24}\n    % & \\scalebox{0.78}{Avg} &\\scalebox{0.78}{0.347}&\\scalebox{0.78}{0.402}&\\scalebox{0.78}{0.399}&\\scalebox{0.78}{0.402}&\\scalebox{0.78}{0.416}&\\scalebox{0.78}{0.418}&\\scalebox{0.78}{0.940}&\\scalebox{0.78}{0.706}&\\scalebox{0.78}{0.714}&\\scalebox{0.78}{0.658}&\\secondres{\\scalebox{0.78}{0.339}}&\\secondres{\\scalebox{0.78}{0.400}}&\\boldres{\\scalebox{0.78}{0.296}}&\\boldres{\\scalebox{0.78}{0.378}}&\\scalebox{0.78}{0.518}&\\scalebox{0.78}{0.500}&\\scalebox{0.78}{0.461}&\\scalebox{0.78}{0.454}&\\scalebox{0.78}{0.613}&\\scalebox{0.78}{0.539}&\\scalebox{0.78}{1.550}&\\scalebox{0.78}{0.998}\\\\\n    % \\midrule\n\n    \\multirow{5}{*}{\\rotatebox{90}{\\scalebox{0.95}{ETTh1}}} \n    & \\scalebox{0.78}{96} &\\boldres{\\scalebox{0.78}{0.361}}&\\boldres{\\scalebox{0.78}{0.390}}&\\secondres{\\scalebox{0.78}{0.370}}&\\scalebox{0.78}{0.400}&\\scalebox{0.78}{0.384}&\\scalebox{0.78}{0.402}&\\scalebox{0.78}{0.418}&\\scalebox{0.78}{0.438}&\\scalebox{0.78}{0.421}&\\scalebox{0.78}{0.431}&\\scalebox{0.78}{0.422}&\\scalebox{0.78}{0.432}&\\scalebox{0.78}{0.375}&\\secondres{\\scalebox{0.78}{0.399}}&\\scalebox{0.78}{0.376}&\\scalebox{0.78}{0.419}&\\scalebox{0.78}{0.513}&\\scalebox{0.78}{0.491}&\\scalebox{0.78}{0.449}&\\scalebox{0.78}{0.459}&\\scalebox{0.78}{0.865}&\\scalebox{0.78}{0.713}\\\\\n    & \\scalebox{0.78}{192} &\\secondres{\\scalebox{0.78}{0.409}}&\\boldres{\\scalebox{0.78}{0.414}}&\\scalebox{0.78}{0.413}&\\scalebox{0.78}{0.429}&\\scalebox{0.78}{0.436}&\\scalebox{0.78}{0.429}&\\scalebox{0.78}{0.539}&\\scalebox{0.78}{0.517}&\\scalebox{0.78}{0.474}&\\scalebox{0.78}{0.487}&\\scalebox{0.78}{0.462}&\\scalebox{0.78}{0.458}&\\boldres{\\scalebox{0.78}{0.405}}&\\secondres{\\scalebox{0.78}{0.416}}&\\scalebox{0.78}{0.420}&\\scalebox{0.78}{0.448}&\\scalebox{0.78}{0.534}&\\scalebox{0.78}{0.504}&\\scalebox{0.78}{0.500}&\\scalebox{0.78}{0.482}&\\scalebox{0.78}{1.008}&\\scalebox{0.78}{0.792}\\\\\n    & \\scalebox{0.78}{336} &\\secondres{\\scalebox{0.78}{0.430}}&\\boldres{\\scalebox{0.78}{0.429}}&\\boldres{\\scalebox{0.78}{0.422}}&\\secondres{\\scalebox{0.78}{0.440}}&\\scalebox{0.78}{0.638}&\\scalebox{0.78}{0.469}&\\scalebox{0.78}{0.709}&\\scalebox{0.78}{0.638}&\\scalebox{0.78}{0.569}&\\scalebox{0.78}{0.551}&\\scalebox{0.78}{0.501}&\\scalebox{0.78}{0.483}&\\scalebox{0.78}{0.439}&\\scalebox{0.78}{0.443}&\\scalebox{0.78}{0.459}&\\scalebox{0.78}{0.465}&\\scalebox{0.78}{0.588}&\\scalebox{0.78}{0.535}&\\scalebox{0.78}{0.521}&\\scalebox{0.78}{0.496}&\\scalebox{0.78}{1.107}&\\scalebox{0.78}{0.809}\\\\\n    & \\scalebox{0.78}{720}&\\boldres{\\scalebox{0.78}{0.445}}&\\boldres{\\scalebox{0.78}{0.460}}&\\secondres{\\scalebox{0.78}{0.447}}&\\secondres{\\scalebox{0.78}{0.468}}&\\scalebox{0.78}{0.521}&\\scalebox{0.78}{0.500}&\\scalebox{0.78}{0.733}&\\scalebox{0.78}{0.636}&\\scalebox{0.78}{0.770}&\\scalebox{0.78}{0.672}&\\scalebox{0.78}{0.544}&\\scalebox{0.78}{0.526}&\\scalebox{0.78}{0.472}&\\scalebox{0.78}{0.490}&\\scalebox{0.78}{0.506}&\\scalebox{0.78}{0.507}&\\scalebox{0.78}{0.643}&\\scalebox{0.78}{0.616}&\\scalebox{0.78}{0.514}&\\scalebox{0.78}{0.512}&\\scalebox{0.78}{1.181}&\\scalebox{0.78}{0.865}\\\\\n    \\cmidrule(lr){2-24}\n    & \\scalebox{0.78}{Avg}&\\boldres{\\scalebox{0.78}{0.411}}&\\boldres{\\scalebox{0.78}{0.423}}&\\secondres{\\scalebox{0.78}{0.413}}&\\secondres{\\scalebox{0.78}{0.434}}&\\scalebox{0.78}{0.458}&\\scalebox{0.78}{0.450}&\\scalebox{0.78}{0.600}&\\scalebox{0.78}{0.557}&\\scalebox{0.78}{0.558}&\\scalebox{0.78}{0.535}&\\scalebox{0.78}{0.482}&\\scalebox{0.78}{0.475}&\\scalebox{0.78}{0.423}&\\scalebox{0.78}{0.437}&\\scalebox{0.78}{0.440}&\\scalebox{0.78}{0.460}&\\scalebox{0.78}{0.57}&\\scalebox{0.78}{0.536}&\\scalebox{0.78}{0.496}&\\scalebox{0.78}{0.487}&\\scalebox{0.78}{1.040}&\\scalebox{0.78}{0.795}\\\\\n    \\midrule\n\n    \\multirow{5}{*}{\\rotatebox{90}{\\scalebox{0.95}{ETTh2}}} \n    & \\scalebox{0.78}{96} &\\boldres{\\scalebox{0.78}{0.271}}&\\boldres{\\scalebox{0.78}{0.330}}&\\secondres{\\scalebox{0.78}{0.274}}&\\secondres{\\scalebox{0.78}{0.337}}&\\scalebox{0.78}{0.340}&\\scalebox{0.78}{0.374}&\\scalebox{0.78}{0.425}&\\scalebox{0.78}{0.463}&\\scalebox{0.78}{0.299}&\\scalebox{0.78}{0.364}&\\scalebox{0.78}{0.323}&\\scalebox{0.78}{0.370}&\\scalebox{0.78}{0.289}&\\scalebox{0.78}{0.353}&\\scalebox{0.78}{0.346}&\\scalebox{0.78}{0.388}&\\scalebox{0.78}{0.476}&\\scalebox{0.78}{0.458}&\\scalebox{0.78}{0.358}&\\scalebox{0.78}{0.397}&\\scalebox{0.78}{3.755}&\\scalebox{0.78}{1.525}\\\\\n    & \\scalebox{0.78}{192} &\\scalebox{0.78}{0.317}&\\scalebox{0.78}{0.402}&\\secondres{\\scalebox{0.78}{0.314}}&\\secondres{\\scalebox{0.78}{0.382}}&\\boldres{\\scalebox{0.78}{0.231}}&\\boldres{\\scalebox{0.78}{0.322}}&\\scalebox{0.78}{0.473}&\\scalebox{0.78}{0.500}&\\scalebox{0.78}{0.441}&\\scalebox{0.78}{0.454}&\\scalebox{0.78}{0.391}&\\scalebox{0.78}{0.415}&\\scalebox{0.78}{0.383}&\\scalebox{0.78}{0.418}&\\scalebox{0.78}{0.429}&\\scalebox{0.78}{0.439}&\\scalebox{0.78}{0.512}&\\scalebox{0.78}{0.493}&\\scalebox{0.78}{0.456}&\\scalebox{0.78}{0.452}&\\scalebox{0.78}{5.602}&\\scalebox{0.78}{1.931}\\\\\n    & \\scalebox{0.78}{336} &\\secondres{\\scalebox{0.78}{0.332}}&\\secondres{\\scalebox{0.78}{0.396}}&\\boldres{\\scalebox{0.78}{0.329}}&\\boldres{\\scalebox{0.78}{0.384}}&\\scalebox{0.78}{0.452}&\\scalebox{0.78}{0.452}&\\scalebox{0.78}{0.581}&\\scalebox{0.78}{0.562}&\\scalebox{0.78}{0.654}&\\scalebox{0.78}{0.567}&\\scalebox{0.78}{0.415}&\\scalebox{0.78}{0.440}&\\scalebox{0.78}{0.448}&\\scalebox{0.78}{0.465}&\\scalebox{0.78}{0.496}&\\scalebox{0.78}{0.487}&\\scalebox{0.78}{0.552}&\\scalebox{0.78}{0.551}&\\scalebox{0.78}{0.482}&\\scalebox{0.78}{0.486}&\\scalebox{0.78}{4.721}&\\scalebox{0.78}{1.835}\\\\\n    & \\scalebox{0.78}{720} &\\boldres{\\scalebox{0.78}{0.342}}&\\boldres{\\scalebox{0.78}{0.408}}&\\secondres{\\scalebox{0.78}{0.379}}&\\secondres{\\scalebox{0.78}{0.422}}&\\scalebox{0.78}{0.462}&\\scalebox{0.78}{0.468}&\\scalebox{0.78}{0.775}&\\scalebox{0.78}{0.665}&\\scalebox{0.78}{0.956}&\\scalebox{0.78}{0.716}&\\scalebox{0.78}{0.441}&\\scalebox{0.78}{0.459}&\\scalebox{0.78}{0.605}&\\scalebox{0.78}{0.551}&\\scalebox{0.78}{0.463}&\\scalebox{0.78}{0.474}&\\scalebox{0.78}{0.562}&\\scalebox{0.78}{0.560}&\\scalebox{0.78}{0.515}&\\scalebox{0.78}{0.511}&\\scalebox{0.78}{3.647}&\\scalebox{0.78}{1.625}\n    \\\\\n    \\cmidrule(lr){2-24}\n    & \\scalebox{0.78}{Avg} &\\boldres{\\scalebox{0.78}{0.316}}&\\secondres{\\scalebox{0.78}{0.384}}&\\secondres{\\scalebox{0.78}{0.324}}&\\boldres{\\scalebox{0.78}{0.381}}&\\scalebox{0.78}{0.371}&\\scalebox{0.78}{0.404}&\\scalebox{0.78}{0.564}&\\scalebox{0.78}{0.548}&\\scalebox{0.78}{0.588}&\\scalebox{0.78}{0.525}&\\scalebox{0.78}{0.393}&\\scalebox{0.78}{0.421}&\\scalebox{0.78}{0.431}&\\scalebox{0.78}{0.447}&\\scalebox{0.78}{0.433}&\\scalebox{0.78}{0.447}&\\scalebox{0.78}{0.526}&\\scalebox{0.78}{0.516}&\\scalebox{0.78}{0.453}&\\scalebox{0.78}{0.462}&\\scalebox{0.78}{4.431}&\\scalebox{0.78}{1.729}\\\\\n    \\midrule\n\n    \\multirow{5}{*}{\\rotatebox{90}{\\scalebox{0.95}{ETTm1}}} \n    & \\scalebox{0.78}{96} &\\boldres{\\scalebox{0.78}{0.291}}&\\boldres{\\scalebox{0.78}{0.340}}&\\secondres{\\scalebox{0.78}{0.293}}&\\scalebox{0.78}{0.346}&\\scalebox{0.78}{0.338}&\\scalebox{0.78}{0.375}&\\scalebox{0.78}{0.361}&\\scalebox{0.78}{0.403}&\\scalebox{0.78}{0.316}&\\scalebox{0.78}{0.362}&\\scalebox{0.78}{0.302}&\\scalebox{0.78}{0.345}&\\scalebox{0.78}{0.299}&\\secondres{\\scalebox{0.78}{0.343}}&\\scalebox{0.78}{0.379}&\\scalebox{0.78}{0.419}&\\scalebox{0.78}{0.386}&\\scalebox{0.78}{0.398}&\\scalebox{0.78}{0.505}&\\scalebox{0.78}{0.475}&\\scalebox{0.78}{0.672}&\\scalebox{0.78}{0.571}\\\\\n    & \\scalebox{0.78}{192} &\\boldres{\\scalebox{0.78}{0.327}}&\\boldres{\\scalebox{0.78}{0.365}}&\\secondres{\\scalebox{0.78}{0.333}}&\\scalebox{0.78}{0.370}&\\scalebox{0.78}{0.374}&\\scalebox{0.78}{0.387}&\\scalebox{0.78}{0.387}&\\scalebox{0.78}{0.422}&\\scalebox{0.78}{0.363}&\\scalebox{0.78}{0.390}&\\scalebox{0.78}{0.338}&\\secondres{\\scalebox{0.78}{0.368}}&\\scalebox{0.78}{0.335}&\\boldres{\\scalebox{0.78}{0.365}}&\\scalebox{0.78}{0.426}&\\scalebox{0.78}{0.441}&\\scalebox{0.78}{0.459}&\\scalebox{0.78}{0.444}&\\scalebox{0.78}{0.553}&\\scalebox{0.78}{0.496}&\\scalebox{0.78}{0.795}&\\scalebox{0.78}{0.669}\\\\\n    & \\scalebox{0.78}{336} &\\boldres{\\scalebox{0.78}{0.360}}&\\boldres{\\scalebox{0.78}{0.381}}&\\secondres{\\scalebox{0.78}{0.369}}&\\scalebox{0.78}{0.392}&\\scalebox{0.78}{0.410}&\\scalebox{0.78}{0.411}&\\scalebox{0.78}{0.605}&\\scalebox{0.78}{0.572}&\\scalebox{0.78}{0.408}&\\scalebox{0.78}{0.426}&\\scalebox{0.78}{0.373}&\\scalebox{0.78}{0.388}&\\secondres{\\scalebox{0.78}{0.369}}&\\secondres{\\scalebox{0.78}{0.386}}&\\scalebox{0.78}{0.445}&\\scalebox{0.78}{0.459}&\\scalebox{0.78}{0.495}&\\scalebox{0.78}{0.464}&\\scalebox{0.78}{0.621}&\\scalebox{0.78}{0.537}&\\scalebox{0.78}{1.212}&\\scalebox{0.78}{0.871}\\\\\n    & \\scalebox{0.78}{720} &\\boldres{\\scalebox{0.78}{0.415}}&\\boldres{\\scalebox{0.78}{0.417}}&\\secondres{\\scalebox{0.78}{0.416}}&\\secondres{\\scalebox{0.78}{0.420}}&\\scalebox{0.78}{0.478}&\\scalebox{0.78}{0.450}&\\scalebox{0.78}{0.703}&\\scalebox{0.78}{0.645}&\\scalebox{0.78}{0.481}&\\scalebox{0.78}{0.476}&\\scalebox{0.78}{0.420}&\\secondres{\\scalebox{0.78}{0.420}}&\\scalebox{0.78}{0.425}&\\scalebox{0.78}{0.421}&\\scalebox{0.78}{0.543}&\\scalebox{0.78}{0.490}&\\scalebox{0.78}{0.585}&\\scalebox{0.78}{0.516}&\\scalebox{0.78}{0.671}&\\scalebox{0.78}{0.561}&\\scalebox{0.78}{1.166}&\\scalebox{0.78}{0.823}\\\\\n    \\cmidrule(lr){2-24}\n    & \\scalebox{0.78}{Avg} &\\boldres{\\scalebox{0.78}{0.348}}&\\boldres{\\scalebox{0.78}{0.375}}&\\secondres{\\scalebox{0.78}{0.353}}&\\scalebox{0.78}{0.382}&\\secondres{\\scalebox{0.78}{0.353}}&\\scalebox{0.78}{0.382}&\\scalebox{0.78}{0.514}&\\scalebox{0.78}{0.510}&\\scalebox{0.78}{0.392}&\\scalebox{0.78}{0.413}&\\scalebox{0.78}{0.358}&\\scalebox{0.78}{0.38}&\\scalebox{0.78}{0.357}&\\secondres{\\scalebox{0.78}{0.379}}&\\scalebox{0.78}{0.448}&\\scalebox{0.78}{0.452}&\\scalebox{0.78}{0.481}&\\scalebox{0.78}{0.456}&\\scalebox{0.78}{0.588}&\\scalebox{0.78}{0.517}&\\scalebox{0.78}{0.961}&\\scalebox{0.78}{0.733}\\\\\n    \\midrule\n\n    \\multirow{5}{*}{\\rotatebox{90}{\\scalebox{0.95}{ETTm2}}} \n    & \\scalebox{0.78}{96} &\\boldres{\\scalebox{0.78}{0.164}}&\\boldres{\\scalebox{0.78}{0.254}}&\\scalebox{0.78}{0.166}&\\secondres{\\scalebox{0.78}{0.256}}&\\scalebox{0.78}{0.187}&\\scalebox{0.78}{0.267}&\\scalebox{0.78}{0.275}&\\scalebox{0.78}{0.358}&\\scalebox{0.78}{0.179}&\\scalebox{0.78}{0.275}&\\secondres{\\scalebox{0.78}{0.165}}&\\secondres{\\scalebox{0.78}{0.256}}&\\scalebox{0.78}{0.167}&\\scalebox{0.78}{0.260}&\\scalebox{0.78}{0.203}&\\scalebox{0.78}{0.287}&\\scalebox{0.78}{0.192}&\\scalebox{0.78}{0.274}&\\scalebox{0.78}{0.255}&\\scalebox{0.78}{0.339}&\\scalebox{0.78}{0.365}&\\scalebox{0.78}{0.453}\\\\\n    & \\scalebox{0.78}{192} &\\secondres{\\scalebox{0.78}{0.223}}&\\boldres{\\scalebox{0.78}{0.295}}&\\secondres{\\scalebox{0.78}{0.223}}&\\secondres{\\scalebox{0.78}{0.296}}&\\scalebox{0.78}{0.249}&\\scalebox{0.78}{0.309}&\\scalebox{0.78}{0.345}&\\scalebox{0.78}{0.400}&\\scalebox{0.78}{0.307}&\\scalebox{0.78}{0.376}&\\boldres{\\scalebox{0.78}{0.222}}&\\secondres{\\scalebox{0.78}{0.296}}&\\scalebox{0.78}{0.224}&\\scalebox{0.78}{0.303}&\\scalebox{0.78}{0.269}&\\scalebox{0.78}{0.328}&\\scalebox{0.78}{0.280}&\\scalebox{0.78}{0.339}&\\scalebox{0.78}{0.281}&\\scalebox{0.78}{0.340}&\\scalebox{0.78}{0.533}&\\scalebox{0.78}{0.563}\\\\\n    & \\scalebox{0.78}{336} &\\scalebox{0.78}{0.279}&\\secondres{\\scalebox{0.78}{0.330}}&\\boldres{\\scalebox{0.78}{0.274}}&\\boldres{\\scalebox{0.78}{0.329}}&\\scalebox{0.78}{0.321}&\\scalebox{0.78}{0.351}&\\scalebox{0.78}{0.657}&\\scalebox{0.78}{0.528}&\\scalebox{0.78}{0.325}&\\scalebox{0.78}{0.388}&\\secondres{\\scalebox{0.78}{0.277}}&\\scalebox{0.78}{0.333}&\\scalebox{0.78}{0.281}&\\scalebox{0.78}{0.342}&\\scalebox{0.78}{0.325}&\\scalebox{0.78}{0.366}&\\scalebox{0.78}{0.334}&\\scalebox{0.78}{0.361}&\\scalebox{0.78}{0.339}&\\scalebox{0.78}{0.372}&\\scalebox{0.78}{1.363}&\\scalebox{0.78}{0.887}\\\\\n    & \\scalebox{0.78}{720} &\\boldres{\\scalebox{0.78}{0.359}}&\\boldres{\\scalebox{0.78}{0.383}}&\\secondres{\\scalebox{0.78}{0.362}}&\\secondres{\\scalebox{0.78}{0.385}}&\\scalebox{0.78}{0.408}&\\scalebox{0.78}{0.403}&\\scalebox{0.78}{1.208}&\\scalebox{0.78}{0.753}&\\scalebox{0.78}{0.502}&\\scalebox{0.78}{0.490}&\\scalebox{0.78}{0.371}&\\scalebox{0.78}{0.389}&\\scalebox{0.78}{0.397}&\\scalebox{0.78}{0.421}&\\scalebox{0.78}{0.421}&\\scalebox{0.78}{0.415}&\\scalebox{0.78}{0.417}&\\scalebox{0.78}{0.413}&\\scalebox{0.78}{0.422}&\\scalebox{0.78}{0.419}&\\scalebox{0.78}{3.379}&\\scalebox{0.78}{1.388}\\\\\n    \\cmidrule(lr){2-24}\n    & \\scalebox{0.78}{Avg} &\\boldres{\\scalebox{0.78}{0.256}}&\\boldres{\\scalebox{0.78}{0.315}}&\\boldres{\\scalebox{0.78}{0.256}}&\\secondres{\\scalebox{0.78}{0.317}}&\\scalebox{0.78}{0.291}&\\scalebox{0.78}{0.333}&\\scalebox{0.78}{0.621}&\\scalebox{0.78}{0.510}&\\scalebox{0.78}{0.328}&\\scalebox{0.78}{0.382}&\\secondres{\\scalebox{0.78}{0.259}}&\\scalebox{0.78}{0.319}&\\scalebox{0.78}{0.267}&\\scalebox{0.78}{0.332}&\\scalebox{0.78}{0.304}&\\scalebox{0.78}{0.349}&\\scalebox{0.78}{0.306}&\\scalebox{0.78}{0.347}&\\scalebox{0.78}{0.324}&\\scalebox{0.78}{0.368}&\\scalebox{0.78}{1.410}&\\scalebox{0.78}{0.823}\\\\\n    % \\midrule\n    \n    % \\multicolumn{2}{c}{\\scalebox{0.78}{{$1^{\\text{st}}$ Count}}}&\\scalebox{0.78}{65} \\\\\n    \\bottomrule\n  \\end{tabular}\n    \\end{small}\n  \\end{threeparttable}\n  }\n\\end{table}",
            "tab:ablation_long": "\\begin{table}[h]\n\\vspace{-5pt}\n\t\\caption{\\revise{Ablations on both Past-Decompose-Mixing (\\textit{Decompose}, \\textit{Season Mixing}, and \\textit{Trend Mixing}) and Future-Multipredictor-Mixing blocks in predict-336 setting for all long-term benchmarks.} \\ $\\nearrow$ indicates the bottom-up mixing while $\\swarrow$ indicates top-down. A check mark $\\checkmark$ and a wrong mark $\\times$ indicate with and without certain components respectively. \\ding{172} is the official design in TimeMixer.}\n\t\\label{tab:ablation_long}\n\t\\centering\n        \\vspace{3pt}\n    \\resizebox{\\columnwidth}{!}{\n\t\\begin{small}\n\t\t% \\begin{sc}\n\t\t\t\\renewcommand{\\multirowsetup}{\\centering}\n\t\t\t\\setlength{\\tabcolsep}{3.5pt}\n\t\t\t\\scalebox{1}{\n\t\t\t\\begin{tabular}{c|c|cc|c|cc|cc|cc|cc|cc|cc|cc|cc}\n\t\t\t\t\\toprule\n\t\t\t\\multirow{2}{*}{Case} &\\multirow{2}{*}{Decompose} & \\multicolumn{2}{c|}{Past mixing} & Future mixing &\\multicolumn{2}{c}{ETTh1} &\\multicolumn{2}{c}{ETTh2} &\\multicolumn{2}{c}{ETTm1}&\\multicolumn{2}{c}{ETTm2} &\\multicolumn{2}{c}{Weather} &\\multicolumn{2}{c}{Solar} &\\multicolumn{2}{c}{Electricity} &\\multicolumn{2}{c}{Traffic} \n            \\\\\n            \\cmidrule(lr){3-4} \\cmidrule(lr){5-5} \\cmidrule(lr){6-7} \\cmidrule(lr){8-9} \\cmidrule(lr){10-11} \\cmidrule(lr){12-13} \\cmidrule(lr){14-15} \\cmidrule(lr){16-17} \\cmidrule(lr){18-19} \\cmidrule(lr){20-21}\n            & & Seasonal & Trend & Multipredictor & MSE & MAE & MSE & MAE & MSE & MAE & MSE & MAE & MSE & MAE & MSE & MAE & MSE & MAE & MSE & MAE\\\\\n            \\midrule\n            \\ding{172} &$\\checkmark$ & $\\nearrow$ & $\\swarrow$ & $\\checkmark$ &\\boldres{0.484} &\\boldres{0.458} &\\boldres{0.386} &\\boldres{0.414} &\\boldres{0.390} &\\boldres{0.404} &\\boldres{0.298} &\\boldres{0.340} &\\boldres{0.251} &\\boldres{0.287} &\\boldres{0.231} &\\boldres{0.292} &\\boldres{0.185} &\\boldres{0.277} &\\boldres{0.498} &\\boldres{0.296} \\\\\n            \\midrule\n            \\ding{173} & $\\checkmark$ & $\\nearrow$ & $\\swarrow$ & $\\times$ &0.493 &0.472 &0.399 &0.426 &0.402 &0.415 &0.311 &0.357 &0.262 &0.308 &0.267 &0.339 &0.198 &0.301 &0.518 &0.337\\\\\n            \\midrule\n            \\ding{174} & $\\checkmark$ &$\\times$ & $\\swarrow$ & $\\checkmark$ &0.507 &0.490 &0.408 &0.437&0.411 &0.427 &0.322 &0.366 &0.273 &0.321 &0.274 &0.355 &0.207 &0.304 &0.532 &0.348\\\\\n            \\midrule\n            \\ding{175} &$\\checkmark$ &$\\nearrow$ & $\\times$ & $\\checkmark$ &0.491 &0.483 &0.397 &0.424 &0.405 &0.414 &0.317 &0.351 &0.269 &0.311 &0.268 &0.341 &0.200 &0.299 &0.525 &0.339\\\\\n            \\midrule\n            \\ding{176} &$\\checkmark$ &$\\swarrow$ &$\\swarrow$ &$\\checkmark$ &0.488 &0.466 &0.393 &0.426 &0.392 &0.413 &0.309 &0.349 &0.257 &0.293 &0.252 &0.330 &0.191 &0.293 &0.520 &0.331\\\\\n            \\midrule\n            \\ding{177} &$\\checkmark$ &$\\nearrow$ &$\\nearrow$ &$\\checkmark$ &0.493 &0.484 &0.401 &0.432 &0.396 &0.415 &0.319 &0.361 &0.271 &0.322 &0.281 &0.363 &0.214 &0.307 &0.541 &0.351\\\\\n            \\midrule\n            \\ding{178} &$\\checkmark$ &$\\swarrow$ &$\\nearrow$ &$\\checkmark$  &0.498 &0.491 &0.421 &0.436 &0.412 &0.429 &0.321 &0.369 &0.277 &0.332 &0.298 &0.375 &0.221 &0.319 &0.564 &0.357\\\\\n            \\midrule\n            \\ding{179} &$\\times$ &\\multicolumn{2}{c|}{$\\nearrow$} & $\\checkmark$ &0.494 &0.488 &0.396 &0.421 &0.395 &0.408 &0.313 &0.360 &0.259 &0.308 &0.260 &0.321 &0.199 &0.303 &0.522 &0.340\\\\\n            \\midrule\n            \\ding{180} &$\\times$ &\\multicolumn{2}{c|}{$\\swarrow$}  & $\\checkmark$ &0.487 &0.462 &0.394 &0.419 &0.393 &0.406 &0.307 &0.354 &0.261 &0.327 &0.257 &0.334 &0.196 &0.310 &0.526 &0.339\\\\\n            \\midrule\n            \\ding{181} &$\\times$ &\\multicolumn{2}{c|}{$\\times$}  & $\\checkmark$ &0.502 &0.489 &0.411 &0. 427 &0.405 &0.412 &0.319 &0.358 &0.273 &0.331 &0.295 &0.336 &0.217 &0.318 &0.558 &0.347\\\\\n\t\t\t\t\\bottomrule\n\t\t\t\\end{tabular}}\n\t\t% \\end{sc}\n\t\\end{small}\n }\n \\vspace{-10pt}\n\\end{table}",
            "tab:ablation_m4": "\\begin{table}[ht]\n\t\\caption{\\revise{Ablations on both Past-Decompose-Mixing (\\textit{Decompose}, \\textit{Season Mixing}, and \\textit{Trend Mixing}) and Future-Multipredictor-Mixing blocks in the M4 short-term forecasting benchmark.} Case notations are same as Table \\ref{tab:ablation_main_text} and \\ref{tab:ablation_long}. \\ding{172} is the official design in TimeMixer.}\n\t\\label{tab:ablation_m4}\n\t\\centering\n        \\vspace{3pt}\n    \\resizebox{0.7\\columnwidth}{!}{\n\t\\begin{small}\n\t\t% \\begin{sc}\n\t\t\t\\renewcommand{\\multirowsetup}{\\centering}\n\t\t\t\\setlength{\\tabcolsep}{6pt}\n\t\t\t\\scalebox{1}{\n\t\t\t\\begin{tabular}{c|c|cc|c|ccc}\n\t\t\t\t\\toprule\n\t\t\t\\multirow{2}{*}{Case} &\\multirow{2}{*}{Decompose} & \\multicolumn{2}{c|}{Past mixing} & Future mixing & \\multicolumn{3}{c}{M4} \\\\\n            \\cmidrule(lr){3-4} \\cmidrule(lr){5-5} \\cmidrule(lr){6-8}\n            & & Seasonal & Trend & Multipredictor & SMAPE & MASE & OWA\\\\\n            \\midrule\n            \\ding{172} &$\\checkmark$ & $\\nearrow$ & $\\swarrow$ & $\\checkmark$ & \\boldres{11.723} &\\boldres{1.559} &\\boldres{0.840}\\\\\n            \\midrule\n            \\ding{173} & $\\checkmark$ & $\\nearrow$ & $\\swarrow$ & $\\times$ &12.503 &1.634 &0.925 \\\\\n            \\midrule\n            \\ding{174} & $\\checkmark$ &$\\times$ & $\\swarrow$ & $\\checkmark$ &13.051 &1.676 &0.962 \\\\\n            \\midrule\n            \\ding{175} &$\\checkmark$ &$\\nearrow$ & $\\times$ & $\\checkmark$ &12.911 &1.655 &0.941  \\\\\n            \\midrule\n            \\ding{176} &$\\checkmark$ &$\\swarrow$ & $\\swarrow$ & $\\checkmark$ &12.008 &1.628 &0.871\\\\\n            \\midrule\n            \\ding{177} &$\\checkmark$ &$\\nearrow$ & $\\nearrow$ & $\\checkmark$ &11.978 &1.626 &0.859 \\\\\n            \\midrule\n            \\ding{178} &$\\checkmark$ &$\\swarrow$ &$\\nearrow$ & $\\checkmark$ &13.012 &1.657 &0.954\\\\\n            \\midrule\n            \\ding{179} &$\\times$ &\\multicolumn{2}{c|}{$\\nearrow$} & $\\checkmark$ &11.975 &1.617 &0.851\\\\\n            \\midrule\n                \\ding{180} &$\\times$ &\\multicolumn{2}{c|}{$\\swarrow$}  & $\\checkmark$ &11.973 &1.622 &0.850 \\\\\n            \\midrule\n            \\ding{181} &$\\times$ &\\multicolumn{2}{c|}{$\\times$}  & $\\checkmark$ &12.468 &1.671 &0.916 \\\\\n\t\t\t\t\\bottomrule\n\t\t\t\\end{tabular}}\n\t\t% \\end{sc}\n\t\\end{small}\n }\n \\vspace{-10pt}\n\\end{table}",
            "tab:ablation_pems": "\\begin{table}[htbp]\n\t\\caption{\\revise{Ablations on both Past-Decompose-Mixing (\\textit{Decompose}, \\textit{Season Mixing}, and \\textit{Trend Mixing}) and Future-Multipredictor-Mixing blocks in the PEMS short-term forecasting benchmarks.} Case notations are same as Table \\ref{tab:ablation_main_text} and \\ref{tab:ablation_long}. \\ding{172} is the official design in TimeMixer.}\n\t\\label{tab:ablation_pems}\n\t\\centering\n        \\vspace{3pt}\n    \\resizebox{\\columnwidth}{!}{\n\t\\begin{small}\n\t\t% \\begin{sc}\n\t\t\t\\renewcommand{\\multirowsetup}{\\centering}\n\t\t\t\\setlength{\\tabcolsep}{3.5pt}\n\t\t\t\\scalebox{1}{\n\t\t\t\\begin{tabular}{c|c|cc|c|ccc|ccc|ccc|ccc}\n\t\t\t\t\\toprule\n\t\t\t\\multirow{2}{*}{Case} &\\multirow{2}{*}{Decompose} & \\multicolumn{2}{c|}{Past mixing} & Future mixing & \\multicolumn{3}{c|}{PEMS03} & \\multicolumn{3}{c|}{PEMS04} & \\multicolumn{3}{c|}{PEMS07} & \\multicolumn{3}{c|}{PEMS08}\\\\\n            \\cmidrule(lr){3-4} \\cmidrule(lr){5-5} \\cmidrule(lr){6-8} \\cmidrule(lr){9-11} \\cmidrule(lr){12-14} \\cmidrule(lr){15-17}\n            & & Seasonal & Trend & Multipredictor & MAE & MAPE & RMSE & MAE & MAPE & RMSE & MAE & MAPE & RMSE & MAE & MAPE & RMSE \\\\\n            \\midrule\n            \\ding{172} &$\\checkmark$ & $\\nearrow$ & $\\swarrow$ & $\\checkmark$ &\\boldres{14.63} &\\boldres{14.54} &\\boldres{23.28} &\\boldres{19.21} &\\boldres{12.53} &\\boldres{30.92} &\\boldres{20.57} &\\boldres{8.62} &\\boldres{33.59} &\\boldres{15.22} &\\boldres{9.67} &\\boldres{24.26}\\\\\n            \\midrule\n            \\ding{173} & $\\checkmark$ & $\\nearrow$ & $\\swarrow$ & $\\times$ &15.66 &15.81 &25.77 &21.67 &13.45 &34.89 &22.78 &9.52  &35.57 &17.48 &10.91 &27.84 \\\\\n            \\midrule\n            \\ding{174} & $\\checkmark$ &$\\times$ & $\\swarrow$ & $\\checkmark$ &18.90 &17.33 &30.75 &24.49 &16.28 &38.79 &25.27 &10.74 &40.06 &19.02 &11.71 &30.05 \\\\\n            \\midrule\n            \\ding{175} &$\\checkmark$ &$\\nearrow$ & $\\times$ & $\\checkmark$ &17.67 &17.58 &28.48 &22.91 &15.02 &37.14  &24.81 &10.02 &38.68 &18.29 &12.21 &28.62\\\\\n            \\midrule\n            \\ding{176} &$\\checkmark$ &$\\swarrow$ & $\\swarrow$ & $\\checkmark$ &15.46 &15.73 &24.91 &20.78 &13.02 &32.47 &22.57 &9.33 &35.87 &16.54 &9.97 &26.88\\\\\n            \\midrule\n            \\ding{177} &$\\checkmark$ &$\\nearrow$ & $\\nearrow$ & $\\checkmark$ &15.32 &15.41 &24.83 &21.09 &13.78 & 33.11 &21.94 &9.41 &35.40 &17.01 &10.82 &26.93 \\\\\n            \\midrule\n            \\ding{178} &$\\checkmark$ &$\\swarrow$ &$\\nearrow$ & $\\checkmark$ &18.81 &17.29 &29.78 &22.27 &15.14 & 34.67 &25.11 &10.60 &39.74 &18.74 &12.09 &28.67\\\\\n            \\midrule\n            \\ding{179} &$\\times$ &\\multicolumn{2}{c|}{$\\nearrow$} & $\\checkmark$ &15.57 &15.62 &24.98 &21.51 &13.47 &34.81 &22.94 &9.81 &35.49 &18.17 &11.02 &28.14 \\\\\n            \\midrule\n                \\ding{180} &$\\times$ &\\multicolumn{2}{c|}{$\\swarrow$}  & $\\checkmark$ &15.48 &15.55 &24.83 & 21.79 &14.03 &35.23 &21.93 &9.91 &36.02 &17.71 &10.88 &27.91\\\\\n            \\midrule\n            \\ding{181} &$\\times$ &\\multicolumn{2}{c|}{$\\times$}  & $\\checkmark$ &19.01 &18.58 &30.06 &24.87 &16.66 &39.48 &24.72 &9.97 &37.18 &19.18 &12.21 &30.79\\\\\n\t\t\t\t\\bottomrule\n\t\t\t\\end{tabular}}\n\t\t% \\end{sc}\n\t\\end{small}\n }\n\\end{table}",
            "tab:abla_decomp": "\\begin{table}[ht]\n  \\caption{\\revise{Alternative decomposition methods in M4, PEMS04 and predict-336 setting of ETTm1.}}\\label{tab:abla_decomp}\n  \\vspace{3pt}\n  \\centering\n   \\resizebox{1.0\\columnwidth}{!}{\n  \\begin{threeparttable}\n  \\begin{small}\n  \\renewcommand{\\multirowsetup}{\\centering}\n  \\setlength{\\tabcolsep}{3pt}\n  \\begin{tabular}{l|cc|ccc|ccc}\n    \\toprule\n    \\multirow{2}{*}{Decomposition methods}  & \\multicolumn{2}{c|}{ETTm1} & \\multicolumn{3}{c|}{M4} & \\multicolumn{3}{c}{PEMS04} \\\\\n    \\cmidrule(lr){2-3} \\cmidrule(lr){4-6} \\cmidrule(lr){7-9}\n    & MSE &MAE &SMAPE &MASE &OWA &MAE &MAPE &RMSE \\\\\n    \\midrule\n    DFT-based high- and low-frequency decomposition &0.392 &0.404 &12.054 &1.632 &0.862 &19.83 &12.74 &31.48  \\\\\n    \\midrule\n    DFT-based season-trend decomposition &0.383 &0.399 &11.673 &1.536 &0.824 &18.91 &12.27 &29.47  \\\\\n    \\midrule\n    Moving-average-based season-trend decomposition (TimeMixer) &0.390 &0.404 &11.723 &1.559 &0.840 &19.21 &12.53 &30.92  \\\\\n    \\bottomrule\n  \\end{tabular}\n    \\end{small}\n  \\end{threeparttable}\n  }\n\\end{table}",
            "tab:abla_sampling": "\\begin{table}[ht]\n\\vspace{-5pt}\n  \\caption{\\revise{Alternative downsampling methods in M4, PEMS04 and predict-336 setting of ETTm1.}}\\label{tab:abla_sampling}\n  \\vspace{3pt}\n  \\centering\n  \\begin{threeparttable}\n  \\begin{small}\n  \\renewcommand{\\multirowsetup}{\\centering}\n  \\setlength{\\tabcolsep}{3pt}\n  \\begin{tabular}{l|cc|ccc|ccc}\n    \\toprule\n    \\multirow{2}{*}{Downsampling methods}  & \\multicolumn{2}{c|}{ETTm1} & \\multicolumn{3}{c|}{M4} & \\multicolumn{3}{c}{PEMS04} \\\\\n    \\cmidrule(lr){2-3} \\cmidrule(lr){4-6} \\cmidrule(lr){7-9}\n    & MSE &MAE &SMAPE &MASE &OWA &MAE &MAPE &RMSE \\\\\n    \\midrule\n    Moving average  &0.390 &0.404 &11.723 &1.559 &0.840 &19.21 &12.53 &30.92  \\\\\n    \\midrule\n    1D convolutions with stride as 2 &0.387 &0.401 &11.682 &1.542 &0.831 &19.04 &12.17 &29.88  \\\\\n    \\bottomrule\n  \\end{tabular}\n    \\end{small}\n  \\end{threeparttable}\n\\end{table}",
            "tab:abla_ensemble": "\\begin{table}[ht]\n  \\vspace{-5pt}\n  \\caption{\\revisenew{Alternative ensemble strategies in M4, PEMS04 and predict-336 setting of ETTm1.}}\\label{tab:abla_ensemble}\n  \\vspace{3pt}\n  \\centering\n  \\begin{threeparttable}\n  \\begin{small}\n  \\renewcommand{\\multirowsetup}{\\centering}\n  \\setlength{\\tabcolsep}{6pt}\n  \\begin{tabular}{l|cc|ccc|ccc}\n    \\toprule\n    \\multirow{2}{*}{Ensemble strategies}  & \\multicolumn{2}{c|}{ETTm1} & \\multicolumn{3}{c|}{M4} & \\multicolumn{3}{c}{PEMS04} \\\\\n    \\cmidrule(lr){2-3} \\cmidrule(lr){4-6} \\cmidrule(lr){7-9}\n    & MSE &MAE &SMAPE &MASE &OWA &MAE &MAPE &RMSE \\\\\n    \\midrule\n    Sum ensemble &0.390 &0.404 &11.723 &1.559 &0.840 &19.21 &12.53 &30.92  \\\\\n    \\midrule\n    Average ensemble & 0.391 & 0.407 & 11.742 & 1.573 & 0.851 & 19.17 & 12.45 & 30.88 \\\\\n    \\bottomrule\n  \\end{tabular}\n    \\end{small}\n  \\end{threeparttable}\n\\end{table}",
            "tab:ablation_main_text_additional": "\\begin{table}[t]\n\t\\caption{\\revisenew{A supplement to Table \\ref{tab:ablation_main_text} of the main text with ablations on both PDM (\\textit{Decompose}, \\textit{Season Mixing}, \\textit{Trend Mixing}) and FMM blocks in PEMS04 with $M=3$ and predict-336 setting of ETTm1 with input-336. Since the input length of M4 is fixed to a small value, larger $M$ may result in a meaningless configuration. We only experiment on PEMS04 here.}}\n \\label{tab:ablation_main_text_additional}\n  \\centering\n  \\vspace{3pt}\n  \\resizebox{0.9\\columnwidth}{!}{\n  \\begin{small}\n  \\renewcommand{\\multirowsetup}{\\centering}\n  \\setlength{\\tabcolsep}{3.5pt}\n\t\t\\begin{tabular}{c|c|cc|c|ccc|cc}\n\t\t\\toprule\n\t\t\\multirow{2}{*}{\\scalebox{0.95}{Case}} &\\multirow{2}{*}{\\scalebox{0.95}{Decompose}} & \\multicolumn{2}{c|}{\\scalebox{0.95}{Past mixing}} & \\scalebox{0.95}{Future mixing} &\\multicolumn{3}{c}{\\scalebox{0.95}{\\revisenew{PEMS04 with $M=3$}}} &\\multicolumn{2}{c}{\\scalebox{0.95}{\\revisenew{ETTm1 with input 336}}} \\\\\n            \\cmidrule(lr){3-4} \\cmidrule(lr){5-5} \\cmidrule(lr){6-8} \\cmidrule(lr){9-10}\n            & & \\scalebox{0.95}{Seasonal} & \\scalebox{0.95}{Trend} & \\scalebox{0.95}{Multipredictor} & \\scalebox{0.95}{\\revisenew{MAE}} & \\scalebox{0.95}{\\revisenew{MAPE}} & \\scalebox{0.95}{\\revisenew{RMSE}} & \\scalebox{0.95}{\\revisenew{MSE}} & \\scalebox{0.95}{\\revisenew{MAE}} \\\\\n            \\midrule\n            \\ding{172} &$\\checkmark$ & $\\nearrow$ & $\\swarrow$ & $\\checkmark$ &\\boldres{18.10} &\\boldres{11.73} &\\boldres{28.51} &\\boldres{0.360} &\\boldres{0.381}\\\\\n            \\midrule\n            \\ding{173} & $\\checkmark$ & $\\nearrow$ & $\\swarrow$ & $\\times$ & 21.49 &13.12 &33.48 &0.375 &0.398 \\\\\n            \\midrule\n            \\ding{174} & $\\checkmark$ &$\\times$ & $\\swarrow$ & $\\checkmark$  &23.68 &16.01 &37.42 &0.390 &0.415 \\\\\n            \\midrule\n            \\ding{175} &$\\checkmark$ &$\\nearrow$ & $\\times$ & $\\checkmark$  &22.44 &14.81 &36.54 &0.386 &0.410 \\\\\n            \\midrule\n            \\ding{176} &$\\checkmark$ &$\\swarrow$ & $\\swarrow$ & $\\checkmark$  &20.41 &13.08 &31.92 &0.371 &0.389 \\\\\n            \\midrule\n            \\ding{177} &$\\checkmark$ &$\\nearrow$ & $\\nearrow$ & $\\checkmark$  &21.28 &13.19 &32.84 &0.370 &0.388 \\\\\n            \\midrule\n            {\\ding{178}} &{$\\checkmark$} &{$\\swarrow$} &{$\\nearrow$} & {$\\checkmark$}  &22.16 &14.60 &35.42 & 0.384 &0.409 \\\\\n            \\midrule\n            \\ding{179} &$\\times$ &\\multicolumn{2}{c|}{$\\nearrow$} & $\\checkmark$  &20.98 &13.12 &33.94 &0.372 &0.396 \\\\\n            \\midrule\n            \\ding{180} &$\\times$ &\\multicolumn{2}{c|}{$\\swarrow$}  & $\\checkmark$  &20.66 &13.06 &32.74 &0.374 &0.398 \\\\\n            \\midrule\n            \\ding{181} &$\\times$ &\\multicolumn{2}{c|}{$\\times$}  & $\\checkmark$  &24.16 &16.21 &38.04 &0.401 &0.414 \\\\\n\t\t\\bottomrule\n\t\t\\end{tabular}\n\t\\end{small}\n }\n\t\\vspace{-10pt}\n\\end{table}",
            "tab:ablation_main_text_additional_relative": "\\begin{table}[t]\n\t\\caption{\\revisenew{Relative promotion analysis on ablations under different hyperparameter configurations. For example, the relative promotion is calculated by $(1-$\\ding{172}/{\\ding{173}}$)$ in case \\ding{173}.}}\n \\label{tab:ablation_main_text_additional_relative}\n  \\centering\n  \\vspace{3pt}\n  \\resizebox{0.9\\columnwidth}{!}{\n  \\begin{small}\n  \\renewcommand{\\multirowsetup}{\\centering}\n  \\setlength{\\tabcolsep}{3.5pt}\n\t\t\\begin{tabular}{c|c|cc|c|ccc|cc}\n\t\t\\toprule\n\t\t\\multirow{2}{*}{\\scalebox{0.95}{Case}} &\\multirow{2}{*}{\\scalebox{0.95}{Decompose}} & \\multicolumn{2}{c|}{\\scalebox{0.95}{Past mixing}} & \\scalebox{0.95}{Future mixing} &\\multicolumn{3}{c}{\\scalebox{0.95}{\\revisenew{PEMS04 with $M=3$}}} &\\multicolumn{2}{c}{\\scalebox{0.95}{\\revisenew{ETTm1 with input 336}}} \\\\\n            \\cmidrule(lr){3-4} \\cmidrule(lr){5-5} \\cmidrule(lr){6-8} \\cmidrule(lr){9-10}\n            & & \\scalebox{0.95}{Seasonal} & \\scalebox{0.95}{Trend} & \\scalebox{0.95}{Multipredictor} & \\scalebox{0.95}{\\revisenew{MAE}} & \\scalebox{0.95}{\\revisenew{MAPE}} & \\scalebox{0.95}{\\revisenew{RMSE}} & \\scalebox{0.95}{\\revisenew{MSE}} & \\scalebox{0.95}{\\revisenew{MAE}} \\\\\n            \\midrule\n            \\ding{172} &$\\checkmark$ & $\\nearrow$ & $\\swarrow$ & $\\checkmark$ &-  &-  &-  &-  &- \\\\\n            \\midrule\n            \\ding{173} & $\\checkmark$ & $\\nearrow$ & $\\swarrow$ & $\\times$ &15.8\\% &10.6\\% &14.9\\% &4.1\\% &4.2\\%\\\\\n            \\midrule\n            \\ding{174} & $\\checkmark$ &$\\times$ & $\\swarrow$ & $\\checkmark$ &23.6\\% &26.7\\% &23.8\\% &7.7\\% &8.2\\%\\\\\n            \\midrule\n            \\ding{175} &$\\checkmark$ &$\\nearrow$ & $\\times$ & $\\checkmark$ &19.2\\% &20.1\\% &22.0\\% &6.8\\% &7.1\\%\\\\\n            \\midrule\n            \\ding{176} &$\\checkmark$ &$\\swarrow$ & $\\swarrow$ & $\\checkmark$ &11.4\\% &10.4\\% &10.7\\% &3.0\\% &2.1\\%\\\\\n            \\midrule\n            \\ding{177} &$\\checkmark$ &$\\nearrow$ & $\\nearrow$ & $\\checkmark$ &15.0\\% &11.1\\% &13.2\\% &2.7\\% &1.8\\%\\\\\n            \\midrule\n            {\\ding{178}} &{$\\checkmark$} &{$\\swarrow$} &{$\\nearrow$} & {$\\checkmark$} &18.4\\% &19.7\\% &19.5\\% &6.2\\% &6.9\\%\\\\\n            \\midrule\n            \\ding{179} &$\\times$ &\\multicolumn{2}{c|}{$\\nearrow$} & $\\checkmark$ &13.7\\% &10.6\\% &15.9\\% &3.2\\% &3.8\\%\\\\\n            \\midrule\n            \\ding{180} &$\\times$ &\\multicolumn{2}{c|}{$\\swarrow$}  & $\\checkmark$ &12.4\\% &10.2\\% &13.0\\% &3.7\\% &4.2\\%\\\\\n            \\midrule\n            \\ding{181} &$\\times$ &\\multicolumn{2}{c|}{$\\times$}  & $\\checkmark$ &25.1\\% &27.6\\% &25.0\\% &10.2\\% &8.0\\%\\\\\n\t\t\\bottomrule\n            \\toprule\n\t\t\\multirow{2}{*}{\\scalebox{0.95}{Case}} &\\multirow{2}{*}{\\scalebox{0.95}{Decompose}} & \\multicolumn{2}{c|}{\\scalebox{0.95}{Past mixing}} & \\scalebox{0.95}{Future mixing} &\\multicolumn{3}{c}{\\scalebox{0.95}{\\revisenew{PEMS04 with $M=1$}}} &\\multicolumn{2}{c}{\\scalebox{0.95}{\\revisenew{ETTm1 with input 96}}} \\\\\n            \\cmidrule(lr){3-4} \\cmidrule(lr){5-5} \\cmidrule(lr){6-8} \\cmidrule(lr){9-10}\n            & & \\scalebox{0.95}{Seasonal} & \\scalebox{0.95}{Trend} & \\scalebox{0.95}{Multipredictor} & \\scalebox{0.95}{\\revisenew{MAE}} & \\scalebox{0.95}{\\revisenew{MAPE}} & \\scalebox{0.95}{\\revisenew{RMSE}} & \\scalebox{0.95}{\\revisenew{MSE}} & \\scalebox{0.95}{\\revisenew{MAE}} \\\\\n            \\midrule\n            \\ding{172} &$\\checkmark$ & $\\nearrow$ & $\\swarrow$ & $\\checkmark$ &-  &-  &-  &-  &-\\\\\n            \\midrule\n            \\ding{173} & $\\checkmark$ & $\\nearrow$ & $\\swarrow$ & $\\times$ &11.4\\% &6.8\\% &11.2\\% &2.9\\% &2.6\\%\\\\\n            \\midrule\n            \\ding{174} & $\\checkmark$ &$\\times$ & $\\swarrow$ & $\\checkmark$ &21.6\\% &23.1\\% &20.2\\% &5.1\\% &5.4\\%\\\\\n            \\midrule\n            \\ding{175} &$\\checkmark$ &$\\nearrow$ & $\\times$ & $\\checkmark$ &16.2\\% &16.6\\% &16.7\\% &3.7\\% &2.4\\%\\\\\n            \\midrule\n            \\ding{176} &$\\checkmark$ &$\\swarrow$ & $\\swarrow$ & $\\checkmark$ &7.6\\% &3.7\\% &4.7\\% &0.5\\% &2.1\\%\\\\\n            \\midrule\n            \\ding{177} &$\\checkmark$ &$\\nearrow$ & $\\nearrow$ & $\\checkmark$ &8.9\\% &9.0\\% &6.6\\% &1.5\\% &2.6\\%\\\\\n            \\midrule\n            {\\ding{178}} &{$\\checkmark$} &{$\\swarrow$} &{$\\nearrow$} & {$\\checkmark$} &13.7\\% &17.2\\% &10.8\\% &5.3\\% &5.8\\%\\\\\n            \\midrule\n            \\ding{179} &$\\times$ &\\multicolumn{2}{c|}{$\\nearrow$} & $\\checkmark$ &10.6\\% &6.9\\% &11.7\\% &1.2\\% &1.0\\%\\\\\n            \\midrule\n            \\ding{180} &$\\times$ &\\multicolumn{2}{c|}{$\\swarrow$}  & $\\checkmark$ &11.8\\% &10.6\\% &12.2\\% &0.7\\% &0.5\\%\\\\\n            \\midrule\n            \\ding{181} &$\\times$ &\\multicolumn{2}{c|}{$\\times$}  & $\\checkmark$ &22.7\\% &24.7\\% &21.6\\% &3.9\\% &2.1\\%\\\\\n\t\t\\bottomrule\n\t\t\\end{tabular}\n\t\\end{small}\n }\n\t\\vspace{-15pt}\n\\end{table}",
            "tab:full_forecasting_results_additional": "\\begin{table}[htbp]\n  \\caption{\\revisenew{Unified and searched hyperparameter results for additional baselines in the long-term forecasting task.} We compare extensive competitive models under different prediction lengths. \\emph{Avg} is averaged from all four prediction lengths, that is 96, 192, 336, 720. \\revisenew{All these baselines are reproduced by their official code. For the searched hyperparameter setting, we follow the searching strategy described in Appendix \\ref{appdix:full_search}. Especially for TSMixer, we reproduced it in Pytorch \\citep{Paszke2019PyTorchAI}.}}\\label{tab:full_forecasting_results_additional}\n  \\vskip 0.05in\n  \\centering\n  \\resizebox{1\\columnwidth}{!}{\n  \\begin{threeparttable}\n  \\begin{small}\n  \\renewcommand{\\multirowsetup}{\\centering}\n  \\setlength{\\tabcolsep}{3.5pt}\n  \\begin{tabular}{c|c|cc|cc|cc|cc|cc|cc|cc|cc}\n    \\toprule\n    \\multicolumn{2}{c}{\\multirow{3}{*}{Models}} & \\multicolumn{8}{c}{\\rotatebox{0}{\\scalebox{1}{\\revise{\\textbf{Unified Hyperparameter}}}}} & \\multicolumn{8}{c}{\\rotatebox{0}{\\scalebox{1}{\\revisenew{\\textbf{Searched Hyperparameter}}}}} \\\\\n    \\cmidrule(lr){3-10}\\cmidrule(lr){11-18}\n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{0.8}{\\textbf{}}}} &\n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{0.8}{\\textbf{TimeMixer}}}} &\n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{0.8}{Scaleformer}}} &\n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{0.8}{MTSMixer}}} &\n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{0.8}{TSMixer}}} &\n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{0.8}{\\textbf{TimeMixer}}}} &\n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{0.8}{Scaleformer}}} &\n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{0.8}{MTSMixer}}} &\n    \\multicolumn{2}{c}{\\rotatebox{0}{\\scalebox{0.8}{TSMixer}}} \\\\\n    \\multicolumn{2}{c}{} & \\multicolumn{2}{c}{\\scalebox{0.8}{(\\textbf{Ours})}} &\n    \\multicolumn{2}{c}{\\scalebox{0.8}{\\citeyearpar{scaleformer}}} &\n    \\multicolumn{2}{c}{\\scalebox{0.8}{\\citeyearpar{li2023mtsmixers}}}&\n    \\multicolumn{2}{c}{\\scalebox{0.8}{\\citeyearpar{chen2023tsmixer}}} & \\multicolumn{2}{c}{\\scalebox{0.8}{(\\textbf{Ours})}} &\n    \\multicolumn{2}{c}{\\scalebox{0.8}{\\citeyearpar{scaleformer}}} &\n    \\multicolumn{2}{c}{\\scalebox{0.8}{\\citeyearpar{li2023mtsmixers}}}&\n    \\multicolumn{2}{c}{\\scalebox{0.8}{\\citeyearpar{chen2023tsmixer}}}\n    \\\\\n    \\cmidrule(lr){3-4} \\cmidrule(lr){5-6}\\cmidrule(lr){7-8} \\cmidrule(lr){9-10} \\cmidrule(lr){11-12} \\cmidrule(lr){12-13}\\cmidrule(lr){13-14}\\cmidrule(lr){14-16}\\cmidrule(lr){17-18}\n    \\multicolumn{2}{c}{Metric} & \\scalebox{0.85}{MSE} & \\scalebox{0.85}{MAE} & \\scalebox{0.85}{MSE} & \\scalebox{0.85}{MAE} & \\scalebox{0.85}{MSE} & \\scalebox{0.85}{MAE} & \\scalebox{0.85}{MSE} & \\scalebox{0.85}{MAE} & \\scalebox{0.85}{MSE} & \\scalebox{0.85}{MAE} & \\scalebox{0.85}{MSE} & \\scalebox{0.85}{MAE} & \\scalebox{0.85}{MSE} & \\scalebox{0.85}{MAE} & \\scalebox{0.85}{MSE} & \\scalebox{0.85}{MAE} \\\\\n    \\toprule\n\n \\multirow{5}{*}{\\rotatebox{90}{\\scalebox{0.95}{Weather}}} \n    & \\scalebox{0.85}{96} &\\boldres{\\scalebox{0.85}{0.163}}&\\boldres{\\scalebox{0.85}{0.209}}&\\scalebox{0.85}{0.220}&\\scalebox{0.85}{0.289}&\\scalebox{0.85}{0.173}&\\scalebox{0.85}{0.224}&\\scalebox{0.85}{0.175}&\\scalebox{0.85}{0.247}&\\boldres{\\scalebox{0.85}{0.147}}&\\boldres{\\scalebox{0.85}{0.197}} &\\scalebox{0.85}{0.192} &\\scalebox{0.85}{0.241} &\\scalebox{0.85}{0.167} &\\scalebox{0.85}{0.221} &\\scalebox{0.85}{0.149} &\\scalebox{0.85}{0.198}\\\\\n    \n    & \\scalebox{0.85}{192} &\\boldres{\\scalebox{0.85}{0.208}}&\\boldres{\\scalebox{0.85}{0.250}}&\\scalebox{0.85}{0.341}&\\scalebox{0.85}{0.385}&\\scalebox{0.85}{0.219}&\\scalebox{0.85}{0.261}&\\scalebox{0.85}{0.224}&\\scalebox{0.85}{0.294} &\\boldres{\\scalebox{0.85}{0.189}}&\\boldres{\\scalebox{0.85}{0.239}} &\\scalebox{0.85}{0.220} &\\scalebox{0.85}{0.288} &\\scalebox{0.85}{0.208} &\\scalebox{0.85}{0.250} &\\scalebox{0.85}{0.201} &\\scalebox{0.85}{0.251}\\\\\n    \n    & \\scalebox{0.85}{336} &\\boldres{\\scalebox{0.85}{0.251}}&\\boldres{\\scalebox{0.85}{0.287}}&\\scalebox{0.85}{0.463}&\\scalebox{0.85}{0.455}&\\scalebox{0.85}{0.274}&\\scalebox{0.85}{0.300}&\\scalebox{0.85}{0.262}&\\scalebox{0.85}{0.326}&\\boldres{\\scalebox{0.85}{0.241}}&\\boldres{\\scalebox{0.85}{0.280}}\n    &\\scalebox{0.85}{0.288} &\\scalebox{0.85}{0.324} &\\scalebox{0.85}{0.298} &\\scalebox{0.85}{0.302} &\\scalebox{0.85}{0.287} &\\scalebox{0.85}{0.291}\n    \\\\\n    & \\scalebox{0.85}{720} &\\boldres{\\scalebox{0.85}{0.339}}&\\boldres{\\scalebox{0.85}{0.341}}&\\scalebox{0.85}{0.640}&\\scalebox{0.85}{0.565}&\\scalebox{0.85}{0.365}&\\scalebox{0.85}{0.359}&\\scalebox{0.85}{0.349}&\\scalebox{0.85}{0.348}&\\boldres{\\scalebox{0.85}{0.310}}&\\boldres{\\scalebox{0.85}{0.330}}\n    &\\scalebox{0.85}{0.321} &\\scalebox{0.85}{0.360} &\\scalebox{0.85}{0.344} &\\scalebox{0.85}{0.339} &\\scalebox{0.85}{0.320} &\\scalebox{0.85}{0.336}\n    \\\\\n    \\cmidrule(lr){2-18}\n    & \\scalebox{0.85}{Avg} &\\boldres{\\scalebox{0.85}{0.240}}&\\boldres{\\scalebox{0.85}{0.271}}&\\scalebox{0.85}{0.416}&\\scalebox{0.85}{0.423}&\\scalebox{0.85}{0.258}&\\scalebox{0.85}{0.286}&\\scalebox{0.85}{0.253}&\\scalebox{0.85}{0.304}&\\boldres{\\scalebox{0.85}{0.222}}&\\boldres{\\scalebox{0.85}{0.262}}\n    &\\scalebox{0.85}{0.248} &\\scalebox{0.85}{0.304} &\\scalebox{0.85}{0.254} &\\scalebox{0.85}{0.278} &\\scalebox{0.85}{0.240} &\\scalebox{0.85}{0.269}\\\\\n    \\midrule\n    \n    \\multirow{5}{*}{\\rotatebox{90}{\\scalebox{0.95}{Solar-Energy}}} \n    & \\scalebox{0.85}{96} &\\boldres{\\scalebox{0.85}{0.189}}&\\boldres{\\scalebox{0.85}{0.259}}&\\scalebox{0.85}{0.271}&\\scalebox{0.85}{0.331}&\\scalebox{0.85}{0.217}&\\scalebox{0.85}{0.272}&\\scalebox{0.85}{0.216}&\\scalebox{0.85}{0.294}&\\boldres{\\scalebox{0.85}{0.167}}&\\boldres{\\scalebox{0.85}{0.220}}\n    &\\scalebox{0.85}{0.224} &\\scalebox{0.85}{0.328} &\\scalebox{0.85}{0.199} &\\scalebox{0.85}{0.251} &\\scalebox{0.85}{0.190} &\\scalebox{0.85}{0.272}\n    \\\\\n    & \\scalebox{0.85}{192} &\\boldres{\\scalebox{0.85}{0.222}}&\\boldres{\\scalebox{0.85}{0.283}}&\\scalebox{0.85}{0.288}&\\scalebox{0.85}{0.332}&\\scalebox{0.85}{0.258}&\\scalebox{0.85}{0.299}&\\scalebox{0.85}{0.294}&\\scalebox{0.85}{0.359}&\\boldres{\\scalebox{0.85}{0.187}}&\\boldres{\\scalebox{0.85}{0.249}}\n    &\\scalebox{0.85}{0.247} &\\scalebox{0.85}{0.312} &\\scalebox{0.85}{0.221} &\\scalebox{0.85}{0.275} &\\scalebox{0.85}{0.207} &\\scalebox{0.85}{0.278}\n    \\\\\n    & \\scalebox{0.85}{336} &\\boldres{\\scalebox{0.85}{0.231}}&\\boldres{\\scalebox{0.85}{0.292}}&\\scalebox{0.85}{0.358}&\\scalebox{0.85}{0.412}&\\scalebox{0.85}{0.278}&\\scalebox{0.85}{0.310}&\\scalebox{0.85}{0.302}&\\scalebox{0.85}{0.367}&\\boldres{\\scalebox{0.85}{0.200}}&\\boldres{\\scalebox{0.85}{0.258}}\n    &\\scalebox{0.85}{0.274} &\\scalebox{0.85}{0.308} &\\scalebox{0.85}{0.231} &\\scalebox{0.85}{0.281} &\\scalebox{0.85}{0.246} &\\scalebox{0.85}{0.304}\n    \\\\\n    & \\scalebox{0.85}{720} &\\boldres{\\scalebox{0.85}{0.223}}&\\boldres{\\scalebox{0.85}{0.285}}&\\scalebox{0.85}{0.377}&\\scalebox{0.85}{0.437}&\\scalebox{0.85}{0.293}&\\scalebox{0.85}{0.321}&\\scalebox{0.85}{0.311}&\\scalebox{0.85}{0.372}&\\boldres{\\scalebox{0.85}{0.215}}&\\boldres{\\scalebox{0.85}{0.250}}\n    &\\scalebox{0.85}{0.335} &\\scalebox{0.85}{0.384} &\\scalebox{0.85}{0.270} &\\scalebox{0.85}{0.301} &\\scalebox{0.85}{0.274} &\\scalebox{0.85}{0.308}\n    \\\\\n    \\cmidrule(lr){2-18}\n    & \\scalebox{0.85}{Avg} &\\boldres{\\scalebox{0.85}{0.216}}&\\boldres{\\scalebox{0.85}{0.280}}&\\scalebox{0.85}{0.323}&\\scalebox{0.85}{0.378}&\\scalebox{0.85}{0.261}&\\scalebox{0.85}{0.300}&\\scalebox{0.85}{0.280}&\\scalebox{0.85}{0.348}&\\boldres{\\scalebox{0.85}{0.192}}&\\boldres{\\scalebox{0.85}{0.244}}\n    &\\scalebox{0.85}{0.270} &\\scalebox{0.85}{0.333} &\\scalebox{0.85}{0.230} &\\scalebox{0.85}{0.277} &\\scalebox{0.85}{0.229} &\\scalebox{0.85}{0.283}\n    \\\\\n    \\midrule\n\n    \\multirow{5}{*}{\\rotatebox{90}{\\scalebox{0.95}{Electricity}}} \n    & \\scalebox{0.85}{96} &\\boldres{\\scalebox{0.85}{0.153}}&\\boldres{\\scalebox{0.85}{0.247}}&\\scalebox{0.85}{0.182}&\\scalebox{0.85}{0.297}&\\scalebox{0.85}{0.173}&\\scalebox{0.85}{0.270}&\\scalebox{0.85}{0.190}&\\scalebox{0.85}{0.299}&\\boldres{\\scalebox{0.85}{0.129}}&\\boldres{\\scalebox{0.85}{0.224}}\n    &\\scalebox{0.85}{0.162} &\\scalebox{0.85}{0.274} &\\scalebox{0.85}{0.154} &\\scalebox{0.85}{0.267} &\\scalebox{0.85}{0.142} &\\scalebox{0.85}{0.234}\n    \\\\\n    & \\scalebox{0.85}{192} &\\boldres{\\scalebox{0.85}{0.166}}&\\boldres{\\scalebox{0.85}{0.256}}&\\scalebox{0.85}{0.188}&\\scalebox{0.85}{0.300}&\\scalebox{0.85}{0.186}&\\scalebox{0.85}{0.280}&\\scalebox{0.85}{0.216}&\\scalebox{0.85}{0.323}&\\boldres{\\scalebox{0.85}{0.140}} &\\boldres{\\scalebox{0.85}{0.220}}\n    &\\scalebox{0.85}{0.171} &\\scalebox{0.85}{0.284} &\\scalebox{0.85}{0.168} &\\scalebox{0.85}{0.272} &\\scalebox{0.85}{0.154} &\\scalebox{0.85}{0.248}\n    \\\\\n    & \\scalebox{0.85}{336} &\\boldres{\\scalebox{0.85}{0.185}}&\\boldres{\\scalebox{0.85}{0.277}}&\\scalebox{0.85}{0.210}&\\scalebox{0.85}{0.324}&\\scalebox{0.85}{0.204}&\\scalebox{0.85}{0.297}&\\scalebox{0.85}{0.226}&\\scalebox{0.85}{0.334}&\\boldres{\\scalebox{0.85}{0.161}} &\\boldres{\\scalebox{0.85}{0.255}}\n    &\\scalebox{0.85}{0.192} &\\scalebox{0.85}{0.304} &\\scalebox{0.85}{0.182} &\\scalebox{0.85}{0.281} &\\boldres{\\scalebox{0.85}{0.161}} &\\scalebox{0.85}{0.262}\n    \\\\\n    & \\scalebox{0.85}{720} &\\boldres{\\scalebox{0.85}{0.225}}&\\boldres{\\scalebox{0.85}{0.310}}&\\scalebox{0.85}{0.232}&\\scalebox{0.85}{0.339}&\\scalebox{0.85}{0.241}&\\scalebox{0.85}{0.326}&\\scalebox{0.85}{0.250}&\\scalebox{0.85}{0.353}&\\boldres{\\scalebox{0.85}{0.194}} &\\boldres{\\scalebox{0.85}{0.287}}\n    &\\scalebox{0.85}{0.238} &\\scalebox{0.85}{0.332} &\\scalebox{0.85}{0.212} &\\scalebox{0.85}{0.321} &\\scalebox{0.85}{0.209} &\\scalebox{0.85}{0.304}\n    \\\\\n    \\cmidrule(lr){2-18}\n    & \\scalebox{0.85}{Avg} &\\boldres{\\scalebox{0.85}{0.182}}&\\boldres{\\scalebox{0.85}{0.272}}&\\scalebox{0.85}{0.203}&\\scalebox{0.85}{0.315}&\\scalebox{0.85}{0.201}&\\scalebox{0.85}{0.293}&\\scalebox{0.85}{0.220}&\\scalebox{0.85}{0.327}&\\boldres{\\scalebox{0.85}{0.156}} &\\boldres{\\scalebox{0.85}{0.246} } \n    &\\scalebox{0.85}{0.191} &\\scalebox{0.85}{0.298} &\\scalebox{0.85}{0.179} &\\scalebox{0.85}{0.286} &\\scalebox{0.85}{0.167} &\\scalebox{0.85}{0.262}\n    \\\\\n    \\midrule\n\n    \\multirow{5}{*}{\\rotatebox{90}{\\scalebox{0.95}{Traffic}}} \n    & \\scalebox{0.85}{96} &\\boldres{\\scalebox{0.85}{0.462}}&\\boldres{\\scalebox{0.85}{0.285}}&\\scalebox{0.85}{0.564}&\\scalebox{0.85}{0.351}&\\scalebox{0.85}{0.523}&\\scalebox{0.85}{0.357}&\\scalebox{0.85}{0.499}&\\scalebox{0.85}{0.344}&\\boldres{\\scalebox{0.85}{0.360}}&\\boldres{\\scalebox{0.85}{0.249}}\n    &\\scalebox{0.85}{0.409} &\\scalebox{0.85}{0.281} &\\scalebox{0.85}{0.514} &\\scalebox{0.85}{0.338} &\\scalebox{0.85}{0.398} &\\scalebox{0.85}{0.272}\n    \\\\\n    & \\scalebox{0.85}{192} &\\boldres{\\scalebox{0.85}{0.473}}&\\boldres{\\scalebox{0.85}{0.296}}&\\scalebox{0.85}{0.570}&\\scalebox{0.85}{0.349}&\\scalebox{0.85}{0.535}&\\scalebox{0.85}{0.367}&\\scalebox{0.85}{0.540}&\\scalebox{0.85}{0.370}&\\boldres{\\scalebox{0.85}{0.375}}&\\boldres{\\scalebox{0.85}{0.250}}\n    &\\scalebox{0.85}{0.418} &\\scalebox{0.85}{0.294} &\\scalebox{0.85}{0.519} &\\scalebox{0.85}{0.351} &\\scalebox{0.85}{0.402} &\\scalebox{0.85}{0.281}\n    \\\\\n    & \\scalebox{0.85}{336} &\\boldres{\\scalebox{0.85}{0.498}}&\\boldres{\\scalebox{0.85}{0.296}}&\\scalebox{0.85}{0.576}&\\scalebox{0.85}{0.349}&\\scalebox{0.85}{0.566}&\\scalebox{0.85}{0.379}&\\scalebox{0.85}{0.557}&\\scalebox{0.85}{0.378}&\\boldres{\\scalebox{0.85}{0.385}}&\\boldres{\\scalebox{0.85}{0.270}}\n    &\\scalebox{0.85}{0.427} &\\scalebox{0.85}{0.294} &\\scalebox{0.85}{0.557} &\\scalebox{0.85}{0.361} &\\scalebox{0.85}{0.412} &\\scalebox{0.85}{0.294}\n    \\\\\n    & \\scalebox{0.85}{720} &\\boldres{\\scalebox{0.85}{0.506}}&\\boldres{\\scalebox{0.85}{0.313}}&\\scalebox{0.85}{0.602}&\\scalebox{0.85}{0.360}&\\scalebox{0.85}{0.608}&\\scalebox{0.85}{0.397}&\\scalebox{0.85}{0.586}&\\scalebox{0.85}{0.397} &\\boldres{\\scalebox{0.85}{0.430}}&\\boldres{\\scalebox{0.85}{0.281}}\n    &\\scalebox{0.85}{0.518} &\\scalebox{0.85}{0.356} &\\scalebox{0.85}{0.569} &\\scalebox{0.85}{0.362} &\\scalebox{0.85}{0.448} &\\scalebox{0.85}{0.311}\n    \\\\\n    \\cmidrule(lr){2-18}\n    & \\scalebox{0.85}{Avg} &\\boldres{\\scalebox{0.85}{0.484}}&\\boldres{\\scalebox{0.85}{0.297}}&\\scalebox{0.85}{0.578}&\\scalebox{0.85}{0.352}&\\scalebox{0.85}{0.558}&\\scalebox{0.85}{0.375}&\\scalebox{0.85}{0.546}&\\scalebox{0.85}{0.372}&\\boldres{\\scalebox{0.85}{0.387}}&\\boldres{\\scalebox{0.85}{0.262}}\n    &\\scalebox{0.85}{0.443} &\\scalebox{0.85}{0.307} &\\scalebox{0.85}{0.539} &\\scalebox{0.85}{0.354} &\\scalebox{0.85}{0.415} &\\scalebox{0.85}{0.290}\n    \\\\\n    \\midrule\n\n    \\multirow{5}{*}{\\rotatebox{90}{\\scalebox{0.95}{ETTh1}}} \n    & \\scalebox{0.85}{96} &\\boldres{\\scalebox{0.85}{0.375}}&\\boldres{\\scalebox{0.85}{0.400}}&\\scalebox{0.85}{0.401}&\\scalebox{0.85}{0.428}&\\scalebox{0.85}{0.418}&\\scalebox{0.85}{0.437}&\\scalebox{0.85}{0.387}&\\scalebox{0.85}{0.411}&\\boldres{\\scalebox{0.85}{0.361}}&\\boldres{\\scalebox{0.85}{0.390}}\n    &\\scalebox{0.85}{0.381} &\\scalebox{0.85}{0.412} &\\scalebox{0.85}{0.397} &\\scalebox{0.85}{0.428} &\\scalebox{0.85}{0.370} &\\scalebox{0.85}{0.402}\n    \\\\\n    & \\scalebox{0.85}{192} &\\boldres{\\scalebox{0.85}{0.429}}&\\boldres{\\scalebox{0.85}{0.421}}&\\scalebox{0.85}{0.471}&\\scalebox{0.85}{0.478}&\\scalebox{0.85}{0.463}&\\scalebox{0.85}{0.460}&\\scalebox{0.85}{0.441}&\\scalebox{0.85}{0.437}&\\scalebox{0.85}{0.409}&\\boldres{\\scalebox{0.85}{0.414}}\n    &\\scalebox{0.85}{0.445} &\\scalebox{0.85}{0.441} &\\scalebox{0.85}{0.452} &\\scalebox{0.85}{0.466} &\\boldres{\\scalebox{0.85}{0.406}} &\\boldres{\\scalebox{0.85}{0.414}}\n    \\\\\n    & \\scalebox{0.85}{336} &\\boldres{\\scalebox{0.85}{0.484}}&\\boldres{\\scalebox{0.85}{0.458}}&\\scalebox{0.85}{0.527}&\\scalebox{0.85}{0.498}&\\scalebox{0.85}{0.516}&\\scalebox{0.85}{0.478}&\\scalebox{0.85}{0.507}&\\scalebox{0.85}{0.467}&\\scalebox{0.85}{0.430}&\\boldres{\\scalebox{0.85}{0.429}}\n    &\\scalebox{0.85}{0.501} &\\scalebox{0.85}{0.484} &\\scalebox{0.85}{0.487} &\\scalebox{0.85}{0.462} &\\boldres{\\scalebox{0.85}{0.424}} &\\scalebox{0.85}{0.434}\n    \\\\\n    & \\scalebox{0.85}{720} &\\boldres{\\scalebox{0.85}{0.498}}&\\boldres{\\scalebox{0.85}{0.482}}&\\scalebox{0.85}{0.578}&\\scalebox{0.85}{0.547}&\\scalebox{0.85}{0.532}&\\scalebox{0.85}{0.549}&\\scalebox{0.85}{0.527}&\\scalebox{0.85}{0.548}&\\boldres{\\scalebox{0.85}{0.445}}&\\boldres{\\scalebox{0.85}{0.460}}\n    &\\scalebox{0.85}{0.544} &\\scalebox{0.85}{0.528} &\\scalebox{0.85}{0.510} &\\scalebox{0.85}{0.506} &\\scalebox{0.85}{0.471} &\\scalebox{0.85}{0.479}\n    \\\\\n    \\cmidrule(lr){2-18}\n    & \\scalebox{0.85}{Avg} &\\boldres{\\scalebox{0.85}{0.447}}&\\boldres{\\scalebox{0.85}{0.440}}&\\scalebox{0.85}{0.495}&\\scalebox{0.85}{0.488}&\\scalebox{0.85}{0.482}&\\scalebox{0.85}{0.481}&\\scalebox{0.85}{0.466}&\\scalebox{0.85}{0.467}&\\boldres{\\scalebox{0.85}{0.411}}&\\boldres{\\scalebox{0.85}{0.423}}\n    &\\scalebox{0.85}{0.468} &\\scalebox{0.85}{0.466} &\\scalebox{0.85}{0.461} &\\scalebox{0.85}{0.464} &\\scalebox{0.85}{0.418} &\\scalebox{0.85}{0.432}\n    \\\\\n    \\midrule\n\n    \\multirow{5}{*}{\\rotatebox{90}{\\scalebox{0.95}{ETTh2}}} \n    & \\scalebox{0.85}{96} &\\boldres{\\scalebox{0.85}{0.289}}&\\boldres{\\scalebox{0.85}{0.341}}&\\scalebox{0.85}{0.368}&\\scalebox{0.85}{0.398}&\\scalebox{0.85}{0.343}&\\scalebox{0.85}{0.378}&\\scalebox{0.85}{0.308}&\\scalebox{0.85}{0.357}&\\boldres{\\scalebox{0.85}{0.271}}&\\boldres{\\scalebox{0.85}{0.330}}\n    &\\scalebox{0.85}{0.340} &\\scalebox{0.85}{0.394} &\\scalebox{0.85}{0.328} &\\scalebox{0.85}{0.367} &\\scalebox{0.85}{0.271} &\\scalebox{0.85}{0.339}\n    \\\\\n    & \\scalebox{0.85}{192} &\\boldres{\\scalebox{0.85}{0.372}}&\\boldres{\\scalebox{0.85}{0.392}}&\\scalebox{0.85}{0.431}&\\scalebox{0.85}{0.446}&\\scalebox{0.85}{0.422}&\\scalebox{0.85}{0.425}&\\scalebox{0.85}{0.395}&\\scalebox{0.85}{0.404}&\\boldres{\\scalebox{0.85}{0.317}}&\\boldres{\\scalebox{0.85}{0.402}}\n    &\\scalebox{0.85}{0.401} &\\scalebox{0.85}{0.414} &\\scalebox{0.85}{0.404} &\\scalebox{0.85}{0.426} &\\scalebox{0.85}{0.344} &\\scalebox{0.85}{0.397}\n    \\\\\n    & \\scalebox{0.85}{336} &\\boldres{\\scalebox{0.85}{0.386}}&\\boldres{\\scalebox{0.85}{0.414}}&\\scalebox{0.85}{0.486}&\\scalebox{0.85}{0.474}&\\scalebox{0.85}{0.462}&\\scalebox{0.85}{0.460}&\\scalebox{0.85}{0.428}&\\scalebox{0.85}{0.434}&\\boldres{\\scalebox{0.85}{0.332}}&\\boldres{\\scalebox{0.85}{0.396}}\n    &\\scalebox{0.85}{0.437} &\\scalebox{0.85}{0.448} &\\scalebox{0.85}{0.406} &\\scalebox{0.85}{0.434} &\\scalebox{0.85}{0.360} &\\scalebox{0.85}{0.400}\n    \\\\\n    & \\scalebox{0.85}{720} &\\boldres{\\scalebox{0.85}{0.412}}&\\boldres{\\scalebox{0.85}{0.434}}&\\scalebox{0.85}{0.517}&\\scalebox{0.85}{0.522}&\\scalebox{0.85}{0.476}&\\scalebox{0.85}{0.475}&\\scalebox{0.85}{0.443}&\\scalebox{0.85}{0.451}&\\boldres{\\scalebox{0.85}{0.342}}&\\boldres{\\scalebox{0.85}{0.408}}\n    &\\scalebox{0.85}{0.469} &\\scalebox{0.85}{0.471} &\\scalebox{0.85}{0.448} &\\scalebox{0.85}{0.463} &\\scalebox{0.85}{0.428} &\\scalebox{0.85}{0.461}\n    \\\\\n    \\cmidrule(lr){2-18}\n    & \\scalebox{0.85}{Avg} &\\boldres{\\scalebox{0.85}{0.364}}&\\boldres{\\scalebox{0.85}{0.395}}&\\scalebox{0.85}{0.451}&\\scalebox{0.85}{0.460}&\\scalebox{0.85}{0.426}&\\scalebox{0.85}{0.435}&\\scalebox{0.85}{0.394}&\\scalebox{0.85}{0.412}&\\boldres{\\scalebox{0.85}{0.316}}&\\boldres{\\scalebox{0.85}{0.384}}\n    &\\scalebox{0.85}{0.412} &\\scalebox{0.85}{0.432} &\\scalebox{0.85}{0.397} &\\scalebox{0.85}{0.422} &\\scalebox{0.85}{0.350} &\\scalebox{0.85}{0.399}\n    \\\\\n    \\midrule\n\n    \\multirow{5}{*}{\\rotatebox{90}{\\scalebox{0.95}{ETTm1}}} \n    & \\scalebox{0.85}{96} &\\boldres{\\scalebox{0.85}{0.320}}&\\boldres{\\scalebox{0.85}{0.357}}&\\scalebox{0.85}{0.383}&\\scalebox{0.85}{0.408}&\\scalebox{0.85}{0.344}&\\scalebox{0.85}{0.378}&\\scalebox{0.85}{0.331}&\\scalebox{0.85}{0.378}&\\scalebox{0.85}{0.291}&\\scalebox{0.85}{0.340}\n    &\\scalebox{0.85}{0.338} &\\scalebox{0.85}{0.375} &\\scalebox{0.85}{0.316} &\\scalebox{0.85}{0.362} &\\boldres{\\scalebox{0.85}{0.288}} &\\boldres{\\scalebox{0.85}{0.336}}\n    \\\\\n    & \\scalebox{0.85}{192} &\\boldres{\\scalebox{0.85}{0.361}}&\\boldres{\\scalebox{0.85}{0.381}}&\\scalebox{0.85}{0.417}&\\scalebox{0.85}{0.421}&\\scalebox{0.85}{0.397}&\\scalebox{0.85}{0.408}&\\scalebox{0.85}{0.386}&\\scalebox{0.85}{0.399}&\\boldres{\\scalebox{0.85}{0.327}}&\\boldres{\\scalebox{0.85}{0.365}}\n    &\\scalebox{0.85}{0.392} &\\scalebox{0.85}{0.406} &\\scalebox{0.85}{0.374} &\\scalebox{0.85}{0.391} &\\scalebox{0.85}{0.332} &\\scalebox{0.85}{0.374}\n    \\\\\n    & \\scalebox{0.85}{336} &\\boldres{\\scalebox{0.85}{0.390}}&\\boldres{\\scalebox{0.85}{0.404}}&\\scalebox{0.85}{0.437}&\\scalebox{0.85}{0.448}&\\scalebox{0.85}{0.429}&\\scalebox{0.85}{0.430}&\\scalebox{0.85}{0.426}&\\scalebox{0.85}{0.421}&\\scalebox{0.85}{0.360}&\\boldres{\\scalebox{0.85}{0.381}}\n    &\\scalebox{0.85}{0.410} &\\scalebox{0.85}{0.426} &\\scalebox{0.85}{0.408} &\\scalebox{0.85}{0.411} &\\boldres{\\scalebox{0.85}{0.358}} &\\scalebox{0.85}{0.381}\n    \\\\\n    & \\scalebox{0.85}{720} &\\boldres{\\scalebox{0.85}{0.454}}&\\boldres{\\scalebox{0.85}{0.441}}&\\scalebox{0.85}{0.512}&\\scalebox{0.85}{0.481}&\\scalebox{0.85}{0.489}&\\scalebox{0.85}{0.460}&\\scalebox{0.85}{0.489}&\\scalebox{0.85}{0.465}&\\boldres{\\scalebox{0.85}{0.415}}&\\boldres{\\scalebox{0.85}{0.417}}\n    &\\scalebox{0.85}{0.481} &\\scalebox{0.85}{0.476} &\\scalebox{0.85}{0.472} &\\scalebox{0.85}{0.454} &\\scalebox{0.85}{0.420} &\\boldres{\\scalebox{0.85}{0.417}}\n    \\\\\n    \\cmidrule(lr){2-18}\n    & \\scalebox{0.85}{Avg} &\\boldres{\\scalebox{0.85}{0.381}}&\\boldres{\\scalebox{0.85}{0.395}}&\\scalebox{0.85}{0.438}&\\scalebox{0.85}{0.440}&\\scalebox{0.85}{0.415}&\\scalebox{0.85}{0.419}&\\scalebox{0.85}{0.408}&\\scalebox{0.85}{0.416}&\\boldres{\\scalebox{0.85}{0.348}}&\\boldres{\\scalebox{0.85}{0.375}}\n    &\\scalebox{0.85}{0.406} &\\scalebox{0.85}{0.421} &\\scalebox{0.85}{0.393} &\\scalebox{0.85}{0.405} &\\scalebox{0.85}{0.350} &\\scalebox{0.85}{0.377}\n    \\\\\n    \\midrule\n\n    \\multirow{5}{*}{\\rotatebox{90}{\\scalebox{0.95}{ETTm2}}} \n    & \\scalebox{0.85}{96} &\\boldres{\\scalebox{0.85}{0.175}}&\\boldres{\\scalebox{0.85}{0.258}}&\\scalebox{0.85}{0.201}&\\scalebox{0.85}{0.297}&\\scalebox{0.85}{0.191}&\\scalebox{0.85}{0.278}&\\scalebox{0.85}{0.179}&\\scalebox{0.85}{0.282}&\\scalebox{0.85}{0.164}&\\scalebox{0.85}{0.254}\n    &\\scalebox{0.85}{0.192} &\\scalebox{0.85}{0.274} &\\scalebox{0.85}{0.187} &\\scalebox{0.85}{0.268} &\\boldres{\\scalebox{0.85}{0.160}} &\\boldres{\\scalebox{0.85}{0.249}}\n    \\\\\n    & \\scalebox{0.85}{192} &\\boldres{\\scalebox{0.85}{0.237}}&\\boldres{\\scalebox{0.85}{0.299}}&\\scalebox{0.85}{0.261}&\\scalebox{0.85}{0.324}&\\scalebox{0.85}{0.258}&\\scalebox{0.85}{0.320}&\\scalebox{0.85}{0.244}&\\scalebox{0.85}{0.305}&\\boldres{\\scalebox{0.85}{0.223}}&\\boldres{\\scalebox{0.85}{0.295}}\n    &\\scalebox{0.85}{0.248} &\\scalebox{0.85}{0.322} &\\scalebox{0.85}{0.237} &\\scalebox{0.85}{0.301} &\\scalebox{0.85}{0.228} &\\scalebox{0.85}{0.299}\n    \\\\\n    & \\scalebox{0.85}{336} &\\boldres{\\scalebox{0.85}{0.298}}&\\boldres{\\scalebox{0.85}{0.340}}&\\scalebox{0.85}{0.328}&\\scalebox{0.85}{0.366}&\\scalebox{0.85}{0.319}&\\scalebox{0.85}{0.357}&\\scalebox{0.85}{0.320}&\\scalebox{0.85}{0.357}&\\scalebox{0.85}{0.279}&\\scalebox{0.85}{0.330}\n    &\\scalebox{0.85}{0.301} &\\scalebox{0.85}{0.348} &\\scalebox{0.85}{0.299} &\\scalebox{0.85}{0.352} &\\boldres{\\scalebox{0.85}{0.269}} &\\boldres{\\scalebox{0.85}{0.328}}\n    \\\\\n    & \\scalebox{0.85}{720} &\\boldres{\\scalebox{0.85}{0.391}}&\\boldres{\\scalebox{0.85}{0.396}}&\\scalebox{0.85}{0.424}&\\scalebox{0.85}{0.417}&\\scalebox{0.85}{0.417}&\\scalebox{0.85}{0.412}&\\scalebox{0.85}{0.419}&\\scalebox{0.85}{0.432}&\\boldres{\\scalebox{0.85}{0.359}}&\\boldres{\\scalebox{0.85}{0.383}}\n    &\\scalebox{0.85}{0.411} &\\scalebox{0.85}{0.398} &\\scalebox{0.85}{0.413} &\\scalebox{0.85}{0.419} &\\scalebox{0.85}{0.421} &\\scalebox{0.85}{0.426}\n    \\\\\n    \\cmidrule(lr){2-18}\n    &\\scalebox{0.85}{Avg} &\\boldres{\\scalebox{0.85}{0.275}}&\\boldres{\\scalebox{0.85}{0.323}}&\\scalebox{0.85}{0.303}&\\scalebox{0.85}{0.351}&\\scalebox{0.85}{0.296}&\\scalebox{0.85}{0.342}&\\scalebox{0.85}{0.290}&\\scalebox{0.85}{0.344}&\\boldres{\\scalebox{0.85}{0.256}}&\\boldres{\\scalebox{0.85}{0.315}}\n    &\\scalebox{0.85}{0.288} &\\scalebox{0.85}{0.336} &\\scalebox{0.85}{0.284} &\\scalebox{0.85}{0.335} &\\scalebox{0.85}{0.270} &\\scalebox{0.85}{0.326}\n    \\\\\n    % \\midrule\n    % \\multicolumn{2}{c}{\\scalebox{0.85}{{$1^{\\text{st}}$ Count}}}&\\scalebox{0.85}{65} \\\\\n    \\bottomrule\n  \\end{tabular}\n    \\end{small}\n  \\end{threeparttable}\n  }\n\\end{table}",
            "tab:PEMS_results_additional": "\\begin{table}[htbp]\n\\vspace{-20pt}\n\\caption{\\revise{Short-term forecasting results in the PEMS datasets with multiple variates.} All input lengths are 96 and prediction lengths are 12. A lower MAE, MAPE or RMSE indicates a better prediction.}\\label{tab:PEMS_results_additional}\n  \\vspace{3pt}\n  \\centering\n  % \\resizebox{\\columnwidth}{!}{\n  \\begin{threeparttable}\n  \\begin{small}\n  \\renewcommand{\\multirowsetup}{\\centering}\n  \\setlength{\\tabcolsep}{15.5pt}\n  \\begin{tabular}{c|c|c|c|c|c}\n    \\toprule\n    \\multicolumn{2}{c}{\\multirow{2}{*}{Models}} &\n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{\\textbf{TimeMixer}}}} &\n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{Scaleformer}}} &\n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{MTSMixer}}} &\n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{TSMixer}}} \n    \\\\\n    \\multicolumn{2}{c}{}&\\multicolumn{1}{c}{\\scalebox{0.95}{(\\textbf{Ours})}} &\n    \\multicolumn{1}{c}{\\scalebox{0.95}{\\citeyearpar{scaleformer}}} &\n    \\multicolumn{1}{c}{\\scalebox{0.95}{\\citeyearpar{li2023mtsmixers}}} &\n    \\multicolumn{1}{c}{\\scalebox{0.95}{\\citeyearpar{chen2023tsmixer}}} \n    \\\\\n    \\toprule\n    \n    \\multirow{3}{*}{\\scalebox{1.0}{\\rotatebox{0}{PEMS03}}} \n    & \\scalebox{1.0}{MAE} & \\boldres{\\scalebox{1.0}{14.63}} & \\scalebox{1.0}{17.66}  & \\scalebox{1.0}{18.63} & \\scalebox{1.0}{15.71}\n    \\\\\n    & \\scalebox{1.0}{MAPE} & \\boldres{\\scalebox{1.0}{14.54}} & \\scalebox{1.0}{17.58} & \\scalebox{1.0}{19.35} & \\scalebox{1.0}{15.28}\n    \\\\\n    & \\scalebox{1.0}{RMSE} & \\boldres{\\scalebox{1.0}{23.28}} & \\scalebox{1.0}{27.51} & \\scalebox{1.0}{28.85} & \\scalebox{1.0}{25.88}\n    \\\\\n    \\midrule\n    \\multirow{3}{*}{\\scalebox{1.0}{\\rotatebox{0}{PEMS04}}} \n    & \\scalebox{1.0}{MAE} & \\boldres{\\scalebox{1.0}{19.21}} & \\scalebox{1.0}{22.68} & \\scalebox{1.0}{25.57} & \\scalebox{1.0}{20.86}\n    \\\\\n    & \\scalebox{1.0}{MAPE} & \\boldres{\\scalebox{1.0}{12.53}} & \\scalebox{1.0}{14.81} & \\scalebox{1.0}{17.79} & \\scalebox{1.0}{12.97}\n    \\\\\n    & \\scalebox{1.0}{RMSE} & \\boldres{\\scalebox{1.0}{30.92} }& \\scalebox{1.0}{35.61} & \\scalebox{1.0}{39.92} & \\scalebox{1.0}{32.68}\n    \\\\\n\n    \\midrule\n    \\multirow{3}{*}{\\scalebox{1.0}{\\rotatebox{0}{PEMS07}}} \n    & \\scalebox{1.0}{MAE} & \\boldres{\\scalebox{1.0}{20.57}} & \\scalebox{1.0}{27.62} & \\scalebox{1.0}{25.69} & \\scalebox{1.0}{22.97} \n    \\\\\n    & \\scalebox{1.0}{MAPE} & \\boldres{\\scalebox{1.0}{8.62}} & \\scalebox{1.0}{12.68} & \\scalebox{1.0}{11.57} & \\scalebox{1.0}{9.93} \n    \\\\ \n    & \\scalebox{1.0}{RMSE} & \\boldres{\\scalebox{1.0}{33.59}} & \\scalebox{1.0}{42.27} & \\scalebox{1.0}{39.82} & \\scalebox{1.0}{35.68} \n    \\\\\n\n    \\midrule\n    \\multirow{3}{*}{\\scalebox{1.0}{\\rotatebox{0}{PEMS08}}} \n    & \\scalebox{1.0}{MAE} & \\boldres{\\scalebox{1.0}{15.22}} & \\scalebox{1.0}{20.74} & \\scalebox{1.0}{24.22}  & \\scalebox{1.0}{18.79}\n    \\\\\n    & \\scalebox{1.0}{MAPE} & \\boldres{\\scalebox{1.0}{9.67}} & \\scalebox{1.0}{12.81} & \\scalebox{1.0}{14.98} & \\scalebox{1.0}{10.69} \n    \\\\\n    & \\scalebox{1.0}{RMSE} & \\boldres{\\scalebox{1.0}{24.26}} & \\scalebox{1.0}{32.77} & \\scalebox{1.0}{37.21} & \\scalebox{1.0}{26.74} \n    \\\\\n    \n    \\bottomrule\n  \\end{tabular}\n    \\end{small}\n  \\end{threeparttable}\n  % }\n  \\vspace{-20pt}\n\\end{table}",
            "tab:M4_results_additional": "\\begin{table}[htbp]\n  \\caption{\\revise{Short-term forecasting results in the M4 dataset with a single variate.} All prediction lengths are in $\\left[ 6,48 \\right]$. A lower SMAPE, MASE or OWA indicates a better prediction.}\\label{tab:M4_results_additional}\n  \\centering\n  \\vspace{3pt}\n  % \\resizebox{\\columnwidth}{!}{\n  \\begin{threeparttable}\n  \\begin{small}\n  \\renewcommand{\\multirowsetup}{\\centering}\n  \\setlength{\\tabcolsep}{14.5pt}\n  \\begin{tabular}{cc|c|c|c|c|c}\n    \\toprule\n    \\multicolumn{3}{c}{\\multirow{2}{*}{Models}} & \n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{\\textbf{TimeMixer}}}}& \n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{Scaleformer}}} &\n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{{MTSMixer}}}} &\n    \\multicolumn{1}{c}{\\rotatebox{0}{\\scalebox{0.95}{TSMixer}}} \n    \\\\\n    \\multicolumn{1}{c}{}&\\multicolumn{1}{c}{} &\\multicolumn{1}{c}{} & \n    \\multicolumn{1}{c}{\\scalebox{0.95}{(\\textbf{Ours})}} &\n    \\multicolumn{1}{c}{\\scalebox{0.95}{\\citeyearpar{scaleformer}}} &\n    \\multicolumn{1}{c}{\\scalebox{0.95}{\\citeyearpar{li2023mtsmixers}}} &\n    \\multicolumn{1}{c}{\\scalebox{0.95}{\\citeyearpar{chen2023tsmixer}}} \n    \\\\\n    \\toprule\n    \\multicolumn{2}{c}{\\multirow{3}{*}{\\rotatebox{0}{\\scalebox{1.0}{Yearly}}}}\n    & \\scalebox{1.0}{SMAPE} &\\boldres{\\scalebox{1.0}{13.206}} &\\scalebox{1.0}{13.778} &\\scalebox{1.0}{20.071} &{\\scalebox{1.0}{19.845}} \n    \\\\\n    & & \\scalebox{1.0}{MASE} &\\boldres{\\scalebox{1.0}{2.916}} &\\scalebox{1.0}{3.176} &{\\scalebox{1.0}{4.537}} &\\scalebox{1.0}{4.439}  \n    \\\\\n    & & \\scalebox{1.0}{OWA}  &\\boldres{\\scalebox{1.0}{0.776}} &\\scalebox{1.0}{0.871} &\\scalebox{1.0}{1.185} &\\scalebox{1.0}{1.166} \n    \\\\\n    \\midrule\n    \\multicolumn{2}{c}{\\multirow{3}{*}{\\rotatebox{0}{\\scalebox{0.9}{Quarterly}}}}\n    & \\scalebox{1.0}{SMAPE} &\\boldres{\\scalebox{1.0}{9.996}} &\\scalebox{1.0}{10.727} &{\\scalebox{1.0}{16.371}} &\\scalebox{1.0}{16.322} \n    \\\\\n    & & \\scalebox{1.0}{MASE} &\\boldres{\\scalebox{1.0}{1.166}} &{\\scalebox{1.0}{1.291}} &\\scalebox{1.0}{2.216} &\\scalebox{1.0}{2.21} \n    \\\\\n    & & \\scalebox{1.0}{OWA} &\\boldres{\\scalebox{1.0}{0.825}} &{\\scalebox{1.0}{0.954}} &\\scalebox{1.0}{1.551} &\\scalebox{1.0}{1.543} \n    \\\\\n    \\midrule\n    \\multicolumn{2}{c}{\\multirow{3}{*}{\\rotatebox{0}{\\scalebox{1.0}{Monthly}}}}\n    & \\scalebox{1.0}{SMAPE} &\\boldres{\\scalebox{1.0}{12.605}} &\\scalebox{1.0}{13.378} &{\\scalebox{1.0}{18.947}} &\\scalebox{1.0}{19.248} \n    \\\\\n    & & \\scalebox{1.0}{MASE} &\\boldres{\\scalebox{1.0}{0.919}} &\\scalebox{1.0}{1.104} &{\\scalebox{1.0}{1.725}} &\\scalebox{1.0}{1.774} \n    \\\\\n    & & \\scalebox{1.0}{OWA}  &\\boldres{\\scalebox{1.0}{0.869}} &\\scalebox{1.0}{0.972} &{\\scalebox{1.0}{1.468}} &\\scalebox{1.0}{1.501} \n    \\\\\n    \\midrule\n    \\multicolumn{2}{c}{\\multirow{3}{*}{\\rotatebox{0}{\\scalebox{1.0}{Others}}}}\n    & \\scalebox{1.0}{SMAPE} &\\boldres{\\scalebox{1.0}{4.564}} &\\scalebox{1.0}{4.972} &{\\scalebox{1.0}{7.493}} &\\scalebox{1.0}{7.494}  \n    \\\\\n    & & \\scalebox{1.0}{MASE} &\\boldres{\\scalebox{1.0}{3.115}} &{\\scalebox{1.0}{3.311}} &\\scalebox{1.0}{5.457}  &\\scalebox{1.0}{5.463} \n    \\\\\n    & & \\scalebox{1.0}{OWA} &\\boldres{\\scalebox{1.0}{0.982}} &\\scalebox{1.0}{1.112} &\\scalebox{1.0}{1.649}  &{\\scalebox{1.0}{1.651}} \n    \\\\\n    \\midrule\n    \\multicolumn{2}{c|}{Weighted}\n    &\\scalebox{1.0}{SMAPE} &\\boldres{\\scalebox{1.0}{11.723}} &\\scalebox{1.0}{12.978} &{\\scalebox{1.0}{18.041}} &\\scalebox{1.0}{18.095} \n    \\\\\n    \\multicolumn{2}{c|}{Average} &  \\scalebox{1.0}{MASE} &\\boldres{\\scalebox{1.0}{1.559}} &\\scalebox{1.0}{1.764} &{\\scalebox{1.0}{2.677}} &\\scalebox{1.0}{2.674} \n    \\\\\n    & & \\scalebox{1.0}{OWA}   &\\boldres{\\scalebox{1.0}{0.840}} &\\scalebox{1.0}{0.921} &{\\scalebox{1.0}{1.364}} &\\scalebox{1.0}{1.336} \n    \\\\\n    \\bottomrule\n  \\end{tabular}\n    \\end{small}\n  \\end{threeparttable}\n  % }\n  \\vspace{-5pt}\n\\end{table}"
        },
        "figures": {
            "fig:fig1": "\\begin{figure*}[t]\n\\label{fig:fig1}\n\\begin{center}\n\t\\centerline{\\includegraphics[width=\\columnwidth]{fig/up-down.pdf}}\n        \\vspace{-5pt}\n\t\\caption{\\revise{The temporal linear layer in seasonal mixing (a), trend mixing (b)} and future prediction (c).}\n\t\\label{fig:components}\n\\end{center}\n\\vspace{-25pt}\n\\end{figure*}",
            "fig:scale_sensitivity": "\\begin{wrapfigure}{r}{0.36\\textwidth}\n  \\begin{center}\n  \\vspace{-25pt}\n    \\includegraphics[width=0.35\\textwidth]{fig/scale_number_analysis.pdf}\n  \\end{center}\n  \\vspace{-15pt}\n  \\caption{\\small{Analysis on number of scales on ETTm1 dataset.}}\\label{fig:scale_sensitivity}\n  \\vspace{-20pt}\n\\end{wrapfigure}"
        },
        "equations": {
            "eq:equ:equ1": "\\begin{equation}\\label{equ:equ1}\n  \\begin{split}\n\\mathcal{X}^{l} = \\operatorname{PDM}(\\mathcal{X}^{l-1}), \\ \\ l\\in\\{0,\\cdots, L\\},\\\\\n  \\end{split}\n\\end{equation}",
            "eq:equ:equ2": "\\begin{equation}\\label{equ:equ2}\n  \\begin{split}\n    \\widehat{\\mathbf{x}} = \\operatorname{FMM}(\\mathcal{X}^L),\\\\\n  \\end{split}\n\\end{equation}",
            "eq:equ:equ3": "\\begin{equation}\\label{equ:equ3}\n  \\begin{split}\n    \\mathbf{s}_{m}^{l},\\mathbf{t}_{m}^{l}&=\\operatorname{SeriesDecomp}(\\mathbf{x}_{m}^{l}), m\\in\\{0,\\cdots, M\\}, \\\\\n    \\mathcal{X}^l = \\mathcal{X}^{l-1} + &\\operatorname{FeedForward}\\bigg(\\operatorname{S-Mix}\\big(\\{\\mathbf{s}_{m}^{l}\\}_{m=0}^{M}\\big)+\\operatorname{T-Mix}\\big(\\{\\mathbf{t}_{m}^{l}\\}_{m=0}^{M}\\big)\\bigg), \\\\\n  \\end{split}\n\\end{equation}",
            "eq:equ:season_mxiing": "\\begin{equation}\\label{equ:season_mxiing} \\\n  \\begin{split}\n\\mathrm{for}\\  m\\mathrm{:}\\ 1\\to M \\ \\mathrm{do}\\mathrm{:}\\ \\ \\ \\ \\mathbf{s}_{m}^{l} = \\mathbf{s}_{m}^{l} + \\revise{\\operatorname{Bottom-Up-Mixing}}(\\mathbf{s}_{m-1}^{l}).\n  \\end{split}\n\\end{equation}",
            "eq:equ:trend_mixing": "\\begin{equation}\\label{equ:trend_mixing} \n  \\begin{split}\n\\mathrm{for}\\  m\\mathrm{:}\\ (M-1)\\to 0\\ \\mathrm{do}\\mathrm{:}\\ \\ \\ \\ \\mathbf{t}_{m}^{l} = \\mathbf{t}_{m}^{l} + \\revise{\\operatorname{Top-Down-Mixing}}(\\mathbf{t}_{m+1}^{l}),\n  \\end{split}\n\\end{equation}",
            "eq:equ:fmm": "\\begin{equation}\\label{equ:fmm} \n  \\begin{split}\n   \\widehat{\\mathbf{x}}_{m}=\\operatorname{Predictor}_{m}(\\mathbf{x}_{m}^L),\\ m\\in\\{0,\\cdots,M\\}, \\  \\widehat{\\mathbf{x}}=\\sum_{m=0}^{M} \\widehat{\\mathbf{x}}_{m},\\\\\n  \\end{split}\n\\end{equation}",
            "eq:1": "\\begin{align*} \\label{equ:metrics}\n    \\text{RMSE} &= (\\sum_{i=1}^F (\\mathbf{X}_{i} - \\widehat{\\mathbf{X}}_{i})^2)^{\\frac{1}{2}},\n    &\n    \\text{MAE} &= \\sum_{i=1}^F|\\mathbf{X}_{i} - \\widehat{\\mathbf{X}}_{i}|,\\\\\n    \\text{SMAPE} &= \\frac{200}{F} \\sum_{i=1}^F \\frac{|\\mathbf{X}_{i} - \\widehat{\\mathbf{X}}_{i}|}{|\\mathbf{X}_{i}| + |\\widehat{\\mathbf{X}}_{i}|},\n    &\n    \\text{MAPE} &= \\frac{100}{F} \\sum_{i=1}^F \\frac{|\\mathbf{X}_{i} - \\widehat{\\mathbf{X}}_{i}|}{|\\mathbf{X}_{i}|}, \\\\\n    \\text{MASE} &= \\frac{1}{F} \\sum_{i=1}^F \\frac{|\\mathbf{X}_{i} - \\widehat{\\mathbf{X}}_{i}|}{\\frac{1}{F-s}\\sum_{j=s+1}^{F}|\\mathbf{X}_j - \\mathbf{X}_{j-s}|},\n    &\n    \\text{OWA} &= \\frac{1}{2} \\left[ \\frac{\\text{SMAPE}}{\\text{SMAPE}_{\\textrm{Na\u00efve2}}}  + \\frac{\\text{MASE}}{\\text{MASE}_{\\textrm{Na\u00efve2}}}  \\right],\n\\end{align*}"
        },
        "git_link": "https://github.com/kwuking/TimeMixer"
    }
}