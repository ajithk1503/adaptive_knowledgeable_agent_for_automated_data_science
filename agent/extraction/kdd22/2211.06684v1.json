{
    "meta_info": {
        "title": "A Generalized Doubly Robust Learning Framework for Debiasing Post-Click  Conversion Rate Prediction",
        "abstract": "Post-click conversion rate (CVR) prediction is an essential task for\ndiscovering user interests and increasing platform revenues in a range of\nindustrial applications. One of the most challenging problems of this task is\nthe existence of severe selection bias caused by the inherent self-selection\nbehavior of users and the item selection process of systems. Currently, doubly\nrobust (DR) learning approaches achieve the state-of-the-art performance for\ndebiasing CVR prediction. However, in this paper, by theoretically analyzing\nthe bias, variance and generalization bounds of DR methods, we find that\nexisting DR approaches may have poor generalization caused by inaccurate\nestimation of propensity scores and imputation errors, which often occur in\npractice. Motivated by such analysis, we propose a generalized learning\nframework that not only unifies existing DR methods, but also provides a\nvaluable opportunity to develop a series of new debiasing techniques to\naccommodate different application scenarios. Based on the framework, we propose\ntwo new DR methods, namely DR-BIAS and DR-MSE. DR-BIAS directly controls the\nbias of DR loss, while DR-MSE balances the bias and variance flexibly, which\nachieves better generalization performance. In addition, we propose a novel\ntri-level joint learning optimization method for DR-MSE in CVR prediction, and\nan efficient training algorithm correspondingly. We conduct extensive\nexperiments on both real-world and semi-synthetic datasets, which validate the\neffectiveness of our proposed methods.",
        "author": "Quanyu Dai, Haoxuan Li, Peng Wu, Zhenhua Dong, Xiao-Hua Zhou, Rui Zhang, Rui zhang, Jie Sun",
        "link": "http://arxiv.org/abs/2211.06684v1",
        "category": [
            "cs.LG"
        ]
    },
    "latex_extraction": {
        "content": {
            "section 1": {
                "name": "Introduction",
                "content": "\n\n% 1. Background, significance of pCVR; application scenarios; key problems  \nThe post-click conversion rate (CVR) prediction has gained much attention in modern recommender systems \\cite{RecSys_Saito20, ESMM18, Wu-etal2018, MRDR_DL, wu2022causal}, as post-click conversion feedback contains strong signals of user preference and directly contributes to the gross merchandise volume (GMV). In many industrial applications, \nCVR prediction is commonly regarded as the central task for discovering user interests and increasing platform revenues.\n% such as e-commerce transaction, music website, and academic article download,  \nFor a user-item pair, CVR represents the probability of the user consuming the item after he/she clicks it.\nEssentially, the task of CVR prediction is a {\\bf counterfactual} problem. This is because what we want to know during inference is intrinsically the conversion rates of all user-item pairs under the assumption that all items are clicked by all users, which is a hypothetical situation that contradicts reality. \n\n% 2. Challenges: NMAR, Sparsity\nMost of the literature treats CVR prediction as a missing data problem in which the conversion labels are observed in clicked events and missing in unclicked events. A conventional and natural strategy is to train the CVR model only based on clicked events and then predict CVR for all the events~\\cite{KDD_LuPWPWY17,IJCAI_SuZDZYWBXHY20}. However, this estimator is biased and often obtains a sub-optimal result due to the existence of severe selection bias~\\cite{ESMM18,MRDR_DL}. In addition, the data sparsity issue, namely, the sample size of clicked events being much smaller than that of unclicked events, will amplify the difference between these two types of events and thus aggravate the selection bias issue.\n    \n% there are two types of selection biases in recommender system. One is \n%  Selection bias \n%  is induced by preferential selection of units for data analysis \\cite{Bareinboim-etal2014}.\n%  In addition, big\n% the sample size of clicked events is much smaller than that of unclicked events, which is called the data sparsity problem. \n% For example, in the read-world experiments, ... \n% As a consequence, the pCVR prediction model may not be sufficiently trained \\cite{Zhang-etal2020}, resulting in an unstable estimator.  \n\n% is valid only when the distributions between clicked events and unclicked events are similar,\n%    Otherwise, the approach suffers the problem of implicitly making extrapolation and the resulting estimator is biased. % unreliable conclusions. \n% Extrapolation is dangerous, and its good performance is partly a matter of luck \\cite{Molenberghs-etal2015}.   \n% \\begin{figure}[h!]\n% \\centering\n% \\includegraphics[scale = 0.25]{fig1_1_1_1.pdf}\n% \\caption{pCVR prediction task.}\n% \\label{fig1}\n% \\end{figure}\n% The task of pCVR prediction is challenge due to the selection bias and data sparsity.  Generally, a big systematic differences exists between the     \n% distributions of clicked and unclicked groups, leading to a selection bias and invalidating the traditional methods.  In addition, \n% the sample size of clicked events is much smaller than that of unclicked events, which is called the data sparsity problem. \n% For example, in the read-world experiments, ... \n% As a consequence, the pCVR prediction model may not be sufficiently trained \\cite{Zhang-etal2020}, resulting in an unstable estimator.  \n\n% only a data sparsity problem \n% will aggravate the selection bias problem.  \n\n\n% 3. Existing methods and its drawbacks \n% Various\nSeveral approaches have been proposed to derive unbiased estimators of CVR by dealing with selection bias. % obtained unbiased estimators of CVR.\n% in debiasing pCVR prediction in recent years.  \nError imputation~\\cite{chang2010training} and inverse propensity score (IPS) weighting  \\cite{Multi_IPW,Schnabel-etal2016} are two main strategies for debiasing CVR prediction. \n%Error imputation based (EIB) methods try to estimate the prediction errors for unclicked events, and then derive an unbiased loss function by averaging the prediction error of all events. However,  EIB estimator relies heavily on the extrapolation of the error imputation model, causing a poor performance in practice.   The IPS approach models the probability of click, called propensity score, and obtains an unbiased loss function through weighting the prediction error of  clicked events with the inverse propensity score.Nevertheless, IPS methods have encountered the problem of high variance in the case of small propensity scores, resulting in a sub-optimal performance \\cite{MRDR_DL}.   \n% Moreover, \nIn addition, Doubly robust (DR) estimators can be constructed by combining EIB and IPS approaches \\cite{Multi_IPW,RecSys_Saito20,Wu-etal2018}. \nA DR estimator enjoys the property of double robustness, which guarantees the unbiased estimation of CVR if either the imputed errors or propensity scores are accurate. \n% Generally, \nCompared with EIB and IPS methods, the DR method has a better performance in general~\\cite{Wang-Zhang-Sun-Qi2019}. \n\n% for CVR prediction task\n% More related works are discussed in Section 6. \n\n\n% 4. Motivation and research gap\nThere are still some concerns for DR methods, even though they usually compare favorably with EIB and IPS estimators. \nTheoretical analysis of DR estimators in Section~\\ref{dr_concerns} shows that the bias, variance and generalization bounds all depend on the error deviation of the imputation model weighted by the inverse of propensity score. This is a worrying result, because the inverse of propensity score tends to be large in unclicked events and error deviations of the imputation model are most likely to be inaccurate in unclicked events due to the selection bias and data sparsity. \nIt indicates that the bias, variance and generalization bounds may still be large \nunder inaccurate imputed errors in unclicked events.  \n% The concern is inherent and result from the problem of data sparsity.  \nRecently, several approaches, mainly including doubly robust joint learning (DR-JL) \n\\cite{Wang-Zhang-Sun-Qi2019} and more robust doubly robust (MRDR) \\cite{MRDR_DL}, have been designed to alleviate this problem. \n%MRDR aims to reduce the variance of DR loss function and anticipates deriving a better estimator of CVR. However, intuitively, this strategy of reducing variance is less effective when the bias is large. \nMRDR aims to reduce the variance of DR loss to enhance model robustness, but it may still have poor generalization when the bias is large. \nDR-JL attempts to reduce the error deviation of the imputation model\n% generalization bound of DR loss function \nin order to obtain a more accurate estimator of CVR, but this method does not\n control the bias and variance directly. \n Therefore, it would be helpful if we could find a more effective way to control the bias and variance directly.    \n% Further discussion about the existing approaches is provided in Section 2.2 and Section 3.\n\n% 5. The proposed methods and contributions\n% Is it helpful to the problem of data sparsity.  \nIn this paper, we reveal the counterfactual issues behind the CVR prediction task and give a formal and strict causal definition of CVR. %\\col{for the first time \"delete?\"}.  \nThen, by analyzing the bias, variance and generalization bound of the DR estimator, we derive a novel generalized learning framework that can accommodate a wide range of CVR estimators through specifying different metrics of loss functions. \nThis framework unifies various existing doubly robust methods for debiasing CVR prediction, such as DR-JL and MRDR.\nMost importantly, it provides key insights for designing new estimators to accommodate different application scenarios in CVR prediction. \nBased on this framework, from a perspective of bias-variance trade-off, we propose two new doubly robust estimators, called {\\bf DR-BIAS} and {\\bf DR-MSE}, which are designed to more flexibly control the bias and mean squared error (MSE) of DR loss function, respectively. \nDR-MSE achieves better generalization performance based on our analysis compared with existing DR based methods. In addition, we propose a novel tri-level joint learning optimization method for flexible DR-MSE in CVR prediction, and an efficient training algorithm correspondingly.\nExtensive experiments are carried out to validate the advantages of the proposed methods compared with state-of-the-art techniques. DR-MSE outperforms them up to 3.22\\% in DCG@2 in our experiments.\n\nThe main contributions of this paper can be summarized as follows:\n(1) We propose a generalized framework of doubly robust learning, which not only unifies the existing DR methods, but also provides key insights for designing new estimators with different requirements to accommodate different application scenarios.\n(2) Based on the proposed framework, we design two new doubly robust methods, called DR-BIAS and DR-MSE, which can better control the bias and mean squared error, compared with existing methods.\n(3) For the bias-variance tradeoff parameter of DR-MSE, we propose a tri-level DR-MSE joint learning optimization for the CVR prediction task, and an efficient training algorithm correspondingly.\n(4) Experimental results on both \\textbf{real-world} and \\textbf{semi-synthetic} datasets show that the two proposed doubly robust methods outperform the state-of-the-art methods significantly. Especially, both datasets with missing-at-random ratings and large industrial dataset are used for comprehensive evaluation. \n\n% By analyzing the bias, variance and \n% \t\\begin{itemize}[leftmargin=5.5mm]\n% \t\t% \\item  We provide a strict causal definition of CVR in the potential outcome framework~\\cite{Rubin1974,Neyman1990} for the first time, which is more coherent and consistent with the practical implications of CVR than the conventional definition.\n\t\t\n% \t\t\\item  We propose a generalized framework of doubly robust learning, which not only unifies the existing DR methods, but also provides key insights for designing new estimators with different requirements to accommodate different application scenarios.\n\t\t\n% \t\t\\item Based on the proposed framework, we design two new doubly robust methods, called DR-BIAS and DR-MSE, which can better control the bias and mean squared error, compared with existing methods.\n% \t\t% of DR loss function.\n\t\t\n% \t\t\\item For the bias-variance tradeoff parameter of DR-MSE, we propose a tri-level DR-MSE joint learning optimization for the CVR prediction task, and an efficient training algorithm correspondingly.\n\t\t\n% \t%\t\\item Theoretical analyses are further presented  to demonstrate the proposed methods and its influence on error imputation  model. \n\t\t\n% \t\t\\item %Experimental results on semi-synthetic and real-world datasets show that the two proposed doubly robust approaches outperform the state-of-the-art methods significantly. \n% \t\tExperimental results on both \\textbf{real-world} and \\textbf{semi-synthetic} datasets show that the two proposed doubly robust methods outperform the state-of-the-art methods significantly. Especially, both datasets with missing-at-random ratings and large industrial dataset are used for comprehensive evaluation. \n% \t\\end{itemize}\n\n\n\n% ===============================================\n"
            },
            "section 2": {
                "name": "Preliminaries",
                "content": "\nIn this section, we uncover the counterfactual feature of CVR prediction task % and present a {\\bf causal} definition of CVR in\nwithin the potential outcome framework~\\cite{Rubin1974,Imbens-Rubin2015}, \n% and then formulate the counterfactual problem of estimating pCVR as a missing data problem. Finally,\nand discuss some existing approaches for CVR prediction. \n% based on the causal definition. \n% The theoretical analysis of these methods in Section 3 will motivate us to  propose a new method. \n\n",
                "subsection 2.1": {
                    "name": "Causal Problem Definition",
                    "content": "\nNotation is described as follows.  \nLet $\\cU = \\{1, 2, ..., m\\}$ and  $\\cI = \\{1, 2, ..., n\\}$ be the sets of $m$ users and $n$ items, respectively, and $\\cD = \\cU \\times \\cI$ be the set of all user-item pairs. Let $x_{u,i}$ be the feature vector of user $u$ and item $i$, and   $r_{u,i} \\in \\{0, 1\\}$ be the indicator of the observed conversion label.\nLet $o_{u,i}$ be the indicator of a click event, i.e., $o_{u,i} = 1$ if user $u$ clicks item $i$, $o_{u,i} = 0$ otherwise. Then, $\\cO = \\{ (u,i) \\mid (u,i)\\in \\cD, o_{u,i} =  1 \\}$ denotes all the clicked events.   \n% Denote $\\bR \\in \\{0,  1\\}^{m\\times n}$ as the observed conversion label matrix where each element $r_{u,i} \\in \\{0, 1\\}$ an indicator of a conversion action. \n\nFor any user-item pair $(u,i)$, we are interested in predicting the CVR {\\bf if} user $u$  had clicked item $i$. Notice in particular that the word ``{\\bf if}'' is {\\bf counterfactual}.\nSpecifically, in the real world, each user clicks only some items and many items have never been clicked by some users, but what we want to know is the conversion rates of all the user-item pairs when each user clicks all items, which is a hypothetical situation \n that contradicts reality.\n% in the hypothesis world where every user has clicked all items.  \n% Better if we present it with a plot. \n \nPotential outcome is a basic tool to delineate counterfactual quantity in causal inference \\cite{Imbens-Rubin2015}.\nThrough it, the task of predicting CVR can be %easily  \ndefined formally.  Concretely,  we treat  $o_{u,i}$ as a treatment (or an intervention) and define the potential conversion label   \n   $r_{u,i}(1)$, which represents the conversion label of a user $u$ on an item $i$ if the item is clicked by the user. Correspondingly, $r_{u,i}(0)$ is defined as the conversion label if the user $u$ did not click the item $i$.\n% Based on the potential outcomes,\nThen the CVR can be fundamentally defined as\n    {%\\small\n  \\begin{equation}\\label{cvr}     \n  \\P ( r_{u,i}(1) = 1 \\mid X_{u,i}= x_{u,i}  ),      \n  \\end{equation}\t\n  }\nwhich is a causal definition and it is \ncoherent and consistent with the practical implications of CVR in recommender systems.  In comparison,  the conventional definition of CVR (see \\cite{ESMM18} ), defined by  \n\t\t$ \\P ( r_{u,i} = 1 \\mid X_{u,i}= x_{u,i},  o_{u,i}  = 1 )$, \nis based on association (or correlation) and  lost the meaning of ``counterfactual''.  \n% Actually, the traditional definition of CVR means the probability that $r_{u,i} = 1$ conditional on events $\\{ X_{u,i} = x_{u,i}, o_{u,i} = 1 \\}$, while the counterfactual definition in (\\ref{cvr}) represents the probability that $r_{u,i} = 1$ conditional on $\\{ X_{u,i} = x_{u,i}\\}$ {\\bf if we intervene to make $o_{u,i} = 1$}  \\cite{Pearl-Glymour-Jewell2016}.\n % In the distributional terminology, $\\P ( r_{u,i} = 1 \\mid X_{u,i}= x_{u,i},  o_{u,i}  = 1 )$ reflects the  distribution of $r_{u,i}$ \\col{among} the user-item pairs with $ X_{u,i} = x_{u,i}$ and $o_{u,i} = 1$, while  $    \\P ( r_{u,i}(1) = 1 \\mid X_{u,i}= x_{u,i} )$ denotes the the population distribution of $r_{u,i}$\n% A limitation of the traditional definition is that the user-item pairs in unclicked events are undefined. For more discussion about their differences, please refer to \\cite{Pearl-Glymour-Jewell2016, Pearl-Mackenzie2018}.  % between these two definitions,\n   \n% only one counterfactual is observable\n\n% are counterfactual and hence \n% To bridge this gap, the consistency assumption~\\cite{Hernan-Robins2020} is imposed throughout, which asserts that   {\\small\t\\[  r_{u,i} =   \\begin{cases}\n%\t\t\t\t\t&\tr_{u,i}(1),   \\quad \\text{if } o_{u,i} = 1, \\\\\n%\t\t\t\t\t&  r_{u,i}(0),   \\quad \\text{if } o_{u,i} = 0. \n%\t\\end{cases}\n%\t \\]\n%\t }\n%The consistency assumption relates the potential conversion labels $(r_{u,i}(1), r_{u,i}(0))$ in hypothetical scenarios  with the observed conversion label $r_{u,i}$ in reality, thus possibly enabling us to unbiasedly estimate CVR with observed data. \n% Otherwise, it is impossible to estimate CVR correctly, in that CVR is defined through $r_{u,i}(1)$ and the connections between observed $r_{u,i}$ and unobserved $r_{u,i}(1)$ are unknown.   \nFor estimating CVR in Equation (\\ref{cvr}), a fundamental challenge is that only one of the potential outcome $(r_{u,i}(1), r_{u,i}(0))$ is observable. \nBy consistency assumption, $r_{u,i}(1)$ is observed  when $o_{u,i} = 1$, missing otherwise. \n% namely, \n%   \t\\[  r_{u,i}(1) = r_{u,i}, \\text{ if }  o_{u,i} = 1;  r_{u,i}(1) \\text{ is missing, otherwise.}  \n% \t \\]   \nTherefore, the goal of estimating CVR can be recast into a missing data problem.  \n% Table~\\ref{cvr_data} clearly illustrates it by presenting the corresponding data structure in the real world and the hypothetical world. We do not include $r_{u,i}(0)$ in the table since it is not what we concern about in the CVR prediction problem.\n  % and the corresponding data structure are  described in Table 1, from which we can see that the data of $\\{o_{u,i}, x_{u,i}, r_{u,i} \\}$ is fully observed for all events, while the \n % In addition, it is often the case where $r_{u,i}(1)$ is missing-not-at-random (MNAR),  which poses a big challenge  to estimate CVR.  % deal with.    % address      \n%\t  It is important to note that $r_{u,i}$ is always fully observed, while  $r_{u,i}(1)$ is observed only when $o_{u,i} = 1$.    \n%\\begin{table}[t] \n%\\centering\n%\t\\caption{Data structure for estimating CVR. $r_{u,i}(1)$ can be observed in real world when the exposed items are clicked by users; it cannot be observed, otherwise.} \n%\t\\vspace{-0.25cm}\n%\\footnotesize  \n%\\begin{tabular}{ ccc | c}\n%\\hline \n %     \\multicolumn{3}{c | }{ real world } &  hypothetical world \\\\ \n% \\hline\n%\t   \t        $o_{u, i}$   &    $x_{u, i}$    &  $r_{u,i}$   &  $r_{u,i}(1)$      \\\\  \n%\t\t\\hline\t\t\n %                  1        &    \\checkmark     &   \\checkmark   &   \\checkmark             \\\\\n  %                 1        &    \\checkmark       &   \\checkmark   &   \\checkmark              \\\\ \n   %                1        &    \\checkmark      &   \\checkmark    &   \\checkmark        \\\\\n\t%         \\hline  \n\t %               0       &    \\checkmark      &     \\checkmark       &   ?    \\\\\n      %              0      &    \\checkmark       &      \\checkmark     &     ?   \\\\ \n       %            0       &    \\checkmark        &      \\checkmark      &    ?  \\\\\n\t    %     \\hline \n% \\multicolumn{3}{c}{ \\underbrace{  }_{ real world  }  }\t &   \\\\ \n\t%\\end{tabular}\n\t%\\begin{center}\n%Note: Symbol $\\checkmark$ indicates that the element is observed; $?$ denotes missing. \n%\\end{center}\n%\\label{cvr_data}\n%\\vspace{-0.25cm}\n%\\end{table}\n\nFor ease of presentation, we denote $\\bR \\in \\{0,  1\\}^{m\\times n}$ as the full potential conversion label matrix with each element being $r_{u,i}(1)$, and let $\\bR^{o} = \\{ r_{u,i}(1) \\mid (u,i) \\in \\cO \\} = \\{ r_{u,i} \\mid (u,i) \\in \\cO \\}$ be the set consisting of potential conversion labels $r_{u,i}(1)$ in clicked events.  \nLet $\\hat \\bR \\in [0, 1]^{m\\times n}$ be the predicted conversion rate matrix, where each entry $\\hat r_{u,i}(1) \\in [0, 1]$ denotes the predicted conversion rate obtained by a model $f_{\\phi}(x_{u,i})$ with parameters $\\phi$. If the full potential conversion label matrix $\\bR$ was observed,  the ideal loss function is \n% for solving parameters $\\phi$ is given as \n        {%\\small\n\t\t\\begin{equation}\n\t\t\t\t\\cL_{ideal}(\\hat \\bR, \\bR)  %=\\cL_{ideal}(\\phi)\n\t\t\t\t=  \\frac{1}{|\\cD|}  \\sum_{(u,i) \\in \\cD} e_{u,i},   \n\t\t\\end{equation}    \n\t\t}\nwhere $e_{u,i}$ is the prediction error. In this paper, we employ the cross entropy loss  \n \t\t\t$e_{u,i}  %= CE( {r_{u,i}(1) , \\hat r_{u,i}(1)}) \n \t\t\t= - r_{u,i}(1) \\log \\{\\hat r_{u,i}(1) \\} - \\{1- r_{u,i}(1)\\} \\log \\{1 - \\hat r_{u,i}(1)\\}$. \n\t{$\\cL_{ideal}(\\hat \\bR, \\bR)$} can be regarded as a benchmark of unbiased loss function theoretically, even though it is infeasible  due to the %unavailability\n\tinaccessibility of $\\bR$ practically.\n\n\n% ===============================================\n"
                },
                "subsection 2.2": {
                    "name": "Existing Methods",
                    "content": "\\label{existing_methods}\nA direct method is to use the following loss function \n{%\\small\n\t $ \\cL_{naive}(\\hat \\bR, \\bR^{o})  = \n\t\t |\\cO|^{-1} \\sum_{(u,i) \\in \\cO } e_{u,i}$ \n}\nbased on the observed conversion labels $\\bR^o$. {$\\cL_{naive}(\\hat \\bR, \\bR^{o})$} is not an unbiased estimate of {$\\cL_{ideal}(\\hat \\bR, \\bR)$}. Next, we will briefly review some typical and latest methods for addressing the selection bias issue.\n\n% =======================================\n",
                    "subsubsection 2.2.1": {
                        "name": "Error Imputation Based Estimator",
                        "content": "  \n\nThe error imputation based (EIB) estimator  can be derived by introducing an  error imputation model $\\hat e_{u,i} = g_{\\theta}(x_{u,i})$ to fit the prediction error $e_{u,i}$. % for the unclicked events.  \nGiven the imputed errors,  the loss function of EIB method is given as  \n\t$ \n\t\t\t \\cL_{EIB}(\\hat \\bR, \\bR^{o}) =   | \\cD |^{-1}  \\sum_{(u,i) \\in \\cD} [ o_{u,i} e_{u,i} + (1- o_{u,i}) \\hat e_{u,i} ].\n\t$\n\n%     {\\small\n% \t\\begin{equation}   \n% \t\t\t \\cL_{EIB}(\\hat \\bR, \\bR^{o}) =  \\frac{1}{ | \\cD |} \\sum_{(u,i) \\in \\cD} [ o_{u,i} e_{u,i} + (1- o_{u,i}) \\hat e_{u,i} ].\n% \t\\end{equation}\n% \t}\n%   It can be seen that {\\small$\\cL_{EIB}(\\hat \\bR, \\bR^{o}) =  \\cL_{ideal}(\\hat \\bR, \\bR)$}, provided that $\\hat e_{u,i}$ estimates $e_{u,i}$ accurately.  Nevertheless, it is hard to obtain accurate error imputation in practice and usually leads to an estimator with large bias. %  and poor \n%   stemming from the truth that error imputation model is trained with clicked events while using the predicted values for unclicked events. This relies heavily on extrapolation since the clicked events are sparse and there may exist significant difference between the distributions of clicked events and unclicked events \\cite{Tan2007, Kang-Schafer2007}.  Thus,  EIB method usually leads to an estimator with large bias. %  and poor performance. \n\n\n% ======================================\n"
                    },
                    "subsubsection 2.2.2": {
                        "name": "Inverse Propensity Score Estimator",
                        "content": " The inverse propensity score (IPS) approach \\cite{Schnabel-etal2016} aims to recover the distribution of all events by  weighting the clicked events with $1/p_{u,i}$, where $p_{u,i} = \\P(o_{u,i} = 1) = \\mathbb{E}[o_{u,i}]$ is the propensity score~\\cite{Rosenbaum-Rubin1983}. Given the estimate of $p_{u,i}$, denoted as $\\hat p_{u,i}$,  the loss function of IPS estimator  is presented as \n  $\t\t\t\\cL_{IPS}(\\hat \\bR, \\bR^{o}) = |\\cD|^{-1}  \\sum_{(u,i) \\in \\cD} o_{u,i} e_{u,i} / \\hat p_{u,i} $.  \n\t\t\t\t\n    %             {\\small\n\t\t\t\t% \\begin{equation}\n\t\t\t\t% \t\\cL_{IPS}(\\hat \\bR, \\bR^{o}) = \\frac{1}{ |\\cD| } \\sum_{(u,i) \\in \\cD} \\frac{ o_{u,i} e_{u,i} }{ \\hat p_{u,i } },  \n\t\t\t\t% \\end{equation}\n\t\t\t\t% }\n% {\\small$\\cL_{IPS}(\\hat \\bR, \\bR^{o})$} is an unbiased estimate of the ideal loss function, that is,\t\t{\\small $E_{\\cO}[ \\cL_{IPS}(\\hat \\bR, \\bR^{o}) ]  =  \\cL_{ideal}(\\hat \\bR, \\bR)$,}  provided that $\\hat p_{u,i}$ equals $p_{u,i}$ accurately for clicked events. A limitation of IPS estimator is that it is highly sensitive to small propensity score values.\n\n\n% ============================================\n% \\subsubsection{Doubly Robust Estimator}  \n \n \n\n% ==========================================\n"
                    },
                    "subsubsection 2.2.3": {
                        "name": "Doubly Robust Joint Learning Estimator",
                        "content": "\nDoubly robust (DR) estimator can be constructed in the augmented IPS form~\\cite{Bang-Robins2005, Wang-Zhang-Sun-Qi2019} %\\cite{Robins-Rotnitzky-Zhao1994,Bang-Robins2005,Tan2010, Wang-Zhang-Sun-Qi2019} \nby combining EIB and IPS methods. Given the learned propensities $\\hat \\bP = \\{ \\hat p_{u,i} \\mid (u,i) \\in \\cD \\}$ and imputed errors $\\hat \\bE = \\{ \\hat e_{u,i} \\mid (u,i) \\in \\cD \\}$, its loss function is formulated as \n        {%\\small\n\t\t\\begin{align}  \\label{dr_loss}\n\t\t\t\t\t\\cL_{DR}(\\hat \\bR, \\bR^{o}) ={}& \\frac{1}{ |\\cD|} \\sum_{(u,i) \\in \\cD}\\Big [ \\hat e_{u,i}  +  \\frac{ o_{u,i} (e_{u,i} -  \\hat e_{u,i}) }{ \\hat p_{u, i} } \\Big ]. \n\t\t\t\t% \t={}&    \\frac{1}{ |\\cD|} \\sum_{(u,i) \\in \\cD} \\Big [ \\frac{ o_{u,i} e_{u,i}  }{ \\hat p_{u, i} }  + ( 1 -  \\frac{ o_{u,i}  }{ \\hat p_{u, i} } ) \\hat e_{u,i} \\Big ].\n\t\t\\end{align}}\n% The DR estimator is unbiased in the sense that {\\small$E_{\\cO}[\\cL_{DR}(\\hat\\bR, \\bR^{o}) ] = \\cL_{ideal}(\\hat \\bR, \\bR)$}, if either $\\hat e_{u,i}$ or $\\hat p_{u,i}$ of all events are estimated accurately.    \n% DR estimator has been well investigated and it can be discussed via using ``augmentation term'' and ``correction term''. Specifically, the augmentation term \n%\t{\\small$ |\\cD|^{-1} \\sum_{(u,i) \\in \\cD}  ( 1 -   o_{u,i}/ \\hat p_{u, i} ) \\hat e_{u,i}$}  reduces the variance of  ${\\small\\cL_{IPS}(\\hat \\bR, \\bR^{o})}$ \\cite{MRDR_DL}, and the correction term \n%\t{\\small$|\\cD|^{-1} \\sum_{(u,i) \\in \\cD}  o_{u,i} (e_{u,i} -  \\hat e_{u,i})/ \\hat p_{u, i}$}  \n % uses IPS  to estimate how much {\\small$|\\cD|^{-1}  \\sum_{(u,i) \\in \\cD} \\hat e_{u,i}$} overestimates (or underestimates) {\\small$\\cL_{ideal}(\\hat \\bR, \\bR)$} and then subtracts it. More discussion about DR method can refer to the two excellent reviews~\\cite{Seaman-Vansteelandt2018,Molenberghs-etal2015}.  \n{$\\cL_{DR}(\\hat \\bR, \\bR^{o})$} involves the conversion rate model $\\hat r_{u,i}(1) = f_{\\phi}(x_{u,i})$ and error imputation model $\\hat e_{u,i} = g_{\\theta}(x_{u,i})$. Doubly robust joint learning (DR-JL) approach \\cite{Wang-Zhang-Sun-Qi2019} estimates them alternately: \n% Given propensities $\\hat \\bP$, doubly robust joint learning (DR-JL) approach \\cite{Wang-Zhang-Sun-Qi2019} learns  the conversion rate model $\\hat r_{u,i}(1) = f_{\\phi}(x_{u,i})$ and error  imputation model $\\hat e_{u,i} = g_{\\theta}(x_{u,i})$ alternately.       \n% The loss function of DR-JL estimator has the exact same form of DR estimator,  \n%and \n% The estimation procedures for solving parameters $\\phi$ and $\\theta$ are as follows:\ngiven $\\hat \\theta$, $\\phi$ is updated by minimizing (\\ref{dr_loss}); given $\\hat \\phi$, $\\theta$ is updated by minimizing \n    {%\\small\n\t\\begin{equation} \\label{drjl_loss}\n\t\t\\cL_{e}^{DR-JL}(\\theta)   = % \\sum_{(u, i) \\in \\col{\\cO}} \\frac{  (  \\hat e_{u,i} - e_{u,i} )^{2}  }{    \\hat p_{u,i}  } =\n\t\t \\sum_{(u, i) \\in \\cD} \\frac{ o_{u,i} (  \\hat e_{u,i} - e_{u,i} )^{2}  }{    \\hat p_{u,i}  }.\n\t\\end{equation}}\n% ==========================================\n"
                    },
                    "subsubsection 2.2.4": {
                        "name": "More Robust Doubly Robust Estimator",
                        "content": "\n Recently, the more robust doubly robust (MRDR) method~\\cite{MRDR_DL} enhances the robustness of DR-JL by optimizing the variance of the DR estimator with the imputation model. Specifically, MRDR keeps the loss of the CVR prediction model in (\\ref{dr_loss}) unchanged, while replacing the loss of the imputation model in (\\ref{drjl_loss}) with the following loss\n    {%\\small\n \t\\begin{equation}\\label{mrdr_loss}\n\t\t \\cL_{e}^{MRDR}(\\theta) = \\sum_{(u,i)\\in \\cD} \\frac{ o_{u,i} (  \\hat e_{u,i} - e_{u,i} )^{2}  }{    \\hat p_{u,i}  } \\cdot  \\frac{ 1- \\hat p_{u,i}  }{ \\hat p_{u,i} }. \n\t\\end{equation}  \n\t}\nThis substitution can % directly\nhelp reduce the variance of {$\\cL_{DR}(\\hat \\bR, \\bR^{o})$} and hence a more robust estimator might be obtained. \n\n"
                    },
                    "subsubsection 2.2.5": {
                        "name": "Bias, Variance and Generalization Bound of DR Estimator",
                        "content": "\n\n  Given a hypothesis space $\\cH$ of CVR prediction matrix $\\hat \\bR$, we define the optimal\n  $\\hat \\bR^{*}$ as \n\t{$ \\hat \\bR^{*} = \\arg \\min_{ \\hat \\bR \\in \\cH } \\cL_{DR}(\\hat \\bR, \\bR^{o})$}. \n\tGiven  imputed errors $\\hat \\bE$ and learned propensities $\\hat \\bP$,  \n\t% with $\\hat p_{u,i} > 0$ for all $(u,i)$ pairs, \n The following Lemmas \\ref{lemma1} and \\ref{lemma2} present the existing theoretical results of  DR estimator~\\cite{schnabel2016recommendations,Wang-Zhang-Sun-Qi2019}.\n\n%The bias and variance of the DR estimator are formally derived as follows. \n\\begin{lemma}[Bias and Variance]\n\\label{lemma1}\n The bias and variance of DR estimator are given as \n% the biases of the IPS, EIB and DR estimators are given as\n    {%\\small\n\t\\begin{align*}\n\t%\\small\n%\tBias[  \\cL_{IPS}(\\hat \\bR, \\bR^{o}) ] ={}&   \\frac{1}{ | \\cD | }  \\Big |  \\sum_{(u,i) \\in D}  \\frac{ p_{u,i} - \\hat p_{u,i}  }{ \\hat p_{u,i} }   e_{u,i} \\Big |, \\\\\n%\\[\tBias[  \\cL_{EIB}(\\hat \\bR, \\bR^{o}) ] =   \\frac{1}{ | \\cD | }  \\Big |  \\sum_{(u,i) \\in D}  (1 - p_{u,i}) (\\hat e_{u,i} -  e_{u,i} ) \\Big |,   \\\\\n   Bias[  \\cL_{DR}(\\hat \\bR, \\bR^{o}) ] ={}&   \\frac{1}{ | \\cD | } \\Big |  \\sum_{(u,i) \\in D}  (p_{u,i} - \\hat p_{u,i}) \\frac{ ( e_{u,i} - \\hat e_{u,i})  }{ \\hat p_{u,i} }  \\Big |, \\\\\n    \\V_{\\cO}[ \\cL_{DR}(\\hat \\bR, \\bR^{o})  ]  ={}&  \\frac{1}{ |\\cD|^{2} } \\sum_{(u,i)\\in \\cD}    p_{u,i} (1- p_{u,i})  \\frac{ ( \\hat e_{u,i} - e_{u,i} )^{2} }{  \\hat p^{2}_{u,i}  }. \n    \\end{align*}}\n\\end{lemma}\n\n\\begin{lemma}[Generalization Bound]\n\\label{lemma2}\nFor any finite hypothesis space $\\cH$ of prediction matrices,  then  with probability $1 - \\eta$, \n    {%\\small\n\t\\begin{align*} \n\t  \\cL_{ideal}(\\hat \\bR^{*}, \\bR)  \n\t  \\leq{}&  \\cL_{DR}(\\hat \\bR^{*}, \\bR^{o})  +   \\underbrace{\\frac{1}{ | \\cD | }  \\sum_{(u,i) \\in \\cD}   \\frac{ | p_{u,i} - \\hat p_{u,i} |  }{ \\hat p_{u,i} }  |  e_{u,i} - \\hat e_{u,i}^{*}  | }_{\\text{Bias term}}  \\\\\n\t   &  +  \\underbrace{ \\sqrt{ \\frac{ \\log(2|\\cH | /\\eta)  }{ 2 |\\cD |^{2}  }   \\sum_{(u,i)\\in \\cD} (  \\frac{  e_{u,i} - \\hat e_{u,i}^{\\dag}  } { \\hat p_{u,i} }  )^{2}   } }_{\\text{Variance term}},       \n\t   \\end{align*}\n\t   } \n where  $\\hat e_{u,i}^{*}$ is the prediction error associated with  $\\hat \\bR^{*}$,  $\\hat e_{u,i}^{\\dag}$ is the prediction error corresponding to the prediction matrix $\\hat \\bR^{\\dag} = \\arg \\max_{ \\hat \\bR^{h} \\in \\cH } \\sum_{(u,i) \\in \\cD } (e_{u,i} -\\hat e_{u,i}^{h})^2 /\\hat p_{u,i}^2$. \n %$\\hat \\bR^{\\dag} = \\arg \\max_{ \\hat \\bR^{h} \\in \\cH } \\sum_{(u,i) \\in \\cD } (  \\frac{ e_{u,i} -\\hat e_{u,i}^{h}  } { \\hat p_{u,i} }  )^{2}$.  \n\\end{lemma}\n\n\n\n\n% =========================================================================================\n"
                    }
                }
            },
            "section 3": {
                "name": "Proposed Methods",
                "content": " \n\n%In this section, we analyze the bias, variance and generalization bound of DR estimator and discuss the basic ideas and limitations of DR-JL and MRDR methods.\n%In this section, we first analyze the DR estimator and discuss the limitations of DR-JL and MRDR. Then, we propose a generalized learning framework that unifies the existing DR methods. Furthermore, based on the proposed framework, we develop two new DR methods called DR-BIAS and DR-MSE.\n\n% =================================================\n",
                "subsection 3.1": {
                    "name": "Motivation",
                    "content": "\\label{dr_concerns}\n\nWe reveal some worrying features of DR method, which provides an initial motivation.   \nLemma~\\ref{lemma1} formally gives the bias and variance of the DR estimator.\nAccording to the lemma, {$Bias[\\cL_{DR}(\\hat \\bR, \\bR^{o})] \\approx 0$}, if either $(\\hat e_{u,i} - e_{u,i}) \\approx 0$ or $(\\hat p_{u,i} - p_{u,i}) \\approx  0$, which is the property of double robustness. \nNonetheless, both the bias and variance terms still have some issues.\nSpecifically, the bias consists of the product of the errors of the propensity score model and imputation model weighted by $1/\\hat p_{u,i}$. \nThe term $(e_{u,i}-\\hat e_{u,i}) / \\hat p_{u,i}$ is worrisome, as  $1/\\hat p_{u,i}$ tends to be large in unclicked events and inaccurate estimates of $e_{u,i}$ are most likely to occur in these events.\nAnalogously,  $( \\hat e_{u,i} - e_{u,i} )^{2} /  \\hat p^{2}_{u,i}$ in the variance term is also likely to be problematic.\n \n It can be seen that both the bias and variance \n are % positively\ncorrelated with the term of error deviation $| \\hat e_{u,i} - e_{u,i} |$. Thus, it may be helpful to reduce them if the magnitude of error deviation is small. This is the basic idea of DR-JL approach that tries to reduce the error deviations of all events by optimizing the loss function (\\ref{drjl_loss}). Further, the MRDR method~\\cite{MRDR_DL} proposed replacing\n {$\\cL_{e}^{DR-JL}(\\theta)$} in (\\ref{drjl_loss}) with {$\\cL_{e}^{MRDR}(\\theta)$} in (\\ref{mrdr_loss}) to deal with the large variance term. The idea behind Equation (\\ref{mrdr_loss}) is the truth that  \n    {%\\small\n\t \\[   \\V_{\\cO}[ \\cL_{DR}(\\hat \\bR, \\bR^{o})  ]  =    \\frac{1}{ |\\cD|^{2} } \\sum_{(u,i)\\in \\cD}  \\mathbb{E}_{\\cO} [ \\frac{ o_{u,i} (1- p_{u,i}) (  \\hat e_{u,i} - e_{u,i} )^{2}  }{    \\hat p_{u,i}^{2}  } ],\t\\]\n\t }\n\t%$\\V_{\\cO}[ \\cL_{DR}(\\hat \\bR, \\bR^{o})  ]  =     |\\cD|^{-2} \\sum_{(u,i)\\in \\cD} \\mathbb{E}_{\\cO} [  o_{u,i} (1- p_{u,i}) (  \\hat e_{u,i} - e_{u,i} )^{2}     \\hat p_{u,i}^{-2}   ],$ \nnamely, the expectation of {$\\cL_{e}^{MRDR}(\\theta)$} equals to {$\\V_{\\cO}[ \\cL_{DR}(\\hat \\bR, \\bR^{o})]$}.  \n\nInterestingly, Lemma~\\ref{lemma2} % (see Appendix~\\ref{proof_lemma} for proof)\nshows that the generalization bound % mainly\ndepends on a weighted sum of the bias term and square root of the variance term in addition to the empirical %DR\nloss, which fully reflects the feature of bias-variance trade-off. Since DR-JL does not control the bias and variance directly and MRDR pays no attention to the bias, both of them may still have poor generalization performance.  \n\n% ================================================\n"
                },
                "subsection 3.2": {
                    "name": "A Generalized DR Learning Framework",
                    "content": "\n\nThe difference between DR-JL and MRDR lies in the loss function of the error imputation model. As presented in Section~\\ref{existing_methods}, the alternating algorithm of DR-JL implies that its underlying loss is {$\\cL_{DR}(\\hat \\bR, \\bR^o) + \\cL_e^{DR-JL}(\\theta).$}\nSimilarly, the real loss of MRDR is {$\\cL_{DR}(\\hat \\bR, \\bR^o) + \\cL_e^{MRDR}(\\theta)$}.\n % It should be \n Note that the real loss functions of DR-JL and MRDR share a similar structure, so they can be discussed within a generalized framework. \n The real loss function of this framework has the following form\n    {%\\small\n    \\begin{equation} \\cL(\\hat \\bR, \\bR^o) + Metric\\{ \\cL(\\hat \\bR, \\bR^o) \\},              \\end{equation}\n    }\nwhere {$\\cL(\\hat \\bR, \\bR^o)$} is an arbitrary unbiased loss function for training CVR prediction model, such as {$\\cL_{IPS}(\\hat \\bR, \\bR^o)$}, {$\\cL_{EIB}(\\hat \\bR, \\bR^o)$} and {$\\cL_{DR}(\\hat \\bR, \\bR^o)$}. {$ Metric\\{ \\cL(\\hat \\bR, \\bR^o) \\}$} is a  pre-specified metric that reflects some features of {$\\cL(\\hat \\bR, \\bR^o)$} and is usually applied to learn the error imputation model.      \nFor example, the MRDR chooses {$\\V_{\\cO}[ \\cL_{DR}(\\hat \\bR, \\bR^{o})]$} as the metric, and DR-JL uses $\\sum_{(u,i)\\in \\cD} (\\hat e_{u,i} - e_{u,i})^2$. \nTable 2 summarizes the metrics and ideas  of existing doubly robust methods and our proposed methods, DR-BIAS and DR-MSE, which will be detailedly illustrated in Section~\\ref{new_methods}.   \n\n\nIt is noteworthy that due to the missing $r_{u,i}(1)$,\noptimizing {$Metric\\{ \\cL(\\hat \\bR, \\bR^o) \\}$} directly is sometimes not feasible. In this case, one can use an approximation of {$Metric\\{ \\cL(\\hat \\bR, \\bR^o) \\}$}. For example, DR-JL adopts the feasible %$\\sum_{ (u,i)\\in \\cD } o_{u,i} (\\hat e_{u,i} - e_{u,i})^2 / \\hat p_{u,i}$\nloss function~(\\ref{drjl_loss}) to approximate the infeasible $\\sum_{ (u,i)\\in \\cD } (\\hat e_{u,i} - e_{u,i})^2$,  and MRDR employs~(\\ref{mrdr_loss}) to substitute {$\\V_{\\cO}[ \\cL_{DR}(\\hat \\bR, \\bR^{o})]$}.\n\nImportantly, the proposed framework \nprovides a valuable opportunity to develop a series of new unbiased CVR estimators with different characteristics to accommodate different application scenarios. In Section~\\ref{new_methods}, we will develop two new DR approaches based on this framework. \n\n% ========================================\n"
                },
                "subsection 3.3": {
                    "name": "Two New DR Methods",
                    "content": "\\label{new_methods}\n% Algorithm\n% Properties\nAs discussed in Section~\\ref{dr_concerns}, MRDR aims to reduce the variance of {$\\cL_{DR}(\\hat \\bR, \\bR^o)$}, and is expected to achieve a more robust performance. However, this strategy works well only when {$Bias[ \\cL_{DR}(\\hat \\bR, \\bR^o) ]$} is small enough as suggested by the generalization bound presented in Lemma~\\ref{lemma2}. Reducing variance  is less effective when the bias is large. DR-JL attempts to lower both the bias and variance  % tries to lower the generalization bound \nby reducing the error deviation of the imputation model.  \nNevertheless, it does not directly control the bias and variance of  {$\\cL_{DR}(\\hat \\bR, \\bR^o)$}. \n % even though it  is  helpful to reduce the bias and variance according to Lemma 1.  \nTo alleviate these limitations, we propose two new DR methods, DR-BIAS and DR-MSE, which are designed to further reduce bias and achieve better bias-variance trade-off, respectively.\n\n",
                    "subsubsection 3.3.1": {
                        "name": "DR-BIAS",
                        "content": "\\label{dr-bias}\nDR-BIAS aims at further reducing the bias of the typical DR method through the optimization of the imputation model, since an accurate CVR prediction means that the bias should be small enough. Based on Lemmas~\\ref{lemma1} and~\\ref{lemma2}, we design a variant of the bias of DR method as the metric to achieve this goal, given by \n% which is as follows \n% a natural way to reduce bias is using the metric  \n        {%\\small\n\t\t\\[      \\frac{1}{ | \\cD | }  \\sum_{(u,i) \\in D}  \\frac{ (o_{u,i} - \\hat p_{u,i})^{2}  }{ \\hat p^{2}_{u,i} } ( e_{u,i} - \\hat e_{u,i})^{2}.          \\]}\nHowever, the above metric is infeasible due to the missing of $e_{u,i}$ in unclicked events. We make an approximation of it and define the loss of the imputation model of DR-BIAS as follows\n{%\\small\n\\begin{equation} \\label{bias_loss} \n\\cL_{e}^{DR-BIAS}(\\theta) = \\sum_{(u,i)\\in \\cD} \\frac{ o_{u,i} (  \\hat e_{u,i} - e_{u,i} )^{2}  }{  \\hat p_{u,i} } \\cdot  \\frac{  (o_{u,i} - \\hat p_{u,i})^{2}   }{ \\hat p_{u,i}^2 }.  \\end{equation}\n}\n\n% Interestingly, % compared with (9), (11) \nBy a comparison between Equation (\\ref{mrdr_loss}) and (\\ref{bias_loss}), we find that\n (\\ref{bias_loss}) just substitutes the weight $(1-\\hat p_{u,i})/\\hat p_{u,i}$ with $(1 - \\hat p_{u,i})^2/\\hat p_{u,i}^2$ in clicked events. Also note that \n {%\\small\n    \\begin{align*}\n    % \\frac{1-\\hat p_{u,i}}{\\hat p_{u,i} } \n    \\begin{cases}\n      & (1-\\hat p_{u,i})/\\hat p_{u,i}    >1, \\text{ if } \\hat p_{u,i} < 1/2, \\\\\n      & (1-\\hat p_{u,i})/\\hat p_{u,i}   <1, \\text{ if } \\hat p_{u,i} > 1/2,\n    \\end{cases}\n    \\end{align*}}\nwhich means that DR-BIAS further magnifies  \nthe penalty of the clicked \nevents with low propensity, and minifies those with high propensity. This leads to a desired effect:  \nin the clicked events that the propensity model performs poorly, the amplified weights force the error imputation model to perform well. In other words, error imputation model complements the inaccurate part of the propensity score model.   \nThus, DR-BIAS would have smaller bias than other methods.\n\n"
                    },
                    "subsubsection 3.3.2": {
                        "name": "DR-MSE",
                        "content": "\nLemma~\\ref{lemma2} indicates that pursuing the bias reduction  or variance reduction alone cannot fully control the generalization error. \nSeeking a better balance between the bias and variance appears to be a more effective way to improve the prediction accuracy. Therefore, we design a new model, namely DR-MSE, to achieve this goal. Specifically, a generalized Mean Squared Error (MSE) metric for DR-MSE method is defined as \n    {%\\small\n    \\begin{equation}\\label{mse_loss}\n     \t\\cL_{e}^{DR-MSE}(\\theta) = \\lambda\\cL_{e}^{DR-BIAS}(\\theta) + \t(1-\\lambda)\\cL_{e}^{MRDR}(\\theta),\n    \\end{equation}}\nwhere $\\lambda$ is a hyper-parameter for controlling the strength of the bias term and the variance term. When $\\lambda=1$, DR-MSE is reduced to DR-BIAS; when $\\lambda=0$, DR-MSE is reduced to MRDR; when $\\lambda=0.5$, DR-MSE optimizes the MSE of {$\\cL_{DR}(\\hat \\bR, \\bR^{o})$} scaled by 0.5 through the imputation model.\n\n\\textcolor{black}{However, simply using a hyper-parameter $\\lambda$ for all samples is not flexible enough due to the different characteristics and popularities of users and items.  \nSpecifically, different samples suffer from different issues during training, i.e., some might have higher variance while others might have worse bias. \nThus, it is necessary to adopt different bias-variance tradeoff strategies for different user-item pairs. To achieve this goal, $\\lambda$ can be computed through a function $\\lambda_\\xi(x_{u,i})$ parameterized by $\\xi$, such as a neural network, which enables personalized values for different user-item pairs. The improved loss of DR-MSE is as follows\n{%\\small \n \\begin{equation}\\label{drmsev2}\n \\begin{array}{lll}\n\\cL_{e}^{DR-MSE}\\left(\\theta, \\lambda_\\xi\\right)=\\sum\\limits_{(u,i)\\in \\cD} \\frac{ o_{u,i}\\lambda_\\xi(x_{u,i}) (  \\hat e_{u,i} - e_{u,i} )^{2}  }{  \\hat p_{u,i} } \\cdot  \\frac{  (o_{u,i} - \\hat p_{u,i})^{2}   }{ \\hat p_{u,i}^2 }\\\\\n\\qquad\\qquad\\qquad\\quad\\;\\, +\\sum\\limits_{(u,i)\\in \\cD} \\frac{ o_{u,i}(1-\\lambda_\\xi(x_{u,i})) (  \\hat e_{u,i} - e_{u,i} )^{2}  }{    \\hat p_{u,i}  } \\cdot  \\frac{ 1- \\hat p_{u,i}  }{ \\hat p_{u,i} }.\n \\end{array}\n \\end{equation}\n}\n}\n\nEssentially, the generalization bound of DR methods contains a weighted sum of the bias term and square root of the variance term, which can be flexibly tradeoff via the proposed generalized MSE metric in~(\\ref{mse_loss}). Thus, it is expected that DR-MSE can obtain a better prediction performance under the tighter generalization bound.\n\n\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n"
                    }
                }
            },
            "section 4": {
                "name": "Proposed Training Approach",
                "content": "\n",
                "subsection 4.1": {
                    "name": "Model Architecture and Training Objective",
                    "content": "\nFigure~\\ref{fig:causalmtl4.1} shows the architecture of DR-BIAS and DR-MSE for experiments on real industrial scenarios.\nIt is a multi-task learning framework with three DCN networks for the predication of post-view click-through rate (CTR), CVR, and error imputation, respectively. The embedding lookup layers of the DCN models for the CTR and CVR tasks are shared to tackle data sparsity issue, while the DCN model for the error imputation has its own embedding lookup layer. Note that DCN can be readily replaced with other models such as FM~\\cite{rendle2010factorization},  Wide\\&Deep~\\cite{cheng2016wide} and DeepFM~\\cite{guo2017deepfm}. We evaluate our proposed methods with both FM and DCN in our experiments.\n\nDuring optimization, the CTR, CVR, and error imputation models are updated alternatively with stochastic gradient descent. Specifically, with the parameters of both CTR and CVR models fixed, the error imputation model is updated first by optimizing (\\ref{drmsev2}).\nWith model parameters of the error imputation model fixed, the CTR and CVR models are optimized jointly through the sum of CVR loss and CTR loss %with another sampled mini-batch of data.\n$$\n\\begin{aligned}\n\\cL_{\\text{CTCVR}}\\left(\\phi, \\zeta, \\theta(\\lambda_\\xi) \\right)=& \\cL_{DR}(\\phi, \\theta(\\lambda_\\xi)) + \\cL_{CTR}(\\zeta), %\\\\\n\\end{aligned}\n$$ \nwhere $\\cL_{DR}(\\phi, \\theta(\\lambda_\\xi))=\\sum_{(u,i) \\in \\cD} [ \\hat e_{u,i}  +   o_{u,i} (e_{u,i} -  \\hat e_{u,i}) / \\hat p_{u, i}]$, $\\cL_{CTR}(\\zeta) = - \\sum_{(u,i) \\in \\cD}  [o_{u, i} \\cdot \\log (\\hat p_{u,i})+(1-o_{u, i}) \\cdot \\log (1-\\hat p_{u,i}) ]$, $\\hat p_{u,i}$ is the predicted CTR value, and used as the estimated propensity for unbiased CVR estimation. \nThis joint learning process continues until the model converges. For DR-MSE, the optimization process %will also \ninvolves updating $\\lambda_\\xi(\\cdot)$, which makes it more challenging. %In the following section, \nIn Section~\\ref{tri-level-opt}, we formally formulate the optimization problem and propose an effective training algorithm.\n%The losses of error imputation model and CVR prediction model have been provided in Section 2 and 3. The loss of CTR prediction is simply a binary cross-entropy loss.\n"
                },
                "subsection 4.2": {
                    "name": "Tri-Level DR-MSE Joint Learning (JL) Optimization and Training Algorithm\n",
                    "content": "\\label{tri-level-opt}\n\nWe propose the tri-level optimization DR-MSE JL approach shown in Figure \\ref{fig:DR-MSE}. Compared to the existing joint learning methods, our approach allows adaptively updating the $\\lambda_\\xi$ in DR-MSE. This goal can be formalized as the following tri-level optimization problem\n{%\\small  \n$$\n\\begin{aligned}\n\\xi^{*} &=\\arg \\min _{\\xi} \\cL_{DR}\\left(\\phi^{*}(\\theta^{*}(\\lambda_\\xi)), \\zeta^{*}(\\theta^{*}(\\lambda_\\xi))\\right) \\\\\n\\text { s.t. } \\phi^{*}(\\theta^{*}(\\lambda_\\xi)), \\zeta^{*}(\\theta^{*}(\\lambda_\\xi))&=\\arg \\min _{\\phi, \\zeta} \\cL_{\\text{CTCVR}}\\left(\\phi, \\zeta, \\theta^{*}(\\lambda_\\xi) \\right)\\\\\n\\text { s.t. } \\theta^{*}(\\lambda_\\xi)&=\\arg \\min _{\\theta} \\cL_{e}^{DR-MSE}\\left(\\theta, \\lambda_\\xi\\right)\n\\end{aligned}\n$$}\n\n\n\nThere are two challenges for solving the above problem. Firstly, it is computationally expensive to search for the optimal DR-MSE by minimizing the upper loss in the tri-level DR-MSE JL optimization method. Secondly, the DR-MSE parameter $\\lambda_\\xi$ of the upper model is difficult to be minimized as there is no closed-form solution. To address them, we further propose a training algorithm for this tri-level optimization problem as shown in Alg. 1. \n\n\\begin{algorithm}[t]\n\\caption{Tri-Level DR-MSE JL Optimization Training}%算法名字\n\\LinesNumbered %要求显示行号\n\\KwIn{$S$, observed ratings $\\mathbf{R}^{o}$, learned propensities $\\hat{\\mathbf{P}}$, }%输入参数\n%\\KwOut{output result}%输出  \n%some description\\; %\\;用于换行\n\\For{$\\mathcal{O}_{s}^l, \\mathcal{O}_{s}^u \\subset \\mathcal{O}$ and $\\mathcal{D}_{s} \\subset \\mathcal{D}$ ($s\\in\\{0, 1, \\cdots, S-1\\}$)}{\n%Sample mini-batches $\\mathcal{O}_{s}^l, \\mathcal{O}_{s}^u \\subset \\mathcal{O}$ and $\\mathcal{D}_{s} \\subset \\mathcal{D}$\\;\n%Compute the loss $\\cL_{e}^{DR-MSE}\\left(\\theta_s, \\lambda_s\\right)$ on $\\mathcal{O}_{s}^l$\\;\nCompute an update function based on $\\mathcal{O}_{s}^l$\\\n$\\theta_{s+1}\\left(\\lambda_{s}\\right) \\leftarrow \\theta_{s}-\\eta \\nabla_{\\theta_s} \\cL_{e}^{DR-MSE}\\left(\\theta, \\lambda_{s}\\right)$\\;\n%Compute the loss$\\cL_{\\text{CTCVR}}\\left(\\phi_s, \\zeta_s,  \\theta_{s+1}\\left(\\lambda_{s}\\right)\\right)$ on $\\mathcal{D}_{s}$\\;\nCompute an update function based on $\\mathcal{D}_{s}$\\ $\\phi_{s+1}(\\theta_{s+1}\\left(\\lambda_{s}\\right)) \\leftarrow \\phi_s-\\eta \\nabla_{\\phi_s}\\cL_{\\text{CTCVR}}\\left(\\phi, \\zeta_s,  \\theta_{s+1}\\left(\\lambda_{s}\\right)\\right)$\\;\nCompute an update function $\\zeta_{s+1}(\\theta_{s+1}\\left(\\lambda_{s}\\right)) \\leftarrow \\zeta_s-\\eta \\nabla_{\\zeta_s}\\cL_{\\text{CTCVR}}\\left(\\phi_s, \\zeta,  \\theta_{s+1}\\left(\\lambda_{s}\\right)\\right)$\\;\nCompute the upper loss based on $\\mathcal{O}_{s}^u$ \\\\ $\\cL_{DR}\\left(\\phi_{s+1}(\\theta_{s+1}\\left(\\lambda_{s}\\right)), \\zeta_{s+1}(\\theta_{s+1}\\left(\\lambda_{s}\\right))\\right)$\\;\nUpdate the bias-variance trade off parameter \\\\\n$\\xi_{s+1} \\leftarrow \\xi_{s}-\\eta \\nabla_{\\xi_{s}} \\cL_{DR}\\left(\\phi_{s+1}(\\theta_{s+1}(\\lambda_{\\xi})), \\zeta_{s+1}(\\theta_{s+1}(\\lambda_{\\xi}))\\right)$\\;\nUpdate the bias-variance trade off model $\\lambda_{s+1} \\leftarrow \\lambda_{\\xi_{s+1}}$\\;\n\\For{$\\mathcal{O}_{s, t}^{l} \\subset \\mathcal{O}$ ($t\\in\\{0, 1, \\cdots, T-1\\}$)}{\n%Sample a mini-batch $\\mathcal{O}_{s, t}^{l} \\subset \\mathcal{O}$\\;\n%Compute the loss $\\cL_{e}^{DR-MSE}\\left(\\theta_{s,t}, \\lambda_{s+1}\\right)$ on $\\mathcal{O}_{s, t}^l$\\;\nUpdate the imputation model based on $\\mathcal{O}_{s, t}^l$ $\\theta_{s,t+1} \\leftarrow \\theta_{s,t}-\\eta \\nabla_{\\theta_{s,t}} \\cL_{e}^{DR-MSE}\\left(\\theta, \\lambda_{s+1}\\right)$\\;}\n\\For{$\\mathcal{D}_{s, t} \\subset \\mathcal{D}$ ($t\\in\\{0, 1, \\cdots, T-1\\}$)}{\n%Sample a mini-batch $\\mathcal{D}_{s, t} \\subset \\mathcal{D}$\\;\n%Compute the loss $\\cL_{\\text{CTCVR}}\\left(\\phi_{s,t}, \\zeta_{s,t},  \\theta_{s,T}\\right)$ on $\\mathcal{D}_{s, t}$\\;\nUpdate the propensity model based on $\\mathcal{D}_{s, t}$\\ $\\zeta_{s,t+1} \\leftarrow \\zeta_{s,t}-\\eta \\nabla_{\\zeta_{s,t}}\\cL_{\\text{CTCVR}}\\left(\\phi_{s,t}, \\zeta,  \\theta_{s,T}\\right)$\\;\nUpdate the predication model based on $\\mathcal{D}_{s, t}$\\ $\\phi_{s,t+1} \\leftarrow \\phi_{s,t}-\\eta \\nabla_{\\phi_{s,t}}\\cL_{\\text{CTCVR}}\\left(\\phi, \\zeta_{s,t},  \\theta_{s,T}\\right)$\\;}\nCopy the model parameter $\\theta_{s+1,0} \\leftarrow \\theta_{s,T}$\\;\nCopy the propensity model's parameter $\\zeta_{s+1,0} \\leftarrow \\zeta_{s,T}$\\;\nCopy the predication model's parameter $\\phi_{s+1,0} \\leftarrow \\phi_{s,T}$.\n}\n\\end{algorithm}\n\nFor illustration purposes, the relevant parameters in Alg. 1 are updated using vanilla SGD. In practice, both SGD and its variants can be used for iterative updates. Specifically, for the error imputation optimization problem, $\\cL_{e}^{DR-MSE}$ is differentiable w.r.t. the parameter $\\theta$ of the error imputation model.  \\textcolor{black}{Given $\\lambda_s$, one can compute the value of $\\theta_{s+1}\\left(\\lambda_{s}\\right)$ after a single vinalla SGD. It should be noted that this value is not directly used for the update of the error imputation model parameter $\\theta_{s+1}$. Moreover, the reason for using single-step SGD is that multi-step SGD here does not result in better performance, but rather increases the computational complexity~\\cite{jenni2018deep}.}\n\nSimilarly, $\\cL_{\\text{CTCVR}}$ is differentiable w.r.t. both CTR model parameter $\\zeta$ and CVR model parameter $\\phi$. Given the pseudo-updated $\\theta_{s+1}\\left(\\lambda_{s}\\right)$, one can compute the value of $\\zeta_{s+1}\\left(\\theta_{s+1}\\left(\\lambda_{s}\\right)\\right)$ and $\\phi_{s+1}\\left(\\theta_{s+1}\\left(\\lambda_{s}\\right)\\right)$ after a single vanilla SGD. Both of the values are not directly used for the update of the CTR and CVR model as well. After that, with given $\\zeta_{s+1}\\left(\\theta_{s+1}\\left(\\lambda_{s}\\right)\\right)$ and $\\phi_{s+1}\\left(\\theta_{s+1}\\left(\\lambda_{s}\\right)\\right)$, we update the bias-variance tradeoff parameter in DR-MSE from $\\lambda_s$ to $\\lambda_{s+1}$ via a single vanilla SGD. Finally, based on the updated $\\lambda_{s+1}$, we take the idea of joint learning to update the error imputation model parameter $\\theta_{s+1}$ and the CTR\\&CVR model parameters $\\zeta_{s+1}, \\phi_{s+1}$, in which the classical multi-step SGD is used until the stopping criteria is satisfied.\n\n% =====================================\n\n"
                }
            },
            "section 5": {
                "name": "Real-world Experiments",
                "content": "\n% Research questions to answer through experiments through real-world data\nIn this section,  we evaluate the proposed methods by conducting experiments on three real-world datasets, including two benchmark datasets with missing-at-random (MAR) ratings and one large-scale industrial product dataset. We aim to answer the following two research questions (RQ): (1) How do our methods compare with state-of-the-art models in terms of debiasing performance in practice? (2) How do the bias-variance tradeoff and the modeling of unobserved data affect the performance of the proposed methods in practice?\n\n",
                "subsection 5.1": {
                    "name": "Experimental Setup",
                    "content": "\n",
                    "subsubsection 5.1.1": {
                        "name": "Datasets with MAR Ratings",
                        "content": "\nA MAR testing set is important for assessing the performance of an unbiased recommender. Thus, we follow existing studies~\\cite{MRDR_DL,RecSys_Saito20} to use {\\bf Coat Shopping\\footnote{https://www.cs.cornell.edu/\\textasciitilde schnabts/mnar/}} and {\\bf Yahoo! R3\\footnote{http://webscope.sandbox.yahoo.com/}} for the evaluation of CVR prediction model. To make the two datasets consistent with the CVR prediction task, we further preprocess them following previous studies~\\cite{RecSys_Saito20,MRDR_DL}. The detailed descriptions of these two datasets and the corresponding data preprocessing method are provided in Appendix~\\ref{apdx-data}.\n\n"
                    },
                    "subsubsection 5.1.2": {
                        "name": "Industrial Product Dataset.",
                        "content": "\nTo provide more comprehensive and reliable evaluation, we also conduct experiments on a large-scale App advertising dataset collected from a real-world system. We denote this dataset as \\textbf{\\textbf{Product}} with some statistics of it displayed in Table~\\ref{tab:huawei}. It contains 8 consecutive days logged data from the system, with the first 7 days for training and the last day for testing. Each sample of the dataset contains features from a user, an item and the corresponding context. Although the unbiased data in CVR prediction is unobtainable in real applications since we cannot force users to randomly click the exposed items, the experiments can still provide valuable observations for the applications of debiasing CVR prediction models in real systems.\n\n"
                    },
                    "subsubsection 5.1.3": {
                        "name": "Baselines and Implementation",
                        "content": "\nFor experiments on \\textbf{Coat} and \\textbf{Yahoo}, we compare our methods with several competitive baselines, including Naive, IPS, DR-JL and MRDR. The base model for all methods is factorization machine. Some brief descriptions of them and implementation details are provided in Appendix~\\ref{apdx-semi}. \nFor experiments on \\textbf{Product}, we also select some state-of-the-art CVR prediction models for large datasets, including DCN~\\cite{wang2017deep}, ESMM~\\cite{ESMM18}, Multi\\_IPW~\\cite{Multi_IPW} and Multi\\_DR~\\cite{Multi_IPW}. The base model for all methods is DCN. More details are provided in Appendix~\\ref{apdx-product}.\n\n"
                    },
                    "subsubsection 5.1.4": {
                        "name": "Experimental Protocols",
                        "content": "\nFor experiments on \\textbf{Coat} and \\textbf{Yahoo}, we evaluate the ranking performance with two types of metrics, i.e., discounted cumulative gain (DCG) and recall, as prior work on debiasing CVR prediction~\\cite{RecSys_Saito20,MRDR_DL}.\nFor experiments on \\textbf{Product}, we evaluate our proposed methods on three important tasks, i.e., CTR, CVR, and CTCVR ($CTCVR=CTR*CVR$) predictions, with the AUC score following existing works~\\cite{ESMM18,Multi_IPW}.\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n% Statistics of Huawei Dataset\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n% real-world experiments\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n% Results of Huawei Dataset\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n"
                    }
                },
                "subsection 5.2": {
                    "name": "Overall Performance (RQ1)",
                    "content": "\n\n",
                    "subsubsection 5.2.1": {
                        "name": "Unbiased Evaluation.",
                        "content": " \nThe experimental results on \\textbf{Coat} and \\textbf{Yahoo} are shown in Table~\\ref{tab:real-result}. We have the following observations.\n\nFirst, our proposed methods are effective for debiasing CVR prediction task. As shown in Table~\\ref{tab:real-result}, both DR-MSE and DR-BIAS consistently outperform all the other ones in terms of DCG@K and Recall@K ($K=2,4,6$) on the two real-world datasets, with only one exception of DR-MSE on Recall@6 of \\textbf{Yahoo}. In particular, DR-MSE achieves a significant 3.22\\%, 2.65\\% and 1.87\\% relative improvements over MRDR on DCG@2, DCG@4 and DCG@6, respectively.\n\nSecond, it is necessary to improve the bias and variance of the typical DR method under inaccurate propensity estimation and error imputation so as to enhance its robustness and ranking performance.\nAs shown in Table~\\ref{tab:real-result}, IPS has worse performance on \\textbf{Coat} and only comparable performance on \\textbf{Yahoo} compared with the Naive method, since it suffers heavily from the high variance issue. Both DR-JL and MRDR performs better compared with IPS because of their double robustness. \nDR-BIAS improves over MRDR by achieving smaller bias through magnifying the penalty of the clicked events with low propensity while minifying those with high propensity as analyzed in Section~\\ref{dr-bias}.\nHowever, these DR methods still suffer from the high bias and/or variance issues.\nOur proposed DR-MSE can further achieve improvements over all other DR methods by better controlling the bias and variance.\n\n"
                    },
                    "subsubsection 5.2.2": {
                        "name": "Large-scale Industrial Dataset.",
                        "content": " The experimental results on \\textbf{Product} are shown in Table~\\ref{tab:huawei-result}. Firstly, we can observe that ESMM improves over DCN on CVR and CTCVR prediction tasks by tackling the data sparsity issue with the multi-task learning framework, but it still suffers from the selection bias issue. Secondly, the debiasing CVR models can simultaneously tackle the data sparsity and selection bias issues, thus they outperform DCN and ESMM.\nThirdly, our proposed methods achieve significant improvements over existing debiasing CVR prediction models, including DR-JL, Multi\\_IPW, Multi\\_DR and MRDR, which is consistent with the observations on experiments with unbiased evaluation. It demonstrates that our proposed methods have both theoretical guarantee and great application potentials in real industrial systems. \n\n"
                    }
                },
                "subsection 5.3": {
                    "name": "In-depth Analysis of DR-MSE (RQ2)",
                    "content": "\nWe conduct an analysis of two important aspects of DR-MSE with \\textbf{Coat} in this section.\nThe experimental results are displayed in Figure~\\ref{fig:hyperparameter}. Note that similar results can be observed on other datasets, and we do not present them here only due to space limitations.\n\nThe loss of the imputation model of DR-MSE contains a bias term and a variance term. We conduct experiments by manually varying $\\lambda$ in Eq. (\\ref{mse_loss}) to demonstrate the necessity of conducting bias-variance tradeoff. The left part of Figure~\\ref{fig:hyperparameter} presents the experimental results of DR-MSE when varying $\\lambda$ from 0.1 to 0.9. We can find that the performance of DR-MSE first improves with the increase of $\\lambda$, and then gradually drops.\nIt shows that an appropriate tradeoff between this two terms can improve model generalization performance.\n\nDR methods can achieve double robustness by jointly considering clicked events and unclicked events. Here, we also study the effect of the sample ratio of unclicked events to clicked events on the performance of DR-MSE.\nWhen the sample ratio is set to ``All'', all the unclicked events are utilized for training; when the sample ratio is set to 0, only clicked events are utilized. As shown in Figure~\\ref{fig:hyperparameter}, when the sample ratio ranges from 0 to ``All'', the DCG@K ($K=1,3,5$) scores on \\textbf{Coat} show an apparent increase first, and then tend to saturate or decrease slightly. It suggests that a certain amount of unclicked events can provide useful information for improving the prediction model with the assistance of an imputation model, but further improvement is marginal when passing some threshold. In real advertising applications, the unclicked events are usually composed of the exposed but unclicked events in consideration of time efficiency. This empirical study on the sample ratio can provide some justification of the practice. \n\n\n\n\n"
                }
            },
            "section 6": {
                "name": "Semi-synthetic Data Experiments",
                "content": "\n\n% \\begin{table*}[t]\n% \\caption{Semi-synthetic datasets based on \\textbf{ML-100k}. %The best two results are highlighted in bold.\n% }\n% \\vspace{-0.3cm}\n% \\center\n% \\small\n% \\renewcommand\\arraystretch{1.1}\n% \\setlength{\\tabcolsep}{5.pt}\n% \\begin{threeparttable}  \n% \\scalebox{1.0}{\n% \\begin{tabular}{c|ccc}\n% \\hline\n% Metrics  & \\multicolumn{3}{c}{AUC}  \\\\\n% \\hline\n% $\\rho$   & 0.5                            & 1                              & 2 \\\\\n% \\hline\n% Naïve   & 0.7250 $\\pm$ 0.0001          & 0.6731 $\\pm$ 0.0001          & 0.5279 $\\pm$ 0.0070  \\\\\n% IPS     & 0.7316 $\\pm$ 0.0001          & 0.6648 $\\pm$ 0.0028          & 0.5263 $\\pm$ 0.0055  \\\\\n% DR-JL   & 0.7319 $\\pm$ 0.0004          & 0.6673 $\\pm$ 0.0035          & 0.5703 $\\pm$ 0.0032   \\\\\n% MRDR & 0.7335 $\\pm$ 0.0006          & 0.6765 $\\pm$ 0.0021          & 0.5563 $\\pm$ 0.0082      \\\\\n% \\hline\n% DR-BIAS & \\textbf{0.7349 $\\pm$ 0.0006*} & \\textbf{0.6916 $\\pm$ 0.0009*}          & \\textbf{0.6073 $\\pm$0.0054*}\\\\\n% DR-MSE  & \\textbf{0.7359 $\\pm$ 0.0002*} & \\textbf{0.6928 $\\pm$ 0.0020*} & \\textbf{0.6084 $\\pm$ 0.0168*}\\\\\n% \\hline\n% \\end{tabular}\n% }   \n% \\end{threeparttable} \n% \\label{tab:synthetic-result}  \n% \\vspace{-0.25cm}\n% \\end{table*}\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n% semi-synthetic experiments: AUC, Log-loss\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n% Research questions to answer through experiments through semi-synthetic data\nIn this section, we aim to investigate the robustness of our proposed method through experiments based on semi-synthetic datasets with different levels of selection bias.\n\n",
                "subsection 6.1": {
                    "name": "Experimental Setup",
                    "content": "\n",
                    "subsubsection 6.1.1": {
                        "name": "Datasets and Preprocessing",
                        "content": "\\label{data_synthesis}\n\\textbf{\\textbf{MovieLens 100K}\\footnote{https://grouplens.org/datasets/movielens/100k/} (\\textbf{ML-100K})} is a dataset collected from a movie recommendation service with 100,000 MNAR ratings from 943 users and 1,682 movies. %The statistics of this dataset is presented in Table~\\ref{tab:dataset}. \nWe used it to generate semi-synthetic datasets for experiments with the following standard procedures as previous studies~\\cite{WSDM_SaitoYNSN20,RecSys_Saito20}.\n\n% [13] Johnson2014LogisticMF [14] koren2009matrix\n%\\begin{enumerate}\n(1) Obtain an approximation of the true ratings of each user on all items with rating-based matrix factorization~\\cite{koren2009matrix}. We denote the predicted rating of a user $u$ on an item $i$ as $\\hat{R}_{u,i}$. Then, the ground-truth CVR for conversion generation is generated as follows:\n{\\small\n\\[\n    p^{cvr}_{u,i} = \\sigma(\\hat{R}_{u,i}-\\epsilon), \\forall (u,i)\\in\\cD,\n\\]\n}\nwhere $\\sigma(\\cdot)$ is the sigmoid function, and $\\epsilon$ controls the level of overall relevance; $\\epsilon$ is set to 5 in experiments.\n\n(2) Obtain an approximation of the true observations with logistic matrix factorization~\\cite{Johnson2014LogisticMF}. We denote the predicted probability of a user-item pair $(u,i)$ being observed as $\\hat{O}_{u,i}$. Then, the ground-truth CTR for generating the click events is defined as follows:\n{\\small\n\\[\n    p^{ctr}_{u,i} = (\\hat{O}_{u,i})^{\\rho}, \\forall (u,i)\\in\\cD,\n\\]\n}\nwhere $\\rho$ controls the skewness of the distribution of the CTR. A large value of $\\rho$ means a huge selection bias in the clicked events and a small number of observed click and conversion events. We set $\\rho$ as 0.5, 1, and 2 in the experiments.\n\n(3) Sample binary click and conversion events with Bernoulli sampling based on the ground-truth CTR and CVR as follows:\n{\\small\n\\[\n    o_{u,i} \\sim Bern(p^{ctr}_{u,i}), \\; r_{u,i} \\sim Bern(p^{cvr}_{u,i}), \\; \\forall (u,i)\\in\\cD,\n\\]\n}\nwhere $Bern(\\cdot)$ is the Bernoulli distribution. Then, the post-click conversions can be derived as $\\{(u,i, r_{u,i})| o_{u,i} = 1\\}$.\n%\\end{enumerate}\n\n"
                    },
                    "subsubsection 6.1.2": {
                        "name": "Baselines and Implementation",
                        "content": "\\label{sec-baslines}\nThe baseline algorithms include the Naive method, IPS~\\cite{schnabel2016recommendations}, DR-JL~\\cite{Wang-Zhang-Sun-Qi2019}, and MRDR~\\cite{MRDR_DL}. The detailed descriptions of the baselines and model implementation are provided in Appendix~\\ref{apdx-semi}.\n\n"
                    },
                    "subsubsection 6.1.3": {
                        "name": "Evaluation Protocols",
                        "content": "\nIn semi-synthetic datasets, we have the ground-truth user preference information and the level of selection bias of the considered datasets, so that we can investigate model robustness through experiments. We generate the semi-synthetic datasets by setting $\\rho$ as 0.5, 1 and 2. The biased set consists of the clicked events generated by the procedure described in Section~\\ref{data_synthesis}, which is further divided into a training set (90\\%) and a validation set (10\\%). We conduct experiments in each setting for 10 times and report the average results. Note that larger value of $\\rho$ means higher selection bias and less clicked events for training because of lower propensity. We use AUC and Log-loss on test sets to evaluate the ranking performance and the relevance prediction, respectively. The test set consists of user-item pairs randomly sampled from the unclicked ones, and we uniformly sample 50 items for each user in the experiments. \n\n"
                    }
                },
                "subsection 6.2": {
                    "name": "Results \\& Discussion",
                    "content": "\nOur method DR-MSE has the best AUC scores and Log-loss results across all the considered levels of selection bias ($\\rho=0.5, 1, 2$). It demonstrates that DR-MSE can achieve better ranking performance and relevance prediction. DR-BIAS also has impressive performance and outperforms MRDR significantly, which is probably because DR-BIAS achieves smaller bias by magnifying the penalty of the clicked events with low propensity while minifying those with high propensity.\nWith the increase of the power $\\rho$, the performance of IPS drops dramatically, and was even worse than that of the Naive method. It shows that IPS suffers heavily from the high variance issue. Doubly robust learning approaches, including DR-JL, MRDR, DR-BIAS and DR-MSE, have better robustness against the selection bias and demonstrate better results compared with the IPS method. Our proposed DR-MSE performs the best because of its bias and variance reduction characteristics.\n\n% ===================================================================\n% =====================================\n\n\\vspace{-0.1cm}\n"
                }
            },
            "section 7": {
                "name": "Related Work",
                "content": "\n",
                "subsection 7.1": {
                    "name": "Approaches to CVR Estimation",
                    "content": "\nIn practice, CTR prediction models are commonly applied to CVR prediction task due to their inherent similarity. These CTR prediction approaches include logistic regression based methods~\\cite{richardson2007predicting,CTR_LR_IJCSIS17}, factorization machine based methods~\\cite{rendle2010factorization,juan2016field}, deep learning based methods~\\cite{cheng2016wide,wang2017deep,guo2017deepfm,CIKM_WangZDSZHYB19}, etc.\nIn addition, many approaches are specially designed for CVR prediction because of several unique and critical issues of the task, such as delayed feedback~\\cite{KDD_Chapelle14,AAAI_ywjzqdaz21,IJCAI_SuZDZYWBXHY20}, data sparsity~\\cite{ESMM18,SIGIR_WenZWLBLY20} and selection bias~\\cite{Multi_IPW,MRDR_DL}. \nIn this paper, we mainly focus on tackling the selection bias issue.\n\n\\textbf{Selection bias} refers to the distribution drift between the train and inference data, which is widely studied recently~\\cite{ESMM18,Multi_IPW,RecSys_Saito20,MRDR_DL}. Some existing multi-task learning methods, such as ESMM~\\cite{ESMM18} and ESM$^2$~\\cite{SIGIR_WenZWLBLY20}, can alleviate the selection bias, but they are heuristic methods and lack theoretic guarantee. \nFurther, the author in~\\cite{Multi_IPW} tried to use DR method to debias CVR prediction and proposed a model namely Multi\\_DR with theoretic guarantee. But they only validated the proposed methods with the biased training and testing sets.\nThe authors in~\\cite{SIGIR_SaitoMY20} proposed a dual learning algorithm for simultaneously tackling the delayed feedback issue and the selection bias issue. MRDR~\\cite{MRDR_DL} designs a new loss for the imputation model to reduce the variance of Multi\\_DR~\\cite{Multi_IPW}. However, it might still suffer from the high bias of DR method due to the incorrect estimations of both propensity scores and imputed errors (which is common in practice). To tackle these problems, in this paper, we proposed a generalized doubly robust learning framework for debiasing CVR prediction, which enables us to propose two new DR methods with more favorable properties.\n\n\\begin{comment}\n\\textbf{Delayed feedback} is due to the long conversion periods, which results in false negative samples. Many existing works tried to solve this problem through time delay modeling~\\cite{KDD_Chapelle14,IJCAI_SuZDZYWBXHY20,SIGIR_SaitoMY20,SIGIR_ZhangJSWXW21,AAAI_ywjzqdaz21}. Early works mainly assumed a static time-delay distribution of the non-converted items, such as an exponential distribution in ~\\cite{KDD_Chapelle14}, a Weibul distribution in~\\cite{fcsc_JiWZ17}, and a non-parametric model in~\\cite{Yoshikawa2018A}. Later, post-click behaviors are utilized to calibrate the time delay model in~\\cite{IJCAI_SuZDZYWBXHY20}. Counterfactual approach is designed to adjust user feedback in~\\cite{SIGIR_ZhangJSWXW21}. Deep neural network is leveraged to model the delay time based on survival analysis in~\\cite{AAAI_ywjzqdaz21}.\n\n\\textbf{Data sparsity} is another challenging problem in CVR prediction, which is due to the extremely sparse clicks and conversions. ESMM~\\cite{ESMM18} jointly models two auxiliary tasks of post-view click-through rate prediction and post-view click-through \\& conversion rate prediction to alleviate this issue. ESM$^2$~\\cite{SIGIR_WenZWLBLY20} further improves ESMM by considering more fine-grained post-click behaviors, such as adding to Shopping Cart and adding to Wise list, in the multi-task prediction framework. In addition, ESDF~\\cite{AAAI_ywjzqdaz21} integrates the time-delay model into the framework to jointly tackle both data sparsity and delayed feedback issues.\n\n\\textbf{Selection bias} refers to the distribution drift between the train and inference data, which is widely studied recently~\\cite{ESMM18,Multi_IPW,RecSys_Saito20,MRDR_DL}. The above mentioned multi-task learning approaches, including ESMM, ESM$^2$ and ESDF, can alleviate the selection bias, but they are heuristic approaches and lack theoretic guarantee. \nFurther, the author in~\\cite{Multi_IPW} tried to use DR method to debias CVR prediction and proposed a model namely Multi\\_DR, which has a theoretic guarantee. But they only validated the proposed methods with the biased training and testing sets.\nThe authors in~\\cite{SIGIR_SaitoMY20} proposed a dual learning algorithm for simultaneously tackling the delayed feedback issue and the selection bias issue. MRDR~\\cite{MRDR_DL} designs a new loss for imputation model to reduce the variance and enhance the robustness of Multi\\_DR~\\cite{Multi_IPW}. However, it might still suffer from the high bias of DR method due to the incorrect estimation of both propensity and imputation error (which is common in practice).\n\\end{comment}\n\n\\vspace{-0.05in}\n"
                },
                "subsection 7.2": {
                    "name": "Debiasing in Recommendation Tasks",
                    "content": "\n% hxli@stu.pku.edu.cn,wupeng@bicmr.pku.edu.cn\nRecent years have witnessed many contributions on incorporating the causal inference idea into the recommendation domain for unbiased learning~\\cite{schnabel2016recommendations,Wang-Zhang-Sun-Qi2019}.\nFor example, ~\\cite{schnabel2016recommendations} explains the recommendation problem by a treatment-effect model, and designs an IPS based method to remove the bias in the observed data based on explicit feedback.~\\cite{Wang-Zhang-Sun-Qi2019} improves over the IPS based method by designing a doubly robust learning approach.\n%~\\cite{yang2018unbiased,saito2019unbiased} design tailored unbiased loss to handle user implicit feedback.\nIn addition, several existing works~\\cite{bonner2018causal,liu2020general,LTD_debias,AutoDebias} design debiasing models by leveraging the available small set of unbiased data.\n%~\\cite{chen2020bias} provides a thorough discussion on the recent progress on debiased recommendation. \nThough these methods have achieved many successes in debiasing recommendation tasks, none of them are specially proposed for CVR prediction. How to design an unbiased learning algorithm for CVR prediction is highly important and needs to be studied further.\n\n\\begin{comment}\nRecent years have witnessed many efforts on incorporating the causal inference into the recommendation domain for unbiased learning~\\cite{schnabel2016recommendations,saito2019unbiased}.\nFor example, ~\\cite{schnabel2016recommendations} designs an IPS based method to remove the bias in the observed data based on explicit feedback.~\\cite{Wang-Zhang-Sun-Qi2019} improves over the IPS based method by designing a doubly robust learning approach.\n~\\cite{yang2018unbiased,saito2019unbiased} design tailored unbiased loss to handle user implicit feedback.\nIn addition, several existing works~\\cite{bonner2018causal,liu2020general,LTD_debias,AutoDebias} leverage the available small set of unbiased data to improve unbiased learning.\n~\\cite{chen2020bias} provides a thorough discussion on the recent progress on debiased recommendation. \nThough these methods have achieved many successes, none of them are specially proposed for CVR prediction. How to design an unbiased learning algorithm for CVR prediction is highly important and needs to be studied further.\n\\end{comment}\n\n\\vspace{-0.05in}\n"
                }
            },
            "section 8": {
                "name": "Conclusion",
                "content": "\nWe have proposed a generic doubly robust (DR) learning framework for debiasing CVR prediction based on the theoretical analysis of the bias, variance and generalization bounds of existing DR methods. This framework enables us to develop a series of new estimators with different desired characteristics to accommodate different application scenarios in CVR prediction. In particular, based on the framework, we proposed two new DR methods, namely DR-BIAS and DR-MSE, which are designed to further reduce the bias and achieve a better bias-variance trade-off. \nIn addition, we propose a novel tri-level  optimization for DR-MSE, and the corresponding efficient training algorithm. Finally, we empirically validate the effectiveness of the proposed methods by extensive experiments on both semi-synthetic and real-world datasets.\n\n"
            },
            "section 9": {
                "name": "Acknowledgements",
                "content": "\nThis study was partly supported by grants from the National Science and Technology Major Project of the Ministry of Science and Technology of China (No.2021YFF0901400). We appreciate the support from Mindspore\\footnote{\\url{https://www.mindspore.cn}}, which is a new deep learning computing framework.\n%\\newpage\n\\bibliographystyle{ACM-Reference-Format}\n\\balance\n\\bibliography{reference}\n\n%\\begin{comment}\n\\clearpage\n\\appendices\n\n\n"
            },
            "section 10": {
                "name": "Proof of lemmas",
                "content": " \\label{proof_lemma}\nThis supplementary material contains the proofs of Lemma 1 and Lemma 2.  \n% \\section{Proofs}\nFor ease of exposition, let $\\cL(\\hat \\bR) = \\cL(\\hat \\bR, \\bR^{o})$. \n\n%The bias and variance of the DR estimator are formally derived as follows. \n\\setcounter{theorem}{0}\n\\begin{lemma}[Bias and Variance]\nGiven \n%features $x_{u,i}$ of all events,  \nimputed errors $\\hat \\bE$ and learned propensities $\\hat \\bP$ with $\\hat p_{u,i} > 0$ for all user-item pairs, the bias and variance of DR estimator are given as \n% the biases of the IPS, EIB and DR estimators are given as \n    {%\\small\n\t\\begin{align*}\n\t%\\small\n%\tBias[  \\cL_{IPS}(\\hat \\bR, \\bR^{o}) ] ={}&   \\frac{1}{ | \\cD | }  \\Big |  \\sum_{(u,i) \\in D}  \\frac{ p_{u,i} - \\hat p_{u,i}  }{ \\hat p_{u,i} }   e_{u,i} \\Big |, \\\\\n%\\[\tBias[  \\cL_{EIB}(\\hat \\bR, \\bR^{o}) ] =   \\frac{1}{ | \\cD | }  \\Big |  \\sum_{(u,i) \\in D}  (1 - p_{u,i}) (\\hat e_{u,i} -  e_{u,i} ) \\Big |,   \\\\\n   Bias[  \\cL_{DR}(\\hat \\bR, \\bR^{o}) ] ={}&   \\frac{1}{ | \\cD | } \\Big |  \\sum_{(u,i) \\in D}  (p_{u,i} - \\hat p_{u,i}) \\frac{ ( e_{u,i} - \\hat e_{u,i})  }{ \\hat p_{u,i} }  \\Big |, \\\\\n    \\V_{\\cO}[ \\cL_{DR}(\\hat \\bR, \\bR^{o})  ]  ={}&  \\frac{1}{ |\\cD|^{2} } \\sum_{(u,i)\\in \\cD}    p_{u,i} (1- p_{u,i})  \\frac{ ( \\hat e_{u,i} - e_{u,i} )^{2} }{  \\hat p^{2}_{u,i}  }  . \n    \\end{align*}}\n\\end{lemma}\n\n\\begin{proof}  \nAccording to the definition of bias, \n{%\\small\n\t\\begin{align*}\n\t\t Bias[  \\cL_{DR}(\\hat \\bR) ] \n\t\t  ={}&  \\Big | \\bfE_{\\cO}[ \\cL_{DR}(\\hat \\bR)]  -   \\cL_{ideal}(\\hat \\bR, \\bR)    \\Big |    \\\\\n\t\t ={}&  \\Big |  \\frac{1}{ |\\cD| } \\sum_{(u,i) \\in \\cD} \\bfE_{\\cO}[  \\hat e_{u,i}  +  \\frac{ o_{u,i} (e_{u,i} -  \\hat e_{u,i}) }{ \\hat p_{u, i} }  - e_{u,i} ]      \\Big |  \t\t  \\\\\n\t\t\t\t={}&    \\Big |  \\frac{1}{ |\\cD| } \\sum_{(u,i) \\in \\cD} [  \\hat e_{u,i}  +  \\frac{ p_{u,i} (e_{u,i} -  \\hat e_{u,i}) }{ \\hat p_{u, i} }  - e_{u,i} ]      \\Big |  \t\t  \\\\\n\t\t ={}& \\frac{1}{ | \\cD | } \\Big |   \\sum_{(u,i) \\in D}  \\frac{ p_{u,i} - \\hat p_{u,i}  }{ \\hat p_{u,i} } ( e_{u,i} - \\hat e_{u,i}) \\Big |.\n  \\end{align*}\n  }\nThe variance of $\\cL_{DR}(\\hat \\bR)$ with respect to  click indicator is given as  \n{%\\small\n\t\\begin{align*}\n\t\t\t  \\V_{\\cO}[ \\cL_{DR}(\\hat \\bR) ] \n\t\t\t  ={}&    \\frac{1}{ |\\cD|^{2} }   \\sum_{(u,i) \\in \\cD}   \\V_{\\cO}  [   \\hat e_{u,i}  +  \\frac{ o_{u,i} (e_{u,i} -  \\hat e_{u,i}) }{ \\hat p_{u, i} } ]     \\\\\n\t\t\t%  ={}&    \\frac{1}{ |\\cD|^{2} }   \\sum_{(u,i) \\in \\cD}   \\V_{\\cO}  [   o_{u,i} ( e_{u,i} - \\hat e_{u,i} )]     \\\\\n\t\t\t  ={}&   \\frac{1}{ |\\cD|^{2} }   \\sum_{(u,i) \\in \\cD}   \\V_{\\cO}[o_{u,i}] \\cdot \\left( \\frac{e_{u,i} - \\hat e_{u,i } }{ \\hat p_{u,i} }   \\right)^{2}         \\\\\n\t\t\t  ={}&   \\frac{1}{ |\\cD|^{2} } \\sum_{(u,i)\\in \\cD}    \\frac{ p_{u,i} (1- p_{u,i})  }{    \\hat p^{2}_{u,i}  }  ( \\hat e_{u,i} - e_{u,i} )^{2}.  \n\t\\end{align*}\n\t}\n\\end{proof}\n\n\nTo show the generalization bound of doubly robust estimator, we need the Hoeffding’s inequality for general bounded random variables, which is presented in Lemma 3.  \n\n\n\\begin{lemma}[Generalization Bound]\nFor any finite hypothesis space $\\cH$ of prediction matrices,  given   imputed errors $\\hat \\bE$ and learned propensities $\\hat \\bP$,  then  with probability $1 - \\eta$, \n    {%\\small\n\t\\begin{align*} \n\t  \\cL_{ideal}(\\hat \\bR^{*}, \\bR)  \n\t  \\leq{}&  \\cL_{DR}(\\hat \\bR^{*}, \\bR^{o})  +   \\underbrace{\\frac{1}{ | \\cD | }  \\sum_{(u,i) \\in \\cD}   \\frac{ | p_{u,i} - \\hat p_{u,i} |  }{ \\hat p_{u,i} }  |  e_{u,i} - \\hat e_{u,i}^{*}  | }_{\\text{Bias term}}  \\\\\n\t   &  +  \\underbrace{ \\sqrt{ \\frac{ \\log(2|\\cH | /\\eta)  }{ 2 |\\cD |^{2}  }   \\sum_{(u,i)\\in \\cD} (  \\frac{  e_{u,i} - \\hat e_{u,i}^{\\dag}  } { \\hat p_{u,i} }  )^{2}   } }_{\\text{Variance term}},       \n\t   \\end{align*}\n\t   }\nwhere $\\hat e_{u,i}^{\\dag}$ is the prediction error corresponding to the prediction matrix $\\hat \\bR^{\\dag} = \\arg \\max_{ \\hat \\bR^{h} \\in \\cH } \\sum_{(u,i) \\in \\cD } (e_{u,i} -\\hat e_{u,i}^{h})^2 /\\hat p_{u,i}^2$, $\\hat e_{u,i}^{*}$ is the prediction error associated with  $\\hat \\bR^{*}$. \n %$\\hat \\bR^{\\dag} = \\arg \\max_{ \\hat \\bR^{h} \\in \\cH } \\sum_{(u,i) \\in \\cD } (  \\frac{ e_{u,i} -\\hat e_{u,i}^{h}  } { \\hat p_{u,i} }  )^{2}$.  \n\\end{lemma}\n\n\\begin{proof}  We first note that \n{%\\small\n\t\\begin{align}\n\t &  \\cL_{ideal}(\\hat \\bR^{*}, \\bR) -    \\cL_{DR}(\\hat \\bR^{*})  \\notag \\\\\n\t  ={}&  \\cL_{ideal}(\\hat \\bR^{*}, \\bR)  - \\bfE_{\\cO}[  \\cL_{DR}(\\hat \\bR^{*}) ] + \\bfE_{\\cO}[  \\cL_{DR}(\\hat \\bR^{*}) ] -  \\cL_{DR}(\\hat \\bR^{*})  \\notag \\\\\n\t  \\leq{}&  Bias[  \\cL_{DR}(\\hat \\bR^{*}) ]  +   \\bfE_{\\cO}[  \\cL_{DR}(\\hat \\bR^{*}) ] -  \\cL_{DR}(\\hat \\bR^{*})  \\notag \\\\\n\t  \\leq{}&  \\frac{1}{ | \\cD | }  \\sum_{(u,i) \\in \\cD}   \\frac{ | p_{u,i} - \\hat p_{u,i} |  }{ \\hat p_{u,i} }  |  e_{u,i} - \\hat e_{u,i}^{*}  |  +  \\bfE_{\\cO}[  \\cL_{DR}(\\hat \\bR^{*}) ] -  \\cL_{DR}(\\hat \\bR^{*}) \\label{A1}. \n\t  \t\\end{align}\n\t  \t}\nNext we focus on analyzing $\\bfE_{\\cO}[  \\cL_{DR}(\\hat \\bR^{*}) ] -  \\cL_{DR}(\\hat \\bR^{*})$.  \n  By Hoeffding's inequality in Lemma 3,  let $X_{u,i} = \\frac{ o_{u,i} (e_{u,i} - \\hat e_{u,i})  }{ \\hat p_{u,i}  }$, then $M_{u,i} - m_{u,i} = \\frac{|e_{u,i} - \\hat e_{u,i}|  }{ \\hat p_{u,i} }$, and for any $\\epsilon > 0$, we have  \n  {%\\small\n\t\\begin{align*}\n\t & \\P \\big \\{ \\big |   \\cL_{DR}(\\hat \\bR^{*}) - \\bfE_{\\cO}[  \\cL_{DR}(\\hat \\bR^{*}) ]  \\big |  \\leq \\epsilon   \\big  \\}  \\\\\n={}&  1 -  \\P \\big \\{  \\big |   \\cL_{DR}(\\hat \\bR^{*}) - \\bfE_{\\cO}[  \\cL_{DR}(\\hat \\bR^{*}) ]  \\big |  > \\epsilon   \\big  \\}  \\\\\n\\geq{}&  1 -   \\P \\big \\{ \\sup_{ \\hat \\bR^{h} \\in \\cH } \\big |   \\cL_{DR}(\\hat \\bR^{h}) - \\bfE_{\\cO}[  \\cL_{DR}(\\hat \\bR^{h}) ]  \\big |  > \\epsilon   \\big  \\}  \\\\\n\\geq{}&  1 -  \\sum_{h=1}^{\\cH}  \\P \\big \\{ \\big |   \\cL_{DR}(\\hat \\bR^{h}) - \\bfE_{\\cO}[  \\cL_{DR}(\\hat \\bR^{h}) ]  \\big |  > \\epsilon   \\big  \\}  \\\\ \n={}&   {\\scriptsize 1-\\sum_{h=1}^{\\cH}  \\P \\big \\{ \\big | \\sum_{(u,i)\\in \\cD } \\big( \\frac{ o_{u,i} (e_{u,i} - \\hat e_{u,i}^{h})  }{ \\hat p_{u,i}  }   -  \\bfE_{\\cO} \\big ( \\frac{ o_{u,i} (e_{u,i} - \\hat e_{u,i}^{h})  }{ \\hat p_{u,i}  } \\big ) \\big)  \\big |  > \\epsilon  |\\cD| \\big  \\} }\t\\\\\n\\geq{}&  1-  \\sum_{h=1}^{\\cH}  2   \\exp\\big \\{  -  2  \\epsilon^{2} |\\cD|^{2} \\big /  \\sum_{(u,i)\\in \\cD} (  \\frac{ e_{u,i} - \\hat e_{u,i}^{h}   } { \\hat p_{u,i} }  )^{2}     \\big \\}\\\\\n \\geq{}&1 - 2  |\\cH|  \\exp\\big \\{  -  2  \\epsilon^{2} |\\cD|^{2} \\big /  \\sum_{(u,i)\\in \\cD} (  \\frac{ e_{u,i} - \\hat e_{u,i}^{\\dag}   } { \\hat p_{u,i} }  )^{2}     \\big \\}.   \n\t\\end{align*}\n\t}\nLetting $2 |\\cH| \\exp\\big \\{  -  2  \\epsilon^{2} |\\cD|^{2} \\big /  \\sum_{(u,i)\\in \\cD} (  \\frac{ e_{u,i} - \\hat e_{u,i}^{\\dag}   } { \\hat p_{u,i} }  )^{2}     \\big \\} = \\eta$ yields that \n{%\\small\n\t  \t\\[       \\epsilon =  \\sqrt{ \\frac{ \\log(2 |\\cH | /\\eta)  }{ 2 |\\cD |^{2}  }   \\sum_{(u,i)\\in \\cD} (  \\frac{  e_{u,i} - \\hat e_{u,i}^{\\dag}  } { \\hat p_{u,i} }  )^{2}   }.         \\]\n\t  \t}\n Then with probability $1- \\eta$, we have \n {%\\small\n \t\\begin{equation} \\label{A2}      \\bfE_{\\cO}[  \\cL_{DR}(\\hat \\bR^{*}) ] -  \\cL_{DR}(\\hat \\bR^{*}) \\leq   \\sqrt{ \\frac{ \\log(2 |\\cH | /\\eta)  }{ 2 |\\cD |^{2}  }   \\sum_{(u,i)\\in \\cD} (  \\frac{ e_{u,i} - \\hat e_{u,i}^{\\dag}   } { \\hat p_{u,i} }  )^{2}   }.     \\end{equation}\n \t}\nLemma 2 follows immediately from inequalities (\\ref{A1}) and  \t(\\ref{A2}). \n\\end{proof}\n\n\\begin{lemma}[Hoeffding’s inequality for general bounded random variables] Let $X_{1}, ..., X_{N}$ be independent random variables. Assume that $X_{i} \\in [m_{i}, M_{i}]$ for every $i$, Then, for any $\\epsilon > 0$, we have   \n{%\\small\n\t\\[      \\P \\big \\{ \\big | \\sum_{i=1}^{N} X_{i}  - \\sum_{i=1}^{N} \\bfE X_{i}  \\big |  > \\epsilon   \\big  \\}  \\leq 2 \\exp\\big \\{  - \\frac{ 2  \\epsilon^{2} }{ \\sum_{i=1}^{N} (M_{i} - m_{i})^{2} }  \\big \\}.       \\]\n\t}\n\\end{lemma} \n\\begin{proof}\n\tThe proof can be found in Theorem 2.2.6 of \\cite{Vershynin2018}. \n\\end{proof}\n\n"
            },
            "section 11": {
                "name": "Yahoo",
                "content": "\\label{apdx-semi}\nHere, we provide more detailed experimental settings on \\textbf{Coat}, \\textbf{Yahoo}, and semi-synthetic datasets generated from \\textbf{ML-100K}.\n\n",
                "subsection 11.1": {
                    "name": "Datasets",
                    "content": "\\label{apdx-data}\n\\begin{itemize}[leftmargin=5.5mm]\n\t\\item {\\bf \\textbf{Coat Shopping}}: It contains a MNAR training set and a MAR testing set. Specifically, there are 6,960 five-star ratings from 290 Amazon Mechanical Turkers on an inventory of 300 coats in the training set. There are 4,640 ratings collected from the 290 workers on 16 randomly selected coats in the testing set.\n\t%This dataset contains five-star ratings from 290 Amazon Mechanical Turkers on an inventory of 300 coats. It includes a MNAR training set and a MAR testing set.\n\t\\item {\\bf \\textbf{Yahoo! R3}}: It includes a MNAR training set with 311,704 five-star ratings from 15,400 users and 1,000 songs, and a MAR testing set with 54,000 ratings from 5,400 users on 10 randomly selected songs.\n\\end{itemize}\t\t\nTo make the two datasets consistent with the CVR prediction task, we further preprocess them following previous studies~\\cite{RecSys_Saito20,MRDR_DL}:\t\n \t\\begin{enumerate}\n\t\\item  The conversion label $r_{u,i}$ is defined as 1 if the rating of item $i$ by user $u$ is greater than or equal to 4, and 0 otherwise.\n\t\t\t%\t\\[  r_{u,i} = \\begin{cases}\n\t\t\t%\t\t\t& 1, \\text{if the rating of item $i$ by user $u$ is greater than or equal to 4}, \\\\\n\t\t\t%\t\t\t& 0,  \\text{otherwise}. \n\t\t\t%\t\\end{cases}\n            %    \\]\n\t\\item   The click indicator $o_{u,i}$ is defined as 1 if user $u$ rated item $i$, and 0 otherwise.\n\t\t\t%\\[    o_{u,i} = \\begin{cases}\n\t\t\t%\t\t\t& 1, \\quad \\text{if user $u$ rated item $i$}, \\\\\n\t\t\t%\t\t\t& 0,   \\quad \\text{otherwise}.\n\t\t\t%\\end{cases}\n            %\\]\n    \\item The sets of observed potential conversion labels $r_{u,i}(1)$ is denoted as $\\bR^{o} = \\{ r_{u,i}(1) \\mid o_{u,i} = 1 \\} = \\{ r_{u,i} \\mid o_{u,i} = 1 \\}$.  \t\t\t\t\t\n\t\\end{enumerate}\nFor both datasets, we split the corresponding MNAR dataset into a training (90\\%) and a validation (10\\%) sets, while all the MAR data is set to testing set. In addition, we restrict our samples to the users with at least one conversion behavior in the testing set as~\\cite{RecSys_Saito20,MRDR_DL}. \n\n\\vspace{-0.1cm}\n\n"
                },
                "subsection 11.2": {
                    "name": "Baselines",
                    "content": "\\label{apdx-semi-baslines}\nWe compare our proposed methods with the following baselines: \n% Naive, IPS, DR-JL and MRDR.\n% {\\bf Naive} directly uses the naive estimator as the loss function for CVR prediction.\n% {\\bf IPS}~\\cite{schnabel2016recommendations} uses the inverse propensity reweighting approach to adjust the distribution of the biased training data.\n% {\\bf DR-JL}~\\cite{Wang-Zhang-Sun-Qi2019} proposes a doubly robust learning model which jointly trains the imputation model and prediction model.\n% {\\bf MRDR}~\\cite{MRDR_DL} is the state-of-the-art model for debiasing CVR prediction, which reduces the variance of doubly robust learning method by designing a new loss for the imputation model.\n\\begin{itemize}[leftmargin=5.5mm]\n\\item {\\bf Naive}: It directly uses the naive estimator as the loss function for CVR prediction.\n\\item {\\bf IPS}~\\cite{schnabel2016recommendations}: It uses the inverse propensity reweighting approach to adjust the distribution of the biased training data.\n\\item {\\bf DR-JL}~\\cite{Wang-Zhang-Sun-Qi2019}: It proposes a doubly robust learning model which jointly trains the imputation model and prediction model.\n\\item {\\bf MRDR}~\\cite{MRDR_DL}: It is the state-of-the-art model for debiasing CVR prediction, which reduces the variance of doubly robust learning method by designing a new loss for the imputation model.\n\\end{itemize}\nFor all considered methods, we follow prior work~\\cite{MRDR_DL} to use factorization machine (FM)~\\cite{rendle2010factorization} for both CTR and CVR predictions in experiments of \\textbf{Coat}, \\textbf{Yahoo}, and the semi-synthetic datasets. The CTR prediction model is firstly learned with FM, and used to generate the CTR scores for inverse propensity weighting as~\\cite{Wang-Zhang-Sun-Qi2019,MRDR_DL}.\n\n\\vspace{-0.1cm}\n\n\n% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n% % Statistics of Huawei Dataset\n% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n% \\begin{table}[t]\n% \\caption{Statistics of the advertising dataset \\textbf{Product}}\n% \\vspace{-0.3cm}\n% \\center\n% \\small\n% \\renewcommand\\arraystretch{1.0}\n% \\setlength{\\tabcolsep}{8.pt}\n% \\scalebox{0.85}{\n% \\begin{tabular}{cccccc}\n% \\hline\n% %\\toprule\n% Dataset & \\#Impression & \\#Click & \\#Conversion & \\#User & \\#Item\\\\\n% \\hline\n% Training & 739.66M    & 3.73M   & 1.90M         & 524K &   68K\\\\\n% Testing & 99.73M     & 519K    & 268K          & 283K &   52K\\\\\n% \\hline\n% %\\bottomrule\n% \\end{tabular}}\n% \\begin{tablenotes}\n% \\footnotesize\n% \\item Note: ``M'' means million, and ``K'' means thousand. \n% \\end{tablenotes}\n% \\label{tab:huawei}   \n% \\vspace{-0.25cm}\n% \\end{table}\n% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n"
                },
                "subsection 11.3": {
                    "name": "Model Implementation",
                    "content": "\\label{apdx-model-implement}\nWe implement all models with TensorFlow~\\cite{tensorflow2015-whitepaper} and optimize them with mini-batch Adam~\\cite{kingma2014adam}.\nWe determine the hyper-parameters of each model based on grid search, and the search ranges for the embedding size, batch size, learning rate, L2 regularization coefficient, and sample ratio of unclicked events to clicked events are set as \\{16, 32, 64, 128, 256\\}, \\{256, 512, 1024, 2048\\}, \\{5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2\\}, \\{1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3\\}, and \\{2, 4, 6, 8\\}, respectively.\nThe best configuration for each method is determined based on the ranking performance on the validation set.\n\n"
                }
            },
            "section 12": {
                "name": "Product",
                "content": "\\label{apdx-product}\n",
                "subsection 12.1": {
                    "name": "Baselines",
                    "content": "\nWe further provide some descriptions of the baselines as follows:\n\\begin{itemize}[leftmargin=5.5mm]\n    \\item \\textbf{DCN}~\\cite{wang2017deep}: It is a widely used deep CTR prediction model with a naive estimator. It consists of a deep network and a cross network for feature interaction learning. It is the base model for building all other models.\n    \\item \\textbf{ESMM}~\\cite{ESMM18}: It is a multi-task learning model that jointly optimizes CTR prediction and CTCVR prediction.\n    \\item \\textbf{DR-JL}~\\cite{Wang-Zhang-Sun-Qi2019}: This model is proposed for debiasing rating prediction by designing a doubly robust learning approach that jointly trains the error imputation model and prediction model. We adapt it for CVR prediction on large-scale dataset with the model architecture shown in Figure~\\ref{fig:causalmtl4.1}.\n    \\item \\textbf{Multi\\_IPW}~\\cite{Multi_IPW}: This model tackles the selection bias in CVR prediction with the inverse propensity weighting approach. It jointly optimizes the CTR loss and IPS based CVR loss.\n    \\item \\textbf{Multi\\_DR}~\\cite{Multi_IPW}: This model tackles the selection bias in CVR prediction with the doubly robust learning approach inspired by the DR-JL method.\n    \\item {\\bf MRDR}~\\cite{MRDR_DL}: It is the state-of-the-art model for debiasing CVR prediction, which reduces the variance of DR method by designing a new loss for the imputation model. However, in the original paper, no experiments on large-scale datasets have been conducted. The original model implementation is not suitable for large-scale dataset, thus we adapt it for experiments on \\textbf{Product} with the model architecture shown in Figure~\\ref{fig:causalmtl4.1}.\n\\end{itemize}\n\nFor DCN, we train two separate models for CTR and CVR predictions, respectively, and then combine the predictions of these two tasks to obtain the prediction of CTCVR. Besides, the prediction models of DR based methods, including DR-JL, MRDR, DR-BIAS and DR-MSE, are adapted into a multi-task learning framework presented in Figure~\\ref{fig:causalmtl4.1} to jointly model CTR prediction and CVR prediction. In other words, the propensity estimation model is jointly learned with the prediction model to handle the data sparsity and selection bias issues. \n\n"
                },
                "subsection 12.2": {
                    "name": "Model Implementation",
                    "content": "\nWe implement all models with TensorFlow and optimize them with mini-batch Adam. \nFor DCN, the embedding size, batch size, learning rate, keep probability of dropout, L2 regularization coefficient and L1 regularization coefficient are set to 150, 8000, 1.5e-4, 0.9, 1e-4, and 1e-8, respectively. The structure of deep network of DCN is set to [1024, 512, 64], and the number of cross layers is set to 3. Other models, including ESMM, DR-JL, Multi\\_IPW, Multi\\_DR, DR-BIAS and DR-MSE, are built upon DCN. They use similar settings as the baseline DCN for common hyper-parameters. \nBesides, IPS based loss suffers from the high variance issue. We clip the predicted CTR with $\\max\\{0.03, CTR\\}$ to obtain propensity score for both IPS based methods and DR based methods to alleviate this issue. \\textbf{Product} contains a training set and a testing set. We report the best results among all training epochs on the testing set of all methods in Table~\\ref{tab:huawei-result} for comparison.\n\n\n% \\begin{equation}\n% \\cL_{e}^{DR-BIAS}(\\theta) = \\sum_{(u,i)\\in \\cD} \\frac{ o_{u,i} (  \\hat e_{u,i} - e_{u,i} )^{2}  }{  \\hat p_{u,i} } \\cdot  \\frac{(1-\\hat p_{u,i})}{ \\hat p_{u,i}} \\cdot \\frac{(1-\\hat p_{u,i})}{\\hat p_{u,i}} \n% \\end{equation}\n\n"
                }
            }
        },
        "tables": {
            "tab:huawei": "\\begin{table}[t]\n\\caption{Statistics of the advertising dataset \\textbf{Product}}\n\\vspace{-0.3cm}\n\\center\n\\small\n\\renewcommand\\arraystretch{1.0}\n\\setlength{\\tabcolsep}{8.pt}\n\\scalebox{0.85}{\n\\begin{tabular}{cccccc}\n\\hline\n%\\toprule\nDataset & \\#Impression & \\#Click & \\#Conversion & \\#User & \\#Item\\\\\n\\hline\nTraining & 739.66M    & 3.73M   & 1.90M         & 524K &   68K\\\\\nTesting & 99.73M     & 519K    & 268K          & 283K &   52K\\\\\n\\hline\n%\\bottomrule\n\\end{tabular}}\n\\begin{tablenotes}\n\\footnotesize\n\\item Note: ``M'' means million, and ``K'' means thousand. \n\\end{tablenotes}\n\\label{tab:huawei}   \n\\vspace{-0.3cm}\n\\end{table}",
            "tab:real-result": "\\begin{table*}[t]\n\\caption{Performance comparison based on \\textbf{Coat} and \\textbf{Yahoo}. %The best two results are highlighted in bold.\n}\n\\vspace{-0.3cm}\n\\center\n\\small\n\\renewcommand\\arraystretch{1.0}\n\\setlength{\\tabcolsep}{5.pt}\n\\begin{threeparttable}  \n\\scalebox{0.90}{\n\\begin{tabular}{c|c|ccc|ccc}\n\\hline\nDatasets                & Models           & \\multicolumn{1}{c}{DCG@2}               & \\multicolumn{1}{c}{DCG@4}               & \\multicolumn{1}{c|}{DCG@6}               & \\multicolumn{1}{c}{Recall@2}            & \\multicolumn{1}{c}{Recall@4}            & \\multicolumn{1}{c}{Recall@6}            \\\\\n\\hline\n\\multirow{7}{*}{\\textbf{Coat}}  & Naïve           & 0.7283 $\\pm$ 0.0264          & 0.9763 $\\pm$ 0.0258          & 1.1512 $\\pm$ 0.0241          & 0.8474 $\\pm$ 0.0310          & 1.3786 $\\pm$ 0.0374          & 1.8490 $\\pm$ 0.0379          \\\\\n                       & IPS             & 0.7102 $\\pm$ 0.0220          & 0.9596 $\\pm$ 0.0222          & 1.1299 $\\pm$ 0.0210          & 0.8248 $\\pm$ 0.0272          & 1.3596 $\\pm$ 0.0360          & 1.8174 $\\pm$ 0.0377          \\\\\n                       & DR-JL           & 0.7416 $\\pm$ 0.0224          & 1.0021 $\\pm$ 0.0224          & 1.1762 $\\pm$ 0.0229          & 0.8645 $\\pm$ 0.0264          & 1.4225 $\\pm$ 0.0362          & 1.8906 $\\pm$ 0.0403          \\\\\n                       %& MRDR-DL         & 0.7273 $\\pm$ 0.0256          & 0.9907 $\\pm$ 0.0283          & 1.1680 $\\pm$ 0.0279          & 0.8537 $\\pm$ 0.0326          & 1.4176 $\\pm$ 0.0440          & 1.8941 $\\pm$ 0.0457          \\\\\n                       & MRDR & 0.7442 $\\pm$ 0.0225          & 1.0132 $\\pm$ 0.0219          & 1.1947 $\\pm$ 0.0194          & 0.8736 $\\pm$ 0.0273          & 1.4494 $\\pm$ 0.0325          & 1.9370 $\\pm$ 0.0318          \\\\\n                       \\cline{2-8}\n                       %& DR-VAR & 0.7442 $\\pm$ 0.0225          & 1.0132 $\\pm$ 0.0219          & 1.1947 $\\pm$ 0.0194          & 0.8736 $\\pm$ 0.0273          & 1.4494 $\\pm$ 0.0325          & 1.9370 $\\pm$ 0.0318          \\\\\n                       & DR-BIAS        & \\textbf{0.7648 $\\pm$ 0.0192*} & \\textbf{1.0353 $\\pm$ 0.0169*} & \\textbf{1.2127 $\\pm$ 0.0162*} & \\textbf{0.8959 $\\pm$ 0.0251*} & \\textbf{1.4751 $\\pm$ 0.0273*} & \\textbf{1.9517 $\\pm$ 0.0324*} \\\\\n                       & DR-MSE          & \\textbf{0.7682 $\\pm$ 0.0151*} & \\textbf{1.0401 $\\pm$ 0.0150*} & \\textbf{1.2170 $\\pm$ 0.0139*} & \\textbf{0.8997 $\\pm$ 0.0194*} & \\textbf{1.4816 $\\pm$ 0.0241*} & \\textbf{1.9569 $\\pm$ 0.0262*} \\\\\n                       \\hline\\hline\n%\\multirow{7}{*}{yahoo} & Naïve           & 0.5571 $\\pm$ 0.0009          & 0.7565 $\\pm$ 0.0008          & \\textbf{0.8848 $\\pm$ 0.0004} & 0.6614 $\\pm$ 0.0012          & 1.0864 $\\pm$ 0.0016          & \\textbf{1.4305 $\\pm$ 0.0013} \\\\\n\\multirow{7}{*}{\\textbf{Yahoo}} & Naïve           & 0.5469 $\\pm$ 0.0009          & 0.7466 $\\pm$ 0.0008          & 0.8714 $\\pm$ 0.0004 & 0.6479 $\\pm$ 0.0012          & 1.0745 $\\pm$ 0.0016          & 1.4098 $\\pm$ 0.0013 \\\\\n                       %& IPS             & 0.5553 $\\pm$ 0.0010          & 0.7550 $\\pm$ 0.0009          & 0.8844 $\\pm$ 0.0009          & 0.6551 $\\pm$ 0.0017          & 1.0804 $\\pm$ 0.0017          & \\textbf{1.4284 $\\pm$ 0.0019} \\\\\n                       & IPS             & 0.5502 $\\pm$ 0.0010          & 0.7520 $\\pm$ 0.0009          & 0.8751 $\\pm$ 0.0009          & 0.6545 $\\pm$ 0.0017          & 1.0797 $\\pm$ 0.0017          & \\textbf{1.4168 $\\pm$ 0.0019} \\\\\n                       & DR-JL           & 0.5602 $\\pm$ 0.0034          & 0.7586 $\\pm$ 0.0030          & 0.8808 $\\pm$ 0.0025          & 0.6615 $\\pm$ 0.0042          & 1.0849 $\\pm$ 0.0049          & 1.4129 $\\pm$ 0.0039          \\\\\n                       %& MRDR-DL         & 0.5592 $\\pm$ 0.0036          & 0.7586 $\\pm$ 0.0028          & 0.8796 $\\pm$ 0.0027          & 0.6609 $\\pm$ 0.0044          & 1.0869 $\\pm$ 0.0046          & 1.4113 $\\pm$ 0.0048          \\\\\n                       & MRDR & 0.5623 $\\pm$ 0.0024          & 0.7603 $\\pm$ 0.0027          & 0.8820 $\\pm$ 0.0020          & 0.6646 $\\pm$ 0.0033          & 1.0881 $\\pm$ 0.0045          & 1.4145 $\\pm$ 0.0037          \\\\\n                       \\cline{2-8}\n                       %& DR-VAR & 0.5623 $\\pm$ 0.0024          & 0.7603 $\\pm$ 0.0027          & 0.8820 $\\pm$ 0.0020          & 0.6646 $\\pm$ 0.0033          & 1.0881 $\\pm$ 0.0045          & 1.4145 $\\pm$ 0.0037          \\\\\n                       & DR-BIAS        & \\textbf{0.5646 $\\pm$ 0.0023*} & \\textbf{0.7624 $\\pm$ 0.0021*} & \\textbf{0.8841 $\\pm$ 0.0018*}          & \\textbf{0.6676 $\\pm$ 0.0026*} & \\textbf{1.0904 $\\pm$ 0.0028*} & \\textbf{1.4169 $\\pm$ 0.0020}          \\\\\n                       & DR-MSE          & \\textbf{0.5662 $\\pm$ 0.0017*} & \\textbf{0.7639 $\\pm$ 0.0016*} & \\textbf{0.8850 $\\pm$ 0.0014*} & \\textbf{0.6670 $\\pm$ 0.0026*} & \\textbf{1.0891 $\\pm$ 0.0029} & 1.4140 $\\pm$ 0.0028          \\\\\n                       \\hline\n                       %\\multicolumn{9}{l}{* statistically significant results ($\\text{p-value} \\leq 0.05$) using the paired-t-test.}\n\\end{tabular}\n}   \n\\end{threeparttable}\n\\begin{tablenotes}\n\\footnotesize\n\\item \\qquad\\qquad Note: * statistically significant results ($\\text{p-value} \\leq 0.05$) using the paired-t-test compared with the best baseline.\n\\end{tablenotes}\n\\label{tab:real-result}  \n\\vspace{-0.4cm}\n\\end{table*}",
            "tab:huawei-result": "\\begin{table}[t]\n\\caption{Performance comparison based on \\textbf{Product}. %The best two results are highlighted in bold.\n}\n\\vspace{-0.3cm}\n\\center\n\\small\n\\renewcommand\\arraystretch{1.0}\n\\setlength{\\tabcolsep}{5.pt}\n\\begin{threeparttable}  \n\\scalebox{0.9}{\n\\begin{tabular}{cccc}\n\\hline\nModels           & CTR AUC (\\%)         & CVR AUC (\\%)     & CTCVR AUC (\\%)       \\\\\n\\hline\nDCN              & 90.763          & 75.691           & 95.254          \\\\\nESMM             & 90.704          & 81.647          & 95.505          \\\\\nDR-JL           & 90.754          & 81.768          & 95.548          \\\\\nMulti\\_IPW       & 90.794          & 81.912          & 95.571          \\\\\nMulti\\_DR        & 90.807          & 81.864          & 95.569          \\\\\nMRDR             & 90.721          & 81.810          & 95.535          \\\\\n\\hline\nDR-BIAS         & \\textbf{90.913} & \\textbf{81.974} & \\textbf{95.633} \\\\\nDR-MSE          & \\textbf{90.825} & \\textbf{82.067} & \\textbf{95.654} \\\\\n\\hline\n\\end{tabular}\n}   \n\\end{threeparttable}    \n\\label{tab:huawei-result}  \n\\vspace{-0.3cm}\n\\end{table}",
            "tab:synthetic-result": "\\begin{table*}[t]\n\\caption{Performance comparison on semi-synthetic datasets based on \\textbf{ML-100k}. %The best two results are highlighted in bold.\n}\n\\vspace{-0.3cm}\n\\center\n\\small\n\\renewcommand\\arraystretch{1.1}\n\\setlength{\\tabcolsep}{5.pt}\n\\begin{threeparttable}  \n\\scalebox{0.9}{\n\\begin{tabular}{c|ccc|ccc}\n\\hline\nMetrics  & \\multicolumn{3}{c|}{AUC}                                                                          & \\multicolumn{3}{c}{Log-loss}                                                                                       \\\\\n\\hline\n$\\rho$   & 0.5                            & 1                              & 2                              & 0.5                            & 1                              & 2                                         \\\\\n\\hline\nNaïve   & 0.7250 $\\pm$ 0.0001          & 0.6731 $\\pm$ 0.0001          & 0.5279 $\\pm$ 0.0070          & 0.3178 $\\pm$ 0.0000          & 0.3343 $\\pm$ 0.0001          & 0.4683 $\\pm$ 0.0179  \\\\\nIPS     & 0.7316 $\\pm$ 0.0001          & 0.6648 $\\pm$ 0.0028          & 0.5263 $\\pm$ 0.0055          & 0.3165 $\\pm$ 0.0001          & 0.3304 $\\pm$ 0.0034          & 0.4789 $\\pm$ 0.0132  \\\\\nDR-JL   & 0.7319 $\\pm$ 0.0004          & 0.6673 $\\pm$ 0.0035          & 0.5703 $\\pm$ 0.0032          & 0.3116 $\\pm$ 0.0002          & 0.3255 $\\pm$ 0.0012          & 0.3607 $\\pm$ 0.0014  \\\\\nMRDR & 0.7335 $\\pm$ 0.0006          & 0.6765 $\\pm$ 0.0021          & 0.5563 $\\pm$ 0.0082          & 0.3067 $\\pm$ 0.0002          & 0.3238 $\\pm$ 0.0006          & 0.3650 $\\pm$ 0.0047     \\\\\n\\hline\nDR-BIAS & \\textbf{0.7349 $\\pm$ 0.0006*} & \\textbf{0.6916 $\\pm$ 0.0009*}          & \\textbf{0.6073 $\\pm$ 0.0054*} & \\textbf{0.3064 $\\pm$ 0.0001*}          & \\textbf{0.3194 $\\pm$ 0.0013*}          & \\textbf{0.3494 $\\pm$ 0.0058}  \\\\\nDR-MSE  & \\textbf{0.7359 $\\pm$ 0.0002*} & \\textbf{0.6928 $\\pm$ 0.0020*} & \\textbf{0.6084 $\\pm$ 0.0168*} & \\textbf{0.3059 $\\pm$ 0.0001*} & \\textbf{0.3193 $\\pm$ 0.0028*} & \\textbf{0.3477 $\\pm$ 0.0084} \\\\\n\\hline\n\\multicolumn{7}{l}{Note: * statistically significant results ($\\text{p-value} \\leq 0.05$) using the paired-t-test compared with the best baseline.}\n\\end{tabular}\n}   \n\\end{threeparttable} \n\\label{tab:synthetic-result}  \n\\vspace{-0.25cm}\n\\end{table*}"
        },
        "figures": {
            "fig:causalmtl4.1": "\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.45\\textwidth]{figures/CausalMTL.pdf}\n    \\vspace{-0.2cm}\n    \\caption{Model architecture of DR-BIAS and DR-MSE for experiments on large-scale industrial dataset. DCN is used as the base model for feature interaction learning for illustration only, and it can be readily replaced with other models such as FM~\\cite{rendle2010factorization}, Wide\\&Deep~\\cite{cheng2016wide} and DeepFM~\\cite{guo2017deepfm}.}\\label{fig:causalmtl4.1}\n    \\vspace{-0.2cm}\n\\end{figure}",
            "fig:DR-MSE": "\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.46\\textwidth]{figures/new.pdf} \n    \\vspace{-0.2cm}\n    \\caption{The proposed tri-level DR-MSE joint learning optimization method updates the $\\lambda_s$ in DR-MSE adaptively in upper level, while the existing bias-variance tradeoff approach uses a fixed $\\lambda_0$. Middle and lower levels are for the joint training between the CTR\\&CVR and error imputation models.}\n    \\label{fig:DR-MSE} \n    \\vspace{-0.2cm}\n\\end{figure}",
            "fig:hyperparameter": "\\begin{figure} \\centering\n\t\\subfigure { \\label{fig:lambda_mse}\n\t\t\\includegraphics[width=0.40\\columnwidth]{figures/labmda_mse_coat_2.pdf}\n\t}\n\t\\hspace{0.15in}\n\t\\subfigure { \\label{fig:sample_ratio}\n\t\t\\includegraphics[width=0.37\\columnwidth]{figures/sample_ratio_coat_2.pdf}\n\t}\n\t\\vspace{-0.2in}\n\t\\caption{The effect of the coefficient $\\lambda$ for balancing bias and variance, and the sample ratio of unclicked events to clicked events on the ranking performance of DR-MSE.}\n\t\\label{fig:hyperparameter}\n\t\\vspace{-0.3cm}\n\\end{figure}"
        }
    }
}