{
    "meta_info": {
        "title": "Debiasing Learning for Membership Inference Attacks Against Recommender  Systems",
        "abstract": "Learned recommender systems may inadvertently leak information about their\ntraining data, leading to privacy violations. We investigate privacy threats\nfaced by recommender systems through the lens of membership inference. In such\nattacks, an adversary aims to infer whether a user's data is used to train the\ntarget recommender. To achieve this, previous work has used a shadow\nrecommender to derive training data for the attack model, and then predicts the\nmembership by calculating difference vectors between users' historical\ninteractions and recommended items. State-of-the-art methods face two\nchallenging problems: (1) training data for the attack model is biased due to\nthe gap between shadow and target recommenders, and (2) hidden states in\nrecommenders are not observational, resulting in inaccurate estimations of\ndifference vectors. To address the above limitations, we propose a Debiasing\nLearning for Membership Inference Attacks against recommender systems (DL-MIA)\nframework that has four main components: (1) a difference vector generator, (2)\na disentangled encoder, (3) a weight estimator, and (4) an attack model. To\nmitigate the gap between recommenders, a variational auto-encoder (VAE) based\ndisentangled encoder is devised to identify recommender invariant and specific\nfeatures. To reduce the estimation bias, we design a weight estimator,\nassigning a truth-level score for each difference vector to indicate estimation\naccuracy. We evaluate DL-MIA against both general recommenders and sequential\nrecommenders on three real-world datasets. Experimental results show that\nDL-MIA effectively alleviates training and estimation biases simultaneously,\nand achieves state-of-the-art attack performance.",
        "author": "Zihan Wang, Na Huang, Fei Sun, Pengjie Ren, Zhumin Chen, Hengliang Luo, Maarten de Rijke, Zhaochun Ren",
        "link": "http://arxiv.org/abs/2206.12401v2",
        "category": [
            "cs.IR",
            "cs.CR",
            "cs.LG"
        ],
        "additionl_info": "Accepted by KDD 2022"
    },
    "latex_extraction": {
        "content": {
            "section 1": {
                "name": "Introduction",
                "content": "\n\\label{sec:Introduction}\nThe success of today's recommender systems is largely attributed to the increased availability of large-scale training data on users' private information (e.g., browsing and purchase history).\nUnfortunately, various studies show that recommender systems are vulnerable to attacks, leading to the leakage of their training data and severe privacy problems~\\citep{DBLP:conf/sp/ShokriSSS17,DBLP:conf/uss/Carlini0EKS19}.\n\nIn this paper, we study privacy threats faced by recommender systems through the lens of membership inference~\\citep{DBLP:conf/sp/ShokriSSS17}.\nSpecifically, \\acp{MIA} against recommender systems enable the adversary to infer whether a user's data is used to train the target recommender~\\citep{DBLP:conf/ccs/ZhangRWRCHZ21}. \nThe main reason for the feasibility of \\ac{MIA} is overfitting, since the learned model tends to perform better on the training data~\\citep{DBLP:conf/ccs/ChenYZF20}.\nRevealing the membership may cause serious harm, and leak sensitive information about specific individuals, such as shopping preferences, social relationships, and location information~\\citep{DBLP:conf/icml/Choquette-ChooT21}.\n\nExisting \\ac{MIA} methods show promising performance in various domains, ranging from biomedical data~\\citep{DBLP:conf/ccs/0001BHM16, DBLP:conf/ndss/Hagestedt0HBT0019,homer2008resolving} to mobility traces~\\citep{DBLP:conf/ndss/PyrgelisTC18}.\nDespite the success, previous \\ac{MIA} methods~\\citep{DBLP:conf/sp/ShokriSSS17,DBLP:conf/ndss/Salem0HBF019,DBLP:conf/csfw/YeomGFJ18, DBLP:conf/sp/NasrSH19, DBLP:conf/icml/Choquette-ChooT21,DBLP:conf/ccs/LiZ21} cannot be directly applied to recommender systems, since they either require knowledge of the target model or use the predicted confidence scores of the classifier.\nIn \\acp{MIA} against recommender systems, the target recommenders are considered inaccessible, and only recommended items, rather than confidence scores, are observational to the adversary~\\citep{DBLP:conf/ccs/ZhangRWRCHZ21}.\nIn fact, this setting is prevalent in real-world scenarios.\n\nIn recent work, \\citet{DBLP:conf/ccs/ZhangRWRCHZ21} infer the membership of the target recommender based on the similarity between users' historical interactions and recommended items. \nThe key idea here is, for users in the training set, their historical interactions tend to be more similar to output items of the recommender.\nSpecifically, a shadow recommender is first established to simulate the target recommender and generate training data for the attack model.\nThen, difference vectors between users' historical interactions and recommended items are computed by factorizing the user-item rating matrix.\nOn this basis, the attack model is able to predict the membership using difference vectors. \nThis framework faces two challenging problems:\n\\begin{enumerate}[leftmargin=*]\n\\item {} \\textbf{Training data for the attack model is biased.}\nAs mentioned above, the algorithm and dataset used by the target recommender are inaccessible~\\citep{DBLP:conf/ccs/ZhangRWRCHZ21}.\nIn that case, the adversary may construct a shadow recommender in a completely distinct manner, resulting in a biased training dataset for the attack model.  \nIn Figure~\\ref{fig:Training data bias.}, feature vectors from the \\ac{MIA} datasets generated by target and shadow recommenders (that use different methods) are visualized by the t-SNE algorithm~\\citep{JMLR:v9:vandermaaten08a}, respectively.\nAnd there exist huge differences between the distributions of features obtained from the shadow recommender (blue) and target recommender (red).\nBesides, as mentioned in~\\citep{DBLP:conf/ccs/ZhangRWRCHZ21}, the attack performance drops dramatically when target and shadow recommenders use different algorithms and datasets.\n\nTo mitigate the gap between recommender systems, we employ a \\ac{VAE} based encoder to disentangle features, and model recommender invariant and specific characteristics using two different distribution families. \n\n\\item {} \\textbf{The estimations of difference vectors are inaccurate.}\nIn this attack, as explained above, the hidden states (e.g., user and item representations) in the target recommender are not available to the adversary. \nAs a result, difference vectors between user historical interactions and recommended items may be estimated inaccurately for the target recommender, leading to incorrect membership predictions.\nFor example, as demonstrated in Figure~\\ref{fig:Estimation bias.},\nthe difference vectors generated by the target recommender (red) and \\ac{MF} (blue) are divergently distributed.\n\nTo reduce the influence of the estimation bias, we develop a weight estimator, and learn a truth-level score for each difference vector to indicate the estimation accuracy during training.\n\\end{enumerate}\n%\\vspace*{1mm}\\noindent\nTo address the above problems, we propose a framework, named \\acfi{DL-MIA}, to simultaneously mitigate training data and estimation biases.\nAs illustrated in Figure~\\ref{fig:An overview.}, \\ac{DL-MIA} has four main components:\n\\begin{enumerate*}[label=(\\roman*)]\n    \\item a difference vector generator,\n    \\item a disentangled encoder,\n    \\item a weight estimator, and\n    \\item an attack model.\n\\end{enumerate*}\nDuring training, to simulate behavior of the target model, a shadow recommender is first constructed and learned on a shadow dataset.\nThen, the generator represents users' history interactions and recommended items by factorizing the user-item rating matrix, and calculates difference vectors.\nTo mitigate the training data bias caused by the gap between target and shadow recommenders, the disentangled encoder is developed, and a \\acf{VAE} based on two distribution families is employed to identify recommender invariant and specific features.\nNext, to reduce the influence of the estimation bias, we establish a weight estimator, and assign a truth-level score for each difference vector.\nFinally, the disentangled and re-weighted difference vectors, as well as membership labels, are input for the \\ac{MLP} based attack model.\nIn addition, to facilitate the model parameter update and weight learning, an alternating training strategy is applied among the disentangled encoder, weight estimator, and attack model.\n\n\n\nOur contributions can be summarized as follows:\n\\begin{enumerate*}[label=(\\roman*)]\n    \\item To the best of our knowledge, ours is the first work to study debiasing learning for membership inference attacks against recommender systems.\n    \\item We develop a \\ac{VAE} based disentangled encoder to mitigate training data bias caused by the gap between shadow and target recommenders.\n    \\item We introduce truth-level scores, and learn the weight estimator with the alternating training strategy to alleviate the estimation bias of difference vectors.\n    \\item Experimental results show that \\ac{DL-MIA} achieves the state-of-the-art attack performance against both general and sequential recommender systems.\n\\end{enumerate*}\n\n% The rest of this paper is organized as follows. \n% In Sec.~\\ref{sec:Related works}, related work is reviewed.\n% In Sec.~\\ref{sec:Method}, our problem formulation and the proposed \\ac{DL-MIA} framework are explained. \n% In Sec.~\\ref{sec:Experiments} and~\\ref{sec:Results}, membership inference attacks against both general and sequential recommenders are evaluated, and detailed analyses are given. Finally, our conclusions are formulated in Sec.~\\ref{sec:Conclusion}.\n% !TEX root = ../main.tex\n\n"
            },
            "section 2": {
                "name": "Related work",
                "content": "\n\\label{sec:Related works}\nWe survey related work along three dimensions: \n\\begin{enumerate*}[label=(\\roman*)]\n\\item membership inference attacks,\n\\item general and sequential recommenders, and\n\\item debiasing learning.\n\\end{enumerate*}\n\n",
                "subsection 2.1": {
                    "name": "Membership inference attacks",
                    "content": "\nRecently, \\acf{MIAs} have achieved pro\\-mising performance in various domains, such as biomedical data~\\citep{DBLP:conf/ccs/0001BHM16, DBLP:conf/ndss/Hagestedt0HBT0019,homer2008resolving} and mobility traces~\\citep{DBLP:conf/ndss/PyrgelisTC18}. \nThe goal of membership inference attacks is to infer the membership of individual training samples for a target model.\n\\citet{DBLP:conf/sp/ShokriSSS17} specify the first membership inference attack against machine learning models.\nThe authors propose a general formulation of membership inference attack against machine learning models, and train multiple shadow models to simulate the target model's behavior.\nIn that case, the training sets for multiple attack models (one for each class) are generated.\n\\citet{DBLP:conf/ndss/Salem0HBF019} further relax several key assumptions from~\\citep{DBLP:conf/sp/ShokriSSS17}, including knowledge of the target model architecture and target dataset distribution.\n\\citet{DBLP:conf/csfw/YeomGFJ18} explore the relationship between attack performance and overfitting, and propose the first decision-based attack.\n\\citet{DBLP:conf/sp/NasrSH19} study membership inference attacks in both black-box and white-box settings.\nInstead of using output scores, several recent membership attacks~\\citep{DBLP:conf/icml/Choquette-ChooT21,DBLP:conf/ccs/LiZ21} assume only predicted hard labels of models are exposed, and demonstrate that label-only exposures are also vulnerable to membership leakage.\nIn addition,~\\citet{DBLP:conf/ccs/ZhangRWRCHZ21} investigate \\ac{MIA} against recommender systems, leveraging the differences between user history behaviors and output items from recommenders.\n\nTo mitigate the attacks, some defense mechanisms, including model stacking~\\citep{DBLP:conf/ndss/Salem0HBF019}, dropout~\\citep{DBLP:conf/ndss/Salem0HBF019}, adversarial training~\\citep{DBLP:conf/ccs/NasrSH18}, differential privacy~\\citep{DBLP:conf/icml/Choquette-ChooT21,DBLP:conf/ccs/LiZ21}, regularization~\\citep{DBLP:conf/icml/Choquette-ChooT21,DBLP:conf/ccs/LiZ21}, and jointly\nmaximizing privacy and prediction accuracy~\\citep{DBLP:conf/ccs/JiaSBZG19}, have been proposed. \nTo protect membership privacy of recommender systems,~\\citet{DBLP:conf/ccs/ZhangRWRCHZ21} design a defense mechanism, named \\emph{Popularity Randomization}, and randomly recommend popular items to non-member users. \n\n\n"
                },
                "subsection 2.2": {
                    "name": "General and sequential recommenders",
                    "content": "\nA generic recommender system aims to model users' preferences from their historical behavior.\nEarly attempts on recommender systems, including \\acf{MF}~\\citep{DBLP:reference/sp/KorenB15,DBLP:journals/computer/KorenBV09,mnih2007probabilistic,DBLP:conf/sac/PolatD05} and item-based neighborhood methods~\\citep{DBLP:journals/internet/LindenSY03,DBLP:conf/kdd/KabburNK13,DBLP:conf/kdd/Koren08,DBLP:conf/www/SarwarKKR01}, typically apply \\acf{CF} on users' interaction histories.\nRecently, deep learning has been used to improve the performance of recommender systems by incorporating with auxiliary information~\\citep{DBLP:conf/recsys/KimPOLY16, DBLP:conf/icdm/KangFWM17}, or replacing the conventional matrix factorization~\\citep{he2017neural,DBLP:conf/www/SedhainMSX15}.\n\nNone of the above methods considers the order in users' behaviors or is designed for sequential recommendation.\nThe earliest work on sequential recommendation, FPMC~\\citep{DBLP:conf/www/RendleFS10}, utilizes Markov chain to capture the transition in behavior sequences.\nTo further enhance the capability of modeling complex behavior, deep learning based models~\\citep{DBLP:journals/corr/HidasiKBT15, DBLP:conf/aaai/ZhouMFPBZZG19,DBLP:conf/icdm/KangM18, DBLP:conf/cikm/SunLWPLOJ19,DBLP:conf/wsdm/TangW18} are devised, including recurrent neural network based~\\citep{DBLP:journals/corr/HidasiKBT15, DBLP:conf/aaai/ZhouMFPBZZG19}, and attention based~\\citep{DBLP:conf/icdm/KangM18, DBLP:conf/cikm/SunLWPLOJ19} methods.\n\n"
                },
                "subsection 2.3": {
                    "name": "Debiasing learning",
                    "content": "\nBias is a critical issue in modern machine learning since trained models often fail to identify the proper representations for the target predictions~\\citep{chu2021learning}.\nTo tackle the limitation, a large number of methods have been proposed to eliminate the biases.\nSpecifically, to address selection bias~\\citep{DBLP:conf/uai/MarlinZRS07} in datasets, propensity score~\\citep{DBLP:conf/icml/SchnabelSSCJ16,DBLP:conf/wsdm/0003ZS021}, ATOP~\\citep{DBLP:conf/kdd/Steck10}, and data imputation~\\citep{DBLP:conf/sigir/Saito20} are utilized.\nBesides, debiasing strategies such as rebalancing~\\citep{DBLP:conf/sigmod/AsudehJS019}, adversarial learning~\\citep{DBLP:conf/wsdm/BeigiMGAN020}, and causal modeling~\\citep{DBLP:conf/nips/KusnerLRS17} are proposed to mitigate\nunfairness~\\citep{DBLP:conf/recsys/LinSMB19} caused by algorithm and unbalanced data.\nIn survey~\\citep{DBLP:journals/corr/abs-2010-03240}, seven types of biases with their definitions and characteristics are summarized and introduced in detail. \nHowever, the work listed does not consider the biases in \\ac{MIA} against recommender systems. \n\n\nIn this paper, we mainly focus on the \\acf{MIA} against recommender systems.\nTo the best of our knowledge, ours is the first work to study debiasing learning for this task.\nThe most closely related work is~\\citep{DBLP:conf/ccs/ZhangRWRCHZ21}.\nHowever, the previous \\ac{MIA} against recommender systems still face two challenging problems:\n\\begin{enumerate*}[label=(\\roman*)]\n    \\item biased attack model training,\n    \\item inaccurate estimations of difference vectors.\n\\end{enumerate*}\nIn our proposed \\ac{DL-MIA}, to mitigate the gap between target and shadow recommenders, the \\ac{VAE} based encoder is employed to model recommender invariant and specific features.\nIn addition, to reduce the impacts of inaccurate estimations, the weight estimator is employed, and truth-level scores for difference vectors are calculated to facilitate the model update.\n% !TEX root = ../main.tex\n\n"
                }
            },
            "section 3": {
                "name": "Method",
                "content": "\n\\label{sec:Method}\nWe first formulate the \\acf{MIA} against recommender systems.\nThen, we give an overview of \\ac{DL-MIA}.\nNext, we explain \\ac{DL-MIA}'s disentangled encoder and weight estimator.\nFinally, the learning algorithm is presented.\n\n",
                "subsection 3.1": {
                    "name": "Problem formulation",
                    "content": "\n\\label{subsec:Problem formulation}\nMembership leakage in recommender systems happens when the adversary aims to determine whether a user's data is used to train the target recommender.\nFormally, given a user's data $\\mathbf{x}$, a trained target recommender $\\mathcal{M}_{\\mathit{target}}$, and external knowledge of the adversary $\\Omega$, a membership inference attack model $\\mathcal{A}$ can be defined as follows:\n\\begin{equation}\n    % \\small\n    \\mathcal{A}:\\mathbf{x}, \\mathcal{M}_{\\mathit{target}},\\Omega \\rightarrow \\{0, 1\\}, \n\\end{equation}\nwhere 0 means $\\mathbf{x}$ is not a member of $\\mathcal{M}_{\\mathit{target}}$'s training dataset while 1 indicates $\\mathbf{x}$ is a member.\nThe attack model $\\mathcal{A}$ is essentially a binary classifier.\n\n\\header{Adversarial knowledge} \nIn this attack, the adversary only has black-box access to the target recommender.\nSpecifically, only the recommendations to users, and users' historical behaviors (e.g., ratings or interaction sequences) are observational. \n% And our threat model consists of the following entities:\n% \\begin{enumerate*}\n%     \\item recommended item  \n% \\end{enumerate*}\nIn that case, as explained in~\\citep{DBLP:conf/ccs/ZhangRWRCHZ21}, the adversary can infer the membership using the similarity between users' historical behaviors and recommended items from the target model.\n\n"
                },
                "subsection 3.2": {
                    "name": "Model overview",
                    "content": "\n\\label{subsec:Model overview}\nFigure~\\ref{fig:An overview.} shows the four main components of \\ac{DL-MIA}: \n\\begin{enumerate*}[label=(\\roman*)]\n    \\item a difference vector generator,\n    \\item a disentangled encoder,\n    \\item a weight estimator, and\n    \\item an attack model.\n\\end{enumerate*}\nIn this section, we give an overview of the \\ac{DL-MIA} framework.\n\n",
                    "subsubsection 3.2.1": {
                        "name": "Difference vector generator",
                        "content": "\nFollowing~\\citet{DBLP:conf/ccs/ZhangRWRCHZ21}, to conduct \\ac{MIA} against the target recommender, a shadow recommender $\\mathcal{M}_{\\mathit{shadow}}$ is established, and difference vectors between users' historical behaviors and recommended items are calculated.\nTo achieve this, we first factorize the user-item rating matrix to obtain item representations $\\mathbf{M}^{\\mathit{item}}$.\nThen, a shadow recommender $\\mathcal{M}_{\\mathit{shadow}}$ is established and trained to simulate the target recommender.\nNext, for the $i$-th user in $\\mathcal{M}_{\\mathit{shadow}}$, we project her/his interacted and recommended items into representations, denoted as $\\mathbf{I}_{\\mathit{shadow}, i}$ and $\\mathbf{R}_{\\mathit{shadow}, i}$, respectively. \nFinally, the difference vector for the $i$-th user is computed as:\n\\begin{equation}\n\\label{eq:difference vector generator}\n% \\small\n    \\mathbf{f}^{\\mathit{diff}}_{\\mathit{shadow}, i} = \\overline{\\mathbf{I}}_{\\mathit{shadow},i} - \\overline{\\mathbf{R}}_{\\mathit{shadow},i},\n\\end{equation}\nwhere $\\overline{\\mathbf{I}}_{\\mathit{shadow},i}$ and $\\overline{\\mathbf{R}}_{\\mathit{shadow},i}$ are the averages of item vectors in $\\mathbf{I}_{\\mathit{shadow}, i}$ and $\\mathbf{R}_{\\mathit{shadow}, i}$, respectively.\n\n\n"
                    },
                    "subsubsection 3.2.2": {
                        "name": "Disentangled encoder",
                        "content": "\nTo mitigate the training data bias, the disentangled encoder aims to identify features invariant and specific to shadow and target recommenders.\nSpecifically, given generated difference vector $\\mathbf{f}^{\\mathit{diff}}$, a \\ac{VAE} based encoder, composing two kinds of prior distributions, is employed to disentangle $\\mathbf{f}^{\\mathit{diff}}$ into the invariant feature $\\mathbf{f}^{\\mathit{inv}}$ and specific feature $\\mathbf{f}^{\\mathit{spe}}$.\nAnd the disentangled difference vector $\\mathbf{f}^{\\mathit{dis}}$ is obtained by concatenating $\\mathbf{f}^{\\mathit{inv}}$ and $\\mathbf{f}^{\\mathit{spe}}$, i.e., $\\mathbf{f}^{\\mathit{dis}} = [\\mathbf{f}^{\\mathit{inv}};\\mathbf{f}^{\\mathit{spe}}]$.\n\n"
                    },
                    "subsubsection 3.2.3": {
                        "name": "Weight estimator",
                        "content": "\nTo further alleviate the influence of the estimation bias, the weight estimator assigns a truth-level score $p$ to each disentangled difference vector $\\mathbf{f}^{\\mathit{dis}}$. \nTo learn $p$, the estimation constraint is constructed.\nMoreover, to facilitate the model update and weight learning, an alternating training scheme is developed. \nIn this way, the disentangled and reweighted difference vector $\\mathbf{f}^{\\mathit{rew}}$ is derived.\n\n"
                    },
                    "subsubsection 3.2.4": {
                        "name": "Attack model",
                        "content": "\nFor membership inference, a generic attack model $\\mathcal{A}$ is essentially a binary classifier with the input of difference vectors.  \nFollowing~\\citet{DBLP:conf/ccs/ZhangRWRCHZ21}, we adopt a \\ac{MLP} with 2 hidden layers for the attack model, i.e., $\\mathcal{A}: \\mathbf{y} = {\\rm MLP}\\left(\\mathbf{f}^{\\mathit{rew}}\\right)$.\nThe output $\\mathbf{y} = (y_{1}, y_{2})$ is a 2-dimensional vector indicating the probability of the user belonging to members ($y_{1}$) or non-members ($y_{2}$).\nAnd the binary cross-entropy loss is used to train the attack model:\n\\begin{equation}\n\\label{eq:BCE}\n% \\small\n    \\mathcal{L}_{\\mathit{BCE}} = -\\sum_{i=1}^{N_{\\mathit{shadow}}} \\left(y_{i}^{*}\\log y_{i, 1} + (1 -y_{i}^{*})\\log y_{i, 2}\\right),\n\\end{equation}\nwhere $y_{i}^{*}$ is the ground truth label for $i$-th user, and $N_{\\mathit{shadow}}$ is the size of training data generated by the shadow recommender.\n\nSince we use the difference vector generator and attack model of the same architecture as the previous work~\\citep{DBLP:conf/ccs/ZhangRWRCHZ21}, only the disentangled encoder and weight estimator are explained in detailed in the following sections.\n\n\n\n"
                    }
                },
                "subsection 3.3": {
                    "name": "Disentangled encoder",
                    "content": "\n\\label{subsec:Disentangled encoder}\nGiven the difference vector $\\mathbf{f}^{\\mathit{diff}}$ from the generator, the disentangled encoder aims to identify recommender invariant and specific features (i.e., $\\mathbf{f}^{\\mathit{inv}}$ and $\\mathbf{f}^{\\mathit{spe}}$).\nTo achieve this, inspired by~\\citep{DBLP:conf/naacl/ChenTWG19}, we construct a \\acf{VAE} using Gaussian and \\ac{vMF} distributions to model recommender invariant and specific characteristics, respectively. \n\nSpecifically, in the encoder, we assume a difference vector is generated by conditioning on two independent latent variables: the recommender invariant feature $\\mathbf{f}^{\\mathit{inv}}$ and the recommender specific feature $\\mathbf{f}^{\\mathit{spe}}$. \nThus, the joint probability in our model is computed as follows:\n\\begin{equation}\n% \\small\n    p_{\\theta}(\\mathbf{f}^{\\mathit{diff}}, \\mathbf{f}^{\\mathit{inv}}, \\mathbf{f}^{\\mathit{spe}}) = p_{\\theta}(\\mathbf{f}^{\\mathit{inv}}) p_{\\theta}(\\mathbf{f}^{\\mathit{spe}}) p_{\\theta}(\\mathbf{f}^{\\mathit{diff}} \\vert \\mathbf{f}^{\\mathit{inv}}, \\mathbf{f}^{\\mathit{spe}}),\n\\end{equation}\nwhere $p_{\\theta}(\\mathbf{f}^{\\mathit{inv}})$ and  $p_{\\theta}(\\mathbf{f}^{\\mathit{spe}})$ are the priors for $\\mathbf{f}^{\\mathit{inv}}$ and $\\mathbf{f}^{\\mathit{spe}}$, respectively.\nAnd $p_{\\theta}(\\mathbf{f}^{\\mathit{diff}} \\vert \\mathbf{f}^{\\mathit{inv}}, \\mathbf{f}^{\\mathit{spe}})$ denotes the likelihood.\nFollowing previous work~\\cite{DBLP:conf/acl/ZhouN17,DBLP:conf/emnlp/ChenTLG18}, we assume a factored posterior probability $q_\\phi(\\mathbf{f}^{\\mathit{inv}},\\mathbf{f}^{\\mathit{spe}}\\vert  \\mathbf{f}^{\\mathit{diff}})=q_\\phi(\\mathbf{f}^{\\mathit{inv}}\\vert \\mathbf{f}^{\\mathit{diff}})q_\\phi(\\mathbf{f}^{\\mathit{spe}}\\vert \\mathbf{f}^{\\mathit{diff}})$. \nTherefore, learning of our encoder maximizes an evidence lower bound on marginal log-likelihood:\n%\n%\\begin{equation}\n% \\small\n\\begin{align}\n    \\mathcal{L}&_{\\mathit{ELBO}} \n    \\nonumber\\\\\n    & \\stackrel{\\text{def}}{=\\joinrel=} \\mathop\\mathbb{E}_{\\substack{\\mathbf{f}^{\\mathit{inv}},\n    \\mathbf{f}^{\\mathit{spe}}}}\\Bigl[\\log p_\\theta\\bigl(\\mathbf{f}^{\\mathit{diff}}\\big\\vert \\mathbf{f}^{\\mathit{spe}},\\mathbf{f}^{\\mathit{inv}}\\bigr)\n    -\\log\\frac{q_\\phi(\\mathbf{f}^{\\mathit{spe}}\\vert  \\mathbf{f}^{\\mathit{diff}})}{p_\\theta(f^{\\mathit{spe}})} \n    \\nonumber \\\\\n    & \\qquad \\qquad\\,\\, -\\log\\frac{q_\\phi(\\mathbf{f}^{\\mathit{inv}}\\vert  \\mathbf{f}^{\\mathit{diff}})}{p_\\theta(\\mathbf{f}^{\\mathit{inv}})}\\Bigr]\n    \\label{eq:ELBO}\\\\\n     & =\\!\\! \\mathop\\mathbb{E}_{\\substack{\\mathbf{f}^{\\mathit{inv}},\n    \\mathbf{f}^{\\mathit{spe}}}}\\! \\bigl[\\log p_\\theta(\\mathbf{f}^{\\mathit{diff}}\\vert  \\mathbf{f}^{\\mathit{spe}},\\mathbf{f}^{\\mathit{inv}})\\bigr] \n    {-}\\kld(q_\\phi(\\mathbf{f}^{\\mathit{spe}}\\vert  \\mathbf{f}^{\\mathit{diff}})\\Vert p_\\theta(\\mathbf{f}^{\\mathit{spe}}))  \n    \\nonumber \\\\\n    &\\quad -\\kld\\bigl(q_\\phi(\\mathbf{f}^{\\mathit{inv}}\\vert  \\mathbf{f}^{\\mathit{diff}})\\Vert p_\\theta(\\mathbf{f}^{\\mathit{inv}})\\bigr),\n    \\nonumber\n\\end{align}\n%\\end{equation}\n%\nwhere $\\mathbf{f}^{\\mathit{inv}}\\sim q_\\phi(\\mathbf{f}^{\\mathit{inv}}\\vert  \\mathbf{f}^{\\mathit{diff}})$ and $    \\mathbf{f}^{\\mathit{spe}}\\sim q_\\phi(\\mathbf{f}^{\\mathit{spe}}\\vert  \\mathbf{f}^{\\mathit{diff}})$.\n$q_\\phi(\\mathbf{f}^{\\mathit{inv}}\\vert  \\mathbf{f}^{\\mathit{diff}})$ and $q_\\phi(\\mathbf{f}^{\\mathit{spe}}\\vert  \\mathbf{f}^{\\mathit{diff}})$ are the posteriors.\n$\\kld(p \\Vert q)$ denotes the KL divergence between the distribution $p$ and $q$.\nIn our disentangled encoder, two distribution families, i.e., the \\ac{vMF} and Gaussian distributions, are used to define the posteriors. \nFurther details on the parameterization are provided below.\n\n",
                    "subsubsection 3.3.1": {
                        "name": "Gaussian Distribution.",
                        "content": "\n%We leverage a Gaussian distribution~\\citep{DBLP:conf/aaai/QianFWC21} to capture recommender invariant features.\nWe assume that $q_\\phi(\\mathbf{f}^{\\mathit{inv}}\\vert  \\mathbf{f}^{\\mathit{diff}})$ follows a Gaussian distribution~\\citep{DBLP:conf/aaai/QianFWC21} $\\mathcal{N}(\\mu_\\beta(\\mathbf{f}^{\\mathit{diff}}),\\text{diag}(\\sigma_\\beta(\\mathbf{f}^{\\mathit{diff}})))$, and that the prior $p_\\theta(\\mathbf{f}^{\\mathit{inv}})$ follows the standard distribution $\\mathcal{N}(0,I)$, where $I$ is an identity matrix.\nIn our encoder, we only consider a diagonal covariance matrix, and thus the KL divergence term $\\kld(q_\\phi(\\mathbf{f}^{\\mathit{inv}}\\vert  \\mathbf{f}^{\\mathit{diff}})\\Vert p_\\theta(\\mathbf{f}^{\\mathit{inv}}))$ can also be obtained as follows:\n%\n\\begin{equation}\n% \\small\n    \\frac{1}{2}\\Bigl(-\\sum_i\\log\\sigma_{\\beta i} + \\sum_i\\sigma_{\\beta i} + \\sum_i{\\mu_{\\beta i} ^2} - d\\Bigr).\n\\end{equation}\n\n\n"
                    },
                    "subsubsection 3.3.2": {
                        "name": "vMF Distribution.",
                        "content": " \nvMF can be recognized as a Gaussian distribution on a hypersphere with two parameters, $\\mu$, and $\\kappa$. \n$\\mu\\in\\mathbb{R}^m$ is a normalized vector (i.e., $\\Vert\\mu\\Vert_2=1$ ) and defines the mean direction. \n$\\kappa\\in\\mathbb{R}_{\\geq 0}$ denotes the concentration parameter analogous to the variance in a Gaussian distribution. \n\nIn our encoder, we assume that $q_\\phi(\\mathbf{f}^{\\mathit{spe}}\\vert  \\mathbf{f}^{\\mathit{diff}})$ follows a \\ac{vMF} distribution $\\vmf(\\mu_\\alpha(\\mathbf{f}^{\\mathit{diff}}),\\kappa_\\alpha(\\mathbf{f}^{\\mathit{diff}}))$ and the prior $p_\\theta(\\mathbf{f}^{\\mathit{spe}})$ follows the uniform distribution $\\vmf(\\cdot,0)$.\nThe $\\kld(q_\\phi(\\mathbf{f}^{\\mathit{spe}}\\vert \\mathbf{f}^{\\mathit{diff}})\\Vert p_\\theta(\\mathbf{f}^{\\mathit{spe}}))$ term in $\\mathcal{L}_{ELBO}$ can then be computed in closed form:\n%\n\\begin{equation}\n\\begin{aligned}\n    &\\kappa_\\alpha\\frac{\\mathcal{I}_{m/2}(\\kappa_\\alpha)}{\\mathcal{I}_{m/2-1}(\\kappa_\\alpha)} + (m/2 - 1)\\log\\kappa_\\alpha - \n    (m/2)\\log(2\\pi) \\\\\n    &- \\log\\mathcal{I}_{m/2-1}(\\kappa_\\alpha)+\n    \\frac{m}{2}\\log\\pi+\\log 2-\\log\\Gamma(m/2),\n\\end{aligned}\n\\end{equation}\n%\nwhere $\\mathcal{I}_v$ is the modified Bessel function of the first kind at order $v$ and $\\Gamma(\\cdot)$ is the Gamma function. \nFollowing~\\citet{DBLP:conf/uai/DavidsonFCKT18}, we use an acceptance-rejection scheme to sample from the vMF distribution.\n\n"
                    },
                    "subsubsection 3.3.3": {
                        "name": "Reconstruction error",
                        "content": "\nWe assume the conditional likelihood distribution $p_\\theta(\\mathbf{f}^{\\mathit{diff}}\\vert  \\mathbf{f}^{\\mathit{spe}},\\mathbf{f}^{\\mathit{inv}})$ follows $\\mathcal{N}(f([\\mathbf{f}^{\\mathit{inv}};\\mathbf{f}^{\\mathit{spe}}]), \\mathbf{I})$, where a \\ac{MLP} with 3 hidden layers is adopted for $f(\\cdot)$. \nThus, the reconstruction error (the first term) in $\\mathcal{L}_{ELBO}$ can be rewritten as:\n\\begin{equation}\n% \\small\n    \\mathop\\mathbb{E}_{\\substack{\\mathbf{f}^{\\mathit{inv}},\n    \\mathbf{f}^{\\mathit{spe}}}}\\left[-\\frac{1}{2}\\left\\lVert f([\\mathbf{f}^{\\mathit{inv}};\\mathbf{f}^{\\mathit{spe}}]) - \\mathbf{f}^{\\mathit{diff}}\\right\\rVert ^{2}\\right].\n\\end{equation}\nDuring training, we use a linear layer to produce $\\mu_{\\beta}$, $\\delta_{\\beta}$, $\\mu_\\alpha$, and $\\kappa_{\\alpha}$.\nThe difference vectors from both shadow and target recommenders are disentangled by the encoder.\nNote that membership labels in the target recommender are not exposed to \\ac{DL-MIA}.\nThrough the encoder, the disentangled difference vector, i.e., $\\mathbf{f}^{\\mathit{dis}} = [\\mathbf{f}^{\\mathit{inv}};\\mathbf{f}^{\\mathit{spe}}]$, is obtained to mitigate the gap between shadow and target recommender.\n\n\n"
                    }
                },
                "subsection 3.4": {
                    "name": "Weight estimator",
                    "content": "\n\\label{subsec:Weight estimator}\nGiven $\\mathbf{f}^{\\mathit{dis}}$ from the disentangled encoder, the weight estimator aims to alleviate the estimation bias of difference vectors.\nSpecifically, we introduce the truth-level score to indicate the estimation accuracy.\nThen, we establish the estimation constraint, and assign a truth-level score for each difference vector.\nMoreover, to update model parameters and learn scores simultaneously, an alternating training strategy among the disentangled encoder, weight estimator, and attack model is adopted.\n\n",
                    "subsubsection 3.4.1": {
                        "name": "Truth-level score",
                        "content": "\nAs mentioned in Sec.~\\ref{subsec:Problem formulation}, the hidden states in the target recommender, including item representations, are not observational to the adversary.\nAs a result, difference vectors for recommenders may be computed inaccurately by \\ac{MF} in the generator.\nIn the estimator, we write $\\mathbf{f'}$ for the ground truth difference vector, and define the truth-level score $p$ for $\\mathbf{f}^{\\mathit{dis}}$ as follows:\n\\begin{equation}\n% \\small\n\\label{eq:truth-level score}\n    p = \\frac{\\delta \\left(\\mathcal{A}\\left(\\mathbf{f'}\\right), y^{*}\\right)}{\\delta (\\mathcal{A}(\\mathbf{f}^{\\mathit{dis}}), y^{*})},\n\\end{equation}\nwhere $\\mathcal{A}(\\cdot)$ denotes the attack model, and $y^{*}$ is the membership label. $\\delta(\\cdot)$ is the error measure, for which we adopt the binary cross-entropy loss.\n\n"
                    },
                    "subsubsection 3.4.2": {
                        "name": "Alternating training",
                        "content": "\nIn the estimator, the truth-level score serves as the weighting parameter for the estimation bias.\nAfter debiasing by the truth-level score, the biased estimation should be equal to the unbiased estimation.\nMotivated by this, we can rewrite Eq.~\\ref{eq:truth-level score} as follows:\n%\n\\begin{equation}\n% \\small\n    p \\cdot\\delta \\left(\\mathcal{A}\\left(\\mathbf{f}^{\\mathit{dis}}\\right), y^{*}\\right) = \\delta \\left(\\mathcal{A}\\left(\\mathbf{f'}\\right), y^{*}\\right).\n\\end{equation}\n%\nOn this basis, to compute the truth-level score $p$, the estimation constraint is established:\n\\begin{equation}\n\\label{eq:estimation constraint}\n\\begin{split}\n   &\\mathcal{L}_{\\mathit{estimate}}  = {}\\\\\n   &\\sum_{j}{\\lambda_{j} {\\cdot} \\!\\sum_{i=1}^{N_{j}}{\\! \\left\\lVert p_{i,j} {\\cdot} \\delta \\left(\\mathcal{A}\\left(\\mathbf{f}_{i,j}^{\\mathit{dis}}\\right), y_{i,j}^{*}\\right) - \\delta \\left(\\mathcal{A}\\left(\\!\\mathbf{f'}_{i,j}\\right), y_{i.j}^{*}\\right)\\right\\rVert^{2}}},\n   \\end{split}\n\\end{equation}\nwhere $j \\in \\{shadow, target\\}$, and $\\lambda_{j}$ is the weight for the shadow or target recommender.\nHere, we set $\\lambda_{j} = \\frac{1}{N_{j}}$, where\n$N_{\\mathit{shadow}}$ and $N_{\\mathit{target}}$ are the size of training dataset generated by shadow recommender, and the test dataset for the target recommender, respectively.\n\nHowever, membership labels $\\mathbf{y}^{*}_{\\mathit{target}}$ of the target recommender and the ground truth difference vector $\\mathbf{f}'$ cannot be obtained directly.\nTo address this issue and facilitate model update, we develop an alternating training strategy among the disentangled encoder, attack model, and weight estimator.\nSpecifically, the re-weighted loss for the disentangled encoder and attack model is defined as follows:\n%\n\\begin{align}\n    \\mathcal{L}_{\\mathit{reweight}} &= \\mathcal{L}'_{BCE} + \\mathcal{L}'_{ELBO},\n    \\label{eq:reweight loss} \\\\\n    \\mathcal{L}'_{BCE} &= -\\!\\!\\sum_{i=1}^{N_{\\mathit{shadow}}}\\!\\! \\mathbf{w}_{\\mathit{shadow}, i}(\\mathbf{p}) \\cdot \\left(y_{i}^{*}\\log y_{i, 1} + (1 -y_{i}^{*})\\log y_{i, 2}\\right),\n    \\nonumber\\\\\n    \\mathcal{L}'_{\\mathit{ELBO}} &= -\\sum_{j}{\\sum_{i}^{N_{j}}{\\mathbf{w}_{j,i}(\\mathbf{p})\\cdot \\mathcal{L}_{{ELBO,j,i}}}},\\quad j\\in \\{\\mathit{shadow}, \\mathit{target}\\},\n    \\nonumber\n\\end{align}\n%\n\\if0\n\\begin{equation}\n\\label{eq:reweight loss}\n% \\small\n\\begin{aligned}\n    \\mathcal{L}_{\\mathit{reweight}} &= \\mathcal{L}'_{BCE} + \\mathcal{L}'_{ELBO},\\\\\n    \\mathcal{L}'_{BCE} &= -\\!\\!\\sum_{i=1}^{N_{\\mathit{shadow}}}\\!\\! \\mathbf{w}_{\\mathit{shadow}, i}(\\mathbf{p}) \\cdot \\left(y_{i}^{*}\\log y_{i, 1} + (1 -y_{i}^{*})\\log y_{i, 2}\\right),\\\\\n    \\mathcal{L}'_{\\mathit{ELBO}} &= -\\sum_{j}{\\sum_{i}^{N_{j}}{\\mathbf{w}_{j,i}(\\mathbf{p})\\cdot \\mathcal{L}_{{ELBO,j,i}}}},\\quad j\\in \\{\\mathit{shadow}, \\mathit{target}\\},\n\\end{aligned}\n\\end{equation}\n\\fi\nwhere $\\mathbf{w}_{\\mathit{shadow}}(\\mathbf{p})$ and $\\mathbf{w}_{\\mathit{target}}(\\mathbf{p})$ are the data sample weights for shadow and target recommenders, obtained by applying a linear layer on the current truth-level scores $\\mathbf{p}$.\nWe compute the re-weighted and disentangled difference vector $\\mathbf{f}^{\\mathit{rew}} = \\left[\\mathbf{f}'^{\\mathit{inv}};\\mathbf{f}'^{\\mathit{spe}}\\right]$ by minimizing $\\mathcal{L}_{\\mathit{reweight}}$, where $\\mathbf{f}'^{\\mathit{inv}}$ and $\\mathbf{f}'^{\\mathit{spe}}$ are the re-weighted invariant and specific vectors.\nMeanwhile, the trained attack model is able to predict membership labels for the target recommender, i.e., $y_{\\mathit{target}}$.\nNext, we approximate $\\mathbf{f}'$ and $y^{*}_{\\mathit{target}}$ by $\\mathbf{f}^{\\mathit{rew}}$ and $y_{\\mathit{target}}$, and minimize $\\mathcal{L}_{\\mathit{estimate}}$ to refine the current truth-level scores $\\mathbf{p}$.\nIn this way, $\\mathcal{L}_{\\mathit{reweight}}$ and $\\mathcal{L}_{\\mathit{estimate}}$ are optimized in an alternating fashion.\n\n"
                    }
                },
                "subsection 3.5": {
                    "name": "Learning algorithm",
                    "content": "\n\\label{subsec:Learning algorithm}\nThe training process of \\ac{DL-MIA} contains two stages:\n\\begin{enumerate*}[label=(\\roman*)]\n    \\item \\textbf{Pretraining}. We first pretrain the disentangled encoder and attack model jointly by optimizing $\\mathcal{L}_{\\mathit{BCE}}$ (Eq.~\\ref{eq:BCE}) and $\\mathcal{L}_{\\mathit{ELBO}}$ (Eq.~\\ref{eq:ELBO}).\n    In this stage, the disentangled difference vector $\\mathbf{f}^{\\mathit{dis}}$ is computed, and inputted into the attack model for learning.\n    \\item \\textbf{Alternating training}. After obtaining the disentangled difference vectors, we adopt the alternating training strategy to reduce the estimation bias. \n    Specifically, the re-weighted loss $\\mathcal{L}_{\\mathit{reweight}}$ and the estimation constraint $\\mathcal{L}_{\\mathit{estimate}}$ are minimized iteratively.\n    In such manner, the re-weighted difference vector $\\mathbf{f}^{\\mathit{rew}}$ is derived, and then used by the attack model to conduct membership inference on the target recommender.\n\\end{enumerate*}\nSec.~\\ref{subsec:learning algorithm and training} gives the detailed training algorithm of \\ac{DL-MIA}.\n% !TEX root = ../main.tex\n\n"
                }
            },
            "section 4": {
                "name": "Experiments",
                "content": "\n\\label{sec:Experiments}\n\n\\textbf{Research questions.}\nWe aim to answer the following research questions:\n\\begin{enumerate*}[label=(RQ\\arabic*),leftmargin=*]\n\\item Does \\ac{DL-MIA} outperform the state-of-the-art attack methods? \nIs \\ac{DL-MIA} able to generalize to the sequential recommendation? (Sec.~\\ref{subsec:MIA against RS} and ~\\ref{subsec:MIA against SR}) \n\\item How does the disentangled encoder and weight estimator contribute to the performance? (Sec.~\\ref{subsec:ablation study})\n\\item What is the influence of the difference vector generator and defense mechanism? (Sec.~\\ref{subsec:Influence of difference vector generator} and~\\ref{subsec:Influence of defense mechanism})\n\\item Is \\ac{DL-MIA} able to identify features invariant and specific to shadow and target recommenders, and alleviate the estimation bias? (Sec.~\\ref{subsec:Case studies})\n\\end{enumerate*}\n\n\\header{Datasets}\nFollowing~\\citet{DBLP:conf/ccs/ZhangRWRCHZ21}, we evaluate the attack performance on two real-world datasets, MovieLens~\\citep{DBLP:journals/tiis/HarperK16} and Amazon~\\citep{DBLP:conf/sigir/McAuleyTSH15}.\nMovieLens is a widely used benchmark dataset for evaluating collaborative filtering algorithms. We use the version (MovieLens-1M) that includes 1 million user ratings for both general and sequential recommenders.\nAmazon is a series of datasets, consisting of large corpora of product reviews crawled from Amazon.com. \nTop-level product categories on Amazon are treated as separate datasets. \nSimilar to~\\citet{DBLP:conf/ccs/ZhangRWRCHZ21}, we consider ``Digital Music'' for general recommenders, while ``Beauty'' is used for sequential recommenders, since the number of the interacting users per item in ``Digital Music'' is extremely low (less than 2). \nTable~\\ref{tab:Statistics of processed datasets for recommender systems.} summarizes the statistics of datasets.\n\nSimilar to~\\citep{DBLP:conf/ccs/ZhangRWRCHZ21}, we further divide each dataset into three disjoint subsets. i.e., a shadow dataset, a target dataset, and a dataset for difference vector generation. \nWe filter the target and shadow datasets to make sure the dataset for difference vector generation contains all the items.\nThen, target and shadow datasets are both randomly separated into two disjoint parts for members and non-members, respectively.\nFor general recommenders, we remove users with less than 20 interactions.\nFor sequential recommenders, we filter out users and items with less than 5 interaction records.\n\n\n\n\\header{Recommender systems}\nFollowing~\\citep{DBLP:conf/ccs/ZhangRWRCHZ21}, we evaluate membership inference attacks against three general recommenders:\n\\begin{enumerate*}[label=(\\roman*)]\n    \\item \\acf{ItemBase}~\\citep{DBLP:conf/www/SarwarKKR01},\n    \\item \\acf{LFM} \\citep{DBLP:conf/sac/PolatD05}, and \n    \\item \\acf{NCF}~\\citep{he2017neural}.\n\\end{enumerate*}\nTo investigate the generality of our proposed model, we also implement attack models on three sequential recommendation methods in our experiments, including GRU4Rec~\\citep{DBLP:journals/corr/HidasiKBT15}, Caser~\\citep{DBLP:conf/wsdm/TangW18},  and BERT4Rec~\\citep{DBLP:conf/cikm/SunLWPLOJ19}.\n\n\n\\header{Experimental settings}\nTable~\\ref{tab:Notations for different settings.} shows the notation for our experimental settings. \nNote that not all possible settings are listed due to space limitations.\nIn the experiments, there are two kinds of combinations (i.e., 2-letter and 4-letter combinations) for experimental settings. \nFor the 2-letter combinations, the first letter indicates the dataset, and the second letter denotes the recommendation algorithm. \nFor example, for general recommenders, ``AI'' denotes that the recommender is implemented by ItemBase and trained on Amazon Digital Music.\nFor the 4-letter combinations, the first two letters represent the dataset and algorithm used by the shadow recommender, and the last two letters denote the dataset and algorithm used by the target recommender. \nFor instance, for sequential recommenders, ``ABMC'' means the adversary establishes a shadow recommender using BERT4REC on Amazon Beauty to attack a target recommender using Caser on MovieLens-1M.\n% \\sun{More details can be found in Tab.~\\ref{tab:Notations for different settings.}.}\n\n\\header{Baseline}\n\\label{subsec:baselines}\nWe compare the proposed \\ac{DL-MIA} with the biased baseline (Biased)~\\citep{DBLP:conf/ccs/ZhangRWRCHZ21}, which is the first work studying the membership inference attack against recommender systems.\nPrevious \\ac{MIA} methods~\\citep{DBLP:conf/sp/ShokriSSS17,DBLP:conf/ndss/Salem0HBF019,DBLP:conf/csfw/YeomGFJ18, DBLP:conf/sp/NasrSH19, DBLP:conf/icml/Choquette-ChooT21,DBLP:conf/ccs/LiZ21} are not considered in our experiments, since they cannot be directly applied to recommender systems.\n\n\n\\header{Evaluation metric}\nWe adopt the area under the ROC curve (AUC) as the evaluation metric. \nAUC signifies the probability that the positive sample’s score is higher than the negative sample’s score, illustrating the classification model’s ability to rank samples.\nFor example, if the attack model infers the membership with random guessing, the AUC is close to 0.5.\n\n\\header{Implementation details}\n\\label{subsec:implementation details}\nFor the attack model, we build a \\ac{MLP} with 2 hidden layers. \nAnd the first layer has 32 units and the second layer has 8 units. \nWe employ the ReLU activation function, and use the softmax function as the output layer.\nFor optimizers, we employ Adam with a learning rate of 0.001 for the disentangled encoder and SGD with a learning rate of 0.01 and a momentum of 0.7 for the attack model. \nDuring training, we first pretrain the attack model and the disentangled encoder jointly for 200 epochs. \nThen, truth-level scores and model parameters are alternatively updated for every 10 epochs. \nThe whole alternative training is conducted for 100 epochs.\nFollowing~\\citep{DBLP:conf/ccs/ZhangRWRCHZ21}, we consider the top 100 recommendations for members, and recommend the most popular items to non-members.  \nTable~\\ref{tab:Parameter settings of different recommender systems} lists detailed parameter settings.\n% !TEX root = ../main.tex\n\n"
            },
            "section 5": {
                "name": "Experimental Results",
                "content": "\n\\label{sec:Results}\nFor RQ1, we evaluate the attack performance of our proposed \\ac{DL-MIA} over general and sequential recommender systems.\n\n",
                "subsection 5.1": {
                    "name": "Attack performance over general recommenders (RQ1)",
                    "content": "\nFigure~\\ref{fig:heatmap_RS} shows the experimental outcomes for the attack performance over general recommender systems.\nBased on the experimental results, we have the following observations:\n\\begin{enumerate*}[label=(\\roman*)]\n    \\item Membership inference attack against general recommender systems is challenging, and for the biased baseline, AUC scores are less than 0.7 in most settings (more than 60\\%).\n    In contrast, our proposed \\ac{DL-MIA} is able to effectively infer the membership of the target recommenders, and AUC scores are over 0.8 for more than 80\\% experimental settings.\n    \\item The proposed \\ac{DL-MIA} consistently outperforms the biased baseline in all the settings.\n    For example, for the ``MLAI'' setting, the AUC score of \\ac{DL-MIA} is 0.980, while that of the biased baseline attack is 0.608.\n    That is, identifying features invariant and specific to recommenders, and computing the truth-level scores for difference vectors substantially enhance the attack performance.\n    \\item Similar to the conclusions mentioned in~\\citep{DBLP:conf/ccs/ZhangRWRCHZ21}, with knowledge of the algorithm and dataset distribution used by the target recommender, the adversary is capable of conducting a strong attack, and AUC scores of \\ac{DL-MIA} at the back-diagonal in Figure~\\ref{fig:heatmap_RS} are the highest in most cases.   \n\\end{enumerate*}\nIn summary, the proposed \\ac{DL-MIA} can effectively infer the membership for the target recommender. \nIdentifying recommender invariant and specific features, as well as considering estimation accuracy of difference vectors, are beneficial for the membership inference attack.\n\n\\label{subsec:MIA against RS}\n\n\n\n"
                },
                "subsection 5.2": {
                    "name": "Attack performance over sequential recommenders (RQ1)",
                    "content": "\n\\label{subsec:MIA against SR}\nTo investigate the generality of \\ac{DL-MIA}, we report the performance of membership inference attacks against sequential recommenders.\nBased on the results in Figure~\\ref{fig:heatmap_SR}, we arrive at the following insights:\n\\begin{enumerate*}[label=(\\roman*)]\n    \\item Even with ordered user historical behaviors, \\ac{DL-MIA} can still accurately calculate the difference vectors, and infer  membership. \n    The AUC scores of \\ac{DL-MIA} are over 0.8 for more than 80\\% settings.\n    \\item \\ac{DL-MIA} surpasses the biased baseline, and achieves better attack performance over both general and sequential recommenders, demonstrating the effectiveness and strong generalizability of our proposed framework.\n\\end{enumerate*}\nIn summary, the \\ac{DL-MIA} framework cannot only effectively conduct membership inference attacks against general recommenders, but also attains the best AUC scores over sequential recommenders.\n% !TEX root = ../main.tex\n\n"
                }
            },
            "section 6": {
                "name": "Analysis",
                "content": "\n\\label{sec:Analysis}\nIn this section, we take a closer look at \\ac{DL-MIA} to analyze its performance.\nWe examine how the disentangled encoder, and the weight estimator contribute to the performance.\nThe influence of the difference vector generator and defense mechanism is also investigated.\nIn addition, we conduct case studies to study whether \\ac{DL-MIA} is able to recognize recommender invariant and specific features, and mitigate the estimation bias.\n\n\n",
                "subsection 6.1": {
                    "name": "Ablation studies (RQ2)",
                    "content": "\nWe conduct ablation studies over both general and sequential recommenders.\nThe results are shown in Table~\\ref{tab:Ablation studies over recommenders.}.\nAUC scores are adopted here to evaluate the attack performance.\nWhen only employing the difference vector generator and attack model, our framework is reduced to the biased baseline.\nIn that case, AUC scores over all the settings suffer a dramatic drop.\nIn the ``-Reweight'' setting, the disentangled encoder and attack model are trained jointly whereas the alternative training is removed.\nCompared to the biased baseline, identifying features invariant and specific to shadow and target recommenders considerably alleviates the training data bias, and AUC scores are consistently improved over both general and sequential recommenders.\nMeanwhile, \\ac{DL-MIA} further enhances the attack performance by reducing the estimation bias of difference vectors.\nIn a nutshell, both the disentangled encoder and weight estimator contribute to the improvements in attack performance.\n\nIn Tabe~\\ref{tab:Ablation studies over recommenders.}, we also consider two model variants, \\ac{DL-MIA} ($\\beta$-VAE) and \\ac{DL-MIA} (FactorVAE), with two widely-used \\ac{VAE} models $\\beta$-VAE~\\citep{DBLP:conf/iclr/HigginsMPBGBML17} and FactorVAE~\\citep{DBLP:conf/icml/KimM18}, respectively.\nBased on the results in Table~\\ref{tab:Ablation studies over recommenders.}, we observe that \\ac{DL-MIA} ($\\beta$-VAE), and \\ac{DL-MIA} (FactorVAE) both achieve a similar attack performance as \\ac{DL-MIA}.\nThat is, even with a different \\ac{VAE} based encoder, our proposed framework is still able to perform effective membership inference.\n\n\\label{subsec:ablation study}\n\n\n\n"
                },
                "subsection 6.2": {
                    "name": "Influence of difference vector generator (RQ3)",
                    "content": "\n\\label{subsec:Influence of difference vector generator}\nTable~\\ref{tab:Influence of the difference vector generator over general recommender systems.} shows the attack performance (AUC) with two kinds of difference vector generators, ``MF'' and ``BERT''.\n``MF'' generates the difference vectors by factorizing user-item matrices (explained in Sec.~\\ref{subsec:Model overview}). ``BERT'' employs the tiny-sized BERT~\\citep{DBLP:conf/naacl/DevlinCLT19} to embed item descriptions, and takes the [CLS] vectors as item representations.\nSince some item descriptions are missing, we do not consider experimental settings using the Amazon Digital Music dataset.\nBased on the results in Table~\\ref{tab:Influence of the difference vector generator over general recommender systems.}, we find that \\ac{DL-MIA} performs better than the biased baseline over both generators, indicating the effectiveness of our framework.\n\n\n\n"
                },
                "subsection 6.3": {
                    "name": "Influence of defense mechanism (RQ3)",
                    "content": "\n\\label{subsec:Influence of defense mechanism}\nFollowing~\\citet{DBLP:conf/ccs/ZhangRWRCHZ21}, we investigate the influence of defense mechanism, and apply the countermeasure named \\emph{Popularity Randomization} to the attack frameworks. \nFigure~\\ref{fig:Influence of the defense mechanism.} shows the attack performance (AUC) before and after deploying the defense mechanism.\nWith the defense mechanism, the attack performance for both the biased baseline and \\ac{DL-MIA} consistently decreases over all the settings.\nMeanwhile, compared to the biased baseline, our proposed \\ac{DL-MIA} achieves higher AUC scores, and shows a stronger robustness to the countermeasure.\n\n\n\n"
                },
                "subsection 6.4": {
                    "name": "Case studies (RQ4)",
                    "content": "\n\\label{subsec:Case studies}\nFigure~\\ref{fig:case studies} shows visualization results of the ``ANML'' setting for the general recommender system by t-SNE~\\citep{JMLR:v9:vandermaaten08a}.\nPoints in Figure~\\ref{fig:invariant.} and Figure~\\ref{fig:specific.} stand for the recommender invariant and specific features, respectively.\nWe can see that invariant features from the shadow recommender (red) and target recommender (blue) are distributed similarly, whereas specific features are scattered divergently.\nThat is, by employing the disentangled encoder, \\ac{DL-MIA} is able to mitigate the gap between recommenders.\n\nIn addition, Figure~\\ref{fig:difference vectors before debiasing.} and Figure~\\ref{fig:difference vectors after debiasing.} demonstrate the visualization results of difference vectors before and after debiasing, respectively.\nBased on the results, we conclude that \\ac{DL-MIA} effectively reduce the gap between difference vectors generated by the attack model (red) and recommender (blue), and alleviate the influence of the estimation bias.\n\n\n\n\n% !TEX root = ../main.tex\n\n"
                }
            },
            "section 7": {
                "name": "Conclusion and future work",
                "content": "\n\\label{sec:Conclusion}\nIn this paper, we investigate the membership inference attack against recommender systems.\nPreviously published methods faces two challenging problems:\n\\begin{enumerate*}[label=(\\roman*)]\n    \\item the biased attack model training caused by the gap between target and shadow recommenders,\n    \\item and inaccurate estimation of difference vectors since hidden states in recommenders are inaccessible.\n\\end{enumerate*}\nTo handle these problems, we propose a novel framework named \\ac{DL-MIA}.\nTo mitigate the gap between target and shadow recommenders, the \\ac{VAE} based encoder is devised to identify recommender invariant and specific features.\nAnd to alleviate the estimation bias, the weight estimator is constructed, and truth-level scores for difference vectors are computed to facilitate the model update.\nWe evaluate \\ac{DL-MIA} against both general recommenders and sequential recommenders on two real-world datasets.\nExperimental results demonstrate that the \\ac{DL-MIA} framework is able to effectively alleviate training and estimation biases, and shows a strong generality.\n\nIn future work, we intend to incorporate more kinds of disentangled methods and explore other types of biases in the membership inference attack against recommender systems.\n\n\n\n\\begin{acks}\nThis work was supported by the National Key R\\&D Program of China with grant No. 2020YFB1406704, the Natural Science Foundation of China (61902219, 61972234, 62072279, 62102234), the Natural Science Foundation of Shandong Province (ZR2021QF129), the Key Scientific and Technological Innovation Program of Shandong Province (2019JZZY010129), Shandong University multidisciplinary research and innovation team of young scholars (No. 2020QNQT017), Meituan, the Hybrid Intelligence Center, a 10-year program funded by the Dutch Ministry of Education, Culture and Science through the Netherlands Organisation for Scientific Research, \\url{https://hybrid-intelligence-centre.nl}. \nAll content represents the opinion of the authors, which is not necessarily shared or endorsed by their respective employers and/or sponsors.\n\\end{acks}\n\n\\clearpage\n\\bibliographystyle{ACM-Reference-Format}\n\\balance\n\\bibliography{main}\n\n\\clearpage\n\\appendix\n"
            },
            "section 8": {
                "name": "Appendix",
                "content": "\n\n",
                "subsection 8.1": {
                    "name": "DL-MIA",
                    "content": "\n\\label{subsec:learning algorithm and training}\n\nAlgorithm~\\ref{algorithm:Training algorithm} gives the detailed learning algorithm of \\ac{DL-MIA}.\nSpecifically, given the target recommender, we first establish the shadow recommender $\\mathcal{M}_{\\mathit{shadow}}$, calculate the difference vector $\\mathbf{f}^{\\mathit{diff}}$ by \\ac{MF}, and initialize model parameter $\\mathbf{\\Theta}$ for the disentangled encoder and attack model (line 1--3).\nThen, to mitigate the gap between the shadow and target recommenders, we train the disentangled encoder and attack model by jointly optimizing $\\mathcal{L}_{\\mathit{BCE}}$ and $\\mathcal{L}_{\\mathit{ELBO}}$ (line 4--7).\nIn this way, the disentangled difference vector $\\mathbf{f}^{\\mathit{dis}}$ is computed.\nNext, to further reduce the influence of the estimation bias, an alternating training strategy is adopted.\nBy determining data sample weights $\\mathbf{w}$ using the current $\\mathbf{p}$, we are able to minimize the reweighted loss $\\mathcal{L}_{\\mathit{reweight}}$, and obtain the reweighted difference vector $\\mathbf{f}^{\\mathit{rew}}$ (line 10--15).\nWith input of $\\mathbf{f}^{\\mathit{rew}}$ and $y_{target}$, the current $p$ can be refined using the estimation constraint $\\mathcal{L}_{estimation}$ (line 16--19).  \nDuring the alternating training process, $\\mathcal{L}_{\\mathit{reweight}}$ and $\\mathcal{L}_{\\mathit{estimation}}$ are optimized iteratively (line 9--20).\n\n\n\n\\begin{algorithm}[!h]\n    \\caption{Training algorithm of \\ac{DL-MIA}.}\n    \\label{algorithm:Training algorithm}      \n    \\begin{algorithmic}[1] \n    \\Require The trained shadow recommender $\\mathcal{M}_{\\mathit{shadow}}$; the difference vector $\\mathbf{f}^{\\mathit{diff}}$ from the generator; randomly initialized truth-level scores $\\mathbf{p}$; the number of inner-loop epochs $\\mathit{epoch}_{\\mathit{in}}$ and outer-loop epochs $\\mathit{epoch}_{\\mathit{out}}$ for the alternating training; the number of epochs for pretraining $\\mathit{epoch}_{\\mathit{pre}}$; parameters $\\mathbf{\\Theta}$ for the disentangled encoder and attack model.\n    \\Ensure The disentangled and reweighted difference vector $\\mathbf{f}^{\\mathit{rew}}$ and trained attack model $\\mathcal{A}$;\n    \\State Establish the shadow recommender $\\mathcal{M}_{\\mathit{shadow}}$;\n    \\State Calculate the difference vector $\\mathbf{f}^{\\mathit{diff}}$ (Eq.~\\ref{eq:difference vector generator});\n    \\State Randomly initialize model parameters $\\mathbf{\\Theta}$;\n    \\While{$i\\leq\\mathit{epoch}_{\\mathit{pre}}$ }\n    \\State Calculate the disentangled difference vector $\\mathbf{f}^{\\mathit{dis}}$;\n    \\State Input $\\mathbf{f}^{\\mathit{dis}}$ into the attack model $\\mathcal{A}$ for predicting $y_{shadow}$;\n    \\State Update $\\mathbf{\\Theta}$ by jointly optimizing $\\mathcal{L}_{\\mathit{BCE}}$ and $\\mathcal{L}_{\\mathit{ELBO}}$ (Eq.~\\ref{eq:BCE} and~\\ref{eq:ELBO});\n    \\EndWhile\n    \n    \\While{$i\\leq\\mathit{epoch}_{\\mathit{out}}$}\n    \\State Compute the data sample weights $\\mathbf{w}$ using the current $\\mathbf{p}$;\n    \\While{$j\\leq\\mathit{epoch}_{\\mathit{in}}$}\n    \\State Calculate the reweighted feature vector $\\mathbf{f}^{\\mathit{rew}}$;\n    \\State Input $\\mathbf{f}^{\\mathit{rew}}$ into $\\mathcal{A}$ for predicting $y_{target}$ and $y_{shadow}$;\n    \\State Update $\\mathbf{\\Theta}$ by minizing $\\mathcal{L}_{\\mathit{reweight}}$ (Eq.~\\ref{eq:reweight loss});\n    \\EndWhile\n    \\State Input $\\mathbf{f}^{\\mathit{rew}}$ and $y_{target}$ into the weight estimator;\n    \\While{$k\\leq\\mathit{epoch}_{\\mathit{in}}$}\n    \\State Refine the current truth-level scores $\\mathbf{p}$ by optimizing $\\mathcal{L}_{\\mathit{estimation}}$ (Eq.~\\ref{eq:truth-level score} and~\\ref{eq:estimation constraint});\n    \\EndWhile\n    \\EndWhile\n    \\end{algorithmic}\n    \\end{algorithm}\n\n"
                },
                "subsection 8.2": {
                    "name": "Notation",
                    "content": "\n\\label{subsec:Notations for different settings}\nTable~\\ref{tab:Notations for different settings.} shows the notation we use for different experimental settings.\n\n\n"
                },
                "subsection 8.3": {
                    "name": "Implementation details",
                    "content": "\n\\label{subsec:implementation details for baselines}\nTable~\\ref{tab:Parameter settings of different recommender systems} demonstrate the parameter settings of different recommenders in our experiments. \nNote that, we do not give the parameter setting of  \\ac{ItemBase}~\\citep{DBLP:conf/www/SarwarKKR01} since it is based on the statistical method.\n\n"
                },
                "subsection 8.4": {
                    "name": "Reproducibility",
                    "content": "\nTo facilitate the reproducibility of the results reported in this work, the\ncode and data used in this work is available at \\url{https://github.com/WZH-NLP/DL-MIA-KDD-2022}.\n\n\n\n\n\n\n"
                }
            }
        },
        "tables": {
            "tab:Statistics of processed datasets for recommender systems.": "\\begin{table}[t]\n%   \\small\n  \\centering\n  \\caption{Statistics of datasets. \\#Users, \\#Items, and \\#Interactions denote the number of users, items, and user-item interactions, respectively.}\n  \\label{tab:Statistics of processed datasets for recommender systems.}\n  % \\scalebox{0.9}{\n  \\begin{tabular}{l rrr}\n  \\toprule\n    Dataset & \\#Users & \\#Items & \\#Interactions  \\\\\n  \\midrule\n    MovieLens-1M & 6,040 & 3,706 & 1,000,209 \\\\\n    Amazon Digital Music & 840,372 & 456,992 & 1,584,082  \\\\\n    Amazon Beauty & 1,210,271 & 249,274 & 2,023,070  \\\\\n  \\bottomrule\n\\end{tabular}\n\\vspace*{-.5\\baselineskip}\n  % }\n\\end{table}",
            "tab:Ablation studies over recommenders.": "\\begin{table}\n\t\\centering\n\t\\caption{Ablation studies over general and sequential recommenders. \\ldots ($\\beta$-VAE) and \\ldots (FactorVAE) are two model-variants of DL-MIA with widely-used VAE models.}\n \t\\setlength{\\tabcolsep}{0.5mm}\n%    \\begin{adjustbox}{max width=\\linewidth}\n\t\\begin{tabular}{l cccc cccc}\n\t\\toprule\n\t\\multirow{2}{*}{Model} &\\multicolumn{4}{c}{General} &\\multicolumn{4}{c}{Sequential}\\\\\n\t\\cmidrule(lr){2-5} \\cmidrule(lr){6-9}\n\t & \\rotatebox[origin=c]{60}{AIMI} & \n\t \\rotatebox[origin=c]{60}{ALML}  & \n\t \\rotatebox[origin=c]{60}{AIML} & \n\t \\rotatebox[origin=c]{60}{ALMI} \t& \n\t \\rotatebox[origin=c]{60}{AGMG} & \n\t \\rotatebox[origin=c]{60}{MGAG}  & \n\t \\rotatebox[origin=c]{60}{MGMC} & \n\t \\rotatebox[origin=c]{60}{AGMC}\n\t  \\\\ \\midrule\n    DL-MIA & \\textbf{0.999} & \\textbf{0.995} & 0.993 & 0.998 & \\textbf{0.999} & \\textbf{0.986}  & 0.992 & \\textbf{0.999} \\\\ \n\t\\midrule\n\t-Reweight & 0.553 & 0.518 & 0.531 & 0.526 & 0.723 & 0.915 & 0.936 & 0.707\\\\\n\tBiased~\\citep{DBLP:conf/ccs/ZhangRWRCHZ21}     & 0.525 & 0.510  & 0.524 & 0.510 & 0.711 & 0.908  & 0.922 & 0.704 \\\\ \n\t\\midrule\n\t\\ldots ($\\beta$-VAE)        & 0.920 & 0.993   & 0.995 & 0.996 & 0.999 & 0.983 &0.993 & 0.996\\\\\n\t\\ldots (FactorVAE)  & 0.999 & 0.987 &\\textbf{0.999} &\\textbf{0.999}   & 0.999 & 0.982  &\\textbf{0.994}       & 0.999\\\\\n\t\\bottomrule\n\t\\end{tabular}\n%\t\\end{adjustbox}\n\t\\label{tab:Ablation studies over recommenders.}\n  \\vspace*{-.5\\baselineskip}\t\n\\end{table}",
            "tab:Influence of the difference vector generator over general recommender systems.": "\\begin{table}\n\t\\centering\n\t\\caption{Influence of the difference vector generator over general and sequential recommenders. ``Gen.'' is short for ``Generator.''}\n\t\\setlength{\\tabcolsep}{0.5mm}\n\t\\begin{tabular}{l l ccccc cccc}\n\t\t\\toprule\n\t\\multirow{4}{*}{\\rotatebox[origin=c]{90}{Gen.} } &  &\\multicolumn{4}{c}{General} &\\multicolumn{4}{c}{Sequential}\\\\\n\t\\cmidrule(lr){3-6} \\cmidrule(lr){7-10}\n\t\t & Model & \n\t\t\\rotatebox[origin=c]{60}{MIMI} & \n\t\t\\rotatebox[origin=c]{60}{MIMN} & \n\t\t\\rotatebox[origin=c]{60}{MLMI} & \n\t\t\\rotatebox[origin=c]{60}{MNML} & \n\t\t\\rotatebox[origin=c]{60}{AGMG} & \n\t\t\\rotatebox[origin=c]{60}{MGAG} & \n\t\t\\rotatebox[origin=c]{60}{MGMC} & \n\t\t\\rotatebox[origin=c]{60}{AGMC} \\\\\n\t\t\\midrule\n\t\t\\multirow{2}{*}{\\rotatebox[origin=c]{90}{\\ac{MF}}}\n\t\t& Biased~\\citep{DBLP:conf/ccs/ZhangRWRCHZ21} & 0.998 & 0.706 & 0.931 & 0.914  & 0.711 & 0.908  & 0.922 & 0.704 \\\\\n\t\t& DL-MIA & \\textbf{1.000}  & \\textbf{0.959} & \\textbf{0.997} & \\textbf{0.987}  & \\textbf{0.999} & \\textbf{0.986}  & \\textbf{0.992} & \\textbf{0.999} \\\\ \n\t\t\\midrule\n\t\t\\multirow{2}{*}{\\rotatebox[origin=c]{90}{BERT}}\n\t\t& Biased~\\citep{DBLP:conf/ccs/ZhangRWRCHZ21} \n\t\t         & 0.979 & 0.575 & 0.505 & 0.706   & 0.517 & 0.584  & 0.922 & 0.621\\\\\n\t\t& DL-MIA & \\textbf{0.980} & \\textbf{0.830} & \\textbf{0.971} & \\textbf{0.770} &\\textbf{0.873}  &\\textbf{0.863}   & \\textbf{0.979}  &\\textbf{0.870} \\\\ \n\t\t\\bottomrule\n\t\\end{tabular}\n\t\\label{tab:Influence of the difference vector generator over general recommender systems.}\n\\end{table}",
            "tab:Parameter settings of different recommender systems": "\\begin{table}\n    \\small\n\t\\centering\n\t\\caption{Parameter settings of different recommender systems.}\n\t\\begin{tabular}{l p{6.3cm}}\n\t\t\\toprule\n\t\t\\textbf{Baseline} & \\textbf{Settings}\\\\\n\t\t\\midrule\n\t\t\\multirow{1}{*}{ItemBase}\n\t\t& -- \\\\ \n\t\t\\midrule\n\t\tLFM\n\t\t& Embed.-size=100, \n\t\tSGD optimizer, \n\t\tlearning-rate=0.01 \\\\ \n\t\t\\midrule\n\t\t\\multirow{2}{*}{NCF}\n\t\t& Embed.-size=8, batch-size=256,   \n\t\tAdam optimizer, \n\t\thidden-size=64, 32, 16, \n\t\tlearning-rate=0.001\\\\ \n\t\t\\midrule\n\t\t\\multirow{2}{*}{BERT4REC}\n\t\t& batch-size=128,   \n\t\tAdam optimizer, dropout=0.1\n\t\thidden-size=256, \n\t\tlearning-rate=0.001\\\\ \n\t\t\\midrule\n\t\t\\multirow{2}{*}{Caser}\n\t\t& Embed.-size=50, batch-size=512,   \n\t\tAdam optimizer, dropout=0.5\n\t\tlearning-rate=0.001\\\\ \n\t\t\\midrule\n\t\t\\multirow{2}{*}{GRU4REC}\n\t\t& batch-size=50,  \n\t\tAdagrad optimizer, dropout=0.5, \n\t\thidden-size=100, \n\t\tlearning-rate=0.01, momentum=0\\\\\n\t\t\\bottomrule\n\t\\end{tabular}\n\t\\label{tab:Parameter settings of different recommender systems}\n\\end{table}"
        },
        "figures": {
            "fig:Motivation": "\\begin{figure}\n  \\centering\n  \\subfigure[Training data bias.]{\n    \\includegraphics[clip,trim=10mm 5mm 0mm 0mm,width=0.485\\linewidth]{figures/bias_shadow_target_AIMI.pdf}\\label{fig:Training data bias.}}\n  \\subfigure[Estimation bias.]{\\includegraphics[clip,trim=10mm 5mm 0mm 0mm,width=0.485\\linewidth]{figures/sAN_gap.pdf}\\label{fig:Estimation bias.}}\n    \\caption{Visualization results for the training data and estimation biases. (a) The bias between the \\ac{MIA} datasets generated by the shadow recommender (blue) and target recommender (red). (b) The bias between difference vectors generated using \\ac{MF} (blue) and hidden states in the recommender (red).}\n  \\label{fig:Motivation}\n  \\vspace*{-.5\\baselineskip}\n\\end{figure}",
            "fig:An overview.": "\\begin{figure*}[t]\n    \\centering\n    \\includegraphics[width=0.92\\linewidth]{figures/Basic-framework-MIA.pdf}\n    \\caption{An overview of \\ac{DL-MIA}. \\ac{DL-MIA} has four main components: a difference vector generator, a disentangled encoder, a weight estimator, and an attack model.}\n    \\label{fig:An overview.}\n  \\vspace*{-.5\\baselineskip}    \n\\end{figure*}",
            "fig:heatmap": "\\begin{figure}\n  \\centering\n  \\subfigure[General recommenders]{\n    \\includegraphics[clip, trim=0mm 1mm 0mm 0mm, width=\\linewidth]{figures/heatmap_RS.pdf}\n    \\label{fig:heatmap_RS}}\n    \\vspace*{-2mm}\n    \\\\\n  \\subfigure[Sequential recommenders]{\n    \\label{fig:heatmap_SR}\n    \\includegraphics[width=\\linewidth]{figures/heatmap_SR.pdf}\n    \\label{fig:heatmap_SR}}\n    \\vspace*{-2mm}    \n  \\caption{Attack performance (AUC) over general recommenders (a) and sequential recommenders (b).}\n  \\label{fig:heatmap}\n  \\vspace*{-.5\\baselineskip}\n\\end{figure}",
            "fig:Influence of the defense mechanism.": "\\begin{figure}\n  \\centering\n    \\includegraphics[width=\\linewidth]{figures/defense.pdf}\n    \\caption{Influence of the defense mechanism. ``Biased-defense'' and ``DL-MIA-defense'' denote Biased~\\citep{DBLP:conf/ccs/ZhangRWRCHZ21} and \\ac{DL-MIA} with the defense mechanism, respectively.}\n  \\label{fig:Influence of the defense mechanism.}\n\\end{figure}",
            "fig:case studies": "\\begin{figure}\n  \\centering\n  \\subfigure[Invariant feature $\\mathbf{f}^{\\mathit{inv}}$]{\n    \\label{fig:invariant.}\n    \\includegraphics[clip, trim=0mm 5mm 0mm 0mm 0mm, width=0.485\\linewidth]{figures/debias_shadow_target_invariant_ANML.png}}\n  \\subfigure[Specific feature $\\mathbf{f}^{\\mathit{spe}}$]{\n    \\label{fig:specific.}\n    \\includegraphics[clip, trim=0mm 5mm 0mm 0mm 0mm, width=0.485\\linewidth]{figures/debias_shadow_target_specific_ANML.png}}\n  \\subfigure[Biased difference vector]{\n    \\label{fig:difference vectors before debiasing.}\n    \\includegraphics[clip, trim=0mm 5mm 0mm 0mm 0mm, width=0.485\\linewidth]{figures/sAN_gap_Biased.png}}\n   \\subfigure[Debiased difference vector]{\n    \\label{fig:difference vectors after debiasing.}\n    \\includegraphics[clip, trim=0mm 5mm 0mm 0mm 0mm, width=0.485\\linewidth]{figures/sAN_gap_Debiased.png}}\n  \\caption{Visualization results of the ``ANML'' setting for the general recommender.}\n  \\label{fig:case studies}\n\\end{figure}"
        },
        "equations": {
            "eq:1": "\\begin{equation}\n    % \\small\n    \\mathcal{A}:\\mathbf{x}, \\mathcal{M}_{\\mathit{target}},\\Omega \\rightarrow \\{0, 1\\}, \n\\end{equation}",
            "eq:2": "\\begin{equation}\n\\label{eq:difference vector generator}\n% \\small\n    \\mathbf{f}^{\\mathit{diff}}_{\\mathit{shadow}, i} = \\overline{\\mathbf{I}}_{\\mathit{shadow},i} - \\overline{\\mathbf{R}}_{\\mathit{shadow},i},\n\\end{equation}",
            "eq:3": "\\begin{equation}\n\\label{eq:BCE}\n% \\small\n    \\mathcal{L}_{\\mathit{BCE}} = -\\sum_{i=1}^{N_{\\mathit{shadow}}} \\left(y_{i}^{*}\\log y_{i, 1} + (1 -y_{i}^{*})\\log y_{i, 2}\\right),\n\\end{equation}",
            "eq:4": "\\begin{equation}\n% \\small\n    p_{\\theta}(\\mathbf{f}^{\\mathit{diff}}, \\mathbf{f}^{\\mathit{inv}}, \\mathbf{f}^{\\mathit{spe}}) = p_{\\theta}(\\mathbf{f}^{\\mathit{inv}}) p_{\\theta}(\\mathbf{f}^{\\mathit{spe}}) p_{\\theta}(\\mathbf{f}^{\\mathit{diff}} \\vert \\mathbf{f}^{\\mathit{inv}}, \\mathbf{f}^{\\mathit{spe}}),\n\\end{equation}",
            "eq:5": "\\begin{align}\n    \\mathcal{L}&_{\\mathit{ELBO}} \n    \\nonumber\\\\\n    & \\stackrel{\\text{def}}{=\\joinrel=} \\mathop\\mathbb{E}_{\\substack{\\mathbf{f}^{\\mathit{inv}},\n    \\mathbf{f}^{\\mathit{spe}}}}\\Bigl[\\log p_\\theta\\bigl(\\mathbf{f}^{\\mathit{diff}}\\big\\vert \\mathbf{f}^{\\mathit{spe}},\\mathbf{f}^{\\mathit{inv}}\\bigr)\n    -\\log\\frac{q_\\phi(\\mathbf{f}^{\\mathit{spe}}\\vert  \\mathbf{f}^{\\mathit{diff}})}{p_\\theta(f^{\\mathit{spe}})} \n    \\nonumber \\\\\n    & \\qquad \\qquad\\,\\, -\\log\\frac{q_\\phi(\\mathbf{f}^{\\mathit{inv}}\\vert  \\mathbf{f}^{\\mathit{diff}})}{p_\\theta(\\mathbf{f}^{\\mathit{inv}})}\\Bigr]\n    \\label{eq:ELBO}\\\\\n     & =\\!\\! \\mathop\\mathbb{E}_{\\substack{\\mathbf{f}^{\\mathit{inv}},\n    \\mathbf{f}^{\\mathit{spe}}}}\\! \\bigl[\\log p_\\theta(\\mathbf{f}^{\\mathit{diff}}\\vert  \\mathbf{f}^{\\mathit{spe}},\\mathbf{f}^{\\mathit{inv}})\\bigr] \n    {-}\\kld(q_\\phi(\\mathbf{f}^{\\mathit{spe}}\\vert  \\mathbf{f}^{\\mathit{diff}})\\Vert p_\\theta(\\mathbf{f}^{\\mathit{spe}}))  \n    \\nonumber \\\\\n    &\\quad -\\kld\\bigl(q_\\phi(\\mathbf{f}^{\\mathit{inv}}\\vert  \\mathbf{f}^{\\mathit{diff}})\\Vert p_\\theta(\\mathbf{f}^{\\mathit{inv}})\\bigr),\n    \\nonumber\n\\end{align}",
            "eq:6": "\\begin{equation}\n% \\small\n    \\frac{1}{2}\\Bigl(-\\sum_i\\log\\sigma_{\\beta i} + \\sum_i\\sigma_{\\beta i} + \\sum_i{\\mu_{\\beta i} ^2} - d\\Bigr).\n\\end{equation}",
            "eq:7": "\\begin{equation}\n\\begin{aligned}\n    &\\kappa_\\alpha\\frac{\\mathcal{I}_{m/2}(\\kappa_\\alpha)}{\\mathcal{I}_{m/2-1}(\\kappa_\\alpha)} + (m/2 - 1)\\log\\kappa_\\alpha - \n    (m/2)\\log(2\\pi) \\\\\n    &- \\log\\mathcal{I}_{m/2-1}(\\kappa_\\alpha)+\n    \\frac{m}{2}\\log\\pi+\\log 2-\\log\\Gamma(m/2),\n\\end{aligned}\n\\end{equation}",
            "eq:8": "\\begin{equation}\n% \\small\n    \\mathop\\mathbb{E}_{\\substack{\\mathbf{f}^{\\mathit{inv}},\n    \\mathbf{f}^{\\mathit{spe}}}}\\left[-\\frac{1}{2}\\left\\lVert f([\\mathbf{f}^{\\mathit{inv}};\\mathbf{f}^{\\mathit{spe}}]) - \\mathbf{f}^{\\mathit{diff}}\\right\\rVert ^{2}\\right].\n\\end{equation}",
            "eq:9": "\\begin{equation}\n% \\small\n\\label{eq:truth-level score}\n    p = \\frac{\\delta \\left(\\mathcal{A}\\left(\\mathbf{f'}\\right), y^{*}\\right)}{\\delta (\\mathcal{A}(\\mathbf{f}^{\\mathit{dis}}), y^{*})},\n\\end{equation}",
            "eq:10": "\\begin{equation}\n% \\small\n    p \\cdot\\delta \\left(\\mathcal{A}\\left(\\mathbf{f}^{\\mathit{dis}}\\right), y^{*}\\right) = \\delta \\left(\\mathcal{A}\\left(\\mathbf{f'}\\right), y^{*}\\right).\n\\end{equation}",
            "eq:11": "\\begin{equation}\n\\label{eq:estimation constraint}\n\\begin{split}\n   &\\mathcal{L}_{\\mathit{estimate}}  = {}\\\\\n   &\\sum_{j}{\\lambda_{j} {\\cdot} \\!\\sum_{i=1}^{N_{j}}{\\! \\left\\lVert p_{i,j} {\\cdot} \\delta \\left(\\mathcal{A}\\left(\\mathbf{f}_{i,j}^{\\mathit{dis}}\\right), y_{i,j}^{*}\\right) - \\delta \\left(\\mathcal{A}\\left(\\!\\mathbf{f'}_{i,j}\\right), y_{i.j}^{*}\\right)\\right\\rVert^{2}}},\n   \\end{split}\n\\end{equation}",
            "eq:12": "\\begin{align}\n    \\mathcal{L}_{\\mathit{reweight}} &= \\mathcal{L}'_{BCE} + \\mathcal{L}'_{ELBO},\n    \\label{eq:reweight loss} \\\\\n    \\mathcal{L}'_{BCE} &= -\\!\\!\\sum_{i=1}^{N_{\\mathit{shadow}}}\\!\\! \\mathbf{w}_{\\mathit{shadow}, i}(\\mathbf{p}) \\cdot \\left(y_{i}^{*}\\log y_{i, 1} + (1 -y_{i}^{*})\\log y_{i, 2}\\right),\n    \\nonumber\\\\\n    \\mathcal{L}'_{\\mathit{ELBO}} &= -\\sum_{j}{\\sum_{i}^{N_{j}}{\\mathbf{w}_{j,i}(\\mathbf{p})\\cdot \\mathcal{L}_{{ELBO,j,i}}}},\\quad j\\in \\{\\mathit{shadow}, \\mathit{target}\\},\n    \\nonumber\n\\end{align}",
            "eq:13": "\\begin{equation}\n\\label{eq:reweight loss}\n% \\small\n\\begin{aligned}\n    \\mathcal{L}_{\\mathit{reweight}} &= \\mathcal{L}'_{BCE} + \\mathcal{L}'_{ELBO},\\\\\n    \\mathcal{L}'_{BCE} &= -\\!\\!\\sum_{i=1}^{N_{\\mathit{shadow}}}\\!\\! \\mathbf{w}_{\\mathit{shadow}, i}(\\mathbf{p}) \\cdot \\left(y_{i}^{*}\\log y_{i, 1} + (1 -y_{i}^{*})\\log y_{i, 2}\\right),\\\\\n    \\mathcal{L}'_{\\mathit{ELBO}} &= -\\sum_{j}{\\sum_{i}^{N_{j}}{\\mathbf{w}_{j,i}(\\mathbf{p})\\cdot \\mathcal{L}_{{ELBO,j,i}}}},\\quad j\\in \\{\\mathit{shadow}, \\mathit{target}\\},\n\\end{aligned}\n\\end{equation}"
        },
        "git_link": "https://github.com/WZH-NLP/DL-MIA-KDD-2022"
    }
}