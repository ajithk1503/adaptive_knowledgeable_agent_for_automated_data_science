{
    "meta_info": {
        "title": "PAC-Wrap: Semi-Supervised PAC Anomaly Detection",
        "abstract": "Anomaly detection is essential for preventing hazardous outcomes for\nsafety-critical applications like autonomous driving. Given their\nsafety-criticality, these applications benefit from provable bounds on various\nerrors in anomaly detection. To achieve this goal in the semi-supervised\nsetting, we propose to provide Probably Approximately Correct (PAC) guarantees\non the false negative and false positive detection rates for anomaly detection\nalgorithms. Our method (PAC-Wrap) can wrap around virtually any existing\nsemi-supervised and unsupervised anomaly detection method, endowing it with\nrigorous guarantees. Our experiments with various anomaly detectors and\ndatasets indicate that PAC-Wrap is broadly effective.",
        "author": "Shuo Li, Xiayan Ji, Edgar Dobriban, Oleg Sokolsky, Insup Lee",
        "link": "http://arxiv.org/abs/2205.10798v2",
        "category": [
            "cs.LG",
            "math.ST",
            "stat.ML",
            "stat.TH"
        ],
        "additionl_info": "Accepted by SIGKDD 2022"
    },
    "latex_extraction": {
        "content": {
            "section 1": {
                "name": "Conservativeness",
                "content": "\n\\label{conservativeness}\nThe conservativeness over \\textit{thyroid} dataset could be explained by the fact that the calibration set size (432) is significantly smaller than that of synthetic dataset (4000). Since a smaller calibration set is less representative of the true distribution, Equation \\eqref{eqn:algorithm} will construct a possibly over-conservative prediction set to satisfy the confidence constraint, which leads to the violation rate being much lower than the confidence constraint. Moreover, a small calibration set, which is unrepresentative of the true distribution, could also contribute to a high violation rate. \n% Since small calibration sets might not be sufficiently representative, PAC prediction sets constructed on small calibration sets are more likely to violate the error constraint on the true distribution. \nThe fact that the calibration set is small could have the opposite effects on the violation rates. On the \\textit{thyroid} dataset, the effect of Equation \\eqref{eqn:algorithm} is dominant. As a result, the constructed PAC prediction sets are relatively conservative.\n\n"
            },
            "section 2": {
                "name": "th_cfp",
                "content": "\n\\label{pf_cfp}\nWe replace the original prediction set $L_{\\Ds}(C)$ with $L_{\\Ds_{\\text{nm}}}(\\cfp)$, setting $\\epsilon=\\epsilon_{\\text{fp}}, \\delta=\\delta_{\\text{fp}}$, and construct the false positive PAC prediction set via solving \\eqref{eqn:algorithm}. By Theorem \\ref{thm:pred_set}, we have\n$\n    \\Prob_{Z \\sim \\Ds^n_{\\text{nm}}}[ L_{\\Ds_{\\text{nm}}}(\\cfp) \\le \\epsilon_{\\text{fp}} ] \\ge 1 - \\delta_{\\text{fp}}. \n$\nTherefore, $\\cfp$ is $(\\epsilon_{\\text{fp}}, \\delta_{\\text{fp}})$-correct. $\\square$\n\n"
            },
            "section 3": {
                "name": "th_fp",
                "content": "\n\\label{pf_fp}\nWe have\n\\begin{equation*} \\label{eq_th_fp}\n\\begin{split}\n&\\Pr(\\hat y =1 \\mid y=0) = \\mathbb{E}_{x\\mid y=0}[\\mathbbm{1}(\\hat y = 1)] \\\\\n&= \\mathbb{E}_{x\\mid y=0}[\\mathbbm{1}(0 \\notin \\cfp(x))]\n= \\mathbb{E}_{x \\mid y=0}[\\mathbbm{1}( y \\notin C_{\\hat\\tau_{\\fp}}(x)]\\\\\n&= \\mathbb{E}_{x \\mid y=0}[\\ell_{\\fp}^{01}(x)] \n=  L_{D_{\\text{nm}}}(\\cfp).\n\\end{split}\n\\end{equation*} By Corollary \\ref{th_cfp}, we have\n\\begin{equation*}\n \\Prob_{Z \\sim D_{\\text{nm}}^n}[ L_{D_{\\text{nm}}}(\\cfp) \\le \\epsilon_\\fp ] \\ge 1 - \\delta_{\\fp}.   \n\\end{equation*} Since $\\Pr(\\hat y =1 \\mid y=0)=L_{D_{\\text{nm}}}(\\cfp)$, we find\n\\begin{equation*}\n    \\Prob_{Z \\sim D_{\\text{nm}}^n}[ \\Prob(\\hat y =1 \\mid y=0) \\le \\epsilon_\\fp ] \\ge 1 - \\delta_{\\fp}. \\square \n\\end{equation*}\n\n"
            },
            "section 4": {
                "name": "th_cfn",
                "content": "\n\\label{pf_cfn}\nWe replace the original prediction set $L_{\\Ds}(C)$ with $L_{\\Ds_{\\text{ano}}}(\\cfn)$, setting $\\epsilon=\\epsilon_{\\text{fn}}, \\delta=\\delta_{\\text{fn}}$, and construct the false positive PAC prediction set via solving \\eqref{eqn:algorithm}. By Theorem \\ref{thm:pred_set}, we have\n$\\Prob_{Z \\sim \\Ds^n_{\\text{ano}}}[ L_{\\Ds_{\\text{ano}}}(\\cfn) \\le \\epsilon_{\\text{fn}} ] \\ge 1 - \\delta_{\\text{fn}}$. \nTherefore, $\\cfn$ is $(\\epsilon_{\\text{fn}}, \\delta_{\\text{fn}})$-correct.  $\\square$\n\n"
            },
            "section 5": {
                "name": "th_fn",
                "content": "\n\\label{pf_fn}\nWe have\n\\begin{equation*} \\label{eq_th_fn}\n\\begin{split}\n&\\Pr(\\hat y =0 \\mid y=1) = \\mathbb{E}_{x\\mid y=1}[\\mathbbm{1}(\\hat y = 0)] \\\\\n&= \\mathbb{E}_{x\\mid y=1}[\\mathbbm{1}(1 \\notin \\cfn(x))]\n= \\mathbb{E}_{x \\mid y=1}[\\mathbbm{1}( y \\notin C_{\\hat\\tau_{\\fn}}(x)]\\\\\n&= \\mathbb{E}_{x \\mid y=1}[\\ell_{\\fn}^{01}(x)] \n=  L_{D_{\\text{ano}}}(\\cfn).\n\\end{split}\n\\end{equation*} By Corollary \\ref{th_cfn}, we have\n\\begin{equation*}\n \\Prob_{Z \\sim D_{\\text{ano}}^n}[ L_{D_{\\text{ano}}}(\\cfn) \\le \\epsilon_\\fn ] \\ge 1 - \\delta_{\\fn}.   \n\\end{equation*} Since $\\Pr(\\hat y =0 \\mid y=1)=L_{D_{ano}}(\\cfn)$, we find\n\\begin{equation*}\n    \\Prob_{Z \\sim D_{\\text{ano}}^n}[ \\Prob(\\hat y =0 \\mid y=1) \\le \\epsilon_\\fn ] \\ge 1 - \\delta_{\\fn}. \\square \n\\end{equation*}\n\n"
            },
            "section 6": {
                "name": "th_cad",
                "content": "\n\\label{pf_ad}\nWhen $d(x) \\geq \\tfn$ and $d(x) \\geq \\tfp$, by Equation \\eqref{y_hat}, $\\hat y = 1$. In this case, the error rate $\\epsilon_{\\text{ad}}$ equals to the FPR. (The anomaly detector's prediction is correct when $y=1$.) By Theorem \\ref{th_fp}, we have\n\\begin{equation*}\n    \\Prob_{Z \\sim D_{\\text{nm}}^n} \\left[ \\Prob(\\hat y = 1 \\mid y=0) \\le \\epsilon_\\fp \\right] \\ge 1 - \\delta_\\fp.\n\\end{equation*} In other words, the error rate when $d(x) \\geq \\tfn$ and $d(x) \\geq \\tfp$ satisfies \n\\begin{equation*}\n    \\Prob_{Z_{\\text{nm}} \\sim D_{\\text{nm}}^n} \\left[ \\epsilon_{\\text{ad}} \\le \\epsilon_\\fp \\right] \\ge 1 - \\delta_\\fp.\n\\end{equation*}\n\nSimilarly, when $d(x) \\leq \\tfn$ and $d(x) \\leq \\tfp$, by Equation \\ref{y_hat}, $\\hat y = 0$. In this case, the error rate $\\epsilon_{\\text{ad}}$ equals to the FNR. (The anomaly detector's prediction is correct when $y=0$.) By Theorem \\ref{th_fn}, we have\n\\begin{equation*}\n    \\Prob_{Z \\sim D_{\\text{ano}}^n} \\left[\n    \\Prob(\\hat y = 0 \\mid y=1)\\le \\epsilon_\\fn \\right] \\ge 1 - \\delta_\\fn.\n\\end{equation*} Thus, the error rate when $f(x) \\geq \\tfn$ and $f(x) \\geq \\tfp$ satisfies \n\\begin{equation*}\n    \\Prob_{Z_{\\text{ano}} \\sim D_{\\text{ano}}^n} \\left[ \\epsilon_{\\text{ad}}  \\le \\epsilon_\\fn \\right] \\ge 1 - \\delta_\\fn.\n\\end{equation*}\n\nTherefore, if we make a certain prediction by Equation \\eqref{y_hat},\n% \\ee{what does this refer to?}\nwe can bound the error rate as\n\\begin{equation*}\n    \\begin{split}\n        \\epsilon_{\\text{ad}} &= \\epsilon_{\\text{fp}} \\cdot \\Pr(y=0) + \\epsilon_{\\text{fn}} \\cdot \\Pr(y=1)\\\\\n        &\\leq \\max{(\\epsilon_{\\text{fp}}, \\epsilon_{\\text{fn}})} \\cdot \\Pr(y=0) + \\max{(\\epsilon_{\\text{fp}}, \\epsilon_{\\text{fn}})} \\cdot \\Pr(y=1)\\\\\n        &= \\max{(\\epsilon_{\\text{fp}}, \\epsilon_{\\text{fn}})}.\n    \\end{split}\n\\end{equation*}\nThe inequality holds with probability at least  $1-(\\delta_{\\text{fp}} + \\delta_{\\text{fn}})$ due to the union bound. Thus, the claim follows. $\\square$\n\n"
            },
            "section 7": {
                "name": "th_final",
                "content": "\n\\label{pf_th_margin}\n\n% if $\\tfp < \\tfn$, the error rate of the anomaly detector $d(x)$ is upper bounded by $\\epsilon_\\text{ad}$ given $\\epsilon=\\epsilon_{\\text{fn}} = \\epsilon_{\\text{fp}}$.\n% Error rate is defined as, i.e.,\n% $$\n% \\epsilon = \\Pr_{(x,y) \\sim \\Ds} (\\hat y \\neq y),\n% $$ where $\\hat y$ is the prediction from the anomaly detector. $\\square$\n% no need to relax \n% need to relax\n\n\n\nSince Algorithm \\ref{Strategy} returns $\\tfp', \\tfn'$ and $\\epsilon$ only when $ \\tfn' \\geq \\tfp'$, we first prove that the error rate of the anomaly detector is bounded by $\\epsilon$.\nFollowing the proof for Theorem \\ref{th_cad}, we have  the guarantee that the FNR and FPR of the anomaly detector is bounded by the updated $\\epsilon_{\\text{fn}}$ and $\\epsilon_{\\text{fp}}$ in Algorithm \\ref{Strategy}, using $\\tfn'$ and $\\tfp'$ respectively. \nIf we use a threshold $\\tau' < \\tfn'$, the corresponding FNR, denoted as $\\epsilon'$, obeys\n\\begin{equation}\n    \\epsilon' \\leq \\epsilon_{\\text{fn}} \\leq \\epsilon.\n    \\label{eq: th_final_fn}\n\\end{equation}\nThis is because using a lower threshold corresponds to a lower quantile of the lower tail part for $\\hat y = 1$ distribution, and we have a smaller chance of making false negative prediction, i.e., classifying an anomaly as a normal point.\n\n\nSimilarly, if $\\tau' > \\tfp'$, for the FPR, denoted as $\\epsilon'$, we will have:\n\\begin{equation}\n    \\epsilon' \\leq \\epsilon_{\\text{fp}} \\leq \\epsilon.\n    \\label{eq: th_final_fp}\n\\end{equation}\nThe same logic follows here; a higher threshold corresponds to a higher quantile of the upper tail of the distribution $x|\\hat y = 0$. Hence we have a smaller chance of making false positive prediction.\n\n\nSince $\\tfp \\leq \\tau \\leq \\tfn$, let $\\tau' = \\tau$. Based on Theorem \\ref{th_cad}, equation (\\ref{eq: th_final_fn}) and equation (\\ref{eq: th_final_fp}), the error rate of the anomaly detector $\\epsilon_\\text{ad}$ is bounded by $\\epsilon$:\n\\begin{equation*}\n\\begin{split}\n%   \\tfp \\leq \\tau_{\\text{final}} \\leq \\tfn, \\\\\n   \\epsilon_{\\text{ad}} &= \\max{(\\epsilon_{\\text{fp}}, \\epsilon_{\\text{fn}})}\n   \\leq \\max{(\\epsilon, \\epsilon)}\n   = \\epsilon.\n\\end{split}\n\\end{equation*} \nSince we use $\\delta_\\text{fn}, \\delta_\\text{fp}$ to re-calculate $\\tfp', \\tfn'$, the resulting $\\delta$ can be taken as $\\delta_\\text{fn}+\\delta_\\text{fp}$ according to Theorem \\ref{th_cad}. Therefore, the claim follows. $\\square$\n\n\n% 1. $\\tau$ median satisfy error rate.\n% $\\tau_{\\text{final}}$\n%  $\\epsilon_{final}$\n\n% We first consider the cases where the anomaly score $f(x)$ falls into certain regions. \n\n% When $f(x) \\geq \\tfn$ and $f(x) \\geq \\tfp$, by Equation \\ref{y_hat}, $\\hat y = 1$. In this case, the error rate $e$ equals to the FPR. By Theorem \\ref{th_fp}, we have the following property, i.e.,\n% \\begin{equation}\n%     \\Prob_{Z_{\\text{nm}} \\sim D_{\\text{nm}}^n} \\left[ \\Prob_{(x,y) \\sim D_\\text{nm}}(\\hat y = 1 \\mid y=0) \\le \\epsilon_\\fp \\right] \\ge 1 - \\delta_\\fp.\n% \\end{equation} In other words, the error rate when $f(x) \\geq \\tfn$ and $f(x) \\geq \\tfp$ satisfies \n% \\begin{equation}\n%     \\Prob_{Z_{\\text{nm}} \\sim D_{\\text{nm}}^n} \\left[ e \\le \\epsilon_\\fp \\right] \\ge 1 - \\delta_\\fp.\n% \\end{equation}\n\n% When $f(x) \\leq \\tfn$ and $f(x) \\leq \\tfp$, by Equation \\ref{y_hat}, $\\hat y = 0$. In this case, the error rate $e$ equals to the FNR. By Theorem \\ref{th_fn}, we have the following property, i.e.,\n% \\begin{equation}\n%     \\Prob_{Z_{\\text{ano}} \\sim D_{\\text{ano}}^n} \\left[\n%     \\Prob_{(x,y) \\sim D_\\text{ano}}(\\hat y = 0 \\mid y=1)\\le \\epsilon_\\fn \\right] \\ge 1 - \\delta_\\fn.\n% \\end{equation} In other words, the error rate when $f(x) \\geq \\tfn$ and $f(x) \\geq \\tfp$ satisfies \n% \\begin{equation}\n%     \\Prob_{Z_{\\text{ano}} \\sim D_{\\text{ano}}^n} \\left[ e \\le \\epsilon_\\fn \\right] \\ge 1 - \\delta_\\fn.\n% \\end{equation}\n\n% We then consider the cases where $f(x)$ falls into ambiguity regions. \n\n% When $\\tfn \\geq f(x) \\geq \\tfp$, for $x \\mid y=1$, the error rate $e$ equals to FNR. By Theorem \\ref{th_fn}, $e$ satisfies the following property, i.e.,\n% \\begin{equation}\n%     \\Prob_{Z_{\\text{ano}} \\sim D_{\\text{ano}}^n} \\left[ e \\le \\epsilon_\\fn \\right] \\ge 1 - \\delta_\\fn;\n% \\end{equation} for $x\\mid y = 0$, the error rate $e$ equals to FPR. By Theorem \\ref{th_fp}, $e$ satisfies the following property, i.e.,\n% \\begin{equation}\n%     \\Prob_{Z_{\\text{nm}} \\sim D_{\\text{nm}}^n} \\left[ e \\le \\epsilon_\\fp \\right] \\ge 1 - \\delta_\\fp.\n% \\end{equation}\n\n% When $\\tfp \\geq f(x) \\geq \\tfn$, the error rate $e$ could be arbitrarily close to 1. $\\square$\n\n% \\section{Additional Plots}\n% \\label{add_plots}\n% Please check Figure \\ref{additional}.\n\n% \\begin{figure}[t!]\n%     \\centering\n%     \\begin{subfigure}[t]{0.5\\textwidth}\n%         \\centering\n%         \\includegraphics[width=0.9\\linewidth]{figures/iid/bank-additional-full_normalised_Box_DevNet.png}\n%         \\caption{Box Plot and thresholds on the \\textit{bank-additional-full\\_normalised} using DevNet}\n%     \\end{subfigure}%\n    \n%     \\begin{subfigure}[t]{0.5\\textwidth}\n%         \\centering\n%         \\includegraphics[width=0.9\\linewidth]{figures/iid/annthyroid_21feat_normalised_Box_DevNet.png}\n%         \\caption{Box Plot and thresholds on the \\textit{annthyroid\\_21feat\\_normalised} using DevNet}\n%     \\end{subfigure}\n\n%     \\caption{Additional plots}\n%     \\label{additional}\n% \\end{figure}\n\n% \\section{Time series anomaly detector}\n% \\begin{figure}[H]\n%     \\centering\n%     \\begin{subfigure}[t]{0.5\\textwidth}\n%         \\centering\n%         \\includegraphics[width=0.9\\linewidth]{figures/time_series/exp215_60.png}\n%         \\caption{Box Plot and thresholds on the \\textit{SMD} using LSTM based anomaly detector for window length of 15 data pointd every 60 timesteps}\n%     \\end{subfigure}%\n    \n%     \\begin{subfigure}[t]{0.5\\textwidth}\n%         \\centering\n%         \\includegraphics[width=0.9\\linewidth]{figures/time_series/exp215_120.png}\n%         \\caption{Box Plot and thresholds on the \\textit{SMD} using LSTM based anomaly detector for window length of 15 data pointd every 120 timesteps}\n%     \\end{subfigure}\n    \n%       \\begin{subfigure}[t]{0.5\\textwidth}\n%         \\centering\n%         \\includegraphics[width=0.9\\linewidth]{figures/time_series/exp215_240.png}\n%         \\caption{Box Plot and thresholds on the \\textit{SMD} using LSTM based anomaly detector for window length of 15 data pointd every 240 timesteps}\n%     \\end{subfigure}\n%     \\caption{SMD results with window length of 15 timesteps, $\\epsilon$ is relaxed to 0.6 using our strategy.}\n%     \\label{time_series}\n% \\end{figure}\n\n% \\begin{figure}[H]\n%     \\centering\n%     \\begin{subfigure}[t]{0.5\\textwidth}\n%         \\centering\n%         \\includegraphics[width=0.9\\linewidth]{figures/time_series/exp230_60.png}\n%         \\caption{Box Plot and thresholds on the \\textit{SMD} using LSTM based anomaly detector for window length of 30 data pointd every 60 timesteps}\n%     \\end{subfigure}%\n    \n    \n    \n    \n%     \\begin{subfigure}[t]{0.5\\textwidth}\n%         \\centering\n%         \\includegraphics[width=0.9\\linewidth]{figures/time_series/exp230_120.png}\n%         \\caption{Box Plot and thresholds on the \\textit{SMD} using LSTM based anomaly detector for window length of 30 data pointd every 120 timesteps}\n%     \\end{subfigure}\n    \n%       \\begin{subfigure}[t]{0.5\\textwidth}\n%         \\centering\n%         \\includegraphics[width=0.9\\linewidth]{figures/time_series/exp230_240.png}\n%         \\caption{Box Plot and thresholds on the \\textit{SMD} using LSTM based anomaly detector for window length of 30 data pointd every 240 timesteps}\n%     \\end{subfigure}\n%     \\caption{SMD results with window length of 30 timesteps, $\\epsilon$ is relaxed to 0.8 using our strategy.}\n%     \\label{SMD}\n% \\end{figure}\n\n% \\begin{figure}[H]\n%     \\centering\n%     \\begin{subfigure}[t]{0.5\\textwidth}\n%         \\centering\n%         \\includegraphics[width=0.9\\linewidth]{figures/time_series/exp2P-2.png}\n%         \\caption{Box Plot and thresholds on the \\textit{NASA P-2 channel} using LSTM based anomaly detector}\n%     \\end{subfigure}%\n    \n%     \\begin{subfigure}[t]{0.5\\textwidth}\n%         \\centering\n%         \\includegraphics[width=0.9\\linewidth]{figures/time_series/exp2D-3.png}\n%         \\caption{Box Plot and thresholds on the \\textit{NASA D-3 channel} using LSTM based anomaly detector}\n%     \\end{subfigure}\n    \n%       \\begin{subfigure}[t]{0.5\\textwidth}\n%         \\centering\n%         \\includegraphics[width=0.9\\linewidth]{figures/time_series/exp2M-6.png}\n%         \\caption{Box Plot and thresholds on the \\textit{NASA M-6 channel} using LSTM based anomaly detector}\n%     \\end{subfigure}\n%     \\caption{NASA results with 3 representative channels, $\\epsilon = 0.1$.}\n%     \\label{NASA_0_1}\n% \\end{figure}\n\n% \\begin{figure}[H]\n%     \\centering\n%     \\begin{subfigure}[t]{0.5\\textwidth}\n%         \\centering\n%         \\includegraphics[width=0.9\\linewidth]{figures/time_series/exp2T-1.png}\n%         \\caption{Box Plot and thresholds on the \\textit{NASA T-1 channel} using LSTM based anomaly detector}\n%     \\end{subfigure}%\n    \n%     \\begin{subfigure}[t]{0.5\\textwidth}\n%         \\centering\n%         \\includegraphics[width=0.9\\linewidth]{figures/time_series/exp2T-2.png}\n%         \\caption{Box Plot and thresholds on the \\textit{NASA T-2 channel} using LSTM based anomaly detector}\n%     \\end{subfigure}\n    \n%       \\begin{subfigure}[t]{0.5\\textwidth}\n%         \\centering\n%         \\includegraphics[width=0.9\\linewidth]{figures/time_series/exp2D-15.png}\n%         \\caption{Box Plot and thresholds on the \\textit{NASA D-15 channel} using LSTM based anomaly detector}\n%     \\end{subfigure}\n%     \\caption{NASA results with 3 representative channels, $\\epsilon$ is relaxed to 0.5.}\n%     \\label{NASA_0_5}\n% \\end{figure}\n\n% \\section{Two Cases Explanation}\n% We take FNR as an example. Recall that it is defined as\n% \\begin{equation*}\n% \\begin{split}\n%     FNR &= \\frac{FN}{FN+TP}\n%     = \\frac{FN}{\\text{Fraction of positive data points}}.\n% \\end{split}\n% \\end{equation*}\n% Thus, FNR is calculated on the positive (anomalous) data distribution. It increases with the fraction of such data points classified as normal.\n\n% Then, we discuss the two ambiguity region cases. If where $\\tfn \\geq \\tfp$, after constructing false positive/negative PAC prediction sets and taking their intersection, we predict in the following way:\n% \\begin{equation*}\n%     \\hat y_{\\text{ad}} \\coloneqq \\begin{cases}1, & \\cad(x) = \\{1\\}\\, (\\text{anomaly score is above $\\tfn$})\\\\\n%     0, & \\cad(x) = \\{0\\}\\, (\\text{anomaly score is below $\\tfp$})\\\\\n%     *, & \\cad(x) = \\emptyset,\\, (\\text{anomaly score is within $[\\tfp, \\tfn]$})\n% \\end{cases},\n% \\label{y_hat_gd}\n% \\end{equation*} \n% We proved in Theorem \\ref{th_cad} that within the unambiguity region, the error rate of the classifier $\\epsilon_{\\text{ad}}$ satisfies the following property:\n% $$\n% \\Prob_{Z \\sim \\Ds_{n}}\\left[ \\epsilon_{\\text{ad}}(\\Ds) \\le \\max{(\\epsilon_\\fp, \\epsilon_\\fn)} \\right] \\ge 1 - (\\delta_\\fp+\\delta_\\fn).\n% $$\n% Intuitively, this is because we use $\\tfn$ to check whether a \\text{1} should be made. This guarantees the FNR; similar, $\\tfp$ serves to guarantee false positive rate. Since these two rates are guarantees and error rate is actually a convex combination of these two rates, ($\\epsilon_{\\text{ad}} = \\lambda \\epsilon_\\fp + (1-\\lambda) \\epsilon_\\fn, \\lambda\\in[0,1]$), the error rate $\\epsilon$ is upper bounded by $\\max{(\\tfn, \\tfp)}$, (and also lower bounded by $\\min{(\\tfn, \\tfp)}$).\n\n% If $\\tfp \\geq \\tfn$, we proposed to predict as follows:\n% \\begin{equation*}\n%     \\hat y_{\\text{ad}} \\coloneqq \\begin{cases}1, & \\cad(x) = \\{1\\}\\, (\\text{anomaly score is above $\\tfp$})\\\\\n%     0, & \\cad(x) = \\{0\\}\\, (\\text{anomaly score is below $\\tfn$})\\\\\n%     *, & \\cad(x) = \\emptyset,\\, (\\text{anomaly score is within $[\\tfn, \\tfp]$})\n% \\end{cases},\n% \\label{y_hat_bd}\n% \\end{equation*} \n% We claim that our guarantees cannot generally hold in this case. We take FNR as an example. If $\\tfp \\geq \\tfn$, we predict \\textit{1} if the anomaly score is above $\\tfp$, thus\n% \\begin{equation*}\n%     \\begin{split}\n%         FNR &= \\mathbb{P}_{x \\sim \\Ds_{ano}}(d(x) < \\tfp)\n%         \\geq \\mathbb{P}_{x \\sim \\Ds_{ano}} (d(x)< \\tfn) = \\epsilon_\\fn.\n%     \\end{split}\n% \\end{equation*}\n% Thus, if we use $\\tfp$ instead of $\\tfn$ to classify whether a data point is \\textit{1}, the resulting FNR may in general be large.\n\n"
            },
            "section 8": {
                "name": "ambiguity",
                "content": "\n\\label{pf_lma}\n\nWe first prove that if $\\tfn \\geq \\tfp$, then $\\sum_{(x,y) \\in Z_{\\text{nm}}} \\mathbbm{1}(d(x) > \\tfn) \\leq k_\\fp^*$ and $ \\sum_{(x,y) \\in Z_{\\text{ano}}} \\mathbbm{1}(d(x) < \\tfp) \\leq k_\\fn^*$. \n% We first prove that $\\frac{1}{|Z_{\\text{nm}}|} \\sum_{(x,y) \\in Z_{\\text{nm}}} \\mathbbm{1}(d(x) > \\tfn) < \\hat \\epsilon_\\fp$. \nTo see this, we construct a false positive PAC prediction set using \\eqref{eqn:algorithm} and make a prediction using \\eqref{fn_construct}. Therefore, we have\n$$\n \\sum_{(x,y) \\in Z_{\\text{nm}}} \\mathbbm{1}(d(x) > \\tfp) \\leq k_\\fp^*.\n$$\nSince $\\tfn > \\tfp$, we find\n\\begin{equation*}\n\\begin{split}\n    \\sum_{(x,y) \\in Z_{\\text{nm}}} \\mathbbm{1}(d(x) > \\tfn) &\\leq \\sum_{(x,y) \\in Z_{\\text{nm}}} \\mathbbm{1}(d(x) > \\tfp) \\leq  k_\\fp^*.\n\\end{split}\n\\end{equation*}\n\nSimilarly, for the false negative PAC prediction set, we have\n\\begin{equation*}\n\\begin{split}\n     \\sum_{(x,y) \\in Z_{\\text{ano}}} \\mathbbm{1}(d(x) < \\tfp) &\\leq \\sum_{(x,y) \\in Z_{\\text{ano}}} \\mathbbm{1}(d(x) < \\tfn) \n     \\leq k_\\fn^*. \n\\end{split}\n\\end{equation*}\n\nNext, we prove that if $\\sum_{(x,y) \\in Z_{\\text{nm}}} \\mathbbm{1}(d(x) > \\tfn) < k_\\fp^*$ and $\\sum_{(x,y) \\in Z_{\\text{ano}}} \\mathbbm{1}(d(x) < \\tfp) < k_\\fn^*$, then $\\tfn \\geq \\tfp$. We argue by contradiction. \nSuppose that $\\sum_{(x,y) \\in Z_{\\text{nm}}} \\mathbbm{1}(d(x) > \\tfn) < k_\\fp^*$, and $\\sum_{(x,y) \\in Z_{\\text{ano}}} \\mathbbm{1}(d(x) < \\tfp) < k_\\fn^*$, but $\\tfp < \\tfn$. Then, for the false negative PAC prediction set, we should choose $\\tfp$ instead of $\\tfn$, since the identified $\\tfn$ should be the largest threshold satisfying $\\hat \\epsilon_\\fn$ and $\\tfp > \\tfn$. This contradicts that $\\tfn$ is the chosen threshold. As a result, our assumption does not hold, and we have $\\tfn \\geq \\tfp$. \n\nIn summary, $\\tfn \\geq \\tfp$ if and only if $\\sum_{(x,y) \\in Z_{\\text{nm}}} \\mathbbm{1}(d(x) > \\tfn) < k_\\fp^*$ and $\\sum_{(x,y) \\in Z_{\\text{ano}}} \\mathbbm{1}(d(x) < \\tfp) < k_\\fn^*$. $\\square$\n\n% \\section{Additional Experiments}\n% \\label{Seeds}\n\n% \\begin{table}[ht]\n% \\begin{tabular}{llll}\n% \\hline\n% Random Seed         & Method  & FPR             & FNR             \\\\ \\hline\n% \\multirow{2}{*}{20} & CPAD    & 0.38 $\\pm$ 0.10 & 0.48 $\\pm$ 0.06 \\\\\n%                     & PAC-Wrap & 0.07 $\\pm$ 0.06 & 0.05 $\\pm$ 0.05 \\\\\n% \\multirow{2}{*}{40} & CPAD    & 0.50 $\\pm$ 0.09 & 0.39 $\\pm$ 0.11 \\\\\n%                     & PAC-Wrap & 0.09 $\\pm$ 0.07 & 0.05 $\\pm$ 0.05 \\\\ \\hline\n% \\end{tabular}\n% \\caption{Comparison between the conformal prediction based method with PAC-Wrap in terms of the constraint satisfaction rate.}\n% \\label{tab_cp_delta}\n% \\end{table}\n% \\balance\n"
            },
            "section 9": {
                "name": "Time-series Experiments",
                "content": "\n\\label{appendix:time}\nWe also experiment with two challenging time series anomaly detection datasets,  the Server Machine Dataset  \\cite{su2019robust}, and NASA Telemetry Anomaly Detection \\cite{hundman2018detecting}, to illustrate the effectiveness of PAC-Wrap on sequential data.\n% To showcase the effectiveness of PAC-Wrap on time-series data, we conducted experiments on the NASA and SMD data set.\nThe NASA dataset consists of spacecraft telemetry data like radiation, temperature, and power from the Soil Moisture Active Passive satellite (SMAP), and the Curiosity Rover on Mars (MSL). In addition, it contains 193500 records for training and 501346 records for testing, of which around 10\\% are anomalies.  \nSMD is a dataset collected from a large Internet company over five weeks, with 38 features such as CPU load, network usage,\nand memory usage. It contains a training set of 708405 records and a test set of 708420 records, among them 4.16\\% are anomalies. We split the original test set into a calibration set (20\\%) and a final test set (80\\%) for both SMD and NASA.\n\\begin{center}\n    \\begin{table}\n    \\begin{adjustbox}{width=0.5\\textwidth}\n\\begin{tabular}{llllllllll}\n\\hline\n     & $\\text{FNR}_{\\text{or}}$ & $\\text{FPR}_{\\text{or}}$ & $\\text{FNR}_{\\text{tt}}$    & $\\text{FPR}_{\\text{tt}}$     & $\\text{FNR}_{\\text{th}}$ & $\\text{FPR}_{\\text{th}}$ & ERR & $\\epsilon$ \\\\ \\hline\nS-1 & 0.000      & 0.615      & 0.059 & 0.088 & 0.340  & 0.293  & 0.337 & 0.40    \\\\\nF-7 & 0.132      & 0.503      & 0.060 & 0.071 & 0.292  & 0.304  & 0.293 & 0.40    \\\\\nE-7 & 0.000     & 0.714      & 0.076 & 0.081 & 0.306  & 0.246  & 0.304 & 0.40     \\\\\nT-1 & 0.001     & 0.653      & 0.103 & 0.099 & 0.367  & 0.448  & 0.382 & 0.50     \\\\\nT-2 & 0.011      & 0.738      & 0.063 & 0.084 & 0.384  & 0.428  & 0.393 & 0.50     \\\\\nP-3 & 0.013      & 0.724      & 0.053 & 0.065 & 0.363  & 0.379  & 0.366 & 0.50  \\\\\n\\hline\n\\end{tabular}\n\\end{adjustbox}\n\\caption{Error rate with PAC-Wrap applied to the LSTM-based anomaly detector on the NASA data. First column is the corresponding channels. $\\text{FNR}_{\\text{tt}}$ and $\\text{FPR}_{\\text{tt}}$ satisfy the $\\epsilon = 0.1$ guarantees. After removing the ambiguity region, the $\\text{FNR}_{\\text{th}}$, $\\text{FPR}_{\\text{th}}$, and ERR satisfy the relaxed error constraints.}\n\\vspace{-25pt}\n\\label{tab: comp_ts}\n\\end{table}\n\\end{center}\n\n% \\vspace{-10pt}\n\n% 15_60,0.9369,0.0355,0.0738,0.0871,0.4873,0.4738,0.4866,0.6\n% 15_120,0.5682,0.3682,0.0523,0.0,0.5982,0.3591,0.5871,0.6\n% 15_240,0.9183,0.0106,0.0865,0.0877,0.5375,0.399,0.5315,0.6\n% 30_60,1.0,0.0,0.0771,0.0,0.7802,0.2006,0.7484,0.7999999999999999\n% 30_120,0.1274,0.8176,0.0566,0.0,0.7806,0.1735,0.7464,0.7999999999999999\n% 30_240,0.4672,0.379,0.0579,0.0,0.7375,0.1583,0.7059,0.7999999999999999\n\n\n% \\vspace{-15pt}\n%Using our PAC-Wrap to wrap around their method, we can see that both $\\text{FPR}_{\\text{th}}$ and FPR\\_th are below 0.1, and hence the final error rate performance is assured to be less than 0.1 as well. \n The detailed result for the NASA data is reported in Table \\ref{tab: comp_ts}.\nIn the T-1, T-2, and P-3 channels, both $\\text{FPR}_{\\text{th}}$ and $\\text{FNR}_\\text{th}$ are guaranteed to be smaller than the relaxed error constraint, and the final error rate ERR is also below the required error constraint $\\epsilon = 0.5$. \nWrapped around the original NASA anomaly detector, PAC-Wrap can reduce the gap between the FNR and FPR and thus has a more balanced performance. \n\nSince there are more datapoints in the SMD dataset than in the NASA one, to approach the independence condition formally required by our guarantees, \nwe consider the windows of the first 15 and 30 contiguous timesteps as data points for every 60, 120, and 240 timesteps. As shown in Table \\ref{tab: comp_smd}, $\\epsilon=0.6, 0.8$ is the relaxed error constraint given the anomaly score distribution. \nFor the baseline anomaly detector, $\\text{FPR}_{\\text{or}}$-s sometimes fail the $\\epsilon=0.6$ guarantee for the 15-timestep settings. \nFor all the 30-timestep settings, the original anomaly detectors violate the $\\epsilon=0.8$ guarantee on either $\\text{FPR}_{\\text{or}}$ or $\\text{FNR}_{\\text{or}}$. \nHowever, using PAC-Wrap as a wrapper, we ensure that both $\\text{FNR}_{\\text{th}}$ and $\\text{FPR}_{\\text{th}}$ fall below 0.6 and 0.8. \nThe final error rates (ERR) are smaller than the maximum of $\\text{FNR}_{\\text{th}}$ and $\\text{FPR}_{\\text{th}}$, which also empirically supports Theorem \\ref{th_cad}.\n% S-1,0.6145,0.0,0.0587,0.0878,0.3398,0.2933,0.4,0.3368\n% F-7,0.503,0.1323,0.0595,0.0714,0.2924,0.3036,0.4,0.2934\n% E-7,0.7143,0.0,0.0759,0.0814,0.306,0.2455,0.4,0.3039\n% T-1,0.6528,0.0095,0.1027,0.0992,0.3674,0.4474,0.5,0.3821\n% T-2,0.738,0.0106,0.0634,0.0844,0.3839,0.4282,0.5,0.3933\n% P-3,0.7238,0.0134,0.0534,0.0652,0.3628,0.3792,0.5,0.3655\n\n% \\section{Link to the implementation}\n% \\label{implementation}\n% Please find our code and data from this link: \\url{https://drive.google.com/file/d/1q5-1pe_AKyGNKe5h23H781otqSrxIcCM/view?usp=sharing}.\n\\vspace{-5pt}\n"
            },
            "section 10": {
                "name": "Distribution shift",
                "content": "\n\\label{distribution shift}\nTo see how shifts in the anomaly distribution affect our guarantees, we generate data from three distributions in the following way:\n\\begin{align*}\n    X_{\\text{normal}} &\\sim \\mathcal{N}(\\mu_{\\text{normal}}, \\sigma^2 I_p) \\\\\n    X_{\\text{anomalous}} &\\sim \\mathcal{N}(\\mu_{\\text{anomalous}}, \\sigma^2 I_p)\\\\\n    X_{\\text{mixture}} &\\sim \\mathcal{N}(\\gamma \\cdot \\mu_{\\text{normal}} + (1-\\gamma) \\cdot\\mu_{\\text{anomalous}}, \\sigma^2 I_p),\n\\end{align*} where $\\gamma \\in [0,1]$ is a mixing ratio. We set $\\mu_{\\text{normal}}=[0, 0, 0, 0, 0]^\\top$, $\\mu_{\\text{anomalous}} = [3, 3, 3, 3, 3]^\\top$, and $\\sigma=2.0$. \n% \\ED{and the other settings are as in Section \\ref{d}?}\nThen, we construct the training set by sampling 98,000 data points from $\\mathcal{N}(\\mu_{\\text{normal}}, \\sigma^2 I_p)$; we construct the calibration set by sampling 1,000 anomalies from $\\mathcal{N}(\\mu_{\\text{anomalous}}, \\sigma^2 I_p)$; we construct the testing set by sampling 1,000 data points from $\\mathcal{N}(\\gamma \\cdot \\mu_{\\text{normal}} + (1-\\gamma) \\cdot\\mu_{\\text{anomalous}}, \\sigma^2 I_p)$ with different $\\gamma$-s. We set $\\gamma$ to $\\{0, 0.02, 0.04$, $0.06, 0.08$, $0.1, 0.2\\}$ and $\\epsilon=\\delta=0.05$. We run PAC-Wrap on the training, calibration, and testing sets. As shown in Figure \\ref{fig:shift}, guarantees nearly hold when $\\gamma$ equals to 0.02, 0.04, and 0.06. However, when the mixing rate is too large, the guarantees might fail to hold.\n\n\n\n"
            }
        },
        "tables": {
            "tab: comp_smd": "\\begin{table}\n\\begin{adjustbox}{width=0.5\\textwidth}\n\\begin{tabular}{lllllllll}\n\\hline\n   & $\\text{FNR}_{\\text{or}}$ & $\\text{FPR}_{\\text{or}}$ & $\\text{FNR}_{\\text{tt}}$    & $\\text{FPR}_{\\text{tt}}$     & $\\text{FNR}_{\\text{th}}$ & $\\text{FPR}_{\\text{th}}$ & ERR &$\\epsilon$  \\\\ \\hline\n15-60  & 0.036      & 0.937      & 0.074 & 0.087 & 0.487  & 0.474  & 0.487 & 0.60     \\\\\n15-120 & 0.368      & 0.563      & 0.052 & 0.000 & 0.598  & 0.359  & 0.587 & 0.60     \\\\\n15-240 & 0.011      & 0.918      & 0.086 & 0.088 & 0.538  & 0.399  & 0.532 & 0.60     \\\\\n30-60  & 0.077      & 1.000      & 0.077 & 0.000 & 0.780  & 0.201  & 0.748 & 0.80     \\\\\n30-120 & 0.818      & 0.127      & 0.057 & 0.000 & 0.781  & 0.174  & 0.746 & 0.80     \\\\\n30-240 & 0.379      & 0.467      & 0.058 & 0.000 & 0.738  & 0.158  & 0.706 & 0.80     \\\\\n\\hline\n\\end{tabular}\n\\end{adjustbox}\n\\caption{Error rate with PAC-Wrap wrapped around the LSTM-based anomaly detector on the SMD data. First column is the corresponding combinations. $\\text{FNR}_{\\text{tt}}$ and $\\text{FPR}_{\\text{tt}}$ satisfy the $\\epsilon = 0.1$ guarantees. After removing the ambiguity region, the $\\text{FNR}_{\\text{th}}$, $\\text{FPR}_{\\text{th}}$, and ERR satisfy the relaxed error constraints.}\n\\vspace{-25pt}\n\\label{tab: comp_smd}\n\\end{table}"
        },
        "figures": {
            "fig:shift": "\\begin{figure}[H]\n    \\centering\n    \\includegraphics[scale=0.2]{figures/shift.png}\n    \\caption{FPR and FNR after mixing different anomaly distributions}\n    \\label{fig:shift}\n\\end{figure}"
        },
        "equations": {
            "eq:1": "\\begin{equation*} \\label{eq_th_fp}\n\\begin{split}\n&\\Pr(\\hat y =1 \\mid y=0) = \\mathbb{E}_{x\\mid y=0}[\\mathbbm{1}(\\hat y = 1)] \\\\\n&= \\mathbb{E}_{x\\mid y=0}[\\mathbbm{1}(0 \\notin \\cfp(x))]\n= \\mathbb{E}_{x \\mid y=0}[\\mathbbm{1}( y \\notin C_{\\hat\\tau_{\\fp}}(x)]\\\\\n&= \\mathbb{E}_{x \\mid y=0}[\\ell_{\\fp}^{01}(x)] \n=  L_{D_{\\text{nm}}}(\\cfp).\n\\end{split}\n\\end{equation*}",
            "eq:2": "\\begin{equation*}\n \\Prob_{Z \\sim D_{\\text{nm}}^n}[ L_{D_{\\text{nm}}}(\\cfp) \\le \\epsilon_\\fp ] \\ge 1 - \\delta_{\\fp}.   \n\\end{equation*}",
            "eq:3": "\\begin{equation*}\n    \\Prob_{Z \\sim D_{\\text{nm}}^n}[ \\Prob(\\hat y =1 \\mid y=0) \\le \\epsilon_\\fp ] \\ge 1 - \\delta_{\\fp}. \\square \n\\end{equation*}",
            "eq:4": "\\begin{equation*} \\label{eq_th_fn}\n\\begin{split}\n&\\Pr(\\hat y =0 \\mid y=1) = \\mathbb{E}_{x\\mid y=1}[\\mathbbm{1}(\\hat y = 0)] \\\\\n&= \\mathbb{E}_{x\\mid y=1}[\\mathbbm{1}(1 \\notin \\cfn(x))]\n= \\mathbb{E}_{x \\mid y=1}[\\mathbbm{1}( y \\notin C_{\\hat\\tau_{\\fn}}(x)]\\\\\n&= \\mathbb{E}_{x \\mid y=1}[\\ell_{\\fn}^{01}(x)] \n=  L_{D_{\\text{ano}}}(\\cfn).\n\\end{split}\n\\end{equation*}",
            "eq:5": "\\begin{equation*}\n \\Prob_{Z \\sim D_{\\text{ano}}^n}[ L_{D_{\\text{ano}}}(\\cfn) \\le \\epsilon_\\fn ] \\ge 1 - \\delta_{\\fn}.   \n\\end{equation*}",
            "eq:6": "\\begin{equation*}\n    \\Prob_{Z \\sim D_{\\text{ano}}^n}[ \\Prob(\\hat y =0 \\mid y=1) \\le \\epsilon_\\fn ] \\ge 1 - \\delta_{\\fn}. \\square \n\\end{equation*}",
            "eq:7": "\\begin{equation*}\n    \\Prob_{Z \\sim D_{\\text{nm}}^n} \\left[ \\Prob(\\hat y = 1 \\mid y=0) \\le \\epsilon_\\fp \\right] \\ge 1 - \\delta_\\fp.\n\\end{equation*}",
            "eq:8": "\\begin{equation*}\n    \\Prob_{Z_{\\text{nm}} \\sim D_{\\text{nm}}^n} \\left[ \\epsilon_{\\text{ad}} \\le \\epsilon_\\fp \\right] \\ge 1 - \\delta_\\fp.\n\\end{equation*}",
            "eq:9": "\\begin{equation*}\n    \\Prob_{Z \\sim D_{\\text{ano}}^n} \\left[\n    \\Prob(\\hat y = 0 \\mid y=1)\\le \\epsilon_\\fn \\right] \\ge 1 - \\delta_\\fn.\n\\end{equation*}",
            "eq:10": "\\begin{equation*}\n    \\Prob_{Z_{\\text{ano}} \\sim D_{\\text{ano}}^n} \\left[ \\epsilon_{\\text{ad}}  \\le \\epsilon_\\fn \\right] \\ge 1 - \\delta_\\fn.\n\\end{equation*}",
            "eq:11": "\\begin{equation*}\n    \\begin{split}\n        \\epsilon_{\\text{ad}} &= \\epsilon_{\\text{fp}} \\cdot \\Pr(y=0) + \\epsilon_{\\text{fn}} \\cdot \\Pr(y=1)\\\\\n        &\\leq \\max{(\\epsilon_{\\text{fp}}, \\epsilon_{\\text{fn}})} \\cdot \\Pr(y=0) + \\max{(\\epsilon_{\\text{fp}}, \\epsilon_{\\text{fn}})} \\cdot \\Pr(y=1)\\\\\n        &= \\max{(\\epsilon_{\\text{fp}}, \\epsilon_{\\text{fn}})}.\n    \\end{split}\n\\end{equation*}",
            "eq:12": "\\begin{equation}\n    \\epsilon' \\leq \\epsilon_{\\text{fn}} \\leq \\epsilon.\n    \\label{eq: th_final_fn}\n\\end{equation}",
            "eq:13": "\\begin{equation}\n    \\epsilon' \\leq \\epsilon_{\\text{fp}} \\leq \\epsilon.\n    \\label{eq: th_final_fp}\n\\end{equation}",
            "eq:14": "\\begin{equation*}\n\\begin{split}\n%   \\tfp \\leq \\tau_{\\text{final}} \\leq \\tfn, \\\\\n   \\epsilon_{\\text{ad}} &= \\max{(\\epsilon_{\\text{fp}}, \\epsilon_{\\text{fn}})}\n   \\leq \\max{(\\epsilon, \\epsilon)}\n   = \\epsilon.\n\\end{split}\n\\end{equation*}",
            "eq:15": "\\begin{equation*}\n\\begin{split}\n    \\sum_{(x,y) \\in Z_{\\text{nm}}} \\mathbbm{1}(d(x) > \\tfn) &\\leq \\sum_{(x,y) \\in Z_{\\text{nm}}} \\mathbbm{1}(d(x) > \\tfp) \\leq  k_\\fp^*.\n\\end{split}\n\\end{equation*}",
            "eq:16": "\\begin{equation*}\n\\begin{split}\n     \\sum_{(x,y) \\in Z_{\\text{ano}}} \\mathbbm{1}(d(x) < \\tfp) &\\leq \\sum_{(x,y) \\in Z_{\\text{ano}}} \\mathbbm{1}(d(x) < \\tfn) \n     \\leq k_\\fn^*. \n\\end{split}\n\\end{equation*}",
            "eq:17": "\\begin{align*}\n    X_{\\text{normal}} &\\sim \\mathcal{N}(\\mu_{\\text{normal}}, \\sigma^2 I_p) \\\\\n    X_{\\text{anomalous}} &\\sim \\mathcal{N}(\\mu_{\\text{anomalous}}, \\sigma^2 I_p)\\\\\n    X_{\\text{mixture}} &\\sim \\mathcal{N}(\\gamma \\cdot \\mu_{\\text{normal}} + (1-\\gamma) \\cdot\\mu_{\\text{anomalous}}, \\sigma^2 I_p),\n\\end{align*}"
        }
    }
}