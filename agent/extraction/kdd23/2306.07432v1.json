{
    "meta_info": {
        "title": "FIRE: An Optimization Approach for Fast Interpretable Rule Extraction",
        "abstract": "We present FIRE, Fast Interpretable Rule Extraction, an optimization-based\nframework to extract a small but useful collection of decision rules from tree\nensembles. FIRE selects sparse representative subsets of rules from tree\nensembles, that are easy for a practitioner to examine. To further enhance the\ninterpretability of the extracted model, FIRE encourages fusing rules during\nselection, so that many of the selected decision rules share common\nantecedents. The optimization framework utilizes a fusion regularization\npenalty to accomplish this, along with a non-convex sparsity-inducing penalty\nto aggressively select rules. Optimization problems in FIRE pose a challenge to\noff-the-shelf solvers due to problem scale and the non-convexity of the\npenalties. To address this, making use of problem-structure, we develop a\nspecialized solver based on block coordinate descent principles; our solver\nperforms up to 40x faster than existing solvers. We show in our experiments\nthat FIRE outperforms state-of-the-art rule ensemble algorithms at building\nsparse rule sets, and can deliver more interpretable models compared to\nexisting methods.",
        "author": "Brian Liu, Rahul Mazumder",
        "link": "http://arxiv.org/abs/2306.07432v1",
        "category": [
            "cs.LG",
            "stat.ML"
        ]
    },
    "latex_extraction": {
        "content": {
            "section 1": {
                "name": "Introduction",
                "content": "\n\n\nTree ensembles are popular for their versatility and excellent off-the-shelf performance. While powerful, these models can grow to massive sizes and become difficult to interpret. To improve model parsimony and interpretability, decision rules can be extracted from trained tree ensembles. Each leaf node in a decision tree represents a decision rule; the path of internal nodes from root to leaf in the tree forms a conjunction of if-then antecedents that assigns a prediction to a partition of the dataset. Extracting a sparse (or parsimonious) subset of decision rules (leaf nodes) from a tree ensemble can produce a compact and transparent model that performs well in terms of prediction accuracy \\cite{friedman2008predictive}. \n\nIn this paper, we present the Fast Interpretable Rule Extraction (\\textsc{Fire}) framework, an optimization-based framework to extract an interpretable collection of rules from tree ensembles. The goal of \\textsc{Fire} is to select a small subset of decision rules that is representative of the larger collection of rules found in a tree ensemble. In addition to sparsity, \\textsc{Fire} allows for the flexibility to encourage \\emph{fusion} in the extracted rules. In other words, the framework can encourage the selection of multiple rules that are {\\emph{close together}} from within the same decision tree, so that the selected rules (leaf nodes) share common antecedents (internal nodes). As we discuss later, encouraging fusion appears to improve the parsimony and interpretability of the extracted rule ensemble. To better convey our intuition,  Figure \\ref{intro_example.fig} presents an illustration. From the original tree ensemble (panel A), we extract 16 decision rules by encouraging only sparsity (panel B), and by encouraging fusion with sparsity (panel C)\\footnote{This example is based off an application of our framework.}. The 16 decision rules selected in the sparsity-only panel each come from a different decision tree while the decision rules selected in the fusion with sparsity panel come from only 6 trees. As a result, the rule set extracted by encouraging both fusion and sparsity contains substantially fewer internal nodes, since leaf nodes from the same decision tree share internal nodes. This translates to fewer if-then antecedents for a practitioner to examine in the rule ensemble, suggesting improved interpretability.\n\n\\textsc{Fire} is based on an optimization formulation that assigns a weight to each decision rule in a tree ensemble and extracts a sparse subset of rules by minimizing regularized loss function. This allows a practitioner to evaluate the trade-off between model compactness and performance by varying the regularization penalty, and to select an appropriately-sized model. \\textsc{Fire} uses a non-convex sparsity-inducing penalty popularly used in highdimensional linear models to aggressively select rules and fused LASSO penalty \\cite{tibshirani2005sparsity} to encourage rule fusion. The fused LASSO is a classical tool used in the context of approximating a signal via a piecewise constant approximation using an $\\ell_1$-based penalty---we present a novel exploration of this tool in the context of rule ensemble extraction.\n\n\n\n\n\n%explain here why we want fusion\n\n%% define what interpretable rule sets mean here\n%% in addition, our framework offers an additional flexibility \n%% emphasize in middle plot that these are coming from seperate trees and highlight that the fusion penalty selects across same trees\n%% we include a fusion penalty the selection of rules \n%% add small r1 , r2 ,r3\n%% rules selected to share common ancestors our framework allows for the flexibility encourages\n\n%compactness + interpretability from fusion (write in words) what that does\n\n% \\textsc{Fire} assigns a weight to each decision rule in a tree ensemble and extracts a sparse subset of rules by minimizing regularized loss. This allows a practitioner to evaluate the trade-off between model compactness and performance by adjusting the regularization penalty, and to select an appropriately-sized model. \\textsc{Fire} introduces two new regularization penalties to enhance the parsimony of the extracted rule sets.\n\n\n% First, a non-convex sparsity-inducing penalty encourages model compression through aggressive rule selection. This sparsity-inducing penalty is combined with a fusion penalty that groups the selected rules together within each decision tree. This reduces the number of internal nodes (antecedents) included in the extracted rule set, since contiguous leaf nodes (rules) share many internal nodes (antecedents). As a result, the rule sets extracted by are more compact and interpretable compared to penalizing for sparsity alone, as illustrated in figure \\ref{intro_example.fig}. \n\n% % add contributions\n\n%% describe\n\n\n\n\n\n\nOptimization problems in \\textsc{Fire} pose a challenge to existing solvers due to problem size and the non-convexity of the penalties. \nOn that account, we develop a novel optimization algorithm to efficiently obtain high-quality solutions to these optimization problems. Our algorithms leverage problem structure and block coordinate descent combined with greedy selection heuristics to improve computational efficiency. By exploiting the blocking structure of problems in \\textsc{Fire}, our specialized solver scales and allows for computation that appear to be well beyond the capabilities of off-the-shelf solvers. In addition, our algorithms support warm start continuation across tuning parameters, which allows a practitioner to use \\textsc{Fire} to rapidly extract rule sets of varying sizes.\n\nWith our specialized solver, \\textsc{Fire} is computationally fast and easy to tune. We show in our experiments that \\textsc{Fire} extracts sparse rule sets that outperform state-of-the-art competing algorithms, by up to a $24\\%$ decrease in test error. We also demonstrate through a real-world example that \\textsc{Fire} extracts decision rules that are easier to interpret compared to the rules selected by existing methods. \n\n\nOur paper is organized as follows. We first overview rule extraction from tree ensembles. We then introduce our model framework and discuss the effects of our new penalties. We next present our specialized optimization algorithm along with timing experiments against off-the-shelf solvers. Finally, we present our experimental results and our interpretability case study. An open-source implementation of \\textsc{Fire} along with a supplement containing derivations and experimental details can be found in this project repository\\footnote{\\href{https://github.com/brianliu12437/FIREKDD2023}{https://github.com/brianliu12437/FIREKDD2023}}.\n\n\n",
                "subsection 1.1": {
                    "name": "Main Contributions",
                    "content": "\n\n\n\\begin{itemize}[noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt, leftmargin=*]\n    \\item We introduce the \\textsc{Fire} framework for rule extraction. \\textsc{Fire} selects sparse representative subsets of decision rules from tree ensembles and can encourage fusion so that the selected rules share common antecedents.\n    \\item \\textsc{Fire} is based on a regularized loss minimization framework. Our regularizer comprises of a non-convex sparsity-inducing penalty to aggressively select rules, and a fused LASSO penalty to encourage fusion. Our work is the first to explore this family of penalty functions originating in high-dimensional statistics in the context of rule extraction.\n    \\item We show how encouraging fusion (in addition to vanilla sparsity) when extracting rules improves the interpretability and compression of the selected model.\n    \\item Optimization problems in \\textsc{Fire} are challenging due to problem scale and the non-convex penalties, so we develop a specialized solver for our framework. Our algorithm computes solutions up to \\textbf{40$\\times$} faster than off-the-shelf solvers on medium-sized problems (10000s of data points and decision variables) and can scale to larger problems.\n    \\item We show in our experiments that \\textsc{Fire} extracts sparse rule sets that outperform rule ensembles built by state-of-the-art algorithms, with up to a \\textbf{24\\%} decrease in test error. In addition, \\textsc{Fire} performs significantly better than RuleFit \\cite{friedman2008predictive}, a classical optimization-based rule extraction algorithm, with up to a \\textbf{46\\%} decrease in test error when extracting sparse models.\n\\end{itemize}\n\n\n\n\n\n% \\begin{itemize}\n\n%     \\item We introduce a novel optimization framework, \\textsc{Fire} that extracts rule ensembles from tr\n\n\n\n\n%     % \\item We introduce a novel optimization framework, \\textsc{Fire}, that extracts rule ensembles from tree ensembles using a non-convex sparsity inducing penalty and a fusion penalty.\n\n%     \\item We introduce a novel optimization framework, \\textsc{Fire}, that extracts decision rules \n\n%     \\item in order to do this we propose a non-convex + fusion \n    \n%     \\item We demonstrate how encouraging fusion when extracting decision rules improves model compression and interpretability.\n    \n    \n%     \\item optimization framework hard to scale, unique penalties + scalability issues + so we develop new solver to address this\n    \n%     \\item We develop a specialized solver to compute solutions to problems under our framework. Our solver performs up to 40$\\times$ faster compared to off-the-shelf solvers.\n%     \\item We show in our experiments that \\textsc{Fire} outperforms state-of-the-art rule ensemble algorithms at building interpretable sets of decision rules.\n% \\end{itemize}\n\n% We show in our performance experiments that \\textsc{Fire} extracts sparse rule sets that outperform state-of-the-art competing algorithms. We also show through real world examples the \n\n\n% We show in our experiments that \\textsc{Fire} extracts sparse rule sets that outperform state-of-the-art competing algorithms. In addition, we show that \\textsc{Fire}, with our specialized solver, can prune larger tree ensembles compared to what is possible with existing optimization-based rule extraction methods.\n\n% Our paper is organized as follows. We first introduce notation and overview rule extraction from tree ensembles. We then introduce our model framework and discuss the effects of our new penalties, along with their corresponding hyperparameters. We next present our specialized optimization algorithm along with timing experiments against off-the-shelf solvers. Finally, we present our experimental results comparing \\textsc{Fire} against competing algorithms and conclude by showcasing the improved interpretability of \\textsc{Fire} on a real world dataset. \n\n\n% % \\textsc{Fire}, Fast Interpretable Rule Extraction, is an optimization framework designed improve the interpretability and compactness of rule sets extracted from tree ensembles. The framework assigns a weight to each decision rule in the tree ensemble and selects a sparse rule ensemble by minimizing regularized loss, \n\n\n% \\textsc{Fire}, Fast Inteprtable Rule Extraction, is an optimization-based framework designed to improve the interpretability of \n\n\n\n% \\textsc{Fire}, Fast Interpretable Rule Extraction, is an optimization-based framework \n\n\n\n% % Extracting decision rules from tree ensembles is a challenging task. Tree ensembles can contain an enormous quantity of leaf nodes, since the number of leaves in a decision tree increases exponentially with tree depth. Ensembles such as full-depth random forests can contain hundreds of thousands to millions of leaves. This makes it difficult for optimization-based based methods to select a sparse subset of decision rules, due to the scale of the corresponding problem. In addition, tree ensembles often contain highly correlated leaf nodes/decision rules. For example, many decision trees in a bagging ensemble share the same structure of splits, which results in duplicated decision rules. Correlated rules further complicates sparse selection. A popular algorithm for rule extraction, RuleFit, is a LASSO-based method that inherits these scalability and correlation issues \\cite{friedman2008predictive}. \n% Finally, many existing rule extraction algorithms, including RuleFit \\cite{friedman2008predictive,benard2021sirus}, do not account for the tree structure of decision rules in an ensemble. Decision rules/leaf nodes adjacent to each other in a decision tree share many internal nodes/antecedents, and each decision tree in an ensemble contains a group of related rules. LASSO-based methods, such as RuleFit, penalizes the selection of all rules equally.\n\n% To address these challenges, we develop a new optimization framework for fast, interpretable rule extraction (\\textsc{Fire}). \\textsc{Fire} assigns a weight to each decision rule in a tree ensemble and sparsifies the ensemble by minimizing regularized loss. We introduce two new regularization penalties, a non-convex sparsity-inducing penalty to encourage aggressive selection between correlated rules and a fusion penalty to encourage rule grouping. We also develop a novel optimization algorithm to find high-quality solutions to problems in \\textsc{Fire}. By exploiting problem structure, our specialized solver allows for computation beyond the capabilities of off-the-shelf solvers, and as a result, \\textsc{Fire} can prune larger tree ensembles compared to existing rule extraction algorithms. Our experiments show that \\textsc{Fire} can rapidly extract sparse subsets of decision rules that outperform state-of-the-art competing algorithms and are easy to interpret.\n\n% To address these challenges, we develop a new optimization framework for fast, interpretable rule extraction (\\textsc{Fire}). \\textsc{Fire} assigns a weight to each decision rule in a tree ensemble and sparsifies the ensemble by minimizing regularized loss. We introduce two new regularization penalties, a non-convex sparsity-inducing penalty to encourage aggressive selection between correlated rules and a fusion penalty to encourage rule grouping. In addition, we develop a novel optimization algorithm to find high-quality solution to problems in \\textsc{Fire}. By exploting problem structure, our specialized solver allows for computation beyond the capabilities of off-the-shelf solvers, and as a result, \\textsc{Fire} can prune larger tree ensembles compared to existing rule extraction algorithms. Our experiments show that \\textsc{Fire} can rapidly extract sparse subsets of rules that outperform state-of-the-art competing algorithms and are easy to interpret.\n\n% \\subsection{Main Contributions}\n% We summarize the main contributions of our paper.\n% \\begin{itemize}\n%     \\item \n% \\end{itemize}\n\n"
                }
            },
            "section 2": {
                "name": "Preliminaries \\& Related Work",
                "content": "\nIn this section provide a cursory overview of decision trees, rules, and tree ensembles, and survey existing work on rule extraction. \n\n\n",
                "subsection 2.1": {
                    "name": "Decision Trees and Decision Rules",
                    "content": "\n\nGiven feature matrix $X \\in \\mathbb{R}^{N \\times P}$ and target $y \\in \\mathbb{R}^{N}$, decision tree $\\Gamma(X)$ maps $\\mathbb{R}^{N \\times P} \\rightarrow \\mathbb{R}^N$. A decision tree of maximum depth $d$ partitions the training data into at most $2^{d}$ non-overlapping partitions. Each partition, or leaf node, is defined by a sequence of at most $d$ splits and data points in a partition are assigned the mean (regression) or majority class (classification) for predictions. Each split is an if-then rule that thresholds a single feature; splits partition the data based on whether the feature value of a data point falls above or below that threshold. \n\nDecision rules are conjunctions of if-then antecedents that partition a dataset and assign a prediction to each partition \\cite{friedman2008predictive}. Decision trees can be viewed as a collection of decision rules, where each leaf node in the tree is a rule. The decision path to each leaf node is a conjunction of if-then antecedents and data points partitioned by these antecedents are assigned a prediction equal to the mean or majority class of the node.\n\nFor example, consider the decision tree shown in figure \\ref{tree_to_rules.fig}. Let $s_j$ denote the threshold for the split on feature $x_j$ and for each split let $x_j \\leq s_j$ denote the left path and let $x_j > s_j$ denote the right path. The rule obtained from leaf node $r_3$ can be represented as:\n    $r_3(x) =\\mathbbm{1}(x_1 > s_1 ) \\cdot \\mathbbm{1}( x_3 \\leq s_3  ) \\cdot v_3$, where $\\mathbbm{1}(x)$ is the indicator function and $v_3$ is the prediction value of leaf node $r_3$. More generally, the rule obtained from a leaf node whose decision path traverses $S$ splits can be expressed by:\n    $r(x) = \\prod_{j = 1} ^ S \\mathbbm{1}(x \\in \\sigma_j) \\cdot v$, where $\\sigma_j$ is the set of data points partitioned along the decision path by split $j$ and $v$ is the value of the node. \n\n\n"
                },
                "subsection 2.2": {
                    "name": "Tree Ensembles",
                    "content": "\n\nTree ensembles consist of a collection of $T$ decision trees, $\\{\\Gamma_t(X): t \\in [T]\\}$. This collection of trees can be obtained via \\emph{bagging} \\cite{breiman1996bagging}, where trees are trained in parallel on bootstrapped samples of the data, or through \\emph{boosting} \\cite{friedman2001greedy}, where dampened trees are added sequentially and trained on the residuals of the prior ensemble. \n\nRule ensembles (rule sets) are collections of decision rules with weights assigned to each rule. The prediction of a rule ensemble is obtained by taking the weighted linear combination of the rules. For example, we can obtain a rule ensemble from the decision tree in figure \\ref{tree_to_rules.fig} by assigning each rule $r_j(x)$ weight $w_j$. The prediction of the rule ensemble can be expressed as: $\\sum_{j=1}^{4} w_j r_j(x).$\n% $w_1 \\cdot r_1(x) + w_2 \\cdot  r_2(x) + w_3 \\cdot  r_3(x) + w_3 \\cdot  r_4(x)$. \n\nTree ensembles result in large collections of decision rules which can be extracted into sparse rule ensembles. We use the following notation to discuss extracting rule ensembles from trees. Consider a decision tree $\\Gamma_t$, fit on data matrix $X \\in \\mathbb{R}^{N \\times P}$, with $R_t$ leaf nodes. Each leaf node has prediction value $v_j$ for $j \\in [R_t]$. Recall that if data point $x_i$ reaches leaf node $r_j$, the data point is assigned prediction value $v_j$. %Define the following mapping matrix $M_t \\in  \\mathbb{R}^{N \\times R_t}$ entrywise as follows:\nWe define a mapping matrix $M_t \\in  \\mathbb{R}^{N \\times R_t}$ whose $(i,j)$-th entry is given by:\n\\begin{equation}\n    (M_t)^{ij} = \\begin{cases}\n    v_j & \\text{if data point $x_i$ reaches leaf node $r_j$} \\\\\n    0 & \\text{otherwise}.\n    \\end{cases}\n\\end{equation}\nMapping matrix $M_t$ maps data points to predictions. The matrix is sparse, with density $\\frac{1}{R_t}$, since each data point is routed to a single leaf in the decision tree. Let weight vector $w_t \\in \\mathbb{R}^{R_t}$ represent the weights assigned to each leaf node; $M_t$ and $w_t$ define the rule ensemble obtained from $\\Gamma_t$. The prediction of this rule ensemble is given by $M_t w_t$. \n\nFor an ensemble of $T$ trees, define $M_t$ for each tree $t \\in [T]$. Let $R = \\sum_{t=1}^T R_t$ denote the total number of rules (nodes) in the ensemble and denote the mapping matrix $M \\in \\mathbb{R}^{N \\times R}$ as $M = [M_1, M_2, \\ldots M_T].$\nMatrix $M$ is also sparse with density $\\frac{T}{R}$. Given weight vector, $w \\in \\mathbb{R}^R$, the prediction of this rule ensemble is $Mw$. To extract rules, we fit weight vector $w$; setting an entry of $w$ to zero prunes the corresponding rule from the ensemble.\n\n\n\n"
                },
                "subsection 2.3": {
                    "name": "Related Work",
                    "content": "\n\n\nExtracting decision rules from tree ensembles was first introduced in 2005 by RuleFit \\cite{friedman2008predictive}. Following the notation introduced above, RuleFit selects a subset of rules by minimizing the $\\ell_1$-regularized optimization problem (aka LASSO): \n\\begin{mini}|s|\n{w}{(1/2)\\left\\|y-M w\\right\\|_{2}^{2} + \\lambda \\left\\|w \\right\\|_1,}{\\label{rulefit_problem}}{}\n\\end{mini}\nwhich penalizes the $\\ell_1$ norm of the weights $w$. RuleFit uses LASSO solvers to compute a solution $w$ to Problem~\\eqref{rulefit_problem}.\n\n\nSubsequently, various algorithms to post-process or generate rule ensembles have been proposed. Node Harvest \\citep{meinshausen2010node} uses the non-negative garrote and quadratic programming to select rule ensembles from tree ensembles. More recently, SIRUS \\citep{benard2021sirus} uses stabilized random forests to build and aggregate rule sets, and GLRM \\citep{wei2019generalized} uses column generation to create rules from scratch. To the best of our knowledge, \\textsc{Fire} is the first framework that incorporates improved sparse selection and rule groupings within a holistic optimization framework. We show in our experiments that \\textsc{Fire} outperforms SIRUS and GLRM at selecting sparse human-readable rule sets.\n\n\n\n\nExisting optimization-based rule extraction algorithms, such as RuleFit, face several challenges due to the structure of tree ensembles. The number of variables in the optimization problem (i.e. the number of leaves in the tree ensemble) increases exponentially with tree depth, as shown in the left plot in figure \\ref{challenges_example.fig}. RuleFit uses cyclic coordinate descent to solve the LASSO, which becomes expensive when the number of coordinates is large. As a result, RuleFit is restricted for use on shallow tree ensembles. We show in \\S\\ref{optimization_algo.section} that our specialized optimization algorithm for \\textsc{Fire} is robust to the depth of the ensemble and scales substantially better than the LASSO solvers used by RuleFit.\n\nAn important difference between \\textsc{Fire} and RuleFit stems from a simple yet critical observation: shallow tree ensembles contain many correlated decision rules.\nThe right plot in figure \\ref{challenges_example.fig} shows the pairwise correlations between the columns of M on a depth $2$ ensemble of 500 trees; many pairs of columns have correlation scores close to 1. This further complicates rule extraction, since LASSO performs poorly at sparse selection on highly correlated features \\cite{hebiri2012correlations, sun2020correlated,hazimeh2022l0learn}. Earlier work in high-dimensional statistics proposes the use of non-convex penalties, which performs better at sparse selection in the presence of correlation \\cite{zhang2010nearly,mazumder2011sparsenet}.\n\n\n% We show in \\S\\ref{framework.section} that the non-convex sparsity-inducing penalty in \\textsc{Fire} can approximate the $\\ell_0$-penalty, which performs well at sparse selection on correlated features \\cite{hastie2020best,hazimeh2022l0learn}.\n\n\n\n\n\n\n\n% \\subsection{Rule Extraction Challenges}\n% We discuss here in further detail the challenges that existing optimization-based methods face when extracting decision rules from tree ensembles.\n\n% % \\subsubsection{Problem Scale}\n\n% Optimization-based rule extraction methods struggle to scale when extracting rules from deep tree ensembles. The number of variables in the optimization problem (i.e., the number of leaves in the tree ensemble) increases exponentially with tree depth. For example, the left plot in figure \\ref{challenges_example} shows the number of leaf nodes versus the depth of tree ensembles with 500 trees fit on the Elevators dataset \\cite{OpenML2013}. The depth 6 tree ensemble contains $\\sim$30000 decision rules and all of the tree ensembles with depth greater than 15 contain over a million rules.\n\n% RuleFit applies cyclic coordinate descent (CD) to compute solutions to Problem ~\\eqref{rulefit_problem}. This approach is only computationally feasible for very shallow ensembles. RuleFit \\cite{friedman2008predictive} suggests restricting the maximum depth of trees in the ensemble to $d \\leq 3$ to reduce computation time and improve interpretability. As a result, the models extracted are unable to capture higher-order interactions.\n% Likewise, quadratic programming (QP) solvers, used by methods such as Node Harvest, also struggle to scale when the number of variables becomes large.\n\n% Restricting the interaction depth of the tree ensemble before extracting decision rules may be insufficient for reducing problem scale. The space of candidate rules, given a fixed interaction depth, still increases exponentially with the number of features in the dataset. To extract rule ensembles that perform well on high-dimensional data, it may be necessary to build large ensembles with many leaves to explore this candidate rule space. Cyclic CD and QP solvers still struggle to solve these large optimization problems. \n\n% We show in \\S\\ref{optimization_algo.section} that \\textsc{Fire} uses a specialized optimization algorithm to address this challenge.\n\n% \\subsubsection{Correlated Rules}\n% Tree ensembles, especially the shallow (depth $\\leq$ 3) ensembles suggested in RuleFit, contain many similar decision trees. As a result, the decision rules in the ensemble are correlated. Since each column of $M$ contains the predictions assigned by a decision rule to the training observations, the columns of $M$ are highly correlated as well. The right plot in figure \\ref{challenges_example} shows the pairwise correlations between the columns of $M$ on a depth 2 tree ensemble of 500 trees, fit on the same dataset as above; many columns are highly correlated with scores close to 1.\n\n% RuleFit uses the LASSO to extract rules, which performs poorly at sparse selection on highly correlated features \\cite{hebiri2012correlations, sun2020correlated}. Feature selection methods that do not encourage shrinkage, such as best subset selection \\cite{bertsimas2016best}, $\\ell_0$-regularized regression \\cite{hazimeh2022l0learn}, and forward step-wise selection \\cite{hocking1976biometrics}, have been shown to outperform LASSO in this setting \\cite{hastie2020best}. We show in \\S\\ref{framework.section} that \\textsc{Fire} introduces a non-convex reduced-bias regularization penalty, that can approximate $\\ell_0$-regularization, to address this challenge. \n\n% \\subsubsection{Summary}\n\n% Existing optimization-based rule extraction methods face several challenges due to the nature of tree ensembles. The number of decision rules in a tree ensemble increases exponentially with tree depth, and existing algorithms struggle to sparsify deep ensembles due to the size of the corresponding optimization problem. Limiting the depth of trees in an ensemble has its own challenges as shallow tree ensembles contain many highly correlated decision rules. This makes it difficult to select sparse subsets of rules using methods such as the LASSO.\n\n% \\textsc{Fire} addresses these challenges by using a specialized optimization algorithm that is robust to tree depth and by using a reduced-bias regularization penalty. The framework also incorporates a new fusion penalty to improve the interpretability of the selected ensemble. We present our framework in detail in the sections below.\n\n\n% RuleFit applies cyclic coordinate descent (CD) to compute a solution $w$ to Problem~\\eqref{rulefit_problem}. This approach only works for very shallow ensembles, since the number of leaves in an ensemble (i.e, coordinates to update) increases exponentially with tree depth. RuleFit \\cite{friedman2008predictive} suggests restricting the maximum depth of trees in the ensemble to $d \\leq 3$ to reduce computation time and improve interpretability. As a result, the models extracted by RuleFit are unable to capture higher-order interactions. Even for shallow interactions, the space of candidate rules increases exponentially with the number of features. To extract rule ensembles that perform well on high-dimensional data, it may be necessary to build large ensembles with many leaves to explore this candidate rule space. For these problems, cyclic CD again struggles to converge as the associated optimization problems are large.\n\n% Each column of $M$ contains the values assigned by a leaf node to the training observations. Tree ensembles, especially short bagging ensembles, contain many similar trees, so the columns of $M$ are correlated. This makes it especially difficult for RuleFit to select sparse rule sets \n% %due to the bias imparted by \n% via $\\ell_1$-regularization \\citep{mazumder2011sparsenet}. In addition, the $\\ell_1$-regularizer in RuleFit\n% penalizes each leaf node equally and ignores the fact that leaves from the same tree share internal nodes (antecedents). Selecting two adjacent nodes from a decision tree adds half as many antecedents to a rule ensemble compared to selecting two nodes from different trees.\n\n\n\n\n\n"
                }
            },
            "section 3": {
                "name": "Proposed Modeling Framework",
                "content": "\n\\label{framework.section}\nIn this section, we present our model framework and discuss in detail the effects of our non-convex sparsity-inducing penalty and fusion penalty on decision rule extraction.\n\nConsider a tree ensemble with $T$ decision trees $\\{\\Gamma_t(X): t \\in [T]\\}$. Each decision tree has $R_t$ leaf nodes and mapping matrix $M_t \\in \\mathbb{R}^{N \\times R_t}$. The ensemble has $R = \\sum_{t=1}^T R_t$ leaf nodes and mapping matrix $M \\in \\mathbb{R}^{N \\times R}$. \\textsc{Fire} selects a sparse subset of rules by learning weights $w$ by solving:\n\\begin{mini}|s|\n{w}{f(w) +  h(w, \\lambda_s) + g(w, \\lambda_f), }{\\label{main_prob}}{}\n\\end{mini}\nwhere $f(w) = (1/2)\\left\\|y-M w\\right\\|_{2}^{2}$ is quadratic loss that measures data-fidelity, $h$ is the sparsity penalty with regularization parameter $\\lambda_s$, and $g$ is the fusion penalty with parameter $\\lambda_f$.\n\n",
                "subsection 3.1": {
                    "name": "Sparsity-Inducing Penalty",
                    "content": "\n\nWe discuss possible choices for sparsity-inducing penalty $h$. One baseline choice is the LASSO from RuleFit where, $h(w, \\lambda_s) = \\lambda_s \\sum_{j=1}^R |w_j|$. However, this $\\ell_1$-penalty encourages heavy shrinkage and bias in $w$, which makes the LASSO a poor choice for sparse variable selection in the presence of correlated variables \\cite{hebiri2012correlations,hazimeh2022l0learn}. \n%The objective of \\textsc{Fire} is to extract a sparse subset of decision rules from an ensemble that contains many correlated rules, so we wish to use a sparsity-inducing penalty with less bias.\nSince we intend to perform sparse selection from a collection of correlated rules, we use a non-convex penalty which incurs less bias than LASSO.\n\nMany unbiased and nearly unbiased penalty functions exist, such as the $\\ell_0$-penalty \\cite{hazimeh2022l0learn}, the smoothly clipped absolute deviation (SCAD) penalty \\cite{fan2001variable}, and the minimax concave plus (MCP) penalty \\cite{zhang2010nearly}.\n%%; these penalty functions all perform aggressive %%variable selection. \n\\textsc{Fire} uses the MCP penalty since it is continuous and sub-differentiable---properties that will come in handy when we develop our optimization solver. We set $h$ as:\n\\begin{equation}\n    h(w, \\lambda_s) = \\sum_{j=1}^R P_{\\gamma}(w_j, \\lambda_s),\n\\end{equation}\nwhere $P_{\\gamma}(w_j, \\lambda_s)$ is the MCP penalty function defined by:\n\\begin{equation}\n    P_{\\gamma}(w_j,\\lambda_s) = \\begin{cases} \n\\lambda_s |w_j|  - \\frac{{w_j}^2}{2 \\gamma} &\\text{if } |w_j| \\leq \\lambda_s \\gamma \\\\\n \\frac{1}{2}\\gamma \\lambda_s^2 & \\text{if } |w_j| > \\lambda_s \\gamma, \\end{cases}\n\\end{equation}\nand $\\gamma > 1$ is a hyperparameter that (loosely speaking) controls the concavity of the penalty function. As $\\gamma \\sim \\infty$, the penalty behaves like the LASSO, and when $\\gamma \\sim 1^+$ it operates like the $\\ell_0$-penalty. \n\n\n\n%As $\\gamma \\xrightarrow[]{} \\infty$, penalty function $P_\\gamma(w_j, \\lambda_s) \\xrightarrow[]{} \\lambda_s |w_j|$; for large values of $\\gamma$ the MCP penalty behaves like the $\\ell_1$-penalty. As $\\gamma \\xrightarrow[]{} 1^{+}$, the MCP penalty function behaves like the $\\ell_0$-penalty: $\\lambda_s \\left\\|w_j\\right\\|_0$. We further discuss the effect of $\\gamma$ on the MCP penalty function in \\S\\ref{param_selection.section}.\n\n%As $gamma \\sim infty$, the penalty behaves like the Lasso and when $gamma \\sim 1+$ it operates like the the L0 penalty.\n\n\n\n"
                },
                "subsection 3.2": {
                    "name": "Fusion Penalty",
                    "content": "\n\\label{fusion.section}\nIn addition to sparse selection, we also present a framework \nto encourage rule fusion. To this end, we use a fused LASSO penalty \\citep{tibshirani2005sparsity} to encourage contiguity in the leaf nodes (rules) selected or pruned from within each tree. The fused LASSO penalizes the sum of absolute differences between the coefficients and is commonly used for piecewise constant signal approximation \\cite{hoefling2010path}. Here, we explore how this classical penalty function can be used to improve rule extraction.\n\nLet $w_t \\in \\mathbb{R}^{R_t} $ represent the sub-vector of weights in $w$ that correspond to tree $\\Gamma_t$ and let $(w_t)_j$ denote the $j$-th entry of $w_t$. We set $g$ as:\n\\begin{equation}\n    g(w, \\lambda_f) = \\lambda_f \\sum_{t=1}^T \\left\\| D_t w_t \\right\\|_1\n\\end{equation}\nwhere $D_t \\in \\{\\text{-} 1, 0 ,1 \\}^{( R_t - 1) \\times R_t}$ is the tree fusion matrix with $(D_t)_{ij} = -1$ for all $i = j$ and $(D_t)_{ij} = 1$ for all $i = j - 1$. We have that:\n\\begin{equation}\n    \\left\\|D_t w_t\\right\\|_1 = \\sum_{j = 2}^{R_t} | (w_t)_j - (w_t)_{j-1}|.\n    \\label{fusion_penalty.eq}\n\\end{equation}\nThis penalizes the absolute value of the differences of the fitted weights in each tree. As a result, in problem~\\eqref{main_prob}, for larger values of $\\lambda_f$, the nodes assigned zero weights and pruned (and the nodes assigned non-zero weights and selected) are grouped together in each tree. In what follows we provide some intuition into why this can be appealing to a practitioner. \n%%We describe why this is useful below.\n\n\n",
                    "subsubsection 3.2.1": {
                        "name": "Compressing Trees",
                        "content": "\nBy grouping pruned leaf nodes together, we increase the number of internal nodes removed from a tree, since an internal node whose children are pruned is removed as well. Consider this example in figure \\ref{fusion_compression.fig}.\n\n\n\n\nIn both plots, we prune 16 out of the 32 leaf nodes from a depth 5 decision tree fit on the California Housing Prices dataset \\citep{OpenML2013}. In the left plot the pruned leaves are noncontiguous so \\textbf{0} internal nodes are removed; the pruned tree contains \\textbf{47} total (leaf + internal) nodes. In contrast, the pruned leaves are grouped in the right plot. Consequently, \\textbf{13} additional internal nodes are removed and the pruned tree contains \\textbf{34} total nodes. Both trees incur the same rule sparsity penalty of 16 leaves, but the right tree contains 28\\% fewer total nodes. The fusion penalty $g$ encourages grouping in the leaf nodes pruned from each tree which further compresses tree ensembles compared to only regularizing for sparsity in the leaves.\n\n\n\n"
                    },
                    "subsubsection 3.2.2": {
                        "name": "Grouping Rules",
                        "content": "\nGrouping the rules selected from each tree improves model interpretability since grouped rules share antecedents. In figure \\ref{fusion_groupings.fig}, we select 4 rules from the decision tree shown in figure \\ref{fusion_compression.fig}. The left plot selects rules that are spread out and the right plot selects rules that are grouped.\n\nConsider the task of interpreting all interaction effects in the rule ensemble up to depth 3. The 4 rules in the right ensemble share the antecedents: $\\mathbbm{1}(\\text{MedInc} > s_1)$, $\\mathbbm{1}(\\text{AveRooms} > s_2)$, and $\\mathbbm{1}( \\text{Longitude}  > s_3)$. A user would need to analyze \\textbf{3} antecedents to interpret the interactions. For the left ensemble, a user would need to analyze \\textbf{7} antecedents to interpret all depth 3 interactions.\n\nFusion regularizer $g$ \\eqref{fusion_penalty.eq} introduces a more natural way of penalizing the complexity of the selected rules. Consider selecting two leaf nodes; the first leaf node shares a parent node with a leaf that has already been selected and the second leaf node is on a branch where no leaves have been selected. Selecting the first leaf adds no internal nodes (antecedents) to the rule ensemble while selecting the second leaf can add up to $d$ new antecedents. Sparsity regularizer $h$ penalizes both choices equally but the fusion regularizer incurs an additional penalty for the second choice.\n\n\n"
                    }
                },
                "subsection 3.3": {
                    "name": "Hyperparameters",
                    "content": "\n\\label{param_selection.section}\n\nWe discuss how to select good values for hyperparameters in \\textsc{Fire}. We denote $\\lambda_s$ as the sparsity hyperparameter, $\\gamma$ as the concavitiy hyperparameter, and $\\lambda_f$ as the fusion hyperparameter.\n\n",
                    "subsubsection 3.3.1": {
                        "name": "Sparsity",
                        "content": "\nSparsity hyperparameter  $\\lambda_s$ generally controls the number of rules extracted from the tree ensemble, i.e., the number of nonzero entries in $w$. We can use warm start continuation to efficiently compute the entire regularization path of $w$ across $\\lambda_s$ with the other hyperparameters held fixed. We start with a value of $\\lambda_s$ sufficiently large such that $w^* = \\textbf{0}$ and decrement $\\lambda_s$, using the previous solution as a warm start to Problem \\ref{main_prob}, until the full model is reached \\citep{friedman2007pathwise}. This procedure allows a practitioner to quickly evaluate rule ensembles of different sizes. Given any fixed configuration of $\\gamma$ and $\\lambda_f$, it is easy to select $\\lambda_s$; we compute the regularization path for the hyperparameter and find the value of $\\lambda_s$ that minimizes validation loss.\n\n\n"
                    },
                    "subsubsection 3.3.2": {
                        "name": "Concavity",
                        "content": "\n\nConcavity hyperparameter $\\gamma$ controls the trade-off between shrinkage and selection in the MCP penalty. When $\\gamma \\xrightarrow[]{} 1^{+}$, the MCP penalty aggressively performs nearly unbiased selection. When $\\gamma \\xrightarrow[]{} \\infty$, the MCP penalty encourages regularization through shrinkage.\n\n\n\n\nThe left plot in figure \\ref{sensitivity_analysis.fig} demonstrates this effect on extracting rules from a tree ensemble fit on the US Communities and Crime dataset \\cite{OpenML2013}. We conduct a sensitivity analysis on the MCP penalty by varying $\\gamma \\in \\{1.1, 3, 10\\}$ and computing the regularization path of $\\lambda_s$ for each value of $\\gamma$. The horizontal axis shows the number of rules extracted \nand the vertical axis shows the test performance of the selected model. The right plot in figure \\ref{sensitivity_analysis.fig} shows the corresponding shape of the MCP penalty function.\n\nWhen $\\gamma \\xrightarrow[]{} 1^{+}$, the MCP penalty performs better at selecting very sparse subsets of rules, due to the reduced bias of the more concave penalty \\cite{zhang2010nearly}. However, this aggressive selection can possibly result in overfitting in low-signal regimes. Increasing $\\gamma$ increases the shrinkage imparted by the MCP penalty, which regularizes the model and reduces overfitting. As $\\gamma$ increases, the model is less likely to overfit in the low regularization regime (RHS of figure \\ref{sensitivity_analysis.fig}) but performs worse at sparse selection (LHS of figure \\ref{sensitivity_analysis.fig}).\n\nSelecting the best value for $\\gamma$ depends on the use case for \\textsc{Fire}. When using \\textsc{Fire} to select very sparse rule ensembles, we recommend  setting $\\gamma$ to be close to $1^{+}$. Otherwise, %%fix a loose grid of potential \nwe consider a small number of possible\n$\\gamma$ values and for each value, we compute the regularization path for $\\lambda_s$. We use validation-tuning to select an appropriate $(\\lambda_s, \\gamma)$ pair.\n%%%%%that minimizes validation loss. \nOur framework's ability to use warm-start continuation to compute regularization paths for $\\lambda_s$ makes this 2-dimensional tuning computationally efficient.\n\n\n\n% The best value for $\\gamma$ depends on the use case of $\\textsc{Fire}$. If a very sparse rule ensemble is to be extracted, $\\gamma$ should be set close to 1 to encourage unbiased selection. In addition, $\\gamma$ should be set close to 1 if the original tree ensemble contains highly correlated rules \\cite{hastie2020best}. On noisier datasets, $\\gamma$ should be increased to encourage regularization and prevent overfitting. \n\n\n"
                    },
                    "subsubsection 3.3.3": {
                        "name": "Fusion",
                        "content": "\n\nFusion hyperparameter $\\lambda_f$ influences the interpretability of the extracted rule ensemble. Increasing $\\lambda_f$ encourages more fused rules which are easier to interpret. The best value of $\\lambda_f$ is use-case specific, and we observe empirically that values of $\\lambda_f \\in [0.5 \\lambda_s , 2 \\lambda_s]$ work well. We show in our case study in \\S\\ref{interpretability_case.section} the effect of $\\lambda_f$ on the interpretability of the selected ensemble. Increasing $\\lambda_f$ also adds additional regularization, which may be useful for preventing overfitting on noisy datasets.\n\n\n"
                    }
                }
            },
            "section 4": {
                "name": " Optimization Algorithm",
                "content": "\n\\label{optimization_algo.section}\nWe present our specialized optimization algorithm to efficiently obtain high-quality solutions to problem \\eqref{main_prob}. Note that the smooth loss function and non-smooth regularizers in problem \\eqref{main_prob} are separable across blocks $w_t$'s, where each block represents a tree in the ensemble. Motivated by the success of block coordinate descent (BCD) algorithms for large-scale sparse regression \\citep{friedman2010regularization, hazimeh2022l0learn}, we apply the method to problem \\eqref{main_prob}. As we discuss below, our proposed algorithm has notable differences: we make use of a block structure to perform updates---taking advantage of a structure that naturally arises from the tree ensemble. Also, a direct application of cyclic coordinate descent approaches can be quite expensive, so we use a greedy selection rule motivated by the success of greedy coordinate descent for LASSO problems \\cite{karimireddy2019efficient,fang2020greed}. This results in important computational savings, as our experiments in \\S\\ref{computation_time_experiment} show.\n\n%%As we discuss below, our proposed algorithm has notable differences: we make use a block sructure to perform updates --- making use of a structure that aruses from the tree-ensemble. A direct application of cyclic CD approaches can be quite expensive, so we use a greedy seelction rule (motivated by bla) which results in important computational savings as out experiments show.  \n\n\n",
                "subsection 4.1": {
                    "name": "Block Proximal Updates",
                    "content": "\\label{blockupdate.section}\nWe make use of a natural blocking structure that arises in our tree ensemble. Specifically, each block $t$ corresponds to a tree in the ensemble with mapping matrix $M_t$ and associated weights $w_t \\in \\mathbb{R}^{R_t}$. For a fixed block $t$, let $\\delta$ denote the other blocks. The goal of a block update is to update weights $w_t$ while holding everything else constant. The optimization criterion for each block update is:\n\\begin{mini}|s|\n{w_t}{f(w_t) +  h(w_t, \\lambda_s) + g(w_t, \\lambda_f)}{\\label{blockupdate_problem}}{}\n\\end{mini}\nwhere  $f(w_t) = \\frac{1}{2} \\left\\| \\hat{y}_{\\delta} - M_t w_t \\right\\|_2^2$ and $\\hat{y}_{\\delta} = y - M_{\\delta} w_{\\delta}$. This composite criterion has smooth loss function $f$ and non-smooth regularizers $h$ and $g$, so we apply (block) proximal gradient updates~\\citep{beck2009fast,nesterov2018lectures}.\n\nThe function $w_{t} \\mapsto f(w_t)$ has Lipschitz continuous gradient and satisfies $\\left\\| \\nabla f(u) - \\nabla f(v) \\right\\| \\leq L_t \\left\\| u - v \\right\\|$,\nfor all $u$ and $v$, where $L_t$ is the largest eigenvalue of $M_t^\\intercal M_t$. At point $w_t^k$ each proximal update minimizes the quadratic approximation of objective \n\\eqref{blockupdate_problem} and can be expressed as:\n\\begin{argmini}|s|{\\theta}{(L_t/{2}) \\| \\theta - \\hat{\\theta} \\|_2^2 +  h(\\theta, \\lambda_s) + g(\\theta, \\lambda_f),}{\\label{blockupdate_proximal_obj}}{w_t^{k+1} = }\n\\end{argmini}\nwhere $\\hat{\\theta} = w_t^k - \\frac{1}{L_t} \\nabla f(w_t^k)$. Our choice of step size $\\frac{1}{L_t}$ ensures that the proximal updates lead to a sequence of decreasing objective values \\citep{beck2009fast}. We show that univariate problem \\eqref{blockupdate_proximal_obj} has closed-form minimizers $\\theta^*$ for all choices of sparsity penalty $h$ when $g = 0$, and can be rapidly solved using dynamic programming when fusion penalty $g$ is introduced.\n\n\n",
                    "subsubsection 4.1.1": {
                        "name": "Sparsity Only",
                        "content": "\nConsider the case where $\\gamma_f = 0$ and $g(\\theta,\\gamma_f) = 0$. For $h(\\theta, \\lambda_s) = \\lambda_s \\left\\|\\theta \\right\\|_1$, the closed-form minimzer to problem \\eqref{blockupdate_proximal_obj} is equal to $\\theta^* = S_{(\\lambda_s/L_t)}(\\hat{\\theta})$, where $S_{\\lambda}$ is the soft-thresholding operator given elementwise by: $S_{\\lambda}(\\hat{\\theta}_j) = \\text{sign}(\\hat{\\theta}_j)(|\\hat{\\theta}_j| - \\lambda|)_+$.\n%\\begin{equation}\n%    S_{\\lambda}(\\hat{\\theta}_j) = \\text{sign}(\\hat{\\theta}_j)(|\\hat{\\theta}_j| - \\lambda)_+.\n%\\end{equation}\nThis expression is obtained through computing subgradient optimality conditions for problem \\eqref{blockupdate_proximal_obj} \\citep{beck2009fast}. We can repeat this procedure with $h(\\theta, \\lambda_s)$ as the MCP sparsity penalty. The closed-form minimizer to problem \\eqref{blockupdate_proximal_obj} is given elementwise by,\n\\begin{equation}\n\\label{mcp_threshold_operator}\n    \\theta_j^* = \\begin{cases}\n                \\frac{\\gamma}{\\gamma - 1} S_{\\frac{\\lambda_s}{L_t}}(\\hat{\\theta}_j) & \\text{if } |\\hat{\\theta}_j| \\leq  \\frac{\\lambda_s \\gamma}{L_t} \\\\\n                \\hat{\\theta}_j & \\text{if } |\\hat{\\theta}_j| >  \\frac{\\lambda_s \\gamma}{L_t}.\n                \\end{cases}\n\\end{equation}\nDenote expression \\eqref{mcp_threshold_operator} as the MCP thresholding operator.\nAs $\\gamma \\xrightarrow[]{} \\infty$ the operator behaves like soft-thresholding and as $\\gamma \\xrightarrow[]{} 1^{+}$ the operator behaves like hard-thresholding. Derivations for both minimizers are presented in the supplement (suppl. C.1 \\& C.2).\n\n"
                    },
                    "subsubsection 4.1.2": {
                        "name": "Sparsity with Fusion",
                        "content": " Now consider the case where the fusion penalty $g$ is nonzero. We start with sparsity penalty set to zero: $\\lambda_s = 0$ and $h(\\theta,\\lambda_s) = 0$. Problem \\eqref{blockupdate_proximal_obj} can be re-expressed as:\n\\begin{argmini}|s|{\\theta}{(1/2) \\| \\theta - \\hat{\\theta} \\|_2^2  + (\\lambda_f/L_t) \\left\\|D_t \\theta \\right\\|_1, }{\\label{fused_proximal_obj}}{}\n\\end{argmini}\nwhich is equivalent to the 1-dimensional fused lasso signal approximation problem (FSLA), with fusion penalty parameter $\\frac{\\lambda_f}{L_t}$. This FSLA problem can be solved efficiently using the dynamic programming algorithm proposed by \\cite{johnson2013dynamic}, in linear worst-case time complexity with respect to the number of training observations.\n\nGiven the solution to problem \\eqref{fused_proximal_obj}, $\\theta^*(0,\\lambda_f)$,\nwe can find the solution to problem \\eqref{blockupdate_proximal_obj}, $\\theta^*(\\lambda_s,\\lambda_f)$, for any $\\lambda_s > 0$ by applying the soft-thresholding operator to  $\\theta^*(0,\\lambda_f)$ if $h$ is the $\\ell_1$-penalty, or by applying the MCP thresholding operator if $h$ is the MCP penalty. We derive these procedures in the supplement (suppl. C.3 \\& C.4).\n\n%%%%%\\subsubsection{Discussion}\nFor improved computational performance, we conduct 5-10 proximal gradient iterations for each block update by solving \\eqref{blockupdate_proximal_obj}. This problem either has a closed-form minimizer or can be solved in O($N$) time complexity, so blocks can be efficiently updated in constant or linear time.  In the following section, we present a method to prioritize the selection of blocks.\n\n"
                    }
                },
                "subsection 4.2": {
                    "name": "Block Selection",
                    "content": "\nWe first discuss unguided block selection methods. Cyclic block selection cycles through blocks $\\{1 \\ldots T\\}$ and updates them one at a time until convergence, while randomized block selection updates a random block at each iteration. BCD algorithms that use unguided block selection are typically slow; guided greedy block selection can greatly reduce computation time \\citep{nutini2015coordinate}. We present a novel greedy block selection heuristic for problem \\eqref{main_prob}.\n\nGreedy selection uses heuristics to find the best block or coordinate to update at each iteration. For example, the Gauss Southwell steepest direction (GS-s) rule picks the steepest coordinate as the best coordinate to update. For smooth functions, this corresponds to the coordinate with the largest gradient magnitude. For composite functions, the steepest direction is computed with respect to the subgradients of the regularizers \\citep{karimireddy2019efficient}. For our composite objective in problem \\eqref{main_prob} define the  direction vector $d \\in \\mathbb{R}^R$ elementwise by:\n \\begin{mini}|s|\n{s \\in \\partial h_j + \\partial g_j}{| \\nabla_j f(w) + s |.}{\\label{steepest_direction_vector}}{d_j =}\n\\end{mini} \nThe GS-s rule selects the entry of $d$ with the largest magnitude as the best coordinate to update. To find the best block to update, we modify the GS-s rule following Nutini et al. (2017)\\cite{nutini2017let} and select the block whose direction vector has the largest magnitude. Let $[T]$ represent the set of all blocks and $d_t \\in \\mathbb{R}^{R_t}$ represent the elements of $d$ associated with block $t$. Select the best block to update $t^*$ via:\n \\begin{argmaxi}|s|\n{t \\in [T]}{\\left\\| d_{t} \\right\\|.}{\\label{steepest_block_selection}}{t^* = }\n \\end{argmaxi}\n Problems \\eqref{steepest_direction_vector} and \\eqref{steepest_block_selection} form our greedy block selection heuristic. Our heuristic is only useful if problem \\eqref{steepest_direction_vector} can be efficiently solved. Karimireddy et al. (2019) \\cite{karimireddy2019efficient} derives a closed-form minimizer for this problem  when $h$ is the $\\ell_1$-penalty and $g=0$. Our algorithm is novel in that we derive closed-form minimizers to find $d$ when fusion penalty $g$ is introduced, and when $h$ is the MCP penalty. This requires computing the subgradients of a modified fused LASSO problem \\citep{tibshirani2011solution} and the MCP penalty function; the derivation is lengthy and is presented for all penalties in the supplement (suppl. D).\n \n",
                    "subsubsection 4.2.1": {
                        "name": "Discussion",
                        "content": "\nOur greedy block selection heuristic drastically reduces the number of BCD iterations as we demonstrate below. Fit a tree ensemble of 250 trees (blocks) with 7500 leaves (rules) on the Stock Price Prediction dataset \\citep{OpenML2013}, which contains 1000 rows.\nSelect a sparse rule ensemble from~\\eqref{main_prob} for various choices of $h$ and $g$, with $\\lambda_s = 1$, $\\lambda_f = 0.5$, and $\\gamma = 1.1$. Compare the progress of our algorithm using cyclic block selection versus greedy block selection. From figure \\ref{greedy_v_cyclic.fig} we observe that greedy BCD requires 2 orders of magnitude fewer iterations compared to cyclic BCD. Greedy BCD iterations are costlier than cyclic BCD iterations since finding the steepest direction vector at each iteration requires computing the full gradient. However, greedy BCD drastically reduces computation time. Here, greedy BCD takes \\textbf{8.5} seconds for~\\eqref{main_prob} with the MCP and fusion penalty, while cyclic BCD takes \\textbf{702} seconds. The timing results for the other configurations are shown in figure \\ref{greedy_v_cyclic.fig}.\n\n\n\n\n"
                    }
                },
                "subsection 4.3": {
                    "name": "Putting Together the Pieces",
                    "content": "\n\\begin{algorithm}\n\\scriptsize \n\\caption{Greedy Block Coordinate Descent (GBCD) Solver  }\n\\label{gbcdalgo}\n\\DontPrintSemicolon\n  \n  \\KwInput{y, \\ $M$, \\ $\\lambda_s$, \\ $\\lambda_f$, \\ $\\gamma$, \\ $[T]$}\n  \n  \\textbf{Initialize} $w = \\textbf{0}$ \n \n  \\Repeat{objective no longer improves}{\n  \n  Find steepest direction vector $d$: \\textcolor{blue}{Problem \\eqref{steepest_direction_vector}}\n  \n  Select block $t$: \\textcolor{blue}{Problem \\eqref{steepest_block_selection}}\n\n  \\RepeatFor{5 to 10 iterations}{\n  Proximal block update $w_{t}$: \\textcolor{blue}{Problem \\eqref{blockupdate_proximal_obj}}\n  } }\n\n\\textbf{optional} sweep through all blocks to check convergence. \\label{optional_convergence_check}\n  \n  \\KwOutput{w}\n\\end{algorithm}\n\n\nAlgorithm \\ref{gbcdalgo} presents our greedy block coordinate descent (GBCD) algorithm. Our algorithm is efficient; the block selection problems have closed-form minimizers and the block update problems either have closed-form minimizers or can be solved in linear $0(N)$ worst-case time complexities. We include step \\ref{optional_convergence_check} as an optional step where we conduct cyclic block coordinate descent sweeps to ensure that our algorithm converges. In practice, we observe that usually only a single pass over the blocks is needed to verify convergence. \n\n\n"
                },
                "subsection 4.4": {
                    "name": "Computation Time Experiment",
                    "content": "\n\\label{computation_time_experiment}\nHere we compare the computation time of GBCD against existing off-the-shelf optimization solvers. Since the MCP and fusion penalties are novel to our framework, we use GBCD to solve problem \\eqref{main_prob} with $h$ set as the $\\ell_1$-penalty and $g = 0$. \nThis optimization problem is the same as the one in RuleFit, so we can directly compare our GBCD algorithm against existing LASSO solvers.\n\n",
                    "subsubsection 4.4.1": {
                        "name": "Medium-Sized Problems",
                        "content": "\nWe build a random forest of 250 trees grown to depths 3, 5, and 7 and use GBCD to sparsify the ensemble with $\\lambda_s = 0.1$. Under this configuration, GBCD typically selects 20\\% of the rules. This represents a realistic use case for RFOP; users compute the regularization path up to some sparsity level and select the best model. With $\\lambda_s = 0.1$, we show the computation time required for a single solve near the middle of the path.\n\nWe compare GBCD against the Python implementation of RuleFit \\citep{molnar_2016}, which uses the LASSO coordinate descent solver in Scikit-learn \\citep{scikit-learn}. Also, we compute the full regularization path for $\\lambda_s \\in [0.01,1000]$ using our GBCD algorithm with warm start continuation and the LASSO coordinate path function in Scikit-learn and compare the timing results. Finally, we compare GBCD for a single solve against Node Harvest implemented using CVXPY \\citep{diamond2016cvxpy}. Node Harvest solves a different optimization problem than GBCD but we include this algorithm to compare GBCD against other optimization-based rule extraction methods. We conduct this timing experiment on a personal laptop with a 2.80 GHz Intel processor.\n\n\n\n\nTable 1 shows the results of our experiment across various problem sizes. We see that GBCD is much faster than Scikit-learn RuleFit (SKLRF) and Node Harvest, up to 40$\\times$ faster on high dimensional problems. In addition, GBCD with warm start continuation computes the entire regularization path around 10$\\times$ faster than SKLRF. \n\nWe think that a main reason behind GBCD outperforming the SKLRF LASSO solver is that we exploit the block-structure of the problem. The leaf nodes (coordinates) in a tree ensemble are naturally grouped into trees (blocks). As tree depth increases, the number of coordinates explodes exponentially, but the number of blocks remains the same. GBCD updates blocks instead of coordinates and leverages greedy block selection heuristics, while SKLRF relies on cyclic coordinate descent. As a result, GBCD computes solutions much faster than SKLRF. Computation times of GBCD on problem \\eqref{main_prob} with the MCP and fusion penalties are shown in the supplement (suppl. E).\n\n% \\begin{figure}[h!]\n%   \\begin{minipage}[c]{0.25\\textwidth}\n%     \\includegraphics[width=\\textwidth]{new_conference_version/figures/run_time_vs_depth_v2.pdf}\n%   \\end{minipage}\\hfill\n%   \\begin{minipage}[c]{0.2\\textwidth}\n%     \\caption{Computation time v. depth for GBCD and SKLRF on the 1316 row dataset (top rows in Table 1). GBCD is robust to the depth of the ensemble.} \\label{time_vs_depth.fig}\n%   \\end{minipage}\n% \\end{figure}\n\n\n"
                    },
                    "subsubsection 4.4.2": {
                        "name": "Large Problems",
                        "content": " \n\n\nAs an aside, we also compare the computation time of GBCD against SKLRF for much larger problems. We modify the experimental setup in the section above to extract rules from depth 20 random forests. The corresponding optimization problems contain hundreds of thousands to millions of decision variables. Table 2 shows the results of this timing experiment; the computation time of GBCD is still much faster than the computation time of SKLRF. For the largest problem instance (10955 row dataset, >1 million decision rules), SKLRF fails to reach a solution after a day of computation. GBCD on the other hand reaches a good solution in hours. Our specialized GBCD algorithm allows \\textsc{Fire} to extract decision rules from problem instances beyond the capabilities of existing off-the-shelf solvers.\n\n\n"
                    }
                }
            },
            "section 5": {
                "name": "Performance Experiments",
                "content": "\n\n\nIn this section, we compare the performance of \\textsc{Fire} against competing state-of-the-art algorithms for building rule ensembles. We evaluate \\textsc{Fire} against RuleFit in greater detail to better understand the effects of the MCP and fused LASSO penalties on rule extraction.\n\n\n",
                "subsection 5.1": {
                    "name": "Fire",
                    "content": "\n\n\nTo evaluate the performance of \\textsc{Fire}, we design an experiment to recreate how rule ensembles are used in practice. Rule ensembles are typically used in situations where model interpretability and transparency are important. In these situations, for a rule ensemble to be useful, the set of extracted rules must be \\emph{human readable}. As such, we restrict our extracted rule set to contain less than 15 rules, with a maximum interaction depth of 3. We use \\textsc{Fire} and our competing methods to extract rule ensembles under these parameters and compare the test performances of the selected models.\n\nWe repeat this procedure on 25 datasets from the OpenML repository \\cite{OpenML2013} using 5-fold cross validations; the full list of datasets with metadata can be found in the supplement. First, fit a random forest of 500 depth 3 trees. Initialize \\textsc{Fire} with the MCP penalty and fusion penalty. Since we are interested in selecting very sparse subsets of decision rules, we set concavity parameter $\\gamma = 1.1$ close to $1^{+}$ as discussed in \\S\\ref{param_selection.section}. We are only interested in the performance of the selected sparse ensemble for this experiment, so we set fusion parameter $\\lambda_f = 0.1$ to a low constant value. We use GBCD with warm start continuation to compute the entire regularization path for $\\lambda_s$ under these \\textsc{Fire} configurations. Select the value of $\\lambda_s$ that produces the best model, evaluated on a validation set, of less than 15 decision rules. Record the test performance of the selected model.\n\n\nWe compare the performance of the model above against the following competing algorithms: RuleFit, GLRM with and without debiasing, and SIRUS. For RuleFit, we extract decision rules from the same tree ensemble as \\textsc{Fire}. We tune the LASSO parameter for this algorithm on the validation set to select the best rule ensemble with less than 15 rules. SIRUS builds stabilized tree ensembles and GLRM builds decision rules using column generation. For these state-of-the-art competing algorithms, we again tune their sparsity hyperparameters on a validation set to find the best performing-rule ensemble with less than 15 rules. We record the test performances of the competing methods and compare them against \\textsc{Fire}.\n\n\n\n\n\nFigure \\ref{sota_competing_algorithm.fig} presents the results of our experiment. The vertical axes show the percent decrease in test error between \\textsc{Fire} and our competing methods, large positive values indicate that \\textsc{Fire} performs better than our competing algorithms. The distributions of each boxplot in the figure are obtained across all datasets and folds in our experiment. We observe that the IQRs of all of the boxplots are positive. This indicates that \\textsc{Fire} consistently performs better than our competing algorithms with median percent decreases in test error of \\textbf{42\\%} compared to GLRM without debiasing, \\textbf{24\\%} compared to GLRM with debiasing, \\textbf{18\\%} compared to SIRUS, and \\textbf{46\\%} compared to RuleFit. These results strongly suggest that \\textsc{Fire} is a competitive algorithm for extracting sparse decision rule sets compared to state-of-the-art methods. \n\nOne interesting thing to note is that the optional debiasing step in GLRM, where the rules are re-weighted after generation, greatly improves the performance of the algorithm. The improvement of GLRM over RuleFit found in Wei et al. (2019) \\cite{wei2019generalized} may be partially due to this step since the LASSO selection in RuleFit introduces bias. We are encouraged to observe that \\textsc{Fire} can outperform GLRM even with debiasing and SIRUS, two recently developed state-of-the-art algorithms for building rule ensembles.\n\n\n"
                },
                "subsection 5.2": {
                    "name": "Fire",
                    "content": "\nOur goal here is to understand how the MCP and fusion penalties in \\textsc{Fire} affect extracting decision rules from tree ensembles. To highlight the effect of our new penalties, we design this experiment to compare \\textsc{Fire} with MCP and fusion against RuleFit, which extracts rules using only the LASSO penalty, across various problem sizes.\n\nOn the same datasets and folds mentioned in the section above, we fit random forests of 500 trees of depths 3,5, and 7. We initialize two versions of \\textsc{Fire}. For the first version (MCP only), we set $\\gamma = 1.1$ and $\\lambda_f = 0$ and use GBCD with warm start continuation to compute the entire regularization path for $\\lambda_s$. This version of \\textsc{Fire} only uses the MCP penalty, and since $\\gamma$ is close to $1^{+}$ the penalty performs aggressive selection. For the second version (MCP w/ fusion), we set $\\gamma = 1.1$ and set the fusion hyperparameter $\\lambda_f = 0.5\\lambda_s$. Again we use warm start continuation to compute the entire regularization path for $\\lambda_s$. This version of \\textsc{Fire} applies a small fusion penalty which works in conjunction with the aggressive selection encouraged by the $\\gamma = 1.1$ MCP penalty. For both versions of \\textsc{Fire}, we record the test performance of the extracted ensemble across various sparsity levels. We compare the test performances of \\textsc{Fire} against RuleFit, computed along the regularization path for the sparsity parameter. \n\n\n\nFigure \\ref{fire_v_rf.fig} shows the results of this experiment. The plots compare the best model selected by \\textsc{Fire} against the best model selected by RuleFit given a budget or rules, shown on the horizontal axis. The vertical axes show the percent decrease in test error between \\textsc{Fire} and RuleFit, values above $0\\%$ indicate that \\textsc{Fire} performs better than RuleFit. The distributions for each boxplot are again obtained across all folds and datasets in the experiment. We observe that \\textsc{Fire} with the MCP penalties perform substantially better than RuleFit at selecting sparse models (LHS of figure \\ref{fire_v_rf.fig}). This is expected due to the behavior of the MCP penalty compared to the LASSO penalty when $\\gamma \\xrightarrow[]{} 1^{+}$. We also note that \\textsc{Fire} with the MCP penalty only performs slightly better than \\textsc{Fire} with both the MCP and fusion penalty in this regime. This is likely due to the fact that the additional regularization imparted by the fusion penalty causes the model to underfit when performing very sparse selection. Consequently, we suggest keeping $\\lambda_f$ small when extracting sparse rule sets.\n\nWhen the sparsity regularization penalty is reduced (i.e., the rule budget is increased) we observe that \\textsc{Fire} with the MCP penalty only begins to overfit. This effect is especially pronounced when extracting decision rules from the depth 7 tree ensemble (bottom panel of figure \\ref{fire_v_rf.fig}), due to the inherent complexity of the deeper rules. \\textsc{Fire} with both the MCP and fusion penalty avoids this issue since the fusion penalty adds additional regularization. We see in figure \\ref{fire_v_rf.fig} that \\textsc{Fire} with both the MCP and fusion penalty outperform RuleFit across all rule budgets; all of the green boxplots in the figure lie above 0\\%. By combining the aggressive selection of the MCP penalty with the regularization added by fusion, \\textsc{Fire} outperforms RuleFit at extracting rule ensembles across all model sparsities.\n\n\n\n\n\n\n% With the results of this experim\n\n% With the results of this experiment in mind, we recommend potentially using $\\lambda_f$ prevent $\n\n\n% With the results of this experiment in mind, we recommend potentially using \\textsc{Fire} under this configuration. \n\n% With the results of this experiment in mind, we recommend generally using \\textsc{Fire} under the following configuration. Set the MCP concavity parameter $\\gamma = 1.1$ to encourage aggressive selection. If a very sparse human readable rule ensemble is desired, set $\\lambda_f$ to a very small value. Otherwise, increase $\\lambda_f$ as needed to add regularization to avoid overfitting. By combining the aggressive selection of the MCP penalty with the regularization of the fusion penalty, \\textsc{Fire} performs better at extracting rule ensembles compared to  RuleFit across all model sparsities. \n\n\n\n\n% We first evaulate the performance of \\textsc{Fire} against RuleFit at extracting rules from a \n\n% We first evaluate the performance of \\textsc{Fire} against RuleFit across a wide range of problem settings and show that \\textsc{Fire} under specific configurations always outperforms RuleFit. We then compare the performance of \\textsc{Fire} against various state-of-the-art algorithms at selecting very sparse, interpretable rule sets \n\n\n% \\subsection{\\textsc{Fire} v. State-of-the-art}\n\n% \\begin{figure}[h!]\n%   \\begin{minipage}[c]{0.25\\textwidth}\n%     \\includegraphics[width=\\textwidth]{figures/RFOP_v_competing.pdf}\n%   \\end{minipage}\\hfill\n%   \\begin{minipage}[c]{0.2\\textwidth}\n%     \\caption{$\\text{RFOP}_{MCP}$ outperforms SOTA competing methods at selecting sparse interpretable rule ensembles of around 10-15 rules.} \\label{sota_RFOP.fig}\n%   \\end{minipage}\n% \\end{figure}\n\n% \\subsection{\\textsc{Fire} v. RuleFit}\n\n% \\begin{figure}[h]\n%     \\centering\n%     \\includegraphics[width = 0.48\\textwidth]{figures/MCP_budgets.pdf}\n%     \\caption{$\\text{RFOP}_{MCP}$ performs the best at selecting very sparse ensembles but can overfit. The fusion penalty in $\\text{RFOP}_{MCPf}$ reduces overfitting.}\n%     \\label{MCP_budget.fig}\n% \\end{figure}\n\n% \\begin{figure}[h]\n%     \\centering\n%     \\includegraphics[width = 0.48\\textwidth]{figures/quad_plot.pdf}\n%     \\caption{Left plots compares $\\text{RFOP}_{MCPf}$ against RuleFit. Right plots show the isolated effect of the fusion penalty on model compression.}\n%     \\label{MCP_and_fuse.fig}\n% \\end{figure}\n\n\n\n"
                }
            },
            "section 6": {
                "name": "Interpretability Case Study",
                "content": "\n\\label{interpretability_case.section}\n\n\n\n\n\nWe conclude with a case study to showcase the improved interpretability of $\\textsc{Fire}$ in a real-world example. We follow the work by Ibrahim et al. (2021) \\cite{ibrahim2021predicting} and use the Census Planning Database to predict census tract response rates. The US Census Bureau wants to understand what features influence response rate so that low-response tracts can be targeted; previous efforts have found that tree ensembles perform well but are difficult to interpret \\citep{erdman2017low}. We use \\textsc{Fire} to extract an interpretable set of decision rules.\n\nWe first build a random forest of 500 depth 3 trees. The full model achieves a test MSE of \\textbf{8.64\\%}. We use \\textsc{Fire} with the MCP and fusion penalties to extract around 10 decision rules with $\\gamma = 1.1$ and $\\lambda_f = 0.5 \\lambda_s$ (low) or $\\lambda_f = 2 \\lambda_s$ (high). The 10 rules selected by \\textsc{Fire} with low $\\gamma_f$ perform the same as the full ensemble (\\textbf{8.64\\%} MSE) and the 10 rules selected when $\\lambda_f$ is high perform slightly worse (\\textbf{9.44\\%} MSE). In contrast, when we select 11 rules with RuleFit, the model performs much worse (\\textbf{12.42\\%} MSE).\n\nThe rule ensembles extracted by \\textsc{Fire} are substantially more interpretable than the RuleFit ensembles. The bottom plot in figure \\ref{census_example.fig} shows the 11 rules selected by RuleFit. These rules are selected across different trees and are not grouped in any meaningful manner; it is difficult to interpret this model from the figure alone. In comparison, the middle plot contains the 10 rule ensemble selected by \\textsc{Fire} with low $\\lambda_f$. This rule ensemble contains a partial decision tree which reveals that the feature \\textit{NH-White-alone} is important since 4 rules share the same split on this feature. Increasing $\\lambda_f$ yields the most interpretable rule ensemble, shown in the top plot, which consists of a single decision tree and 2 additional rules.\n\n\n\nAs an attempt to quantify interpretability, we can count the number of antecedents, colored nodes in figure \\ref{census_example.fig}, that a user must analyze to interpret a rule ensemble. The RuleFit ensemble contains \\textbf{33} antecedents while the \\textsc{Fire} high $\\lambda_f$ ensemble contains just \\textbf{13}. \n\n% \\textsc{Fire} extracts a much more interpretable ensemble that performs better than the model produced by RuleFit.\n\n"
            },
            "section 7": {
                "name": "Conclusion",
                "content": "\n\n\n\n\n\n\\textsc{Fire} is a novel optimization-based framework to extract decision rules from tree ensembles. The framework selects sparse representative subsets of rules from an ensemble and allows for the flexibility to encourage rule fusion during the selection procedure. This improves the interpretability and compression of the extracted model since many of the selected rules share common antecedents. \\textsc{Fire} uses a non-convex MCP penalty to aggressively select rules in the presence of correlations and a fused LASSO penalty to encourage rule fusion. To solve the large non-convex optimization problems in \\textsc{Fire}, we develop a specialized GBCD solver that computes high-quality solutions efficiently. Our solver exploits the blocking structure of the problem and leverages greedy block selection heuristics to reduce computation time. As a result, our solver scales well and allows for computation beyond the capabilities of off-the-shelf methods. Our experiments show that \\textsc{Fire} performs better than state-of-the-art algorithms at building human readable rule sets and that \\textsc{Fire}\noutperforms RuleFit at extracting rule ensembles across all sparsity levels. Altogether, these features and finding make \\textsc{Fire} a fast and effective framework for extracting interpretable rule ensembles.\n\n\\textbf{ACKNOWLEDGMENTS} This research is funded in part by a grant from the Office of Naval Research (ONR-N00014-21-1-2841).\n\n\\bibliographystyle{plainnat}\n\\balance\n\\bibliography{ref2}\n\n\n"
            }
        },
        "tables": {
            "timingtable.fig": "\\begin{table}[h]\n\\scalebox{0.6} {\n\\begin{tabular}{|cccc|cccccc}\n\\cline{1-4} \\cline{6-9}\n\\multicolumn{4}{|c|}{\\textbf{Rule Extraction Single Solve}}                                                                                                                                                                                                                                                                                                                             & \\multicolumn{1}{c|}{} & \\multicolumn{4}{c|}{\\textbf{Rule Extraction Full Path}}                                                                                                                                                                                                                                                                                &  \\\\ \\cline{1-4} \\cline{6-9}\n\\multicolumn{4}{|c|}{\\cellcolor[HTML]{C0C0C0}{\\color[HTML]{333333} \\textbf{GBCD Single Solve}}}                                                                                                                                                                                                                                                                                                  & \\multicolumn{1}{c|}{} & \\multicolumn{4}{c|}{\\cellcolor[HTML]{C0C0C0}{\\color[HTML]{333333} \\textbf{GBCD Regularization Path}}}                                                                                                                                                                                                                                           &  \\\\ \\cline{1-4} \\cline{6-9}\n\\multicolumn{1}{|c|}{\\textbf{\\begin{tabular}[c]{@{}c@{}}Rows/\\\\ Vars\\end{tabular}}} & \\multicolumn{1}{c|}{\\textbf{\\begin{tabular}[c]{@{}c@{}}2000\\\\  (3)\\end{tabular}}}                        & \\multicolumn{1}{c|}{\\textbf{\\begin{tabular}[c]{@{}c@{}}8000 \\\\ (5)\\end{tabular}}}                        & \\textbf{\\begin{tabular}[c]{@{}c@{}}25000 \\\\ (7)\\end{tabular}}                        & \\multicolumn{1}{c|}{} & \\multicolumn{1}{c|}{\\textbf{\\begin{tabular}[c]{@{}c@{}}Rows/\\\\ Vars\\end{tabular}}} & \\multicolumn{1}{c|}{\\textbf{\\begin{tabular}[c]{@{}c@{}}2000\\\\  (3)\\end{tabular}}} & \\multicolumn{1}{c|}{\\textbf{\\begin{tabular}[c]{@{}c@{}}8000 \\\\ (5)\\end{tabular}}} & \\multicolumn{1}{c|}{\\textbf{\\begin{tabular}[c]{@{}c@{}}25000 \\\\ (7)\\end{tabular}}} &  \\\\ \\cline{1-4} \\cline{6-9}\n\\multicolumn{1}{|c|}{\\textbf{1316}}                                                 & \\multicolumn{1}{c|}{\\cellcolor[HTML]{A1E9A1}{\\color[HTML]{333333} 21.6 (0.6)}}                           & \\multicolumn{1}{c|}{\\cellcolor[HTML]{A1E9A1}{\\color[HTML]{333333} 16.5 (1.4)}}                           & \\cellcolor[HTML]{A1E9A1}{\\color[HTML]{333333} 16.3 (0.4)}                            & \\multicolumn{1}{c|}{} & \\multicolumn{1}{c|}{\\textbf{1316}}                                                 & \\multicolumn{1}{c|}{\\cellcolor[HTML]{A1E9A1}{\\color[HTML]{333333} 90.8 (2.0)}}    & \\multicolumn{1}{c|}{\\cellcolor[HTML]{A1E9A1}{\\color[HTML]{333333} 83.8 (5.5)}}    & \\multicolumn{1}{c|}{\\cellcolor[HTML]{A1E9A1}{\\color[HTML]{333333} 90.4 (7.4)}}     &  \\\\ \\cline{1-4} \\cline{6-9}\n\\multicolumn{1}{|c|}{\\textbf{4338}}                                                 & \\multicolumn{1}{c|}{\\cellcolor[HTML]{A1E9A1}{\\color[HTML]{333333} 63.9 (2.2)}}                           & \\multicolumn{1}{c|}{\\cellcolor[HTML]{A1E9A1}{\\color[HTML]{333333} 137.7 (2.2)}}                          & \\cellcolor[HTML]{A1E9A1}{\\color[HTML]{333333} 146.4 (0.9)}                           & \\multicolumn{1}{c|}{} & \\multicolumn{1}{c|}{\\textbf{4338}}                                                 & \\multicolumn{1}{c|}{\\cellcolor[HTML]{A1E9A1}{\\color[HTML]{333333} 196.0 (2.0)}}   & \\multicolumn{1}{c|}{\\cellcolor[HTML]{A1E9A1}{\\color[HTML]{333333} 465.2 (10.9)}}  & \\multicolumn{1}{c|}{\\cellcolor[HTML]{A1E9A1}{\\color[HTML]{333333} 653.25 (21.8)}}  &  \\\\ \\cline{1-4} \\cline{6-9}\n\\multicolumn{1}{|c|}{\\textbf{10955}}                                                & \\multicolumn{1}{c|}{\\cellcolor[HTML]{A1E9A1}{\\color[HTML]{333333} 106.4 (3.9)}}                          & \\multicolumn{1}{c|}{\\cellcolor[HTML]{A1E9A1}{\\color[HTML]{333333} 176.8 (0.6)}}                          & \\cellcolor[HTML]{A1E9A1}{\\color[HTML]{333333} 419.6 (1.6)}                           & \\multicolumn{1}{c|}{} & \\multicolumn{1}{c|}{\\textbf{10955}}                                                & \\multicolumn{1}{c|}{\\cellcolor[HTML]{A1E9A1}{\\color[HTML]{333333} 350.0 (5.4)}}   & \\multicolumn{1}{c|}{\\cellcolor[HTML]{A1E9A1}{\\color[HTML]{333333} 732.8 (14.8)}}  & \\multicolumn{1}{c|}{\\cellcolor[HTML]{A1E9A1}{\\color[HTML]{333333} 1712.3 (37.2)}}  &  \\\\ \\cline{1-4} \\cline{6-9}\n\\multicolumn{4}{|c|}{\\cellcolor[HTML]{C0C0C0}\\textbf{Scikit-learn RuleFit}}                                                                                                                                                                                                                                                                                                                      & \\multicolumn{1}{c|}{} & \\multicolumn{4}{c|}{\\cellcolor[HTML]{C0C0C0}\\textbf{Scikit-learn RuleFit Regularization Path}}                                                                                                                                                                                                                                                  &  \\\\ \\cline{1-4} \\cline{6-9}\n\\multicolumn{1}{|c|}{\\textbf{\\begin{tabular}[c]{@{}c@{}}Rows/\\\\ Vars\\end{tabular}}} & \\multicolumn{1}{c|}{{\\color[HTML]{333333} \\textbf{\\begin{tabular}[c]{@{}c@{}}2000\\\\  (3)\\end{tabular}}}} & \\multicolumn{1}{c|}{{\\color[HTML]{333333} \\textbf{\\begin{tabular}[c]{@{}c@{}}8000 \\\\ (5)\\end{tabular}}}} & {\\color[HTML]{333333} \\textbf{\\begin{tabular}[c]{@{}c@{}}25000 \\\\ (7)\\end{tabular}}} & \\multicolumn{1}{c|}{} & \\multicolumn{1}{c|}{\\textbf{\\begin{tabular}[c]{@{}c@{}}Rows/\\\\ Vars\\end{tabular}}} & \\multicolumn{1}{c|}{\\textbf{\\begin{tabular}[c]{@{}c@{}}2000\\\\  (3)\\end{tabular}}} & \\multicolumn{1}{c|}{\\textbf{\\begin{tabular}[c]{@{}c@{}}8000 \\\\ (5)\\end{tabular}}} & \\multicolumn{1}{c|}{\\textbf{\\begin{tabular}[c]{@{}c@{}}25000 \\\\ (7)\\end{tabular}}} &  \\\\ \\cline{1-4} \\cline{6-9}\n\\multicolumn{1}{|c|}{\\textbf{1316}}                                                 & \\multicolumn{1}{c|}{{\\color[HTML]{333333} 221.9 (12.4)}}                                                 & \\multicolumn{1}{c|}{{\\color[HTML]{333333} 492.3 (19.8)}}                                                 & \\cellcolor[HTML]{FFFFFF}{\\color[HTML]{333333} 628.3 (32.7)}                          & \\multicolumn{1}{c|}{} & \\multicolumn{1}{c|}{\\textbf{1316}}                                                 & \\multicolumn{1}{c|}{{\\color[HTML]{333333} 1250.9 (17.6)}}                         & \\multicolumn{1}{c|}{{\\color[HTML]{333333} 1732.2 (19.2)}}                         & \\multicolumn{1}{c|}{\\cellcolor[HTML]{FFCCC9}{\\color[HTML]{333333} $>$ 1800}}       &  \\\\ \\cline{1-4} \\cline{6-9}\n\\multicolumn{1}{|c|}{\\textbf{4338}}                                                 & \\multicolumn{1}{c|}{\\cellcolor[HTML]{FFFFFF}{\\color[HTML]{333333} 998.4 (130.5)}}                        & \\multicolumn{1}{c|}{\\cellcolor[HTML]{FFCCC9}{\\color[HTML]{333333} $>$ 1800}}                             & \\cellcolor[HTML]{FFCCC9}{\\color[HTML]{333333} $>$ 1800}                              & \\multicolumn{1}{c|}{} & \\multicolumn{1}{c|}{\\textbf{4338}}                                                 & \\multicolumn{1}{c|}{\\cellcolor[HTML]{FFCCC9}{\\color[HTML]{333333} $>$ 1800}}      & \\multicolumn{1}{c|}{\\cellcolor[HTML]{FFCCC9}{\\color[HTML]{333333} $>$ 1800}}      & \\multicolumn{1}{c|}{\\cellcolor[HTML]{FFCCC9}{\\color[HTML]{333333} $>$ 1800}}       &  \\\\ \\cline{1-4} \\cline{6-9}\n\\multicolumn{1}{|c|}{\\textbf{10955}}                                                & \\multicolumn{1}{c|}{\\cellcolor[HTML]{FFCCC9}{\\color[HTML]{333333} $>$ 1800}}                             & \\multicolumn{1}{c|}{\\cellcolor[HTML]{FFCCC9}{\\color[HTML]{333333} $>$ 1800}}                             & \\cellcolor[HTML]{FFCCC9}{\\color[HTML]{333333} $>$ 1800}                              & \\multicolumn{1}{c|}{} & \\multicolumn{1}{c|}{\\textbf{10955}}                                                & \\multicolumn{1}{c|}{\\cellcolor[HTML]{FFCCC9}{\\color[HTML]{333333} $>$ 1800}}      & \\multicolumn{1}{c|}{\\cellcolor[HTML]{FFCCC9}{\\color[HTML]{333333} $>$ 1800}}      & \\multicolumn{1}{c|}{\\cellcolor[HTML]{FFCCC9}{\\color[HTML]{333333} $>$ 1800}}       &  \\\\ \\cline{1-4} \\cline{6-9}\n\\multicolumn{4}{|c|}{\\cellcolor[HTML]{C0C0C0}\\textbf{Node Harvest (CVXPY ECOS)}}                                                                                                                                                                                                                                                                                                                 &                       & \\multicolumn{4}{c}{\\cellcolor[HTML]{FFFFFF}\\textbf{}}                                                                                                                                                                                                                                                                                           &  \\\\ \\cline{1-4}\n\\multicolumn{1}{|c|}{\\textbf{\\begin{tabular}[c]{@{}c@{}}Rows/\\\\ Vars\\end{tabular}}} & \\multicolumn{1}{c|}{{\\color[HTML]{333333} \\textbf{\\begin{tabular}[c]{@{}c@{}}2000\\\\  (3)\\end{tabular}}}} & \\multicolumn{1}{c|}{{\\color[HTML]{333333} \\textbf{\\begin{tabular}[c]{@{}c@{}}8000 \\\\ (5)\\end{tabular}}}} & {\\color[HTML]{333333} \\textbf{\\begin{tabular}[c]{@{}c@{}}25000 \\\\ (7)\\end{tabular}}} &                       & \\multicolumn{4}{c}{\\cellcolor[HTML]{FFFFFF}\\textbf{}}                                                                                                                                                                                                                                                                                           &  \\\\ \\cline{1-4}\n\\multicolumn{1}{|c|}{\\textbf{1316}}                                                 & \\multicolumn{1}{c|}{{\\color[HTML]{333333} 114.2 (5.6)}}                                                  & \\multicolumn{1}{c|}{{\\color[HTML]{333333} 109.1 (3.2)}}                                                  & {\\color[HTML]{333333} 297.3 (6.0)}                                                   &                       & {\\color[HTML]{333333} \\textbf{}}                                                   & \\textbf{}                                                                         & \\textbf{}                                                                         & \\textbf{}                                                                          &  \\\\ \\cline{1-4}\n\\multicolumn{1}{|c|}{\\textbf{4338}}                                                 & \\multicolumn{1}{c|}{{\\color[HTML]{333333} 172.2 (1.3)}}                                                  & \\multicolumn{1}{c|}{\\cellcolor[HTML]{FFCCC9}{\\color[HTML]{333333} $>$ 1800}}                             & \\cellcolor[HTML]{FFCCC9}{\\color[HTML]{333333} $>$ 1800}                              &                       & \\cellcolor[HTML]{FFFFFF}\\textbf{}                                                  &                                                                                   &                                                                                   &                                                                                    &  \\\\ \\cline{1-4}\n\\multicolumn{1}{|c|}{\\textbf{10955}}                                                & \\multicolumn{1}{c|}{\\cellcolor[HTML]{FFCCC9}{\\color[HTML]{333333} $>$ 1800}}                             & \\multicolumn{1}{c|}{\\cellcolor[HTML]{FFCCC9}{\\color[HTML]{333333} $>$ 1800}}                             & \\cellcolor[HTML]{FFCCC9}{\\color[HTML]{333333} $>$ 1800}                              &                       & \\cellcolor[HTML]{FFFFFF}\\textbf{}                                                  &                                                                                   &                                                                                   &                                                                                    &  \\\\ \\cline{1-4}\n\\end{tabular}}\n\\label{timingtable.fig}\n\\caption{Timing results in seconds. The fastest methods are highlighted in green and red cells indicate that the method did not finish within 30 minutes.}\n\\end{table}"
        },
        "figures": {
            "intro_example.fig": "\\begin{figure}[h]\n    \\centering\n    \\includegraphics[width = 0.45\\textwidth]{new_conference_version/figures/introduction_example.pdf}\n    \\caption{Fusion improves parsimony by reducing internal nodes. In both panels, 16 decision rules are selected but the sparsity with fusion panel contains \\textbf{44\\%} fewer internal nodes.}\n    \\label{intro_example.fig}\n\\end{figure}",
            "challenges_example.fig": "\\begin{figure}[h]\n    \\centering\n    \\includegraphics[width = 0.45\\textwidth]{new_conference_version/figures/challenges_example.pdf}\n    \\caption{Bagging ensemble of 500 trees fit on the Elevators dataset \\cite{OpenML2013}. The number of decision rules in the ensemble scales exponentially with tree depth. Shallower ensembles contain highly correlated rules.} \\label{challenges_example.fig}\n\\end{figure}",
            "fusion_compression.fig": "\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width = 0.45\\textwidth ]{new_conference_version/figures/fusion_compression_single_row_no_legend_new.pdf}\n    \\caption{Grouping pruned leaves increases the number of internal nodes removed from a decision tree.}\n    \\label{fusion_compression.fig}\n\\end{figure}",
            "fusion_groupings.fig": "\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width = 0.45\\textwidth ]{new_conference_version/figures/fusion_rule_groups_V2_new.pdf}\n    \\caption{Extracting 4 rules from a decision tree fit on the California Housing Price dataset. In the right plot, the rules are grouped together and are more interpretable.}\n    \\label{fusion_groupings.fig}\n\\end{figure}",
            "sensitivity_analysis.fig": "\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width = 0.45\\textwidth ]{new_conference_version/figures/sensitivity_analysis_kdd_V2.pdf}\n    \\caption{Effect of $\\gamma$ on the MCP penalty. Varying $\\gamma$ controls the trade-off between shrinkage and selection.}\n    \\label{sensitivity_analysis.fig}\n\\end{figure}",
            "greedy_v_cyclic.fig": "\\begin{figure}[h]\n    \\centering\n    \\includegraphics[width = 0.45\\textwidth ]{figures/greedy_v_cyclic_w_time.pdf}\n    \\caption{Training loss v. \\# iterations for greedy v. cyclic BCD, with computation time in seconds. Greedy block selection takes 2 orders of magnitude (\\textbf{100x}) fewer iterations. Horizontal axis is log scale.}\n    \\label{greedy_v_cyclic.fig}\n\\end{figure}",
            "sota_competing_algorithm.fig": "\\begin{figure}[h]\n    \\centering\n    \\includegraphics[width = 0.4\\textwidth]{new_conference_version/figures/RFOP_v_competing_new.pdf}\n    \\caption{\\textsc{Fire} outperforms SOTA competing algorithms at selecting sparse human readable rule ensembles.}\n    \\label{sota_competing_algorithm.fig}\n\\end{figure}",
            "fire_v_rf.fig": "\\begin{figure}[h]\n    \\centering\n    \\includegraphics[width = 0.45\\textwidth]{new_conference_version/figures/MCP_budgets_new.pdf}\n    \\caption{\\textsc{Fire} v. RuleFit across various problem sizes. The MCP penalty in \\textsc{Fire} performs better at selecting sparse sets of rules and the fusion penalty helps prevent overfitting.}\n    \\label{fire_v_rf.fig}\n\\end{figure}",
            "census_example.fig": "\\begin{figure}[h]\n    \\centering\n    \\includegraphics[width = 0.48\\textwidth]{figures/interpretability_census.pdf}\n    \\caption{US Census case study:\n    \\textsc{Fire} extracts more interpretable, better performing ensembles compared to RuleFit.}\n    \\label{census_example.fig}\n\\end{figure}"
        },
        "equations": {
            "eq:1": "\\begin{equation}\n    (M_t)^{ij} = \\begin{cases}\n    v_j & \\text{if data point $x_i$ reaches leaf node $r_j$} \\\\\n    0 & \\text{otherwise}.\n    \\end{cases}\n\\end{equation}",
            "eq:2": "\\begin{equation}\n    h(w, \\lambda_s) = \\sum_{j=1}^R P_{\\gamma}(w_j, \\lambda_s),\n\\end{equation}",
            "eq:3": "\\begin{equation}\n    P_{\\gamma}(w_j,\\lambda_s) = \\begin{cases} \n\\lambda_s |w_j|  - \\frac{{w_j}^2}{2 \\gamma} &\\text{if } |w_j| \\leq \\lambda_s \\gamma \\\\\n \\frac{1}{2}\\gamma \\lambda_s^2 & \\text{if } |w_j| > \\lambda_s \\gamma, \\end{cases}\n\\end{equation}",
            "eq:4": "\\begin{equation}\n    g(w, \\lambda_f) = \\lambda_f \\sum_{t=1}^T \\left\\| D_t w_t \\right\\|_1\n\\end{equation}",
            "eq:5": "\\begin{equation}\n    \\left\\|D_t w_t\\right\\|_1 = \\sum_{j = 2}^{R_t} | (w_t)_j - (w_t)_{j-1}|.\n    \\label{fusion_penalty.eq}\n\\end{equation}",
            "eq:6": "\\begin{equation}\n\\label{mcp_threshold_operator}\n    \\theta_j^* = \\begin{cases}\n                \\frac{\\gamma}{\\gamma - 1} S_{\\frac{\\lambda_s}{L_t}}(\\hat{\\theta}_j) & \\text{if } |\\hat{\\theta}_j| \\leq  \\frac{\\lambda_s \\gamma}{L_t} \\\\\n                \\hat{\\theta}_j & \\text{if } |\\hat{\\theta}_j| >  \\frac{\\lambda_s \\gamma}{L_t}.\n                \\end{cases}\n\\end{equation}"
        },
        "git_link": "https://github.com/brianliu12437/FIREKDD2023"
    }
}