{
    "meta_info": {
        "title": "Proton: Probing Schema Linking Information from Pre-trained Language  Models for Text-to-SQL Parsing",
        "abstract": "The importance of building text-to-SQL parsers which can be applied to new\ndatabases has long been acknowledged, and a critical step to achieve this goal\nis schema linking, i.e., properly recognizing mentions of unseen columns or\ntables when generating SQLs. In this work, we propose a novel framework to\nelicit relational structures from large-scale pre-trained language models\n(PLMs) via a probing procedure based on Poincar\\'e distance metric, and use the\ninduced relations to augment current graph-based parsers for better schema\nlinking. Compared with commonly-used rule-based methods for schema linking, we\nfound that probing relations can robustly capture semantic correspondences,\neven when surface forms of mentions and entities differ. Moreover, our probing\nprocedure is entirely unsupervised and requires no additional parameters.\nExtensive experiments show that our framework sets new state-of-the-art\nperformance on three benchmarks. We empirically verify that our probing\nprocedure can indeed find desired relational structures through qualitative\nanalysis. Our code can be found at\nhttps://github.com/AlibabaResearch/DAMO-ConvAI.",
        "author": "Lihan Wang, Bowen Qin, Binyuan Hui, Bowen Li, Min Yang, Bailin Wang, Binhua Li, Fei Huang, Luo Si, Yongbin Li",
        "link": "http://arxiv.org/abs/2206.14017v2",
        "category": [
            "cs.CL"
        ],
        "additionl_info": "Accepted at KDD 2022"
    },
    "latex_extraction": {
        "content": {
            "section 1": {
                "name": "Introduction",
                "content": "\nText-to-SQL parsing aims at converting a natural language  (NL) question to its corresponding structured query language (SQL) in the context of a relational database.\nAlthough relational databases can be efficiently accessed by skilled professionals via handcrafted SQLs, a natural language interface, whose core component relies on text-to-SQL parsing, would allow ubiquitous relational data to be accessible for a wider range of non-technical users. \nHence, text-to-SQL parsing has attracted remarkable attention in both academic and industrial communities. \n\n\n\n\nOne challenging goal of text-to-SQL parsing is achieving \\textit{domain generalization}, i.e., building parsers which can be successfully applied to new domains (or databases). \nThe availability of benchmarks~\\citep{wikisql,spider} has led to numerous advances  in developing parsers with domain generalization~\\citep[e.g.,][]{guo2019towards,ratsql,slsql,lgesql}.\nCentral to achieving domain generalization is schema linking â€“ correctly aligning entity references in the NL question to the intended schema columns or tables, even on unseen databases.\nAs shown in Figure~\\ref{fig1}, a parser needs to link mentions \\texttt{singers} and \\texttt{musicians} to their corresponding column \\texttt{singer}.\nThe importance of schema linking to domain generalization has also been verified in \\cite{slsql,wang2020meta}.\n\nRecent work suggests that standard benchmarks are limited in assessing domain generalization, and methods incorporated by current neural semantic parsers to handle schema linking cannot generalize well to more realistic settings.\nSpecifically, for the standard benchmark Spider~\\citep{spider}, most entity mentions can be extracted by a heuristic such as string matching.~\\footnote{Such artifacts might result from a biased annotation process: annotators were shown\nthe database schema and asked to formulate queries.} For example, \nthe mention \\texttt{singers} in the first question in Figure~\\ref{fig1} can be trivially linked to the column \\texttt{singer} based on their surface forms. Many  parsers~\\citep{guo2019towards,ratsql} exploit such artifacts (or shortcuts), but their good performance on Spider does not transfer to real-life settings where mentions and columns/tables are very likely to share different surface forms. For example, when the mention \\texttt{singer} is replaced with its synonym \\texttt{musicians}, the state-of-the-art parser LGESQL~\\citep{lgesql} fails to handle the schema-linking relations.\n\n\n\nIn this work, we propose a novel approach to elicit relational structures for schema linking from large-scale pre-trained language models (PLMs) through a probing procedure.\nIn addition to simply encoding NL question and schema in  \\textit{continuous} vector space using PLMs, as most previous semantic parsers do, we propose to distill \\textit{discrete} relational structures from PLMs. Such relational structures are extracted in an unsupervised manner, and they can be directly exploited for schema linking when generating structured programs of SQLs. We capitalize on the intuition that although relational information is already contained in the continuous representations of PLMs, neural parsers lack an optimal mechanism to benefit from such information. The algorithmic inductive biases introduced by our probing procedure would allow the underlying relational structures to be explicitly and easily exploited by neural parsers. Previous work has shown that PLMs such as BERT \\cite{devlin2018bert}, RoBERTa \\cite{liu2019roberta}, ELECTRA \\cite{clark2020electra} store linguistic knowledge \\cite{hewitt-liang-2019-designing}, world knowledge \\cite{raffel2019exploring} and relational knowledge \\cite{petroni2019language}. To our best knowledge, we are the first work to adapt probing methods to exploit relational information from PLMs for the complex structured prediction task of text-to-SQL parsing.\n\nThe relational structures extracted from PLMs hold several appealing properties which make them suitable for domain generalization of text-to-SQL parsing. First, they are domain-invariant, and this is inherited from that PLMs are usually obtained via self-supervised training on various domains of textual data. Second, they can better capture semantic correspondences than current heuristics such as n-gram matching~\\citep{spiderSYN,ratsql}.\nThird, they are relatively more robust to the cross-database setting. As they are elicited in an unsupervised probing procedure and not induced during in-domain training, they will not suffer from overfitting to observed training databases.\n\nIn this work, we propose a novel framework, called \\textbf{\\name}\\footnote{\\underline{\\textbf{PRO}}bing Schema Linking Informa\\underline{\\textbf{T}}i\\underline{\\textbf{O}}n from Pre-trai\\underline{\\textbf{N}}ed Language Models}, which first probes the underlying relational schema-linking structures between a NL query and its database schema from a pre-trained language model, and then effectively injects it into the downstream text-to-SQL parsing models.\nTo better model the heterogeneous relational structures, we introduce a probing procedure based on Poincar\\'e distance metric instead of the traditional Euclidean distance metric, inspired by \\citet{chen2021probing}.\nOur probing procedure is entirely unsupervised and does not require additional parameters.\nWe empirically show the effectiveness of \\textbf{\\name} on several text-to-SQL benchmarks, \\ie, Spider~\\cite{spider}, SYN~\\cite{spiderSYN} and DK~\\cite{spiderDK}, and through qualitative analysis, we verify that our probing procedure can indeed find desired relational structures.\n\nThe contributions of this work can be summarized as follows:\n\\begin{itemize}\n    \\item To boost domain generalization for text-to-SQL parsing, we propose a novel framework that utilizes relational schema-linking structures that are extracted from a PLM via an unsupervised probing process. \n    \\item  To better capture the heterogeneous relational structures between NL queries and database schema, we introduce a Poincar\\'e distance metric that can better measure semantic relevance than the typical Euclidean distance metric.\n    \\item Extensive experiments on three text-to-SQL benchmarks show that our probing method can lead to significantly better results when compared with current state-of-the-art parsers.\n\\end{itemize}\n\n\n\n\nThough we only focus on text-to-SQL parsing in this work, we believe that the general methodology of probing underlying discrete relational structures from PLMs can be extended to related tasks that require complex reasoning over structured knowledge, such as knowledge-based question answering~\\citep{gu2021beyond} and dialog~\\citep{dai2020learning,dai2021preview,lin2022duplex}, table-based fact checking~\\citep{chen2019tabfact} and structured data record to text generation~\\citep{nan2020dart}. \n\n"
            },
            "section 2": {
                "name": "Graph-based Text-to-SQL Models",
                "content": "\n\\label{sec:graph}\n\n",
                "subsection 2.1": {
                    "name": "Notation Definition",
                    "content": "\nGiven a natural language question $Q$  and the corresponding database schema $\\mathcal{S}=\\langle\\mathcal{T}, \\mathcal{C}\\rangle$, the target is to generate a SQL query $Y$.\nMore specifically, the question $Q = \\left\\{q_{1}, q_{2}, \\cdots, q_{|Q|} \\right\\}$ is a sequence of tokens, and the schema consists of tables $T=\\left\\{t_{1}, t_{2}, \\cdots, t_{|\\mathcal{T}|} \\right\\}$ and columns $C=\\left\\{c_{1}, c_{2}, \\cdots, c_{|\\mathcal{C}|} \\right\\}$.\nEach table $t_i$ contains multiple words $(t_{i,1}, t_{i,2}, \\cdots, t_{i,|t_i|})$ and each column name $c_j^{t_i}$ in table $t_i$ contains words $(c_{j,1}^{t_{i}}, c_{j,2}^{t_{i}}, \\cdots, c_{j,|c_j^{t_i}|}^{t_{i}})$. Formally, we denote the input  as $X$, where $X = \\langle\\mathcal{Q}, \\mathcal{S}\\rangle$ and the desired SQL query as $Y$ which is represented as an abstract syntax tree (AST) \\cite{YinN17} in the context-free grammar of SQL.\nWe employ the de facto encoder-decoder framework, where the encoder jointly maps NL questions and schema items into embeddings $\\mathbf{X}$ and the decoder generates the AST of the target query $Y$ in the depth-first-search order. In this paper, we adopt two representative graph-based models RAT-SQL \\cite{ratsql} and LGESQL \\cite{lgesql} as our base models given their SOTA performance. \n\n"
                },
                "subsection 2.2": {
                    "name": "Encoder",
                    "content": "\nFormally, the graph-based models RAT-SQL and LGESQL consider the NL question and the database schema as a single direct graph $\\mathcal{G} = \\langle \\mathcal{V}, \\mathcal{E} \\rangle $, where $\\mathcal{V} = Q \\cup \\mathcal{T} \\cup \\mathcal{C}$ denotes the node set containing the input NL question tokens as well as schema items and $\\mathcal{E}$ is the edge set depicting  \\emph{pre-existing} relations between NL question tokens and schema items. \nGiven the inputs $X=\\left\\{\\boldsymbol{x}_{\\boldsymbol{i}}\\right\\}_{i=1}^{n}$ and input graph $\\mathcal{G}$,  a relational-aware transformer (RAT) \\cite{ratsql} is leveraged as the encoder.\nThe relation-aware transformer is based on the classic transformer but represents relative position information in a self-attention layer, which transforms each $\\boldsymbol{x}_{\\boldsymbol{i}}$ into $\\boldsymbol{y}_{\\boldsymbol{i}} \\in \\mathbb{R}^{d_{\\boldsymbol{x}}}$ as follows:\n\\begin{equation}\ne_{i j}^{(h)} =\\frac{\\boldsymbol{x}_{i} W_{Q}^{(h)}\\left(\\boldsymbol{x}_{j} W_{K}^{(h)}+r_{i j}\\right)^{\\top}}{\\sqrt{d_{z} / H}}\n\\label{rij1}\n\\end{equation}\n\\vspace{-0.1cm}\n\\begin{equation}\n \\alpha_{i j}^{(h)}=\\operatorname{softmax}_{j}\\left\\{e_{i j}^{(h)}\\right\\} \n\\end{equation}\n\\vspace{-0.2cm}\n\\begin{equation}\n    \\boldsymbol{z}_{i}^{(h)} =\\sum_{j=1}^{n} \\alpha_{i j}^{(h)}\\left(\\boldsymbol{x}_{j} W_{V}^{(h)}+r_{i j}\\right) \\label{rij2}\n\\end{equation}\n\\vspace{-0.2cm}\n\\begin{equation}\n    \\boldsymbol{z}_{i}=\\operatorname{Concat}\\left(\\boldsymbol{z}_{i}^{(1)}, \\cdots, \\boldsymbol{z}_{i}^{(H)}\\right)\n\\end{equation}\n\\vspace{-0.2cm}\n\\begin{equation}\n    \\tilde{\\boldsymbol{y}}_{\\boldsymbol{i}} =\\operatorname{LayerNorm}\\left(\\boldsymbol{x}_{\\boldsymbol{i}}+\\boldsymbol{z}_{i}\\right)\n\\end{equation}\n\\vspace{-0.3cm}\n\\begin{equation}\n    \\boldsymbol{y}_{\\boldsymbol{i}}  =\\operatorname{LayerNorm}\\left(\\tilde{\\boldsymbol{y}}_{\\boldsymbol{i}}+\\operatorname{FC}\\left(\\operatorname{ReLU}\\left(\\operatorname{FC}\\left(\\tilde{\\boldsymbol{y}}_{\\boldsymbol{i}}\\right)\\right)\\right)\\right.\n\\end{equation}\nwhere FC is a fully-connected layer and LayerNorm is the layer normalization operation \\cite{ba2016layer}.\n$W_{Q}^{(h)}, W_{K}^{(h)}, W_{V}^{(h)} \\in \\mathbb{R}^{d_{x} \\times\\left(d_{x} / H\\right)}$ are learnable parameters where $d_{x}$ denotes the dimension of hidden representation.\n$d_{x}$ and $d_{z}$ represents the dimension of $x$ and $z$.\n$H$ is the number of heads and we have $1 \\leq h \\leq H$. \nHere, the term $r_{ij}$ encodes the known relationship between the two elements $x_i$ and $x_j$ in the input.\nThe RAT framework represents all the pre-existing features for each edge $(i,j)$ as\n$r_{i j}$ in which each element is either a learnable embedding for each corresponding edge or a zero vector if the relation does not hold for the edge.\nThe reader can refer to \\cite{ratsql} for the implementation details of RAT.\n\nLGESQL applies a line-graph enhanced relational graph attention network (RGAT) as its encoder.\nDifferent from RAT, RGAT is based on graph attention network and represents relative position information in a self-attention layer.\nCompared with normal RGAT, line-graph enhanced RGAT employs an additional edge-centric line graph constructed from the original node-centric graph. During the iteration process of node embeddings, each node in either graph integrates information from its neighborhood and incorporates edge features from the dual graph to update its representation. \nDue to the limited space, we omit the formal definition of RGAT.\nThe reader can refer to \\cite{lgesql} for the implementation details of LGESQL.\n\n\n"
                },
                "subsection 2.3": {
                    "name": "Decoder",
                    "content": "\nBoth RAT-SQL and LGESQL apply grammar-based syntactic neural decoder \\cite{YinN17} to generate the abstract syntax tree (AST) of the target query $Y$ in a depth-first-search order. \nThe output at each decoding time step is either 1) an  $\\mathtt{APPLYRULE}$ action that expands the current non-terminal node in the partially generated AST, or 2) $\\mathtt{SELECTTABLE}$ or $\\mathtt{SELECTCOLUMN}$ action that chooses one schema item from the output memory of encoder. \nThe readers can refer to \\cite{ratsql} for more details.\n\n\\paragraph{\\textbf{Discussion of Schema Linking}}\nAs mentioned above, $r_{i,j}$ in Eq.\\ref{rij1} and Eq.\\ref{rij2} represents the schema linking items in inputs.\nThe graphs adopted in RAT-SQL and LGESQL are constructed by schema linking with lexical matching. \nFor instance, the word ``\\textit{cylinders}'' in a NL question will be linked to the \\texttt{cylinders} column in a table \\texttt{cars\\_data}.\nIn this way, a relation-aware input graph can be constructed, which is represented as an adjacency matrix.\nHowever, the rule-based string matching is inapplicable in more challenging scenarios where the NL questions contain implicit mentions such as synonym substitution and entity abbreviation. \nThe missing linkage may hinder the encoder's ability to capture salient relations.\nIn this paper, we propose to probe schema linking information from large-scale PLMs that are claimed to contain rich \\emph{semantic} relational knowledge implicitly.\nIt is noteworthy that our probing technique is model-agnostic and potentially applicable for any text-to-SQL parsing models. In the next section, we will introduce the details of our probing technique. \n\n\\iffalse\nGenerally, graph-based Text-to-SQL models consider the question as well as the database schema as a single direct graph $\\mathcal{G} = \\langle \\mathcal{V}, \\mathcal{E} \\rangle $.\nThe nodes, $\\mathcal{V} = Q \\cup \\mathcal{T} \\cup \\mathcal{C}$, contain all input question tokens and schema items as mentioned above.\nThe edges $\\mathcal{E}$ depict arbitrary \\emph{pre-existing} relations.\nTwo representative graph-based models, RAT-SQL \\cite{ratsql} and LGESQL \\cite{lgesql}, have achieved state-of-the-art performance on this task.\nGiven the input graph $\\mathbf{G}$,  a Relational Graph Attention Network (RGAT, \\citealt{ratsql}) is employed as the encoder.\nRGAT is based on the classic graph attention network, but represents relative position information via self-attention.\nFormally, given the graph $\\mathbf{G}$ and input embeddings $\\mathbf{x}^{l} \\in \\mathbb{R}^{\\left|V^{n}\\right| \\times d}$ at a specific layer $l$, the output representation $\\mathbf{x}^{l+1}$ is computed as:\n\\begin{equation}\n    \\mathbf{x}^{l+1} = \\operatorname{RGAT}\\left( \\mathbf{x}^{l}, \\mathbf{G} \\right).\n    % $}\n\\end{equation}\n\n\n\n\nThe edges of the graph are defined as schema linking relations via rule-based string match methods.\nFor instance, the word \\texttt{cylinders} in a question will be linked to the \\texttt{cylinders} column in a table \\texttt{cars\\_data}, since they form a trivial string match.\nAfterwards, a relation-aware input graph is constructed, which is represented as an adjacency matrix.\nWe conjecture that rule-based string matching is not sufficient to cover semantic relations between questions and schemas. \nThe missing linkage may hinder the encoder's ability to capture \\lbw{salient relations}.\nIn the next section, we propose to probe such relations from PLMs that are claimed to contain rich \\emph{semantic} relational knowledge implicitly.\nOur method is favorably applicable to different graph-based Text-to-SQL models as it can be seamlessly integrated into the graph construction process.\n\\fi\n\n\n \n"
                }
            },
            "section 3": {
                "name": "Probing Schema Linking",
                "content": "\nIn this section, we introduce a  parameter-free probing technique, as illustrated in Figure \\ref{prob}, to probe schema linking information between the NL query and the database schema from PLMs. Concretely, we propose a masking technique to measure the correlation between NL question tokens and schema items (i.e., columns and tables) in the masked language modeling (MLM) process. \n\n\n\n",
                "subsection 3.1": {
                    "name": "Probing Stage",
                    "content": "\n\nGiven a database schema $\\mathcal{S}=\\langle\\mathcal{T}, \\mathcal{C}\\rangle$, where the table and column sequences are $\\mathcal{T}=\\left(t_{1}, t_{2}, \\cdots, t_{|\\mathcal{T}|} \\right)$ and $\\mathcal{C}=\\left(c_{1}, c_{2}, \\cdots, c_{|\\mathcal{C}|} \\right)$ respectively.\nWe first concatenate $T$ and $C$ into a single sequence $\\mathcal{S}=\\left(\\mathcal{T}, \\mathcal{C}\\right)=\\left(s_1, s_2, ..., s_{|\\mathcal{T}| + |\\mathcal{C}|}\\right)$.\nTogether with the NL question sequence $\\mathcal{Q}=\\left(q_1, q_2, ..., q_{|Q|}\\right)$, the input $\\mathcal{I}$ is formed by a sequential concatenation of $\\mathcal{Q}$ and $\\mathcal{S}$ as:\n\\begin{equation*}\n\\resizebox{1\\hsize}{!}{$\n\\mathcal{I}= (\\langle\\mathsf{s}\\rangle;q_1;\\dots;q_{|Q|};\\langle\\backslash\\mathsf{s}\\rangle; s_1;\\langle\\backslash\\mathsf{s}\\rangle;\\dots;\\langle\\backslash\\mathsf{s}\\rangle; s_{|\\mathcal{T}| + |\\mathcal{C}|}),\n $}\n\\end{equation*}\nwhere $\\langle\\mathsf{s}\\rangle$, $\\langle\\backslash\\mathsf{s}\\rangle$ are special tokens to delimit the input tokens. \n% \\footnote{Different special tokens apply for different PLMs. \\lbw{[details]}}\nThe MLM maps the input $\\mathcal{I}$ into the deep contextualized representations. \nWe denote $(\\mathbf{h}^{q}_1, \\ldots, \\mathbf{h}^{q}_{|Q|})$ and $(\\mathbf{h}^{s}_1, \\ldots, \\mathbf{h}^{s}_{|\\mathcal{T}| + |\\mathcal{C}|})$ as  question token representations and schema item representations, respectively.\n\nThe goal of our probing technique is to derive a function $f(\\cdot,\\cdot)$ that captures the correlation between an arbitrary pair of a question token and a schema item.\nTo this end, we employ a two-step MLM process.\nIt is inspired by the observation that a word is considered as essential for document classification if removing the word from a document leads to a considerable accuracy decrease.\n\nAs shown in Figure \\ref{prob}, we first feed the input $\\mathcal{I}$ into the PLM. We use $\\mathbf{h}^{s}_{j}$ to denote the contextualized representation of the $j$-th schema item $s_j$, where $1 \\le j \\le |\\mathcal{T}| + |\\mathcal{C}|$.\nThen, we replace the question token $q_i$ with a special mask token $\\texttt{[MASK]}$ and feed the corrupted input $\\mathcal{I}\\backslash\\left\\{q_i\\right\\}$ into the PLM again.\nAccordingly, we use $\\mathbf{h}^{s}_{j \\backslash q_i}$ to denote the new representation of the $j$-th schema item when $q_i$ is masked out.\\footnote{\n\\citet{wu2020perturbed} proposed a similar two step perturbed masking.\nThe difference is that they first masked out one input token $\\{s_i\\}$ and then masked out a token pair $\\{s_i, s_j\\}$.\nThen the correlation was obtained by comparing $\\mathbf{h}_{i \\backslash \\{s_i\\}}$ and $\\mathbf{h}_{i \\backslash \\{s_i, s_j\\}}$.\nThis method heavily relies on the MLM prediction ability of the PLMs (e.g., BERT).\nWe tried it in our preliminary experiments, but it performed poorly.\nWe conjecture that our input data (i.e., questions and schemas) differs from the PLM's pre-training data, and the PLM struggles to make reasonable schema predictions without further finetuning.\n}\n\nFormally, we measure the distance between $\\mathbf{h}^{s}_{j}$ and $\\mathbf{h}^{s}_{j \\backslash q_i}$ to induce the correlation between the schema item $s_j$ and the question token $q_i$ as follows:\n\\begin{equation}\n\tf(q_i, s_j) = d(\\mathbf{h}^{s}_{j \\backslash q_i}, \\mathbf{h}^{s}_{j})\n\\end{equation}\nwhere $d(\\cdot,\\cdot)$ is the distance metric to measure the difference between two vectors. Generally, we can use Euclidean distance metric to implement  $d(\\cdot,\\cdot)$:\n\\begin{equation}\n\\label{eq:euclidean}\n\td_{\\rm Euc}(q_i, s_j) = || \\mathbf{h}^{s}_{j \\backslash q_i} - \\mathbf{h}^{s}_{j}||_2\n\\end{equation}\nwhere $d_{\\rm Euc}(\\cdot,\\cdot)$ denotes a distance function in Euclidean space. \n\n\n"
                },
                "subsection 3.2": {
                    "name": "Poincar\\'e Probe",
                    "content": "\nEuclidean space has intrinsic difficulties in modeling complex data \\cite{bronstein2017geometric}. \nTo better model the heterogeneous relational structures between the NL query and the database schema, we devise a Poincar\\'e probe, which probes schema linking information from PLMs in the hyperbolic space that is expected to better capture linguistic hierarchies encoded in contextualized representations \\citep{nickel2017poincare, Tifrea19PoincareGlove}. As revealed in \\cite{chami2019hyperbolic}, the hyperbolic space enables vector comparison with much smaller distortion compared with the Euclidean space. In addition, recent work \\cite{krioukov2010hyperbolic,nickel2017poincare,chami2019hyperbolic} demonstrates that the hyperbolic space may reflect some properties of graph naturally.\n\n \n\n\\paragraph{\\textbf{The Poincar\\'e Ball}}\nIn this paper, we employ the standard Poincar\\'e ball, which is a special model of hyperbolic spaces, to capture the difference between $\\mathbf{h}^{s}_{j \\backslash q_i}$ and  $\\mathbf{h}^{s}_{j}$.\nBefore introducing the Poincar\\'e Probe, we first review basic concepts of the standard Poincar\\'e ball following \\citet{ganea2018hyperbolic}. Formally, for a point $\\mathbf{x}$ in the hyperbolic space, the standard Poincar\\'e ball model is defined as $\\left(\\mathbb{D}^{n},g_{\\mathbf{x}}^{\\mathbb{D}}\\right)$, where $\\mathbb{D}^{n}=\\left\\{\\mathbf{x} \\in \\mathbb{R}^{n} \\mid \\|\\mathbf{x}\\|^{2}<1\\right\\}$ is a Riemannian manifold and $g_{\\mathbf{x}}^{\\mathbb{D}}=\\left(\\lambda_\\mathbf{x}\\right)^{2} \\mathbf{I}_{n}$ is the metric tensor. We formulate $\\lambda_{\\mathbf{x}}=2 /\\left(1-\\|\\mathbf{x}\\|^{2}\\right)$ as the conformal factor. Here, $n$ denotes the dimension size. \n\n\\paragraph{\\textbf{Feature Projection}}\nTo compare the feature vectors learned by PLMs in the hyperbolic space, we first use the exponential mapping function $g_\\mathbf{x}(\\cdot)$ to project the embeddings into the hyperbolic space. \nSuppose $\\mathbf{h}\\in \\mathbb{T}^n_{\\mathbf{x}}$ is the input vector in the tangent space with respect to the point $\\mathbf{x}$ in the hyperbolic space. Here, $\\mathbf{h}$ will be instantiated as $\\mathbf{h}^{s}_{j \\backslash q_i}$ and $\\mathbf{h}^{s}_{j}$. The mapping function $g_\\mathbf{x}(\\cdot)$: $\\mathbb{T}_{\\mathbf{x}}^{n} \\rightarrow \\mathbb{D}^{n}$ can be computed by:\n\\begin{equation}\n  g_{\\mathbf{x}}\\left(\\mathbf{h}\\right)= \\mathbf{x} \\oplus \\left(\\tanh \\left( \\frac{\\lambda_{x}\\left\\|\\mathbf{h}\\right\\|}{2}\\right) \\frac{\\mathbf{h}}{\\left\\|\\mathbf{h}\\right\\|}\\right) \n\\end{equation}\nwhere the operation $\\oplus$ is the M\\\"obius addition. For any $\\mathbf{a}, \\mathbf{b} \\in \\mathbb{D}^{n}$, it is calculated as:\n\\begin{equation}\n\\label{eq:mobius}\n \\mathbf{a} \\oplus \\mathbf{b} = \\frac{\n \\left(1+2\\left\\langle \\mathbf{a}, \\mathbf{b}\\right\\rangle+\\left\\|\\mathbf{b}\\right\\|^{2}\\right) \\mathbf{a}+\\left(1-\\left\\|\\mathbf{a}\\right\\|^{2}\\right) \\mathbf{b} }{ 1+2 \\left\\langle \\mathbf{a}, \\mathbf{b}\\right\\rangle+\\left\\|\\mathbf{a}\\right\\|^{2}\\left\\|\\mathbf{b}\\right\\|^{2}} \n\\end{equation}\n\nIn this work, we assume that $\\mathbf{h}$ lies in the tangent space at the point $\\mathbf{x}=\\mathbf{0}$.\nThen, the hyperbolic representation $\\tilde{\\mathbf{h}}$ of $\\mathbf{h}$ can be obtained by:\n\\begin{equation}\n\\label{eq:exp proj}\n\\tilde{\\mathbf{h}} =  g _{\\mathbf{0}}\\left(\\mathbf{h}\\right)=\\tanh \\left( \\left\\|\\mathbf{h}\\right\\|\\right) \\frac{\\mathbf{h}}{  \\left\\|\\mathbf{h}\\right\\|}.\n\\end{equation}\n\n\n\n\\iffalse\nThen, for $\\mathbf{h} \\in T_{x} \\mathbb{D}_{c}^{n} \\backslash\\{\\mathbf{0}\\}$, where $x$ is a point in the hyperbolic space and $T_{x} \\mathbb{D}_{c}^{n}$ is the tangent space at point $x$,\nthe exponential map $\\exp _{x}^{c}: T_{x} \\mathbb{D}_{c}^{n} \\rightarrow \\mathbb{D}_{c}^{n}$ for $x \\neq 0$ is given by:\n%\n\\begin{equation}\n  \\exp _{x}^{c}\\left(\\mathbf{h}\\right)=x \\oplus_{c}\\left(\\tanh \\left(\\sqrt{c} \\frac{\\lambda_{x}^{c}\\left\\|\\mathbf{h}\\right\\|}{2}\\right) \\frac{\\mathbf{h}}{\\sqrt{c}\\left\\|\\mathbf{h}\\right\\|}\\right),\n\\end{equation}\n%\nwhere $\\lambda_{x}^{c}= 2/ {\\left(1-c\\|x\\|^{2}\\right)}$ is the conformal factor.\nThe operation $\\oplus_{c}$ is the M\\\"obius addition.\nFor any $\\mathbf{a}, \\mathbf{b} \\in \\mathbb{D}_{c}^{n}$, it is calculated as:\n%\n\\begin{equation}\n\\label{eq:mobius}\n \\mathbf{a} \\oplus_{c} \\mathbf{b} = \\frac{\n \\left(1+2 c\\left\\langle \\mathbf{a}, \\mathbf{b}\\right\\rangle+c\\left\\|\\mathbf{b}\\right\\|^{2}\\right) \\mathbf{a}+\\left(1-c\\left\\|\\mathbf{a}\\right\\|^{2}\\right) \\mathbf{b} }{ 1+2 c\\left\\langle \\mathbf{a}, \\mathbf{b}\\right\\rangle+c^{2}\\left\\|\\mathbf{a}\\right\\|^{2}\\left\\|\\mathbf{b}\\right\\|^{2}}.\n\\end{equation}\n\nIn our case, we assume that $\\mathbf{h}$ lies in the tangent spaces at the point $x = 0$.\nThen the hyperbolic representation $\\hat{\\mathbf{h}}$ of $\\mathbf{h}$ can be obtained by\n\\begin{equation}\n\\label{eq:exp proj}\n\\tilde{\\mathbf{h}} =  \\exp _{\\mathbf{0}}^{c}\\left(\\mathbf{h}\\right)=\\tanh \\left( \\sqrt{c}\\left\\|\\mathbf{h}\\right\\|\\right) \\frac{\\mathbf{h}}{ \\sqrt{c} \\left\\|\\mathbf{h}\\right\\|}.\n\\end{equation}\n\\fi\n\n\n\\paragraph{\\textbf{The Poincar\\'e Distance}}\nAfter obtaining the feature representations in the hyperbolic space via the feature mapping function $g_{\\mathbf{x}}(\\cdot)$, we can measure the correlation between the schema item $s_j$ and the question token $q_i$ by calculating the Poincar\\'e distance between  $\\tilde{\\mathbf{h}}^s_j$ and $\\tilde{\\mathbf{h}}^s_{j\\backslash {q_i}}$ in the hyperbolic space as follows:\n\\vspace{-0.15cm}\n\\begin{equation}\n\td_{\\rm Poin}(q_i, s_j) = 2 \\tanh ^{-1} ( \\| - \\tilde{\\mathbf{h}}^s_{j\\backslash {q_i}}  \\oplus \\tilde{\\mathbf{h}}^s_j \\|)\n\\end{equation}\nwhere $\\oplus$ is the M\\\"obius addition defined in Eq. (\\ref{eq:mobius}). We can replace the Euclidean distance $d_{\\rm Euc}(\\cdot, \\cdot)$ defined in Eq. (\\ref{eq:euclidean}) with the Poincar\\'e distance $d_{\\rm Poin}(\\cdot, \\cdot)$ to implement the function $f(\\cdot, \\cdot)$ for relational knowledge probing.\n\n"
                },
                "subsection 3.3": {
                    "name": "Schema Linking for Graph Construction",
                    "content": "\nBy repeating the two-stage MLM process on\neach pair of tokens $q_i$, $s_j$ and calculating \n$f(q_i, s_j)$, we obtain a relation matrix $\\mathbf{X} = \\{x_{i,j}\\}_{i=1, j=1}^{|Q|,|S|}$, where $x_{i, j}$ denotes the relation between question-schema pair $(q_i, s_j)$. \nWe utilize the min-max normalization to reduce the impact of the range of correlation scores: \n\\begin{equation}\n\\tilde{x}_{i,j} = \\frac{x_{i,j}-\\min \\left(\\mathbf{X}\\right)}{\\max \\left(\\mathbf{X}\\right)-\\min \\left(\\mathbf{X}\\right)}\n\\end{equation}\n\nNow, we can derive a strategy to construct the unweighted direct graph $G$ used in RAT-SQL and LGESQL. Specifically, we convert the relation matrix $\\mathbf{X}$ into an adjacency matrix $\\mathbf{A}$ that represents the structure of graph $\\mathcal{G}$. We compute the adjacency matrix $\\mathbf{A}$ by:\n\\begin {equation}\n\\label{adjacency}\n\\mathbf{A}_{i j}=\\left\\{\\begin{array}{cl}\n\\text {0} & \\text { if } \\tilde{x}_{i, j} < \\tau \\\\\n\\text { 1 } & \\text { if } \\tilde{x}_{i, j} > \\tau \n\\end{array}\\right. ,\n\\end{equation}\nwhere $\\tau$ is a pre-defined threshold.\nThe learned adjacency matrix $\\mathbf{A}$ via probing the relational knowledge from PLMs can facilitate the semantic linking of text-to-SQL parsing. \n\n\\iffalse\nIt should be noticed that the sum of row $x_i$ is not equal to $1$ because each token in question is not only related to one token in the schema.\nWe further convert the relational matrix into probing-related adjacency matrix $\\mathbf{A}$ via:\n\\begin {equation}\n\\mathbf{A}_{i j}=\\left\\{\\begin{array}{cl}\n\\text {0} & \\text { if } {x}_{i, j} < \\tau \\\\\n\\text { 1 } & \\text { if } {x}_{i, j} > \\tau \n\\end{array}\\right. ,\n\\end{equation}\nwhere $\\tau$ is a threshold.\nAfter obtaining the probing-related adjacency matrix $\\mathbf{A}$ via probing the relational knowledge from PLMs, we can enrich the original input $\\mathbf{G}$ mentioned in Sec.~\\ref{sec:graph} to further improve the semantic parsing model.\n\\fi\n\n"
                }
            },
            "section 4": {
                "name": "Experimental Setup",
                "content": "\n",
                "subsection 4.1": {
                    "name": "Datasets",
                    "content": "\nWe conduct extensive experiments on three benchmark  datasets. (1) \\textbf{Spider} \\cite{spider} is a large-scale cross-domain zero-shot text-to-SQL benchmark.\nWe follow the common practice to report the exact match accuracy on the development set, as the test set is not publicly available. (2) \\textbf{DK} \\cite{spiderDK} is a human-curated dataset based on  Spider, a challenging variant of the Spider development set, with focus on evaluating the model understanding of domain knowledge. \n(3) \\textbf{SYN} \\cite{spiderSYN} is another challenging variant of Spider.\nSYN is constructed by manually modifying NL questions in Spider using synonym substitution, which aims to simulate the scenario where users do not know the exact schema words in the utterances.\n\n"
                },
                "subsection 4.2": {
                    "name": "Baselines",
                    "content": "\nWe choose RAT-SQL and LGESQL as our base parsers,\nwhere RAT-SQL is a sequence-to-sequence model enhanced by a relational-aware transformer and LGESQL is a graph attention network based sequence-to-sequence model with the relational GAT and the line graph.\nBoth models use schema linking to build the input graph.\nMeanwhile, for a comprehensive comparison, we also compare our model with several recent state-of-the-art models, including GNN \\citep{bogin-representing}, IRNet \\citep{guo2019towards}, EditSQL \\citep{editsql}, RYANSQL \\citep{Choi2020RYANSQLRA}, TranX \\citep{Yin2020TaBERTPF}. \nFor RAT-SQL, we choose RAT-SQL + Grappa as our baseline, which has the best performance of RAT-SQL.\nWe adopt the same hyper-parameter settings as in \\citet{Yu2020GraPPaGP}.\n\n"
                },
                "subsection 4.3": {
                    "name": "Implementation Details",
                    "content": "\nFor RAT-SQL, in the encoder, the hidden size of bidirectional LSTMs per direction is set to 128. \nThe number of relation-aware self-attention layers stacked on top of the bidirectional LSTMs is 8 and the dimension of each attention layer is 256.\nThe position-wise feed-forward network has inner layer dimension 1024. In the decoder, the dimension of rule embedding, node type embedding and hidden state are set to 128, 64 and 512 respectively. \nRAT-SQL applies Adam optimizer \\cite{kingma2014adam} with default hyperparameters.\nThe batch size is 8 and the number of training steps is 40,000.\n\nFor LGESQL, in the encoder, the GNN hidden size is set to 512 for PLMs. The number of GNN layers is 8. In the decoder, the dimension of hidden state, action embedding and node type embedding are set to 512, 128 and 128 respectively. \nThe recurrent dropout rate is 0.2 for decoder LSTM. The number of heads in multi-head attention is 8 and the dropout rate of features is set to 0.2 in both the encoder and decoder.\nLGESQL uses AdamW optimizer \\cite{loshchilov2017decoupled} with linear warmup scheduler and the warmup ratio of total training steps is 0.1.\nThe maximum gradient norm is set to 5.\nThe batch size is 20 and the number of training epochs is 200.\n\n\n\n\n\n\n"
                }
            },
            "section 5": {
                "name": "Experimental Results",
                "content": "\n",
                "subsection 5.1": {
                    "name": "Main Results",
                    "content": "\nTables \\ref{tab:dk}-\\ref{tab:spider} show the results of DK, SYN and Spider datasets, respectively. From the results, we have the following observations. First, we can observe that the LGESQL with our probing methods (\\ie, Euclidean \\name and Hyperbolic \\name) yields substantially better results than the compared baseline methods on all the datasets. In particular,  LGESQL+ELECTRA-large with Hyperbolic \\name achieves the exact match accuracy of 51.0\\% on the DK benchmark, which obtains 2.6\\% improvement over LGESQL+ELECTRA-large. \nThe effectiveness of \\name on the DK benchmark demonstrates that the semantic and relational knowledge elicited from PLMs can help text-to-SQL parsers understand the domain knowledge and adapt the knowledge to a new domain. Similar trends can be observed on the SYN benchmark and the Spider dataset. For instance, LGESQL+ELECTRA-large with Hyperbolic \\name achieves the strong performance (76.3\\%) for text-to-SQL parsing on the Spider dataset. The exact match accuracy increases by 1.0\\% over the best baseline LGESQL+ELECTRA-large.  As we know, it is difficult to boost 1\\% of exact match accuracy on the Spider dataset.  This also verifies the effectiveness of our \\name model.\nSecondly, we find that Hyperbolic \\name performs better than Euclidean \\name with notable improvements across all datasets. This is because the Poincar\\'e distance metric can better measure semantic relevance between NL queries and database schema than the typical Euclidean distance metric.\nThird, Hyperbolic \\name can largely improve the performance of RAT-SQL+Grappa, up to 7.9\\% on the DK benchmark and 13.5\\% on SYN benchmark. The reason may be that RAT-SQL+Grappa is not well designed for schema linking, while our Hyperbolic \\name can effectively capture the relational information between the NL query and the database schema by probing relational knowledge from PLMs. \n\n\n\n\n\n\n\n\n"
                },
                "subsection 5.2": {
                    "name": "Schema Linking Performance Analysis",
                    "content": "\nTo have a better analysis on how \\name help capture relational knowledge from PLMs, we carefully conduct error checking in terms of schema linking on the Spider benchmark.\nWe analyze the errors made by previous works \\cite{ratsql,lgesql} and classify them into four categories: \\textit{World Knowledge Error}, \\textit{Semantic Understanding Error}, \\textit{Type Error} and \\textit{Inference Error}. We observe that \\name can successfully solve most of these bad cases which the previous methods fail to address. Due to the limited space, we only report one or two representative examples for each error category  in Figure \\ref{fault_type}. From the results, we have the following observations.\n\nFirst, we find that most of wrong predictions are due to the lack of world knowledge \\cite{slsql}. For example, as shown in the first example in Figure \\ref{fault_type}, the rule-based semantic linking with exact text matching can not predict ``\\textit{Brazil}'' as a country name , and it also fails to understand that ``\\textit{republic}'' is a government form in the second example. \nTheoretically, PLMs can be seen as an external knowledge resource by pre-training on large-scale corpora, and previous models with PLMs can identify that the word ``\\textit{republic}'' is related to ``\\textit{government form}'' by referring to PLMs. However, previous methods with PLMs still fail to capture these reference linking \\cite{slsql,ratsql,lgesql}. This is because only using the embeddings of PLMs cannot effectively elicit relational knowledge from PLMs.  \nIn contrast, our probing method can successfully elicit such world (relational) knowledge, and is portable for practical use.\n\nSecond, one kind of error categories is caused by failing to capture semantic relations between words and tables/columns. The rule-based schema linking often chooses columns/tables that exactly occur in the query via exact string matching.\nAs shown in the fourth example in Figure \\ref{fault_type}, the rule-based schema linking method links the word ``\\textit{maker}'' to the column ``\\textit{car\\_makers.Maker}''  while the correct choice should be the column ``\\textit{car\\_names.Make}''. Similarly, the third example fails to identify that the word ``\\textit{highschooler}'' is a synonym of ``\\textit{students}''.\nThis can be solved by considering in-depth semantic information of the query instead of only word occurrence. Our probing method can easily solve this kind of problem.\n\nThird, some questions may contain more than one entity words that can match the table names. The rule-based schema linking could choose the wrong columns that match the entity names occurred in the question. For example, in the fifth example, the rule-based schema linking predicts the wrong column ``\\textit{Address}'' instead of the correct column ``\\textit{current\\_address\\_id}''. \nIn addition, in some special cases, when the column name exactly matches the keyword in the question,  the rule-based schema linking can not distinguish it clearly, as shown in the sixth example.\nThis problem often occurs when the question contains keywords such as average, maximum, and minimum, etc.\n\nFinally, the rule-based schema linking cannot solve the difficult cases that require strong inference ability.\nTaking the seventh example as an example, the word ``\\textit{accepted}'' in the question implicitly links the column ``\\textit{decision}'', which cannot be identified by exact string matching. \nOur \\name model can solve these difficult cases by using semantic information learned from PLMs.\n\n\n\n\n\n\n\\vspace{-0.2cm}\n"
                },
                "subsection 5.3": {
                    "name": "Case Study",
                    "content": "\nWe use four exemplary cases selected from DK and SYN benchmarks to demonstrate the effectiveness of our model qualitatively. Table \\ref{tab:case} shows the SQL queries generated by the best baseline LGESQL and our \\name model, where the first two cases are from the SYN benchmark and the last two cases are from the DK benchmark. From the results, we can observe that \\name can generate correct SQL queries when dealing with challenging scenarios such as synonym substitution.\nFor instance, in the first case, when replacing the schema-related word  ``\\textit{type}'' with its synonym  ``\\textit{category}'' in NL question, LGESQL fails to identify the correct column \\texttt{PetType}. \n\nFigure \\ref{fig:case1} shows the visualization of correlation matrices obtained by rule-based feature engineering and our probing technique. In the right two sub-figures, the rule-based technique (exact string matching) cannot capture the alignment between the word ``\\textit{category}'' and the schema item \\texttt{PetType}. While \\name can easily catch such semantic similarity with the help of elicited knowledge from PLMs, it thus generates the correct SQL query. \nSimilarly, in the left two sub-figures, \\name successfully links the domain knowledge word ``\\textit{French}'' to column \\texttt{Citizenship}, while LGESQL fails to identify the column \\texttt{Citizenship} without explicit mentions.\nWe believe that  \\name can probe rich semantic and relational knowledge from large-scale PLMs, facilitating schema linking in text-to-SQL parsing. \n\n\n"
                }
            },
            "section 6": {
                "name": "Related Work",
                "content": "\n\n\\noindent\\paragraph{\\textbf{Text-to-SQL Parsing.}}\nRecently, meaningful advances emerged on the encoder \\cite{bogin-representing,chen2021shadowgnn,hui2022ssql,hui2021dynamic}, decoder \\cite{YinN17,Choi2020RYANSQLRA,hui2021improving} and table-based pre-training models \\cite{Yin2020TaBERTPF,Yu2020GraPPaGP,Shi2020LearningCR,qin2021sdcup,liu2022tapex} on Spider benchmark\\cite{spider}.\nIn particular, \\citet{slsql} pointed out that the schema linking module in the encoder was a crucial ingredient for successful prediction. \nTo tackle the problem, \\citet{typesql} incorporated prior knowledge of column types and schema linking as additional input features. \\citet{guo2019towards} used heuristic rules to construct intermediate representation. \\citet{editsql} used the co-attention mechanism to measure similarity between NL tokens with schema tokens.\nThe recent method RAT-SQL \\cite{ratsql} utilized a relational graph attention to handle various pre-defined relations and further considered both local and non-local edge features.\nTo tackle the robustness problem in a more realistic setting, \\citet{spiderSYN} proposed to use different data augmentation techniques including data annotation and adversarial training.\n\\citet{wang2020meta} proposed a model-agnostic meta-learning based training objective to boost out-of-domain generalization of text-to-SQL models.\n\\citet{Scholak2021PICARDPI} propose PICARD, a method for constraining auto-regressive decoders of language models through incremental parsing. \nDifferent from these methods, we are the first to explore the potential knowledge stored in PLMs to help the model perform better schema linking and further improve the generalization of the model.\n\n\\noindent\\paragraph{\\textbf{Probing PLMs.}}\nThe success of PLMs has led to a large number of studies investigating and interpreting the rich knowledge that PLMs learn implicitly during pre-training \\citep{kovaleva-etal-2019-revealing, rogers2020primer,he2021galaxy, he2022unified}.\nOne typical approach is to probe PLMs with a small amount of learnable parameters considering a variety of linguistic properties, including morphology \\citep{belinkov-etal-2017-neural}, word sense \\citep{bert-geomertry}, syntax \\cite{hewitt2019structural, dai2021does}, world knowledge \\cite{petroni2019language} and semantics \\citep{liu-etal-2019-linguistic}.\nAnother line of work is motivated to probe PLMs in an unsupervised and parameter-free fashion \\citep{wu2020perturbed, li-etal-2020-heads}.\nOur work generally follows this line and exploits an unsupervised probing technique to extract relational knowledge for the downstream text-to-SQL parsing task.\n\\citet{liu2021awakening} proposed the ETA model to explore the grounding capabilities of PLMs. The proposed erasing-then-awakening  trains a concept classification module by human-crafted supervision.\nThen, it erases tokens in a question to obtain the concept prediction confidence differences as pseudo alignment.\nFinally, it awaken latent grounding from PLMs by applying pseudo alignment as supervision.\nThis method requires human-crafted label as supervision, which could not be easily obtained in most tasks.\nFurthermore, the additional trainable parameters may cause failures to adequately reflect differences in representations \\citep{hewitt-liang-2019-designing}.\n\nDifferent from previous methods, \\name does not need any extra labels or supervision, which is not limited to specific tasks.\nOur method follows an unsupervised technique, which makes sure all the relational knowledge is extracted from PLMs.\nIn addition, \\name utilizes a direct graph to represent the relational knowledge and can better extract the relational information within the input.\n\n"
            },
            "section 7": {
                "name": "Conclusion",
                "content": "\nIn this paper, we proposed a probing technique to probe schema linking information between the NL query and the database schema from large-scale PLMs, which improved the generalization and robustness of the text-to-SQL parsing models. In addition, a Poincar\\'e distance metric was devised to measure the difference between two vectors in the hyperbolic space, capturing the heterogenous relational structures between the NL query and the database schema.\nExperimental results on three benchmark datasets demonstrated that our method substantially outperformed strong baselines and set state-of-the-art performance on three text-to-SQL benchmarks. \n\n\n\\begin{acks}\nThis work was partially supported by National Natural Science Foundation of China (No. 61906185), Youth Innovation Promotion Association of CAS China (No. 2020357), Shenzhen Science and Technology Innovation Program (Grant No. KQTD20190929172835662), Shenzhen Basic Research Foundation (No. JCYJ20210324115614039 and No. JCYJ20200109113441941).\nThis work was supported by Alibaba Group through Alibaba Innovative Research Program.\n\\end{acks}\n\n\n%%\n%% The next two lines define the bibliography style to be used, and\n%% the bibliography file.\n\\bibliographystyle{ACM-Reference-Format}\n\\bibliography{anthology.bib,custom.bib,text2sql.bib}\n\n\n%%\n%% If your work has an appendix, this is the place to put it.\n\\appendix\n\n\n\n"
            },
            "section 8": {
                "name": "Results on Complex Queries",
                "content": "\nThe three benchmarks provide four different difficulty levels of samples. We investigate the detailed model performance and have further insights on how \\name can help complex queries.\nTable \\ref{diff_result} shows the exact match accuracy by varying the levels of difficulty of the data.\nFrom the results, we can observe that  \\name can boost the performance of SOTA text-to-SQL parsers (RAT-SQL/LGESQL) across almost all different difficulty levels on the three benchmark datasets.\nIt suggests that \\name can lead to more significant accuracy improvements compared to RAT-SQL/LGESQL.\nFor example, LGESQL with Hyperbolic \\name, which better captures the relational knowledge, achieves the highest score on most cases.\nIn particular, \\name gains much better performance on the extremely hard samples than the baselines, verifying that the harder samples require better schema linking for correct text-to-SQL parsing.\n\n\n\n"
            },
            "section 9": {
                "name": "Computational Cost",
                "content": "\nWe investigate the computational cost of baseline methods and our \\name model in inference.\nAll these models are run on a desktop machine with a single NVIDIA Tesla V100 GPU. \nIn Table \\ref{tab:time}, we report the inference time on 1034 SYN samples with the batch size of 1. \\name has a slightly slower inference speed than the base models (LGESQL and RAT-SQL). For example, on average, the inference time of \\name with Poincar\\'e probe increases by 0.09s on each sample compared with LGESQL, which is acceptable in practice.\n\n"
            }
        },
        "tables": {
            "tab:dk": "\\begin{table}[t]  \n    \\centering\n     \\setlength{\\abovecaptionskip}{5pt} \n    \\caption{Exact match accuracy (\\%) on DK benchmark. }\n    \\small\n    \\begin{tabular}{lc}  \n    \\toprule\n    \\textbf{Model}& \\textbf{Acc.} \\\\ \n    \\midrule\n    GNN + BERT \\citep{bogin-representing} & 26.0 \\\\ \n    IRNet + BERT \\citep{guo2019towards} & 33.1  \\\\ \n    RAT-SQL  \\citep{ratsql} & 35.8\\\\\n    RAT-SQL + BERT \\citep{ratsql} & 40.9 \\\\\n    RAT-SQL + GAP \\citep{Shi2020LearningCR} & 44.1\\\\\n    \n    \\midrule\n    \n    RAT-SQL + Grappa  & 38.5  \\\\\n    \\quad w/ Euclidean \\name & {45.0} ($\\uparrow$ 6.5)\\\\\n    \\quad w/ Hyperbolic \\name& \\textbf{46.4} ($\\uparrow$ \\textbf{7.9})\\\\\n    \\midrule\n    \n    LGESQL + RoBERTa-large & 45.9   \\\\\n    \\quad w/ Euclidean \\name& {46.2} ($\\uparrow$ 0.3)\\\\\n    \\quad w/ Hyperbolic \\name& \\textbf{46.7} ($\\uparrow$ 0.8)\\\\\n    \\midrule\n    LGESQL + ELECTRA-large & 48.4   \\\\\n    \\quad w/ Euclidean \\name& {49.3} ($\\uparrow$ 0.9)\\\\\n    \\quad w/ Hyperbolic \\name& \\textbf{51.0} ($\\uparrow$ 2.6)\\\\\n    \n    \\bottomrule\n    \\end{tabular}  \n    \\label{tab:dk}\n    \\vspace{-0.3cm}\n\\end{table}",
            "tab:syn": "\\begin{table}[t]  \n    \\centering\n    \\setlength{\\abovecaptionskip}{5pt}  \n    \\caption{Exact match accuracy (\\%) on SYN benchmark. }\n    \\small\n    \\begin{tabular}{lc}  \n    \\toprule\n    \\textbf{Model}& \\textbf{Acc.} \\\\ \n    \\midrule\n    GNN \\citep{bogin-representing} & 23.6 \\\\ \n    IRNet  \\citep{guo2019towards} & 28.4  \\\\ \n    RAT-SQL  \\citep{ratsql} & 33.6\\\\\n    RAT-SQL + BERT \\citep{ratsql} & 48.2\\\\\n    \\midrule \n    \n    RAT-SQL + Grappa & 49.1\\\\\n\n    \\quad w/ Euclidean \\name& {61.4} ($\\uparrow$ 12.3)\\\\\n    \\quad w/ Hyperbolic \\name& \\textbf{62.6} ($\\uparrow$ \\textbf{13.5})\\\\\n    \\midrule\n    LGESQL + RoBERTa-large & 54.1    \\\\\n\n    \\quad w/ Euclidean \\name& {57.7} ($\\uparrow$ 3.6)\\\\\n    \\quad w/ Hyperbolic \\name& \\textbf{58.6} ($\\uparrow$ 4.5)\\\\\n    \\midrule\n    LGESQL + ELECTRA-large & 64.6 \\\\\n    \\quad w/ Euclidean \\name& {65.4} ($\\uparrow$ 0.8)\\\\\n    \\quad w/ Hyperbolic \\name& \\textbf{65.6} ($\\uparrow$ 1.0)\\\\\n    \n    \\bottomrule\n    \\end{tabular}  \n    \\label{tab:syn}\n    \\vspace{-0.3cm}\n\\end{table}",
            "tab:spider": "\\begin{table}[t]  \n    \\centering\n    \\setlength{\\abovecaptionskip}{5pt} \n    \\caption{Exact match accuracy (\\%) on Spider dev set. The $*$ means re-implemented results.}\n    \\small\n    \\begin{tabular}{lc}  \n    \\toprule\n    \\textbf{Model}& \\textbf{Acc.} \\\\ \n    \\midrule\n    EditSQL + BERT \\citep{editsql} & 57.6 \\\\ \n    IRNet + BERT \\citep{guo2019towards} & 61.9  \\\\ \n    RYANSQL + BERT \\citep{Choi2020RYANSQLRA} & 70.6  \\\\\n    TranX + TaBERT \\citep{Yin2020TaBERTPF} & 65.2  \\\\  \n    RAT-SQL + BERT \\citep{ratsql} & 69.7 \\\\\n    \\midrule\n    RAT-SQL + Grappa$^{*}$  & 71.2 \\\\\n    \\quad w/ Euclidean \\name& 72.6 ($\\uparrow$ 1.4)\\\\\n    \\quad w/ Hyperbolic \\name& \\textbf{73.1} ($\\uparrow$ \\textbf{1.9})\\\\\n    \n    \\midrule\n    LGESQL + RoBERTa-large$^{*}$  & 71.7   \\\\\n    \\quad w/ Euclidean \\name& {72.9} ($\\uparrow$ 1.2)\\\\\n    \\quad w/ Hyperbolic \\name& \\textbf{73.3} ($\\uparrow$ 1.6)\\\\\n    \\midrule\n    LGESQL + ELECTRA-large & 75.3  \\\\\n\n    \\quad w/ Euclidean \\name& {76.0} ($\\uparrow$ 0.7)\\\\\n    \\quad w/ Hyperbolic \\name& \\textbf{76.3} ($\\uparrow$ 1.0)\\\\\n    \n    \\bottomrule\n    \\end{tabular}  \n    \\label{tab:spider}\n\\end{table}",
            "tab:case": "\\begin{table*}[t]\n\\centering\n\\small\n\\setlength{\\abovecaptionskip}{5pt} \n\\caption{Case study: the first two cases are sampled from SYN and the last two cases are sampled from DK.}\n\\resizebox{0.75\\hsize}{!}{\n\\begin{tabular}{ll}\n\\toprule\n Question & \\textit{Find the \\textbf{\\sout{type}} and weight of the youngest pet.} \\\\\n SYN\\_Question& \\textit{Find the \\textbf{category} and weight of the youngest pet.}\\\\\n LGESQL & SELECT Pets.\\bad{Pet\\_age}, Pets.weight FROM Pets ORDER BY Pets.{pet\\_age} LIMIT 1  \\\\\n \\name& SELECT Pets.\\good{PetType}, Pets.weight FROM Pets ORDER BY Pets.{pet\\_age} LIMIT 1 \\\\\n Gold& SELECT Pets.PetType , Pets.weight FROM Pets ORDER BY Pets.pet\\_age LIMIT 1\n \\\\ \\midrule\n Question & \\textit{How many distinct \\textbf{\\sout{countries}} do \\textbf{\\sout{players}} come from?}\\\\\n SYN\\_Question& \\textit{How many distinct \\textbf{states} do \\textbf{participants} come from?} \\\\ \n LGESQL& SELECT COUNT(\\bad{*}) FROM \\bad{matches}\\\\\n \\name& SELECT COUNT(\\good{DISTINCT players.country\\_code}) FROM \\good{players}\\\\\n Gold& SELECT COUNT(DISTINCT players.country\\_code) FROM {players} \\\\ \n \\midrule\n Question & \\textit{What are the names of the singers who are not French?}\\\\\n LGESQL & SELECT singer.Name FROM singer WHERE singer.\\bad{Name} != 'French' \\\\\n \\name & SELECT singer.Name FROM singer WHERE singer.\\good{Citizenship} != 'French' \\\\\n Gold & SELECT singer.Name FROM singer WHERE singer.Citizenship != 'French'\n \\\\ \\midrule\n Question & \\textit{Find the average and maximum id for each type of pet.}\\\\\n LGESQL & SELECT Pets.PetType, Avg(Pets.\\bad{PetType}), Max(Pets.\\bad{PetType}) FROM Pets GROUP BY Pets.PetType \\\\\n \\name & SELECT Pets.PetType, Avg(Pets.\\good{PetID}), Max(Pets.\\good{PetID}) FROM Pets GROUP BY Pets.PetType \\\\\n Gold & SELECT Pets.PetType, Avg(Pets.PetID), Max(Pets.PetID) FROM Pets GROUP BY Pets.PetType\n\n\\\\ \\bottomrule\n\\vspace{-0.5cm}\n\\end{tabular}\n}\n\n\\label{tab:case}\n\\end{table*}",
            "diff_result": "\\begin{table*}[]\n\\centering\n\\small\n\\setlength{\\abovecaptionskip}{5pt} \n\\caption{Exact matching accuracy by varying the levels of difficulty of the inference data on the development sets of DK, SYN and Spider.}\n\\resizebox{1.0\\hsize}{!}{\n\\begin{tabular}{l|ccccc|ccccc|ccccc}\n\\toprule\n\\multirow{2}{*}{Model} & \\multicolumn{5}{c|}{DK}             & \\multicolumn{5}{c|}{SYN}            & \\multicolumn{5}{c}{Spider}         \\\\\n\\cline{2-16}\n        & easy & medium & hard & extra & all & easy & medium & hard & extra & all & easy & medium & hard & extra & all \\\\\n\\midrule\nRAT-SQL     &69.0 &42.2 &18.9 & 11.4& 38.5   &68.9 &57.5 &32.2 &15.9 & 49.1  & 87.9 & 74.6 &60.3 & 48.7 & 71.2 \\\\\n\\midrule\nRAT-SQL+Euclidean \\name  &69.0 &45.5 &31.0 &\\textbf{29.5} & 45.2   & \\textbf{80.2}&62.9 &51.4 &\\textbf{40.2} &61.4     & 86.2 &74.6  &64.9 &\\textbf{54.8} & 72.6   \\\\\n\\midrule\nRAT-SQL+Hyperbolic \\name &\\textbf{71.8}  &\\textbf{46.3} &\\textbf{33.8} &28.6 & \\textbf{46.4}    & 78.2    &\\textbf{66.8}    & \\textbf{54.2}     &  37.9     & \\textbf{62.6}  & \\textbf{88.3}     & \\textbf{76.0}   & \\textbf{65.5}    & 50.0     &  \\textbf{73.1}   \\\\\n\\midrule\n\\midrule\nLGESQL     & 74.5     & 46.7      & \\textbf{41.9}    & 29.5      &  48.4   &  79.4    &  \\textbf{67.9}      & 62.1     & 36.1      & 64.6    &  91.9    &  78.3      &  64.9    &  \\textbf{52.4}    & 75.1    \\\\\n\\midrule\nLGESQL+Euclidean \\name & 72.8     & 49.6       & 40.5     & 31.4      & 49.3    & 81.5     & 67.3       & \\textbf{62.1}     & 39.8      & 65.4    & 91.9     & 79.4       & 70.1     & 50.0      & 76.0    \\\\\n\\midrule\nLGESQL+Hyperbolic \\name & \\textbf{75.5}     & \\textbf{50.8}       & 40.5     &  \\textbf{33.3}     &  \\textbf{51.0}   &  \\textbf{81.9}    &  67.3      & 60.9     &   \\textbf{41.6}    &  \\textbf{65.6}   & \\textbf{92.7}     &  \\textbf{79.6}      & \\textbf{68.4}     &51.2       &  \\textbf{76.3}  \\\\\n\\bottomrule\n\n\\end{tabular}\n}\n\\label{diff_result}\n\\end{table*}",
            "tab:time": "\\begin{table}\n\\centering\n\\small\n\\setlength{\\abovecaptionskip}{5pt} \n\\caption{Comparison of the inference time in seconds on 1034 SYN samples.}\n\\scalebox{1}{\n\\begin{tabular}{lccc}\n\\toprule\n  & Model & \\multicolumn{1}{l}{Model+Euclidean} & Model+Hyperbolic        \\\\\n\\midrule\nLGESQL &  878(s)   & 979(s)                                 & \\multicolumn{1}{c}{975(s)} \\\\\nRAT-SQL &   1162(s)       & 1255(s)                                &\\multicolumn{1}{c}{1387(s)}\\\\\n\\bottomrule\n\\end{tabular}\n}\n\\label{tab:time}\n\\end{table}"
        },
        "figures": {
            "fig1": "\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.45\\textwidth]{probing-fig1.pdf}\n    \\caption{An illustration of the schema-linking relational structures between NL questions and database schemas. Heuristic methods such as exact string matching would not be able to capture the correspondences when surface forms of mentions appear differently.}\n    \\label{fig1}\n\\end{figure}",
            "pipeline": "\\begin{figure*}\n    \\centering\n    \\setlength{\\abovecaptionskip}{5pt} \n    \\includegraphics[width=0.7\\textwidth]{probing-pipeline.pdf}\n    \\caption{The overview of our proposed framework for text-to-SQL parsing. To obtain relation graphs among NL questions and database schema, we first use our proposed method \\name to probe relational structures from PLMs. The induced relations, along with the commonly-used heuristic relations extracted with handcrafted rules, are then utilized by a graph-based text-to-SQL parser to boost its schema linking for domain generalization. \n    }\n    \\label{pipeline}\n\\end{figure*}",
            "prob": "\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.3\\textwidth]{hyperbolic.pdf}\n    \\caption{\n    Probing process for \\name.\n    $\\mathbf{h}^s_2$ represents the embedding of the schema item $s_2$, while $\\mathbf{h}^s_{2\\backslash q_2}$ represents the embedding when the question token $q_2$ is masked out.\n    The relation between $s_2$ and $q_2$ as well as other candidate pairs are identified in the Poincar\\'e ball.}\n    \\label{prob}\n\\end{figure}",
            "fault_type": "\\begin{figure*}\n    \\centering\n    \\setlength{\\abovecaptionskip}{5pt} \n    \\includegraphics[width=0.8\\textwidth]{fig5.pdf}\n    \\caption{Representative erroneous schema linking predictions by rule-based methods. Notations Q, G, R, and P stand for question, ground truth, rule-based approach prediction and \\name prediction, respectively.\n    }\n    \\label{fault_type}\n\\end{figure*}",
            "fig:case1": "\\begin{figure*}[h]\n    \\centering\n    \\setlength{\\abovecaptionskip}{2pt} \n    \\subfigure{\n             \\includegraphics[width=0.23\\textwidth]{ad_matrix.png}\n             \\includegraphics[width=0.23\\textwidth]{probe_matrix.png}\n    }\n    \\subfigure{\n             \\includegraphics[width=0.23\\textwidth]{ad_matrix2.png}\n             \\includegraphics[width=0.23\\textwidth]{probe_matrix2.png}\n    }\n     \\vspace{-0.2cm}\n    \\caption{The visualization of Rule-based Matrix and Probing Matrix on two cases. The left two sub-figures correspond to the first case (SYN) in the Table \\ref{tab:case} and the right two sub-figures correspond to the third case (DK) in the Table \\ref{tab:case}.}\n    \\label{fig:case1}\n\\end{figure*}"
        },
        "equations": {
            "eq:1": "\\begin{equation}\ne_{i j}^{(h)} =\\frac{\\boldsymbol{x}_{i} W_{Q}^{(h)}\\left(\\boldsymbol{x}_{j} W_{K}^{(h)}+r_{i j}\\right)^{\\top}}{\\sqrt{d_{z} / H}}\n\\label{rij1}\n\\end{equation}",
            "eq:2": "\\begin{equation}\n \\alpha_{i j}^{(h)}=\\operatorname{softmax}_{j}\\left\\{e_{i j}^{(h)}\\right\\} \n\\end{equation}",
            "eq:3": "\\begin{equation}\n    \\boldsymbol{z}_{i}^{(h)} =\\sum_{j=1}^{n} \\alpha_{i j}^{(h)}\\left(\\boldsymbol{x}_{j} W_{V}^{(h)}+r_{i j}\\right) \\label{rij2}\n\\end{equation}",
            "eq:4": "\\begin{equation}\n    \\boldsymbol{z}_{i}=\\operatorname{Concat}\\left(\\boldsymbol{z}_{i}^{(1)}, \\cdots, \\boldsymbol{z}_{i}^{(H)}\\right)\n\\end{equation}",
            "eq:5": "\\begin{equation}\n    \\tilde{\\boldsymbol{y}}_{\\boldsymbol{i}} =\\operatorname{LayerNorm}\\left(\\boldsymbol{x}_{\\boldsymbol{i}}+\\boldsymbol{z}_{i}\\right)\n\\end{equation}",
            "eq:6": "\\begin{equation}\n    \\boldsymbol{y}_{\\boldsymbol{i}}  =\\operatorname{LayerNorm}\\left(\\tilde{\\boldsymbol{y}}_{\\boldsymbol{i}}+\\operatorname{FC}\\left(\\operatorname{ReLU}\\left(\\operatorname{FC}\\left(\\tilde{\\boldsymbol{y}}_{\\boldsymbol{i}}\\right)\\right)\\right)\\right.\n\\end{equation}",
            "eq:7": "\\begin{equation}\n    \\mathbf{x}^{l+1} = \\operatorname{RGAT}\\left( \\mathbf{x}^{l}, \\mathbf{G} \\right).\n    % $}\n\\end{equation}",
            "eq:8": "\\begin{equation*}\n\\resizebox{1\\hsize}{!}{$\n\\mathcal{I}= (\\langle\\mathsf{s}\\rangle;q_1;\\dots;q_{|Q|};\\langle\\backslash\\mathsf{s}\\rangle; s_1;\\langle\\backslash\\mathsf{s}\\rangle;\\dots;\\langle\\backslash\\mathsf{s}\\rangle; s_{|\\mathcal{T}| + |\\mathcal{C}|}),\n $}\n\\end{equation*}",
            "eq:9": "\\begin{equation}\n\tf(q_i, s_j) = d(\\mathbf{h}^{s}_{j \\backslash q_i}, \\mathbf{h}^{s}_{j})\n\\end{equation}",
            "eq:10": "\\begin{equation}\n\\label{eq:euclidean}\n\td_{\\rm Euc}(q_i, s_j) = || \\mathbf{h}^{s}_{j \\backslash q_i} - \\mathbf{h}^{s}_{j}||_2\n\\end{equation}",
            "eq:11": "\\begin{equation}\n  g_{\\mathbf{x}}\\left(\\mathbf{h}\\right)= \\mathbf{x} \\oplus \\left(\\tanh \\left( \\frac{\\lambda_{x}\\left\\|\\mathbf{h}\\right\\|}{2}\\right) \\frac{\\mathbf{h}}{\\left\\|\\mathbf{h}\\right\\|}\\right) \n\\end{equation}",
            "eq:12": "\\begin{equation}\n\\label{eq:mobius}\n \\mathbf{a} \\oplus \\mathbf{b} = \\frac{\n \\left(1+2\\left\\langle \\mathbf{a}, \\mathbf{b}\\right\\rangle+\\left\\|\\mathbf{b}\\right\\|^{2}\\right) \\mathbf{a}+\\left(1-\\left\\|\\mathbf{a}\\right\\|^{2}\\right) \\mathbf{b} }{ 1+2 \\left\\langle \\mathbf{a}, \\mathbf{b}\\right\\rangle+\\left\\|\\mathbf{a}\\right\\|^{2}\\left\\|\\mathbf{b}\\right\\|^{2}} \n\\end{equation}",
            "eq:13": "\\begin{equation}\n\\label{eq:exp proj}\n\\tilde{\\mathbf{h}} =  g _{\\mathbf{0}}\\left(\\mathbf{h}\\right)=\\tanh \\left( \\left\\|\\mathbf{h}\\right\\|\\right) \\frac{\\mathbf{h}}{  \\left\\|\\mathbf{h}\\right\\|}.\n\\end{equation}",
            "eq:14": "\\begin{equation}\n  \\exp _{x}^{c}\\left(\\mathbf{h}\\right)=x \\oplus_{c}\\left(\\tanh \\left(\\sqrt{c} \\frac{\\lambda_{x}^{c}\\left\\|\\mathbf{h}\\right\\|}{2}\\right) \\frac{\\mathbf{h}}{\\sqrt{c}\\left\\|\\mathbf{h}\\right\\|}\\right),\n\\end{equation}",
            "eq:15": "\\begin{equation}\n\\label{eq:mobius}\n \\mathbf{a} \\oplus_{c} \\mathbf{b} = \\frac{\n \\left(1+2 c\\left\\langle \\mathbf{a}, \\mathbf{b}\\right\\rangle+c\\left\\|\\mathbf{b}\\right\\|^{2}\\right) \\mathbf{a}+\\left(1-c\\left\\|\\mathbf{a}\\right\\|^{2}\\right) \\mathbf{b} }{ 1+2 c\\left\\langle \\mathbf{a}, \\mathbf{b}\\right\\rangle+c^{2}\\left\\|\\mathbf{a}\\right\\|^{2}\\left\\|\\mathbf{b}\\right\\|^{2}}.\n\\end{equation}",
            "eq:16": "\\begin{equation}\n\\label{eq:exp proj}\n\\tilde{\\mathbf{h}} =  \\exp _{\\mathbf{0}}^{c}\\left(\\mathbf{h}\\right)=\\tanh \\left( \\sqrt{c}\\left\\|\\mathbf{h}\\right\\|\\right) \\frac{\\mathbf{h}}{ \\sqrt{c} \\left\\|\\mathbf{h}\\right\\|}.\n\\end{equation}",
            "eq:17": "\\begin{equation}\n\td_{\\rm Poin}(q_i, s_j) = 2 \\tanh ^{-1} ( \\| - \\tilde{\\mathbf{h}}^s_{j\\backslash {q_i}}  \\oplus \\tilde{\\mathbf{h}}^s_j \\|)\n\\end{equation}",
            "eq:18": "\\begin{equation}\n\\tilde{x}_{i,j} = \\frac{x_{i,j}-\\min \\left(\\mathbf{X}\\right)}{\\max \\left(\\mathbf{X}\\right)-\\min \\left(\\mathbf{X}\\right)}\n\\end{equation}",
            "eq:19": "\\begin {equation}\n\\label{adjacency}\n\\mathbf{A}_{i j}=\\left\\{\\begin{array}{cl}\n\\text {0} & \\text { if } \\tilde{x}_{i, j} < \\tau \\\\\n\\text { 1 } & \\text { if } \\tilde{x}_{i, j} > \\tau \n\\end{array}\\right. ,\n\\end{equation}",
            "eq:20": "\\begin {equation}\n\\mathbf{A}_{i j}=\\left\\{\\begin{array}{cl}\n\\text {0} & \\text { if } {x}_{i, j} < \\tau \\\\\n\\text { 1 } & \\text { if } {x}_{i, j} > \\tau \n\\end{array}\\right. ,\n\\end{equation}"
        },
        "git_link": "https://github.com/AlibabaResearch/DAMO-ConvAI"
    }
}