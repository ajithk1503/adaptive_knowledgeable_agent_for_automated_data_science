{
    "meta_info": {
        "title": "MetaV: A Meta-Verifier Approach to Task-Agnostic Model Fingerprinting",
        "abstract": "For model piracy forensics, previous model fingerprinting schemes are\ncommonly based on adversarial examples constructed for the owner's model as the\n\\textit{fingerprint}, and verify whether a suspect model is indeed pirated from\nthe original model by matching the behavioral pattern on the fingerprint\nexamples between one another. However, these methods heavily rely on the\ncharacteristics of classification tasks which inhibits their application to\nmore general scenarios. To address this issue, we present MetaV, the first\ntask-agnostic model fingerprinting framework which enables fingerprinting on a\nmuch wider range of DNNs independent from the downstream learning task, and\nexhibits strong robustness against a variety of ownership obfuscation\ntechniques. Specifically, we generalize previous schemes into two critical\ndesign components in MetaV: the \\textit{adaptive fingerprint} and the\n\\textit{meta-verifier}, which are jointly optimized such that the meta-verifier\nlearns to determine whether a suspect model is stolen based on the concatenated\noutputs of the suspect model on the adaptive fingerprint. As a key of being\ntask-agnostic, the full process makes no assumption on the model internals in\nthe ensemble only if they have the same input and output dimensions. Spanning\nclassification, regression and generative modeling, extensive experimental\nresults validate the substantially improved performance of MetaV over the\nstate-of-the-art fingerprinting schemes and demonstrate the enhanced generality\nof MetaV for providing task-agnostic fingerprinting. For example, on\nfingerprinting ResNet-18 trained for skin cancer diagnosis, MetaV achieves\nsimultaneously $100\\%$ true positives and $100\\%$ true negatives on a diverse\ntest set of $70$ suspect models, achieving an about $220\\%$ relative\nimprovement in ARUC in comparison to the optimal baseline.",
        "author": "Xudong Pan, Yifan Yan, Mi Zhang, Min Yang",
        "link": "http://arxiv.org/abs/2201.07391v3",
        "category": [
            "cs.CR"
        ],
        "additionl_info": "To Appear in KDD'2022"
    },
    "latex_extraction": {
        "content": {
            "section 1": {
                "name": "Datasets and Target Models",
                "content": "\n\\noindent\\textbf{(1) Skin Cancer Diagnosis} (\\textit{abbrev.} \\textbf{Skin}). The first scenario covers the usage of deep convolutional neural network (CNN) for skin cancer diagnosis. According to \\cite{Yang2020MedMNISTCD}, we train a ResNet-18 \\cite{He2016DeepRL} as the target model on DermaMNIST \\cite{Yang2020MedMNISTCD}, which consists of $10005$ multi-source dermatoscopic images of common pigmented skin lesions imaging dataset. The input size is originally $3\\times{28}\\times{28}$, which is upsampled to be $3\\times{224}\\times{224}$ to fit the input shape of a standard ResNet-18 architecture implemented in torchvision \\footnote{\\url{https://pytorch.org/vision/stable/_modules/torchvision/models/resnet.html\\#resnet18}}. The task is a $7$-class classification task. \n\n\\noindent\\textbf{(2) Warfarin Dose Prediction} (\\textit{abbrev.} \\textbf{Warfarin}). The second scenario covers the usage of FCN for warfarin dose prediction, which is a safety-critical regression task that helps predict the proper individualised warfarin dosing according to the demographic and physiological record of the patients (e.g., weight, age and genetics). We use the International Warfarin Pharmacogenetics Consortium (IWPC) dataset \\cite{WhirlCarrillo2012PharmacogenomicsKF}, which is a public dataset composed of $31$-dimensional features of $6256$ patients and is widely used for researches in automated warfarin dosing. According to \\citet{Truda2019WarfarinDE}, we use a three-layer multi-layer perception (MLP) with ReLU as the target model, with its hidden layer composed of $100$ neurons. As a notation, we denote the architecture as $(31$-$100$-$1)$. The target model learns to predict the value of proper warfarin dosing, which is a non-negative real-valued scalar with its value in $(0, 300.0]$.\n\n\\noindent\\textbf{(3) Fashion Generation} (\\textit{abbrev.} \\textbf{Fashion}) The final scenario covers the usage of FCN for generative modeling. We choose \\cite{Xiao2017FashionMNISTAN}, which consists of $60000$  images for articles of clothing of size $28\\times{28}$. We train a DCGAN-like architecture \\cite{Radford2016UnsupervisedRL} for generative modeling on this task. We solely view the generator as the target model, as a well-trained generator represents more the IP of the model owner because it can be directly used to generate realistic images without the aid of the discriminator. The detailed DCGAN architecture we use is demonstrated in Table \\ref{tab:app:dcgan}.\n\n\n%%%% BEGIN OF DCGAN Table\n%%%% END OF DCGAN Table\n\n%%% FIG APP\n\n\n\n\n%%% BEGIN OF MODEL STAT TABLE\n%%% END OF MODEL STAT TABLE \n\n\n\n%%% BEGIN OF negative suspect model for GAN\n%%% END OF negative suspect models for DCGAN\n\n\n"
            },
            "section 2": {
                "name": "Details of Suspect Models",
                "content": " We list the composition of the suspect models for all the three scenarios in Table \\ref{tab:app:model_stat}. For convenience, we use the following abbreviation: fine-tuning the last layer (=\\textit{FTLL}), fine-tuning all layers (=\\textit{FTAL}), retraining the last layer (=\\textit{RTAL}), retraining all layers (=\\textit{RTAL}), weight-pruning (=\\textit{WP}), filter-pruning (=\\textit{FP}). For constructing distillation-based positive suspect models and independently trained negative suspect models, we implement $3$-$5$ models of diverse architectures and incremental sizes for each of the three target models. For convenience, we index these models as \\textit{S, M, L, XL, XLL}. Specifically, these models are:\n\\begin{itemize}\n    \\item \\textbf{Skin}: \\textit{S}=SqueezeNet-1\\_0 \\cite{Iandola2016SqueezeNetAA}; \\textit{M}=ResNet-18 (\\citet{He2016DeepRL}, the same as the target model); \\textit{L}=DenseNet-161 \\cite{Huang2017DenselyCC}; \\textit{XL}=AlexNet \\cite{Krizhevsky2014OneWT}; \\textit{XXL}=VGG-16 \\cite{Simonyan2015VeryDC}.\n    \\item \\textbf{Warfarin}: \\textit{S}=$(31$-$100$-$1)$ (the same as the target model); \\textit{M}=$(31$-$100$-$100$-$1)$; \\textit{L}=$(31$-$100$-$100$-$100$-$1)$.\n    \\item \\textbf{Fashion}: \\textit{S}=Architecture in Table \\ref{tab:app:fcn_gan} with $L=1$; \\textit{M}=with $L=2$; \\textit{L}=with $L=3$; \\textit{XL}=the same as the target model in Table \\ref{tab:app:dcgan}. \n\\end{itemize}\n\n"
            },
            "section 3": {
                "name": "More Implementation Details.",
                "content": " \n",
                "subsection 3.0": {
                    "subsubsection 3.0.1": {
                        "name": "Hyperparameter Setups.",
                        "content": " With no further specifications, we always set the number of fingerprint examples, i.e., $N$, for UTAF and the baselines as $100$ for fair comparisons. We set the learning rate in Algorithm 1 as $0.001$ and the number of iteration as $1000$. In all the three scenarios, we implement the meta-verifier $\\mathcal{V}$ as a three-layer fully-connected neural network with the ReLU hidden layer size of $100$.\n\n"
                    },
                    "subsubsection 3.0.2": {
                        "name": "Experimental Environment.",
                        "content": " All the defenses and experiments are implemented with PyTorch \\cite{Paszke2019PyTorchAI}, an open-source software framework for numeric computation and deep learning. All our experiments are conducted on a Linux server running Ubuntu 16.04, one AMD Ryzen Threadripper 2990WX 32-core processor and 2 NVIDIA GTX RTX2080 GPUs.\n\n\n%%%%% OTHER PARTS\n\n\n\\newpage\n% argument is your BibTeX string definitions and bibliography database(s)\n\\bibliography{ref}\n\n"
                    }
                }
            }
        }
    }
}