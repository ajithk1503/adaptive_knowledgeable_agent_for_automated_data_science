{
    "meta_info": {
        "title": "Compressing Deep Graph Neural Networks via Adversarial Knowledge  Distillation",
        "abstract": "Deep graph neural networks (GNNs) have been shown to be expressive for\nmodeling graph-structured data. Nevertheless, the over-stacked architecture of\ndeep graph models makes it difficult to deploy and rapidly test on mobile or\nembedded systems. To compress over-stacked GNNs, knowledge distillation via a\nteacher-student architecture turns out to be an effective technique, where the\nkey step is to measure the discrepancy between teacher and student networks\nwith predefined distance functions. However, using the same distance for graphs\nof various structures may be unfit, and the optimal distance formulation is\nhard to determine. To tackle these problems, we propose a novel Adversarial\nKnowledge Distillation framework for graph models named GraphAKD, which\nadversarially trains a discriminator and a generator to adaptively detect and\ndecrease the discrepancy. Specifically, noticing that the well-captured\ninter-node and inter-class correlations favor the success of deep GNNs, we\npropose to criticize the inherited knowledge from node-level and class-level\nviews with a trainable discriminator. The discriminator distinguishes between\nteacher knowledge and what the student inherits, while the student GNN works as\na generator and aims to fool the discriminator. To our best knowledge, GraphAKD\nis the first to introduce adversarial training to knowledge distillation in\ngraph domains. Experiments on node-level and graph-level classification\nbenchmarks demonstrate that GraphAKD improves the student performance by a\nlarge margin. The results imply that GraphAKD can precisely transfer knowledge\nfrom a complicated teacher GNN to a compact student GNN.",
        "author": "Huarui He, Jie Wang, Zhanqiu Zhang, Feng Wu",
        "link": "http://arxiv.org/abs/2205.11678v1",
        "category": [
            "cs.LG",
            "cs.AI"
        ],
        "additionl_info": "Accepted to KDD 2022"
    },
    "latex_extraction": {
        "content": {
            "section 1": {
                "name": "Introduction",
                "content": "\n\n\nIn recent years, graph neural networks (GNNs) have become the standard toolkit for graph-related applications including recommender systems \\cite{DBLP:conf/kdd/YingHCEHL18,lightgcn}, social network \\cite{reddit,DBLP:conf/acl/LiG19}, and biochemistry \\cite{DBLP:conf/nips/DuvenaudMABHAA15,DBLP:conf/nips/FoutBSB17}.\nHowever, GNNs that show great expressive power on large-scale graphs tend to be over-parameterized \\cite{ogb-lsc}.\nAs large-scale graph benchmarks including Microsoft Academic Graph (MAG) \\cite{mag} and Open Graph Benchmark (OGB) \\cite{ogb} spring up, complicated and over-stacked GNNs \\cite{gcn2,revgnn} have been developed to achieve state-of-the-art performance.\nFigure \\ref{fig:bubble} illustrates model performance versus graph size (i.e., the number of nodes in a graph).\n% 图中体现的结论\nWe note that deep and complicated GNNs significantly outperform shallow models on large-scale graphs, implying the great expressive power of over-parameterized GNNs.\n%\nHowever, the over-stacked architecture frequently and inevitably degrades both parameter-efficiency and time-efficiency of GNNs \\cite{revgnn}, which makes them inapplicable to computationally limited platforms such as mobile or embedded systems.\nTo compress deep GNNs and preserve their expressive power, we explore the knowledge distillation technique in graph domains, which has attracted growing attention in recent years.\n\n\nKnowledge distillation has been shown to be powerful for compressing huge neural networks in both visual learning and language modeling tasks \\cite{DBLP:conf/cvpr/BergmannFSS20,tinybert}, especially with a teacher-student architecture.\nThe main idea is that the student network mimics the behavior of the teacher network to obtain a competitive or even a superior performance \\cite{ban,fitnets},\nwhile the teacher network transfers soft targets, hidden feature maps, or relations between pair of layers as distilled knowledge to the shallow student network.\n%\nHowever, existing algorithms that adapt knowledge distillation to graph domains \\cite{DBLP:conf/cvpr/YangQSTW20,DBLP:conf/sigmod/ZhangMSJCR020,DBLP:conf/www/0002LS21} mainly propose specially designed and fixed distance functions to measure the discrepancy between teacher and student graph models, which results in following two inherent limitations.\n\\begin{itemize}[leftmargin=*]\n    \\item They force the student network to mimic the teacher network with hand-crafted distance functions, of which the optimal formulation is hard to determine  \\cite{DBLP:conf/aaai/WangXXT18}. Even worse, \\citet{kdgan, DBLP:journals/pami/WangZSQ21} have pointed out that the performance of the student trained this way is always suboptimal because it is difficult to learn the exact distribution from the teacher.\n    \\item The predefined and fixed distance is unfit to measure the distribution discrepancy of teacher and student representations in different feature spaces. For example, citation networks and image networks have distinct feature spaces due to the intrinsic difference between textual data and visual data. Experiments in Section \\ref{sec:node-level results} also confirm this claim.\n\\end{itemize}\n\n%% Specific pipeline of our KD4GNN\nIn this paper, we propose a novel adversarial knowledge distillation framework named \\med~to tackle the aforementioned problems.\nSpecifically, instead of forcing the student network to exactly mimic the teacher network with hand-designed distance functions,\nwe develop a trainable discriminator to distinguish between student and teacher from the views of node representations and logits.\nThe discriminator modifies the teacher-student architecture into generative adversarial networks (GANs) \\cite{gan}, where the student model works as a generator.\n%\nTwo identifiers constitute the discriminator, namely the represenation identifier and the logit identifier.\nThe representation identifier tells student and teacher node representations apart via criticizing the local affinity of connected nodes and the global affinity of patch-summary pairs,\nwhile the logit identifier distinguishes between teacher and student logits with a residual multi-layer perceptron (MLP).\n{We think the proposed discriminator is topology-aware as it considers graph structures.}\n%\nThe generator, i.e., the student network, is trained to produce node representations and logits similar to the teacher's distributions so that the discriminator cannot distinguish.\n%\nBy alternately optimizing the discriminator and the generator, \\med~is able to transfer both inter-node and inter-class correlations from a complicated teacher GNN to a compact student GNN.\n%\nWe further note that the discriminator is more tolerant than predefined distance formulations such as Kullback-Leibler (KL) divergence and Euclidean distance.\nWe can view the trainable discriminator as a teaching assistant that helps bridge the capacity gap between teacher and student models.\nMoreover, the proposed {topology-aware} discriminator can lower the risk of over-fitting.\n\n%% Empirical results\nTo evaluate the effectiveness of our proposed \\med, we conduct extensive experiments on eight node classification benchmarks and two graph classification benchmarks.\nExperiments demonstrate that \\med~enables compact student GNNs to achieve satisfying results on par with or sometimes even superior to those of the deep teacher models, while requiring only 10 $\\sim$ 40\\% parameters of their corresponding teachers.\n\n% % summary\n% We summarize the contributions of this paper as follows.\n% \\begin{itemize}[leftmargin=*]\n%     \\item To our best knowledge, we are the first to introduce adversarial training to knowledge distillation in graph domains.\n%     \\item We develop a discriminator to enable topology-aware knowledge transfer for graph models.\n%     \\item We conduct extensive experiments to show that \\med~enables compact student GNNs to achieve competitive results while requiring on average less than 20\\% parameters of the teachers.\n% \\end{itemize}\n\n%% Notation\n\n\n"
            },
            "section 2": {
                "name": "Background",
                "content": "\\label{sec:gnn}\nIn this part, we review the basic concepts of GNNs. Main notations are summarized in Table \\ref{tab:notation}.\n% \\subsection{Graph Neural Networks} \\label{sec:gnn}\nGNNs are designed as an extension of convolutions to non-Euclidean data \\cite{DBLP:journals/corr/BrunaZSL13}.\nIn this paper, we mainly select message passing based GNNs \\cite{DBLP:conf/icml/GilmerSRVD17} as both teacher and student models, {where} messages are exchanged between nodes and updated with neural networks \\cite{DBLP:conf/icml/GilmerSRVD17}.\nLet $\\mathcal{G}=(\\mathcal{V}, \\mathcal{E})$ denote a graph with feature vector $\\mathbf{X}_v$ for node $v\\in \\mathcal{V}$.\nWe are interested in two tasks, namely (1) \\textit{Node classification}, where each node $v\\in \\mathcal{V}$ has an associated label $y_v$ and the goal is to learn a representation vector $\\mathbf{h}_v$ of $v$ that aids in predicting $v$'s label as $\\hat{\\mathbf{y}}_v=f(\\mathbf{h}_v)$; and (2) \\textit{Graph classification}, where we are given a set of graphs $\\{\\mathcal{G}_1, \\cdots, \\mathcal{G}_N\\}$ with corresponding labels $\\{\\mathbf{y}_{\\mathcal{G}_1}, \\cdots, \\mathbf{y}_{\\mathcal{G}_N}\\}$ and the goal is to learn a summary vector $\\mathbf{s}_\\mathcal{G}$ such that the label of an entire graph can be predicted as $\\hat{\\mathbf{y}}_\\mathcal{G}=f(\\mathbf{s}_\\mathcal{G})$.\n%\nTherefore, we decompose a general GNN into an encoder and a classifier.\nThe encoder follows a message-passing scheme, where the hidden embedding $\\mathbf{h}_v^{(k+1)}$ of node $v\\in \\mathcal{V}$ is updated according to information aggregated from $v$'s graph neighborhood $\\mathcal{N}(v)$ at $k$-th iteration.\n%\nThis message-passing update \\cite{grl} can be expressed as\n\\begin{align*}\n    \\mathbf{h}_v^{(k+1)} &=\\textup{UPDATE}^{(k)}\\left(\\mathbf{h}_v^{(k)}, m_{\\mathcal{N}(v)}^{(k)}\\right), \\\\\n    \\textup{where } m_{\\mathcal{N}(v)}^{(k)} &= \\textup{AGGREGATE}^{(k)}\\left( \\{\\mathbf{h}_u^{(k)}\\mid \\forall\\,u\\in \\mathcal{N}(v) \\} \\right).\n\\end{align*}\nNote that the initial embeddings are set to the input features for all the nodes if $k=0$, i.e., $\\mathbf{h}_v^{(0)}=\\mathbf{X}_v, \\forall\\,v\\in \\mathcal{V}$. \nAfter running $K$ iterations of the GNN message passing, we derive the final representation $\\mathbf{h}_v=\\mathbf{h}_v^{(K)}$ for each node $v\\in \\mathcal{V}$.\n%\nFor graph-level classification, the READOUT function aggregates final node embeddings to obtain the summary vector $\\mathbf{s}_\\mathcal{G}$ of the entire graph, i.e., \n\\[\n\\mathbf{s}_\\mathcal{G}=\\textup{READOUT}(\\{\\mathbf{h}_v\\mid \\forall\\,v\\in\\mathcal{V}\\}),\n\\]\nwhere the READOUT function can be a simple permutation invariant function such as max-pooling and mean-pooling \\cite{reddit, gin}.\n%\nThe classifier then reads into the final representation of a node or a graph for node-level or graph-level classification, i.e.,\n\\begin{align*}\n    \\mathbf{z} &= g(\\mathbf{h}), \\\\\n    \\hat{\\mathbf{y}} &=\\textup{softmax}(\\mathbf{z}),\n\\end{align*}\nwhere we usually interpret $\\mathbf{z}_v$ (or $\\mathbf{z}_\\mathcal{G}$) and $\\hat{\\textbf{y}}_v$ (or $\\hat{\\textbf{y}}_\\mathcal{G}$) as logit and prediction of a node (or a graph), respectively.\n\n%% 方法框架图\n\n\n\n\n"
            },
            "section 3": {
                "name": "Methodology",
                "content": "\nIn this part, we first introduce our adversarial knowledge distillation framework in Section \\ref{sec:framework}. \nNext, we detail the proposed representation identifier in Section \\ref{sec:rep-dis} and logit identifier in Section \\ref{sec:log-dis}. \n\n",
                "subsection 3.1": {
                    "name": "An Adversarial Knowledge  Distillation Framework for Graph Neural Networks",
                    "content": " \\label{sec:framework}\n\n% observations and demands\nWe note that a powerful knowledge distillation method in graph domains should be able to \n% meet following two requirements.\n1) adaptively detect the difference between teacher and student on graphs of various fields; 2) inherit the teacher knowledge as much as possible; \nand 3) transfer teacher knowledge in a {topology-aware manner.}\n\n% why adversarial\nPrevious work \\cite{DBLP:conf/icml/ChungPKK20,kdgan,DBLP:conf/iclr/0002HH18} has demonstrated that distance functions such as $\\ell_p$ distance and KL-divergence are too vigorous for student models with a small capacity. Even worse, \\citet{DBLP:conf/aaai/WangXXT18} declared that it is hard to determine which distance formulation is optimal.\nTherefore, we develop the first adversarial distillation framework in graph domains to meet the first requirement.\n%\n% why node embeddings\nFurthermore, inspired by the fact that intermediate representations can provide hints for knowledge transfer \\cite{fitnets}, we take advantage of node representations and logits derived from deep teacher models to improve the training of compact student networks.\nFinally, to meet the third requirement, we develop a topology-aware discriminator, which stimulates student networks to mimic teachers and produce similar local affinity of connected nodes and global affinity of patch-summary pairs.\n\n%\nFigure \\ref{fig:framework} illustrates the overall architecture of \\med, which adversarially trains the student model against a topology-aware discriminator in a two-player minimax game.\nThe student GNN serves as a generator and produces node embeddings and logits that are similar to teacher output, while the discriminator aims to distinguish between teacher output and what the generator produces.\nThe minimax game ensures the student network to perfectly model the probability distribution of teacher knowledge at the equilibrium via adversarial losses \\cite{kdgan,DBLP:journals/pami/WangZSQ21}.\n\n% 算法伪代码\n\\begin{algorithm}[!ht]\n    \\caption{\\med~for node-level classification.} \\label{alg:framework}\n    \\begin{algorithmic}[1]\n        \\Require Graph $\\mathcal{G}=(\\mathcal{V}, \\mathcal{E})$, adjacent matrix $\\mathbf{A}$, node features $\\mathbf{X}$ and the pretrained teacher model $G^T$.\n        \\Ensure The learnt student model $G^S$.\n        \\State $\\mathbf{H}^T, \\mathbf{Z}^T=G^T(\\mathbf{X}, \\mathbf{A})$; $\\mathbf{s}^T=\\frac{1}{|\\mathcal{V}|}\\sum_{v\\in \\mathcal{V}}\\mathbf{h}_v^T$\n        \\While{not converge} \n            \\State $\\mathbf{H}^S, \\mathbf{Z}^S=G^S(\\mathbf{X}, \\mathbf{A})$; $\\mathbf{s}^S=\\frac{1}{|\\mathcal{V}|}\\sum_{v\\in \\mathcal{V}}\\mathbf{h}_v^S$\n            \\ForAll{node $v\\in \\mathcal{V}$}\n                \\State Update $D_e$ to distinguish $(\\mathbf{h}_v^T, \\mathbf{s}^T)$ and $(\\mathbf{h}_v^S, \\mathbf{s}^T)$\n                \\State Update $D_e$ to distinguish $(\\mathbf{h}_v^S, \\mathbf{s}^S)$ and $(\\mathbf{h}_v^T, \\mathbf{s}^S)$ \n                \\For{node $u\\in \\mathcal{N}(v)$}\n                    \\State Update $D_e$ to distinguish $(\\mathbf{h}_v^T, \\mathbf{h}_u^T)$ and $(\\mathbf{h}_v^S, \\mathbf{h}_u^S)$\n                    \\State Update the parameters of $G^S$ to fool $D_e$ via Eq.~\\ref{eq:emb_D}\n                \\EndFor\n                \\State Update $D_\\ell$ to distinguish $\\mathbf{z}_v^T$ and $\\mathbf{z}_v^S$\n                \\State Update the parameters of $G^S$ to fool $D_\\ell$ via Eq.~\\ref{eq:logits_D}\n            \\EndFor\n        \\EndWhile \n        \\State \\Return $G^S$\n    \\end{algorithmic}\n    % \\vspace{-3ex}\n\\end{algorithm}\n\n\n% workflow and pseudo code\nIn addition to teacher and student GNNs, \\med~includes a novel discriminator as well, which can be decomposed into a representation identifier and a logit identifier.\nAs the node classification task is popular in existing distillation literature \\cite{DBLP:conf/cvpr/YangQSTW20,DBLP:conf/sigmod/ZhangMSJCR020,DBLP:conf/www/0002LS21}, we take node classification for an example and represent the training procedure of \\med~for node-level classification in\nAlgorithm \\ref{alg:framework}.\nAs for the graph-level algorithm, please refer to Appendix \\ref{sec:alg2}.\n% adversarial distillation framework. \nLet $D_e$ and $D_\\ell$ be the two identifiers that operate on node embeddings and logits, respectively.\nSuppose we have a pretrained teacher GNN $G^T$ and accompanying knowledge, i.e., node representations $\\mathbf{H}^T$ and logits $\\mathbf{Z}^T$.\nThe objective is to train a student GNN $G^S$ with much less parameters while preserving the expressive power of the teacher $G^T$.\nThat is, we expect that the student $G^S$ can generate high-quality node representations $\\mathbf{H}^S$ and logits $\\mathbf{Z}^S$ to achieve competitive performance against the teacher.\n%\nAs the trainable discriminator is more flexible and tolerant than most specific distance including KL-divergence and $\\ell_p$ distance \\cite{DBLP:conf/icml/ChungPKK20,DBLP:conf/iclr/0002HH18}, \\med~enables student GNNs to capture inter-node and inter-class correlations instead of mimicking the exact distribution of teacher knowledge.\n\n\n\n"
                },
                "subsection 3.2": {
                    "name": "The Representation Identifier",
                    "content": " \\label{sec:rep-dis}\n% definition and motivation\nIn this section, we introduce our topology-aware representation identifier.\nNote that we decompose a GNN into an encoder and a classifier in Section \\ref{sec:gnn}.\nThe representation identifier focuses on the output of the GNN encoder, i.e., the final node embeddings.\n%\n% innovation and idea of repr discriminator\nInstead of directly matching the feature maps of teacher and student \\cite{DBLP:conf/cvpr/YangQSTW20}, we adversarially distill node representations of teacher models from both local and global views.\n\n% graph dis 的工作方式 formulation\nGiven the node representations of teacher and student GNNs, namely $\\mathbf{H}^T\\in \\mathbb{R}^{| \\mathcal{V}|\\times d^T}$ and $\\mathbf{H}^S\\in \\mathbb{R}^{| \\mathcal{V}|\\times d^S}$, we perform mean-pooling to obtain the corresponding summary vectors for a graph as $\\mathbf{s}^T\\in \\mathbb{R}^{d^T}$ and $\\mathbf{s}^S\\in \\mathbb{R}^{d^S}$.\nIn practice we set the dimension of student's node representations equal to that of teacher's, i.e., $d^S=d^T=d$.\nFor each node $v$, the representation learned by the student GNN $G^S$ is criticized by the identifier $D_e$ through both local and global views.\nSpecifically, reading in connected node pair $\\{\\mathbf{h}_v, \\mathbf{h}_u\\}$ or patch-summary pair $\\{\\mathbf{h}_v, \\mathbf{s}\\}$, the identifier $D_e$ is expected to predict a binary value ``Real/Fake'' that indicates whether the pair is real or fake.\nFake node pair implies that the representations of the two adjacent nodes are produced by the student GNN $G^S$;\nwhile fake patch-summary pair implies that the patch representation and summary representation are produced by GNNs of different roles.\n\nFormally, the topology-aware identifier $D_e$ consists of $D_e^{local}$ and $D_e^{global}$. If nodes $v$ and $u$ form an edge on the graph $\\mathcal{G}$, then $D_e^{local}$ maps representations of the two connected nodes to the real value that we interpret as affinity between connected nodes. On the other hand, for each node $v$ on the graph, $D_e^{global}$ maps the patch-summary pair to the real value that we interpret as affinity between node and graph. That is,\n\\begin{align*}\n    D_e^{local}(\\mathbf{h}_v^T, \\mathbf{h}_u^T) &= \\langle \\mathbf{h}_v^T, \\mathbf{W}^{local} \\mathbf{h}_u^T \\rangle \\in [0, 1],\\\\\n    D_e^{local}(\\mathbf{h}_v^S, \\mathbf{h}_u^S) &= \\langle \\mathbf{h}_v^S, \\mathbf{W}^{local} \\mathbf{h}_u^S \\rangle \\in [0, 1], \\quad \\forall~(v,u)\\in \\mathcal{E},\\\\\n    D_e^{global}(\\mathbf{h}_v^{T/S}, \\mathbf{s}_\\mathcal{G}^{T}) &= \\langle \\mathbf{h}_v^{T/S}, \\mathbf{W}^{global} \\mathbf{s}_\\mathcal{G}^{T} \\rangle \\in [0, 1],\\\\\n    D_e^{global}(\\mathbf{h}_v^{T/S}, \\mathbf{s}_\\mathcal{G}^{S}) &= \\langle \\mathbf{h}_v^{T/S}, \\mathbf{W}^{global} \\mathbf{s}_\\mathcal{G}^{S} \\rangle \\in [0, 1], \\quad \\forall~v\\in \\mathcal{V}\\subset\\mathcal{G},\n\\end{align*}\nwhere $\\textbf{W}^{local}$ and $\\textbf{W}^{global}$ are learnable diagonal matrices.\nBy this means, $D_e^{local}$ encourages the student to inherit the local affinity hidden in teacher's node embeddings, while $D_e^{global}$ encourages the student to inherit the global affinity.\n\nAs the student GNN aims to fool the representation identifier $D_e$, we view $G^S$ as a generator. \nUnder the guidance of the identifier $D_e$, the generator strives to yield indistinguishable node representations.\nThe adversarial training process can be formulated as a two-player minimax game, i.e.,\n\\begin{equation}\n\\begin{aligned}\n    \\min_{G^S} \\max_{D_e} \\mathcal{J}^{local} +\\mathcal{J}^{global},\n\\end{aligned} \n\\label{eq:emb_D}\n\\end{equation}\nwhere $\\mathcal{J}^{local}$ is written as\n\\begin{align*}\n    \\frac{1}{|\\mathcal{E}|}\\sum_{(v,u)\\in \\mathcal{E}}\\Big( &\\log\\textup{P}(\\textup{Real}\\mid D_e^{l}(\\mathbf{h}_v^T, \\mathbf{h}_u^T))+\\log\\textup{P} (\\textup{Fake}\\mid D_e^{l}(\\mathbf{h}_v^S, \\mathbf{h}_u^S))\\Big),\n\\end{align*}\nand $\\mathcal{J}^{global}$ is written as\n\\begin{align*}\n    \\frac{1}{2|\\mathcal{V}|}\\sum_{v\\in \\mathcal{V}}\\Big( &\\log\\textup{P}(\\textup{Real}\\mid D_e^{g}(\\mathbf{h}_v^T, \\mathbf{s}_\\mathcal{G}^T))+\\log\\textup{P} (\\textup{Fake}\\mid D_e^{g}(\\mathbf{h}_v^S,\\mathbf{s}_\\mathcal{G}^T))+\\\\\n    &\\log\\textup{P}(\\textup{Real}\\mid D_e^{g}(\\mathbf{h}_v^S,\\mathbf{s}_\\mathcal{G}^S))\n    +\\log\\textup{P} (\\textup{Fake}\\mid D_e^{g}(\\mathbf{h}_v^T,\\mathbf{s}_\\mathcal{G}^S))\\Big),\n\\end{align*}\nwhere $D_e^{l}$ and $D_e^{g}$ denote $D_e^{local}$ and $D_e^{global}$, respectively.\nBy alternately maximizing and minimizing the objective function, we finally obtain an expressive student GNN when it converges.\n\n% graph dis 的退化和等价性\nIt is worth noting that we can understand the representation identifier $D_e$ from different perspectives.\nIn fact, $D_e^{local}$ can degenerate into a bilinear distance function. If we modify the trainable diagonal matrix to the identity matrix and normalize the input vectors, \nthen the local affinity calculated by $D_e^{local}$ is equivalent to cosine similarity between node embeddings. That is, if $\\textbf{W}^{local}=\\textbf{I}$ and $\\widehat{\\mathbf{h}}_v=\\mathbf{h}_v/\\|\\mathbf{h}_v\\|_2$, then\n\\begin{align*}\n    \\langle \\widehat{\\mathbf{h}}_v, \\textbf{W}^{local}  \\widehat{\\mathbf{h}}_u \\rangle=\\textup{cosine\\_sim}(\\mathbf{h}_v, \\mathbf{h}_u), ~\\forall~(v,u)\\in \\mathcal{E}.\n\\end{align*}\n% \nApart from that, we can perceive the training process of $D_e^{global}$ as the maximization of the mutual information between the graph-level representation (i.e., the summary vector $\\mathbf{s}_\\mathcal{G}$) and the node-level representation (i.e., the patch vector $\\mathbf{h}_v$).\nLikewise, \\citet{dgi} propose a discriminator to maximize the mutual information between graph representations of different levels. However, our proposed $D_e^{global}$ differs from DGI \\cite{dgi} in two aspects.\nFirst, the performance of DGI \\cite{dgi} heavily relies on how to draw negative samples, while $D_e^{global}$ exempts the need of negative sampling.\nSecond, DGI \\cite{dgi} judges the representations produced by the same encoder for unsupervised graph learning, while $D_e^{global}$ discriminates the representations produced by teacher and student for adversarial knowledge distillation.\n\n\nCompared with existing distance-based embedding distillation in graph domains \\cite{DBLP:conf/cvpr/YangQSTW20}, we replace predefined distance formulations with a more flexible and tolerant identifier.\n%\nInstead of mimicking the exact distribution of teacher node embeddings, our representation identifier enables student GNN to capture the inter-node correlation, which is proved to be of crucial importance in graph domains \\cite{DBLP:conf/wsdm/JinDW0LT21}.\n\n"
                },
                "subsection 3.3": {
                    "name": "The Logit Identifier",
                    "content": " \\label{sec:log-dis}\n% definition and motivation\nIn this section, we introduce the second identifier of the proposed framework, which operates on the output logits.\nFor notation convenience, we introduce the logit identifier in the context of node-level classification.\nOutput of the GNN-based classifier is a probability distribution over categories. The probability is derived by applying a softmax function over the output of the last fully connected layer, which is also known as logits.\nBy leveraging adversarial training, we aim to transfer inter-class correlation \\cite{DBLP:conf/aaai/YangXQY19} from complicated teacher GNNs to compact student GNNs.\n\n% innovation and idea of logits discriminator\nInstead of forcing the student to exactly mimic the teacher by minimizing KL-divergence \\cite{hinton2015distilling} or other predefined distance, we transfer the inter-class correlation hidden in teacher logits through a logit identifier.\nInspired by adversarial training in visual representation learning \\cite{DBLP:conf/aaai/WangXXT18,DBLP:conf/iclr/0002HH18}, our logit identifier is trained to distinguish student logits from teacher logits, while the generator (i.e., the student GNN) is adversarially trained to fool the identifier. That is, we expect the compact student GNN to output logits similar to the teacher logits so that the identifier cannot distinguish.\n\n% formulation\nAs residual learning can mitigate the gap between teacher and student \\cite{DBLP:journals/ijon/GaoWW21},\nwe use an MLP with residual connections as our logit identifier $D_\\ell$.\nThe number of hidden units in each layer is the same as the dimension of logit, which is equal to the number of categories $C$.\nA plain identifier reads into the logit of each node and predicts a binary value ``Real/Fake'' that indicates whether the logit is derived by teacher or student.\nDenote the logit of node $v$ derived by teacher and student as $\\mathbf{z}_v^T$ and $\\mathbf{z}_v^S$, respectively.\nA plain identifier $D$ aims to maximize the log-likelihood as\n\\begin{equation}\n\\max_D \\frac{1}{| \\mathcal{V}|}\\sum_{v\\in \\mathcal{V}}\n\\Big(\\log \\textup{P}(\\textup{Real}\\mid D(\\mathbf{z}_v^T))+\\log \\textup{P}(\\textup{Fake}\\mid D(\\mathbf{z}_v^S))\\Big).\n\\end{equation}\n%\nAs \\citet{DBLP:conf/iclr/0002HH18} pointed out that the plain version is slow and unstable, we follow \\cite{DBLP:conf/icml/OdenaOS17,DBLP:conf/iclr/0002HH18} and modify the objective to also predict the specific node labels.\nTherefore, the output of $D_\\ell$ is a $C+1$ dimensional vector with the first $C$ for label prediction and the last for Real/Fake (namely teacher/student) indicator.\nWe thus maximize following objective for the training of $D_\\ell$:\n\\begin{equation}\n\\begin{aligned}\n\\max_{D_\\ell} \\frac{1}{| \\mathcal{V}|}\\sum_{v\\in \\mathcal{V}}&\n\\Big(\\log \\textup{P}(\\textup{Real}\\mid D_\\ell(\\mathbf{z}_v^T))+\\log \\textup{P}(\\textup{Fake}\\mid D_\\ell(\\mathbf{z}_v^S))\\\\\n&+\\log \\textup{P}(y_v\\mid D_\\ell(\\mathbf{z}_v^T))+\\log \\textup{P}(y_v\\mid D_\\ell(\\mathbf{z}_v^S))\\Big).    \n\\end{aligned}\n\\label{eq:logits-d}\n\\end{equation}\n\nAs for the training of generator, i.e., the student GNN $G^S$, we follow \\cite{DBLP:conf/cvpr/IsolaZZE17,DBLP:conf/iclr/0002HH18} and introduce instance-level alignment between teacher and student logits besides the category-level alignment. \nWe thus minimize the loss function for the training of $G^S$ as\n\\begin{equation}\n\\begin{aligned}\n\\min_{G^S} \\frac{1}{| \\mathcal{V}|}\\sum_{v\\in \\mathcal{V}}&\n\\Big(\\log \\textup{P}(\\textup{Real}\\mid D_\\ell(\\mathbf{z}_v^T))+\\log \\textup{P}(\\textup{Fake}\\mid D_\\ell(\\mathbf{z}_v^S))\\\\\n&-\\Big[ \\log \\textup{P}(y_v\\mid D_\\ell(\\mathbf{z}_v^T))+\\log \\textup{P}(y_v\\mid D_\\ell(\\mathbf{z}_v^S)) \\Big]\\\\\n&+\\|\\mathbf{z}_v^S - \\mathbf{z}_v^T\\|_1\n\\Big).  \n\\end{aligned} \n\\label{eq:logits_D}\n\\end{equation}\n\n\n% benefits\nCompared to existing knowledge distillation models for GNNs \\cite{DBLP:conf/sigmod/ZhangMSJCR020,DBLP:conf/www/0002LS21}, the logit identifier relaxes the rigid coupling between student and teacher.\nBesides, the adversarial training approach relieves the pain for hand-engineering the loss.\n% Empirical study \\cite{DBLP:conf/iclr/0002HH18} demonstrates that the performance is less sensitive to the discriminator architecture than the metric selection or temperature setting in traditional distance-based knowledge distillation.\n\n% is able to capture the inter-class correlation, rather than mimicking the exact distribution of teacher logits.\\section{Experiments}\n\nIn this part, we conduct extensive experiments to evaluate the capability of our proposed \\med. Our experiments are intended to answer the following five research questions.\n\n\\vspace{2mm}\n\\noindent \\textbf{RQ1:} How does \\med~perform on node-level classification?\n\n\\noindent \\textbf{RQ2:} How does \\med~perform on graph-level classification?\n\n\\noindent \\textbf{RQ3:} How efficient are the student GNNs trained by \\med?\n% \\vspace{1mm}\n\n\\noindent \\textbf{RQ4:} How do different components (i.e., $D_e$ or $D_\\ell$) affect the performance of \\med? \n\n\\noindent \\textbf{RQ5:} Do student GNNs learn better node representations when equipped with \\med? \n\n\n\n"
                },
                "subsection 3.4": {
                    "name": "Experimental Setup",
                    "content": " \\label{sec:setup}\n\n% main results\n\n\n\n\n",
                    "subsubsection 3.4.1": {
                        "name": "Datasets.",
                        "content": "\nFor a comprehensive comparison, in Section \\ref{sec:node-level results} we perform node classification on eight widely-used datasets, covering graphs of various sizes. \nThe statistics are summarized in Table \\ref{tab:dataset}.\nTo evaluate the effectiveness of \\med~on graph-level classification, we benchmark \\med~against traditional knowledge distillation methods on two molecular property prediction datasets \\cite{ogb} in Section \\ref{sec:graph-level results}.\nFor detailed information on the ten datasets, please refer to Appendix \\ref{app:dataset}.\nIn a nutshell, all datasets are collected from real-world networks in different domains, including social networks, citation networks, molecular graphs, and trading networks. We conduct experiments under both transductive and inductive settings, involving both textual and visual features.\n%directed, inductive, multi-class, text&image\n\n"
                    },
                    "subsubsection 3.4.2": {
                        "name": "Model Selection for Student and Teacher.",
                        "content": "\nIn fact, \\med~is applicable to all message passing based GNNs.\nFor node-level classification, we select two simple and famous GNNs as the student models. \nSpecifically, we choose GCN \\cite{gcn} for Cora \\cite{DBLP:journals/ir/McCallumNRS00,DBLP:conf/iclr/BojchevskiG18}, CiteSeer \\cite{DBLP:journals/aim/SenNBGGE08}, PubMed \\cite{namata2012query}, Flickr \\cite{DBLP:conf/eccv/McAuleyL12,graphsaint}, Arxiv \\cite{ogb} and Reddit \\cite{reddit,graphsaint}, while Cluster-GCN \\cite{cluster-gcn} is selected for large-scale datasets including Yelp \\cite{graphsaint} and Products \\cite{ogb}.\nOn the other hand, we employ two deep teacher GNNs on different graphs, namely GAMLP \\cite{gamlp} for Products and GCNII \\cite{gcn2} for other seven datasets. \n%\nAs for graph-level classification, we test both GCN \\cite{gcn} and GIN \\cite{gin} as students on Molhiv \\cite{ogb} and Molpcba \\cite{ogb}. Simultaneously, we choose HIG\\footnote{\\url{https://github.com/TencentYoutuResearch/HIG-GraphClassification}.} as the sole teacher model for the graph-level task. Note that we execute the teacher models during pre-computation, which prepares node representations and logits for student training. For more implementation details and the information on the mentioned teacher and student graph models, please refer to Appendix \\ref{app:detail}.\n\n"
                    }
                },
                "subsection 3.5": {
                    "name": "Performance on Node Classification (RQ1)",
                    "content": " \\label{sec:node-level results} %Main results\n% 先说实验细节\nTo evaluate the capability of our proposed adversarial knowledge distillation framework, we conduct node classification across graphs of various sizes.\nEmpirical results on eight datasets are presented in Table \\ref{tab:results}.\nNote that we follow the standard data split of previous work \\cite{gcn,cluster-gcn,graphsaint,gas}.\nAs a node in the graph may belong to multiple classes (e.g., Yelp \\cite{graphsaint}), we use F1-micro score to measure the performance.\n\n% 描述整体实验结果\nIn general, deep and complex GNNs have great expressive power and perform well on node classification task, especially for large graphs.\nFor example, GCNII \\cite{gcn2}  outperforms the vanilla GCN \\cite{gcn} by a large margin.\nHowever, deep and wide GNNs usually suffer from prohibitive time and space complexity \\cite{revgnn}.\nBy contrast, shallow and thin GNNs have small model capacity while they can easily scale to large datasets.\n%\nTabel \\ref{tab:results} shows that the proposed \\med~enables shallow student GNNs to achieve comparable or even superior performance to their teachers while maintaining the computational efficiency.\nConcretely, the GCN student outperforms the over-stacked teacher (i.e., GCNII) on PubMed and Arxiv with the knowledge transferred by \\med.\nAs for large-scale graphs such as Flickr and Products, \\med~consistently and significantly improves the performance of student GNNs.\nWe notice that to achieve superior accuracy on PubMed and Arxiv, the student GCN only requires less than 20\\% parameters of its teacher.\nHowever, the reason why \\med~can achieve superior performance to the teacher GNNs is intriguing.\n\\citet{cheng2020explaining} have pointed out that knowledge distillation makes students learn various concepts simultaneously, rather than learn concepts from raw data sequentially. \nTherefore, \\med~enables students learn both node-level and class-level views simultaneously, alleviating the problem that deep teacher GNNs tend to gradually discard views through layers according to the information-bottleneck theory \\cite{wolchover2017new,shwartz2017opening}.\n\n\n% 和同类方法比较\nTo further demonstrate the effectiveness of \\med, we compare the proposed framework with several distillation methods including the traditional logit-based knowledge distillation (KD) \\cite{hinton2015distilling}, the feature mimicking algorithm FitNet \\cite{fitnets} and the recent local structure preserving (LSP) method \\cite{DBLP:conf/cvpr/YangQSTW20}.\n%是自己实现的\nWe reproduce them and present comparisons in Table \\ref{tab:comparison}. Highest performance of each row is highlighted with boldface.\nAs graphs in different fields own distinct feature spaces, the three distance-based approaches fail to yield consistent improvement across all fields, which support the claim that a predefined and fixed distance is unfit to measure the discrepancy between teacher and student in different feature spaces.\nSpecifically, KD \\cite{hinton2015distilling} performs even inferior than the vanilla student on Yelp; LSP \\cite{DBLP:conf/cvpr/YangQSTW20} achieves poor performance on two trading networks (namely Yelp and Products); and FitNet \\cite{fitnets} barely yields gains on two citation networks (namely CiteSeer and Arxiv).\n%\nOn the other hand, \\med~outperforms three baselines by a large margin on most of the eight datasets. \nMoreover, we note that LSP incurs the out-of-memory (OOM) issue on Arxiv and Reddit, while the GCN students equipped with \\med~survive.\n\n\n\n% 分析奏效原因:1,用的知识内容不同；2,用的手段不同\nTo understand why the proposed framework outperforms other baselines, we delve deeper into the four competitors.\nWe note that KD \\cite{hinton2015distilling}, FitNet \\cite{fitnets} and LSP \\cite{DBLP:conf/cvpr/YangQSTW20} take advantage of teacher knowledge from different aspects.\nSpecifically, KD \\cite{hinton2015distilling} only uses teacher logits as soft targets, while FitNet \\cite{fitnets} and LSP \\cite{DBLP:conf/cvpr/YangQSTW20} are proposed to leverage intermediate node embeddings.\nContrary to them, \\med~leverages both aspects of teacher knowledge to distill inter-class and inter-node correlations.\nAnother important reason comes from the different ways they transfer teacher knowledge to student.\nConcretely, KD \\cite{hinton2015distilling}, FitNet \\cite{fitnets} and LSP \\cite{DBLP:conf/cvpr/YangQSTW20} force the student to mimic the exact distribution of teacher output (logits or intermediate embeddings) with fixed distance formulations, namely KL-divergence, Euclidean distance, and kernel functions.\n\\med~differs from KD \\cite{hinton2015distilling}, FitNet \\cite{fitnets} and LSP \\cite{DBLP:conf/cvpr/YangQSTW20} as it transfers teacher knowledge via adversarial training, which is more tolerant and is less sensitive to parameters than the metric selection or temperature setting in traditional distance-based distillation.\n% particularly effective for relatively small student models.\n\n% graph-level classification\n \n\n\n\n"
                },
                "subsection 3.6": {
                    "name": "Performance on Graph Classification (RQ2)",
                    "content": "\\label{sec:graph-level results}\n% 实验设置\nTo evaluate the capability of \\med~on graph-level tasks, we conduct molecular property prediction across two benchmarks, namely Molhiv \\cite{ogb} and Molpcba \\cite{ogb}.\nTable \\ref{tab:molecules} summarizes the empirical results.\nNote that the teacher model HIG on Molhiv \\cite{ogb} is based on DeeperGCN \\cite{li2020deepergcn}, while the teacher model on Molpcba \\cite{ogb} is built upon Graphormer \\cite{ying2021transformers}.\nOur student architectures are GCN and GIN, which do not use virtual nodes and are considered to be less expressive but more efficient than HIG.\n\n\n% 实验结果\nIn Table \\ref{tab:molecules}, we compare the proposed \\med~with knowledge distillation approaches including the traditional logit-based KD \\cite{hinton2015distilling} and the representation-based FitNet \\cite{fitnets}.\nWe observe that \\med~consistently improves student performance and outperforms the two distillation baselines.\n% 半个实验分析\nNotably, as Graphormer \\cite{ying2021transformers} is different from typical GNNs, both KD and FitNet yield minor performance boosts on Molpcba \\cite{ogb}.\nHowever, \\med~yields significant improvement against the vanilla student models across the two graph-level benchmarks, which implies that \\med~is promising to bridge graph models of different architectures.\n\n\n% visualization\n\n\n\n"
                },
                "subsection 3.7": {
                    "name": "Analysis of Model Efficiency (RQ3)",
                    "content": "\n\\label{sec:efficiency}\nFor practical applications, apart from effectiveness, the usability of a neural network also depends on model efficiency.\nWe investigate the efficiency of \\med~with three criteria: 1) parameter-efficiency, 2) computation-efficiency, and 3) time-efficiency.\nSpecifically, we compare the student GNNs trained by \\med~against their teachers in terms of the aforementioned three criteria.\nWe select five graph benchmarks (namely Cora, PubMed, Flickr, Yelp, and Products) and\nsummarize the efficiency comparison in Table \\ref{tab:eff}.\n%\nNote that we conduct full-batch testing for both teacher and student on Cora, PubMed and Flickr. As for Yelp and Products, we align the batch size of teacher and student for a fair comparison.\nWe provide detailed analyses as follows.\n\n",
                    "subsubsection 3.7.1": {
                        "name": "Parameter efficiency",
                        "content": "\\label{sec:param} For resource limited device, the amount of memory occupied by the model becomes critical to deployment. Here we use the number of parameters to measure the memory consumption for both teacher and student models. We observe that the number of node features, network layers, and hidden dimensions contribute to the number of parameters. By drastically lessening hidden dimensions and network layers, \\med~reduces the model size of teacher GNNs to less than 20\\% on average.\n\n%efficiency\n\n\n\n"
                    },
                    "subsubsection 3.7.2": {
                        "name": "Computation efficiency",
                        "content": "In addition to storage consumption, the dynamic memory usage is important as well. The reported GPU memory is the peak GPU memory usage during the first training epoch, which is also used in \\cite{revgnn}. Restricted to the size and weight of mobile or embedded systems, neural networks that consume huge memory may be inapplicable to many practical situations.\nWe note that the GPU memory is highly related to the hidden dimensions and the number of network layers. As mentioned in Section \\ref{sec:param}, \\med~significantly reduces hidden dimensions and network layers of over-stacked teacher GNNs, which brings about portable and flexible student graph models.\n"
                    },
                    "subsubsection 3.7.3": {
                        "name": "Time efficiency",
                        "content": "As low latency is sometimes demanded in real-world applications, we also evaluate the inference time of both teacher and student GNNs, which refers to the time consumption of inference on testing dataset. \nTable \\ref{tab:eff} shows that \\med~significantly reduces the inference time for deep GNNs. On Flickr, in particular, \\med~even cuts down more than 90\\% inference time of the GCNII teacher, which shows that \\med~trades off a reasonable amount of accuracy to reduce latency. The acceleration may originate from the sharp decrease in the number of network layers.\n%\nIn a nutshell, Table \\ref{tab:eff} shows that \\med~is able to compress over-parameterized teacher GNNs into compact and computationally efficient student GNNs with relatively low latency.\n\n\n% 消融实验\n\n\n\n"
                    }
                },
                "subsection 3.8": {
                    "name": "Ablation Studies (RQ4)",
                    "content": " \\label{sec:ablation}\nTo thoroughly evaluate our framework, in this section we provide ablation studies to show the influence of the two identifiers.\nSpecifically, we separately test the capability of the two identifiers ($D_e$ and $D_\\ell$) to clarify the essential improvement of each component.\nWe conduct our analysis on the same five node-level benchmarks used in Section \\ref{sec:efficiency} as well as a graph-level dataset.\nHighest performance of each column is highlighted in Table \\ref{tab:abalation}.\n\nWe can conclude that the improvements benefit from both the representation identifier and the logit identifier.\n%\nAnother valuable observation in Table \\ref{tab:abalation} is that both $D_e$ and $D_\\ell$ enable a vanilla GCN to achieve results superior to the GCNII teacher on PubMed.\n%\nThe fact that \\med~outperforms each of the identifiers demonstrates the importance of both node representations and logits. Either of the two identifiers captures orthogonal yet valuable knowledge via adversarial training. Specifically, the representation identifier excels at capturing inter-node correlation, while the logit identifier specializes in capturing inter-class correlation.\n\n\n"
                },
                "subsection 3.9": {
                    "name": "Visualization (RQ5)",
                    "content": " \\label{sec:visualization}\nWe further perform qualitative analysis on the embeddings learnt by the GCN student in order to better understand the properties of our \\med. \nWe follow \\cite{dgi} and focus our analysis exclusively on Cora \\cite{DBLP:journals/ir/McCallumNRS00,DBLP:conf/iclr/BojchevskiG18} because it has the smallest number of nodes among the node-level benchmarks, which notably aids clarity.\n\nFigure \\ref{fig:tsne} gives a standard set of ``evolving'' t-SNE plots of the embeddings learnt by three models, namely the vanilla GCN, the student GCN trained with our \\med, and the teacher GCNII, respectively. \n%\nFor all the three subfigures, we can observe that the learnt embeddings’ 2D projections exhibit discernible clustering in the projected space, which corresponds to the seven topic classes of Cora. \nWe further notice that the 7-category scientific papers can be differentiated more effectively by student GCN equipped with \\med~than by a vanilla GCN. \n\nFigure \\ref{fig:tsne} qualitatively shows that \\med~not only increases the accuracy of classification, but also enables the student GCN to learn high-quality node representations.\nTo obtain a more accurate and convincing conclusion, we calculate Silhouette scores \\cite{rousseeuw1987silhouettes} for the three projections.\nSpecifically, the Silhouette score \\cite{rousseeuw1987silhouettes} of the  embeddings learned by student GCN is 0.2638, which compares favorably with the score of 0.2196 for the vanilla GCN.\n\n% The projection obtains a Silhouette score \\cite{rousseeuw1987silhouettes} of 0.234, which compares favorably with the previous reported score of 0.158 for Embedding Propagation \\cite{DBLP:conf/nips/Garcia-DuranN17}.\\section{Related Work} \nIn this part, we first introduce existing work that adapts knowledge distillation to graph domains in Section \\ref{sec:kd4gnn}. Next, we review applications of adversarial training in graph domains in Section \\ref{sec:adv}.\n\n\n"
                },
                "subsection 3.10": {
                    "name": "Knowledge Distillation for Graph Models",
                    "content": " \\label{sec:kd4gnn}\n% KD在CV、NLP领域很繁荣，但不能直接用于图结构\nKnowledge distillation has achieved great success for network compression in visual learning and language modeling tasks \\cite{DBLP:conf/cvpr/BergmannFSS20,fitnets, tinybert,distilbert}.\nHowever, directly applying the established approaches in visual learning and language modeling to graph domains is not applicable as graphs contain both features and topological structures.\n\n% 详述本文和现有研究的不同之处\nRecent success in GNNs impels the advent of knowledge distillation for GNNs.\nAmong existing work, \\cite{DBLP:conf/cvpr/YangQSTW20,DBLP:conf/sigmod/ZhangMSJCR020,DBLP:conf/www/0002LS21} are the most relevant to this paper as they all use the teacher-student architecture and focus on node classification.\nHowever, the adaptive distillation strategy makes our work distinct from existing research \\cite{DBLP:conf/cvpr/YangQSTW20,DBLP:conf/sigmod/ZhangMSJCR020,DBLP:conf/www/0002LS21}.\nSpecifically, LSP \\cite{DBLP:conf/cvpr/YangQSTW20} aligns node representations of teacher and student with kernel function based distance;\n\\citet{DBLP:conf/sigmod/ZhangMSJCR020} and \\citet{DBLP:conf/www/0002LS21} use Euclidean distance to match the probability distributions of teacher and student.\n% both embeddings and logits of teacher and student;\nContrary to them, our proposed \\med~adversarially trains a discriminator and a generator to adaptively detect and decrease the discrepancy between teacher and student.\nMoreover, \\cite{DBLP:conf/cvpr/YangQSTW20,DBLP:conf/sigmod/ZhangMSJCR020,DBLP:conf/www/0002LS21} merely conduct node-level classification and focus on graphs with less than 100K nodes, while the proposed \\med~is widely applicable to both node-level and graph-level classification tasks and performs well on graphs with number of nodes varying from 2K to 2M.\n\n"
                },
                "subsection 3.11": {
                    "name": "Adversarial Training for Graph Models",
                    "content": " \\label{sec:adv}\nThe idea of adversarial training originates from generative adversarial networks (GANs) \\cite{gan}, where the generator and discriminator compete with each other to improve their performance.\n\nIn recent years, adversarial training has demonstrated superior performance in graph domains for different aims.\nSpecifically, \\citet{wang2018graphgan} and \\citet{feng2019graph} leverage the adversarial architecture to learn universal and robust graph representations, while \\citet{dai2018adversarial} explore adversarial attack on graph structured data.\n\\citet{alam2018domain} perform adversarial domain adaptation with graph models, while \\citet{suresh2021adversarial} develop adversarial graph augmentation to improve the performance of self-supervised learning.\nDifferent from them, this work aims to conduct adversarial knowledge distillation for graph models, which leads to the contribution.\n\n\n\n\n\n\n\n\n\n\n"
                }
            },
            "section 4": {
                "name": "Conclusion",
                "content": "\nOver-stacked GNNs are usually expressive and powerful on large-scale graph data.\nTo compress deep GNNs, we present a novel adversarial knowledge distillation framework in graph domains, namely \\med, which introduces adversarial training to topology-aware knowledge transfer for the first time.\n%\nBy adversarially training a discriminator and a generator, \\med~is able to transfer both inter-node and inter-class correlations from a complicated teacher GNN to a compact student GNN (i.e., the generator).\nExperiments demonstrate that \\med~yields consistent and significant improvements across node-level and graph-level tasks on ten benchmark datasets.\nThe student GNNs trained this way achieve competitive or even superior results to their teacher graph models, \nwhile requiring only a small proportion of parameters.\nIn the future work, we plan to explore the potential application of \\med~on graph tasks beyond classification.\n\n% \\newpage\n\n\n%%\n%% The next two lines define the bibliography style to be used, and\n%% the bibliography file.\n\\bibliographystyle{ACM-Reference-Format}\n\\bibliography{kdd2022}\n\n%%\n%% If your work has an appendix, this is the place to put it.\n\\appendix\n"
            },
            "section 5": {
                "name": "Code for Graph Classification",
                "content": "\\label{sec:alg2}\n% 算法伪代码\n\\begin{algorithm}[!ht]\n    \\caption{\\med~for graph-level classification.} \\label{alg:graph-level}\n    \\begin{algorithmic}[1]\n        \\Require Graphs $\\{\\mathcal{G}_1, \\cdots, \\mathcal{G}_N\\}$, and the pretrained teacher $G^T$.\n        \\Ensure The learnt student model $G^S$.\n        \\While{not converge} \n            \\ForAll{graph $\\mathcal{G}\\in \\{\\mathcal{G}_1, \\cdots, \\mathcal{G}_N\\}$}\n                \\State $\\mathbf{H}^T, \\mathbf{z}_\\mathcal{G}^T=G^T(\\mathbf{X}_\\mathcal{G}, \\mathbf{A}_\\mathcal{G})$; $\\mathbf{s}_\\mathcal{G}^T=\\frac{1}{|\\mathcal{V}|}\\sum_{v\\in \\mathcal{V}}\\mathbf{h}_v^T$\n                \\State $\\mathbf{H}^S, \\mathbf{z}_\\mathcal{G}^S=G^S(\\mathbf{X}_\\mathcal{G}, \\mathbf{A}_\\mathcal{G})$; $\\mathbf{s}_\\mathcal{G}^S=\\frac{1}{|\\mathcal{V}|}\\sum_{v\\in \\mathcal{V}}\\mathbf{h}_v^S$\n                \\ForAll{node $v\\in \\mathcal{V}\\subset \\mathcal{G}$}\n                    \\State Update $D_e$ to distinguish $(\\mathbf{h}_v^T, \\mathbf{s}_\\mathcal{G}^T)$ and $(\\mathbf{h}_v^S, \\mathbf{s}_\\mathcal{G}^T)$\n                    \\State Update $D_e$ to distinguish $(\\mathbf{h}_v^T, \\mathbf{s}_\\mathcal{G}^S)$ and $(\\mathbf{h}_v^S, \\mathbf{s}_\\mathcal{G}^S)$\n                    \\For{node $u\\in \\mathcal{N}(v)$}\n                        \\State Update $D_e$ to distinguish $(\\mathbf{h}_v^T, \\mathbf{h}_u^T)$ and $(\\mathbf{h}_v^S, \\mathbf{h}_u^S)$\n                        \\State Update the parameters of $G^S$ to fool $D_e$ via Eq.~\\ref{eq:emb_D}\n                    \\EndFor\n                \\EndFor\n                \\State Update $D_\\ell$ to distinguish $\\mathbf{z}_\\mathcal{G}^T$ and $\\mathbf{z}_\\mathcal{G}^S$\n                \\State Update the parameters of $G^S$ to fool $D_\\ell$ via Eq.~\\ref{eq:logits_D}\n            \\EndFor\n        \\EndWhile \n        \\State \\Return $G^S$\n    \\end{algorithmic}\n    % \\vspace{-4ex}\n\\end{algorithm}\n\n\n"
            },
            "section 6": {
                "name": "Datasets",
                "content": " \\label{app:dataset}\nWe detail all datasets as follows.\n\\begin{itemize}[leftmargin=*]\n    \\item \\textbf{Cora} \\cite{DBLP:journals/ir/McCallumNRS00,DBLP:conf/iclr/BojchevskiG18} and \\textbf{CiteSeer} \\cite{DBLP:journals/aim/SenNBGGE08} are networks of computer science publications. Each node in the two networks represents a publication and each directed edge means a citation. Each node is annotated with a vector of binary word indicators and a label indicating the paper topic.\n    \\item \\textbf{PubMed} \\cite{namata2012query} is a set of articles related to diabetes from the PubMed database. Node features are TF/IDF-weighted word frequencies and the labels specify the type of diabetes.\n    \\item \\textbf{Flickr} \\cite{DBLP:conf/eccv/McAuleyL12,graphsaint} is an undirected graph of images. Nodes are \\emph{images}, and edges indicate the connected two images share some common properties (e.g., geographic location, gallery, and users commented, etc.).\n    Node features are the 500-dimensional bag-of-words representation of the images.\n    We adopt the labels and dataset split in \\cite{graphsaint}.\n    % , where the 7-category label is manually merged from 81 tags.\n    \\item \\textbf{Arxiv} \\cite{ogb} is a directed graph that represents the citation network between all computer science arXiv papers indexed by MAG \\cite{mag}. \n    % Each node represents an arXiv paper and each directed edge indicates that one paper cites another.\n    Node features are the averaged skip-gram word embeddings of the paper title and abstract.\n    \\item \\textbf{Reddit} \\cite{reddit,graphsaint} is an undirected graph constructed from an online discussion forum. Nodes are posts belonging to different communities and each edge indicates the connected posts are commented by the same user.\n    We use the sparse version of Reddit dataset, which contains about 23M edges instead of more than 114M edges \\cite{graphsaint, gas}. Besides, we follow the same inductive setting in \\cite{reddit, graphsaint, gas}, i.e., we do not require all nodes in the graph are present during training.\n    \\item \\textbf{Yelp} \\cite{graphsaint} is constructed with the data of business, users and reviews provided in the open challenge website. Each node is a customer and each edge implies the connected users are friends. Node features are Word2Vec embeddings of the user's reviews. We follow \\cite{graphsaint, gas} to use the categories of the businesses reviewed by a user as the multi-class label of the corresponding node.\n    \\item \\textbf{Products} \\cite{ogb} is an undirected graph that represents an Amazon product co-purchasing network. Nodes are products sold on Amazon, and edges indicate that the connected products are purchased together. Node features are bag-of-words vectors of the product descriptions, and node labels are categories of the products.\n    \\item \\textbf{Molhiv} \\cite{ogb} and \\textbf{Molpcba} \\cite{ogb} are two molecular property prediction datasets of different sizes. Each graph represents a molecule, where nodes are atoms, and edge are chemical bonds. Edge features indicate bond type, bond stereochemistry, and whether the bond is conjugated. Both node features and edge features are considered to predict the target molecular properties as accurately as possible.\n\\end{itemize}\n\n"
            },
            "section 7": {
                "name": "Experimental Details",
                "content": " \\label{app:detail}\n\n",
                "subsection 7.1": {
                    "name": "Implementation Details.",
                    "content": "\nWe implement \\med~in PyTorch and run it on a single NVIDIA GeForce RTX 2080Ti graphics card.\nOur implementation generally follows the open source codebases of deep graph library. \n%\nWe instantiate \\med~with a generator-discriminator architecture.\nFor the generator part, we employ almost the same experimental settings including initialization, optimization and hyper-parameters as the corresponding vanilla student GNN.\nFor convenience, we set the generator's node embedding dimension to be the same as the teacher model's embedding dimension.\nFor the discriminator part, $D_\\ell$ and $D_e$ are uniformly initialized and all-one initialized, respectively. \nWe sum the adversarial losses produced by $D_\\ell$ and $D_e$ without any tuned weight.\nWe train the discriminator using Adam optimizer \\cite{adam} with a learning rate varying from 0.05 to 0.001.\n\\med~updates the parameters of generator and discriminator with a ratio of $k:1$, which implies that the discriminator is update once after the generator is updated k times. \nWe perform grid search to find a suitable $k$ among $\\{1, 5, 10, 20, 30\\}$ for each dataset.\n\n"
                },
                "subsection 7.2": {
                    "name": "Model selection",
                    "content": "\n\nWe detail the teacher graph models as follows.\n\\begin{itemize}[leftmargin=*]\n    \\item \\textbf{GCNII} \\cite{gcn2} is an extension of the vanilla GCN \\cite{gcn}. \\citet{gcn2} propose two effective techniques---namely initial residual and identity mapping---to deepen the graph convolution layers.\n    GCNII increases the number of graph convolution layers from 2 to 64, while the performance on node classification is not affected by the over-smoothing issue \\cite{DBLP:conf/aaai/LiHW18,jknet}.\n    \\item \\textbf{GAMLP} \\cite{gamlp} is a powerful and over-parameterized graph learning model based on the reception field attention. Specifically, GAMLP \\cite{gamlp} incorporates three principled attention mechanisms---namely smoothing attention, recursive attention, and jumping knowledge (JK) attention---into the representation learning process.\n    \\item \\textbf{HIG} \\footnote{\\url{https://github.com/TencentYoutuResearch/HIG-GraphClassification}.} is proposed as a node augmentation method to solve the graph classification task. HIG randomly selects nodes and applies heterogeneous interpolation, then adds KL divergence constraint loss to make the distributions of augmented features be similar. For Molhiv \\cite{ogb}, HIG built upon DeeperGCN \\cite{li2020deepergcn} achieves state-of-the-art performance. For Molpcba \\cite{ogb}, HIG that selects Graphormer \\cite{ying2021transformers} as the backbone achieves state-of-the-art performance.\n\\end{itemize}\n\nWe detail the student graph models as follows.\n\\begin{itemize}[leftmargin=*]\n    \\item \\textbf{GCN} \\cite{gcn} simplifies graph convolutions by stacking layers of first-order Chebyshev polynomial filters. It has been proved to be one of the most popular baseline GNN architectures.\n    \\item \\textbf{Cluster-GCN} \\cite{cluster-gcn} relieves the out-of-memory issue for GCN when scaling to large-scale graphs. Specifically, Cluster-GCN designs node batches based on efficient graph clustering algorithms, which leads to great computational benefits.\n    \\item \\textbf{GIN} \\cite{gin} generalizes the WL test and provably achieves great discriminative power among GNNs. Based on the theory of ``deep multisets'', GIN learns to embed the subtrees in WL test to the low-dimensional space. By this means, GIN is able to discriminate different structures, and capture dependencies between graph structures as well.\n\\end{itemize}\n\n\n"
                }
            }
        },
        "tables": {
            "tab:notation": "\\begin{table}[!t]\n\\caption{Glossary of notations.}\\label{tab:notation}\n\\vspace{-1.5ex}\n    \\centering\n    \\resizebox{\\columnwidth}{!}{\n    \\begin{tabular}{@{}l|c@{}}\n\\toprule\nNotation & Description \\\\\\midrule\n$\\mathcal{G}=(\\mathcal{V}, \\mathcal{E})$ & a graph composed of node set $\\mathcal{V}$ and edge set $\\mathcal{E}$ \\\\\n$\\mathbf{y}_v$; $\\mathbf{y}_{\\mathcal{G}}$ & labels of node $v$ and graph $\\mathcal{G}$, respectively\\\\\n$m_{\\mathcal{N}(v)}$                     & message aggregated from $v$'s neighborhood $\\mathcal{N}(v)$\\\\\n$\\mathbf{X}$; $\\mathbf{H}^{(k)}$           & node embeddings of initial and $k$-th layers, respectively\\\\\n$\\mathbf{h}_v$; $\\mathbf{z}_v$             & representation vector and logit of node $v$, respectively\\\\\n$\\mathbf{s}_\\mathcal{G}$; $\\mathbf{z}_\\mathcal{G}$             & summary vector and logit of graph $\\mathcal{G}$, respectively\\\\\n$G^T$; $G^S$                               &  GNN models of teacher and student, respectively\\\\\n$\\mathbf{H}^T$; $\\mathbf{H}^S$             & node embeddings of teacher and student, respectively\\\\\n$\\mathbf{Z}^T$; $\\mathbf{Z}^S$             & logits of teacher and student, respectively\\\\\n$D_e$; $D_\\ell$ & identifiers of node embeddings and logits, respectively\\\\\\bottomrule\n    \\end{tabular}\n    }\n\\vspace{-3ex}\n\\end{table}",
            "tab:dataset": "\\begin{table}[!t]\\small\n\\caption{Statistics of the eight node classification benchmarks.}\n% \\vspace{-1ex}\n\\centering\n% \\resizebox{\\columnwidth}{!}{\n\\begin{tabular}{@{}lcccc@{}}\n\\toprule\n\\textbf{Datasets} & \\textbf{\\#Nodes} & \\textbf{\\#Edges} & \\textbf{\\#Feat.} & \\textbf{Data Split} \\\\\\midrule\nCora \\cite{DBLP:journals/ir/McCallumNRS00,DBLP:conf/iclr/BojchevskiG18} & 2,708            & 5,429            & 1,433      & 140/500/1K \\\\\nCiteSeer \\cite{DBLP:journals/aim/SenNBGGE08}& 3,327            & 4,732            & 3,703           & 120/500/1K \\\\\nPubMed \\cite{namata2012query}& 19,717           & 44,338           & 500    & 60/500/1K \\\\\n\\midrule\nFlickr \\cite{DBLP:conf/eccv/McAuleyL12,graphsaint}& 89,250           & 899,756          & 500   & 44K/22K/22K \\\\\nArxiv \\cite{ogb}& 169,343          & 1,166,243        & 128 & 90K/29K/48K \\\\\nReddit \\cite{reddit,graphsaint}& 232,965          & 23,213,838       & 602  & 153K/23K/55K \\\\\n\\midrule\nYelp \\cite{graphsaint}& 716,847          & 13,954,819       & 300     & 537K/107K/71K \\\\\nProducts \\cite{ogb}& 2,449,029        & 61,859,140       & 100     & 196K/39K/2M \\\\\n\\bottomrule\n\\end{tabular}\n% }\n\\vspace{-3ex}\n\\label{tab:dataset}\n\\end{table}",
            "tab:results": "\\begin{table*}[!ht]\\small\n\\caption{Performance on Node Classification (metric: F1-micro (\\%) ). \n``O. Perf.'' and ``R. Perf.'' refer to performance reported in original papers and reproduced by our own, respectively. Higher of these two columns are underlined.\n``Perf. Impv.'' and ``\\#Params Decr.'' refer to the absolute improvement of student performance (w.r.t. the underlined results) and the relative decrease of teacher parameters, respectively.\nResults of previous work are mainly taken from \\cite{graphsaint}, \\cite{gas}, and OGB Leaderboards. We report the average performance and std. across 10 random seeds.}\n\\centering\n\\begin{tabular}{@{}l  ccc ccc cccc@{}}\n\\toprule\n&  \\multicolumn{3}{c}{\\textbf{Teacher}} & \\multicolumn{3}{c}{\\textbf{Vanilla Student}} & \\multicolumn{4}{c}{\\textbf{Student trained with \\med}} \\\\ \n\\cmidrule(lr){2-4}\n\\cmidrule(lr){5-7}\n\\cmidrule(lr){8-11}\n% \\multirow{2}{Datasets}\nDatasets& Model & Perf.& \\#Params  & Model&O. Perf. & R. Perf. & Perf.      & \\#Params  & Perf. Impv. (\\%) & \\#Params Decr. \\\\\\midrule\nCora    & GCNII & 85.5 & 616,519   & GCN  & \\underline{81.5}    & 78.3 $\\pm$0.9    & 83.6 $\\pm$0.8   & 96,633    & 2.1   & 84.3\\% \\\\\nCiteSeer& GCNII & 73.4 & 5,144,070 & GCN  & \\underline{71.1}    & 68.6 $\\pm$1.1    & 72.9 $\\pm$0.4   & 1,016.156 & 1.8   & 80.2\\% \\\\\nPubMed  & GCNII & 80.3 & 1,177,603 & GCN  & \\underline{79.0}    & 78.1 $\\pm$1.0    & 81.3 $\\pm$0.4   & 195,357   & 2.3   & 83.4\\% \\\\ \\midrule\nFlickr  & GCNII & 56.20& 1,182,727 & GCN  & 49.20   & \\underline{49.63} $\\pm$1.19  & 52.95 $\\pm$0.24 & 196,473   & 3.32  & 83.4\\% \\\\\nArxiv   & GCNII & 72.74& 2,148,648 & GCN  & \\underline{71.74}   & 71.43 $\\pm$0.13  & 73.05 $\\pm$0.22 & 242,426   & 1.31  & 88.7\\% \\\\\nReddit  & GCNII & 96.77& 691,241   & GCN  & 93.30   & \\underline{94.12} $\\pm$0.04  & 95.15 $\\pm$0.02 & 234,655   & 1.03  & 66.1\\% \\\\ \\midrule\nYelp    & GCNII & 65.14& 2,306,660 & Cluster-GCN& 59.15 & \\underline{59.63} $\\pm$0.51 & 60.63 $\\pm$0.42 & 431,950   & 1.00  & 81.3\\% \\\\\nProducts& GAMLP & 84.59& 3,335,831 & Cluster-GCN& \\underline{76.21} & 74.99 $\\pm$0.76 & 81.45 $\\pm$0.47 & 682,449   & 5.24  & 79.5\\% \\\\\n\\bottomrule\n\\end{tabular}\n\\vspace{-1ex}\n\\label{tab:results}\n\\end{table*}",
            "tab:comparison": "\\begin{table}[!t]\\small\n\\caption{Comparison with other distillation algorithms.}\n\\vspace{-1ex}\n\\centering\n% \\resizebox{\\columnwidth}{!}{\n\\begin{tabular}{@{}lccccc@{}}\n\\toprule\nDatasets & Student & KD \\cite{hinton2015distilling} & FitNet \\cite{fitnets} & LSP \\cite{DBLP:conf/cvpr/YangQSTW20} & \\med  \\\\\n\\midrule\nCora     & 81.5  & 83.2  & 82.4  & 81.7   & \\textbf{83.6} \\\\\nCiteSeer & 71.1  & 71.4  & 71.6  & 68.8   & \\textbf{72.9} \\\\\nPubMed   & 79.0  & 80.3  & \\textbf{81.3}  & 80.8   & \\textbf{81.3} \\\\\\midrule\nFlickr   & 49.20  & 50.58 & 50.69 & 50.02  & \\textbf{52.95} \\\\\nArxiv    & 71.74 & 73.03 & 71.83  & OOM    & \\textbf{73.05} \\\\\nReddit   & 93.30  & 94.01 & 94.99  & OOM    & \\textbf{95.15} \\\\\\midrule \nYelp     & 59.15 & 59.14 & 59.92  & 49.24  & \\textbf{60.63} \\\\\nProducts & 76.21 & 79.19 & 76.57  & 70.86  & \\textbf{81.45} \\\\\n\\bottomrule\n\\end{tabular}\n% }\n% \\vspace{-3ex}\n\\label{tab:comparison}\n\\end{table}",
            "tab:molecules": "\\begin{table}[!ht]\n    \\centering\n    \\caption{Graph classification on Molhiv \\cite{ogb} (metric: ROC-AUC (\\%)) and Molpcba \\cite{ogb} (metric: AP (\\%)). Results of teacher and student are taken from OGB Leaderboards.\n    We report the average performance and std. across 10 random seeds.\n    % Bold denote the best performing distillation technique for each column. \n    }\n    \\resizebox{\\linewidth}{!}{\n    \\begin{tabular}{@{}lcccc@{}}\n        \\toprule\n        \\textbf{Dataset} & \\multicolumn{2}{c}{\\textbf{Molhiv}} & \\multicolumn{2}{c}{\\textbf{Molpcba} } \\\\\n        \\textbf{Teacher} & \\multicolumn{2}{c}{\\textbf{HIG with DeeperGCN } } & \\multicolumn{2}{c}{\\textbf{HIG with Graphormer } } \\\\\n        \\textbf{Student} & \\textbf{GCN} & \\textbf{GIN} & \\textbf{GCN} & \\textbf{GIN} \\\\\n        \\midrule \\midrule\n        Teacher & 84.03 \\text{$\\pm$0.21} & 84.03 \\text{$\\pm$0.21} & 31.67 \\text{$\\pm$0.34} & 31.67 \\text{$\\pm$0.34} \\\\\n        Student & 76.06 \\text{$\\pm$0.97} & 75.58 \\text{$\\pm$1.40} & 20.20 \\text{$\\pm$0.24} & 22.66 \\text{$\\pm$0.28} \\\\ \\midrule\n        KD \\cite{hinton2015distilling} & 74.98 \\text{$\\pm$1.09} & 75.08 \\text{$\\pm$1.76} & 21.35 \\text{$\\pm$0.42} & 23.56 \\text{$\\pm$0.16} \\\\\n        FitNet \\cite{fitnets} & 79.05 \\text{$\\pm$0.96} & 77.93 \\text{$\\pm$0.61} & 21.25 \\text{$\\pm$0.91} & 23.74 \\text{$\\pm$0.19}\\\\\n        % LSP \\cite{DBLP:conf/cvpr/YangQSTW20} & 73.58 \\text{$\\pm$1.29} & 73.24 \\text{$\\pm$1.67} & 75.04 \\text{$\\pm$1.20} & 70.74 \\text{$\\pm$1.82} \\\\\n        \\med & \\textbf{79.46} \\text{$\\pm$0.97}& \\textbf{79.16} \\text{$\\pm$1.50} & \\textbf{22.56} \\text{$\\pm$0.23}& \\textbf{25.85} \\text{$\\pm$0.17}\\\\\n        \\bottomrule\n    \\end{tabular}\n    }\n    \\label{tab:molecules}\n\\end{table}",
            "tab:eff": "\\begin{table}[!t]\\small\n\\caption{Comparison of efficiency between student GNNs and the corresponding teachers.}\n% \\vspace{-1ex}\n\\centering\n\\resizebox{\\columnwidth}{!}{\n\\begin{tabular}{@{}lcccccc@{}}\n\\toprule\n& \\multicolumn{2}{c}{\\textbf{\\#Params}} & \\multicolumn{2}{c}{\\textbf{GPU Memory}} &\\multicolumn{2}{c}{\\textbf{Inference time}} \\\\ \n\\cmidrule(lr){2-3}\n\\cmidrule(lr){4-5}\n\\cmidrule(lr){6-7}\nDatasets & Teacher & Student & Teacher & Student & Teacher & Student  \\\\\n\\midrule\nCora           & 0.6M & 0.1M & 0.22G & 0.03G & 40.3ms  & 4.1ms \\\\\nPubMed         & 1.2M & 0.2M & 1.23G & 0.33G & 57.3ms  & 5.7ms \\\\\nFlickr         & 1.2M & 0.2M & 2.79G & 1.49G & 309.7ms & 11.9ms\\\\\nYelp           & 2.3M & 0.4M & 6.28G & 4.73G & 3.0s & 1.5s \\\\\nProducts  & 3.3M & 0.7M & 6.25G & 6.20G & 16.1s   & 7.0s \\\\\n\\bottomrule\n\\end{tabular}\n}\n\\vspace{-4ex}\n\\label{tab:eff}\n\\end{table}",
            "tab:abalation": "\\begin{table}[!t]\\small\n\\caption{Ablation studies on the impacts of each identifier. }\n% \\vspace{-1ex}\n\\vspace{-1ex}\n\\centering\n% \\resizebox{\\columnwidth}{!}{\n\\begin{tabular}{@{}lcccccc@{}}\n\\toprule\nDatasets & Cora  & PubMed & Flickr & Yelp  & Products & Molhiv \\\\\\midrule\nTeacher  & 85.5 & 80.3 & 56.20 & 65.14 & 84.59 & 84.03\\\\\nStudent  & 81.5 & 79.0 & 49.20 & 59.15 & 76.21 & 75.58\\\\\\midrule\nOnly $D_e$    & 82.9 & 80.6 & 52.20 & 59.63 & 81.13 & 78.28\\\\\nOnly $D_\\ell$ & 82.3 & 81.0 & 52.52 & 60.03 & 79.76 & 78.09\\\\\n% Ensemble      & 83.6 & 81.7 & 52.12 & 58.74 & 80.34 \\\\\n\\med & \\textbf{83.6} &\\textbf{81.3} & \\textbf{52.95} & \\textbf{60.63} & \\textbf{81.45} & \\textbf{79.16} \\\\\n\\bottomrule\n\\end{tabular}\n% }\n\\vspace{-2ex}\n\\label{tab:abalation}\n\\end{table}"
        },
        "figures": {
            "fig:bubble": "\\begin{figure}[!t]\n  \\centering\n  \\includegraphics[width=\\linewidth]{fig/bubble2.pdf}\n  \\caption{Node classification accuracy v.s. graph size. Each bubble's area is proportional to the number of parameters of a model. Model name with * means the variant. The statistics are collected from OGB leaderboards.}\n  \\label{fig:bubble}\n  \\vspace{-4ex}\n\\end{figure}",
            "fig:framework": "\\begin{figure*}[!t]\n    \\centering\n    \\includegraphics[width=0.85\\linewidth]{fig/model.pdf}\n    \\vskip -0.5em\n    \\caption{Illustration of the proposed adversarial knowledge distillation framework \\med.}\n    \\label{fig:framework}\n    \\vskip -0.5em\n\\end{figure*}",
            "fig:tsne": "\\begin{figure*}[!ht]%\n     \\centering\n     \\subfloat[Vanilla GCN]{{\\includegraphics[width=0.33\\linewidth]{fig/tsne-gcn10.pdf} }\\label{fig:gcn}}%\n     \\subfloat[Student GCN trained with \\med]{{\\includegraphics[width=0.33\\linewidth]{fig/tsne-stu10.pdf} }\\label{fig:stu}}%\n    \\subfloat[Teacher GCNII]{{\\includegraphics[width=0.33\\linewidth]{fig/tsne-tea10.pdf} }\\label{fig:tea}}%\n    \\qquad\n    \\vskip -0.5em\n    \\caption{t-SNE embeddings of the nodes in the Cora dataset from the vanilla GCN embeddings ({\\bf left}), embeddings from the student GCN that trained by \\med~({\\bf middle}), and GCNII ({\\bf right}). The Silhouette scores \\cite{rousseeuw1987silhouettes} of the embeddings learned by three models are 0.2196, 0.2638, and 0.3033, respectively.}\n    \\label{fig:tsne}\n\\vskip -0.75em\n% \\vspace{-4mm}\n\\end{figure*}"
        },
        "equations": {
            "eq:1": "\\begin{align*}\n    \\mathbf{h}_v^{(k+1)} &=\\textup{UPDATE}^{(k)}\\left(\\mathbf{h}_v^{(k)}, m_{\\mathcal{N}(v)}^{(k)}\\right), \\\\\n    \\textup{where } m_{\\mathcal{N}(v)}^{(k)} &= \\textup{AGGREGATE}^{(k)}\\left( \\{\\mathbf{h}_u^{(k)}\\mid \\forall\\,u\\in \\mathcal{N}(v) \\} \\right).\n\\end{align*}",
            "eq:2": "\\begin{align*}\n    \\mathbf{z} &= g(\\mathbf{h}), \\\\\n    \\hat{\\mathbf{y}} &=\\textup{softmax}(\\mathbf{z}),\n\\end{align*}",
            "eq:3": "\\begin{align*}\n    D_e^{local}(\\mathbf{h}_v^T, \\mathbf{h}_u^T) &= \\langle \\mathbf{h}_v^T, \\mathbf{W}^{local} \\mathbf{h}_u^T \\rangle \\in [0, 1],\\\\\n    D_e^{local}(\\mathbf{h}_v^S, \\mathbf{h}_u^S) &= \\langle \\mathbf{h}_v^S, \\mathbf{W}^{local} \\mathbf{h}_u^S \\rangle \\in [0, 1], \\quad \\forall~(v,u)\\in \\mathcal{E},\\\\\n    D_e^{global}(\\mathbf{h}_v^{T/S}, \\mathbf{s}_\\mathcal{G}^{T}) &= \\langle \\mathbf{h}_v^{T/S}, \\mathbf{W}^{global} \\mathbf{s}_\\mathcal{G}^{T} \\rangle \\in [0, 1],\\\\\n    D_e^{global}(\\mathbf{h}_v^{T/S}, \\mathbf{s}_\\mathcal{G}^{S}) &= \\langle \\mathbf{h}_v^{T/S}, \\mathbf{W}^{global} \\mathbf{s}_\\mathcal{G}^{S} \\rangle \\in [0, 1], \\quad \\forall~v\\in \\mathcal{V}\\subset\\mathcal{G},\n\\end{align*}",
            "eq:4": "\\begin{equation}\n\\begin{aligned}\n    \\min_{G^S} \\max_{D_e} \\mathcal{J}^{local} +\\mathcal{J}^{global},\n\\end{aligned} \n\\label{eq:emb_D}\n\\end{equation}",
            "eq:5": "\\begin{align*}\n    \\frac{1}{|\\mathcal{E}|}\\sum_{(v,u)\\in \\mathcal{E}}\\Big( &\\log\\textup{P}(\\textup{Real}\\mid D_e^{l}(\\mathbf{h}_v^T, \\mathbf{h}_u^T))+\\log\\textup{P} (\\textup{Fake}\\mid D_e^{l}(\\mathbf{h}_v^S, \\mathbf{h}_u^S))\\Big),\n\\end{align*}",
            "eq:6": "\\begin{align*}\n    \\frac{1}{2|\\mathcal{V}|}\\sum_{v\\in \\mathcal{V}}\\Big( &\\log\\textup{P}(\\textup{Real}\\mid D_e^{g}(\\mathbf{h}_v^T, \\mathbf{s}_\\mathcal{G}^T))+\\log\\textup{P} (\\textup{Fake}\\mid D_e^{g}(\\mathbf{h}_v^S,\\mathbf{s}_\\mathcal{G}^T))+\\\\\n    &\\log\\textup{P}(\\textup{Real}\\mid D_e^{g}(\\mathbf{h}_v^S,\\mathbf{s}_\\mathcal{G}^S))\n    +\\log\\textup{P} (\\textup{Fake}\\mid D_e^{g}(\\mathbf{h}_v^T,\\mathbf{s}_\\mathcal{G}^S))\\Big),\n\\end{align*}",
            "eq:7": "\\begin{align*}\n    \\langle \\widehat{\\mathbf{h}}_v, \\textbf{W}^{local}  \\widehat{\\mathbf{h}}_u \\rangle=\\textup{cosine\\_sim}(\\mathbf{h}_v, \\mathbf{h}_u), ~\\forall~(v,u)\\in \\mathcal{E}.\n\\end{align*}",
            "eq:8": "\\begin{equation}\n\\max_D \\frac{1}{| \\mathcal{V}|}\\sum_{v\\in \\mathcal{V}}\n\\Big(\\log \\textup{P}(\\textup{Real}\\mid D(\\mathbf{z}_v^T))+\\log \\textup{P}(\\textup{Fake}\\mid D(\\mathbf{z}_v^S))\\Big).\n\\end{equation}",
            "eq:9": "\\begin{equation}\n\\begin{aligned}\n\\max_{D_\\ell} \\frac{1}{| \\mathcal{V}|}\\sum_{v\\in \\mathcal{V}}&\n\\Big(\\log \\textup{P}(\\textup{Real}\\mid D_\\ell(\\mathbf{z}_v^T))+\\log \\textup{P}(\\textup{Fake}\\mid D_\\ell(\\mathbf{z}_v^S))\\\\\n&+\\log \\textup{P}(y_v\\mid D_\\ell(\\mathbf{z}_v^T))+\\log \\textup{P}(y_v\\mid D_\\ell(\\mathbf{z}_v^S))\\Big).    \n\\end{aligned}\n\\label{eq:logits-d}\n\\end{equation}",
            "eq:10": "\\begin{equation}\n\\begin{aligned}\n\\min_{G^S} \\frac{1}{| \\mathcal{V}|}\\sum_{v\\in \\mathcal{V}}&\n\\Big(\\log \\textup{P}(\\textup{Real}\\mid D_\\ell(\\mathbf{z}_v^T))+\\log \\textup{P}(\\textup{Fake}\\mid D_\\ell(\\mathbf{z}_v^S))\\\\\n&-\\Big[ \\log \\textup{P}(y_v\\mid D_\\ell(\\mathbf{z}_v^T))+\\log \\textup{P}(y_v\\mid D_\\ell(\\mathbf{z}_v^S)) \\Big]\\\\\n&+\\|\\mathbf{z}_v^S - \\mathbf{z}_v^T\\|_1\n\\Big).  \n\\end{aligned} \n\\label{eq:logits_D}\n\\end{equation}"
        },
        "git_link": "https://github.com/TencentYoutuResearch/HIG-GraphClassification"
    }
}