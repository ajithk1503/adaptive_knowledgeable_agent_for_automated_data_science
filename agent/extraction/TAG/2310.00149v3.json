{
    "meta_info": {
        "title": "One for All: Towards Training One Graph Model for All Classification  Tasks",
        "abstract": "Designing a single model to address multiple tasks has been a long-standing\nobjective in artificial intelligence. Recently, large language models have\ndemonstrated exceptional capability in solving different tasks within the\nlanguage domain. However, a unified model for various graph tasks remains\nunderexplored, primarily due to the challenges unique to the graph learning\ndomain. First, graph data from different areas carry distinct attributes and\nfollow different distributions. Such discrepancy makes it hard to represent\ngraphs in a single representation space. Second, tasks on graphs diversify into\nnode, link, and graph tasks, requiring distinct embedding strategies. Finally,\nan appropriate graph prompting paradigm for in-context learning is unclear. We\npropose \\textbf{One for All (OFA)}, the first general framework that can use a\nsingle graph model to address the above challenges. Specifically, OFA proposes\ntext-attributed graphs to unify different graph data by describing nodes and\nedges with natural language and uses language models to encode the diverse and\npossibly cross-domain text attributes to feature vectors in the same embedding\nspace. Furthermore, OFA introduces the concept of nodes-of-interest to\nstandardize different tasks with a single task representation. For in-context\nlearning on graphs, OFA introduces a novel graph prompting paradigm that\nappends prompting substructures to the input graph, which enables it to address\nvaried tasks without fine-tuning. We train the OFA model using graph data from\nmultiple domains (including citation networks, molecular graphs, knowledge\ngraphs, etc.) simultaneously and evaluate its ability in supervised, few-shot,\nand zero-shot learning scenarios. OFA performs well across different tasks,\nmaking it the first general-purpose across-domains classification model on\ngraphs.",
        "author": "Hao Liu, Jiarui Feng, Lecheng Kong, Ningyue Liang, Dacheng Tao, Yixin Chen, Muhan Zhang",
        "link": "http://arxiv.org/abs/2310.00149v3",
        "category": [
            "cs.LG"
        ],
        "additionl_info": "23 Pages, Published at ICLR 2024"
    },
    "latex_extraction": {
        "content": {
            "section 1": {
                "name": "Introduction",
                "content": "\nRecently, large language models (LLMs) have received tremendous attention due to their power and versatility in solving natural language tasks like text generation, machine translation, and question-answering. LLMs' in-context learning ability and universality allow the model to directly perform various cross-domain downstream tasks by providing related context or prompt to the model, therefore avoiding any fine-tuning on model parameters~\\citep{brown2020Language,zhang2023automatic,Lu2021PretrainedTA,Bommasani2021OnTO}. \n\n\nDespite the great success of foundation models on language, developing a foundation model for graph structure data is less explored. Particularly, several challenges unique to graph data prevent the direct transfer of foundation model design from the language domain to the graph domain. First, although the natures of language tasks differ, they are still uniformly represented in human-interpretable texts. An LLM can encode them into the same text embedding space and train on different source tasks together. However, \\textbf{graph datasets from different sources are usually completely different in feature representation}. Concretely, widely used graph datasets include citation networks~\\citep{Cora-CiteSeer, hu2020open}, e-commerce networks~\\citep{Coauthor-Amazon}, knowledge graphs~\\citep{dettmers2018conve, Toutanova2015ObservedVL}, and molecular graphs~\\citep{dwivedi2020benchmarkgnns}. Their raw forms contain attributes generated from isolated processes. For example, node features in molecular graphs are usually vectors whose entries are indices of nominal features of atoms. In contrast, node features in e-commerce networks could be Bag-of-Word vectors of item descriptions. These features are so different in dimension, scale, and semantic meanings that it is almost impossible to directly learn the representation of these data using the same model. Second, \\textbf{different downstream tasks in the graph domain attend to different parts of the graph and require task-specific knowledge and methodologies}. Specifically, graph-related tasks can be roughly divided into three classes: node-level, link-level, and graph-level. Even though Graph Neural Networks (GNNs) achieved great success in all three task classes, the rationale for the success behind each task class is different. For node-level tasks, proper smoothing of the node features leads to good performance~\\citep{cnn_graph, chien2021adaptive, he2021bernnet}. However, for link-level and graph-level tasks, encoding the local structure is vital to the success, encouraging a line of work that develops more expressive GNNs~\\citep{xu2018powerful, zhang2021nested, zhang2018link}. Generally, a powerful model for node-level tasks may not work on link-level or graph-level tasks. Consequently, current models are incompetent and infeasible to learn different tasks jointly. Third, the design of the in-context learning or prompt is straightforward in natural language, where we can simply add a description of the task or a few examples to the input. However, there is no existing solution to add such context information to the graph \\textit{generically}. \\textbf{How to design a unified way to perform cross-domain and in-context learning on the graph tasks is ambiguous.}\n\n\nTo address these challenges, we propose \\textbf{One-for-All (OFA)}, a general solution for building and training a foundation GNN model with in-context learning ability across different domains. OFA has three main unique features: (1) OFA uses text-attributed graphs (TAGs) to integrate graph datasets from different domains into one large TAG dataset and leverages the power of LLMs to learn from all domains jointly. We collect nine graph datasets commonly used in the community varying in size, domains, and task types (see Table~\\ref{tab:dataset} for the full list). Then, we describe all nodes and edges in the graphs using human-readable texts and embed the texts from different domains into the same embedding space with a single LLM. (2) OFA proposes the nodes-of-interest (NOI) subgraph and the NOI prompt node, which not only unify different types of graph tasks but also improve the ability of the foundation model to learn the structural information in the graph. (3) OFA introduces a carefully designed and widely applicable graph prompting paradigm (GPP) that inserts a prompt graph into the original input graph in a task-specific way. The nodes in the prompt graph contain all related information about the downstream task (described by texts and encoded by the same LLM encoder as the input graph). Then, the modified graph becomes the actual input to the foundation graph model. Thus, the model is adaptive to perform different tasks according to the prompt graphs. Figure~\\ref{fig:overview} illustrates the pipeline of OFA. \\textbf{After training, the users can describe any graph with natural texts and apply the OFA pipeline to predict possibly unseen classes.}\n\n\nWe evaluate the proposed OFA on all collected TAG datasets under supervised, few-shot, and zero-shot scenarios. We demonstrate that a single OFA model can perform well on cross-domain and cross-task scenarios. In particular, we show that the OFA achieves great results on zero-shot learning, which is impossible for most of the existing graph models. \n"
            },
            "section 2": {
                "name": "Preliminaries",
                "content": "\n\\textbf{Text-attributed graphs (TAGs).} We define a TAG as a graph where each node and each edge in the graph is associated with a text sentence. We denote a TAG as $\\mathcal{G}=(\\mathcal{V}, \\mathcal{E}, \\mathcal{R})$, where $\\mathcal{V}=\\{v_1, \\ldots, v_{|\\mathcal{V}|}\\}$ is the set of nodes, $\\mathcal{R}=\\{r_1, \\ldots, r_{|\\mathcal{R}|}\\}$ is the set of relations, $\\mathcal{E}=\\{e_1, \\ldots, e_{|\\mathcal{E}|}\\}$ is the set of edges. An edge $e_{ij}=(v_i, r, v_j) \\in \\mathcal{E}$ consists of a source node $v_i \\in \\mathcal{V}$, a relation $r \\in \\mathcal{R}$, and a target node $v_j \\in \\mathcal{V}$. Let $s_{v_i}$ denote the text sentence associated with node $v_i$ and $s_{e_{ij}}$ denote the text sentence associated with edge $e_{ij}\\in \\mathcal{E}$. Finally, let $\\mathcal{N}_{k}(v)$ denote the set of all neighbor nodes within $k$ hops of node $v$. Note that some concurrent works also introduce the concept of TAGs~\\citep{explorenlgnn,expasfeat}. However, they only focus on graphs whose raw node features are already texts. On the contrary, we extend this concept and regard all graphs as TAGs since any nodes and edges are describable by texts.  \n\n\\textbf{Learning scenarios.} In this work, we focus on the classification problem. Denote a dataset as $\\mathcal{D}=\\{(d_i, y_i)\\}^D_1$, where $D$ is the number of data in the dataset, $d_i$ is a data sample, $y_i \\in \\mathcal{Y}$ is the label of $d_i$ and $\\mathcal{Y}$ is the set of all data labels. To train a classifier, we split the dataset into the train, validation, and test sets, denoted as $\\mathcal{D}_{train}$, $\\mathcal{D}_{val}$, and $\\mathcal{D}_{test}$ respectively. Their label sets are $\\mathcal{Y}_{train}$, $\\mathcal{Y}_{val}$, and $\\mathcal{Y}_{test}$. We focus on three learning scenarios. In \\textbf{supervised learning}, the model will be trained on $\\mathcal{D}_{train}$ and be evaluated on $\\mathcal{D}_{val}$ to determine the best model. Finally, $\\mathcal{D}_{test}$ is used to evaluate the model's performance. All labels in the validation and test data are seen during training, that is, $\\mathcal{Y}_{train} = \\mathcal{Y}_{test}$. \nThe second learning scenario is \\textbf{few-shot learning}. The training and evaluation procedure of few-shot learning is similar to supervised learning. However, in few-shot learning, we have $\\mathcal{Y}_{train} \\bigcap \\mathcal{Y}_{test} = \\emptyset$. Few-shot learning typically deals with $N$-way $K$-shot tasks, \nwhere we use $N\\cdot K$ data $\\{(d_i, y_i)\\}^{N \\cdot K}_1$ as support samples, such that each distinct class is provided with $K$ labeled data and $N$ is the total number of distinct classes. Next, given these support samples, the model needs to classify data in the query set $\\mathcal{Q}=\\{d_i\\}^{n}_1$ into these $N$ classes. The third learning scenario is \\textbf{zero-shot learning}, which can be viewed as a special case of few-shot learning. In zero-shot learning, for any $N$-way $K$-shot task, we have $K=0$ as there are no support samples. \n\n\\textbf{In-context learning in language.} In-context learning mainly refers to the ability of the model to learn tasks given only a few examples in the form of demonstration~\\citep{dong2023survey}. For the language model, this is mainly achieved by the prompting mechanism. The pretrained LLM model takes the demonstration as input, which is provided by the prompt text $C$. Then, the answer to the task is given by generating the rest of the sentence conditioned on $C$~\\citep{brown2020Language}. \n\n\n% In supervised learning, we mainly model the probability $P(y_i|d_i, \\theta)$. However, to do that, we must have supervised tasks and the learned model cannot generalize to out-of-distribution tasks. Instead, in in-context/prompt learning, we model the probability $P(d_i;\\theta)$ directly and use this probability to predict the $y_i$~\\citep{promptreview}. In language, this is usually achieved by encoding the task description into a partial sentence and letting the LLM provide the answer to the task by completing the remaining sentence~.\\section{One-for-All: Towards foundation model on graph}\n\\label{sec:OFA}\n\nThe proposed OFA is a general graph learning framework that uses one model to simultaneously solve classification tasks varying in formats and backgrounds, similar to LLMs that can answer substantially different questions using the same model weight. Figure~\\ref{fig:overview} illustrates the pipeline of OFA. OFA can be divided into three parts. First, graphs from different domains are integrated into text-attributed graphs with the same format, allowing a single LLM to embed all TAGs into the same space. In the second part, OFA unifies different task types in the graph domain by introducing the Nodes-of-Interest (NOI) subgraph and NOI prompt node, where a graph model can attend to task-relevant information automatically. Finally, OFA proposes the Graph Prompting Paradigm (GPP) that organically injects task information into the graph data, enabling in-context learning. \n\n",
                "subsection 2.1": {
                    "name": "Unifying graph data from different domains with TAGs",
                    "content": "\nOne critical challenge in building a foundation model for graphs is that cross-domain graph data are usually generated by entirely different procedures and have node/edge attributes embedded in different spaces. This makes graph models trained on one domain almost impossible to generalize to another domain. However, despite the distinct attributes across datasets, almost all can be described by human-interpretable language. For example, in molecular graphs where nodes represent atoms, we can use plain text to describe the node with atomic features, including element names, chirality, etc. The key advantage is that by using text to describe nodes and edges, we can apply an LLM to encode different graph attributes into the same space. Consequently, we introduce the concept of TAGs to integrate graph data from different domains systematically.\n\nSpecifically, we design a standardized format for text feature generation of any nodes and edges in graph data. The text feature format for nodes is shown below:\n\\begin{tcolorbox}[boxsep=0mm,left=2.5mm,right=2.5mm]\n\\textbf{Text feature of nodes:} Feature node. $<$\\textit{feature description}$>$: $<$\\textit{feature content}$>$; $<$\\textit{feature description}$>$: $<$\\textit{feature content}$>$; ...\n\n\\textbf{Example:} Feature node. Atom: Carbon, Atomic number 6, helix chirality, is not in a ring, ...\n\n\\textbf{Example:} Feature node. Paper title and abstract: Attention is all you need. The dominant sequence transduction models are ...\n\\end{tcolorbox}\n%\\vspace{-5pt}\nGiven a TAG $\\mathcal{G}$, the text feature $s_{v_i}$ always starts with the text \\textit{Feature node.} to indicate that this node is an input node with features from the original graph as opposed to prompt nodes, which will be introduced in Section \\ref{sec:incontext}. Next, the text describes the type of a feature, followed by the content of the feature. If there are multiple features for a node, they are joined by semicolons. The construction of the text feature $s_{e_{ij}}$ for edge $e_{ij}$ is similar, except the start of the text is \\textit{Feature edge.}\n\\begin{tcolorbox}[boxsep=0mm,left=2.5mm,right=2.5mm]\n\\textbf{Text feature of edges:} Feature edge. $<$\\textit{feature description}$>$: $<$\\textit{feature content}$>$; $<$\\textit{feature description}$>$: $<$\\textit{feature content}$>$; ...\n\n\\textbf{Example:} Feature edge. Chemical Bond: ionic bonding, is conjugated, ...\n\n\\textbf{Example:} Feature edge. Citation from one paper to another.\n\\end{tcolorbox}\nFollowing the protocol, we meticulously collected nine graph datasets widely recognized as benchmarks in numerous downstream tasks. This collection encompasses graph data from various domains, including citation networks, molecular graphs, knowledge graphs, and more. Additionally, it covers nearly all classification tasks employed in the research community, i.e., node classification, link prediction, and graph classification. We provide the detailed summarization of all the collected datasets in OFA in Table~\\ref{tab:dataset} and detailed collection and processing protocol in Appendix~\\ref{app:dataset}.\n\nAs mentioned above, we can apply an LLM encoder to encode all text features into a fixed-length vector as the final input feature of all nodes/edges. Namely, for node $v_i$ and edge $e_{ij}$, their vector representations are defined as $x_i = \\text{LLM}(s_{v_i})$ and $x_{ij}= \\text{LLM}(s_{e_{ij}})$. Because the LLM-encoded input features contain domain information, the subsequent pipeline can capture and leverage this information. Generally, any kind of LLM can be used as the encoder, and a stronger LLM potentially yields better overall performance. In OFA, we evaluate and compare the performance of different LLMs (further discussion in Section~\\ref{sec:experiments}). We also provide a visualization of all generated OFA datasets in Appendix~\\ref{app:dataset_visual}.\n\n"
                },
                "subsection 2.2": {
                    "name": "Unifying different graph tasks with nodes-of-interest",
                    "content": "\\label{sec:NOI}\nDownstream classification tasks in the graph domain can be divided into different categories like: (1) \\textbf{node-level tasks}, where the task is to classify a node in the graph; (2) \\textbf{link-level tasks}, where the task is to reason about the connection between a node pair; (3) \\textbf{graph-level tasks}, where the task is to make prediction on the whole graph. However, tasks at different levels need to be handled by distinct procedures and methods, which makes the construction of a foundation model for graphs difficult. In contrast, different downstream tasks in language share the same autoregressive generation nature, which makes the knowledge learned from the next-token prediction task used in LLMs uniformly beneficial to various downstream tasks. Then the question arises: Can we unify different graph tasks into a single task to facilitate the training and knowledge transferring in the graph domain?\n\nIn OFA, we propose Nodes-of-Interest (NOI) subgraph and NOI prompt node to achieve the goal. The term \\textbf{NOI} refers to the set of target nodes in a task, illustrated by the blue nodes in Figure~\\ref{fig:prompt_design}, and is represented as $\\mathcal{T}$. NOI is not limited to the listed levels of tasks, and its size depends on the prediction target. An \\textbf{NOI subgraph} is defined as the subgraph around the NOI. Denote $\\mathcal{S}_h(v)=\\{\\mathcal{V}^h_v, \\mathcal{E}^h_v, \\mathcal{R}^h_v\\}$ as the $h$-hop ego-subgraphs around $v$, consisting of $h$-hop neighbor nodes of $v$ and all interconnecting edges. A NOI subgraph $\\mathcal{G}_h(\\mathcal{T})$ combines ego-subgraphs of all nodes in NOI, \n\\begin{equation}\n    \\mathcal{G}_h(\\mathcal{T})=\\bigcup_{v\\in \\mathcal{T}}\\mathcal{S}_h(v)=\\{\\bigcup_{v\\in \\mathcal{T}}\\mathcal{V}^h_v, \\bigcup_{v\\in \\mathcal{T}}\\mathcal{E}^h_v, \\bigcup_{v\\in \\mathcal{T}}\\mathcal{R}^h_v\\}.\n\\end{equation}\nFor node-level tasks on node $v$, NOI is the node itself, so $\\mathcal{T}=\\{v\\}$ and $\\mathcal{G}_h(\\mathcal{T})=\\mathcal{S}_h(v)$. For link-level tasks on node pair $(v_i, v_j)$, we have $\\mathcal{T}=\\{v_i, v_j\\}$ and $\\mathcal{G}_h(\\{v_i, v_j\\})=\\mathcal{S}_h(v_i)\\bigcup \\mathcal{S}_h(v_j)$. For graph-level tasks, NOI contains all nodes in the graph, and the NOI subgraph is $\\mathcal{G}_h(\\mathcal{V})=(\\mathcal{V}, \\mathcal{E}, \\mathcal{R})$.\n\n% \\mathcal{R}$ contains all possible relations exist in edge set $\\mathcal{E}^h_v$\n\n% With the carefully designed NOI prompt node and corresponding connections, the information required for making predictions can be encoded in the NOI prompt node through a graph learning model in a unified way.\n\nThen, we define the \\textbf{NOI prompt node} to unify the processing and readout procedures in different task types. The NOI prompt node is associated with a task prompt text:\n\\begin{tcolorbox}[boxsep=0mm,left=2.5mm,right=2.5mm]\n\\textbf{Text feature of the NOI prompt node:} Prompt node. $<$\\textit{task description}$>$.\n\n\\textbf{Example:} Prompt node. Graph classification on molecule properties.\n\n\\textbf{Example:} Prompt node. Node classification on the literature category of the paper.\n\\end{tcolorbox}\nThe text is encoded by the same LLM as other text in $\\mathcal{G}$. The NOI prompt node connects to all nodes in NOI, as illustrated by double concentric circles in Figure \\ref{fig:prompt_design}. \\textit{Through message passing, the NOI prompt node summarizes information in the NOI and the task description.} We can then attach class nodes to the NOI prompt node for downstream tasks, which we will explain further in Section \\ref{sec:incontext}. While concurrent works also utilize subgraphs to unify different types of tasks~\\citep{allinone, liu2023graphprompt}, these approaches mainly leverage the subgraph concept to transform tasks into a graph-level task, \\textbf{without a NOI prompt node design}. In contrast, with the NOI prompt node, we do not require any explicit pooling mechanism, distinguishing our method from previous ones. The combination of NOI subgraph and NOI prompt nodes in our design achieves a unified readout and treatment for all node-level, link-level, and graph-level tasks. Further, the NOI prompt node connected to NOI can be viewed as a labeling trick, which uplifts the expressive power of the original graph model to better learn structural information around the NOI~\\citep{zhang2021labeling}. Moreover, the task prompt text on the NOI prompt node allows the graph model to adjust the readout parameters according to the specific task, which is not feasible in existing works. %The NOI design also appears similar to the pooling mechanism adopted by existing graph learning approaches. However, unlike the pooling function bound to the graph model, At the same time, a fixed pooling mechanism does not have the same functionality.\n\n\n"
                },
                "subsection 2.3": {
                    "name": "Graph prompting paradigm for graph in-context learning",
                    "content": "\\label{sec:incontext}\nOne of the most fascinating properties of LLMs is their ability of in-context learning through prompting, which allows the model to perform various downstream tasks in different learning scenarios without fine-tuning. For example, in a few-shot scenario where the goal is to predict the category of a paper based on its title and abstract, we can provide LLMs with $k$ papers from each category as context and instruct the model to generate predictions based on the provided context. However, research on performing in-context learning for graphs remains relatively uncharted.\n\nWe recognize that the core principle of in-context learning involves manipulating the input data to align it with downstream tasks. Hence, we propose the Graph Prompting Paradigm (GPP) to manipulate the input graph so that the graph model can acquire task-relevant information from the input itself. Such a paradigm endows the graph model with in-context learning ability for both seen and unseen classes, enabling \\textbf{zero-shot learning}. Concretely, a prompt graph, denoted as $\\mathcal{P}=(\\mathcal{V}_p, \\mathcal{E}_p, \\mathcal{R}_p)$ has \\textbf{two types of nodes}. The first node type is the NOI prompt node, which we have introduced in section \\ref{sec:NOI}. %The NOI subgraphs connect to prompt graphs only through NOI prompt nodes. \nSuppose we are querying a target NOI subgraph $\\mathcal{G}_{h}^{q}(\\mathcal{T}^q)=(\\mathcal{V}^h_{q}, \\mathcal{E}^h_{q}, \\mathcal{R}^h_{q})$, and the NOI prompt node is $p_{q}$. GPP adds edges between the NOI prompt node and every node in NOI, as illustrated by the dotted line in Figure \\ref{fig:prompt_design}. We denote them by $\\mathcal{E}_{cross}^q=\\{(t, r_{t2p}, p_q), (p_q, r_{p2t}, t) | t \\in \\mathcal{T}^q\\}$. Note that $r_{t2p}$ and $r_{p2t}$ are the relation types for edges from NOI to the NOI prompt node and the reverse edges, respectively. The second node type in the prompt graph is called the \\textbf{class node}. Each class node holds text information related to a specific class. \n\\begin{tcolorbox}[boxsep=0mm,left=2.5mm,right=2.5mm]\n\\textbf{Text feature of class node:} Prompt node. $<$\\textit{class description}$>$.\n\n\\textbf{Example:} Prompt node. Molecule property. The molecule is effective in: ...\n\n\\textbf{Example:} Prompt node. Literature Category. cs.AI (Artificial Intelligence). Covers all areas of AI except Vision ...\n\\end{tcolorbox}\nDenote the class node for class $i$ by $c_i$. We add edges between every class node and the NOI prompt node as illustrated by the gray lines in Figure \\ref{fig:prompt_design}, denoted as: $\\mathcal{E}_{query}=\\{(p_q, r_{q2c}, c_i), (c_i, r_{c2q}, p_q) | i \\in [N]\\}$, where $N$ is the number of classes. $r_{q2c}$ and $r_{c2q}$ specify the edge relation type from the NOI prompt node to a class node and the reverse. Overall, the prompt graph $\\mathcal{P}=(\\mathcal{V}_p, \\mathcal{E}_p, \\mathcal{R}_p)$ is given by:\n\\begin{equation}\n    \\mathcal{V}_p=\\{p_q\\} \\bigcup \\{c_i|i\\in [N]\\}, \\mathcal{E}_p= \\mathcal{E}_{query} \\bigcup \\mathcal{E}_{cross}^q, \\mathcal{R}_p=\\{r_{t2p},r_{p2t},r_{q2c}, r_{c2q}\\}.\n\\end{equation}\nThen, the \\textit{prompted graph} fed to the subsequent graph model is the combination of the input graph and prompt graph, denoted as $\\mathcal{G}_m=(\\mathcal{V}^h_{q}\\bigcup \\mathcal{V}_p, \\mathcal{E}^h_{q} \\bigcup \\mathcal{E}_p, \\mathcal{R}^h_{q} \\bigcup \\mathcal{R}_p)$. We use a graph learning model to process the prompted graph and use the embeddings of the class nodes to make binary classification. Specifically, let $h_{c_i}$ be the vector representation of class node $c_i$ from the graph learning model. We predict the likelihood of the NOI belonging to class $i$ by \n\\begin{equation}\n    P[\\text{NOI belongs to class }i]=\\sigma(\\text{MLP}(h_{c_i})),\n\\end{equation} \nwhere MLP is a Multi-layer Perceptron whose 1-dimensional output represents the classification score of $h_{c_i}$. Note that because the NOI prompt node and class nodes connect to the NOI and contain task text description, the fixed-length vector $h_{c_i}$ contains information about both the input graph and task, making the prediction task-dependent. While existing graph learning methods need to use different pooling mechanisms for different tasks, this formulation turns different levels of tasks into the same binary classification tasks on class nodes so all tasks can be trained together. For multi-class problems, we compare the prediction scores of different classes to make the decision.\n\\begin{equation}\n    l = \\mathrm{argmax}_{i} \\left(\\text{MLP}(h_{c_i}) | i \\in [N]\\right),\n\\end{equation}\n$l$ is the predicted class of the NOI. Apart from the generality on task levels, because the graph model is oblivious to the class node order and can inductively infer the class based on the class text description on the class node, the users can attach arbitrary unseen class nodes with proper text descriptions to the NOI prompt node. In such cases, the model can predict the unseen class nodes based on its experience with seen class nodes whose text description is semantically close to the unseen ones, facilitating \\textbf{zero-shot learning}. %as long as the model is trained on prompt graphs with a sufficient number of labels, \n\nThe GPP can also prompt few-shot problems, where support NOI subgraphs of unseen classes are provided to help classify the query NOI subgraph better. The support NOI subgraphs are denoted by $\\mathcal{G}_h^{i, k}(\\mathcal{T}_{k}^{i})$ for the $i$-th class and $k$-th support sample and the NOI $\\mathcal{T}_{k}^{i}$ belong to class $i$. As for the query NOI prompt node, we connect each support NOI subgraph to its corresponding support NOI prompt node $p_{i,k}$ by \n\\begin{equation}\n    \\mathcal{E}_{cross}^s=\\bigcup_{i \\in [N], k \\in [K]}\\mathcal{E}_{cross}^{i, k}=\\bigcup_{i \\in [N], k \\in [K]}\\{(t, r_{t2p}, p_{i,k}), (p_{i,k}, r_{p2t}, t) | t \\in \\mathcal{T}^i_k\\}.\n\\end{equation}\nThen, to augment classification, we connect the support NOI prompt node to the class node that its NOI belongs to, as illustrated by the few-shot section in Figure \\ref{fig:prompt_design}. That is, $\\mathcal{E}_{supp}=\\{ (p_{i,k}, r_{s2c}, c_i )| i \\in [N], k \\in [K]\\}$. Because the relation type $r_{s2c}$ differs from $r_{q2c}$ between the query NOI prompt node and class nodes, the model can differentiate information from query and support NOI. The overall components of the few-shot prompt graph $\\mathcal{P}$ are\n\\begin{equation}\n\\begin{split}\n    \\mathcal{V}_p=\\{p_q\\} \\bigcup \\{p_{i,k}|i\\in [N],& k\\in[K]\\}\\bigcup \\{c_i|i\\in [N]\\}, \\\\ \\mathcal{E}_p=\\mathcal{E}_{cross}^q \\bigcup \\mathcal{E}_{query} \\bigcup \\mathcal{E}_{cross}^s \\bigcup &\\mathcal{E}_{supp}, \\quad \\mathcal{R}_p=\\{r_{t2p},r_{p2t},r_{q2c}, r_{c2q}, r_{s2c}\\}.\n\\end{split} \n\\end{equation}\nThe prompted graph can be constructed in a similar way as discussed above. Like in the aforementioned scenarios, the output embeddings of class nodes are used to make binary classifications. OFA utilizes few-shot support examples by connecting the support NOI prompt nodes to the corresponding class nodes, and the model synthesizes both exemplary information and the task semantic information on the class nodes for more accurate predictions. Note that the few-shot class node representations are still consistent with that in zero-shot scenarios, so they can also be trained together.\n\nTo summarize, NOI represents the set of nodes related to the task, and the extracted NOI subgraph includes the neighborhood information of NOI. Then, the NOI prompt node summarizes information in the NOI by a graph learning model because all NOI nodes connect to the NOI prompt node. The NOI prompt node is later connected to a set of class nodes with text descriptions. After graph model processing, class node representations contain class information, task information, and NOI information, which can be used to make predictions independently, just like a prompted input to LLM contains the input, target, and task description. The implementation details and training procedure of the model can be found in Appendix~\\ref{app:impl}.\n% The number of NOI prompt and class nodes in the prompt graph depends on the learning scenario. For example, for few-shot learning we may have multiple NOI prompt nodes associated with different few-shot examples. \n\n\n% To provide a unified description, suppose we are doing $N$-way classification. We define the NOI subgraph that the task performed on as the query NOI subgraph, denoted as $\\mathcal{G}_{h}^{q}(\\mathcal{T}^q)$. We define all other input NOI subgraphs as support NOI subgraphs (only in the $K$-shot learning scenario), denoted as $\\mathcal{G}_h^{i, k}(\\mathcal{T}_{k}^{i})$ for $i$-th class and $k$-th support sample. Let the class node for class $i$ be denoted by $c_i$, and the NOI prompt node associated with the query NOI subgraph be denoted by $p_{q}$, and the NOI prompt node associated with the $k$-th support NOI subgraph of class $c_i$ as $p_{i, k}$. Thus, we have $\\mathcal{V}_{p}=\\{p_q\\} \\bigcup\\{p_{i,k}|i\\in [N], k\\in[K]\\} \\bigcup \\{c_i|i\\in [N]\\} $ Next, we describe the details of the prompt graph connection design. \n\n% First, we describe the connection design within the prompt graph. Within the prompt graph, the connections only exist between class nodes and NOI prompt nodes. Specifically, for query NOI prompt node $p_q$, it will connect to all class nodes. Instead, for support NOI prompt node $p_{i,k}$, it will only connect to the class node $c_i$. Here, we only have edges from the NOI prompt nodes to class nodes, but no reverse edges. Let $r_{q2c}$ denotes the relation type of edges from query NOI prompt nodes to class nodes and $r_{s2c}$ denotes the relation type of edges from support NOI prompt nodes to class nodes. We have the $\\mathcal{E}_p=\\{(p_q, r_{q2c}, c_i) | i \\in [N]\\} \\bigcup\\{ (p_{i,k}, r_{s2c}, c_i )| i \\in [N], k \\in [K]\\}$. Meanwhile, we have $\\mathcal{R}_p=\\{r_{q2c}, r_{s2c}\\}$ and all elements in the prompt graph $\\mathcal{G}_{p}$ have been formally defined. \n\n% Next, we describe the connection design between NOI subgraphs and the prompt graph in order to modify the original input graph. The connections only exist between NOI prompt nodes and input NOI subgraphs. Specifically, for both query and support NOI subgraphs, all nodes in the NOI will connect to their corresponding NOI prompt node. Denotes the relation type of edges from nodes in NOI to the NOI prompt node as $r_{t2p}$ and denotes $r_{p2t}$ as the relation type for the reverse edges. We have $\\mathcal{E}_{cross}^q=\\{(t, r_{t2p}, p_q), (p_q, r_{p2t}, t) | t \\in \\mathcal{T}^q\\}$ for query NOI subgraph and $\\mathcal{E}_{cross}^{i, k}=\\{(t, r_{t2p}, p_{i,k}), (p_{i,k}, r_{p2t}, t) | t \\in \\mathcal{T}^i_k\\}$ for $k$-th support NOI subgraph of class $i$. Note that edges with the relation type of $r_{p2t}$ can be removed for some graph datasets to achieve better performance (detailed description in Section~\\ref{sec:experiments}). Let $\\mathcal{G}_m=\\{\\mathcal{V}_m, \\mathcal{E}_m, \\mathcal{R}_m\\}$ denote the final constructed graph, it will include all NOI subgraphs, the prompt graph, and all cross connections $\\mathcal{E}_{cross}$. In Figure~\\ref{fig:prompt_design}, we give a detailed illustration of the modified graph in different scenarios. \n\n% Finally, we describe the text features of nodes and edges introduced in GPP. To align with the principle of the proposed TAG, all features are text sentences that describe task-related information. Specifically, we have:\n% \\textbf{maybe separate and move to where they first appear, and add examples.}\n% \\input{tex/3_implementation}\n"
                }
            },
            "section 3": {
                "name": "Related works",
                "content": "\nThe success of the LLM and prompt learning has enlightened many recent works that try to incorporate similar ideas to graphs. The first line of research tries to design prompt learning in the graph domain. Both VNT~\\citep{VNT} and GraphPrompt~\\citep{liu2023graphprompt, graphpromptplus} introduce trainable prompt vectors to extract related information for different downstream tasks. HGPROMPT~\\citep{hgprompt} further extends GraphPrompt to heterogeneous graphs. Prodigy~\\citep{prodigy} converts classification tasks to link prediction problems on prompt graphs, facilitating in-context graph learning. All-in-one~\\citep{allinone} proposes to learn prompt graphs from downstream tasks. Our work also uses prompting to unify all classification tasks. More importantly, unlike existing work that still needs to train separate GNNs in different domains, we leverage language models to unify different tasks further and use one GNN to solve all tasks. The second line of research combines language models with GNNs. Some works directly apply LLMs to solve graph problems by describing the graph using natural language and feeding text description to LLMs, including InstructGLM~\\citep{InstructGLM}, GraphText~\\citep{GraphText}, NLGraph~\\citep{graphnl} and GPT4Graph~\\citep{gpt4graph}. However, these methods also describe graph connections by texts, losing important structural features, while our method explicitly utilizes the information through GNNs. Very recently, GraphGPT~\\citep{GraphGPT} introduced a new method to encode the graph structure information with trainable vectors and an alignment module. More related works can be found in Appendix~\\ref{app:related_work}.\n"
            },
            "section 4": {
                "name": "Experiments",
                "content": "\n\\label{sec:experiments}\n\nThe experiment section assesses OFA's potential to serve as a graph foundation model by answering the following questions: \\textbf{Q1}: How does replacing the raw node/edge features with text features from LLM affect GNN performance? \\textbf{Q2}: Using text as features for all graphs, is a single OFA GNN versatile to tasks in all domains? \\textbf{Q3}: What is the effect of different LLMs? \\textbf{Q4}: Is the proposed graph prompting paradigm effective in in-context learning? By answering these questions, we validate the approach of using TAGs and OFA's ability to solve various tasks, demonstrating the strong potential of using OFA as a unified graph foundation model. More experiment and training details can be found in Appendix~\\ref{app:exp_setup}.\n\n\n",
                "subsection 4.1": {
                    "name": "Cross-domain supervised learning",
                    "content": "\nTo answer \\textbf{Q1-Q3}, we conduct experiments on the supervised learning scenario using all collected OFA datasets with different LLMs. Specifically, we select four popular LLMs for evaluation, including sentence transformer ~\\citep{reimers-2019-sentence-bert}, e5-large-v2~\\citep{e5}, Llama2-7b, and Llama2-13b~\\citep{touvron2023llama}. Then, we evaluate OFA in two different settings. The first setting trains and tests the model on each dataset independently with text embedding generated by the sentence transformer, denoted as OFA-ind-st. The second setting trains a single model using all datasets jointly. We denote the joint model utilized different LLMs as OFA-st, OFA-e5, OFA-llama2-7b, and OFA-llama2-13b respectively. For baseline methods, we use GCN~\\citep{kipf2017semisupervised}, GAT~\\citep{veli\u010dkovi\u01072018graph}, and GIN~\\citep{xu2018powerful} for fair comparison. The results can be found in Table~\\ref{tab:cross_domain1} and Table~\\ref{tab:cross_domain2}. \n\nFrom the results, we have the following observations: (1) Both the independent and joint training achieve comparable or better results on all datasets compared to baseline methods. (2) OFA successfully enabled a single graph model to be effective on all graph datasets across different domains as the joint version with all different LLMs performs well on all datasets. Further, we can see that the joint version OFA-st achieves better results on most of the datasets compared to OFA-ind-st. This may indicate that by leveraging the text feature and GPP, the knowledge learned from one domain/dataset can be useful for the learning of other domains/datasets. (3) The comparison of different LLMs is interesting, generally speaking, a larger LLM can achieve better and more stable performance in joint training. We also observe a faster convergence for larger LLM (Llama2-13b). However, the margin is less significant. Meanwhile, different LLMs seem specialized for different domains. For example, Llama2 achieves better performance in citation networks but e5-large-v2 achieves great results in molecular datasets. To further investigate the mechanism behind the OFA, we take the output embedding of NOI prompt nodes from OFA-joint-st for each dataset and project it to two-dimensional space. As shown in Figure~\\ref{fig:visualization}, node embeddings from different domains are separated. This demonstrates that the OFA model can represent data from different domains in different sub-spaces to process it. In Appendix~\\ref{app:exp}, we conduct additional ablation studies to verify the effectiveness of the proposed GPP. \n\n"
                },
                "subsection 4.2": {
                    "name": "few-shot and zero-shot learning",
                    "content": "\n\n\nTo answer \\textbf{Q4}, we design few-shot and zero-shot scenarios for all levels of tasks. We consider both transductive and transfer situations. In the transductive setting, the task is to classify unseen classes on the same training graph. In the transfer setting, both the test graph and test classes are unseen. For simplicity, all experiments are conducted using OFA datasets generated from the sentence transformer. We train one few-shot model on various tasks varying $N$-way and $k$-shot, where $N \\geq 2$ and $k \\geq 0$. We include ogbn-arxiv, FB15K237, and Chemble as training sets, then evaluate two transductive settings: ogbn-arxiv and FB15K237, and four transfer settings: Cora, WN18RR, HIV, and PCBA. We present node/link/graph level results in Table \\ref{tab:fs_nc} / \\ref{tab:fs_link} / \\ref{tab:fs_graph}, respectively. The model is denoted by OFA-joint-lr (\\textbf{l}ow-\\textbf{r}esource).\n\n\nFor node-level tasks, we compare with meta-learning models~\\citep{GPN, TENT, GLITTER} and graph contrastive learning model~\\citep{TLP}. For graph-level tasks, LLM-based models Galactica-1.3B~\\citep{galactica} and GIMLET~\\citep{gimlet} are considered. Prodigy~\\cite{prodigy} follows a different setting, where the model is trained on the MAG240M or Wiki datasets~\\citep{ogb} and transferred to the corresponding tasks. OFA exhibits comparable or better performance than most existing works on few-shot tasks. Especially in the transfer setting of node tasks, where all baselines are trained and evaluated on the Cora dataset, OFA still shows comparable performance without any prior knowledge about the test dataset, illustrating its capability to generalize. Furthermore, our proposed GPP endows OFA with the ability to address zero-shot scenarios\u2014a task generally impossible for most existing baseline models. OFA utilizes one single model to address all low-resource tasks across domains, demonstrating the ability of in-context learning.\n\n\n%\\input{tex/limitations}% \\input{tex/6_limitations}\n"
                }
            },
            "section 5": {
                "name": "Conclusions, limitations and future research",
                "content": "\\label{sec:conclusion}\nIn this work, we propose OFA, the first solution towards building the foundation GNN model for learning on graphs. By showing great results on supervised, few-shot, and zero-shot scenarios, OFA reveals great potential as the future foundation model on the graph. Currently, OFA falls short of learning regression tasks and the cross-domain datasets are limited, we leave this to future work. More discussion can be found in Appendix~\\ref{app:limit}.\\newpage\n"
            },
            "section 6": {
                "name": "Acknowledgement",
                "content": "\nHao Liu, Jiarui Feng, Lecheng Kong, and Yixin Chen are supported by NSF grant CBE-2225809. Muhan Zhang is supported by the National Key R\\&D Program of China (2022ZD0160303) and National Natural Science Foundation of China (62276003).\n\\bibliographystyle{iclr2024_conference}\n\\bibliography{references}\n\n\n\\newpage\n\\appendix\n"
            },
            "section 7": {
                "name": "Related Works (Extended)",
                "content": "\n\\label{app:related_work}\n\\textbf{Large Language Model and Prompt Learning.}\nSince the ground-breaking advances in Large Language Models, including GPT~\\citep{brown2020Language, wei2022finetuned} and LLaMa~\\citep{touvron2023llama}, tremendous attention has been drawn to developing and using them. One particular approach is prompt learning. By prompting the LLMs according to a carefully designed paradigm, users can uncover LLM's surprising capability in many difficult tasks. Chain-of-thoughts, by providing step-by-step reasoning examples, greatly improve LLMs' reasoning power. Considerable efforts were also made to use prior semantic knowledge learned by LLMs to perform zero-shot and few-shot tasks~\\citep{fewshorprompt, promptreview, palm}. The key advantage of prompting LLMs is that no further fine-tuning is required for the model to adapt to a new class of tasks. Innovated by this practical advantage, several works adapted the prompting idea to the GNN domain. VNT~\\citep{VNT} offers a new method for few-shot node classification (FSNC) by integrating trainable virtual node embeddings into the original graph, which serves as a form of prompting. For each new FSNC task, the pre-trained graph transformer model can be frozen and only the embedding of virtual nodes needs to be trained. GraphPrompt~\\citep{liu2023graphprompt,graphpromptplus} also introduces trainable prompt vectors to extract related information for the downstream tasks. Meanwhile, it further utilizes the subgraph and link prediction to design a novel unsupervised pertaining method, which unifies the pertaining and downstream tasks. MultiGPrompt~\\cite{multigprompt} proposes a multi-task pre-training and prompting framework, effectively harnessing diverse pretext task knowledge for enhanced graph-based analysis. Prodigy~\\cite{prodigy} converts classification tasks to link prediction problems on prompt graphs, facilitating in-context graph learning. All-in-one~\\cite{allinone} proposes to learn prompt graphs from data. Our work also uses prompting to unify all classification tasks. However, our works differ in two parts. First, unlike existing work that still needs to train separate GNNs in different domains, we leverage language models to unify different tasks further and use one GNN to solve all tasks. Second, most of the existing works cannot perform zero-shot learning as their prompt module needs to be re-trained for different downstream tasks. instead, OFA directly describes all tasks in a unified way, which allows the model to perform zero-shot learning without further training. \n\n\\textbf{Graph Neural Networks.}\nRecently, extensive efforts have been spent on using GNNs to learn relational data. Earlier GNN variants, including GCN~\\citep{kipf2017semisupervised}, GAT~\\citep{veli\u010dkovi\u01072018graph}, and GraphSage~\\citep{hamilton2017inductive}, achieved great success in solving graph learning problems. Later works unify the GNNs into the Message Passing Neural Network~\\citep{gilmer2017neural} and show the expressivity upper-bound of such framework~\\citep{xu2018powerful, morris2019weisfeiler}, which demonstrates the inherent difference between learning on graphs and learning on other data formats such as images and languages where expressivity is not an issue. Following such observation, subsequent works, such as SEAL~\\citep{zhang2018link} and ID-GNN~\\citep{you2021identity}, propose subgraph GNNs that apply GNNs to subgraphs and aggregate subgraph representations to enhance the expressivity. Moreover, unlike MPNN, which fits the full graph into the GPU memory, subgraph GNNs process the data by subgraphs, solving the scalability problem of MPNN. Innovated by subgraph GNNs, our work and concurrent works~\\citep{prodigy, allinone} also add prompts to subgraphs of interest, which allows our models to perform cross-level tasks.\n\nThe applications of GNN have also become prevalent. Much research focuses on the molecular property prediction domain and has achieved promising performance~\\citep{zhang2023complete, feng2023extending, maggnn, feng2022kp}. GNNs have also become one of the primary tools in citation network analysis and mining~\\citep{kipf2017semisupervised, chien2022node}. Many efforts have also been made to adapt GNNs to the Knowledge Graph mining domain and achieved great success due to GNN's efficiency and inductive learning capabilities~\\citep{zhu2021neural, kong2022geodesic}. While the promising results of these applications demonstrate the potential of GNNs, a critical problem is that they are tailored to the specified application. On the contrary, our work, by three carefully designed components, unifies all tasks into one GNN framework that allows large-scale training and inference across different domains. The proposed framework can be a foundation model in the graph learning domain.\n\n\\textbf{Language Models and Graph Neural Networks.}\nThe surge of foundational Large Language Models inspires several directions combining language models with GNNs. One of them directly applies LLMs to solve graph problems. They propose graph descriptive languages to represent the structural information as prompt texts and feed them to LLMs, like InstructGLM~\\citep{InstructGLM}, GraphText~\\citep{GraphText}, NLGraph~\\citep{graphnl}, and GPT4Graph~\\citep{gpt4graph}. Some works for molecular graph classification propose to only use SMILE molecule sequences to describe the molecular graph in input to the LLM, including LMMOL~\\citep{lmmol} and GIMLET~\\citep{gimlet}. The exceptional power of LLMs enables these methods to perform difficult tasks such as zero/few-shot learning. However, such graph representation is implicit, and the LLM might not correctly capture the structural information but only summarize texts corresponding to the nodes that appear in the prompt. Such approaches will fall short in applications where graph structures are important. \\input{tables/related_method}Very recently, GraphGPT~\\citep{GraphGPT} introduced a new method to encode the graph structure information with trainable vectors and an alignment module. It concatenates the trainable vectors along with textual input to LLms to improve the structure reasoning ability of LLMs. Another direction uses LLMs to encode the corresponding texts of nodes, such as paper abstracts, and apply GNN to the graph with encoded text embeddings~\\citep{expasfeat,explorenlgnn}. The high-quality text representation from LLMs allows these models to achieve better performance. Our approach adopts the same idea of using text embedding to represent graph entities (nodes and edges). However, we are the first work that drives the language model to full power by systematically unifying graph entities in different domains with the same language protocol and representing them in the same embedding space. This consequently grants cross-domain functionality that other GNN frameworks lack. Table~\\ref{tab:comparison} summarizes the characteristics of different models. We can see that OFA is the most versatile model among existing works.\n\n"
            },
            "section 8": {
                "name": "More on OFA Dataset",
                "content": "\n",
                "subsection 8.1": {
                    "name": "Dataset Collection and Construction",
                    "content": "\n\\label{app:dataset}\nIn this section, we discuss the detailed processing procedure for each dataset collected in OFA.\n\n",
                    "subsubsection 8.1.1": {
                        "name": "Cora",
                        "content": "\nCora is a citation network that contains papers and their citation relationship in the computer science domain. The raw text data of the Cora dataset was collected from the GitHub repository provided in~\\citet{explorenlgnn}. Each node in Cora represents a research paper from the computer science domain. The raw text feature of a node is the title and abstract of the respective paper. Every edge in the Cora dataset indicates the citation relationship between papers. Each node's label corresponds to the category of the paper. Tasks that can be executed on Cora include predicting the paper's category (node-level) or identifying missing citation links within the graph (link-level). Using the proposed processing protocol, we reformat all text features in Cora. Particularly, for each node category, we further use gpt-3.5-turbo(ChatGPT) to generate a description as additional information. In table~\\ref{tab:cora_example}, we show a processed example on Cora dataset. \n\n"
                    },
                    "subsubsection 8.1.2": {
                        "name": "PubMed",
                        "content": "\nCora is a citation network that contains papers and their citation relationship in the biomedical domain. The raw text data of the PubMed dataset was collected from the GitHub repository provided in~\\citet{explorenlgnn}. All nodes and edges are similar to Cora dataset and we use the exact same processing procedure as Cora dataset. Because its original literature categories are diabetes, experimental/diabetes, type 1/diabetes, and type 2, which are overly simple and very difficult for our BERT-based LLM to distinguish, we asked ChatGPT to generate a detailed description of each category.\n\n"
                    },
                    "subsubsection 8.1.3": {
                        "name": "ogbn-arxiv",
                        "content": "\nCora is a citation network that contains papers and their citation relationship collected from Arxiv platform. The raw text data of the ogbn-arxiv was collected using the same protocol as the GitHub repository provided in Prodigy~\\citep{prodigy}. For ogbn-arxiv, we only evaluate the model on the node classification task. All nodes and edges are similar to Cora dataset and we use the exact same processing procedure as Cora dataset except that the description for each category is directly obtained from the Prodigy.\n\n% \\subsection{MAG240M}\n% MAG240M is a heterogeneous academic graph extracted from Microsoft Academic Graph. The raw text data of the MAG240M was collected from OGB group\\footnote{https://groups.google.com/g/open-graph-benchmark/c/R0SKtj9qQyE?pli=1}. We only include nodes of paper and edges of citation in the dataset. The processing procedure is the same as Cora dataset except that the description for each category is generated from LLAMA2-7b-chat model. For MAG240M, we only evaluate the model on the node classification task.\n\n"
                    },
                    "subsubsection 8.1.4": {
                        "name": "Wiki-CS",
                        "content": "\nWiki-CS is an Internet link network with each node representing a Wikipedia page and each edge representing the reference link. The raw text of the Wiki-CS dataset was collected from the official website~\\citep{mernyei2020wiki}. The raw text feature of a node is the name and content of an entry in Wikipedia. Each node's label corresponds to the category of the entry. We evaluate Wiki-CS on node classification tasks. In table~\\ref{tab:wikics_example}, we show a processed example on the Wiki-CS dataset using the processing protocol proposed in OFA.\n\n"
                    },
                    "subsubsection 8.1.5": {
                        "name": "FB15K237",
                        "content": "\nFB15K237 is a knowledge graph that contains knowledge base relation triples and textual mentions of Freebase entity pairs. The raw text data of nodes in FB15K237 was collected from GitHub repository\\footnote{https://github.com/villmow/datasets\\_knowledge\\_embedding/tree/master\\label{ftnt:kg}}. The raw text feature of a node is the name of the relation entity and its description. The raw text feature of an edge is the type of relation between two entities. We provide an example of processed data example in Table~\\ref{tab:FB15K237_example}.\n\n"
                    },
                    "subsubsection 8.1.6": {
                        "name": "WN18RR",
                        "content": "\nWN18RR is a knowledge graph, which is a subset of WordNet that consists of 18 relations and 40943 entities. The raw text data of nodes in WN18RR was collected from GitHub repository\\hyperref[ftnt:kg]{\\footnotemark[\\value{footnote}]}. The raw text feature of nodes and edges are the same as FB15K237 and we follow the same process protocol to process the WN18RR dataset.\n\n"
                    },
                    "subsubsection 8.1.7": {
                        "name": "Molecular Datasets",
                        "content": "\nWe adopted three molecular datasets: (1) ChEMBL dataset~\\cite{chembl} is a widely used molecule property prediction dataset. It contains 1,310 prediction target labels of molecules from biological assays for drug discovery. (2) MOLPCBA dataset~\\cite{molnet} is a subset of the BioChem BioAssay dataset consisting of 128 labels on the biological activities of small molecules. (3) MOLHIV dataset~\\cite{molnet} contains over 40,000 compounds labeled for their ability to inhibit HIV replication. The raw data of these datasets are represented in SMILE string format. We use RDKit to construct molecule objects and graph structures from the SMILE string and use natural language to describe the atoms (nodes) and bonds (edges) as shown in Table \\ref{tab:molecule}. For the class nodes text, we use the assay/molecule properties description in~\\cite{gimlet}.\n\n"
                    }
                },
                "subsection 8.2": {
                    "name": "Visualization of OFA dataset",
                    "content": "\nIn this section, we provide a visualization of all generated OFA datasets using the sentence transformer. Concretely, For each generated dataset, we randomly select 400 node embeddings and project it to 2 dimensions using TSNE. Note for molecular datasets, we include all node embeddings. The result is shown in Figure~\\ref{fig:visualization_dataset}. \n\n\nWe can see that the generated embeddings from different domains are successfully separated by the LLM as the embedding from molecular datasets, knowledge graphs, wiki pages, and citation networks are well separated in the visualization. Moreover, the LLM can even separate the citation network from different research domains. embeddings from Arxiv and Cora, which mainly contain papers from computer science are close to each other and far from the embeddings of Pubmed, which focus on biology. This result reveals one of the key rationales behind the success of the OFA. That is, by encoding the datasets from different domains into different sub-spaces, OFA allows one GNN to learn the information from different domains separately without impacting each other. \n\n\n\n"
                }
            },
            "section 9": {
                "name": "Implementation of OFA",
                "content": "\\label{app:impl}\nThe last section described how OFA combines LLMs, text-attributed graphs, and the graph-prompting paradigm to facilitate cross-domain and in-context learning. In this section, we illustrate the training and evaluation procedure of OFA.\n\nTraining an OFA pipeline for different tasks is straightforward with the unified task representation introduced in Section~\\ref{sec:OFA} because all the inputs are standardized to the prompted text attributed graph $\\mathcal{G}_m$ regardless of the task type. The task information is carried out in the prompt nodes and edges. Recall that OFA first embeds all texts in graphs to vector representations using LLM:\n\\begin{equation}\n    x_{ij}=LLM(s_{e_{ij}}), \\forall e_{ij}\\in \\mathcal{E}_m,\\quad x_i=LLM(s_{v_i}), \\forall v_i \\in \\mathcal{V}_m.\n\\end{equation}\nThen, a GNN processes $\\mathcal{G}_m$ along with the embedded texts through multiple message-passing layers and gets the final node embedding for each node in $\\mathcal{G}_m$. Formally,\n\\begin{equation}\nh^{l+1}_{v_i} = \\bm{W}_{\\text{self}}h^{l}_{v_i} + \\sum_{r\\in \\mathcal{R}_m} \\sum_{v_j \\in \\mathcal{N}_{1}^r(v_i)} \\frac{1}{|\\mathcal{N}_{1}^r(v_i)|}\\bm{W}_r (\\text{ReLU}(h^l_{v_j}+ x_{ij})),\n\\end{equation}\nwhere $h_{v_i}^0=x_i$, $\\bm{W}_{\\text{self}}$ and $\\bm{W}_r$ are trainable transformation matrix for self-loop and relations, $\\mathcal{N}_{1}^r(v_i)$ is the direct neighbors that connects to $v_i$ with relation type $r$. Our GNN model is a natural extension of R-GCN~\\citep{Schlichtkrull18modeling}, incorporating edge features. Such an implementation helps differentiate nodes in the input graph and the prompt graph. It also effectively extracts useful information from the input graph and encodes it to the class node in the prompt graph for prediction. Usually, the last layer output can be used for prediction. However, due to the different natures of tasks and the well-known over-smoothing effect, a GNN with a fixed number of layers will not perform well on all tasks. Hence, we design a simple attention layer to summarize all layer outputs from $h^{1}$ to $h^{L}$. Eventually, the node representation is\n\\begin{equation}\n    h_{v_i} = \\bm{H}\\cdot Softmax((\\bm{W}_k\\bm{H})' \\cdot \\bm{W}_qx_i)', \\quad \\bm{H}=[h_{v_i}^1\\quad ... \\quad h_{v_i}^l \\quad ... \\quad h_{v_i}^L],\n\\end{equation}\nwhere $\\bm{W}_k$ and $\\bm{W}_q$ are key and query trainable weights. Note that because the text features $x_i$ also include the domain information, by querying on the feature, a properly trained attention layer can choose the most important layers to aggregate outputs based on the domain. Lastly, we gather the output node embedding for each class node $\\{h_{c_i} | \\forall i\\in [N]\\}$ and use an MLP prediction head to perform binary classification on every class node. Even for multi-class problems, each class node connects to the NOI prompt node and hence can integrate the information of other connected class nodes through message-passing. While each class node is processed separately by the MLP, such binary classification is still conditioned on other candidate classes and not individualized. Moreover, since the format of $\\mathcal{G}_m$ is consistent in different learning scenarios (supervised/few-shot/zero-shot) and task types (node/link/graph-level), such a procedure can work without any modification across these situations. Formally, the likelihood of class $i$ is:\n\\begin{equation}\np_i = \\sigma(\\text{MLP}(h_{c_i})),\n\\end{equation}\nwhere $\\sigma$ is the Sigmoid function. If it's a multi-class problem, OFA collects all classes' probabilities as\n\\begin{equation}\n    l_p = \\mathrm{argmax} \\left((p_i | i \\in [N])\\right),\n\\end{equation}\nand $l_p$ is the final prediction from the model. The binary training loss for a single $\\mathcal{G}_m$ can be expressed as:\n\\begin{equation}\n\\mathcal{L}_{\\mathcal{G}_m} = -\\frac{1}{N} \\sum^{N}_{i=1}y_i \\cdot log(p_i) + (1-y_i) \\cdot (1- log(p_i)),\n\\end{equation}\nwhere $N$ is the number of candidate classes in $\\mathcal{G}_m$.\n"
            },
            "section 10": {
                "name": "Experimental settings",
                "content": "\n\\label{app:exp_setup}\nIn this section, we provide detailed settings for all experiments shown in the paper. The code of OFA can be found at the Github link \\url{https://github.com/LechengKong/OneForAll}.\n\n",
                "subsection 10.1": {
                    "name": "Supervised learning experiments",
                    "content": "\nWe set the number of layers for GNN of independent training (OFA-ind-st) and joint training to be 6 and 7 respectively, as the joint model might require a larger embedding space. The dropout rate is set to 0.15. We set the hidden size of the GNN as 768 and project the initial embedding generated by different LLMs to 768 before the GNN.\nWe train OFA-ind-st for 100 epochs and 50 for OFA-st and OFA-e5. For OFA-llama2-7b and OFA-llama2-13b, we only train 40 epochs due to the limitation of computing resources. For OFA-ind-st, we evaluate the model after each epoch and take the model with the best validation performance for testing. For all versions of joint training, since there is no easy way to define the best validation performance, we directly use the final model for testing. Because datasets vary in sample size, smaller sets might be neglected during training. Hence, we sample from each dataset by a multiple of the dataset size to form the training set and control the weight of each dataset. Data are resampled after every epoch. The multipliers are Cora-link: 1.5, Cora-node 2, Pubmed-link: 0.5, Pubmed-node: 2.5, ogbn-arxiv: 0.7, WN18RR: 0.6, FB15K237: 0.4, WikiCS: 2, ChEMBL: 1, PCBA: 2, HIV: 4. For independent and joint training, we repeat experiments 10 and 3 times, respectively, and report the mean results and standard deviation. The final training set contains all training sets of the collected datasets, and the test sets are the datasets' original test sets.\n\nFor Cora-node, Pubmed-node, and ogbn-arxiv datasets, a different split is used. Specifically, for Cora-node and Pubmed-node, the split is obtained from~\\cite{explorenlgnn}, where they split data into 10 folds and we use the first fold as our split. For ogbn-arxiv, in each experiment, we will randomly split data with a train/val/test ratio of 0.8/0.1/0.1. For Cora-node, Pubmed-node, ogbn-arxiv, WN18RR, and FB15K237, we rerun the baseline models 10 times and report the average performance. For other datasets, we report results from existing works.\n\n"
                },
                "subsection 10.2": {
                    "name": "few-shot and zero-shot learning experiments",
                    "content": "\nFor OFA joint training low resource (OFA-joint-lr) experiments, we set the number of layers to be 5, the learning rate as 0.0001, and the number of epochs to be 30. We split the label of ogbn-arxiv dataset with ratio $[20,10,10]$ for train/validation/test, and use the $[142, 47, 48]$ as the split ratio for FB15K237 dataset. During training, we use the training set from Arxiv (node-level), the training set from FB15K237 (link-level), and the whole Chemble dataset (graph-level) to train a single model for all downstream tasks. We construct diverse $N$-way $k$-shot tasks from the training sets. For ogbn-arxiv dataset, $N$ varies from 3 to 5, $k$ varies from 0 to 5; for FB15K237 dataset, $N$ varies from 3 to 10, $k$ varies from 0 to 5; for ChEMBL dataset, all tasks are 2-way, and $k$ varies from 0 to 10. \n\nIn few-shot graph construction, the text feature of class nodes differs significantly from that in supervised and zero-shot scenarios. Specifically, we omit category information and utilize a uniform text feature across all class nodes. This uniformity shifts the focus from learning class-specific information to enhancing the model's ability to compare the query node with support nodes. Such comparisons are crucial for determining matches, which proves particularly effective in few-shot scenarios where the model must classify unseen classes.\n\nDuring the test, we involved six datasets: for the transductive setting, we evaluate on the test set from ogbn-arxiv dataset and test set from FB15K237 dataset; for the transfer setting, we evaluate on Cora (node-level), WN18RR (link-level), MOLPCBA and MOLHIV (graph-level). Note that for the transductive setting, we keep the same train/validation/test labels for OFA and all the baselines to ensure a fair comparison. For baseline results on the Cora dataset, we report the performance provided by COLA~\\citep{cola}, which is the average performance of 20 random label splits. For baseline results of Prodigy, we follow the provided code to pre-train separate models for different shot numbers, that is, we pre-train 5-shot/3-shot/1-shot models for node-level tasks and pre-train 5-shot/3-shot/1-shot models for link-level tasks, then evaluate different shot settings using the corresponding pre-trained model. For the baselines of graph-level tasks, we report the results from GIMLET~\\citep{gimlet}.\n"
                }
            },
            "section 11": {
                "name": "More Experimental Results",
                "content": "\n\\label{app:exp}\nThis section includes more experimental results that provide a detailed evaluation of OFA's in-context learning ability and justify the OFA design by ablation study.\n\n",
                "subsection 11.1": {
                    "name": "Ablation study",
                    "content": "\nWhile using LLM to unify graph and task representation is a unique design in OFA, there are alternatives to our prompting paradigm GPP to make classifications. One alternative is to discard graph prompting completely but keep track of the NOI for each NOI subgraph. After being processed by the graph model, the embeddings of the NOI are summarized by average pooling to form the final NOI representation, the LLM encoded tasks representation is concatenated to the NOI for binary classification. We denote this as \\textbf{\"-Class node\"}. We perform a case study comparing the two methods on hiv, ogbn-arxiv, Cora-node, and Cora-link datasets when these datasets are trained jointly using the same model and separately. The results are presented in Table~\\ref{tab:ablation}.\n\nWe observe that, if the datasets are trained separately, all methods achieve similar performance, since in end-to-end training for one dataset the prompting design is essentially a pooling mechanism. However, it is striking that the \\textbf{\"-Class node\"} approach's performance significantly drops when the datasets are trained together, while the OFA prompting approach maintains the original performance. Intuitively, when datasets from different domains are trained together, the model needs to learn which domain a particular data is from and which tasks are being performed to make appropriate predictions. However, without the NOI prompt node that carries task text descriptions, the \\textbf{\"-Class node\"} approaches can confound tasks in different domains.\n\n"
                },
                "subsection 11.2": {
                    "name": "Few-shot and Zero-shot Results",
                    "content": "\n\nTo explore the in-context learning ability of OFA, we train a single model for all few-shot and zero-shot low-resource tasks denoted as OFA-joint-lr. Here, we provide more comprehensive experiment results spanning more ways and shots. We also implement three experiments that train separately on node-, link-, and graph-level tasks denoted as OFA-ind-lr. For node-level tasks, we train the model using the ogbn-arxiv dataset. For link-level tasks, we train the model on the FB15K237 dataset. For graph-level tasks, we train the model on Chemble.  \n\nResults for the ogbn-arxiv and Cora can be found in Table~\\ref{tab:fs_arxiv_ablation} and Table~\\ref{tab:fs_cora_ablation}, respectively. We can see that for the Cora dataset, OFA-joint-lr achieve better performance than OFA-ind-lr in all setting. This may indicate that the knowledge learned from other task levels like link- or graph-level can help the generalization of the model on Cora. For ogbn-arxiv dataset, the results for OFA-joint-lr and OFA-ind-lr are similar.\n\nThe results for FB15K237 and WN18RR datasets can be found in Table~\\ref{tab:fs_fb_ablation} and Table~\\ref{tab:fs_wn_ablation}, respectively. For link-level task, the OFA-ind-lr have better results than OFA-joint-lr. This may indicate that the knowledge learned from graph or node level is not helpful for link-level tasks. \n\nFinally, the results for HIV and PCBA datasets can be found in Table~\\ref{tab:fs_hiv_ablation} and Table~\\ref{tab:fs_pcba_ablation}, respectively. We can notice that joint training can benefit the prediction of HIV in most cases and the zero-shot scenario of PCBA, but the performance of few-shot tasks of PCBA dropped significantly. One reason might be the different number of tasks used for training: the graph-related tasks involved in individual training are much more than those in joint training.\n\n"
                }
            },
            "section 12": {
                "name": "Limitations and future works",
                "content": "\\label{app:limit}\nWhile OFA aims to provide a solution for the general graph foundation model, it is not yet able to perform regression tasks, because regression targets can be unbounded in values. Hence, if the range of all target values in a zero-shot regression task falls out of the range that OFA is trained on, it is very difficult for OFA to predict the correct target value in that range, which is why we focus on general classification in this work. A potential approach is to specify a target range in the NOI prompt node task description, and let the model predict regression value based on the specified range. However, reasoning about math concepts is difficult even for most advanced LLMs, and certainly unreliable for our current adopted LLMs. Hence, we leave such an approach to future work.\n\nWhile OFA is already trained in several different domains and the performance is on par or even outperforms some GNN and LLM approaches, the training data for the graph foundation model is still scarce compared to that of LLMs. Also, LLMs explore training techniques beyond supervised training, including auto-regressive training, and contrastive learning, which largely improve LLM's ability to model data and generalize to unseen tasks. Other unsupervised training techniques are possible, like the one proposed in GraphPrompt~\\citep{liu2023graphprompt}. We believe these training techniques can further enhance the performance of OFA and regard this as an important direction to explore in the future.\n"
            }
        },
        "figures": {
            "fig:overview": "\\begin{figure}[h]\n    \\centering\n    \\includegraphics[width=\\linewidth, trim={0cm, 4.5cm, 0cm, 0cm}, clip]{figures/figure1v3.pdf}\n    \\caption{The pipeline of OFA. An input to the model contains a text-attributed graph and a task description. Cross-domain texts in graphs and task descriptions can be co-embedded in the same space by an LLM. OFA's graph prompting paradigm converts the input with embedded features to prompted graphs with a unified task representation, which allows adaptive downstream prediction.}\n\n    \\label{fig:overview}\n    \\vspace{-15pt}\n\\end{figure}",
            "fig:prompt_design": "\\begin{figure}\n    \\includegraphics[width=0.98\\textwidth]{figures/figure2v3.pdf}\n    \\caption{In-context learning design in OFA}\n    \\label{fig:prompt_design}\n        \\vspace{-10pt}\n\\end{figure}",
            "app:dataset_visual": "\\begin{wrapfigure}{r}{0.38\\textwidth}\n\\vspace{-10pt}\n\\label{app:dataset_visual}\n    \\centering\n    \\includegraphics[width=0.37\\textwidth, trim={1.2cm, 1.7cm, 1.0cm, 0cm}, clip]{figures/visualization_dataset.pdf}\n    \\caption{Embedded node features from all OFA datasets (sentence transformer).}\n    \\label{fig:visualization_dataset}\n    \\vspace{-10pt}\n\\end{wrapfigure}",
            "fig:visualization_dataset": "\\begin{wrapfigure}{r}{0.38\\textwidth}\n\\vspace{-10pt}\n\\label{app:dataset_visual}\n    \\centering\n    \\includegraphics[width=0.37\\textwidth, trim={1.2cm, 1.7cm, 1.0cm, 0cm}, clip]{figures/visualization_dataset.pdf}\n    \\caption{Embedded node features from all OFA datasets (sentence transformer).}\n    \\label{fig:visualization_dataset}\n    \\vspace{-10pt}\n\\end{wrapfigure}"
        },
        "equations": {
            "eq:1": "\\begin{equation}\n    \\mathcal{G}_h(\\mathcal{T})=\\bigcup_{v\\in \\mathcal{T}}\\mathcal{S}_h(v)=\\{\\bigcup_{v\\in \\mathcal{T}}\\mathcal{V}^h_v, \\bigcup_{v\\in \\mathcal{T}}\\mathcal{E}^h_v, \\bigcup_{v\\in \\mathcal{T}}\\mathcal{R}^h_v\\}.\n\\end{equation}",
            "eq:2": "\\begin{equation}\n    \\mathcal{V}_p=\\{p_q\\} \\bigcup \\{c_i|i\\in [N]\\}, \\mathcal{E}_p= \\mathcal{E}_{query} \\bigcup \\mathcal{E}_{cross}^q, \\mathcal{R}_p=\\{r_{t2p},r_{p2t},r_{q2c}, r_{c2q}\\}.\n\\end{equation}",
            "eq:3": "\\begin{equation}\n    P[\\text{NOI belongs to class }i]=\\sigma(\\text{MLP}(h_{c_i})),\n\\end{equation}",
            "eq:4": "\\begin{equation}\n    l = \\mathrm{argmax}_{i} \\left(\\text{MLP}(h_{c_i}) | i \\in [N]\\right),\n\\end{equation}",
            "eq:5": "\\begin{equation}\n    \\mathcal{E}_{cross}^s=\\bigcup_{i \\in [N], k \\in [K]}\\mathcal{E}_{cross}^{i, k}=\\bigcup_{i \\in [N], k \\in [K]}\\{(t, r_{t2p}, p_{i,k}), (p_{i,k}, r_{p2t}, t) | t \\in \\mathcal{T}^i_k\\}.\n\\end{equation}",
            "eq:6": "\\begin{equation}\n\\begin{split}\n    \\mathcal{V}_p=\\{p_q\\} \\bigcup \\{p_{i,k}|i\\in [N],& k\\in[K]\\}\\bigcup \\{c_i|i\\in [N]\\}, \\\\ \\mathcal{E}_p=\\mathcal{E}_{cross}^q \\bigcup \\mathcal{E}_{query} \\bigcup \\mathcal{E}_{cross}^s \\bigcup &\\mathcal{E}_{supp}, \\quad \\mathcal{R}_p=\\{r_{t2p},r_{p2t},r_{q2c}, r_{c2q}, r_{s2c}\\}.\n\\end{split} \n\\end{equation}",
            "eq:7": "\\begin{equation}\n    x_{ij}=LLM(s_{e_{ij}}), \\forall e_{ij}\\in \\mathcal{E}_m,\\quad x_i=LLM(s_{v_i}), \\forall v_i \\in \\mathcal{V}_m.\n\\end{equation}",
            "eq:8": "\\begin{equation}\nh^{l+1}_{v_i} = \\bm{W}_{\\text{self}}h^{l}_{v_i} + \\sum_{r\\in \\mathcal{R}_m} \\sum_{v_j \\in \\mathcal{N}_{1}^r(v_i)} \\frac{1}{|\\mathcal{N}_{1}^r(v_i)|}\\bm{W}_r (\\text{ReLU}(h^l_{v_j}+ x_{ij})),\n\\end{equation}",
            "eq:9": "\\begin{equation}\n    h_{v_i} = \\bm{H}\\cdot Softmax((\\bm{W}_k\\bm{H})' \\cdot \\bm{W}_qx_i)', \\quad \\bm{H}=[h_{v_i}^1\\quad ... \\quad h_{v_i}^l \\quad ... \\quad h_{v_i}^L],\n\\end{equation}",
            "eq:10": "\\begin{equation}\np_i = \\sigma(\\text{MLP}(h_{c_i})),\n\\end{equation}",
            "eq:11": "\\begin{equation}\n    l_p = \\mathrm{argmax} \\left((p_i | i \\in [N])\\right),\n\\end{equation}",
            "eq:12": "\\begin{equation}\n\\mathcal{L}_{\\mathcal{G}_m} = -\\frac{1}{N} \\sum^{N}_{i=1}y_i \\cdot log(p_i) + (1-y_i) \\cdot (1- log(p_i)),\n\\end{equation}"
        },
        "git_link": "https://github.com/LechengKong/OneForAll"
    }
}