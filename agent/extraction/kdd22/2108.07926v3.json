{
    "meta_info": {
        "title": "Collaboration Equilibrium in Federated Learning",
        "abstract": "Federated learning (FL) refers to the paradigm of learning models over a\ncollaborative research network involving multiple clients without sacrificing\nprivacy. Recently, there have been rising concerns on the distributional\ndiscrepancies across different clients, which could even cause\ncounterproductive consequences when collaborating with others. While it is not\nnecessarily that collaborating with all clients will achieve the best\nperformance, in this paper, we study a rational collaboration called\n``collaboration equilibrium'' (CE), where smaller collaboration coalitions are\nformed. Each client collaborates with certain members who maximally improve the\nmodel learning and isolates the others who make little contribution. We propose\nthe concept of benefit graph which describes how each client can benefit from\ncollaborating with other clients and advance a Pareto optimization approach to\nidentify the optimal collaborators. Then we theoretically prove that we can\nreach a CE from the benefit graph through an iterative graph operation. Our\nframework provides a new way of setting up collaborations in a research\nnetwork. Experiments on both synthetic and real world data sets are provided to\ndemonstrate the effectiveness of our method.",
        "author": "Sen Cui, Jian Liang, Weishen Pan, Kun Chen, Changshui Zhang, Fei Wang",
        "link": "http://arxiv.org/abs/2108.07926v3",
        "category": [
            "cs.LG"
        ],
        "additionl_info": "This paper is accepted by SIGKDD2022"
    },
    "latex_extraction": {
        "content": {
            "section 1": {
                "name": "Introduction",
                "content": "\n\nEffective learning of machine learning models over a collaborative network of data clients has drawn considerable interest in recent years. Frequently, due to privacy concerns, we cannot simultaneously access the raw data residing on different clients. Therefore, distributed \\citep{li2014scaling} or federated learning ~\\citep{mcmahan2017communication} strategies have been proposed, where typically model parameters are updated locally at each client with its own data, and the parameter updates, such as gradients, are transmitted out and communicate with other clients. During this process, it is usually assumed that the participation in the network comes at no cost, i.e., every client is willing to participate in the collaboration. However, this is not always true in reality.\n\nOne example is the clinical research network (CRN) involving multiple hospitals \\citep{fleurence2014launching}. Each hospital has its own patient population. The patient data are sensitive and cannot be shared with other hospitals. If we want to build a risk prediction model with the patient data within this network in a privacy-preserving way, the expectation from each hospital is that a better model can be obtained through participating in the CRN compared to the one built from its own data collected from various clinical practice with big efforts. In this scenario, there has been a prior study showing that the model performance can decrease when collaborating with hospitals with very distinct patient populations due to negative transfer induced by sample distribution discrepancies~\\citep{wang2019characterizing,pan2009survey}.\n\nWith these considerations, in this paper, we propose a novel {\\em learning to collaborate} framework. We allow the participating clients in a large collaborative network to form non-overlapping collaboration coalitions. Each coalition includes a subset of clients such that the collaboration among them can benefit their respective model performance. We aim at identifying the collaboration coalitions that can lead to a {\\em collaboration equilibrium}, i.e., there are no other coalition settings that any of the individual clients can benefit more (i.e., achieve better model performance).\n\n\n\nTo obtain the coalitions that can lead to a collaboration equilibrium, we propose a Pareto optimization framework to identify the necessary collaborators for each client in the network to achieve its maximum utility. In particular, we optimize a local model associated with a specific client on the Pareto front of the learning objectives of all clients. Through the analysis of the geometric location of such an optimal model on the Pareto front, we can identify the necessary collaborators of each client. The relationships between each client and its necessary collaborators can be encoded in a {\\em benefit graph}, in which each node denotes a client and the edge from $I^{j}$ to $I^{i}$ represents $I^{j}$ is one of the necessary collaborators for $I^{i}$, as exemplified in Figure~\\ref{fig:intro} (a). Then we can derive the coalitions corresponding to the collaboration equilibrium through an iterative process introduced as follows. Specifically, we define a stable coalition as the minimum set such that its all involved clients can achieve its maximal utility. From the perspective of graph theory, these stable coalitions are the strongly connected components of the benefit graph. For example, $C = \\left\\{I^{1}, I^{2}, I^{3} \\right\\}$ in Figure~\\ref{fig:intro} (b) is a stable coalition as all clients can achieve their best performance by collaborating with the clients in $C$ (compared with collaborating with other clients in the network). By removing the stable coalitions and re-building the benefit graph of the remaining client iteratively as shown in Figure~\\ref{fig:intro} (b) and (c), we can identify all coalitions as in Figure~\\ref{fig:intro} (d) and prove that the obtained coalitions can lead to a collaboration equilibrium.\n\nWe empirically evaluate our method on synthetic data, UCI adult~\\citep{kohavi1996scaling}, a classical FL benchmark data set CIFAR10~\\citep{krizhevsky2009learning}, and a real-world electronic health record (EHR) data repository eICU~\\citep{pollard2018eicu}, which includes patient EHR data in ICU from multiple hospitals. The results show our method significantly outperforms existing relevant methods. The experiments on eICU data demonstrate that our algorithm is able to derive a good collaboration strategy for the hospitals to collaborate. The source codes are made publicly available at \\url{https://github.com/cuis15/learning-to-collaborate}.\n\n"
            },
            "section 2": {
                "name": "Related Work",
                "content": "\n",
                "subsection 2.1": {
                    "name": "Federated Learning",
                    "content": "\nFederated learning has raised several concerns, including communication efficiency~\\cite{konevcny2016federated}, fairness~\\cite{cui2021addressing,cui2021towards,pan2021explaining}, and statistical heterogeneity~\\cite{karimireddy2020scaffold}, and they have been the topic of multiple research efforts~\\cite{mohri2019agnostic}. In a typical FL setting, a global model~\\cite{deng2020distributionally,mohri2019agnostic,reisizadeh2020robust,diamandis2021wasserstein,li2019fair} is learned from the data residing in multiple distinct local clients. However, a single global model may lead to performance degradation on certain clients due to data heterogeneity. Personalized federated learning (PFL)~\\citep{kulkarni2020survey}, which aims at learning a customized model for each client in the federation, has been proposed to tackle this challenge. For example, ~\\citet{zhang2020personalized} proposes to adjust the weight of the objectives corresponding to all clients dynamically; ~\\citet{fallah2020personalized} proposes a meta-learning based method for achieving an effectively shared initialization of all local models followed by a fine-tuning procedure; ~\\citet{shamsian2021personalized} proposes to learn a central hypernetwork which can generate a set of customized models for each client. FL assumes all clients are willing to participate in the collaboration and existing methods have not considered whether the collaboration can really benefit each client or not. Without benefit, a local client could be reluctant to participate in the collaboration, which is a realistic scenario we investigate in this paper. One specific FL setup that is relevant to our work is clustered federated learning~\\citep{sattler2020clustered, mansour2020three}, which groups the clients with similar data distributions and trains a model for each client group. The scenario we are considering in this paper is to form collaboration coalitions based on the performance gain each client can get for its corresponding model, rather than sample distribution similarities.\n\n"
                },
                "subsection 2.2": {
                    "name": "Multi-Task Learning and Negative Transfer",
                    "content": "\nMulti-task learning~\\citep{caruana1997multitask} (MTL) aims at learning shared knowledge across multiple inter-related tasks for mutual benefits.  Typical examples include hard model parameter sharing~\\citep{kokkinos2017ubernet}, soft parameter sharing~\\citep{lu2017fully}, and neural architecture search (NAS) for a shared model architecture~\\citep{real2019regularized}. However, sharing representations of model structures cannot guarantee model performance gain due to the existence of negative transfer, while we directly consider forming collaboration coalitions according to individual model performance benefits. In addition, MTL usually assumes the data from all tasks are accessible, while our goal is to learn a personalized model for each client through collaborating with other clients without directly accessing their raw data. It is worth mentioning that there are also clustered MTL approaches~\\citep{standley2020tasks,zamir2018taskonomy} which assume the models for the tasks within the same group are similar to each other, while we want the clients within each coalition can benefit each other through collaboration when learning their respective models.\n% \\liang{% In theory, \\citet{blum2017collaborative} discussed the sample complexity of MTL.\n% Some works extend MTL to a multi-source domain adaptation~\\citep{wen2020domain,duan2009domain} setting in which unlabeled data exist in some tasks. See detailed discussions in Appendix.}\n\n% \\cui{Due to space limitation, there are also research fields such as multi-source domain adaptation~\\citep{wen2020domain} and collaborative PAC learning~\\citep{blum2017collaborative} related to learning from multiple data sources and we will discuss these works in Appendix.}\n\n\n"
                },
                "subsection 2.3": {
                    "name": "Cooperative Game Theory",
                    "content": "\nCooperative game theory studies the game with competition between groups of players, which focuses on predicting which coalitions will form. There are theoretical research~\\cite{donahue2021model,donahue2021optimality} focusing on the linear regression and mean estimation problems in federated learning from a coalitional game perspective. Classical cooperative game theory~\\cite{arkin2009geometric,aumann1974cooperative,yi1997stable} requires a predefined payoff function, so that it obtains the payoff of each group of players directly. Given a predefined payoff function over all possible groups, the payoff of each coalition is transferable among players in the coalition.\n\nIn our work, we study how to collaborate among clients to learn personalized models in federated learning. Suppose we analogize the model performance of each client to the payoff in cooperative game theory, this ``payoff function'' is not predefined and has to be approximated by the evaluation of the learned models on each client. Meanwhile, the performance of learned models is not transferable, so prior methods in cooperative game theory may not be used to reach a collaboration equilibrium directly.\n\n\n\n%. We propose to identify  T\n"
                }
            },
            "section 3": {
                "name": "Collaboration Learning Problem",
                "content": "\n% \\begin{enumerate}\n%   \\item the uncertainty of the collaboration;\n%   \\item emphasize the privacy preserving of the combination;\n%   \\item emphasize the sparsity of collaborator combination.\n% \\end{enumerate}\n\nWe first introduce the necessary notations and definitions in Section \\ref{sec:3-1}, and then define the collaboration equilibrium we aim to achieve in Section \\ref{sec:3-2}.\n% collaboration equilibrium and its practical meaning from a point of view of multi-objective optimization; then we will\n\n\n% \\begin{table}\n%     \\caption{Notations}\n%     \\label{table:notation}\n%     \\centering\n%     \\begin{tabular}{c|c}\n%     \\hline\n%     variables & meaning\\\\\n%     $N$ & the num of clients\\\\\n%     $\\bm{I} = \\left\\{ I_{1}, I_{2},... I_{N}\\right\\}$ & the set of clients\\\\\n%     $C$ & the coalition\\\\\n%     $M^{i}$ & the learned model for the target client\\\\\n%     $S$ & set partitioning strategy (a set of coalitions which is a set partition)\\\\\n%     \\hline\n%     \\end{tabular}\n% \\end{table}\n\n\n\n",
                "subsection 3.1": {
                    "name": "Definitions and Notations",
                    "content": "\n%这一段前边是联邦学习相关的设定，介绍各个机构拥有的数据和它们各自的任务。后边提出联盟的概念，联盟就是机构的一个集合，单个的机构也是一个联盟，是最小的联盟。在这里提出了一个后边广泛应用的一个概念，是 最大可实现效能（MAU）， MAU值的是，在一个联盟里边，一个机构所能够达到的最高的性能是多少，因为我们是为每个机构学习一个个性化的模型，因此机构自己肯定会努力最大化自己的性能，最终在联盟里边实现的性能就是MAU，也是各个机构的目的，就是要提高MAU。 MAU有个特点，就是联盟越大它就越大，这就导致一个trivial的情况，就是是不是所有的机构直接合作就行了，因为这种情况肯定各个机构的MAU都是最大的，因此后边引出了contribution所起的作用。\n\\label{sec:3-1}\nSuppose there are $N$ clients $\\bm{I} = \\left\\{I^{i}\\right\\}_{i=1}^{N}$ in a collaborative network and each client is associated with a specific learning task $T^{i}$ based on its own data $D^{i} = \\left\\{ X^{i}, Y^{i}\\right\\}, i \\in \\left\\{ 1, 2,..., N\\right\\}$, where the input space $X^{i}$ and the output space $Y^{i}$ may or may not share across all $N$ clients. Each client pursues collaboration with others to learn a personalized model $M^{i}$ by maximizing its utility (i.e., model performance) without sacrificing data privacy. There is no guarantee that one client can always benefit from the collaboration with others, and the client would be reluctant to participate in the collaboration if there is no benefit. In the following, we describe this through a concrete example.\n%. Moreover, there is a cost for each client to collaborate with others (e.g., negotiation cost), one is not willing to provide ``free lunch'' to other clients. Therefore, the premise of collaboration is every client benefits from it. To better understand this, let's introduce an interesting and yet counter-intuitive example.\n\n\\paragraph{No benefit, no collaboration.}\n\\label{example1}\nSuppose the local data $\\{D^{i}\\}, i \\in \\left\\{ 1, 2,..., N\\right\\}$ owned by different clients satisfy the following conditions: 1) all local data are from the same distribution $D^{i} \\sim \\mathcal{P}$; 2) $D^{1} \\subset D^{2} \\subset D^{3} ,..., \\subset D^{N}$. Since $D^{N}$ contains more data than other clients, $I^{N}$ cannot benefit from collaboration with any other clients, so $I^{N}$ will learn a local model using its own data. Once $I^{N}$ refuses to collaboration, $I^{N-1}$ will also work on its own as $I^{N-1}$ can only improve its utility by collaborating with $I^{N}$. $I^{N-2}$ will learn individually out of the same concerns. Finally, there is no collaboration among any clients.\n\nDue to the discrepancies of the sample distributions across different clients, the best local model for a specific client is very likely to come from collaborating with a subset of clients rather than all of them. Suppose $U(I^{i}, C)$ denotes the model utility of client $I^{i}$ when collaborating with the clients in client set $C$. In the following, we define $U_{max}(I^{i}, C)$ as the maximum model utility that $I^{i}$ can achieve when collaborating with different subsets of $C$.\n\\begin{definition}[Maximum Achievable Utility (MAU)]\n\\label{def:mau}\nThis is the maximum model utility for a specific client $I^{i}$ to collaborate with different subsets of client set $C$:\n$U_{max}(I^{i}, C) =  \\max_{C' \\subset C} U(I^{i}, C')$.\n\\end{definition}\n\\vspace{-.1cm}\nFrom Definition \\ref{def:mau}, MAU satisfies $U_{max}(I^{i}, C') \\leq U_{max}(I^{i}, C)$ if $C'$ is a subset of $C$. Each client $I^{i} \\in \\bm{I}$ aims to identify its ``optimal set\" of collaborators from $\\bm{I}$ to maximize its local utility, which is defined as follows. %the client $I^{i}$ needs to identify which clients are most beneficial for it to achieve its maximal performance in $\\bm{I}$: %which we call optimal collaborator set,\n\n\\begin{definition}[Optimal Collaborator Set (OCS)]\n\\label{def:occ}\nA client set $C^{opt}_{\\bm{I}}(I^{i})\\subset\\bm{I}$ is an optimal collaborator set for $I^{i}$ if and only if $C^{opt}_{\\bm{I}}(I^{i})$ satisfies\n\\begin{subequations}\n\\begin{align}\n& \\forall C \\subset \\bm{I}, \\ U(I^{i}, C^{opt}_{\\bm{I}}(I^{i})) \\geq U(I^{i}, C); \\label{eq:occ1} \\\\\n& \\forall C' \\varsubsetneqq C^{opt}_{\\bm{I}}(I^{i}), \\ U(I^{i}, C^{opt}_{\\bm{I}}(I^{i})) > U(I^{i}, C'). \\label{eq:occ2}\n\\end{align}\n\\end{subequations}\n\\end{definition}\nEq.(\\ref{eq:occ1}) means that $I^{i}$ can achieve its maximal utility when collaborating with $C^{opt}_{\\bm{I}}(I^{i})$ and Eq.(\\ref{eq:occ2}) means that all clients in $C^{opt}_{\\bm{I}}(I^{i})$ are necessary. In this way, the relationships between any client $I^{i}\\in\\bm{I}$ and its optimal collaborator set $C^{opt}_{\\bm{I}}(I^{i})$ can be represented by a graph which is called the \\emph{benefit graph} (BG). Specifically, for a given client set $C\\subset\\bm{I}$, we use $BG(C)$ to denote its corresponding BG. For the example in Figure~\\ref{fig:intro} (a), an arrow from $I^{j}$ to $I^{i}$ means $I^{j} \\in C^{opt}_{\\bm{I}}(I^{i})$, e.g., $I^{1}\\rightarrow I^{3}$ means $I^{1} \\in C^{opt}_{\\bm{I}}(I^{3})$. For a client set $C$, if every member can achieve its maximum model utility through the collaboration with other members within $C$ (without collaboration with other members outside $C$), then we call $C$ a {\\em coalition}.\n\n%$I^{3}\\rightarrow I^{4}$ means  $C^{opt}_{\\bm{I}}(I^{4}) = \\left\\{I^{3}\\right\\} \\cup \\left\\{I^{4}\\right\\}$. It is worth mentioning that $BG(C)$ is determined by the client set $C$. \\sen{From Figure~\\ref{fig:intro} (a), $C^{opt}_{\\bm{I}}(I^{4}) = \\{ I^{3} \\} \\cup \\{ I^{4} \\}$ so that by collaborating with $I^{3}$, $I^{4}$ can achieve its optimal utiltiy when $ I^{4}$ in $\\bm{I}$. However, when $\\left\\{I^{1}, I^{2}, I^{3} \\right\\}$ is removed, $C^{opt}_{\\{I^{4}, I^{5}, I^{6} \\}}(I^{4}) = \\{ I^{5} \\} \\cup \\{ I^{4} \\}$ as shown in Figure~\\ref{fig:intro} (c)}.\n\n%If the clients in a subset $C$ can achieve the optimal utility by collaborating with others in $C$, the clients in $C$ will form a collaboration coalition and do not need to collaborate with others in $\\bm{I} \\backslash C$. To better understand it, let's introduce another interesting example.\n\n% \\begin{wrapfigure}{l}{4.50cm}\n%   \\includegraphics[width=0.32\\columnwidth]{figures/exp2.pdf}\n%   \\caption{Forming coalitions for maximizing the local utility}\n%   \\label{fig:example2}\n% \\end{wrapfigure}\n\n\n\n\\paragraph{Forming coalitions for maximizing the local model utilities}\nFigure~\\ref{fig:example2} shows an example BG with 6 clients. %From the $BG(\\left\\{I^{1},...I^{6} \\right\\})$ shown in Figure~\\ref{fig:example2},\n$I^{3}$ can achieve its optimal model utility by collaborating with $I^{1}$. Similarly, $I^{1}$ and $I^{2}$ can achieve their optimal model utility through collaborating with $I^{2}$ and $I^{3}$. In this case, $C = \\left\\{I^{1}, I^{2},I^{3} \\right\\}$ denotes a collaboration coalition, and each client achieves its optimal utility by collaborating with other clients in $C$. If $I^{1}$ is taken out from $C$, $I^{3}$ will leave $C$ as well because it cannot gain any benefit through collaboration with others, and then $I^2$ will leave for the same reason. With this ring structure of $C$, none of the clients in $C$ can achieve its best performance without collaborating with the clients in $C$.\n"
                },
                "subsection 3.2": {
                    "name": "Problem Setup",
                    "content": "\n\\label{sec:3-2}\nAs each client in $\\bm{I}$ aims to maximize its local model utility by forming a collaboration coalition with others, all clients in $\\bm{I}$ can form several non-overlapping collaboration coalitions. In order to derive those coalitions, we propose the concept of \\emph{collaboration equilibrium} (CE) as follows.\n\nSuppose we have a set of coalitions $S  = \\left\\{C^{0}, C^{1},...C^{K} \\right\\}$ such that $\\bigcup_{k=1}^KC^k=\\bm{I}$ and $C^{k_1}\\bigcap C^{k_2}=\\emptyset$ for $\\forall k_1\\ne k_2$, then we say $S$ reaches CE if it satisfies the following two axioms.%to represent a collaboration strategy in which all collaboration coalitions are disjoint and the clients $I^{i} \\in C^{i}$ can only collaborate with others in $C^{i}$.\n\\begin{axiom}[Inner Agreement]\nAll collaboration coalitions satisfy inner agreement, i.e.,\n\\begin{equation}\n\\forall C \\in S, \\ \\forall C' \\varsubsetneqq C, \\ \\exists I^{i} \\in C', \\ \\text{s.t.,} \\ U_{max}(I^{i}, C') < U_{max}(I^{i}, C)\n\\label{eq:ia}\n\\end{equation}\n\\label{axiom:1}\n\\end{axiom}\nFrom Axiom~\\ref{axiom:1}, inner agreement emphasizes that the clients of each coalition agree to form this coalition. It gives the necessary condition for a collaboration coalition to be formed such that any of the subset $C' \\varsubsetneqq C$ can benefit from the collaboration with $C \\backslash C'$. Eq.(\\ref{eq:ia}) tells us that there always exists a client in $C'$ that opposes leaving $C$ because its utility will go down if $C'$ is split from $C$.\nIn this way, inner agreement guarantees that all coalitions will not fall apart or the clients involved will suffer. For example, $S = \\left\\{ \\left\\{I^{1},I^{2},I^{3},I^{4}  \\right\\}, \\left\\{ I^{5}, I^{6} \\right\\} \\right\\}$ in Figure~\\ref{fig:example2} does not satisfy inner agreement, because the clients in the subset $ C' = \\left\\{I^{1},I^{2},I^{3} \\right\\}$ achieves their optimal utility in $C'$ and can leave $C = \\left\\{I^{1},I^{2},I^{3},I^{4}  \\right\\}$ without any loss.\n\n\\vspace{.5em}\n\\begin{axiom}[Outer Agreement]\nThe collaboration strategy should satisfy outer agreement, i.e.,\n\\begin{equation}\n\\forall C' \\notin S, \\ \\exists I^{i} \\in C', \\ \\text{s.t.} \\ U_{max}(I^{i}, C') \\leq U_{max}(I^{i}, C ) \\ (I^{i} \\in C \\in S)\n\\label{eq:oa}\n\\end{equation}\n\\label{axiom:2}\n\\end{axiom}\\vspace{-2em}\nFrom Axiom~\\ref{axiom:2}, outer agreement guarantees that there is no other coalition $C'$ which can benefit each client involved more than $S$ achieves. Eq.(\\ref{eq:oa}) tells us that if $C'$ is a coalition not from $S$, there always exists a client $I^i$ and a coalition in $C\\in S$ such that $I^i$ can benefit more. The collaboration strategy $S = \\left\\{ \\left\\{ I^{1},I^{2},I^{3}\\right\\}, \\left\\{I^{4} \\right\\}, \\left\\{ I^{5},I^{6} \\right\\} \\right\\}$ in Figure~\\ref{fig:example2} is a CE in which the clients in $\\left\\{I^{1},I^{2},I^{3}\\right\\}$ and $\\left\\{ I^{5},I^{6} \\right\\}$ achieve their optimal model utility. Though $I^{4}$ does not achieve its maximum model utility in $\\left\\{I^{4} \\right\\}$, there is no other coalitions which can attract $I^{2}$ and $I^{5}$ to form a new coalition with $I^{4}$. Therefore, all clients have no better choice but agree upon this collaboration strategy.\n\nOur goal is to obtain a collaboration strategy to achieve CE that satisfies Axiom~\\ref{axiom:1} and Axiom~\\ref{axiom:2}, so that all clients achieve their optimal model utilities in the collaboration coalition. In the next section, we introduce our algorithm in detail on 1) how to derive a collaboration strategy that can achieve CE from the benefit graph and 2) how to construct the benefit graph.\n\n\n"
                }
            },
            "section 4": {
                "name": "Collaboration Equilibrium",
                "content": "\nIn this section, we will %answer the two problems proposed in Section \\ref{sec:3-2}.\nintroduce our framework on learning to collaborate.\nFirstly, we propose an iterative graph-theory-based method to achieve CE based on a given benefit graph.\n\n",
                "subsection 4.1": {
                    "name": "Achieving Collaboration Equilibrium Given the Benefit Graph",
                    "content": "\n\\label{sec:4-1}\n\nIn theory, there are $B_{N}$ collaboration strategies for partitioning $N$ clients into several coalitions, where $B_{N}$ is the Bell number which denotes how many solutions for partitioning a set with $N$ elements~\\citep{bell1934exponential}. While exhaustive trying all partitions has exponential time complexity, in this section, we propose an iterative method for deriving a collaboration strategy that achieves CE with polynomial time complexity. Specifically, at each iteration, we search for a \\emph{stable coalition} which is formally defined in~Definition \\ref{def:sc} below, then we remove the clients in the \\emph{stable coalition} and re-build the benefit graph for the remaining clients. The iterations will continue until all clients are able to identify their own coalitions. %One may wonder why we need to re-rebuild the benefit graph after removing the stable coalition $C^{s}$ from $\\bm{I}$. It is because that the current benefit graph $BG(I \\backslash C^{s})$ depends on the remaining client set $I \\backslash C^{s}$ and may not be the subgraph of $BG(I)$.\n\n\n\\begin{definition}[Stable Coalition]\n\\label{def:sc}\nGiven a client set $\\bm{I}$, a coalition $C^{s}$ is stable if it satisfies\n\\begin{enumerate}\n  \\item Each client in $C^{s}$ achieves its maximal model utility, i.e.,\n  \\begin{equation}\n  \\label{eq:sc-1}\n  U_{max}(I^{i}, C^{s}) = U_{max}(I^{i}, \\bm{I}) \\ \\forall I^{i} \\in C^{s}.\n  \\end{equation}\n  \\item Any sub coalition $C'\\subset C^{s}$ cannot achieve the maximal utility for all clients in $C'$, i.e., \\label{property:2}\n  \\begin{equation}\n  \\label{eq:sc-2}\n  \\forall C' \\varsubsetneqq C^{s}, \\ \\exists I^{i} \\in C', \\ \\text{s.t.,} \\ U_{max}(I^{i}, C') < U_{max}(I^{i}, C^{s}).\n  \\end{equation}\n\\end{enumerate}\n\\end{definition}\nFrom Definition \\ref{def:sc}, Eq.(\\ref{eq:sc-1}) means that any client in a stable coalition cannot improve its model utility further. Eq.(\\ref{eq:sc-2}) states that this coalition is \\emph{stable} as any sub coalition $C'$ can benefit from $C^{s} \\backslash C'$. Therefore any sub coalition has no motivation to leave $C^{s}$. Eq.(\\ref{eq:sc-1}) implies that a stable coalition will not welcome any other clients to join as others will not benefit the clients in $C^{s}$ further. In Figure~\\ref{fig:example2}, $\\left\\{ I^{1}, I^{2}, I^{3} \\right\\}$ and $\\left\\{ I^{5}, I^{6} \\right\\}$ are the two stable coalitions. In order to identify the stable coalitions from the benefit graph, we first introduce the concept of strongly connected component in a directed graph.\n\n\\sen{%Stable coalition means that the clients involved have achieved their goal of collaboration and will leave the original client set. To bridge the concepts of stable coalition and benefit graph, we firstly introduce the definition of \\emph{strongly connected components} of a directed graph.\n\n\\begin{definition}[Strongly Connected Component~\\citep{tarjan1972depth}]\nA subgraph $G'$ is a strongly connected component of a given directed graph $G$ if it satisfies:\n1) It is strongly connected, which means that there is a path in each direction between each pair of vertices in $G'$;\n2) It is maximal, which means no additional vertices from $G$ can be included in $G'$ without breaking the property of being strongly connected.\n\\label{def:scc}\n\\end{definition}\n\nThen we derive a graph-based method to obtain the collaboration coalitions that can achieve collaboration equilibrium by identifying all stable coalitions iteratively according to Theorem~\\ref{theorem:1} below.}\n\n\\begin{theorem}\n(Proof in Appendix) Given a client set $\\bm{I}$ and its $BG(\\bm{I})$, the stable coalitions are strongly connected components of $BG(\\bm{I})$.\n\\label{theorem:1}\n\\end{theorem}\n\nWith Theorem~\\ref{theorem:1}, we need to identify all strongly connected components of $BG(\\bm{I})$, which can be achieved using the \\textbf{Tarjan} algorithm~\\citep{tarjan1972depth} with time complexity $O(V+E)$, where $V$ is the number of nodes and $E$ is the number of edges. Then following Eq.(\\ref{eq:sc-1}), we judge whether a strongly connected component is a stable coalition by checking whether all clients have achieved their maximal model utility.\nA stable coalition $C^{s}$ has no interest to collaborate with other clients, so $C^{s}$ will be removed and the remaining clients $\\bm{I} \\backslash C^{s}$ will continue to seek collaborations until all $N$ clients find their coalitions. In this way, we can achieve a partitioning strategy, with the details shown in Algorithm~\\ref{alg:CE1}.\n\n\\begin{algorithm}\n\\caption{Achieving collaboration equilibrium}\n\\label{alg:CE1}\n\\KwIn{$N$ institutions $\\bm{I} = \\{ I^{i} \\}_{i = 1}^{N}$ seeking collaborating with others}\nSet original client set $C \\gets \\bm{I}$;\\\\\nSet collaboration strategy $S \\gets \\emptyset$;\\\\\n\\While {$C \\not = \\emptyset $}{\n\n  \\ForAll{client $I^{i} \\in C$}{\n    Determine the OCS of $I^{i}$ by SPO; \\\\\n    (detailed description in Sec~\\ref{sec:4-2}) \\\\\n  }\n  Construct the benefit graph $BG(C)$; \\\\\n  Search for all strongly connected components $\\left\\{ C^{1}, C^{2},...C^{k} \\right\\}$ of $BG(C)$ using \\textbf{Tarjan} algorithm;\\\\\n  \\ForAll{i = 1, 2, 3,... k}{\n    \\textcolor{text}{\\If{$C^{i}$ is stable coalition}{\n    $C \\gets C \\backslash C^{i}$ ; \\\\\n    $S \\gets S \\cup \\{ C^{i} \\}$;\n  }\n  }\n  }\n}\n\\KwOut{collaboration strategy $S$}\n\\end{algorithm}\n\nOne may wonder whether our algorithm could get stuck because none of the strongly connected components are stable coalitions as highlighted in red in Algorithm~\\ref{alg:CE1}. We answer this question by giving the following proposition:\n\n\\begin{proposition}\n(Proof in Appendix) In any iteration, our algorithm ensures that at least one stable coalition is identified, so it will not get stuck because none of the strongly connected components are stable coalitions.\n\\label{proposition:1}\n\\end{proposition}\n\nThe clients in all stable coalitions found in each iteration cannot improve their model utility further and will not collaborate with others because there are no additional benefits. Therefore, the collaboration strategy is approved by all clients and we have the following theorem:\n\n\\begin{theorem}\n(Proof in Appendix) The collaboration strategy obtained above achieves collaboration equilibrium.\n\\label{theorem:3}\n\\end{theorem}\n\n% The clients in all stable coalitions found in each iteration have no better choice to continue to improve its model utility and do not collaborate with others for no benefits. Therefore, the collaboration strategy can be approved by all clients. The iterative method achieves CE considering the $BG$ varies in each iteration after we remove the stable coalitions, which can be time-consuming because we need to redefine $BG$ in each iteration by re-learning an optimal personalized model for each remaining client.\n\n% \\begin{assumption}\n% The benefit graph of a subset $C \\subset \\bm{I}$ ($BG(C)$) is the subgraph of the $BG(\\bm{I})$.\n% \\label{assumption:1}\n% \\end{assumption}\n\n% Assumption~\\ref{assumption:1} claims that the benefit graph of the remaining clients $\\bm{I} \\backslash C^{s}$ keeps unchanged when the subgraph $BG(C^{s})$ is split from $BG(\\bm{I})$. It implies that for each pair of clients $I^{i}$ and $I^{j}$, whether $I^{i}$ is one of the optimal collaborators for $I^{j}$ will not be affected by other clients. In this case, we do not need to re-build the benefit graph and have the following corollary.\n\n% \\begin{corollary}\n% (proof in Appendix) When Assumption~\\ref{assumption:1} holds, the strongly connected components of $BG(I)$ leads to a collaboration equilibrium.\n% \\label{coro:1}\n% \\end{corollary}\n\n\n\n"
                },
                "subsection 4.2": {
                    "name": "Determine the Benefit Graph by Specific Pareto Optimization",
                    "content": "\n\\label{sec:4-2}\n\n\\cui{The benefit graph of $N$ clients consists of the clients and their corresponding OCS. However, each client has $2^{N-1}$ collaborator sets and it's hard to determine which one is the OCS. Exhaustive trying all sets to determine the OCS may be impractical, especially when there are many clients. To identify the OCS effectively and efficiently, we propose Specific Pareto Optimization (SPO) to \\liang{alternately perform the following two steps:} 1). learn a Pareto model (defined below) given the weight of all clients $\\bm{d}$; 2). optimize the weight vector $\\bm{d}$ to search for a best model $M^{*}(I^{i})$ by gradient descent.}\n\n\\begin{definition}[Pareto Solution and Pareto Front]\nWe consider $n$ objectives corresponding to $n$ clients: $ l_{i} : \\mathbb{R}^{n} \\rightarrow \\mathbb{R}_{+}, i = \\left\\{ 1,2,...,n \\right\\}$. Given a learned hypothesis $h$, suppose the loss vector $\\bm{l(h)} = [l_{1}, l_{2},...,l_{n} ]$ represents the utility loss on $n$ clients with hypothesis $h \\in \\mathcal{H}$, we say $h$ is a Pareto Solution if there is no hypothesis $h'$ that dominates h, often called Pareto optimality, i.e., $$\\nexists h^{\\prime} \\in \\mathcal{H}, \\text { s.t. } \\forall i: l_{i}\\left(h^{\\prime}\\right) \\leq l_{i}(h) \\text { and } \\exists j: l_{j}\\left(h^{\\prime}\\right)<l_{j}(h).$$ In a collaboration network with $N$ clients $\\{ I^{i}\\}_{i=1}^{N}$, as each client has its own learning task which can be formulated as a specific objective, we use $P( \\left\\{ I^{1}, I^{2},...,I^{N} \\right\\} )$ to represent the Pareto Front (PF) of the client set $\\{ I^{i}\\}_{i=1}^{N}$ formed by all Pareto hypothesis.\n\\label{def:pt}\n\\end{definition}\n\n\n\\paragraph{Learning a best model and identify the OCS by SPO} \\cui{ To search for an optimal model $M^{*}(I^{i})$ for $I^{i}$, we propose to firstly learn the empirical Pareto Front by a hypernetwork denoted as $HN$ \\footnote{More information please refer to~\\citep{navon2020learning}}. As each client owns its objective, given the weight of all clients (objectives), the learned PT by $HN$ outputs a Pareto model $M$,\n\\begin{equation}\n\\setlength{\\abovedisplayskip}{4pt}\n    M = HN(\\bm{d}),\n\\end{equation}\nwhere $\\bm{d} = [d^{1}, d^{2},...,d^{N}]$ satisfying $\\sum_{i=1}^{N} d^{i} = 1$ and $d^{i}$ denotes the weight of the objective $l_{i}$. Each $\\bm{d}$ corresponds to a specific Pareto model $M$, and all Pareto models $M$ satisfy Pareto optimality that the losses on the training data of all clients cannot be further optimized.\n\nThough the Pareto models maximize the utilization of the training data from all clients, they may not be the best models on the true (test) data distribution. For example, $HN(\\bm{d}_{4})$ achieves a minimum loss on the training data of $I^{1}$ shown in Figure~\\ref{fig:spo} (b), but it is not the optimal model on the true data distribution of $I^{1}$ shown in Figure~\\ref{fig:spo} (c). Therefore, we propose to search for a best Pareto model that achieves the best performance on the true (validation) data set of the target client $I^{i}$, i.e.,\n\\begin{equation}\n\\setlength{\\belowdisplayskip}{-5pt}\n    M^{*}(I^{i}) = HN(\\bm{d}^{*}), \\quad \\text{where} \\  \\bm{d}^{*} = \\arg\\max_{\\bm{d}} \\mathrm{Per}(HN(\\bm{d}), I^{i}),\n\\label{eq:hn_per}\n\\end{equation}\n\nwhere $\\mathrm{Per}(HN(\\bm{d}), I^{i})$ denotes the performance of $HN(\\bm{d})$ on the validation data set of $I^{i}$. We identify the OCS of $I^{i}$ based on the optimized weight of all clients $\\bm{d^{*}}$. For example shown in Figure~\\ref{fig:spo}(c), the best model is $h_{1}^{*}$ for client $I^{1}$ and the corresponding optimized weight $\\bm{d}^{*} = \\bm{d}_{3} = [0.7, 0.3, 0]$. So the OCS of $I^{1}$ consists of the clients with non-zero weights, which is $\\left\\{ I^{1}, I^{2}\\right\\}$. }\n\n\n\\begin{proposition}[Pareto Front Embedding Property]\n\\label{prop:embed-pt}\n(proof in Appendix) Suppose $\\bm{l'^{*}} = [l_{i}(h'^{*})], i \\in C'$ and $\\bm{l^{*}} = [l_{i}(h^{*})], i \\in C$ are the loss vectors achieved by the PFs $P(C')$ and $P(C)$ where $C' \\subset C$, then\n\\begin{equation}\n\\forall h'^{*} \\in P(C'), \\ \\exists h^{*} \\in P(C), \\ \\text{s.t.,} \\ l_{i}(h'^{*}) = l_{i}(h^{*}) \\ \\forall i \\in C'.\n\\label{eq:prop}\n\\end{equation}\n\\end{proposition}\nFrom Proposition \\ref{prop:embed-pt}, the loss vectors achieved by the PF of a sub-coalition are embedded in the loss vectors of the full coalition, such as the loss curve of $P(\\left\\{ l_{1}, l_{2} \\right\\})$ is in the loss plane of $P(\\left\\{ l_{1}, l_{2}, l_{3} \\right\\})$ shown in Figure~\\ref{fig:spo} (a) and (b).\n\\paragraph{Explanation of SPO from a geometric point of view} \\cui{\nIntuitively, if the best model $M^{*}(I^{i})$ searched on the PF of all clients $P(\\bm{I})$ belongs to the PF of a sub coalition $P(C)$ simultaneously, i.e.,\n\\begin{equation}\n    \\setlength{\\abovecaptionskip}{-5pt}\n    \\setlength{\\belowcaptionskip}{-5pt}\n    M^{*}(I^{i}) \\in P(C) \\quad \\text{and} \\quad M^{*}(I^{i}) \\in P(I),\n\\end{equation}\nthen the clients $\\bm{I} \\backslash C$ are not necessary for obtaining $M^{*}(I^{i})$. However, exhaustively trying the PF of all sub-coalitions can have exponential time complexity. From Proposition~\\ref{prop:embed-pt}, the PF of full coalition $\\bm{I}$ contains the PF of all sub-coalitions. Therefore, we propose SPO to search for a best model $M^{*}(I^{i})$ on the PF of full coalition $\\bm{I}$, and identify whether $M^{*}(I^{i})$ belongs to the PF of a sub-coalition using the optimized weight vector $\\bm{d}$. For example, suppose there are three clients and the three corresponding objectives achieved by the PF are shown in Figure~\\ref{fig:spo}(a). The model $h^{*}_{1}$ in Figure~\\ref{fig:spo}(a) is on the PF $P(\\left\\{ l_{1}, l_{2}, l_{3} \\right\\})$. Since the corresponding weight $\\bm{d} = [0.7, 0.3, 0]$, from Figure~\\ref{fig:spo}(b), $h^{*}_{1}$ is also on the PF $P(\\left\\{ l_{1}, l_{2} \\right\\})$, so $I^{3}$ is not a necessary client and the OCS of $I^{1}$ is $\\left\\{ l_{1}, l_{2} \\right\\}$.\n}\n\n"
                },
                "subsection 4.3": {
                    "name": "More Discussion",
                    "content": "\n\\textbf{Time Complexity Analysis} The analysis about the time complexity is as follows:\n\\begin{enumerate}\n    \\item to find an OCS efficiently, we propose SPO to learn an optimal model by gradient descent and identify the OCS based upon the geometric location of the learned model on the Pareto Front according to Proposition 1, which avoids exhaustively trying;\n    \\item to find the stable coalitions of a given client set, we propose to identify the OCS of all clients to construct the benefit graph firstly. Then we propose a graph-based method to recognize the stable coalitions which has $O(V+E)$ time complexity as stated in Sec~\\ref{sec:4-1};\n    \\item to achieve a collaboration equilibrium, we propose to look for stable coalitions and remove them iteratively. Combining (1) and (2), our method to reach a CE has polynomial time complexity.\n\\end{enumerate}\n\n\\noindent \\textbf{Influence Factor of CE} The collaboration equilibrium of a collaborated network is affected by 1) the selected model structure; 2) the data distribution of the clients. For 1), different model structures utilize the data in different ways. For example, non-linear models can capture the non-linear mapping relations in the data among different local clients while linear models cannot. For 2), the collaboration equilibrium is affected by the data distribution of the clients given the model structure. The data distribution of one client determines whether it can benefit another when learning together and this was verified by the experiments on the synthetic dataset.\n\n\n"
                }
            },
            "section 5": {
                "name": "Experiments",
                "content": "\nTo demonstrate the effectiveness of SPO, we conduct experiments on synthetic data, a real-world UCI dataset \\textbf{Adult}~\\citep{kohavi1996scaling} and a benchmark data set \\textbf{CIFAR10}~\\citep{lecun1998gradient}. We use the following two ways to demonstrate the effectiveness of our proposed SPO:\n\n\\begin{enumerate}\n    \\item exhaustive trying; we exhaustively try each subset to obtain the true OCS for each client. Then we compare the true benefit graph with the learned benefit graph by SPO;\n    \\item performance of the learned models; we compare the model performance learned by SPO with prior methods in PFL, as the optimality of the obtained benefit graph is reflected in the performance of the model learned based on the benefit graph.\n\\end{enumerate}\n\nTo intuitively show the motivation of \\emph{collaboration equilibrium} and the practicability of our framework, we conduct experiments on a real-world multiple hospitals collaboration network using the electronic health record (EHR) data set \\textbf{eICU}~\\citep{pollard2018eicu}.\n\nAs SPO aims to achieve an optimal model utility by optimizing the personalized model on the PF of all clients, we use SPO to denote the model utility achieved by SPO. According to the OCS determined by SPO, we achieve a CE for all clients and the model utility of each client in the CE can be different from the utility achieved by SPO. We use CE to denote the model utility achieved in the CE without causing further confusion. We anonymously upload our source code in Supplementary Material. More implementation details can be found in Appendix.\n\n\n",
                "subsection 5.1": {
                    "name": "Synthetic Experiments",
                    "content": "\n\\noindent \\textbf{Synthetic data} Suppose there are 6 clients in the collaboration network. The synthetic features owned by each client $I^{i}$ are generated by $\\mathbf{x} \\sim \\mathcal{U}[-1.0,1.0]$; the ground-truth weights $\\mathbf{u}_{i}=\\mathbf{v}+\\mathbf{r}_{i}$ are samples as $\\mathbf{v} \\sim \\mathcal{U}[0.0,1.0], \\mathbf{r}_{i} \\sim \\mathcal{N}(\\mathbf{0}_{d}, \\rho^{2})$  where $\\rho^{2}$ represents the client variance (if $\\rho^{2}$ increases, the data distribution discrepancy among clients will increase). Labels of the clients are observed with i.i.d noise $\\epsilon \\sim \\mathcal{N}\\left(0, \\sigma^{2}\\right)$. To generate conflicting learning tasks assigned to different clients, we flip over the label of some clients: $y = \\mathbf{u}_{i}^{\\top} \\mathbf{x}+\\epsilon, i \\in \\left\\{0,1,2\\right\\}$ and $y = -\\mathbf{u}_{i}^{\\top} \\mathbf{x}+\\epsilon, i \\in \\left\\{3,4,5\\right\\}$.\n\n\nTo obtain the true benefit graph, we exhaustively try all subsets to determine the OCS for each client. For example, we learn $2^{5}$ models for each group of clients for $I^{0}$ and determine the OCS with which the model achieves the minimal loss. The true benefit graph is shown in Figure~\\ref{fig:syn_bg}.\n\n\n\n\n\nWe also show the experimental results of SPO in Table~\\ref{table:synthetic}. From Table~\\ref{table:synthetic}, when there are fewer samples ($n=2000$) and less distribution discrepancy $\\rho = 0.1$ in the client set $\\left\\{I^{0}, I^{1}, I^{2}\\right\\}$ and $\\left\\{I^{3}, I^{4}, I^{5}\\right\\}$ with similar label generation process, these clients collaborate with others to achieve a low MSE. In this case, the OCS of each client is the clients with similar learning tasks and we achieve CE $S = \\{ \\{I^{i} \\}_{i=0}^{2}, \\{I^{i} \\}_{i=3}^{5} \\}$ as shown in the top of Figure~\\ref{fig:syn-equ} (a). With the increase of the number of samples and the distribution discrepancy, collaboration cannot benefit the clients and all clients will learn individually on their own data. Therefore, when $n = 20000$ and $\\rho = 1.0$, the OCS of each client is itself and the collaboration strategy $S = \\{ \\{I^{0} \\}, \\{I^{1} \\},., \\{I^{5}\\} \\}$ leads to a CE as shown in the bottom of Figure~\\ref{fig:syn-equ} (a).\n\nComparing the OCS in Table~\\ref{table:synthetic} with the graph in Figure~\\ref{fig:syn_bg}, SPO obtains the same benefit graph realized by exhaustively trying in polynomial time complexity.\n\n\n\n\\noindent \\textbf{UCI adult data} UCI \\emph{adult} is a public dataset~\\citep{kohavi1996scaling}, which contains more than 40000 adult records and the task is to predict whether an individual earns more than 50K/year given other features (e.g., age, gender, education, etc.). Following the setting in~\\citep{li2019fair,mohri2019agnostic}, we split the data set into two clients. One is PhD client ($I^{1}$) in which all individuals are PhDs and the other is non-PhD client ($I^{0}$). We implement SPO on this data set. Specifically, we construct the hypernetwork using a 1-layer hidden MLP. The target network is a Logistic Regression model as in ~\\citep{li2019fair,mohri2019agnostic}. We split 83\\% training data for learning the PF and the remaining 17\\% training data for determining the optimal vector $\\bm{d}$. We compare the performance with existing relevant methods AFL \\citep{mohri2019agnostic} and q-FFL \\citep{li2019fair}\\footnote{The results of baselines are from~\\citep{li2019fair}}.\n\n\nThe two clients $I^{0}$ and $I^{1}$ have different data distribution and non-PhD client has more than 30000 samples while PhD client has about 500 samples. From Table \\ref{table:adult}, PhD client improves its performance by collaborating with non-PhD client. However, non-PhD client achieves an optimal accuracy (83.5) by local training, so non-PhD will not be willing to collaborate with non-PhD client. Therefore, the benefit graph is shown at the top of Figure \\ref{fig:syn-equ} (b). The CE is non-collaboration as in the bottom of Figure \\ref{fig:syn-equ} (b) and the model of both clients in the CE are trained individually.\n\nCompared with prior methods, SPO achieves higher performance on both clients in Table~\\ref{table:adult} especially on PhD client (77.0), which verifies its superiority on the learning of personalized models.\n\n\n\n\n"
                },
                "subsection 5.2": {
                    "name": "Benchmark Experiments",
                    "content": "\nWe compare our method with previous personalized federated learning (PFL) methods on CIFAR-10~\\citep{krizhevsky2009learning}\\footnote{The results of baselines are from ~\\citep{shamsian2021personalized}}. CIFAR10 is a public dataset~\\citep{lecun1998gradient} which contains 50000 images for training and 10000 images for testing. In our experiments, we follow the setting in ~\\citep{mcmahan2016federated}. We split the data into 10 clients and simulate a non-i.i.d environment by randomly assigning two classes to each client among ten total classes. The training data of each client will be divided into a training set (83\\%) and a validation set(17\\%). We construct the hypernetwork using 3-layer hidden MLP for generating the parameters of the target network and the target network is constructed following the work~\\citep{shamsian2021personalized}. All baselines share the same target network structure for each client.\n\nBaselines we evaluate are as follows: (1) Local training on each client; (2) FedAvg~\\citep{mcmahan2016federated}; (3) Per-FedAvg~\\citep{fallah2020personalized}, a meta-learning based PFL algorithm. (4) pFedMe~\\citep{t2020personalized}, a PFL approach which adds a Moreau-envelopes loss term; (5) LG-FedAvg~\\citep{liang2020think} PFL method with local feature extractor and global output layers; (6) FedPer~\\citep{arivazhagan2019federated}, a PFL approach that learns personal classifier on top of a shared feature extractor; (7) pFedHN~\\citep{shamsian2021personalized}, a PFL approach that generates models by training a hyper-network. In all experiments, our target network shares the same architecture as the baseline models. For each client, we split 87\\% of the training data for learning a Pareto Front by collaborating with the others and the remaining 13\\% of the training data for optimizing the vector $\\bm{d}$ to reach an optimal model as shown in Figure~\\ref{fig:spo} (c).\n\nTable~\\ref{table:cifar10} reports the results of all methods. FedAve achieves a lower accuracy (51.4) compared to local training (86.46) which means that training a global model can hurt the performance of each client. Compared to other PFL methods in Table~\\ref{table:cifar10}, SPO reaches an optimal model on the PF of all objectives and achieves a higher accuracy (92.47). As the features learned from the images are transferable though there is a label shift among all clients, the collaboration among all clients leads to a more efficient feature extractor for each client. Therefore, the benefit graph of this collaboration network is a fully connected graph and the collaboration equilibrium is that all clients form a full coalition for collaboration as shown in Figure~\\ref{fig:syn-equ} (c). In this experiment, the accuracy model of each client in CE equals to the accuracy achieved by SPO.\n\n"
                },
                "subsection 5.3": {
                    "name": "Hospital Collaboration",
                    "content": "\neICU~\\citep{pollard2018eicu} is a clinical data set collecting the patients about their admissions to ICUs with hospital information. Each instance is a specific ICU stay. We follow the data pre-processing procedure in~\\citep{sheikhalishahi2019benchmarking} and naturally treat different hospitals as local clients. We conduct the task of predicting in-hospital mortality which is defined as the patient’s outcome at the hospital discharge. This is a binary classification task, where each data sample spans a 1-hour window. In this experiment, we select 5 hospitals with more patient samples (about 1000) $\\left\\{ I^{i} \\right\\}_{i=0}^{4}$ and 5 hospitals with less patient samples $\\left\\{ I^{i} \\right\\}_{i=5}^{9}$ (about 100). Due to label imbalance (more than 90\\% samples have negative labels), we use AUC to measure the utility for each client as in~\\citep{sheikhalishahi2019benchmarking}. We construct the hypernetwork by a 1-layer MLP for training the Pareto Front of all objectives. The target network is an ANN model following the work in ~\\citep{sheikhalishahi2019benchmarking}. For a fair comparison, we also use the same ANN in~\\citep{sheikhalishahi2019benchmarking} all baselines.\n\nThe model AUC of each hospital is reported in Table~\\ref{table:eicu}. Because of the lack of patient data for each hospital, Local achieves a relatively lower AUC compared to FedAve and SPO. For example, due to the severely insufficient data, the AUC of $I^{7}$ is very low (0.4), which indicates that there is a drastic shift between test distribution and training distribution. While patient populations vary substantially from hospital to hospital, SPO learns a personalized model for each hospital and outperforms FedAve from Table~\\ref{table:eicu}.\n\n\\paragraph{Collaboration Equilibrium}\n\\cui{The benefit graph of all hospitals determined by SPO and its corresponding strongly connected components are shown in Figure~\\ref{fig:eicu_bg} and~\\ref{fig:eicu_scc}. From Figure~\\ref{fig:eicu_bg}, $I^{0}$ and $I^{3}$ are the unique necessary collaborator for each other, $C^1 = \\left\\{I^{0}, I^{3} \\right\\}$ is the first identified stable coalition as shown in Figure~\\ref{fig:eicu_scc}; $I^{9}$ is a tiny clinic that cannot contribute to any hospitals, so no hospital is willing to collaborate with it and $I^{9}$ learns a local model with its own data by forming a simple coalition $C^{2} = \\left\\{I^{9} \\right\\}$. The benefit graph of the remaining clients are shown in Figure~\\ref{fig:eicu_scc}. On the one hand they cannot benefit $I^{3}$ or $I^{0}$ so they cannot form coalitions with them, on the other hand they refuse to contribute $I^{9}$ without any charge. They choose form the coalition $C^{3} = \\left\\{I^{1}, I^{2}, I^{4}, I^{5}, I^{6}, I^{7}, I^{8} \\right\\}$ to maximize their AUC. Therefore, the CE in this hospital collaboration network is achieved by the collaboration strategy $S = \\{C^{1}, C^{2}, C^{3} \\}$ and the model AUC of each client in the CE is in Table~\\ref{table:eicu}.}\n\n"
                }
            },
            "section 6": {
                "name": "Applications",
                "content": "\nOne cannot know which clients should collaborate with unless it knows the result of the collaboration. This requires that all clients agree to collaborate to obtain the results of the collaboration, before finalizing the collaboration equilibrium. The premise of achieving the collaboration equilibrium is that all clients agree to collaborate first to construct the benefit graph. In practice, this would be done by an impartial and authoritative third-party (e.g., the industry association) in the paradigm of federated learning. The approved third-party firstly determines the benefit graphs by learning the optimal models from multiple clients without direct access to the data of the local clients. Then the approved third-party derives the collaboration equilibrium based upon the benefit graphs and publishes the collaboration strategies of all clients.\n\nAs our framework quantifies the benefit and the contribution of each client in a collaborative network, on the one hand, this promotes a more equitable collaboration such as some big clients may no longer collaborate with small clients without any charge; on the other hand, it also leads to a more efficient collaboration as all clients will collaborate with the necessary collaborators rather than all participants.\n\\begin{acks}\nSen Cui, Weishen Pan and Changshui Zhang would like to acknowledge the funding by the National Key Research and Development Program of China (No. 2018AAA0100701). Kun Chen would like to acknowledge the support from the U.S. National Institutes of Health (R01-MH124740).\n\\end{acks}\n"
            },
            "section 7": {
                "name": "Conclusion",
                "content": "\nIn this paper, we propose a \\emph{learning to collaborate} framework to achieve collaboration equilibrium such that any of the individual clients cannot improve their performance further. Comprehensive experiments on benchmark and real-world data sets demonstrated the validity of our proposed framework. In our study, some small clients could be isolated as they cannot benefit others. Our framework can quantify both the benefit to and the contribution from each client in a network. In practice, such information can be utilized to either provide incentives or to impose charges on each client, to facilitate and enhance the foundation of the network or coalition.\n\n\\bibliographystyle{ACM-Reference-Format}\n\\bibliography{kdd_2022}\n\n\\clearpage\n\\appendix\n"
            },
            "section 8": {
                "name": "Proofs of all Theoretical Results",
                "content": "\n\n",
                "subsection 8.1": {
                    "name": "Proof of Theorem 1",
                    "content": "\nTo prove Theorem~\\ref{theorem:1}, we first prove that the benefit graph of a stable coalition is strongly connected shown in Lemma~\\ref{lemma:1}.\n\n\\begin{lemma}\nFor a given client set $\\bm{I}$, the benefit graph of each stable coalition $C^{s}$ is strongly connected, which means that there is a path in each direction between each pair of vertices in $BG(C^{s})$.\n\\label{lemma:1}\n\\end{lemma}\n\n\n\\begin{proof}\n\\label{proof:lemma1}\nWe will prove the Lemma~\\ref{lemma:1} by contradiction. Given a stable coalition $C^{s}$, suppose there exsits a pair of vertices $I^{1}, I^{2} \\in BG(C^{s})$ such that there is no path from $I^{1}$ to $I^{2}$, which is denoted as $\\nexists p, \\ \\text{s.t.,} \\ I^{1} \\rightarrow I^{2}$ for expressive clearly. We split $C^{s}$ into two sub-coalitions $C'$ and $C^{s} \\backslash C'$ depending on whether the clients have paths to $I^{2}$. The clients in $C'$ have no path to $I^{2}$, and the clients in $C^{s} \\backslash C'$ have paths to $I^{2}$.\n\\begin{equation}\n\\begin{aligned}\n& \\forall I^{i} \\in C', \\nexists p, \\ \\text{s.t.,} \\ I^{i} \\rightarrow I^{2} \\\\\n& \\forall I^{i} \\in C^{s} \\backslash C', \\exists p, \\ \\text{s.t.,} \\ I^{i} \\rightarrow I^{2}. \\\\\n\\end{aligned}\n\\end{equation}\nObviously, $C'$ and $C^{s} \\backslash C'$ are not empty because $I^{1} \\in C'$ and and $I^{2} \\in C^{s} \\backslash C'$. From Eq.(5) in the main text in the Definition of \\emph{stable coalition}, each client $I^{i} \\in C^{s}$ achieves its maximal utility by collaborating with others in $C^{s}$ which means that\n\n\\begin{equation}\n\\begin{aligned}\n\\forall I^{i} \\in C^{s}, \\ \\forall I^{j} \\in C^{opt}_{\\bm{I}}(I^{i}), \\ I^{j} \\in C^{s}.\n\\end{aligned}\n\\end{equation}\n\nFrom the Definition of \\emph{Optimal Collaborator Set} (OCS), each client $I^{i}$ in the OCS of $I^{2}$ has an edge from $I^{i}$ to $I^{2}$,\n\\begin{equation}\n\\begin{aligned}\n& \\forall I^{i} \\in C^{opt}_{\\bm{I}}(I^{2}), \\ \\exists p ,\\ \\text{s.t.,} \\ I^{i} \\rightarrow I^{2}, \\\\\n\\end{aligned}\n\\end{equation}\n\nTherefore, because each client $I^{i} \\in C^{opt}_{\\bm{I}}(I^{2})$ is in $C^{s} \\backslash C'$, $I^{2}$ can achieve its maximal utility in $C^{s} \\backslash C'$. Morever, we can prove that $I^{i} \\in C^{opt}_{\\bm{I}}(I^{2})$ achieves its maximal utiltiy in $C^{s} \\backslash C'$ because each client $I^{i} \\in C^{opt}_{\\bm{I}}(I^{2})$ and its corresponding OCS are in $C^{s} \\backslash C'$,\n\n\\begin{subequations}\n\\begin{align}\n& \\forall I^{i} \\in C^{opt}_{\\bm{I}}(I^{2}), \\ \\forall I^{j} \\in C^{opt}_{\\bm{I}}(I^{i}), \\ \\exists p, \\ I^{j} \\rightarrow I^{i}, \\label{eq:4-1}\\\\\n& \\forall I^{i} \\in C^{opt}_{\\bm{I}}(I^{2}), \\ \\exists p ,\\ \\text{s.t.,} \\ I^{i} \\rightarrow I^{2}, \\label{eq:4-2}\\\\\n& \\Rightarrow \\ \\forall I^{i} \\in C^{opt}_{\\bm{I}}(I^{2}), \\ \\forall I^{j} \\in C^{opt}_{\\bm{I}}(I^{i}), \\ \\exists p, \\ I^{j} \\rightarrow  I^{i} \\rightarrow I^{2}\n\\end{align}\n\\label{eq:4}\n\\end{subequations}\n\nFrom Eq.(\\ref{eq:4}), the clients in the OCS of $I^{i}$ ($ I^{i} \\in C^{opt}_{\\bm{I}}(I^{2})$) are in $C^{s} \\backslash C'$ and $I^{i}$ can achieve its optimal utility. Based on the same analysis, for each client $I^{i} \\in C^{s} \\backslash C'$, its OCS $C^{opt}_{\\bm{I}}(I^{i})$ is in $C^{s} \\backslash C'$ because all clients in $C^{opt}_{\\bm{I}}(I^{i})$ have a path to $I^{2}$. So we have the conclusion that all clients in $C^{s} \\backslash C'$ achieves its optimal utility by collaborating with others in $C^{s} \\backslash C'$. However, this contradicts Eq.(6) in the main text in the Definition of \\emph{stable coalition}. Therefore, we prove that the benefit graph $BG(C^{s})$ of the stable coalition $C^{s}$ is strongly connected as in Lemma~\\ref{lemma:1}.\n\\end{proof}\n\nFrom Lemma~\\ref{lemma:1}, the $BG(C^{s})$ is strongly connected, then we will prove that $BG(C^{s})$ is a strongly connected component of $BG(\\bm{I})$ by pointing out that $BG(C^{s})$ is maximal which means that no additional vertices from $\\bm{I}$ can be included in $BG(C^{s})$ without breaking the property of being strongly connected.\n\n\\begin{proof}\nWe will prove that $BG(C^{s})$ is maximal by contradiction. Suppose there is another client $I^{0} \\in \\bm{I} \\backslash C^{s}$ which can be added in $BG(C^{s})$ without breaking the property of being strongly connected. Therefore, there exists $I^{i} \\in C^{s}$ which has an edge from $I^{0}$ to $I^{i}$. This means that $I^{0}$ is one of the necessary collaborators of $I^{i}$ ($I^{0} \\in C^{opt}_{\\bm{I}}(I^{i})$) and $I^{0}$ cannot achieve its optimal utility in $C^{s}$ without collaborating with $I^{0}$. However, this contradicts Eq.(5) in the main text in the Definition of \\emph{stable coalition} that all clients in $C^{s}$ can achieve its optimal utility by collaborating with others in $C^{s}$. Therefore, we prove that $BG(C^{s})$ is a strongly connected component as stated in Theorem~\\ref{theorem:1}.\n\\end{proof}\n\n"
                },
                "subsection 8.2": {
                    "name": "Proof of Proposition 1",
                    "content": "\n\nFrom Algorithm~\\ref{alg:CE1}, firstly, we search for all strongly connected components (SCC) { $C^{1}, C^{2},...,C^{k}$}. From Definition~\\ref{def:scc}, these SCCs consist of a partition of all clients. For convenience, we group each SCC as a point in the benefit graph.\n\\begin{enumerate}\n    \\item Suppose all SCCs are not stable coalitions, this means that each SCC $C^{i}$ cannot achieve its optimal performance without the collaboration with clients in other SCCs;\n\n    \\item from (1), for each $C^{i}$, there exists at least an edge pointing to $C^{i}$ (since it needs other SCCs' help);\n\n    \\item from graph theory, if for each node $C^{i}$, there is an edge pointing to $C^{i}$, then there exists a loop in this graph.\n\n    \\item from (3), this loop means there is a larger SCC in the benefit graph, which contradicts the definition of SCC that SCC is maximal.\n\\end{enumerate}\nSo we prove that there always exists a $C^{i}$ that no edge points to, and such a SCC is a stable coalition.\n\nIn fact, the graph of SCCs is a directed acyclic graph and there always exists a node (SCC) that no edge points to (which is called \"head node\"). For example in Figure 1 (a), the graph of SCCs is $\\left\\{ I^{1}, I^{2}, I^{3} \\right\\} \\rightarrow \\left\\{ I^{4} \\right\\} \\rightarrow  \\left\\{I^{5}, I^{6} \\right\\}$, in which $\\left\\{ I^{1}, I^{2}, I^{3} \\right\\} $ is a stable coalition that no edge points to.\n\n% \\begin{table*}[h!] \\small\n%     \\setlength{\\belowcaptionskip}{3pt}\n%     \\centering\n%     \\caption{Full experimental results on eICU dataset.}\n%     \\begin{tabular}{cccccccccccc}%l=left, r=right,c=center分别代表左对齐，右对齐和居中，字母的个数代表列数\n%         \\toprule\n%         \\multirow{2}{*}{methods}  & \\multirow{2}{*}{ave}  &  \\multicolumn{10}{c}{AUC}  \\\\\n%         \\cline{3-12} \\\\\n%          & &$I^{0}$ &$I^{1}$ &$I^{2}$ &$I^{3}$ &$I^{4}$ &$I^{5}$ &$I^{6}$ &$I^{7}$ &$I^{8}$ &$I^{9}$  \\\\\n%         \\hline\n\n%         Local  & 66.44   &66.89 &85.03 &61.83 &68.83 &82.31 &59.65 &67.78 &40.00 &61.90 &70.00  \\\\\n%         FedAve  & 69.57 &71.92 &89.36 &81.00 &73.89 &80.23 &70.18 &52.22 &40.00 &61.90 &75.00  \\\\\n%         Per-FedAve & 68.82 &68.72 &89.82 &71.19 &72.70 &74.96 &68.42 &46.67 &45.00 &85.71 &65.00  \\\\\n%         FedPer &    72.53 &72.59 &87.74 &80.01 &56.37 &86.56 &94.74 &73.33 &15.00 &85.71 &73.33  \\\\\n%         pFedMe & 70.68 &76.21&89.31&76.30&68.17&87.50&82.46&84.44&10.00&52.38&80.00  \\\\\n%         LG-FedAve & 71.07 &74.70&88.80&76.37&66.45&86.40&82.46&83.33&15.00&57.14&80.00\\\\\n%         pFedHN  & 67.57  &57.29&76.15&84.67&52.01&66.95&45.61&57.78&70.00&95.24&70.00\\\\\n%         \\hline\n%         SPO (ours) &75.90 &76.35 &91.80 &80.28 &70.52 &86.93 &82.46 &71.11 &40.00 &76.19 &83.30  \\\\\n%         CE (ours)  &70.05    &77.93 &87.28 &70.47 &70.64 & 83.48 &64.92 & 68.89 & 45.00 & 61.90 & 70.00 \\\\\n% %       \\hline\n% %       CE        &77.93 &87.28 &70.47 &70.64 & 83.48 &64.92 & 68.89 & 45.00 & 61.90 & 70.00 \\\\\n%         \\bottomrule\n%     \\end{tabular}\n%     \\label{table:eicu_full}\n% \\end{table*}\n\n\n"
                },
                "subsection 8.3": {
                    "name": "Proof of Theorem 2",
                    "content": "\n\\begin{proof}\n\\textbf{1. All coalitions in $S = \\{C^0, C^{1}, ..., C^{k} \\}$ satisfies Inner Agreement as in Axiom 1.}\n\nAs each coalition $C^{i} \\in S$ is a stable coalition, from Eq.(6) of the Definition of \\emph{stable coalition}, we have\n\n\\begin{equation}\n\\forall C^{i} \\in S, \\ \\forall C' \\varsubsetneqq C^{i}, \\ \\exists I^{i} \\in C', \\ \\text{s.t.,} \\ U_{max}(I^{i}, C') < U_{max}(I^{i}, C^{i}).\n\\label{eq:ce1}\n\\end{equation}\n\nThen Eq.(\\ref{eq:ce1}) is the definition of \\emph{Inner Agreement} in Eq.(3) in the main text. Therefore, we prove that all collaboration coalitions in $S$ satisfy inner agreement.\n\n\\textbf{2. The collaboration strategy $S$ satisfies Outer Agreement as in Axiom 2.}\n\nWe will prove it by contradiction. Suppose there exists a new nonempty coalition $C' = \\{I^{i^{0}}, I^{i^{1}},..., I^{i^{k}} \\} \\notin S$ which satisfies\n\n\\begin{equation}\n\\forall I^{i} \\in C', \\ U_{max}(I^{i}, C') > U_{max}(I^{i}, C^{j}) \\ (I^{i} \\in C^{j} \\in S).\n\\label{eq:ce2}\n\\end{equation}\n\nSuppose that $C^{0}$ denotes the coalition in the first iteration. Then $\\forall I^{i} \\in C^{0}$, $I^{i}$ achieves its maximal utility in the client set $\\bm{I}$ and cannot increase its model utility further. So we have\n\n\\begin{equation}\n\\forall I^{i} \\in C', \\ I^{i} \\notin C^{0}.\n\\end{equation}\n\nThe clients in the coalition $C^{0} \\in S$ identified in the first iteration have no interest in collaborating with others and will be removed. Suppose $C^{1}$ denotes the coalition in the first iteration. $\\forall I^{i} \\in C^{1}$, $I^{i}$ achieves its maximal utility in the client set $\\bm{I} \\backslash C^{0}$ and cannot increase its model utility further. So we have\n\n\\begin{equation}\n\\forall I^{i} \\in C', \\ I^{i} \\notin C^{1}.\n\\end{equation}\n\nThen $C^{1}$ will be removed and we have $\\forall I^{i} \\in C', \\ I^{i} \\notin I^{2}.$. Based on the same analysis, we finally have\n\\begin{equation}\n\\begin{aligned}\n& \\forall I^{i} \\in C', \\ \\forall C^{j} \\in S, \\ I^{i} \\notin C^{j}, \\\\\n& \\Rightarrow C' = \\emptyset.\n\\end{aligned}\n\\end{equation}\n\nTherefore, we prove that there is no nonempty $C'$ satisfying Eq.(\\ref{eq:ce2}) and $S$ satisfies Outer Agreement.\n\\end{proof}\n\n\n"
                },
                "subsection 8.4": {
                    "name": "Proof of Proposition 2",
                    "content": "\n\\begin{proof}\nFor any hypothesis $h'^{*} \\in P(C')$, $h'^{*}$ satisfies\n\n\\begin{equation}\n\\nexists h^{\\prime} \\in \\mathcal{H}, \\text { s.t. } \\forall i \\in C': l_{i}\\left(h^{\\prime}\\right) \\leq l_{i}(h'^{*}) \\text { and } \\exists j: l_{j}\\left(h^{\\prime}\\right)<l_{j}(h'^{*}).\n\\label{eq:prop1}\n\\end{equation}\n\n% Suppose we define\n% \\begin{equation}\n% \\begin{aligned}\n% & \\bm{l''} = [l_{i}(h'^{*})], \\ i \\in C.\n% \\end{aligned}\n% \\label{eq:prop2}\n% \\end{equation}\n\n1) If $h^{*} \\in P(C)$ which satisfies\n\n\\begin{equation}\n\\nexists h^{\\prime} \\in \\mathcal{H}, \\text { s.t. } \\forall i \\in C: l_{i}\\left(h^{\\prime}\\right) \\leq l_{i}(h) \\text { and } \\exists j: l_{j}\\left(h^{\\prime}\\right)<l_{j}(h),\n\\label{eq:prop3}\n\\end{equation}\n\nthen we let $h^{*} = h'^{*}$ in Eq.(\\ref{eq:prop}) so Eq.(\\ref{eq:prop}) holds;\n\n2) if $h'^{*} \\notin P(C)$, there exists $h' \\in P(C)$ which satisfies\n\n\\begin{equation}\n\\forall i \\in C: l_{i}\\left(h^{\\prime}\\right) \\leq l_{i}(h'^{*}) \\text { and } \\exists j: l_{j}\\left(h^{\\prime}\\right)<l_{j}(h'^{*}),\n\\label{eq:prop4}\n\\end{equation}\n\ncombining Eq.(\\ref{eq:prop1}), we have\n\n\\begin{equation}\n\\forall i \\in C': l_{i}\\left(h^{\\prime}\\right) = l_{i}(h'^{*}) \\text { and } \\exists j \\in C \\backslash C': l_{j}\\left(h^{\\prime}\\right)<l_{j}(h'^{*}).\n\\end{equation}\nthen we let $h^{*} = h'$ in Eq.(\\ref{eq:prop}) so Eq.(\\ref{eq:prop}) holds.\n\\end{proof}\n\n"
                }
            },
            "section 9": {
                "name": "Implementation Details",
                "content": "\n\n",
                "subsection 9.1": {
                    "name": "Learning Pareto Front",
                    "content": "\nMulti-objective optimization (MOO) problems have a set of optimal solutions, and these optimal solutions form the Pareto front, where each point on the front represents a different trade-off among possibly conflicting objectives. We construct a personalized model for each client which we call target network and it has the same architecture as the baselines. To determine the parameters of the target network of each client, in our experiments, we learn the entire Pareto Front simultaneously using a hypernetwork which receives as input a vector $\\bm{d}$ and returns all parameters of the target network. The input vector is N-dimension $\\bm{d}$ in which each entry $d^{i}$ corresponds to the client $I^{i}$ and is sampled from the convex hull $\\mathcal{D}$,\n\\begin{equation}\n\\mathcal{D} = \\left\\{ d, | \\forall i, 1\\leq i \\leq N, d^{i} \\geq 0, \\ \\text{and} \\ \\sum_{i = 1}^{N} d^{i} = 1 \\right\\}.\n\\end{equation}\nSpecifically, we construct the hypernetwork following in the architecture introduced in ~\\citep{navon2020learning}. By a n-layer ($n \\leq 3$) MLP network with the activation function ReLU, we infer the parameters of the target network. Then the obtained parameters will be assigned to the target network. We evaluate the performance of the parameters on the training set and the gradient information will be returned for updating the hypernetwork.\n\n"
                },
                "subsection 9.2": {
                    "name": "Identifying the Optimal Collaborator Set",
                    "content": "\nFrom the statement above, we train a hypernetwork $HN$ for learning the whole Pareto front. $HN$ bridges the mapping from the vector $\\bm{d}$ to the corresponding model parameters of the target network. To obtain the optimal target network parameters that achieve the minimal value loss of the target objective on the validation set, we optimize the vector $\\bm{d}$ by gradient descent. Specifically, given an initial direction $d_{0}$, we firstly obtain the parameters of the target network using the learned hypernetwork $HN(d_{0})$. Like training the hypernetwork, the obtained parameters will be assigned to the target network. Then we evaluate the performance of the generated parameters on the validation set and compute the gradient of the input direction $d_{0}$. Finally, the gradient information will be used for updating the vector $\\bm{d}$ iteratively until convergence.\n\\begin{equation}\n\\begin{aligned}\n& d_{i+1} = d_{i} - \\eta \\cdot \\nabla_{d_{i}} l^{*} \\\\\n& d_{i+1} \\leftarrow Clip(d_{i+1}) \\\\\n& d_{i+1} \\leftarrow Normalization(d_{i+1}),\n\\end{aligned}\n\\end{equation}\nwhere $\\eta$ denotes the learning rate, $Clip(d_{i+1})$ means that we clip each values $ d^{j}_{i+1} \\in d_{i+1}$ to satisfy $\\epsilon_{0} \\leq d^{j}_{i+1} \\leq 1 $ and $Normalization(d_{i+1})$ is as follows,\n\\begin{equation}\n\\begin{aligned}\n\\forall j\\ (1 \\leq j \\leq N),  d'^{j}_{i+1} = \\frac{d^{j}_{i+1}}{\\sum_{j = 1}^{N} d^{j}_{i+1}}.\n\\end{aligned}\n\\end{equation}\nFinally, we reach the optimal direction $d^{*}$ and its corresponding Pareto model $M^{*} = HN(d^{*})$.\n\nFor each client, we determine the optimal collaborator set by the optimal direction $d^{*}$ and the loss value of all objectives $\\bm{l} = [l_{1}(M^{*}), l_{2}(M^{*}), ..., l_{N}(M^{*})]$. From the Pareto Front Embedded property described in Proposition~\\ref{prop:embed-pt}, an ideal direction $d^{*}$ is a sparse vector in which the indexes of the non-zero values in $d^{*}$ are the necessary collaborators for the target client. In our experiments, $d^{*}$ usually is not a sparse vector, but there are values in $d^{*}$ which are significantly small. Therefore, we set a threshold $\\epsilon$ for $d^{*}$ to determine which clients are necessary/unnecessary.\n\n"
                },
                "subsection 9.3": {
                    "name": "Datasets and Training Resources",
                    "content": "\nIn our experiments, UCI adult~\\cite{kohavi1996scaling} and CIFAR10~\\cite{krizhevsky2009learning} are public datasets. eICU~~\\cite{pollard2018eicu} is a dataset for which permission is required. We followed the procedure on the website \\url{https://eicu-crd.mit.edu} and got the approval to the dataset.\n\nWe run our experiments on a local Linux server that has two physical CPU chips (Inter(R) Xeon(R) CPU E5-2640 v4 @ 2.40GHz) and 32 logical kernels. We use Pytorch framework to implement our model and train all models on GeForce RTX 2080 Ti GPUs.\n\n\n"
                }
            }
        },
        "tables": {
            "table:synthetic": "\\begin{table}[htbp]\n\\setlength{\\abovecaptionskip}{-0pt}\n\\centering\n\\caption{synthetic}\n\\begin{tabular}{lllll}\n\\toprule\n\\multirow{2}{*}{I} & \\multicolumn{2}{c}{$n = 2000, \\rho = 0.1$} & \\multicolumn{2}{c}{$n = 20000, \\rho = 1.0$} \\\\\n\\cline{2-3}\n\\cline{4-5}\n        & OCS                                  & CE (MSE)   & OCS                    &  CE (MSE)  \\\\\n\\hline\n$I^{0}$ &$\\left\\{I^{0}, I^{1}, I^{2} \\right\\}$ & 0.24±0.08 & $\\left\\{I^{0}\\right\\}$ & 1e-4±.0\\\\\n$I^{1}$ &$\\left\\{I^{0}, I^{1}, I^{2} \\right\\}$ & 0.26±0.08 & $\\left\\{I^{1}\\right\\}$ & 1e-4±.0\\\\\n$I^{2}$ &$\\left\\{I^{0}, I^{1}, I^{2} \\right\\}$ & 0.24±0.04 & $\\left\\{I^{2}\\right\\}$ & 1e-4±.0\\\\\n$I^{3}$ &$\\left\\{I^{3}, I^{4}, I^{5} \\right\\}$ & 0.26±0.07 & $\\left\\{I^{3}\\right\\}$ & 1e-4±.0\\\\\n$I^{4}$ &$\\left\\{I^{3}, I^{4}, I^{5} \\right\\}$ & 0.26±0.09 & $\\left\\{I^{4}\\right\\}$ & 1e-4±.0\\\\\n$I^{5}$ &$\\left\\{I^{3}, I^{4}, I^{5} \\right\\}$ & 0.26±0.03 & $\\left\\{I^{5}\\right\\}$ & 1e-4±.0\\\\\n\\bottomrule\n\\end{tabular}\n\\label{table:synthetic}\n\\end{table}",
            "table:eicu": "\\begin{table*}[htbp]\n\\setlength{\\abovecaptionskip}{-0pt}\n\\centering\n\\caption{eICU}\n\\begin{tabular}{ccccccccccc}%l=left, r=right,c=center分别代表左对齐，右对齐和居中，字母的个数代表列数\n\\toprule\n\\multirow{2}{*}{methods} & \\multicolumn{10}{c}{AUC}  \\\\\n\\cline{2-11} \\\\\n       &$I^{0}$ &$I^{1}$ &$I^{2}$ &$I^{3}$ &$I^{4}$ &$I^{5}$ &$I^{6}$ &$I^{7}$ &$I^{8}$ &$I^{9}$  \\\\\n\\hline\nLocal     &66.89 &85.03 &61.83 &68.83 &82.31 &59.65 &67.78 &40.00 &61.90 &70.00  \\\\\nFedAve    &71.92 &89.36 &\\textbf{81.00} &\\textbf{73.89} &80.23 &70.18 &52.22 &40.00 &61.90 &75.00  \\\\\nSPO (ours) &\\textbf{76.35} &\\textbf{91.80} &80.28 &70.52 &\\textbf{86.93} &\\textbf{82.46} &\\textbf{71.11} &\\textbf{40.00} &\\textbf{76.19} &\\textbf{83.33}  \\\\\n\\hline\nCE (ours)      &77.93 &87.28 &70.47 &70.64 & 83.48 &64.92 & 68.89 & 45.00 & 61.90 & 70.00 \\\\\n\\bottomrule\n\\end{tabular}\n\\label{table:eicu}\n\\end{table*}"
        },
        "figures": {
            "fig:intro": "\\begin{figure*}[h!]\n    \\centering{\n    \\includegraphics[width=2.0\\columnwidth]{figures/intro.pdf}}\n    \\caption{(a) The benefit graph on all clients; (b) Finding all stable coalitions and remove them; (c) \\sen{reconstruct the benefit graph on the remaining clients; after $I^{3}$ is removed, $I^{4}$ re-identifies its necessary collaborators in $\\left\\{ I^{4}, I^{5}, I^{6} \\right\\}$  which is $\\{I^{5} \\}$ as the added the red arrow from $I^{5}$ to $I^{4}$ in the figure}; (d) iterate (b) and (c) until achieving collaboration equilibrium.}\n    \\label{fig:intro}\n\\end{figure*}",
            "fig:example2": "\\begin{figure}[h!]\n    \\centering{\n    \\includegraphics[width=0.7\\columnwidth]{figures/exp2.pdf}}\n    \\caption{Forming coalitions for maximizing the local utility.}\n    \\label{fig:example2}\n\\end{figure}",
            "fig:spo": "\\begin{figure*}[h!]\n    \\setlength{\\abovecaptionskip}{-0.1cm}\n    \\setlength{\\belowcaptionskip}{-0.1cm}\n    \\centering{\n    \\includegraphics[width=1.9\\columnwidth]{figures/spo.pdf}}\n    \\caption{(a) the loss plane of $P(\\left\\{l_{1}, l_{2}, l_{3} \\right\\})$ learned from training data of $\\left\\{I^{1}, I^{2}, I^{3}\\right\\}$; (b) the loss curve of $P(\\left\\{l_{1}, l_{2} \\right\\})$ learned from training data of $\\left\\{I^{1}, I^{2}\\right\\}$ is embedded in the loss plane of $P(\\left\\{l_{1}, l_{2}, l_{3} \\right\\})$; $d_{1},d_{2},.,d_{4}$ are 4 vectors corresponding to 4 Pareto models in $P(\\left\\{l_{1}, l_{2} \\right\\})$; (3) the performances of the models $h \\in P(\\left\\{l_{1}, l_{2} \\right\\})$ on true (testing) distributions and $h_{1}^{*}$ ($h_{2}^{*}$) achieves the optimal performance on client $I^{1}$ ($I^{2}$) corresponding to $d_{3}$ ($d_{2}$) in (b).}\n    \\label{fig:spo}\n\\end{figure*}",
            "fig:syn_bg": "\\begin{figure}[h!]\n    \\centering{\n    \\includegraphics[width=0.8\\columnwidth]{figures/syn_bg.pdf}}\n    \\caption{The true benefit graph by exhaustive trying}\n    \\label{fig:syn_bg}\n\\end{figure}",
            "fig:syn-equ": "\\begin{figure*}[h!]\n\\setlength{\\abovecaptionskip}{-3pt}\n\\setlength{\\belowcaptionskip}{-3pt}\n    \\centering{\n    \\includegraphics[width=1.8\\columnwidth]{figures/synthetic_equilibrium1.pdf}}\n    \\caption{Collaboration equilibrium on synthetic data, Adult and CIFAR10.}\n    \\label{fig:syn-equ}\n\\end{figure*}",
            "fig:eicu": "\\begin{figure*}[h!]\n  \\centering\n  \\subfigure[benefit graph]{\n    \\centering\n    \\includegraphics[width=0.5\\columnwidth]{figures/eicu_bg.pdf}\n    \\label{fig:eicu_bg}\n  }%\n  \\hskip 0.5in\n  \\subfigure[strongly connected components of (a)]{\n    \\centering\n    \\includegraphics[width=0.5\\columnwidth]{figures/eicu_stable.pdf}\n    \\label{fig:eicu_scc}\n  }%\n  \\hskip 0.5in\n  \\subfigure[collaboration equilibrium]{\n    \\centering\n    \\includegraphics[width=0.5\\columnwidth]{figures/eicu_ce.pdf}\n    \\label{fig:eicu_ce}\n  }%\n  \\caption{Collaboration Equilibrium of 10 real hospitals}\n  \\label{fig:eicu}\n\\end{figure*}"
        },
        "equations": {
            "eq:1": "\\begin{equation}\n\\mathcal{D} = \\left\\{ d, | \\forall i, 1\\leq i \\leq N, d^{i} \\geq 0, \\ \\text{and} \\ \\sum_{i = 1}^{N} d^{i} = 1 \\right\\}.\n\\end{equation}",
            "eq:2": "\\begin{equation}\n\\begin{aligned}\n& d_{i+1} = d_{i} - \\eta \\cdot \\nabla_{d_{i}} l^{*} \\\\\n& d_{i+1} \\leftarrow Clip(d_{i+1}) \\\\\n& d_{i+1} \\leftarrow Normalization(d_{i+1}),\n\\end{aligned}\n\\end{equation}",
            "eq:3": "\\begin{equation}\n\\begin{aligned}\n\\forall j\\ (1 \\leq j \\leq N),  d'^{j}_{i+1} = \\frac{d^{j}_{i+1}}{\\sum_{j = 1}^{N} d^{j}_{i+1}}.\n\\end{aligned}\n\\end{equation}"
        },
        "git_link": "https://github.com/cuis15/learning-to-collaborate"
    }
}