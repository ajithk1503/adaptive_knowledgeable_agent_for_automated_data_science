{
    "meta_info": {
        "title": "DCdetector: Dual Attention Contrastive Representation Learning for Time  Series Anomaly Detection",
        "abstract": "Time series anomaly detection is critical for a wide range of applications.\nIt aims to identify deviant samples from the normal sample distribution in time\nseries. The most fundamental challenge for this task is to learn a\nrepresentation map that enables effective discrimination of anomalies.\nReconstruction-based methods still dominate, but the representation learning\nwith anomalies might hurt the performance with its large abnormal loss. On the\nother hand, contrastive learning aims to find a representation that can clearly\ndistinguish any instance from the others, which can bring a more natural and\npromising representation for time series anomaly detection. In this paper, we\npropose DCdetector, a multi-scale dual attention contrastive representation\nlearning model. DCdetector utilizes a novel dual attention asymmetric design to\ncreate the permutated environment and pure contrastive loss to guide the\nlearning process, thus learning a permutation invariant representation with\nsuperior discrimination abilities. Extensive experiments show that DCdetector\nachieves state-of-the-art results on multiple time series anomaly detection\nbenchmark datasets. Code is publicly available at\nhttps://github.com/DAMO-DI-ML/KDD2023-DCdetector.",
        "author": "Yiyuan Yang, Chaoli Zhang, Tian Zhou, Qingsong Wen, Liang Sun",
        "link": "http://arxiv.org/abs/2306.10347v2",
        "category": [
            "cs.LG",
            "cs.AI"
        ],
        "additionl_info": "Accepted by ACM SIGKDD International Conference on Knowledge  Discovery & Data Mining (KDD 2023)"
    },
    "latex_extraction": {
        "content": {
            "section 1": {
                "name": "Introduction",
                "content": "\n\nTime series anomaly detection is widely used in real-world applications, including but not limited to industrial equipment status monitoring, financial fraud detection, fault diagnosis, and daily monitoring and maintenance of automobiles~\\cite{cook2019anomaly,ren2019time,anandakrishnan2018anomaly,golmohammadi2015time,yang2021early}. \nWith the rapid development of different sensors, large-scale time series data has been collected during the system's running time in many different applications~\\cite{wen2022robust, li2021block, yang2023sgdp}. Effectively discovering abnormal patterns in systems is crucial to ensure security and avoid economic losses~\\cite{yang2021pipeline}. For example, in the energy industry, detecting anomalies in wind turbine sensors in time helps to avoid catastrophic failure. In the financial industry, detecting fraud is essential for reducing pecuniary loss. \n\nHowever, it is challenging to discover abnormal patterns from a mass of complex time series. Firstly, it is still being determined what the anomalies will be like. Anomaly is also called outlier or novelty, which means observation unusual, irregular, inconsistent, unexpected, rare, faulty, or simply strange depending on the situation~\\cite{ruff2021unifying}. Moreover, the typical situation is usually complex, which makes it harder to define what is unusual or unexpected. For instance, the wind turbine works in different patterns with different weather situations. Secondly, anomalies are usually rare, so it takes work to get labels~\\cite{yang2021long}. Most supervised or semi-supervised methods fail to work given limited labeled training data. Third, anomaly detection models should consider temporal, multidimensional, and non-stationary features for time series data~\\cite{yang2021pipeline2}. \nMultidimensionality describes that there is usually a dependence among dimensions in multivariate time series, and non-stationarity means the statistical features of time series are unstable. Specifically, temporal dependency means the adjacent points have latent dependence on each other. Although every point should be labeled as normal or abnormal, it is not reasonable to consider a single point as a sample. \n\n\nResearchers have designed various time-series anomaly detection methods to deal with these challenges. They can be roughly classified as statistical, \nclassic machine learning, and deep learning-based methods~\\cite{blazquez2021review,ruff2021unifying}. Machine learning methods, especially deep learning-based methods, have succeeded greatly due to their powerful representation advantages. Most of the supervised and semi-supervised methods~\\cite{zhang2022tfad,chauhan2015anomaly,chen2021learning,park2018multimodal,niu2020lstm,zhao2020multivariate} can not handle the challenge of limited labeled data, especially the anomalies are dynamic and new anomalies never observed before may occur. \nUnsupervised methods are popular without strict requirements on labeled data, including one class classification-based, probabilistic-based, distance-based, forecasting-based, reconstruction-based approaches~\\cite{deng2021graph,zong2018deep,su2019robust,li2022learning,campos2021unsupervised,zamanzadeh2022deep,ruff2021unifying}. \n\nReconstruction-based methods learn a model to reconstruct normal samples, and thereby the instances \\emph{failing} be reconstructed by the learned model are anomalies. Such an approach is developing rapidly due to its power in handling complex data by combining it with different machine learning models and its interpretability that the instances behave unusually abnormally.\nHowever, it is usually challenging to learn a well-reconstructed model for normal data without being obstructed by anomalies. The situation is even worse in time series anomaly detection as the number of anomalies is unknown, and normal and abnormal points may appear in one instance, making it harder to learn a clean, well-reconstructed model for normal points. \n\nRecently, contrastive representative learning has attracted attention due to its diverse design and outstanding performance in downstream tasks in the computer vision field~\\cite{ye2019unsupervised,he2020momentum,chen2020simple,caron2020unsupervised}. However, the effectiveness of contrastive representative learning still needs to be explored in the time-series anomaly detection area. In this paper, we propose a \\textbf{D}ual attention \\textbf{C}ontrastive representation learning anomaly \\textbf{detector} called \\textbf{DCdetector} to handle the challenges in time series anomaly detection.\nThe key idea of our DCdetector is that normal time series points share the latent pattern, which means normal points have strong correlations with other points. In contrast, the anomalies do not (\\emph{i.e.}, weak correlations with others). Learning consistent representations for anomalies from different views will be hard but easy for normal points. The primary motivation is that if normal and abnormal points' representations are distinguishable, we can detect anomalies without a highly qualified reconstruction model. \n\n\nSpecifically, we propose a contrastive structure with two branches and a dual attention module, and two branches share network weights. This model is trained based on the similarity of two branches, as normal points are the majority. The representation inconsistency of anomaly will be conspicuous. Thus, the representation difference between normal and abnormal data is enlarged without a highly qualified reconstruction model. \nTo capture the temporal dependency in time series, DCdetector utilizes patching-based attention networks as the basic module. A multi-scale design is proposed to reduce information loss during patching. DCdetector takes all channels into representation efficiently with a channel independence design for multivariate time series. \nIn particular, DCdetector does not require prior knowledge about anomalies and thus can handle new outliers never observed before. The main contributions of our DCdetector are summarized as follows:\n\n\n\n\n\\begin{itemize}\n    \\item Architecture: A contrastive learning-based dual-branch attention structure is designed to learn a permutation invariant representation that enlarges the representation differences between normal points and anomalies. Also, channel independence patching is proposed to enhance local semantic information in time series. Multi-scale is proposed in the attention module to reduce information loss during patching. \n    \\item Optimization: An effective and robust loss function is designed based on the similarity of two branches. Note that the model is trained purely contrastively without reconstruction loss, which reduces distractions from anomalies. \n    \\item Performance \\& Justification: DCdetector achieves performance comparable or superior to state-of-the-art methods on seven multivariate and one univariate time series anomaly detection benchmark datasets. We also provide justification discussion to explain how our model avoids collapse without negative samples.\n\n\\end{itemize} \n"
            },
            "section 2": {
                "name": "Related Work",
                "content": "\nIn this section, we show the related literature for this work. The relevant works include anomaly detection and contrastive representation learning.\n\\paragraph{Time Series Anomaly Detection}\n\n\n\nThere are various approaches to detect anomalies in time series, including statistical methods, classical machine learning methods, and deep learning methods~\\cite{schmidl2022anomaly}. Statistical methods include using moving averages, exponential smoothing~\\cite{phillips2015business}, and the autoregressive integrated moving average (ARIMA) model~\\cite{box1970distribution}. Machine learning methods include clustering algorithms such as k-means~\\cite{kant2019time} and density-based methods, as well as classification algorithms such as decision trees~\\cite{liu2008isolation,karczmarek2020k} and support vector machines (SVMs).\nDeep learning methods include using autoencoders, variational autoencoders (VAEs)~\\cite{sakurada2014anomaly,park2018multimodal}, and recurrent neural networks (RNNs)~\\cite{canizo2019multi,su2019robust} such as long short-term memory (LSTM) networks~\\cite{zamanzadeh2022deep}. Recent works in time series anomaly detection also include generative adversarial networks (GANs) based methods~\\cite{li2019mad,zhou2019beatgan,chen2021daemon,chen2021daemon} and deep reinforcement learning (DRL) based methods~\\cite{yu2020policy,huang2018towards}. In general, deep learning methods are more effective in identifying anomalies in time series data, especially when the data is high-dimensional or non-linear.\n\nIn another view, time series anomaly detection models can be roughly divided into two categories: supervised and unsupervised anomaly detection algorithms. Supervised methods can perform better when the anomaly label is available or affordable. Such methods can be dated back to AutoEncoder~\\cite{sakurada2014anomaly}, LSTM-VAE~\\cite{park2018multimodal}, Spectral Residual (SR)~\\cite{ren2019time}, RobustTAD~\\cite{jingkun20_TAD} and so on. On the other hand, an unsupervised anomaly detection algorithm can be applied in cases where the anomaly labels are difficult to obtain. Such versatility results in the community's long-lasting interest in developing new unsupervised time-series anomaly detection methods, including DAGMM~\\cite{zong2018deep}, OmniAnomaly~\\cite{su2019robust}, GDN~\\cite{deng2021graph}, RDSSM~\\cite{li2022learning} and so on. \nUnsupervised deep learning methods have been widely studied in time series anomaly detection. The main reasons are as follows. First, it is usually hard or unaffordable to get labels for all time series sequences in real-world applications. Second, deep models are powerful in representation learning and have the potential to get a decent detection accuracy under the unsupervised setting. Most of them are based on a reconstruction approach where a well-reconstructed model is learned for normal points; Then, the instances failing to be reconstructed are anomalies. \nRecently, some self-supervised learning-based methods have been proposed to enhance the generalization ability in unsupervised anomaly detection~\\cite{zhao2020multivariate, jiao2022timeautoad, zhang2022adaptive}. \n\n\n\\paragraph{Contrastive Representation Learning}\nThe goal of contrastive representation learning is to learn an embedding space in which similar data samples stay close to each other while dissimilar ones are far apart. The idea of contrastive learning can be traced back to InstDic~\\cite{wu2018unsupervised}. Classical contrastive models create <positive, negative> sample pairs to learn a representation where positive samples are near each other (pulled together) and far from negative samples (pushed apart)~\\cite{ye2019unsupervised,he2020momentum,chen2020simple,caron2020unsupervised}. Their key designs are about how to define negative samples and deal with the high computation power/large batches requirements~\\cite{khan2022contrastive}. On the other hand, BYOL~\\cite{grill2020bootstrap} and SimSiam~\\cite{chen2021exploring} get rid of negative samples involved, and such a simple siamese model (SimSiam) achieves comparable performance with other state-of-the-art complex architecture.\n\nIt is illuminating to make the distance of two-type samples larger using contrastive design. We try to distinguish time series anomalies and normal points with a well-designed multi-scale patching-based attention module. Moreover, our DCdetector is also free from negative samples and does not fall into a trivial solution even without the \"stop gradient\". \n\n\n"
            },
            "section 3": {
                "name": "Methodology",
                "content": "\n\nConsider a multivariate time-series sequence of length T: $$ {\\mathcal{X} = (x_1, x_2, \\ldots, x_T),} $$\n\n\\noindent where each data point $x_t \\in {\\rm I\\!R}^d$ is acquired at a certain timestamp $t$ from industrial sensors or machines, and $d$ is the data dimensionality, e.g., the number of sensors or machines. Our problem can be regarded as given input time-series sequence $\\mathcal{X}$, for another unknown test sequence $\\mathcal{X}_{test}$ of length $T'$ with the same modality as the training sequence, we want to predict $\\mathcal{Y}_{test} = (y_1,y_2,\\ldots,y_{T'})$. Here $y_t \\in \\{0,1\\}$ where 1 denotes an anomalous data point and 0 denotes a normal data point.\n\n\nAs mentioned previously, representation learning is a powerful tool to handle the complex pattern of time series. Due to the high cost of gaining labels in practice, unsupervised and self-supervised methods are more popular. The critical issue in time series anomaly detection is to distinguish anomalies from normal points. Learning representations that demonstrate wide disparities without anomalies is promising. We amplify the advantages of contrastive representation learning with a dual attention structure. \n\nIn some way, the underlining inductive bias we used here is similar to what Anomaly Transformer explored~\\cite{xu2021anomaly}. That is, anomalies have less connection or interaction with the whole series than their adjacent points. The Anomaly Transformer detects anomalies by association discrepancy between a learned Gaussian kernel and attention weight distribution. In contrast, we proposed DCdetector, which achieves a similar goal in a much more general and concise way with a dual-attention self-supervised contrastive-type structure. \n\nTo better position our work in the landscape of time series anomaly detection, we give a brief comparison of three approaches. To be noticed, Anomaly Transformer is a representation of a series of explicit association modeling works~\\cite{cheng2009detection,Zhao2020MultivariateTA,Deng2021GraphNN,Boniol2020Series2GraphGS}, not implying it is the only one. We merely want to make a more direct comparison with the closest work here.  Figure~\\ref{fig:art-compare} shows the architecture comparison of three approaches. The reconstruction-based approach (Figure~\\ref{fig:art-compare}(a)) uses a representation neural network to learn the pattern of normal points and do reconstruction. Anomaly Transformer (Figure~\\ref{fig:art-compare}(b)) takes advantage of the observation that it is difficult to build nontrivial associations from abnormal points to the whole series. Thereby, the prior discrepancy is learned with Gaussian Kernel and the association discrepancy is learned with a transformer module. MinMax association learning is also critical for Anomaly Transformer and reconstruction loss is contained. In contrast, the proposed DCdetector (Figure~\\ref{fig:art-compare}(c)) is concise, in the sense that it does not need a specially designed Gaussian Kernel, a MinMax learning strategy, or a reconstruction loss. The DCdetector mainly leverages the designed contrastive learning-based dual-branch attention for discrepancy learning of anomalies in different views to enlarge the differences between anomalies and normal points. The simplicity and effectiveness contribute to DCdetector’s versatility.\n\n\n\n\n\n\n\n",
                "subsection 3.1": {
                    "name": "Overall Architecture",
                    "content": "\nFigure~\\ref{fig:workflow} shows the overall architecture of the DCdetector, which consists of four main components, Forward Process module, Dual Attention Contrastive Structure module, Representation Discrepancy module, and Anomaly Criterion module.\n\nThe input multivariate time series in the Forward Process module is normalized by an instance normalization~\\cite{kim2021reversible,ulyanov2017improved} module. The inputs to the instance normalization all come from the independent channels themselves. It can be seen as a consolidation and adjustment of global information, and a more stable approach to training processing. Channel independence assumption has been proven helpful in multivariate time series forecasting tasks~\\cite{salinas2020deepar,li2019enhancing} to reduce parameter numbers and overfitting issues. Our DCdetector follows such channel independence setting to simplify the attention network with patching. \n\nMore specifically, the basic patching attention with channel independence is shown in Figure~\\ref{fig:patch}. Each channel in the multivariate time series input ($\\mathcal{X}\\in {\\rm I\\!R}^{T\\times d}$) is considered as a single time series ($\\mathcal{X}^{i}\\in {\\rm I\\!R}^{T\\times 1}, i = 1,2,\\dots, d$) and divided into patches. Each channel shares the same self-attention network, and the representation results ($\\mathcal{X}'^{i}\\in {\\rm I\\!R}^{N\\times 1}, i = 1,2,\\dots, d$) is concatenated as the final output ($\\mathcal{X}'\\in {\\rm I\\!R}^{N\\times d}$). \nIn the implementation phase, running a sliding window in time series data is widely used in time series anomaly detection tasks~\\cite{shen2020timeseries,xu2021anomaly} and has little influence on the main design. More implementation details are left in the experiment section.\n\n\n\n\n\nThe Dual Attention Contrastive Structure module is critical in our design. It learns the representation of inputs in different views. The insight is that, for normal points, most of them will share the same latent pattern even in different views (a strong correlation is not easy to be destroyed). However, as anomalies are rare and do not have explicit patterns, it is hard for them to share latent modes with normal points or among themselves (\\emph{i.e.}, anomalies have a weak correlation with other points). Thus, the difference will be slight for normal point representations in different views and large for anomalies. We can distinguish anomalies from normal points with a well-designed Representation Discrepancy criterion. The details of Dual Attention Contrastive Structure and Representation Discrepancy are left in the following Section~\\ref{sec:dacs} and Section~\\ref{sec:rd}.\n\nAs for the Anomaly Criterion, we calculate anomaly scores based on the discrepancy between the two representations and use a prior threshold for anomaly detection. The details are left in Section~\\ref{sec:ac}.\n\n\n\n"
                },
                "subsection 3.2": {
                    "name": "Dual Attention Contrastive Structure",
                    "content": "\\label{sec:dacs}\n\n\nIn DCdetector, we propose a contrastive representation learning structure with dual attention to get the representations of input time series from different views. Concretely, with the patching operation, DCdetector takes patch-wise and in-patch representations as two views. Note that it differs from traditional contrastive learning, where original and augmented data are considered as two views of the original data. Moreover, DCdetector does not construct <positive, negative> pairs like the typical contrastive methods~\\cite{wu2018unsupervised,he2020momentum}. Instead, its basic setting is similar to the contrastive methods only using positive samples~\\cite{chen2021exploring,grill2020bootstrap}.\n\n",
                    "subsubsection 3.2.1": {
                        "name": "Dual Attention",
                        "content": "\nAs shown in Figure~\\ref{fig:workflow}, input time series $\\mathcal{X}\\in{\\rm I\\!R}^{T\\times d}$ are patched as $\\mathcal{X}\\in {\\rm I\\!R}^{P \\times N \\times d}$ where $P$ is the size of patches and $N$ is the number of patches. Then, we fuse the channel information with the batch dimension and the input size becomes $\\mathcal{X}\\in {\\rm I\\!R}^{P \\times N}$. With such patched time series, DCdetector learns representation in patch-wise and in-patch views with self-attention networks. Our dual attention can be encoded in $L$ layers, so for simplicity, we only use one of these layers as an example.\n\nFor the patch-wise representation, a single patch is considered as a unit, and the dependencies among patches are modeled by a multi-head self-attention network (named patch-wise attention). In detail, an embedded operation will be applied in the patch\\_size ($P$) dimension, and the shape of embedding is $\\mathcal{X_N}\\in {\\rm I\\!R}^{N \\times d_{model}}$. Then, we adopt multi-head attention weights to calculate the patch-wise representation. Firstly, initialize the query and key: \n\\begin{equation}\\label{eq1}\n    \\mathcal{Q_N}_i, \\mathcal{K_N}_i = \\mathcal{W_{Q}}_i \\mathcal{X_{N}}_i, \\mathcal{W_{K}}_i \\mathcal{X_{N}}_i \\quad 1 \\leq i \\leq H,\n\\end{equation}\nwhere $\\mathcal{Q_{N}}_i, \\mathcal{K_{N}}_i \\in {\\rm I\\!R}^{N \\times \\frac{d_{model}}{H}}$ denote the query and key, respectively, $\\mathcal{W_{Q}}_i, \\mathcal{W_{K}}_i \\in {\\rm I\\!R}^{\\frac{d_{model}}{H} \\times \\frac{d_{model}}{H}}$ represent learnable parameter matrices of $\\mathcal{Q_{N}}_i, \\mathcal{K_{N}}_i$, and $H$ is the head number. Then, compute the attention weights: \n\\begin{equation}\\label{eq2}\n    Attn_{\\mathcal{N}_i} = Softmax(\\frac{\\mathcal{Q_{N}}_i \\mathcal{K_{N}}_i^T}{\\sqrt{\\frac{d_{model}}{H}}}),\n\\end{equation}\nwhere $Softmax(\\cdot)$ function normalizes the attention weight. Finally, contact the multi-head and get the final patch-wise representation $Attn_\\mathcal{N}$, which is: \n\\begin{equation}\\label{eq3}\n    Attn_{\\mathcal{N}} = \\text{Concat}(Attn_{\\mathcal{N}_1},\\cdots, Attn_{\\mathcal{N}_H}) W_\\mathcal{N}^{O},\n\\end{equation}\nwhere $W_\\mathcal{N}^{O} \\in {\\rm I\\!R}^{d_{model} \\times d_{model}}$ is a learnable parameter matrix.\n\n\n\n\nSimilarly, for the in-patch representation, the dependencies of points in the same patch are gained by a multi-head self-attention network (called in-patch attention). Note that the patch-wise attention network shares weights with the in-patch attention network. Specifically, another embedded operation will be applied in the patch\\_number ($N$) dimension, and the shape of embedding is $\\mathcal{X_P}\\in {\\rm I\\!R}^{P \\times d_{model}}$. Then, we adopt multi-head attention weights to calculate the in-patch representation. First, initialize the query and key: \n\\begin{equation}\\label{eq4}\n    \\mathcal{Q_P}_i, \\mathcal{K_P}_i = \\mathcal{W_{Q}}_i \\mathcal{X_{P}}_i, \\mathcal{W_{K}}_i \\mathcal{X_{P}}_i \\quad 1 \\leq i \\leq H,\n\\end{equation}\nwhere $\\mathcal{Q_{P}}_i, \\mathcal{K_{P}}_i \\in {\\rm I\\!R}^{P \\times \\frac{d_{model}}{H}}$ denote the query and key, respectively, and $\\mathcal{W_{Q}}_i, \\mathcal{W_{K}}_i \\in {\\rm I\\!R}^{\\frac{d_{model}}{H} \\times \\frac{d_{model}}{H}}$ represent learnable parameter matrices of $\\mathcal{Q_{P}}_i, \\mathcal{K_{N}}_i$. Then, compute the attention weights: \n\\begin{equation}\\label{eq5}\n    Attn_{\\mathcal{P}_i} = Softmax(\\frac{\\mathcal{Q_{P}}_i \\mathcal{K_{P}}_i^T}{\\sqrt{\\frac{d_{model}}{H}}}),\n\\end{equation}\nwhere $Softmax(\\cdot)$ function normalizes the attention weight. Finally, contact the multi-head and get the final in-patch representation $Attn_{\\mathcal{P}}$, which is: \n\\begin{equation}\\label{eq6}\n    Attn_\\mathcal{P} = \\text{Concat}(Attn_{\\mathcal{P}_1},\\cdots, Attn_{\\mathcal{P}_H}) W_\\mathcal{P}^{O},\n\\end{equation}\nwhere $W_\\mathcal{P}^{O} \\in {\\rm I\\!R}^{d_{model} \\times d_{model}}$ is a learnable parameter matrix. \n\nNote that the $\\mathcal{W_{Q}}_i, \\mathcal{W_{K}}_i$ are the shared weights within the in-patch attention representation network and patch-wise attention representation network.\n\n\n\n"
                    },
                    "subsubsection 3.2.2": {
                        "name": "Up-sampling and Multi-scale Design",
                        "content": "\nAlthough the patching design benefits from gaining local semantic information, patch-wise attention ignores the relevance among points in a patch, and in-patch attention ignores the relevance among patches. To compare the results of two representation networks, we need to do up-sampling first. For the patch-wise branch, as we only have the dependencies among patches, repeating is done inside patches (\\emph{i.e.}, from patch to points) for up-sampling, and we will get the final patch-wise representation $\\mathcal{N}$. For the in-patch branch, as only dependencies among patch points are gained, repeating is done from \"one\" patch to a full number of patches, and we will get the final in-patch representation $\\mathcal{P}$. \n\nA simple example is shown in Figure~\\ref{fig:upsample} where a patch is noted as $P^i$, and a point is noted as $p_i$. Such patching and repeating up-sampling operations inevitably lead to information loss. To keep the information from the original data better, DCdetector introduces a multi-scale design for patching representation and up-sampling. The final representation concatenates results in different scales (\\emph{i.e.}, patch sizes). Specifically, we can preset a list of various patches to perform parallel patching and the computation of dual attention representations, simultaneously. After upsampling each patch part, they are summed to obtain the final patch-wise representation $\\mathcal{N}$ and in-patch representation $\\mathcal{P}$, which are\n\\begin{align}\n     \\mathcal{N} = \\text{Upsampling}(Attn_{\\mathcal{N}}),  \\quad    \\mathcal{P} = \\text{Upsampling}(Attn_{\\mathcal{P}}).\n\\end{align}\n\n \n\n"
                    },
                    "subsubsection 3.2.3": {
                        "name": "Contrastive Structure",
                        "content": "\nPatch-wise and in-patch branches output representations of the same input time series in two different views. As shown in Figure \\ref{fig:workflow} (c), patch-wise sample representation learns a weighted combination between sample points in the same position from each patch. In-patch sample representation, on the other hand, learns a weighted combination between points within the same patch. We can treat these two representations as permutated multi-view representations. The key inductive bias we exploit here is that normal points can maintain their representation under permutations while the anomalies can not. From such dual attention non-negative contrastive learning, we want to learn a \\textbf{permutation invariant representation}. Learning details are left in Section~\\ref{sec:rd}.\n\n\n\n"
                    }
                },
                "subsection 3.3": {
                    "name": "Representation Discrepancy",
                    "content": "\\label{sec:rd}\n\nWith dual attention contrastive structure, representations from two views (patch-wise branch and in-patch branch) are gained. We formalize a loss function based on Kullback–Leibler divergence (KL divergence) to measure the similarity of such two representations. The intuition is that, as anomalies are rare and normal points share latent patterns, the same inputs' representations should be similar.  \n\n",
                    "subsubsection 3.3.1": {
                        "name": "Loss function definition",
                        "content": "\nThe loss function of the $\\mathcal{P}$ and $\\mathcal{N}$ can then be defined as \n\\begin{equation}\n    \\mathcal{L_P}\\{\\mathcal{P}, \\mathcal{N}; \\mathcal{X}\\} = \\sum KL(\\mathcal{P}, \\text{Stopgrad}(\\mathcal{N})) + KL(\\text{Stopgrad}(\\mathcal{N}), \\mathcal{P}),\n\\end{equation}\n\\begin{equation}\n    \\mathcal{L_N}\\{\\mathcal{P}, \\mathcal{N}; \\mathcal{X}\\} = \\sum KL(\\mathcal{N}, \\text{Stopgrad}(\\mathcal{P})) + KL(\\text{Stopgrad}(\\mathcal{P}), \\mathcal{N}),\n\\end{equation}\nwhere $\\mathcal{X}$ is the input time series, $KL(\\cdot||\\cdot)$ is the KL divergence distance, $\\mathcal{P}$ and $\\mathcal{N}$ are the representation result matrices of the in-patch branch and the patch-wise branch, respectively. Stop-gradient (labeled as 'Stopgrad') operation is also used in our loss function to train two branches asynchronously. Then, the total loss function $\\mathcal{L}$ is defined as\n\\begin{equation}\n    \\mathcal{L} = \\frac{\\mathcal{L_N}-\\mathcal{L_P}}{len(\\mathcal{N})}.\n\\end{equation}\n\nUnlike most anomaly detection works based on reconstruction framework~\\cite{ruff2021unifying}, DCdetector is a self-supervised framework based on representation learning, and no reconstruction part is utilized in our model. There is no doubt that reconstruction helps to detect the anomalies which behave not as expected. However, it is not easy to build a suitable encoder and decoder to 'reconstruct' the time series as they are expected to be with anomalies' interference. Moreover, the ability of representation is restricted as the latent pattern information is not fully considered. \n\n"
                    },
                    "subsubsection 3.3.2": {
                        "name": "Discussion about Model Collapse",
                        "content": "\nInterestingly, with only single-type inputs (or saying, no negative samples included), our DCdetector model does not fall into a trivial solution (model collapse). SimSiam~\\cite{chen2021exploring} gives the main credit for avoiding model collapse to stop gradient operation in their setting. However, we find that DCdetector still works without stop gradient operation, although with the same parameters, the no stop gradient version does not gain the best performance. Details are shown in the ablation study (Section~\\ref{sec:ablation}). \n\nA possible explanation is that our two branches are totally asymmetric. Following the unified perspective proposed in~\\cite{zhang2022does}, consider the output vector of a branch as $Z$ and $Z$ can be decomposed into two parts $o$ and $r$ as $Z = o+r$, where $o = {\\rm I\\!E}[Z]$ is the center vector defined as an average of $Z$ in the whole representation space, \nand $r$ is the residual vector. When the collapse happens, all vectors $Z$ fall into the center vector $o$ and $o$ dominates over $r$. With two branches noted as $Z_p = o_p + r_p$, $Z_n = o_n + r_n$, if the branches are symmetric, \\emph{i.e.}, $o_p = o_n$, then the distance between them is $Z_p - Z_n = r_p - r_n$. As $r_p$ and $r_n$ come from the same input example, it will lead to collapse. Fortunately, the two branches in DCdetector are asymmetric, so it is not easy for $o_p$ to be the same as $o_n$ even when $r_p$ and $r_n$ are similar. Thus, due to our asymmetric design, DCdetector is hard to fall into a trivial solution. \n\n\n"
                    }
                },
                "subsection 3.4": {
                    "name": "Anomaly Criterion",
                    "content": " \\label{sec:ac}\n\nWith the insight that normal points usually share latent patterns (with strong correlation among them), thus the distances of representation results from different views for normal points are less than that for anomalies. The final anomaly score of $\\mathcal{X}\\in {\\rm I\\!R}^{T\\times d}$ is defined as \n\\begin{equation}\n    \\text{AnomalyScore}(\\mathcal{X}) = \\sum KL(\\mathcal{P},\\text{Stopgrad}(\\mathcal{N}))+KL(\\mathcal{N},\\text{Stopgrad}(\\mathcal{P})).\n\\end{equation}\nIt is a point-wise anomaly score, and anomalies result in higher scores than normal points. \n\nBased on the point-wise anomaly score, a hyperparameter threshold $\\delta$ is used to decide if a point is an anomaly (1) or not (0). If the score exceeds the threshold, the output $\\mathcal{Y}$ is an anomaly. That is \n\\begin{equation} \\label{eq11}\n\\mathcal{Y}_i = \n\\begin{cases}\n\\text{1: anomaly} \\quad \\text{AnomalyScore}(\\mathcal{X}_i) \\geq \\delta \\\\\n\\text{0: normal}  \\quad \\quad \\!\\!\\! \\text{AnomalyScore}(\\mathcal{X}_i) < \\delta .\n\\end{cases}\n\\end{equation}\n\n\n"
                }
            },
            "section 4": {
                "name": "Experiments",
                "content": "\n\n\n\n",
                "subsection 4.1": {
                    "name": "Benchmark Datasets",
                    "content": " \\label{Chap: Benchmarks}\nWe adopt eight representative benchmarks from five real-world applications to evaluate DCdetector: (1) \\textbf{MSL} (Mars Science Laboratory dataset) is collected by NASA and shows the condition of the sensors and actuator data from the Mars rover \\cite{hundman2018detecting}. (2) \\textbf{SMAP} (Soil Moisture Active Passive dataset) is also collected by NASA and presents the soil samples and telemetry information used by the Mars rover \\cite{hundman2018detecting}. Compared with MSL, SMAP has more point anomalies.\n(3) \\textbf{PSM} (Pooled Server Metrics dataset) is a public dataset from eBay Server Machines with 25 dimensions \\cite{abdulaal2021practical}. (4) \\textbf{SMD} (Server Machine Dataset) is a five-week-long dataset collected from an internet company compute cluster, which stacks accessed traces of resource utilization of 28 machines \\cite{su2019robust}. (5) \\textbf{SWaT} (Secure Water Treatment) is a 51-dimension sensor-based dataset collected from critical infrastructure systems under continuous operations \\cite{mathur2016swat}. (6) \\textbf{NIPS-TS-SWAN} is an openly accessible comprehensive, multivariate time series benchmark extracted from solar photospheric vector magnetograms in Spaceweather HMI Active Region Patch series \\cite{DVN/EBCFKM_2020,lai2021revisiting}. (7) \\textbf{NIPS-TS-GECCO} is a drinking water quality dataset for the `internet of things', which is published in the 2018 genetic and evolutionary computation conference \\cite{moritz2018gecco,lai2021revisiting}. Besides the above multivariate time series datasets, we also test univariate time series datasets. (8) \\textbf{UCR} is provided by the Multi-dataset Time Series Anomaly Detection Competition of KDD2021, and contains 250 sub-datasets from various natural sources \\cite{dau2019ucr,keogh2021multi}. It is a univariate time series of dataset subsequence anomalies. In each time series, there is one and only one anomaly. \nMore details of the eight benchmark datasets are summarized in Table \\ref{Tab: Dataset Description} in Appendix~\\ref{sec:datasets}.\n\n\n"
                },
                "subsection 4.2": {
                    "name": "Baselines and Evaluation Criteria",
                    "content": " \\label{Chap: Baselines}\nWe compare our model with the 26 baselines for comprehensive evaluations, including the reconstruction-based model: AutoEncoder \\cite{sakurada2014anomaly}, LSTM-VAE \\cite{park2018multimodal}, OmniAnomaly \\cite{su2019robust}, BeatGAN \\cite{zhou2019beatgan}, InterFusion \\cite{li2021multivariate}, Anomaly Transformer \\cite{xu2021anomaly}; the autoregression-based models: VAR \\cite{anderson1976time}, Autoregression \\cite{rousseeuw2005robust}, LSTM-RNN \\cite{bontemps2016collective}, LSTM \\cite{hundman2018detecting}, CL-MPPCA \\cite{tariq2019detecting}; the density-estimation models: LOF \\cite{breunig2000lof}, MPPCACD \\cite{yairi2017data}, DAGMM \\cite{zong2018deep}; the clustering-based methods: Deep-SVDD \\cite{ruff2018deep}, THOC \\cite{shen2020timeseries}, ITAD \\cite{shin2020itad}; the classic methods: OCSVM \\cite{tax2004support}, OCSVM-based subsequence clustering (OCSVM*), IForest \\cite{liu2008isolation}, IForest-based subsequence clustering (IForest*), Gradient boosting regression (GBRT) \\cite{elsayed2021we}; the change point detection and time series segmentation methods: BOCPD \\cite{adams2007bayesian}, U-Time \\cite{perslev2019u}, TS-CP2 \\cite{deldari2021time}. We also compare our model with a time-series subsequence anomaly detection algorithm Matrix Profile \\cite{yeh2016matrix}.\n\nBesides, we adopt various evaluation criteria for comprehensive comparison, including the commonly-used evaluation measures: accuracy, precision, recall, F1-score; the recently proposed evaluation measures: affiliation precision/recall pair \\cite{huet2022local} and Volume under the surface (VUS) \\cite{paparrizos2022volume}. F1-score is the most widely used metric but does not consider anomaly events. Affiliation precision and recall are calculated based on\nthe distance between ground truth and prediction events. VUS metric takes anomaly events into consideration based on the receiver operator characteristic (ROC) curve. Different metrics provide different evaluation views. We employ the commonly-used adjustment technique for a fair comparison \\cite{xu2018unsupervised, su2019robust, shen2020timeseries, xu2021anomaly}, according to which all abnormalities in an abnormal segment are considered to have been detected if a single time point in an abnormal segment is identified.\n\n\n"
                },
                "subsection 4.3": {
                    "name": "Implementation Details",
                    "content": " \\label{Chap: Implementation}\n\nWe summarize all the default hyper-parameters as follows in our implementation. Our DCdetector model contains three encoder layers ($L=3$). The dimension of the hidden state $d_{model}$ is 256, and the number of attention heads $H$ is 1 for simplicity. We select various patch size and window size options for different datasets, as shown in Table \\ref{Tab: Dataset Description} in Appendix~\\ref{sec:datasets}. Our model defines an anomaly as a time point whose anomaly score exceeds a hyperparameter threshold $\\delta$, and its default value to 1. For all experiments on the above hyperparameter selection and trade-off, please refer to Appendix~\\ref{sec:appendix_extra_ablation}. \nBesides, all the experiments are implemented in PyTorch \\cite{paszke2019pytorch} with one NVIDIA Tesla-V100 32GB GPU. Adam \\cite{kingma2014adam} with default parameter is applied for optimization. We set the initial learning rate to $10^{-4}$ and the batch size to 128 with 3 epochs for all datasets.\n\n\n\n\n\n\n\n\n\n\n"
                },
                "subsection 4.4": {
                    "name": "Main Results",
                    "content": " \\label{Chap: Main Results}\n\n",
                    "subsubsection 4.4.1": {
                        "name": "Multivariate Anomaly Detection",
                        "content": "\n\nWe first evaluate our DCdetector with nineteen competitive baselines on five real-world multivariate datasets as shown in Table \\ref{Tab: Overall result}. \nIt can be seen that our proposed DCdetector achieves SOTA results under the widely used F1 metric~\\cite{ren2019time,xu2021anomaly} in most benchmark datasets.\nIt is worth mentioning that it has been an intense discussion among recent studies about how to evaluate the performance of anomaly detection algorithms fairly. Precision, Recall, and F1 score are still the most widely used metrics for comparison. Some additional metrics (affiliation precision/recall pair, VUS, etc.) are proposed to complement their deficiencies \\cite{huet2022local,paparrizos2022volume,xu2018unsupervised, su2019robust, shen2020timeseries, xu2021anomaly}. To judge which metric is the best beyond the scope of our work, we include all the metrics here. \nAs the recent Anomaly Transformer achieves better results than other baseline models, we mainly evaluate DCdetector with the Anomaly Transformer in this multi-metrics comparison as shown in Table~\\ref{Tab: multi-matrix results}. It can be seen that DCdetector performs better or at least comparable with the Anomaly Transformer in most metrics.\n\n\nWe also evaluate the performance of another two datasets NIPS-TS-SWAN and NIPS-TS-GECCO in Table \\ref{Tab: NIPS-TS overall results}, which are more challenging with more types of anomalies than the above five datasets. Although the two datasets have the highest (32.6\\% in NIPS-TS-SWAN) and lowest (1.1\\% in NIPS-TS-GECCO) anomaly ratio, DCdetector is still able to achieve SOTA results and completely outperform other methods.  \nSimilarly, multi-metrics comparisons between DCdetector and Anomaly Transformer are conducted and summarized in Table~\\ref{Tab: NIPS-TS multi-matrix results}, and DCdetector still achieves better performance in most metrics. \n \n\n\n"
                    },
                    "subsubsection 4.4.2": {
                        "name": "Univariate Anomaly Detection",
                        "content": "\nIn this part, we compare the performance of the DCdetector and Anomaly Transformer in univariate time series anomaly detection.\nWe trained and tested separately for each of the sub-datasets in UCR datasets, and the average results are shown in Table \\ref{Tab: UCR and UCR_AUG results}. The count indicates how many sub-datasets have reached SOTA. The sub-datasets of the UCR all have only one segment of subsequence anomalies, and DCdetecter can identify and locate them correctly and achieve optimal results. \n\n\n\n"
                    }
                },
                "subsection 4.5": {
                    "name": "Model Analysis",
                    "content": "\n\n\n\n\n",
                    "subsubsection 4.5.1": {
                        "name": "Ablation Studies",
                        "content": "\\label{sec:ablation}\nTable~\\ref{Tab: Ablation Stop Gradient} shows the ablation study of stop gradient. According to the loss function definition in Section~\\ref{sec:rd}, we use two stop gradient modules in $\\mathcal{L}\\{\\mathcal{P}, \\mathcal{N}; \\mathcal{X}\\}$, noted as stop gradient in patch-wise branch and in-patch branch, respectively. With two-stop gradient modules, we can see that DCdetector gains the best performances. If no stop gradient is contained, DCdetector still works and does not fall into a trivial solution. Moreover, in such a setting, it outperforms all the baselines except Anomaly Transformer. \nBesides, we also conduct an ablation study on how the two main preprocessing methods (bilateral filter for denoising and instance normalization for normalization) affect the performance of our method in Table \\ref{Tab: Ablation Preprocess results}. It can be seen that either of them slightly improves the performance of our model when used individually. However, if they are utilized simultaneously, the performance degrades. Therefore, our final DCdetector only contains the instance normalization module for preprocessing. More ablation studies on multi-scale patching, window size, attention head, embedding dimension, encoder layer, anomaly threshold, and metrics in loss function are left in Appendix~\\ref{sec:appendix_extra_ablation}. \n\n\n\n"
                    },
                    "subsubsection 4.5.2": {
                        "name": "Visual Analysis",
                        "content": "\n\nWe show how DCdetector works by visualizing different anomalies in Figure~\\ref{fig:case2}. We use the synthetic data generation methods reported in \\cite{lai2021revisiting} to generate univariate time series with different types of anomalies, including point-wise anomalies (global point and contextual point anomalies) and pattern-wise anomalies (seasonal, group, and trend anomalies)~\\cite{lai2021revisiting}. It can be seen that DCdetector can robustly detect various anomalies better from normal points with relatively higher anomaly scores.\n\n\n\n"
                    },
                    "subsubsection 4.5.3": {
                        "name": "Parameter Sensitivity",
                        "content": "\nWe also study the parameter sensitivity of the DCdetector. \nFigure~\\ref{fig:ab-win} shows the performance under different window sizes. \nAs discussed, a single point can not be taken as an instance in a time series. Window segmentation is widely used in the analysis, and window size is a significant parameter. \nFor our primary evaluation, the window size is usually set as 60 or 100. Nevertheless, results in Figure~\\ref{fig:ab-win} demonstrate that DCdetector is robust with a wide range of window sizes (from 30 to 210). Actually, in the window size range [45, 195], the performances fluctuate less than 2.3\\%.\nFigure~\\ref{fig:ab-scale} shows the performance under different multi-scale sizes. \nHorizontal coordinate is the patch-size combination used in multi-scale attention which means we combine several dual-attention modules with a given patch-size combination. Unlike window size, the multi-scale design contributes to the final performance of the DCdetector, and different patch-size combinations lead to different performances. Note that when studying the parameter sensitivity of window size, the scale size is fixed as [3,5]. When studying the parameter sensitivity of scale size, the window size is fixed at 60. \nFigure~\\ref{fig:ab-layer} shows the performance under different numbers of encoder layers, since many deep neural networks' performances are affected by the layer number. \nFigure~\\ref{fig:ab-head} and Figure~\\ref{fig:ab-atten} show model performances with different head numbers or $d_{model}$ sizes in attention. It can be seen that DCdetector achieves the best performance with a small attention head number and $d_{model}$ size. The memory and time usages with different $d_{model}$ sizes are shown in Figure~\\ref{fig:mem-time}. Based on Figure~\\ref{fig:mem-time} and Figure~\\ref{fig:ab-atten}, we set the dimension of the hidden state $d_{model}=256$ for the performance-complexity trade-off, and it can be seen that DCdetector can work quite well under $d_{model}=256$ with efficient running time and small memory consumption.\n\n\n"
                    }
                }
            },
            "section 5": {
                "name": "Conclusion",
                "content": "\n\nThis paper proposes a novel algorithm named DCdetector for time-series anomaly detection. We design a contrastive learning-based dual-branch attention structure in DCdetector to learn a permutation invariant representation. \nSuch representation enlarges the differences between normal points and anomalies, improving detection accuracy. \nBesides, two additional designs: multiscale and channel independence patching, are implemented to enhance the performance. \nMoreover, we propose a pure contrastive loss function without reconstruction error, which empirically proves the effectiveness of contrastive representation compared to the widely used reconstructive one. \nLastly, extensive experiments show that DCdetector achieves the best or comparable performance on eight benchmark datasets compared to various state-of-the-art algorithms. \n\n"
            },
            "section 6": {
                "name": "Acknowledgements",
                "content": "\nThis work was supported by Alibaba Group through Alibaba Research Intern Program.\n\n\n\\bibliographystyle{ACM-Reference-Format}\n\\clearpage\n\\bibliography{8_reference}\n\n\\newpage\n\n\\appendix\n\n\\newpage\n"
            },
            "section 7": {
                "name": "Algorithms",
                "content": "\\label{sec:appendix}\n\\begin{algorithm}[htb]\n\t\\caption{DCdetector Outliner}\n\t\\label{alg:code1}\n\n\t\\definecolor{codeblue}{rgb}{0.25,0.5,0.5}\n\t\\lstset{\n\t\tbackgroundcolor=\\color{white},\n\t\tbasicstyle=\\fontsize{7.2pt}{7.2pt}\\ttfamily\\selectfont,\n\t\tcolumns=fullflexible,\n\t\tbreaklines=true,\n\t\tcaptionpos=b,\n\t\tcommentstyle=\\fontsize{7.2pt}{7.2pt}\\color{codeblue},\n\t\tkeywordstyle=\\fontsize{7.2pt}{7.2pt},\n\t}\n    \n    \\begin{lstlisting}[language=python]\nfrom einops import rearrange\n\nclass DCdetector(nn.Module):\n    def __init__(self, win_size, enc_in, c_out, n_heads, d_model, e_layers, patch_size, channel, d_ff, dropout):\n        super(DCdetector, self).__init__()\n        self.patch_size = patch_size\n        self.channel = channel\n        self.win_size = win_size\n        \n        # Patching List Embedding  \n        self.embedding_patch_size = nn.ModuleList()\n        self.embedding_patch_num = nn.ModuleList()\n        for i, patchsize in enumerate(self.patch_size):\n            self.embedding_patch_size.append(DataEmbedding(patchsize, d_model, dropout))\n            self.embedding_patch_num.append(DataEmbedding(self.win_size//patchsize, d_model, dropout))\n        self.embedding_window_size = DataEmbedding(enc_in, d_model, dropout)\n         \n        # Dual Attention Encoder\n        self.encoder = Encoder(\n            [AttentionLayer(\n                    DAC_structure(win_size, patch_size, channel, False, attention_dropout=dropout, output_attention=output_attention),\n                d_model, patch_size, channel, n_heads, win_size) \n                for l in range(e_layers)\n            ],norm_layer=torch.nn.LayerNorm(d_model))\n\n    def forward(self, x):\n        B, L, M = x.shape #Batch win_size channel\n        revin_layer = RevIN(num_features=M)\n        patch_wise_mean = [], in_patch_mean = []\n        x_ori = self.embedding_window_size(x)\n          \n        # Instance Normalization Operation\n        x = revin_layer(x, 'norm')     \n        \n        # Mutil-scale Patching Operation \n        for patch_index, patchsize in enumerate(self.patch_size):   \n            x_patch_size = rearrange(x, 'b (n p) m -> (b m) n p', p = patchsize) \n            x_patch_num = rearrange(x, 'b (p n) m -> (b m) p n', p = patchsize) \n            x_patch_size = self.embedding_patch_size[patch_index](x_patch_size)\n            x_patch_num = self.embedding_patch_num[patch_index](x_patch_num)\n            patch_wise, in_patch = self.encoder(x_patch_size, x_patch_num, x_ori, patch_index)\n            patch_wise_mean.append(patch_wise)\n            in_patch_mean.append(in_patch)\n            \n        return patch_wise_mean, in_patch_mean\n        \n    \\end{lstlisting}\n\\end{algorithm}\n\\begin{algorithm}[htb]\n\t\\caption{Dual Attention Contrastive Structure}\n\t\\label{alg:code2}\n\t\\definecolor{codeblue}{rgb}{0.25,0.5,0.5}\n\t\\lstset{\n\t\tbackgroundcolor=\\color{white},\n\t\tbasicstyle=\\fontsize{7.2pt}{7.2pt}\\ttfamily\\selectfont,\n\t\tcolumns=fullflexible,\n\t\tbreaklines=true,\n\t\tcaptionpos=b,\n\t\tcommentstyle=\\fontsize{7.2pt}{7.2pt}\\color{codeblue},\n\t\tkeywordstyle=\\fontsize{7.2pt}{7.2pt},\n\t}\n    \n    \\begin{lstlisting}[language=python]\nfrom einops import reduce, repeat\nfrom math import sqrt\n\nclass DAC_structure(nn.Module):\n    def __init__(self, win_size, patch_size, channel, scale=None, attention_dropout=0.05):\n        super(DAC_structure, self).__init__()\n        self.scale = scale\n        self.dropout = nn.Dropout(attention_dropout)\n        self.window_size = win_size\n        self.patch_size = patch_size\n        self.channel = channel\n\n    def forward(self, queries_patch_size, queries_patch_num, keys_patch_size, keys_patch_num, values, patch_index, attn_mask):\n                                                 \n        # Patch-wise Representation\n        B, L, H, E = queries_patch_size.shape #batch_size*channel, patch_num, n_head, d_model/n_head\n        scale_patch_size = self.scale or 1. / sqrt(E)\n        scores_patch_size = torch.einsum(\"blhe,bshe->bhls\", queries_patch_size, keys_patch_size) #batch*ch, nheads, p_num, p_num   \n        attn_patch_size = scale_patch_size * scores_patch_size\n        series_patch_size = self.dropout(torch.softmax(attn_patch_size, dim=-1)) # B*D_model H N N\n\n        # In-patch Representation\n        B, L, H, E = queries_patch_num.shape #batch_size*channel, patch_size, n_head, d_model/n_head\n        scale_patch_num = self.scale or 1. / sqrt(E)\n        scores_patch_num = torch.einsum(\"blhe,bshe->bhls\", queries_patch_num, keys_patch_num) #batch*ch, nheads, p_size, p_size \n        attn_patch_num = scale_patch_num * scores_patch_num\n        series_patch_num = self.dropout(torch.softmax(attn_patch_num, dim=-1)) # B*D_model H S S \n\n        # Upsampling\n        series_patch_size = repeat(series_patch_size, 'blmn->bl(m repeat_m)(n repeat_n)', repeat_m=self.patch_size[patch_index], repeat_n=self.patch_size[patch_index])  \n        series_patch_num = series_patch_num.repeat(1,1,self.window_size//self.patch_size[patch_index],self.window_size//self.patch_size[patch_index]) \n\n        return series_patch_size, series_patch_num\n    \\end{lstlisting}\n\\end{algorithm}\nTwo main algorithms and their codes are presented as follows, the DCdetector Outliner (Algorithm~\\ref{alg:code1}) and the Dual Attention Contrastive Structure (Algorithm~\\ref{alg:code2}). \n\nFor the DCdetector Outliner (Algorithm~\\ref{alg:code1}), we use nn.ModuleList() in PyTorch~\\cite{paszke2019pytorch} to define multiple patching scales and perform embedding and dual attention operations for each set of patch sizes. After instance normalization, patch-wise encoders and in-patch encoders are calculated in the patch number $N$ dimension and the patch size $P$ dimension, respectively. Finally, we average the different patching scales to obtain the final patch-wise representation $\\mathcal{N}$ and in-patch representation $\\mathcal{P}$.\n\nFor the Dual Attention Contrastive Structure (Algorithm~\\ref{alg:code2}), we calculate patch-wise representation based on Eq.\\ref{eq1} - Eq.\\ref{eq3} and in-patch representation using Eq.\\ref{eq4} - Eq.\\ref{eq6}, respectively. Finally, we apply different upsampling methods to make the shape of the two representations the same for subsequent comparison of representation discrepancy. Note that, we do not need to calculate the specific attention values, as only two representations are made and the attention weights can also be used as representations as well as improving the efficiency of the code. Besides, only a single patch scale of dual attention contrastive structure is shown here, which may suffer from information loss when upsampling is performed. However, the multi-patch scale will compensate for this issue, as shown in Algorithm~\\ref{alg:code1}.\n\n\n"
            },
            "section 8": {
                "name": "Dataset Description",
                "content": "\\label{sec:datasets}\n\nWe summarize the seven adopted benchmark datasets for evaluation in Table \\ref{Tab: Dataset Description}. These datasets include both univariate and multivariate time series scenarios with different types and anomaly ratios. MSL, SMAP, PSM, SMD, SWaT, NIPS-TS-SWAN, and NIPS-TS-GECCO are multivariate time series datasets. UCR is a univariate time series dataset.\n\n"
            },
            "section 9": {
                "name": "Extra Studies",
                "content": "\\label{sec:appendix_extra_ablation}\nTo verify the sensitivity of the parameters in the proposed DCdetector, more ablation experiments are conducted in this part. We provide more detailed results here than those in Section~\\ref{sec:ablation}. We also show the memory used as well as the iteration time spent during the training process.\n\n",
                "subsection 9.1": {
                    "name": "Study on Metrics in Loss Function",
                    "content": "\nWe use different statistical distances to calculate the discrepancy between patch-wise representation and in-patch representation, and the results are shown in Table~\\ref{Tab: Ablation Metric Loss Function}. The loss function proposed in Section~\\ref{sec:rd} can get the SOTA performance in all benchmarks. Note that only using simple KL divergence, which is an asymmetrical loss function, we can still get a comparable result. However, for the Jensen-Shannon (JS) divergence, there is visible performance degradation, especially for the MSL benchmark.\n\n"
                },
                "subsection 9.2": {
                    "name": "Study on Multi-scale Patching",
                    "content": "\nThe multi-patching scale $\\in\\{[1],[3],[5],[1,3],[1,5],[3,5],[1,3,5]\\}$ are tested. Patch size preference is for odd numbers to prevent information loss during upsampling. Generally, multi-scale design results in larger memory and different datasets have different best multi-patching scales. This is perhaps due to different information densities and anomaly types in different situations. The details of evaluation results are shown in Table~\\ref{Tab: Ablation multiscale results}.\n\n"
                },
                "subsection 9.3": {
                    "name": "Study on Window Size",
                    "content": "\nWindow size is a significant hyper-parameter in time series analysis. It is used to split time series into instances, as usually, a single point can not be considered as a sample. The results in Table~\\ref{Tab: Ablation window size results} show that DCdetector is rather robust in different window sizes. Actually, in a large range [45, 195], the performances are slightly lower than the best ones for all benchmarks. Besides, we also test the impact of window size on memory cost and running time. The window size will affect the memory cost in a quadratic computational complexity way. So, the trade-off between slide window size and memory cost/running time is pretty important, especially for real-life scenarios. Fortunately, DCdetector can work optimally with a window size of less than 105 in all benchmarks, which greatly decreases the complexity of the model and its memory cost.\n\n"
                },
                "subsection 9.4": {
                    "name": "Study on Attention Head",
                    "content": "\nGenerally, multi-head attention is widely used in attention networks. We study the influence of attention head number $H$ in DCdetector. In general, the number of attention heads is even, so we set $H \\in \\{1,2,4,8\\}$. Fortunately, with a small attention head number, as shown in Table~\\ref{Tab: Ablation attention head number results}, our model still achieves good performances (the best one or slightly lower than the best). Thus, DCdetector does not need a large memory when running. \n\n"
                },
                "subsection 9.5": {
                    "name": "Study on Embedding Dimension",
                    "content": "\nThe embedding dimension $d_{model}$ is another important parameter in the attention network. As a hyperparameter of the hidden channels, it may have impacts on model performance, memory cost, and running efficiency. We set $d_{model} \\in \\{128,256,512,1024\\}$ as suggested hyperparameters by Transformer \\cite{vaswani2017attention}. For SMAP and PSM, it has little effect on the final results. As for MSL, it achieves the best performance with a small $d_{model}$ size and small memory. Overall, the proposed DCdetector can achieve quite good performance even with a small memory cost and good real-time performance. Details are in Table~\\ref{Tab: Ablation Embedding d_model results}.\n\n"
                },
                "subsection 9.6": {
                    "name": "Study on Encoder Layer",
                    "content": "\nMany deep models' performances are dependent on the number of network layers $L$. We also show the influence of the number of encoder layers in Table~\\ref{Tab: Ablation Encoder layers results}. We set $L \\in \\{1,2,3,4,5\\}$ as suggested hyperparameters by Transformer \\cite{vaswani2017attention}. Different benchmarks have different optimal parameters. Luckily, our model can gain the best performance in no more than 3 layers, and will not fail with too few encoder layers or over-fit with too many encoder layers.\n\n"
                },
                "subsection 9.7": {
                    "name": "Study on Anomaly Threshold",
                    "content": "\nAnomaly threshold $\\delta$ is a hyperparameter, which may affect the determination of anomaly or not, based on Eq. \\ref{eq11}. We have a default value of 1 for all benchmarks. As shown in Table~\\ref{Tab: Ablation Anomaly Threshold results}, when it is in the range of 0.5 to 1, it has little effect on the final model performance. PSM and SMAP are also more robust to anomaly threshold than MSL. For the three benchmarks, its best results appear when $\\delta$ equals 0.7 or 0.8. \n\n\n\n\n  \n"
                }
            }
        },
        "tables": {
            "Tab: Overall result": "\\begin{table*}[h!]\n\\caption{Overall results on real-world multivariate datasets. Performance ranked from lowest to highest. The \\textit{P}, \\textit{R} and \\textit{F1} are the precision, recall and F1-score. All results are in \\%, the best ones are in \\textbf{Bold}, and the second ones are {\\ul underlined}.}\n\\centering\n\\resizebox{1.0\\textwidth}{!}{\n\\begin{tabular}{c|ccc|ccc|ccc|ccc|ccc}\n\\hline \\hline\n\\textbf{Dataset} & \\multicolumn{3}{c|}{\\textbf{SMD}} & \\multicolumn{3}{c|}{\\textbf{MSL}} & \\multicolumn{3}{c|}{\\textbf{SMAP}} & \\multicolumn{3}{c|}{\\textbf{SWaT}} & \\multicolumn{3}{c}{\\textbf{PSM}} \\\\ \\hline\n\\textbf{Metric} & \\textbf{P} & \\textbf{R} & \\textbf{F1} & \\textbf{P} & \\textbf{R} & \\textbf{F1} & \\textbf{P} & \\textbf{R} & \\textbf{F1} & \\textbf{P} & \\textbf{R} & \\textbf{F1} & \\textbf{P} & \\textbf{R} & \\textbf{F1} \\\\ \\hline\nLOF & 56.34 & 39.86 & 46.68 & 47.72 & 85.25 & 61.18 & 58.93 & 56.33 & 57.60 & 72.15 & 65.43 & 68.62 & 57.89 & 90.49 & 70.61 \\\\\nOCSVM & 44.34 & 76.72 & 56.19 & 59.78 & 86.87 & 70.82 & 53.85 & 59.07 & 56.34 & 45.39 & 49.22 & 47.23 & 62.75 & 80.89 & 70.67 \\\\\nU-Time & 65.95 & 74.75 & 70.07 & 57.20 & 71.66 & 63.62 & 49.71 & 56.18 & 52.75 & 46.20 & 87.94 & 60.58 & 82.85 & 79.34 & 81.06 \\\\\nIForest & 42.31 & 73.29 & 53.64 & 53.94 & 86.54 & 66.45 & 52.39 & 59.07 & 55.53 & 49.29 & 44.95 & 47.02 & 76.09 & 92.45 & 83.48 \\\\\nDAGMM & 67.30 & 49.89 & 57.30 & 89.60 & 63.93 & 74.62 & 86.45 & 56.73 & 68.51 & {\\ul 89.92} & 57.84 & 70.40 & 93.49 & 70.03 & 80.08 \\\\\nITAD & 86.22 & 73.71 & 79.48 & 69.44 & 84.09 & 76.07 & 82.42 & 66.89 & 73.85 & 63.13 & 52.08 & 57.08 & 72.80 & 64.02 & 68.13 \\\\\nVAR & 78.35 & 70.26 & 74.08 & 74.68 & 81.42 & 77.90 & 81.38 & 53.88 & 64.83 & 81.59 & 60.29 & 69.34 & 90.71 & 83.82 & 87.13 \\\\\nMMPCACD & 71.20 & 79.28 & 75.02 & 81.42 & 61.31 & 69.95 & 88.61 & 75.84 & 81.73 & 82.52 & 68.29 & 74.73 & 76.26 & 78.35 & 77.29 \\\\\nCL-MPPCA & 82.36 & 76.07 & 79.09 & 73.71 & 88.54 & 80.44 & 86.13 & 63.16 & 72.88 & 76.78 & 81.50 & 79.07 & 56.02 & \\textbf{99.93} & 71.80 \\\\\nTS-CP2 & {\\ul 87.42} & 66.25 & 75.38 & 86.45 & 68.48 & 76.42 & 87.65 & 83.18 & 85.36 & 81.23 & 74.10 & 77.50 & 82.67 & 78.16 & 80.35 \\\\\nDeep-SVDD & 78.54 & 79.67 & 79.10 & {\\ul 91.92} & 76.63 & 83.58 & 89.93 & 56.02 & 69.04 & 80.42 & 84.45 & 82.39 & 95.41 & 86.49 & 90.73 \\\\\nBOCPD & 70.9 & 82.04 & 76.07 & 80.32 & 87.20 & 83.62 & 84.65 & 85.85 & 85.24 & 89.46 & 70.75 & 79.01 & 80.22 & 75.33 & 77.70 \\\\\nLSTM-VAE & 75.76 & 90.08 & 82.30 & 85.49 & 79.94 & 82.62 & 92.20 & 67.75 & 78.10 & 76.00 & 89.50 & 82.20 & 73.62 & 89.92 & 80.96 \\\\\nBeatGAN & 72.90 & 84.09 & 78.10 & 89.75 & 85.42 & 87.53 & 92.38 & 55.85 & 69.61 & 64.01 & 87.46 & 73.92 & 90.30 & 93.84 & 92.04 \\\\\nLSTM & 78.55 & 85.28 & 81.78 & 85.45 & 82.50 & 83.95 & 89.41 & 78.13 & 83.39 & 86.15 & 83.27 & 84.69 & 76.93 & 89.64 & 82.80 \\\\\nOmniAnomaly & 83.68 & 86.82 & 85.22 & 89.02 & 86.37 & 87.67 & 92.49 & 81.99 & 86.92 & 81.42 & 84.30 & 82.83 & 88.39 & 74.46 & 80.83 \\\\\nInterFusion & 87.02 & 85.43 & 86.22 & 81.28 & 92.70 & 86.62 & 89.77 & 88.52 & 89.14 & 80.59 & 85.58 & 83.01 & 83.61 & 83.45 & 83.52 \\\\\nTHOC & 79.76 & 90.95 & 84.99 & 88.45 & 90.97 & 89.69 & 92.06 & 89.34 & 90.68 & 83.94 & 86.36 & 85.13 & 88.14 & 90.99 & 89.54 \\\\\nAnomalyTrans & \\textbf{88.47} & \\textbf{92.28} & \\textbf{90.33} & {\\ul 91.92} & {\\ul 96.03} & {\\ul 93.93} & {\\ul 93.59} & \\textbf{99.41} & {\\ul 96.41} & 89.10 & {\\ul99.28} & {\\ul94.22} & {\\ul 96.94} & 97.81 & {\\ul 97.37} \\\\ \\hline\nDCdetector & 83.59 & {\\ul 91.10} & {\\ul 87.18} & \\textbf{93.69} & \\textbf{99.69} & \\textbf{96.60} & \\textbf{95.63} & {\\ul 98.92} & \\textbf{97.02} & \\textbf{93.11} & \\textbf{99.77} & \\textbf{96.33} & \\textbf{97.14} & {\\ul 98.74} & \\textbf{97.94} \\\\ \\hline \\hline\n\\end{tabular}}\n\\label{Tab: Overall result}\n\\end{table*}",
            "Tab: multi-matrix results": "\\begin{table*}[]\n\\caption{\\small{Multi-metrics results on real-world multivariate datasets. Aff-P and Aff-R are the precision and recall of affiliation metric~\\cite{huet2022local}, respectively. R\\_A\\_R and R\\_A\\_P are Range-AUC-ROC and Range-AUC-PR~\\cite{paparrizos2022volume}, which denote two scores based on label transformation under ROC curve and PR curve, respectively. V\\_ROC and V\\_RR are volumes under the surfaces created based on ROC curve and PR curve~\\cite{paparrizos2022volume}, respectively. All results are in \\%, and the best ones are in \\textbf{Bold}. } }\n\\label{Tab: multi-matrix results} \n\\resizebox{1.0\\textwidth}{!}\n{\n\\begin{tabular}{c|c|cccccccc}\n\\hline \\hline\n\\textbf{Dataset}               & \\textbf{Method}     & \\textbf{Acc} & \\textbf{F1} & \\textbf{Aff-P~\\cite{huet2022local}} & \\textbf{Aff-R~\\cite{huet2022local}} & \\textbf{R\\_A\\_R~\\cite{paparrizos2022volume}} & \\textbf{R\\_A\\_P~\\cite{paparrizos2022volume}} & \\textbf{V\\_ROC~\\cite{paparrizos2022volume}} & \\textbf{V\\_PR~\\cite{paparrizos2022volume}} \\\\ \\hline\n\\multirow{2}{*}{\\textbf{MSL}}  & AnomalyTrans & 98.69             & 93.93             & 51.76                  & 95.98               & 90.04                & 87.87               & 88.20             & 86.26            \\\\\n                               & DCdetector                & \\textbf{99.06}    & \\textbf{96.60}    & \\textbf{51.84}         & \\textbf{97.39}      & \\textbf{93.17}       & \\textbf{91.64}      & \\textbf{93.15}    & \\textbf{91.66}   \\\\ \\hline\n\\multirow{2}{*}{\\textbf{SMAP}} & AnomalyTrans & 99.05             & 96.41             & 51.39                  & \\textbf{98.68}      & \\textbf{96.32}       & 94.07               & \\textbf{95.52}    & 93.37            \\\\\n                               & DCdetector                & \\textbf{99.21}    & \\textbf{97.02}    & \\textbf{51.46}         & 98.64               & 96.03                & \\textbf{94.18}      & 95.19             & \\textbf{93.46}   \\\\ \\hline\n                               \n\\multirow{2}{*}{\\textbf{SWaT}}  & AnomalyTrans &   98.51     &  94.22      &   \\textbf{53.03}   &    \\textbf{98.08}          &    \\textbf{97.89}  &  93.47     &\\textbf{97.92}     & 93.49   \\\\\n                               & DCdetector                & \\textbf{99.09}  & \\textbf{96.33}    &  52.40                &  97.67      &   96.63      & \\textbf{94.06}        &  96.95        & \\textbf{94.34}          \\\\ \\hline\n    \n\\multirow{2}{*}{\\textbf{PSM}}  & AnomalyTrans & 98.68             & 97.37             & \\textbf{55.35}         & 80.28               & \\textbf{91.83}       & \\textbf{93.03}      & \\textbf{88.71}    & \\textbf{90.71}   \\\\\n                               & DCdetector                & \\textbf{98.95}    & \\textbf{97.94}    & 54.71                  & \\textbf{82.93}      & 91.55                & 92.93               & 88.41             & 90.58            \\\\ \\hline \\hline\n\\end{tabular}\n}\n\\end{table*}",
            "Tab: NIPS-TS overall results": "\\begin{table}[htbp]\n\\caption{Overall results on NIPS-TS datasets. Performance ranked from lowest to highest. All results are in \\%, the best ones are in bold, and the second ones are {\\ul underlined}.}\n\\resizebox{1.0\\columnwidth}{!}\n{\n\\begin{tabular}{c|ccc|ccc}\n\\hline \\hline\n\\textbf{Dataset}    & \\multicolumn{3}{c|}{\\textbf{NIPS-TS-GECCO}} & \\multicolumn{3}{c}{\\textbf{NIPS-TS-SWAN}} \\\\ \\hline\n\\textbf{Metric}     & \\textbf{P}   & \\textbf{R}   & \\textbf{F1}   & \\textbf{P}   & \\textbf{R}  & \\textbf{F1}  \\\\ \\hline\nOCSVM*              & 2.1          & 34.1         & 4.0           & 19.3         & 0.1         & 0.1          \\\\\nMatrixProfile       & 4.6          & 18.5         & 7.4           & 16.7         & 17.5        & 17.1         \\\\\nGBRT                & 17.5         & 14.0         & 15.6          & 44.7         & 37.5        & 40.8         \\\\\nLSTM-RNN            & 34.3         & 27.5         & 30.5          & 52.7         & 22.1        & 31.2         \\\\\nAutoregression      & 39.2         & 31.4         & 34.9          & 42.1         & 35.4        & 38.5         \\\\\nOCSVM               & 18.5         & \\textbf{74.3}         & 29.6          & 47.4         & 49.8        & 48.5         \\\\\nIForest*            & 39.2         & 31.5         & 39.0          & 40.6         & 42.5        & 41.6         \\\\\nAutoEncoder         & {\\ul 42.4}         & 34.0         & 37.7          & 49.7         & 52.2        & 50.9         \\\\\nAnomalyTrans        & 25.7         & 28.5         & 27.0          & {\\ul 90.7}         & 47.4        & {\\ul 62.3}        \\\\\nIForest             & \\textbf{43.9}         & 35.3         & {\\ul 39.1}          & 56.9         & \\textbf{59.8}        & 58.3         \\\\ \\hline\nDCdetector                & 38.3         & {\\ul 59.7}         & \\textbf{46.6}          & \\textbf{95.5}         & {\\ul 59.6}        & \\textbf{73.4}        \\\\ \\hline \\hline\n\\end{tabular}\n}\n\\label{Tab: NIPS-TS overall results}\n\\end{table}",
            "Tab: UCR and UCR_AUG results": "\\begin{table}[h!]\n\\caption{Overall results on univariate dataset. Results are in \\%, and the best ones are in Bold.}\n\\centering\n\\resizebox{0.9\\columnwidth}{!}{\n\\begin{tabular}{c|ccccc}\n\\hline \\hline\n\\textbf{Dataset}    & \\multicolumn{5}{c}{\\textbf{UCR}}  \\\\  \\hline\n\\textbf{Metric}     & \\multicolumn{1}{c}{\\textbf{Acc}} & \\multicolumn{1}{c}{\\textbf{P}} & \\multicolumn{1}{c}{\\textbf{R}} & \\multicolumn{1}{c}{\\textbf{F1}} & \\multicolumn{1}{c}{\\textbf{Count}} \\\\  \\hline\nAnomalyTrans & 99.49                            & 60.41                          & \\textbf{100}                            & 73.08                           & 42    \\\\\nDCdetector                & \\textbf{99.51}                            & \\textbf{61.62}                          & \\textbf{100 }                           & \\textbf{74.05}                           & \\textbf{46}                 \\\\ \\hline \\hline\n\\end{tabular}}\n\\label{Tab: UCR and UCR_AUG results}\n\\end{table}",
            "Tab: NIPS-TS multi-matrix results": "\\begin{table*}[h!]\n\\caption{\\small{Multi-metrics results on NIPS-TS datasets. All results are in \\%, and the best ones are in \\textbf{Bold}.}}\n\\resizebox{1.0\\textwidth}{!}{\n\\begin{tabular}{c|c|cccccccccc}\n\\hline \\hline\n\\textbf{Dataset}                      & \\textbf{Method}     & \\textbf{Acc}   & \\textbf{P}     & \\textbf{R}     & \\textbf{F1}    & \\textbf{Aff-P} & \\textbf{Aff-R} & \\textbf{R\\_A\\_R} & \\textbf{R\\_A\\_P} & \\textbf{V\\_ROC} & \\textbf{V\\_PR} \\\\ \\hline\n\\multirow{2}{*}{\\textbf{NIPS-TS-SWAN}}  & AnomalyTrans & 84.57          & 90.71          & 47.43          & 62.29          & \\textbf{58.45} & \\textbf{9.49}  & 86.42                & 93.26               & 84.81             & 92.00            \\\\\n                                     & DCdetector                & \\textbf{85.94} & \\textbf{95.48} & \\textbf{59.55} & \\textbf{73.35} & 50.48          & 5.63           & \\textbf{88.06}       & \\textbf{94.71}      & \\textbf{86.25}    & \\textbf{93.50}   \\\\ \\hline\n\\multirow{2}{*}{\\textbf{NIPS-TS-GECCO}} & AnomalyTrans & 98.03          & 25.65          & 28.48          & 26.99          & 49.23          & 81.20           & 56.35                & 22.53               & 55.45             & 21.71            \\\\\n                                     & DCdetector                & \\textbf{98.56} & \\textbf{38.25} & \\textbf{59.73} & \\textbf{46.63} & \\textbf{50.05} & \\textbf{88.55} & \\textbf{62.95}       & \\textbf{34.17}      & \\textbf{62.41}    & \\textbf{33.67}   \\\\ \\hline \\hline\n\\end{tabular}\n}\n\\label{Tab: NIPS-TS multi-matrix results}\n\\end{table*}",
            "Tab: Ablation Stop Gradient": "\\begin{table*}[!t]\n\\caption{Ablation studies on Stop Gradient in DCdetector. All results are in \\%, and the best ones are in \\textbf{Bold}.}\n\\resizebox{0.86\\textwidth}{!}{\n\\begin{tabular}{cc|lll|lll|lll}\n\\hline \\hline\n\\multicolumn{2}{c|}{\\textbf{Stop Gradient}}          & \\multicolumn{3}{c|}{\\textbf{MSL}}                                                                  & \\multicolumn{3}{c|}{\\textbf{SMAP}}                                                                 & \\multicolumn{3}{c}{\\textbf{PSM}}                                                                  \\\\ \\hline\n\\textbf{Patch-wise Branch} & \\textbf{In-patch Branch} & \\multicolumn{1}{c}{\\textbf{P}} & \\multicolumn{1}{c}{\\textbf{R}} & \\multicolumn{1}{c|}{\\textbf{F1}} & \\multicolumn{1}{c}{\\textbf{P}} & \\multicolumn{1}{c}{\\textbf{R}} & \\multicolumn{1}{c|}{\\textbf{F1}} & \\multicolumn{1}{c}{\\textbf{P}} & \\multicolumn{1}{c}{\\textbf{R}} & \\multicolumn{1}{c}{\\textbf{F1}} \\\\ \\hline\n\\ding{56}                         & \\ding{56}                        & 91.99                          & 89.98                          & 90.97                           & 94.49                          & 96.56                          & 95.51                           & 96.86                          & 97.51                          & 97.18                           \\\\\n\\ding{52}                          & \\ding{56}                       & 91.27                          & 72.61                          & 80.88                           & 94.46                             & 93.17                             & 93.81                               & 97.15                             & 98.51                           & 97.83                               \\\\\n\\ding{56}                         & \\ding{52}                         & 92.18                          & 96.27                          & 94.18                           & 94.37                          & 98.19                          & 96.24                           & 96.98                          & 98.04                          & 97.51                           \\\\\n\\ding{52}                           & \\ding{52}                         & 93.69      & 99.69      & \\textbf{96.60}       & 95.63     & 98.92      & \\textbf{97.02}       & 97.14      & 98.74      & \\textbf{97.94}      \\\\ \\hline \\hline\n\\end{tabular}}\n\\label{Tab: Ablation Stop Gradient}\n\\end{table*}",
            "Tab: Ablation Preprocess results": "\\begin{table*}[!t]\n\\caption{Ablation studies on Forward Process module in DCdetector. All results are in \\%, and the best ones are in \\textbf{Bold}.}\n\\resizebox{0.85\\textwidth}{!}{\n\\begin{tabular}{cc|ccc|ccc|ccc}\n\\hline \\hline\n\\multicolumn{2}{c|}{\\textbf{Forward Process}}     & \\multicolumn{3}{c|}{\\textbf{MSL}}      & \\multicolumn{3}{c|}{\\textbf{SMAP}}     & \\multicolumn{3}{c}{\\textbf{PSM}}      \\\\ \\hline\n\\textbf{Bilateral Filter} & \\textbf{Instance Norm} & \\textbf{P} & \\textbf{R} & \\textbf{F1} & \\textbf{P} & \\textbf{R} & \\textbf{F1} & \\textbf{P} & \\textbf{R} & \\textbf{F1} \\\\ \\hline\n\\ding{56}                         & \\ding{56}                      & 92.58      & 96.68      & 94.59       & 94.65      & 97.38      & 96.00       & 97.01      & 97.79      & 97.40       \\\\\n\\ding{52}                         & \\ding{56}                      & 92.64      & 98.74      & 95.59       & 94.48      & 98.48      & 96.44       & 97.11      & 98.44      & 97.77       \\\\\n\\ding{56}                         & \\ding{52}                      & 93.69      & 99.69      & \\textbf{96.60}       & 95.63      & 98.92      & \\textbf{97.02}       & 97.14      & 98.74      & \\textbf{97.94}       \\\\\n\\ding{52}                         & \\ding{52}                      & 92.28      & 98.82      & 95.44       & 95.11      & 97.06      & 96.08       & 96.88      & 97.82      & 97.35      \\\\ \\hline \\hline\n\\end{tabular}}\n\\label{Tab: Ablation Preprocess results}\n\\end{table*}",
            "Tab: Dataset Description": "\\begin{table*}[!t]\n\\caption{Details of benchmark datasets. AR (anomaly ratio) represents the abnormal proportion of the whole dataset.}\n{\n\\begin{tabular}{c|ccccccc}\n\\hline \\hline\n\\textbf{Benchmark}     & \\textbf{Source}                  & \\textbf{Dimension} & \\textbf{Window} & \\textbf{Patch Size}  & \\textbf{\\#Training} & \\textbf{\\#Test (Labeled)} & \\textbf{AR (\\%)} \\\\ \\hline\nMSL           & NASA Space Sensors      & 55        & 90     & {[}3,5{]}   & 58,317     & 73,729           & 10.5    \\\\\nSMAP          & NASA Space Sensors      & 25        & 105    & {[}3,5,7{]} & 135,183    & 427,617          & 12.8    \\\\\nPSM           & eBay Server Machine     & 25        & 60     & {[}1,3,5{]} & 132,481    & 87,841           & 27.8    \\\\\nSMD           & Internet Server Machine & 38        & 105    & {[}5,7{]}   & 708,405    & 708,420          & 4.2     \\\\\nSWaT           & Infrastructure System & 51        & 105    & {[}3,5,7{]}   & 495,000    &  449,919         & 12.1     \\\\\nNIPS-TS-SWAN  & Space (Solar) Weather   & 38        & 36     & {[}1,3{]}   & 60,000     & 60,000           & 32.6    \\\\\nNIPS-TS-GECCO & Water Quality for IoT   & 9         & 90     & {[}1,3,5{]} & 69,260     & 69,261           & 1.1     \\\\ \\hline\nUCR           & Various Natural Sources & 1         & 105    & {[}3,5,7{]} & 2,238,349  & 6,143,541        & 0.6     \\\\\\hline \\hline\n\\end{tabular}}\n\\label{Tab: Dataset Description}\n\\end{table*}",
            "Tab: Ablation Metric Loss Function": "\\begin{table*}[!ht]\n\\caption{Ablation studies on metrics in the loss function. All results are in \\%. The best ones are in \\textbf{Bold}.}\n{\n\\begin{tabular}{c|lll|lll|lll}\n\\hline \\hline\n\\textbf{Dataset} & \\multicolumn{3}{c|}{\\textbf{MSL}}                                                                  & \\multicolumn{3}{c|}{\\textbf{SMAP}}                                                                 & \\multicolumn{3}{c}{\\textbf{PSM}}                                                                  \\\\ \\hline\n\\textbf{Metric}  & \\multicolumn{1}{c}{\\textbf{P}} & \\multicolumn{1}{c}{\\textbf{R}} & \\multicolumn{1}{c|}{\\textbf{F1}} & \\multicolumn{1}{c}{\\textbf{P}} & \\multicolumn{1}{c}{\\textbf{R}} & \\multicolumn{1}{c|}{\\textbf{F1}} & \\multicolumn{1}{c}{\\textbf{P}} & \\multicolumn{1}{c}{\\textbf{R}} & \\multicolumn{1}{c}{\\textbf{F1}} \\\\ \\hline\n                         JS                       & 89.23                          & 70.42                          & 78.72                           & 93.23                          & 93.62                          & 93.42                           & 97.18                          & 92.29                          & 94.67                           \\\\\nSimple KL                         & 92.44                          & 98.82                          & 95.52                           & 92.20                          & 93.44                          & 92.82                           & 97.80                         & 96.71                          & 97.25                           \\\\ \\hline \nDCdetector & 93.69 & 99.69 & \\textbf{96.60} & 95.63 & 98.92 & \\textbf{97.02} & 97.14 & 98.74 & \\textbf{97.94} \\\\\n\\hline \\hline\n\\end{tabular}}\n\\label{Tab: Ablation Metric Loss Function}\n\\end{table*}",
            "Tab: Ablation multiscale results": "\\begin{table*}[h!]\n\\caption{Ablation studies on multi-scale patching results (window size=60). All results are in \\%. The best ones are in \\textbf{Bold}.}\n{\n\\begin{tabular}{c|cccc|cccc|cccc|cc}\n\\hline \\hline\n\\textbf{Dataset}                          & \\multicolumn{4}{c|}{\\textbf{MSL}}                     & \\multicolumn{4}{c|}{\\textbf{SMAP}}                    & \\multicolumn{4}{c|}{\\textbf{PSM}}                     & \\multirow{2}{*}{\\makecell[c]{\\textbf{Mem} \\\\ \\textbf{(GB)}}} & \\multirow{2}{*}{\\makecell[c]{\\textbf{Time} \\\\ \\textbf{(s)}}} \\\\ \\cline{1-13}\n\\textbf{Metric} & \\textbf{Acc} & \\textbf{P} & \\textbf{R} & \\textbf{F1} & \\textbf{Acc} & \\textbf{P} & \\textbf{R} & \\textbf{F1} & \\textbf{Acc} & \\textbf{P} & \\textbf{R} & \\textbf{F1} &                                    &                                    \\\\ \\hline\nPatch Size = {[}1{]}                      & 97.98        & 92.77      & 88.29      & 90.48       & 98.96        & 93.91      & 98.31      & 96.06       & 98.82        & 97.27      & 98.07      & 97.66       & 16.9                               & 0.42                               \\\\\nPatch Size = {[}3{]}                      & 98.64        & 92.39      & 95.34      & 93.84       & 98.59        & 94.65      & 94.43      & 94.54       & 97.22        & 96.95      & 91.84      & 94.33       & 6.0                                & 0.24                               \\\\\nPatch Size = {[}5{]}                      & 98.91        & 92.55      & 97.87      & 95.14       & 98.92        & 94.40      & 97.44      & 95.90       & 98.75        & 97.22      & 97.84      & 97.53       & 3.2                                & 0.17                               \\\\\nPatch Size = {[}1,3{]}                    & 98.30        & 93.19      & 90.77      & 91.96       & 98.98        & 94.42      & 97.87      & 96.11       & 98.83        & 96.96      & 98.42      & \\textbf{97.68}       & 16.9                               & 0.59                               \\\\\nPatch Size = {[}1,5{]}                    & 98.52        & 92.88      & 93.60      & 93.24       & 98.89        & 94.15      & 97.49      & 95.79       & 98.76        & 97.03      & 98.07      & 97.55       & 16.9                               & 0.46                               \\\\\nPatch Size = {[}3,5{]}                    & 98.93        & 93.88      & 97.72      & \\textbf{95.76}       & 98.89        & 94.61      & 96.95      & 95.77       & 98.38        & 97.00      & 96.54      & 96.77       & 6.0                                & 0.27                               \\\\\nPatch Size = {[}1,3,5{]}                  & 98.44        & 91.52      & 93.78      & 92.64       & 99.03        & 93.72      & 99.10      & \\textbf{96.34}       & 98.95        & 97.14      & 98.74      & 97.94       & 16.9                               & 0.71                              \\\\ \\hline \\hline \n\\end{tabular}}\n\\label{Tab: Ablation multiscale results}\n\\end{table*}",
            "Tab: Ablation window size results": "\\begin{table*}[h!]\n\\caption{Ablation studies on window size results (patch size=[3,5]). All results are in \\%. The best ones are in \\textbf{Bold}.}\n{\n\\begin{tabular}{c|llll|llll|llll|cc}\n\\hline \\hline\n\\textbf{Dataset}                        & \\multicolumn{4}{c|}{\\textbf{MSL}}                                                                                                     & \\multicolumn{4}{c|}{\\textbf{SMAP}}                                                                                                    & \\multicolumn{4}{c|}{\\textbf{PSM}}                                                                                                     & \\multirow{2}{*}{\\makecell[c]{\\textbf{Mem} \\\\ \\textbf{(GB)}}} & \\multirow{2}{*}{\\makecell[c]{\\textbf{Time} \\\\ \\textbf{(s)}}} \\\\ \\cline{1-13}\n\\textbf{Metric} & \\multicolumn{1}{c}{\\textbf{Acc}} & \\multicolumn{1}{c}{\\textbf{P}} & \\multicolumn{1}{c}{\\textbf{R}} & \\multicolumn{1}{c|}{\\textbf{F1}} & \\multicolumn{1}{c}{\\textbf{Acc}} & \\multicolumn{1}{c}{\\textbf{P}} & \\multicolumn{1}{c}{\\textbf{R}} & \\multicolumn{1}{c|}{\\textbf{F1}} & \\multicolumn{1}{c}{\\textbf{Acc}} & \\multicolumn{1}{c}{\\textbf{P}} & \\multicolumn{1}{c}{\\textbf{R}} & \\multicolumn{1}{c|}{\\textbf{F1}} &                                    &                                    \\\\ \\hline\nWindow size = 30                                      & 96.87                            & 92.39                          & 76.47                          & 83.68                           & 98.62                            & 93.93                          & 95.46                          & 94.69                           & 98.42                            & 97.42                          & 96.27                          & 96.84                           & 2.9                                & 0.17                               \\\\\nWindow size = 45                                      & 98.77                            & 92.80                          & 96.13                          & 94.44                           & 98.94                            & 94.24                          & 97.75                          & 95.96                           & 98.79                            & 97.01                          & 98.09                          & 97.55                           & 6.0                                & 0.22                               \\\\\nWindow size = 60                                      & 98.63                            & 91.82                          & 96.01                          & 93.87                           & 98.87                            & 94.87                          & 96.44                          & 95.65                           & 98.91                            & 97.04                          & 98.67                          & \\textbf{97.85}                  & 6.1                                & 0.28                               \\\\\nWindow size = 75                                      & 98.79                            & 91.71                          & 97.93                          & 94.72                           & 98.97                            & 94.62                          & 97.60                          & 96.09                           & 98.79                            & 97.26                          & 98.20                          & 97.73                           & 7.6                                & 0.36                               \\\\\nWindow size = 90                                      & 98.94                            & 92.04                          & 98.82                          & 95.31                           & 98.99                            & 94.61                          & 97.69                          & 96.13                           & 98.74                            & 96.87                          & 98.05                          & 97.46                           & 7.6                                & 0.40                               \\\\\nWindow size = 105                                     & 99.06                            & 93.69                          & 99.69                          & \\textbf{96.60}                  & 99.16                            & 94.69                          & 98.87                          & \\textbf{96.74}                  & 98.57                            & 96.84                          & 97.37                          & 97.10                           & 18.5                               & 0.46                               \\\\\nWindow size = 120                                     & 98.95                            & 92.64                          & 98.74                          & 95.59                           & 99.08                            & 94.48                          & 98.48                          & 96.44                           & 98.80                            & 97.00                          & 98.24                          & 97.61                           & 18.5                               & 0.53                               \\\\\nWindow size = 135                                     & 98.44                            & 91.52                          & 94.45                          & 92.96                           & 99.09                            & 94.26                          & 98.91                          & 96.53                           & 98.70                            & 96.97                          & 98.17                          & 97.57                           & 24.4                               & 0.60                               \\\\\nWindow size = 150                                     & 98.49                            & 91.70                          & 95.02                          & 93.34                           & 98.93                            & 94.40                          & 97.48                          & 95.92                           & 98.55                            & 97.02                          & 97.18                          & 97.10                           & 24.4                               & 0.67                               \\\\\nWindow size = 165                                     & 98.64                            & 92.61                          & 95.68                          & 94.12                           & 99.01                            & 94.50                          & 98.07                          & 96.25                           & 98.77                            & 97.11                          & 98.05                          & 97.58                           & 24.4                               & 0.74                               \\\\\nWindow size = 180                                     & 98.68                            & 92.13                          & 96.13                          & 94.09                           & 98.99                            & 94.53                          & 97.73                          & 96.10                           & 98.67                            & 97.31                          & 97.87                          & 97.59                           & 24.4                               & 0.81                               \\\\\nWindow size = 195                                     & 98.50                            & 92.68                          & 94.18                          & 93.43                           & 98.95                            & 94.44                          & 97.60                          & 96.00                           & 98.66                            & 97.24                          & 97.88                          & 97.55                           & 24.5                               & 0.89                               \\\\\nWindow size = 210                                     & 98.03                            & 91.31                          & 90.88                          & 91.09                           & 98.58                            & 92.79                          & 96.29                          & 94.51                           & 98.39                            & 96.86                          & 96.59                          & 96.72                           & 24.5                               & 0.97  \\\\ \\hline \\hline                            \n\\end{tabular}}\n\\label{Tab: Ablation window size results}\n\\end{table*}",
            "Tab: Ablation attention head number results": "\\begin{table*}[h!]\n\\caption{Ablation studies on attention head $H$ results (patch size=[3,5], window size=60). All results are in \\%. The best ones are in \\textbf{Bold}.}\n{\n\\begin{tabular}{c|llll|llll|llll|cc}\n\\hline \\hline\n\\textbf{Dataset}                          & \\multicolumn{4}{c|}{\\textbf{MSL}}                                                                                                     & \\multicolumn{4}{c|}{\\textbf{SMAP}}                                                                                                    & \\multicolumn{4}{c|}{\\textbf{PSM}}                                                                                                     & \\multirow{2}{*}{\\makecell[c]{\\textbf{Mem} \\\\ \\textbf{(GB)}}} & \\multirow{2}{*}{\\makecell[c]{\\textbf{Time} \\\\ \\textbf{(s)}}} \\\\ \\cline{1-13}\n\\textbf{Metric} & \\multicolumn{1}{c}{\\textbf{Acc}} & \\multicolumn{1}{c}{\\textbf{P}} & \\multicolumn{1}{c}{\\textbf{R}} & \\multicolumn{1}{c|}{\\textbf{F1}} & \\multicolumn{1}{c}{\\textbf{Acc}} & \\multicolumn{1}{c}{\\textbf{P}} & \\multicolumn{1}{c}{\\textbf{R}} & \\multicolumn{1}{c|}{\\textbf{F1}} & \\multicolumn{1}{c}{\\textbf{Acc}} & \\multicolumn{1}{c}{\\textbf{P}} & \\multicolumn{1}{c}{\\textbf{R}} & \\multicolumn{1}{c|}{\\textbf{F1}} &                                    &                                    \\\\ \\hline\n$H$ = 1                                   & 98.63                            & 91.82                          & 96.01                          & \\textbf{93.87}                  & 98.87                            & 94.87                          & 96.44                          & 95.65                           & 98.91                            & 97.04                          & 98.67                          & \\textbf{97.85}                  & 6.1                                & 0.05                               \\\\\n$H$ = 2                                   & 98.50                             & 92.13                          & 94.29                          & 93.20                            & 98.98                            & 93.99                          & 98.44                          & 96.16                           & 98.67                            & 97.16                          & 97.55                          & 97.36                           & 6.1                                & 0.17                               \\\\\n$H$ = 4                                   & 98.67                            & 91.93                          & 95.71                          & 93.78                           & 98.97                            & 93.89                          & 98.46                          & 96.12                           & 98.69                            & 97.02                          & 97.79                          & 97.41                           & 9.8                                & 0.19                               \\\\\n$H$ = 8                                   & 98.55                            & 91.30                           & 95.21                          & 93.21                           & 99.11                            & 94.87                          & 98.47                          & \\textbf{96.63}                  & 98.63                            & 96.84                          & 97.73                          & 97.29                           & 9.8                                & 0.40    \\\\ \\hline \\hline                           \n\\end{tabular}}\n\\label{Tab: Ablation attention head number results}\n\\end{table*}",
            "Tab: Ablation Embedding d_model results": "\\begin{table*}[h!]\n\\caption{Ablation studies on embedding $d_{model}$ results (patch size=[3,5], window size=60). All results are in \\%. The best ones are in \\textbf{Bold}.}\n{\n\\begin{tabular}{c|llll|llll|llll|cc}\n\\hline \\hline\n\\textbf{Dataset}    & \\multicolumn{4}{c|}{\\textbf{MSL}}                                                                                                     & \\multicolumn{4}{c|}{\\textbf{SMAP}}                                                                                                    & \\multicolumn{4}{c|}{\\textbf{PSM}}                                                                                                     & \\multirow{2}{*}{\\makecell[c]{\\textbf{Mem} \\\\ \\textbf{(GB)}}} & \\multirow{2}{*}{\\makecell[c]{\\textbf{Time} \\\\ \\textbf{(s)}}} \\\\ \\cline{1-13}\n\\textbf{Metric}     & \\multicolumn{1}{c}{\\textbf{Acc}} & \\multicolumn{1}{c}{\\textbf{P}} & \\multicolumn{1}{c}{\\textbf{R}} & \\multicolumn{1}{c|}{\\textbf{F1}} & \\multicolumn{1}{c}{\\textbf{Acc}} & \\multicolumn{1}{c}{\\textbf{P}} & \\multicolumn{1}{c}{\\textbf{R}} & \\multicolumn{1}{c|}{\\textbf{F1}} & \\multicolumn{1}{c}{\\textbf{Acc}} & \\multicolumn{1}{c}{\\textbf{P}} & \\multicolumn{1}{c}{\\textbf{R}} & \\multicolumn{1}{c|}{\\textbf{F1}} &                           &                           \\\\ \\hline\n$d_{model}$ = 128  & 98.47                            & 91.62                          & 94.59                          & 93.08                  & 99.10                             & 94.85                          & 98.34                          & \\textbf{96.56}                  & 98.86                            & 97.13                          & 98.38                          & 97.75                           & 3.9                       & 0.05                      \\\\\n$d_{model}$ = 256  & 98.79                            & 91.47                          & 98.02                          & \\textbf{94.63}                  & 99.02                            & 94.25                          & 98.40                           & 96.28                           & 98.85                            & 96.98                          & 98.51                          & 97.74                           & 6.1                       & 0.10                       \\\\\n$d_{model}$ = 512  & 98.63                            & 91.82                          & 96.01                          & 93.87                           & 98.87                            & 94.87                          & 96.44                          & 95.65                           & 98.91                            & 97.04                          & 98.67                          & 97.85                           & 10.3                      & 0.28                      \\\\\n$d_{model}$ = 1024 & 98.13                            & 91.92                          & 90.81                          & 91.36                           & 98.97                            & 94.87                          & 97.27                          & 96.06                           & 98.97                            & 97.11                          & 98.83                          & \\textbf{97.96}                  & 18.4                       & 0.92     \\\\ \\hline \\hline                \n\\end{tabular}}\n\\label{Tab: Ablation Embedding d_model results}\n\\end{table*}",
            "Tab: Ablation Encoder layers results": "\\begin{table*}[h!]\n\\caption{Ablation studies on encoder layers $L$ results (patch size=[3,5], window size=60). All results are in \\%. The best ones are in \\textbf{Bold}.}\n{\n\\begin{tabular}{c|llll|llll|llll|cc}\n\\hline \\hline\n\\textbf{Dataset} & \\multicolumn{4}{c|}{\\textbf{MSL}}                                                                                                     & \\multicolumn{4}{c|}{\\textbf{SMAP}}                                                                                                    & \\multicolumn{4}{c|}{\\textbf{PSM}}                                                                                                     & \\multirow{2}{*}{\\makecell[c]{\\textbf{Mem} \\\\ \\textbf{(GB)}}} & \\multirow{2}{*}{\\makecell[c]{\\textbf{Time} \\\\ \\textbf{(s)}}} \\\\ \\cline{1-13}\n\\textbf{Metric}  & \\multicolumn{1}{c}{\\textbf{Acc}} & \\multicolumn{1}{c}{\\textbf{P}} & \\multicolumn{1}{c}{\\textbf{R}} & \\multicolumn{1}{c|}{\\textbf{F1}} & \\multicolumn{1}{c}{\\textbf{Acc}} & \\multicolumn{1}{c}{\\textbf{P}} & \\multicolumn{1}{c}{\\textbf{R}} & \\multicolumn{1}{c|}{\\textbf{F1}} & \\multicolumn{1}{c}{\\textbf{Acc}} & \\multicolumn{1}{c}{\\textbf{P}} & \\multicolumn{1}{c}{\\textbf{R}} & \\multicolumn{1}{c|}{\\textbf{F1}} &                           &                           \\\\ \\hline \n$L$ = 1              & 98.73                            & 91.76                          & 96.52                          & \\textbf{94.08}                          & 98.94                            & 94.34                          & 97.69                          & 95.98                           & 96.92                            & 97.26                          & 90.33                          & 93.66                           & 6.0                         & 0.02                      \\\\\n$L$ = 2              & 98.67                            & 98.67                          & 94.56                          & 93.72                           & 98.75                            & 93.93                          & 96.53                          & 95.22                           & 98.88                            & 97.24                          & 98.35                          & 97.79                           & 6.0                         & 0.04                      \\\\\n$L$ = 3              & 98.63                            & 91.82                          & 96.01                          & 93.87                           & 98.87                            & 94.87                          & 96.44                          & 95.65                           & 98.91                            & 97.04                          & 98.67                          & \\textbf{97.85}                  & 6.1                       & 0.10                       \\\\\n$L$ = 4              & 98.33                            & 91.52                          & 92.72                          & 92.11                           & 99.01                            & 95.03                          & 97.42                          & 96.21                           & 98.88                            & 97.00                             & 98.53                          & 97.76                           & 6.1                       & 0.19                      \\\\\n$L$ = 5              & 98.34                            & 91.38                          & 92.91                          & 92.14                           & 99.04                            & 94.23                          & 98.63                          & \\textbf{96.38}                           & 98.83                            & 96.97                          & 98.41                          & 97.69                           & 6.1                       & 0.24        \\\\ \\hline \\hline             \n\\end{tabular}}\n\\label{Tab: Ablation Encoder layers results}\n\\end{table*}",
            "Tab: Ablation Anomaly Threshold results": "\\begin{table*}[]\n\\caption{Ablation studies on anomaly threshold $\\delta$ results (patch size=[3,5], window size=60). All results are in \\%. The best ones are in \\textbf{Bold}.}\n{\n\\begin{tabular}{c|llll|llll|llll}\n\\hline \\hline\n\\textbf{Dataset} & \\multicolumn{4}{c|}{\\textbf{MSL}}                                                                                                     & \\multicolumn{4}{c|}{\\textbf{SMAP}}                                                                                                    & \\multicolumn{4}{c}{\\textbf{PSM}}                                                                                                     \\\\ \\hline\n\\textbf{Metric}  & \\multicolumn{1}{c}{\\textbf{Acc}} & \\multicolumn{1}{c}{\\textbf{P}} & \\multicolumn{1}{c}{\\textbf{R}} & \\multicolumn{1}{c|}{\\textbf{F1}} & \\multicolumn{1}{c}{\\textbf{Acc}} & \\multicolumn{1}{c}{\\textbf{P}} & \\multicolumn{1}{c}{\\textbf{R}} & \\multicolumn{1}{c|}{\\textbf{F1}} & \\multicolumn{1}{c}{\\textbf{Acc}} & \\multicolumn{1}{c}{\\textbf{P}} & \\multicolumn{1}{c}{\\textbf{R}} & \\multicolumn{1}{c}{\\textbf{F1}} \\\\ \\hline\n$\\delta$=0.5     & 96.62                            & 95.69                          & 72.23                          & 82.32                           & 98.85                            & 96.60                          & 94.40                          & 95.49                           & 98.45                            & 98.76                          & 95.03                          & 96.86                           \\\\\n$\\delta$=0.6     & 98.08                            & 94.75                          & 87.20                          & 90.80                           & 99.12                            & 96.66                          & 96.53                          & 96.59                           & 98.71                            & 98.27                          & 96.56                          & 97.41                           \\\\\n$\\delta$=0.7     & 98.80                            & 93.65                          & 95.47                          & 94.55                           & 99.29                            & 95.73                          & 98.88                          & \\textbf{97.28}                  & 98.98                            & 98.14                          & 97.81                          & \\textbf{97.97}                  \\\\\n$\\delta$=0.8     & 98.83                            & 93.12                          & 96.40                          & \\textbf{94.73}                  & 99.06                            & 94.29                          & 98.72                          & 96.45                           & 98.88                            & 97.71                          & 97.85                          & 97.78                           \\\\\n$\\delta$=0.9     & 98.42                            & 91.90                          & 93.75                          & 92.82                           & 98.82                            & 93.81                          & 97.32                          & 95.54                           & 98.92                            & 97.42                          & 98.31                          & 97.86                           \\\\\n$\\delta$=1.0     & 98.33                            & 92.58                          & 92.04                          & 92.31                           & 98.90                            & 93.30                          & 98.56                          & 95.86                           & 98.91                            & 97.04                          & 98.67                          & 97.85                          \\\\ \\hline \\hline\n\\end{tabular}}\n\\label{Tab: Ablation Anomaly Threshold results}\n\\end{table*}"
        },
        "figures": {
            "fig:art-compare": "\\begin{figure*}[!ht]\n    \\includegraphics[width=1.0\\textwidth]{img/art-compare-new.pdf}\n    \\caption{Architecture comparison of three approaches. The reconstruction-based approach uses a representation neural network to learn the pattern of normal points and do reconstruction. In Anomaly Transformer, the prior discrepancy is learned with Gaussian Kernel and the association discrepancy is learned with a transformer module; MinMax association learning is also critical and reconstruction loss is contained. DCdetector is concise without a specially designed Gaussian Kernel or a MinMax learning strategy, nor a reconstruction loss.}\n    \\label{fig:art-compare}\n\\end{figure*}",
            "fig:workflow": "\\begin{figure*}[!t]\n    \\centering\n    \\includegraphics[width=1.0\\textwidth]{img/workflow-new.pdf}\n    \\caption{The workflow of the DCdetector framework. DCdetector consists of four main components: Forward Process module, Dual Attention Contrastive Structure module, Representation Discrepancy module, and Anomaly Criterion module.} \n    \\label{fig:workflow}\n\\end{figure*}",
            "fig:patch": "\\begin{figure*}[!t]\n    \\includegraphics[width=1.0\\textwidth]{img/patch-new.pdf}\n    \\caption{Basic patching attention with channel independence. Each channel in the multivariate time series input is considered as a single time series and divided into patches. Each channel shares the same self-attention network, and the representation results are concatenated as the final output.}\n    \\label{fig:patch}\n\\end{figure*}",
            "fig:upsample": "\\begin{figure}[t]\n    \\centering\n    \\includegraphics[width=1.0\\columnwidth]{img/up-sampling-new.pdf}\n    \\caption{A simple example of how up-sampling is done. For patch-wise branch, repeating is done in patches (from patch to points). For in-patch branch, repeating is done from \"one\" patch to a full number of patches (from points to patches).}\n    \\label{fig:upsample}\n\\end{figure}",
            "fig:case2": "\\begin{figure*}[htbp]\n\\centering\n\\includegraphics[width=1.0\\textwidth]{img/case_compare.pdf}\n\\caption{Visualization comparisons of ground-truth anomalies and anomaly scores between DCdetector and Anomaly Transformer for different types of anomalies.} \n\\label{fig:case2} \n\\end{figure*}",
            "fig:ab": "\\begin{figure*}[htbp]\n\t\\centering\n\\subfigure[Window size]{\\includegraphics[width=.195\\textwidth]{img/wind-size.pdf}\\label{fig:ab-win}}\n\t\\subfigure[Multi-scale size]{\\includegraphics[width=.195\\textwidth]{img/scale-size.pdf}\\label{fig:ab-scale}}\n        \\subfigure[Encoder layer number]{\\includegraphics[width=.195\\textwidth]{img/encoder-layer.pdf}\\label{fig:ab-layer}}\n\t\\subfigure[Attention head number]{\\includegraphics[width=.195\\textwidth]{img/head-num.pdf}\\label{fig:ab-head}}\n\t\\subfigure[$d_{model}$ of attention]{\\includegraphics[width=.195\\textwidth]{img/embedding-size.pdf}\\label{fig:ab-atten}}\n    \\caption{Parameter sensitivity studies of main hyper-parameters in DCdetector.}\n        \\label{fig:ab} \n\\end{figure*}",
            "fig:mem-time": "\\begin{figure}[htbp]\n\t\\centering\n\t\\subfigure[Memory used]{\\includegraphics[width=.225\\textwidth]{img/MEM-size-bar.pdf}}\\quad\n\t\\subfigure[Time cost]{\\includegraphics[width=.225\\textwidth]{img/time-bar.pdf}\\label{fig:ab-time}}\n        \\caption{The averaged GPU memory cost and the averaged running time of 100 iterations during training with different $d_{model}$ sizes. } \n        \\label{fig:mem-time}  \n\\end{figure}"
        },
        "equations": {
            "eq:eq1": "\\begin{equation}\\label{eq1}\n    \\mathcal{Q_N}_i, \\mathcal{K_N}_i = \\mathcal{W_{Q}}_i \\mathcal{X_{N}}_i, \\mathcal{W_{K}}_i \\mathcal{X_{N}}_i \\quad 1 \\leq i \\leq H,\n\\end{equation}",
            "eq:eq2": "\\begin{equation}\\label{eq2}\n    Attn_{\\mathcal{N}_i} = Softmax(\\frac{\\mathcal{Q_{N}}_i \\mathcal{K_{N}}_i^T}{\\sqrt{\\frac{d_{model}}{H}}}),\n\\end{equation}",
            "eq:eq3": "\\begin{equation}\\label{eq3}\n    Attn_{\\mathcal{N}} = \\text{Concat}(Attn_{\\mathcal{N}_1},\\cdots, Attn_{\\mathcal{N}_H}) W_\\mathcal{N}^{O},\n\\end{equation}",
            "eq:eq4": "\\begin{equation}\\label{eq4}\n    \\mathcal{Q_P}_i, \\mathcal{K_P}_i = \\mathcal{W_{Q}}_i \\mathcal{X_{P}}_i, \\mathcal{W_{K}}_i \\mathcal{X_{P}}_i \\quad 1 \\leq i \\leq H,\n\\end{equation}",
            "eq:eq5": "\\begin{equation}\\label{eq5}\n    Attn_{\\mathcal{P}_i} = Softmax(\\frac{\\mathcal{Q_{P}}_i \\mathcal{K_{P}}_i^T}{\\sqrt{\\frac{d_{model}}{H}}}),\n\\end{equation}",
            "eq:eq6": "\\begin{equation}\\label{eq6}\n    Attn_\\mathcal{P} = \\text{Concat}(Attn_{\\mathcal{P}_1},\\cdots, Attn_{\\mathcal{P}_H}) W_\\mathcal{P}^{O},\n\\end{equation}",
            "eq:1": "\\begin{align}\n     \\mathcal{N} = \\text{Upsampling}(Attn_{\\mathcal{N}}),  \\quad    \\mathcal{P} = \\text{Upsampling}(Attn_{\\mathcal{P}}).\n\\end{align}",
            "eq:2": "\\begin{equation}\n    \\mathcal{L_P}\\{\\mathcal{P}, \\mathcal{N}; \\mathcal{X}\\} = \\sum KL(\\mathcal{P}, \\text{Stopgrad}(\\mathcal{N})) + KL(\\text{Stopgrad}(\\mathcal{N}), \\mathcal{P}),\n\\end{equation}",
            "eq:3": "\\begin{equation}\n    \\mathcal{L_N}\\{\\mathcal{P}, \\mathcal{N}; \\mathcal{X}\\} = \\sum KL(\\mathcal{N}, \\text{Stopgrad}(\\mathcal{P})) + KL(\\text{Stopgrad}(\\mathcal{P}), \\mathcal{N}),\n\\end{equation}",
            "eq:4": "\\begin{equation}\n    \\mathcal{L} = \\frac{\\mathcal{L_N}-\\mathcal{L_P}}{len(\\mathcal{N})}.\n\\end{equation}",
            "eq:5": "\\begin{equation}\n    \\text{AnomalyScore}(\\mathcal{X}) = \\sum KL(\\mathcal{P},\\text{Stopgrad}(\\mathcal{N}))+KL(\\mathcal{N},\\text{Stopgrad}(\\mathcal{P})).\n\\end{equation}",
            "eq:6": "\\begin{equation} \\label{eq11}\n\\mathcal{Y}_i = \n\\begin{cases}\n\\text{1: anomaly} \\quad \\text{AnomalyScore}(\\mathcal{X}_i) \\geq \\delta \\\\\n\\text{0: normal}  \\quad \\quad \\!\\!\\! \\text{AnomalyScore}(\\mathcal{X}_i) < \\delta .\n\\end{cases}\n\\end{equation}"
        },
        "git_link": "https://github.com/DAMO-DI-ML/KDD2023-DCdetector"
    }
}