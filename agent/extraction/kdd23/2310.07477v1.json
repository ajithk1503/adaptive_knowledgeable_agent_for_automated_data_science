{
    "meta_info": {
        "title": "GMOCAT: A Graph-Enhanced Multi-Objective Method for Computerized  Adaptive Testing",
        "abstract": "Computerized Adaptive Testing(CAT) refers to an online system that adaptively\nselects the best-suited question for students with various abilities based on\ntheir historical response records. Most CAT methods only focus on the quality\nobjective of predicting the student ability accurately, but neglect concept\ndiversity or question exposure control, which are important considerations in\nensuring the performance and validity of CAT. Besides, the students' response\nrecords contain valuable relational information between questions and knowledge\nconcepts. The previous methods ignore this relational information, resulting in\nthe selection of sub-optimal test questions. To address these challenges, we\npropose a Graph-Enhanced Multi-Objective method for CAT (GMOCAT). Firstly,\nthree objectives, namely quality, diversity and novelty, are introduced into\nthe Scalarized Multi-Objective Reinforcement Learning framework of CAT, which\nrespectively correspond to improving the prediction accuracy, increasing the\nconcept diversity and reducing the question exposure. We use an Actor-Critic\nRecommender to select questions and optimize three objectives simultaneously by\nthe scalarization function. Secondly, we utilize the graph neural network to\nlearn relation-aware embeddings of questions and concepts. These embeddings are\nable to aggregate neighborhood information in the relation graphs between\nquestions and concepts. We conduct experiments on three real-world educational\ndatasets, and show that GMOCAT not only outperforms the state-of-the-art\nmethods in the ability prediction, but also achieve superior performance in\nimproving the concept diversity and alleviating the question exposure. Our code\nis available at https://github.com/justarter/GMOCAT.",
        "author": "Hangyu Wang, Ting Long, Liang Yin, Weinan Zhang, Wei Xia, Qichen Hong, Dingyin Xia, Ruiming Tang, Yong Yu",
        "link": "http://arxiv.org/abs/2310.07477v1",
        "category": [
            "cs.IR"
        ],
        "additionl_info": "KDD23"
    },
    "latex_extraction": {
        "content": {
            "section 1": {
                "name": "Introduction",
                "content": "\n\\vspace{-2pt}\nWith the rapid development of Internet technology, Computerized Adaptive Testing (CAT) gradually releases the repetitive work with paper-and-pencil tests \\cite{appofcat}. CAT is an online test that can accurately measure the student ability by continuously feeding the most suitable questions to students \\cite{cat:primer}. CAT has been applied in many large-scale educational examination scenarios, e.g., GMAT \\cite{gmat} and GRE \\cite{gre}, to increase student engagements \\cite{cat:overview}.\n\n% CAT has been applied in many large-scale educational examination scenarios (e.g. GMAT \\cite{gmat} and GRE \\cite{gre}) by virtue of advantages, such as online assessment, real-time feedback of scores, and increased student engagement \\cite{cat:overview, cat:primer}.\n\nFigure \\ref{fig:catprocess} shows an example of the CAT procedure. A CAT system usually consists of two main components, which work iteratively: (1) \\textbf{Cognitive Diagnosis Model (CDM)}, which captures a student's ability using her responses to questions \\cite{cdm}. The simplest CDM is Item Response Theory (IRT) \\cite{irt}, using an item response function to approximate the student's real ability. Deep learning-based CDMs, such as NeuralCDM (NCD), apply neural networks to model interactions between students and questions \\cite{ncd}. (2) \\textbf{Selection Algorithm}, which selects the most suitable question for a student based on her historical response records. Traditional static algorithms usually use heuristic rules to select questions with the largest information \\cite{appofirt} or with the largest expected model change \\cite{maat}. These algorithms are usually greedy for one step but lack a long-term perspective. In recent years, data-driven approaches that learn selection rules from large-scale datasets have also emerged \\cite{bobcat}. The selection algorithm helps CDM evaluate the student ability more efficiently by selecting the best-suited questions. \n\n\n\nAs a question selector, the selection algorithm plays a crucial role in the above CAT process, thus we focus on designing an effective data-driven selection algorithm in this paper. In recent years, data-driven selection algorithms have been proposed from the perspectives of meta learning \\cite{bobcat} or Reinforcement Learning (RL) \\cite{ncat}. However, these studies only focus on the quality objective of predicting the student ability, which is insufficient in real-world scenarios \\cite{cat:overview}. We argue that the single-objective method suffers from two main limitations: (1) a lack of concept diversity. A good examination evaluates students' abilities on related but diverse knowledge concepts \\cite{maat}. For example, at the end of each semester, the final exam for mathematics usually covers concepts in algebra, geometry, etc. Unfortunately, previous algorithms are suboptimal due to the neglect of diversity issues, leading to very limited concepts. (2)a lack of novelty. CAT keeps reusing all questions in the question pool for different students, causing some questions to be selected too frequently. The overexposure of test questions will reduce their novelty and change the student's test-taking behavior \\cite{han2018components}. For example, overexposed questions can be known to many students, which could inflate the scores of subsequent students. Horribly, \\citet{bobcat} found that most selection algorithms prefer a part of questions, resulting in an excessive exposure rate. That is not practical in real-world CAT systems. In conclusion, quality, diversity and novelty are all important and deserve attention in CAT. Although some of previous studies \\cite{maat,Randomesque} have noticed these problems, they only focus on parts of them, and none have addressed these problems from a unified perspective.\n% \\lt{``Although some of previous researches \\cite{maat,Randomesque} noticed these issue, they only focus parts of them, none of them address this issue  from a unified perspective.''?}\n% The above two limitations hinder the performance of CAT. Some work has noticed and attempted to solve these limitations by additional modules \\cite{maat} or Boltzmann distribution \\cite{Randomesque}. However, these methods only consider either the diversity or the novelty, do not solve the two limitations from a unified perspective.\n\n% For example, to enforce diversity, \\citet{maat} designs an extra diversity module after generating a subset of high-quality questions. To control question exposure, \\citet{ncat} selects the question from the Boltzmann distribution of the Q value.\n\n\n\nTo address the above shortcomings, we propose a \\textbf{G}raph-Enhanced \\textbf{M}ulti-\\textbf{O}bjective method for \\textbf{CAT} (\\textbf{GMOCAT}). Firstly, we formalize the CAT procedure as a Multi-Objective Markov decision process (MOMDP) and then introduce a Scalarized Multi-Objective Reinforcement Learning (Scalarized MORL) framework into the CAT setting. \n% we catch that the CAT process is a complex and interdependent system. \nCompared with the greedy methods for CAT, the RL framework has been proven to explore more appropriate questions for students from a long-term view \\cite{ncat}.\n\n\n\nIn a unified framework, our GMOCAT considers the following three objectives: i) \\textbf{Quality} predicts the student ability accurately. ii) \\textbf{Diversity} diversifies knowledge concepts in recommended questions. iii) \\textbf{Novelty} controls the question exposure. In view of these three objectives, we design three rewards, namely, quality, diversity and novelty rewards. We design an Actor-Critic Recommender to select questions, which optimizes three objectives simultaneously with the scalarization function. A naive and widely used approach in MORL is to simply modify the environment to return a scalar weighted reward and optimize the policy by a single-objective method \\cite{mooinlearning}. In contrast to this, we improve the single-objective algorithm by extending the value and reward function to be vectorized. With the more fine-grained and vectorized feedback, the Actor-Critic Recommender doesn't confuse the objectives and achieves better performance \\cite{cantintoonereward, preguidemorl}.\n\n\n% Finally, to enhance the proposed framework, we learn the relation-aware embeddings of questions and concepts to encode the state of MORL. These relation-aware embeddings are aggregated from two relation graphs between questions and concepts, i.e. correlation graph and prerequisite graph, which have been neglected in previous work.\n\n% Secondly, the selecting algorithm chooses the next question based on students' historical responses to questions. Those responses containing rich relational information between questions and concepts help capture students' abilities. \n\n% GMOCAT also utilizes the relational information between the questions and knowledge concepts,\nTo further improve the effectiveness of CAT, the relational information between the questions and knowledge concepts can be utilized, since this information is closely related to the objectives in CAT. For example, the diversity objective requires to select questions that contain a variety of knowledge concepts. In our work, we mainly consider two types of relations: correlation and prerequisite, which are shown in Figure \\ref{fig:graphexample}. Correlation relation exists between a question and its related concepts, and prerequisite relation involves a pair of concepts, implying that one concept should be learned logically before the other (e.g. \\textit{multiplication} is the successor of \\textit{addition}). This relational information is crucial for selecting appropriate questions, but has been overlooked in previous work. Therefore, we employ relational information for question selection in our framework. In particular, we use graph attention networks to extract and aggregate neighborhood information from the multiple relation graphs.\n\n% Questions are related to each other by their common knowledge concepts, while knowledge concepts are linked together by various dependencies. Figure \\ref{fig:graphexample} shows the relation graphs with two relations: correlation and prerequisite. Correlation relation exists between a question and its related concept, and prerequisite relation involves a pair of concepts, implying that one concept should be learned logically before the other (e.g. \\textit{multiplication} is the successor of \\textit{addition}). These relational information is closely related to our three objectives, but has been overlooked in previous work. \n% Therefore, we employ the relational information for question selection in multi-objective framework. In particular, we use graph attention networks to extract and aggregate neighborhood information on the multiple relation graphs.\n\n% + experiment results, can we move this sentence to before the experiment results reveal?}two utilize two relation graphs among questions and concepts, which have been overlooked in the previous work, to encode the state of MORL. Our ablation experiments demonstrate the effectiveness of relation-aware embeddings. \n\n\nIn summary, our key contributions are listed as follows:\n\\begin{itemize}[leftmargin=2pt]\n    \\item We consider three important objectives in CAT: Quality, Diversity, and Novelty, and integrate them into a unified MORL framework. We also propose three rewards to quantify the feedback from three objectives. To our knowledge, this is the first work to apply MORL in CAT.\n    \\item We introduce relation graphs into CAT and learn relation-aware embeddings to help select more appropriate questions. It's also the first attempt to use relation graphs to aid in question selection.\n    \\item We conduct extensive experiments on three real-world educational datasets. The experimental results show that our method achieves a more accurate ability estimate than the state-of-the-art methods. Meanwhile, our proposed approach also significantly improves the concept diversity and reduces the question exposure.\n\\end{itemize}\n\n\n\n\n\n\n\n\n\n\n\n\\vspace{-10pt}\n"
            },
            "section 2": {
                "name": "Related Work",
                "content": "\n",
                "subsection 2.1": {
                    "name": "Computerized Adaptive Testing",
                    "content": "\nComputerized Adaptive Testing (CAT) has two main components: a Cognitive Diagnosis Model (CDM) and a Selection Algorithm. In traditional CAT systems, a widely used CDM is Item Response Theory (IRT) \\cite{irt}, which estimates the student ability by predicting her response to questions. The recently emerged Neural Cognitive Diagnosis Model (NCD) utilizes the neural network to model the student-question interactions \\cite{ncd}.\n\n% Computerized Adaptive Testing (CAT) is an online system that adaptively selects questions for students with various abilities. CAT aims to estimate the student ability with as few questions as possible by choosing the current best-fitting question given the student's response records \\cite{psybehindcat}.\n\nThis paper focuses on the selection algorithm. The most widely used algorithm utilizes Maximum Fisher Information (MFI) \\cite{appofirt} to select questions. Alternatively, Kullback-Leibler Information (KLI) \\cite{kli} calculates the integral over an ability interval to pick questions. These heuristic algorithms are designed for specific CDMs, such as IRT. To alleviate this problem, \\citet{maat} proposed a model-agnostic algorithm, MAAT, that leverages active learning for question selection. They also design an extra module to enforce concept diversity. RAT \\cite{rat} benefits the selection algorithm by capturing multiple aspects of the student ability. After that, more deep-learning based and data-driven algorithms have been developed. For example, BOBCAT \\cite{bobcat} is a meta learning-based method that couples CDM and selection algorithm together in a bilevel optimization problem. NCAT \\cite{ncat} is a reinforcement learning-based method that utilizes an attention-based DQN to select questions. NCAT also controls the question exposure by sampling from the Boltzmann distribution \\cite{boltzmanndistribution}. The above methods only consider either the importance of diversity or novelty without the combination of these two parts. To the best of our knowledge, few existing works have well established the multi-objective framework for CAT. \n\n\\vspace{-5pt}\n"
                },
                "subsection 2.2": {
                    "name": "Multi-Objective Optimization",
                    "content": "\n% Pareto optimal solutions are defined as non-dominated solutions representing trade-offs among multiple conflicting objectives \\cite{cantintoonereward}.\nMulti-Objective Optimization aims to reach Pareto Optimality while optimizing multiple objectives simultaneously \\cite{moogenetic}. Multi-objective problems can be solved by various methods, such as genetic algorithms \\cite{moogenetic}, evolutionary algorithms \\cite{mooincat} or Multi-Objective RL algorithms \\cite{modrl}. In CAT, \\citet{mooincat} proposed optimizing test length and accuracy by a multi-objective evolutionary algorithm. However, this method has not been verified on a real-world dataset. As far as we know, the most similar method to ours is DRE \\cite{mooinlearning} in the field of adaptive learning, which integrates three rewards into one, and uses a DQN strategy. In contrast, we apply Scalarized Multi-Objective policy gradient method to maintain mutual independence of objectives.\n% Moreover, we extract the relational information to help with question selection.\n\n\\vspace{-5pt}\n"
                },
                "subsection 2.3": {
                    "name": "Knowledge Graph",
                    "content": "\nKnowledge Graph contains a large amount of information with nodes (entities, e.g. questions or concepts) and edges (relations, e.g. prerequisite) \\cite{reviewofrelationgraph}. The relation graph, as a type of knowledge graph, has been used in many fields with various graph representation learning \\cite{rcd,gkt,cseal}. For example, GKT \\cite{gkt} uses Graph Neural Network (GNN) \\cite{gnn} with a graph-like knowledge structure for knowledge tracing. RCD \\cite{rcd} uses Graph Attention Network (GAT) \\cite{gat} to aggregate multi-level information for cognitive diagnosis and CSEAL \\cite{cseal} designs a graph-based cognitive navigation for adaptive learning. To our best knowledge, we are the first to involve the relation graph in the CAT setting. \n\\vspace{-5pt}\n"
                }
            },
            "section 3": {
                "name": "Preliminaries",
                "content": "\n\n% \\lt{suggested organization of this section: 1. data description; 2. graph definition; 3. CAT pipeline; 4. our problem formulation for CAT}\n",
                "subsection 3.1": {
                    "name": "Terminologies",
                    "content": " \n\\definition \\textbf{Response Record}. In CAT process, for the student $i$, her response record at test step $t$ is denoted as ($q^i_t$,$c^i_t$,$y^i_t$), where $q^i_t$ denotes the question responded by the student at step $t$, and $c^i_t$ denotes the concept covered by this question, and $y^i_t$ denotes the student's response. $y^i_t$ is 1 if the response is correct, and 0 otherwise. \n\nWe define two types of graphs to represent relations among questions and concepts.\n% There are multiple relations among questions and concepts, and we define two types of graphs to represent these relations. \nTaking Figure \\ref{fig:graphexample} as an example, we define the correlation graph and the prerequisite graph\\footnote{If a dataset does not explicitly contain the graph, we can construct one with the method from Appendix \\ref{app:graphconstruction}.}:\n% Figure \\ref{fig:graphexample} presents the examples of a correlation graph and a prerequisite graph. \\lt{youdian tuwu, may be we could say ``there are multiple relations among questions and concepts, and we define two types of graph to represent these relations.'', then say graph, subsequently take the figure as example} Specifically, we define these two types of graphs to represent the relations between questions and concepts\\footnote{If a dataset does not explicitly contain the graph, we can construct one with the method from Sec \\ref{graphconstruction}.}:\n\n% We denote the set of questions as $\\mathcal{Q}$. Each question in $\\mathcal{Q}$ is related to multiple knowledge concepts, we denotes the set of knowledge concepts as $\\mathcal{K}$. \n\\vspace{-5pt}\n\\definition \\textbf{Correlation Graph ($\\mathcal{G}_{qc}$)}: is an undirected bipartite graph to represent the relations between the questions and their related knowledge concepts. The set of nodes in $\\mathcal{G}_{qc}$ is composed by questions and concepts. An arbitrary edge in the edge set connects a question and one of its related concepts. \n\\vspace{-5pt}\n\\definition \\textbf{Prerequisite Graph ($\\mathcal{G}_{cc}$)}: is a directional graph to represent the prerequisite relations between concepts. The set of nodes in $\\mathcal{G}_{cc}$ is composed of knowledge concepts, and an arbitrary edge in the edge set connects a concept and its prerequisite concept.\n\n\n\n% Figure \\ref{fig:graphexample} presents an example of a correlation graph, in which the nodes are the question $q_1$, $q_2$ and their related knowledge concepts $c_1$ and $c_2$. Since $q_2$ is related to concept $c_2$(i.e. \\textit{multiplication}), there is an edge connecting $q_2$ and $c_2$. Figure \\ref{fig:graphexample} also shows an example of a prerequisite graph, in which a directed edge is from concept $c_1$ to $c_2$, since \\textit{addition} is a prerequisite for \\textit{multiplication}.\n\n% Figure \\ref{fig:graphexample} presents the examples of correlation graph and prerequisite graph. In the correlation graph, the nodes are the question $q_1$, $q_2$ and their related knowledge concepts $c_1$ and $c_2$. Since $q_2$ is related to concept $c_2$(i.e. \\textit{multiplication}), there is an edge connecting $q_2$ and $c_2$. In the prerequisite graph, a directed edge is from concept $c_1$ to $c_2$, since \\textit{addition} is a prerequisite for \\textit{multiplication}.\n\n\\vspace{-5pt}\n"
                },
                "subsection 3.2": {
                    "name": "The CAT Process and Problem Setting",
                    "content": "\n% \\lt{shall we name this part with ``The CAT Process and Problem Setting'': we discuss the cat process, the candidata/meta set, then the training and test process.\n\n% As we discussed before, \nCAT is composed of CDM and the selection algorithm, in which the former aims to estimate the student ability and the latter aims to select the best-suited question. Data-driven selection algorithms have been demonstrated to be superior to hand-designed ones \\cite{bobcat}. Therefore, we focus on designing an effective data-driven selection algorithm in this paper. \n\n% Specifically, CAT adopts the following process: (1) at step $t\\in [1,T]$, the selection algorithm first selects question $q_t^i$ to the student $i$ based on her historical response records; (2) the student gives her response $y_t^i$ to $q_t^i$ and CDM updates the current ability estimate $\\theta^i_t$ based on this response record. The above process iterates $T$ times. Since CAT is based on the assumption that student's real ability is ${\\theta}^i_*$ and remains constant in the testing process \\cite{psybehindcat}, the goal of CAT is to make the final estimate $\\theta^T$ as close to real ability ${\\theta}^i_*$ as possible. Our target in this paper is the design of selection algorithm, which selects the best question at each step to assist CDM in estimating students' abilities better. \\\\\n% To training the selection algorithm, a regular setting \\cite{ncat,bobcat} for CAT is splitting the samples which contains students' test records into candidate question set $\\mathcal{D}_c^i$ and meta question set $\\mathcal{D}_m^i$, as it is illustrated in Figure \\ref{fig：training/testing_phase}. The candidate question set act as the pool which selection algorithm select one question to test students ability. The meta question set is used to test the advantage of the selected question bring in estimate students' ability. Specifically, At each step, the selection algorithm select a question from the candidate question set to the student. Then the student give her response and the CDM estimate her ability according to her response on the given question. Finally, the estimated ability is used to predict her performance in answering the question of meta question set. Thus, if a better question is selected, the CDM has better estimation, which cause better prediction in meta question set. Since the candidate question set and meta question set has different question, the the prediction results on meta question set could be used to train and test the selection algorithm.\n\nThe CAT process with the data-driven selection algorithm consists of training and testing phases. To train/test the selection algorithm, a regular setting \\cite{ncat} is splitting the samples which contain student $i$'s test records into \\textbf{Candidate Question Set} $\\mathcal{D}^i_c$ and \\textbf{Meta Question Set} $\\mathcal{D}^i_m$, as illustrated in Appendix \\ref{app:training/testing_phase}. \n% The candidate and meta question sets are randomly selected and not the same for each student. \nBelow, we take the single-objective selection algorithm as an example to analyze the training/testing phase in CAT process:\n\n% \\begin{figure}\n%     \\centering\n%     \\includegraphics[width=\\linewidth]{picture/training_testing_phase.png}\n%     \\caption{The training/testing of the single-objective selection algorithm.}\n%     \\vspace{-10pt}\n%     \\label{fig:training/testing_phase}\n% \\end{figure}\n\n\\textbf{Training Phase}. For each student $i$ in the training set, (1) at test step $t\\in [1,T]$, the selection algorithm selects $q^i_t$ from candidate question set $\\mathcal{D}^i_c$ based on her historical response records; (2) the student gives her response $y^i_t$ and CDM updates the current ability estimate $\\theta^i_t$; (3) use $\\theta^i_t$ and meta question set $\\mathcal{D}^i_m$ to calculate a feedback(e.g., reward), which measures the accuracy of the ability estimate; (4) after $T$ iterations of the above process, we train the selection algorithm to maximize the feedback.\n\n\\textbf{Testing Phase\\footnote{Non-data-driven selection algorithms do not require training and can be tested directly}}. For a new student $j$ in the testing set, stages (1) and (2) are the same as the training phase. Stage (3) is to evaluate the accuracy of $\\theta^j_t$ on her meta question set $\\mathcal{D}^j_m$. The selection algorithm is not trained during the testing phase.\n\n% \\definition \\textbf{Typical CAT Process}. (1) at step $t\\in [1,T]$, the selection algorithm first selects question $q^i_t$ to the student $i$ based on her historical response records; (2) the student gives her response $y^i_t$ and CDM updates the current ability estimate $\\theta^i_t$ based on this response record. The above process iterates $T$ times. \n\n\nIn the CAT process, the student's real ability ${\\theta}^i_{*}$ is assumed to remain constant \\cite{psybehindcat}. From the above phases, we can find that the goal of single-objective method, so-called the quality objective, is to make the final estimate $\\theta^i_T$ as close to real ability ${\\theta}^i_*$ as possible by maximizing feedback. In our work, we not only consider the above quality objective, but also the diversity and novelty objectives, so as to optimize and evaluate CAT in multiple aspects. Overall, our target in this paper is \\textit{the design of selection algorithm, which selects the best-suited question at each step to achieve three objectives}.\n\n% Suppose there is a student set $\\mathcal{S}$, a question set $\\mathcal{Q}$ and a knowledge concept set $\\mathcal{K}$. For student $s_i$, her response record to question $q_t$ at step $t$ is defined as <$s_i$,$q_t$,$y_t$>, where response $y_t$ equals 1 if answer is correct, and 0 otherwise. Therefore, her historical response records at step $t$ are $(q_1,y_1, \\ldots, q_{t-1},y_{t-1})$ (we omit $s_i$ for the sake of brevity). Her  is $\\mathcal{D}^i$, which is divided into candidate set $\\mathcal{D}^i_c$ and meta set $\\mathcal{D}^i_m$. The selection algorithm only selects questions from candidate set and evaluate the ability estimation's accuracy on meta set. \n\n% The process of CAT is: (1) at test step $t\\in [1,T]$, the selection algorithm $\\pi$ first selects question $q_t$ from candidate set to student $s_i$ based on her historical response records: $q_t \\sim \\pi(q_1,y_1, \\ldots, q_{t-1},y_{t-1})$. (2) the student gives her response $y_t$ and CDM updates the current ability estimate $\\theta_t^i$ based on this response record. The above process iterates continuously until the specified test length is reached \\footnote{in this paper, we only consider CAT with fixed test length}. \n\n% A basic assumption is that each student has a real ability, denoted as $\\theta^*$, that remains constant throughout the whole CAT process \\cite{psybehindcat}. This assumption makes CAT different from other educational scenarios, such as adaptive learning \\cite{drlinadaptivelearning}. The traditional goal of CAT is to make the final estimate $\\theta_T$ as close to real ability $\\theta^*$ as possible. Moreover, in our work, we not only consider the above goal, but also consider the diversity and novelty metrics, so as to optimize and evaluate CAT in multiple aspects. \\lt{can we remove this paragraph?}\n\\vspace{-5pt}\n"
                }
            },
            "section 4": {
                "name": "Method",
                "content": "\n\n\n\n",
                "subsection 4.1": {
                    "name": "Formulation and Overview",
                    "content": "\nAs described in the Introduction, the CAT process is a complex and interdependent system . \n% which includes the encoding of historical response records, the estimation of the student's ability, and the decision process of the selection algorithm \\lt{can we remove this sentence}. \n% In contrast to examining the dynamics of CAT as a whole and performing direct optimization, \nWe model the CAT task as a sequential decision problem and formalize it as a Multi-Objective Markov decision process (MOMDP) \\cite{modrl}. The RL framework can explore more suitable questions from a long-term view rather than the greedy approximation \\cite{ncat,dai2021adversarial}. This MOMDP can be defined by tuples of $<\\mathcal{S}, \\mathcal{A}, \\mathcal{P}, \\mathbf{R}, \\gamma>$, in which:\n\\begin{itemize} [leftmargin=2pt]\n    \\item $\\mathcal{S}$: denotes the set of states that are used by the selection algorithm to select questions. Given a test step $t$, the state can be defined as $\\mathbf{s}^i_t=f_{se}(\\{(q^i_1,c^i_1,y^i_1),\\ldots,(q^i_{t-1},c^i_{t-1},y^i_{t-1})\\}) \\in \\mathcal{S}$, where $f_{se}$ is a state encoder that will be discussed in Section \\ref{sec:stateencoder}. The state encoder takes the student $i$'s historical response records $\\{(q^i_1,c^i_1,y^i_1),\\ldots,(q^i_{t-1},c^i_{t-1},y^i_{t-1})\\}$ as input and outputs state $\\mathbf{s}^i_t$.\n    \\item $\\mathcal{A}$: is a finite set of actions. At a given step $t$, an action is taken from the action space (i.e., the candidate question set) to select the question $q^i_t$ by the selection algorithm $\\pi$.\n    \\item $\\mathcal{P}$: denotes the transition probability of reaching next state $\\mathbf{s}^i_{t+1}$ after selecting question $q^i_t$ on state $\\mathbf{s}^i_t$. i.e., $\\mathcal{P}(\\mathbf{s}^i_{t+1}|\\mathbf{s}^i_t,q^i_t)$.\n    \\item $\\mathbf{R}$: $\\mathcal{S} \\times \\mathcal{A} \\mapsto \\mathbb{R}^m$, denotes the instant reward function for the selection algorithm to select $q^i_t$ on state $\\mathbf{s}^i_t$. Different from previous work, our reward is vector-valued. In our setting, $\\mathbf{r}(\\mathbf{s}^i_t, q^i_t)= [r_{qua}, r_{div},r_{nov}]$, which refers to the quality, diversity and novelty reward respectively. This reward will be explained in Section \\ref{sec:moreward}.\n    \\item $\\gamma \\in [0,1]$: is the discounted factor that trades off the immediate and future rewards. \n\\end{itemize}\n\n\nSo far, we have reconstructed the CAT process from the perspective of MORL. \n\n\\textbf{MORL Formulation of CAT Process}: Let $n$ denote the number of students. For student $i$, at test step $t$, the selection algorithm $\\pi$ selects question $q^i_t$ from her candidate question set based on the state $\\mathbf{s}^i_t$, i.e., $\\pi(q^i_t|\\mathbf{s}^i_t)$. Then, it pushes $q^i_t$ to the student $i$ and receives multi-objective reward $\\textbf{r}(\\mathbf{s}^i_t,q^i_t)$. Finally, our multi-objective goal is to maximize the weighted-sum return $\\mathcal{J}$:\n\\vspace{-5pt}\n\\begin{align}\n    \\max_{\\pi} \\mathcal{J} &= \\max_{\\pi} \\frac{1}{n} \\sum_{i=1}^{n} \\left[ \\mathbf{w}^T \\left( \\sum_{t'=1}^{T}\\gamma^{t'}\\mathbf{r}\\left(\\mathbf{s}^i_{t'},q^i_{t'}\\right)\\right) \\right] \\\\\n   &=\\max_{\\pi} \\mathbb{E}_{i \\sim \\pi} \\left[ \\mathbf{w}^T \\left( \\sum_{t'=1}^{T}\\gamma^{t'}\\mathbf{r}\\left(\\mathbf{s}^i_{t'},q^i_{t'}\\right)\\right) \\right]\n   \\label{eq:objectivefunction}\n\\end{align}\n$\\mathbf{w}$ is the scalarization function, which can be regarded as a weight vector whose element represents the importance of each objective. \n\nUnder this goal, our GMOCAT consists of four components: a multi-objective reward, a relation aggregator, a self-attentive state encoder, and an actor-critic recommender. As it is shown in Figure \\ref{fig:modelframework}, the relation aggregator uses relation graphs to learn the relation-aware embeddings of questions and concepts. Then, state encoder uses these embeddings to encode students' historical response records, and generates the state of GMOCAT. Subsequently, this state is fed to the actor-critic recommender, which is instructed by the multi-objective reward, to select the questions. \n\nTo adequately explain the details of GMOCAT, we will first go through the multi-objective reward, self-attentive state encoder and actor-critic recommender. Lastly, we discuss how to use the relation aggregator to learn the relation-aware embeddings. Please note that \\textit{in the following sections, we omit superscript $i$ as we discuss how to select questions for a single student}.\n\n% Under this goal, our GMOCAT consists of four components: a multi-objective reward, a relation aggregator, a self-attentive state encoder, and an actor-critic recommender, which are shown in Figure \\ref{fig:modelframework}. As the key to model optimization, we firstly discuss the design of the multi-objective reward based upon three objectives of CAT. Next, we begin to represent the state. The relation aggregator is used to learn relation-aware representations of questions and concepts, given the relation graphs between them. Then the state encoder takes the historical response records as input and generates the state using the relation-aware embeddings and a self-attention mechanism. Finally, the actor-critic recommender selects the next question using the state. We will describe these components in detail in the following sections.\n\n% \\subsubsection{\\textbf{Overview}}\n% The GMOCAT method consists of four components: a multi-objective reward, a relation aggregator, a self-attentive state encoder, and an actor-critic recommender. Figure \\ref{fig:modelframework} shows the GMOCAT method and its components.\n\n% we can see three important components: (1) The Multi-Objective Rewards, which are essential feedback from three objectives. (2) The Actor-Critic Recommender, which contains an actor acts as a policy to select questions, and a critic to evaluate the state. (3) State Encoder, which represents the state for policy to make decision. In the following, we will discuss these components in details.\n\n\n% Generally, our GMOCAT contains three main components, i.e., Multi-Objective Rewards, State Encoder and Multi-Objective Actor-Critic Recommender (MOACR). The overall framework is shown in Figure \\ref{fig:modelframework}. State Encoder converts the historical response records into a low-dimensional state representation Given the state, MOACR chooses the next question and receives the instant Multi-Objective Rewards, which will be used for the reinforcement learning training at the end of the test.\n\n"
                },
                "subsection 4.2": {
                    "name": "Multi-Objective Reward",
                    "content": " \n\\label{sec:moreward}\n% Reward is the essential feedback received by the selection algorithm during the adaptive testing process.\n\nIn this part, we discuss how to design our multi-objective reward, which plays an important role in learning the optimal selection algorithm. As mentioned before, previous works only focus on the quality objective. However, such single-objective methods cannot satisfy the needs of CAT in practice. In this paper, we incorporate three domain-specific objectives into the reward design, including quality, diversity and novelty, to support the adaptive question selection.\n\n% CAT should concentrate on several objectives. In this part, we explain the design of our multi-objective reward, namely the quality, diversity and novelty reward, to highlight the core objectives within GMOCAT. \n\n",
                    "subsubsection 4.2.1": {
                        "name": "Quality",
                        "content": "\n\nAn excellent selection algorithm should select the best-suited question to predict the student's ability accurately. For an arbitrary student, since her real ability is unknown, we can use her meta question set to measure the error of ability estimate ${\\theta}_t$. Specifically, at test step $t$, we use ${\\theta}_t$ to calculate the prediction accuracy on her meta question set, which is denoted as $ACC({\\theta}_t)$.\n% we obtain the ability estimate ${\\theta}_t$ at step $t$, then calculate the accuracy on her meta question set by using ${\\theta}_t$, which is denoted as $ACC({\\theta}_t)$. \nA higher value of $ACC({\\theta}_t)$ means the ability estimate ${\\theta}_t$ is more accurate and closer to real ability.\n\n% we leverage the fit of ability \\lt{fit of ability?} estimate ${\\theta}_t$ on her meta question set to measure the error between the ability estimate and real ability \\cite{ncat}. Specifically, at test step $t$, we use the ability estimate to predict binary-valued responses on her meta question set, and denote the calculated accuracy as $ACC_t$. Larger $ACC_t$ means smaller error. \\lt{may be we need state the meaning of ${ACC}_t$}\n\n% Intuitively, the better the selection algorithm, the more likely it is to select the best-suited question to improve the estimation accuracy. We set the accuracy of the ability estimate as a quality goal. However, we can't measure this accuracy directly since the ability groundtruth in reality is inaccessible. A conventional solution \\cite{ncat} is to evaluate the student $i$'s ability estimate  by using it to predict binary-valued responses on  held-out set, namely the meta set. \n% We denote this accuracy at the step $t$ as $ACC_t$.\nIntuitively, a stimulation should be given if the selected question by the selection algorithm helps enhance the accuracy of ability estimate. Comparatively, a punishment should be given if the selected question reduces this accuracy. Formally, we design the quality reward as:\n\\begin{equation}\n    r_{qua} = ACC({\\theta}_t) - ACC({\\theta}_{t-1})\n\\label{equ:qualityreward}\n\\end{equation}\nThe meta question set is used to compute quality reward and will not be selected to the student. \n\n"
                    },
                    "subsubsection 4.2.2": {
                        "name": "Diversity",
                        "content": "\n\\label{sec:diveristyreward}\n\nIn the large and comprehensive exam, the test questions should include rich knowledge concepts \\cite{maat}. The diversity objective requires to cover a variety of knowledge concepts. This implies that a stimulation should be given if the selection algorithm chooses a question with a new concept. Here, for simplicity, we discretize the reward value. Formally, the diversity reward is 1 if a question involving a new concept is selected, and 0 otherwise:\n% \\vspace{-5pt}\n\\begin{equation}\n    r_{div} =\n    \t\\begin{cases}\n\t\t\t\t 1, \\quad \\text{if}\\quad c_t \\setminus \\{c_1 \\cup c_2 \\ldots \\cup c_{t-1}\\} \\neq \\emptyset \\\\\n\t\t\t\t 0, \\quad \\text{otherwise}\n\t\t\\end{cases}\n\t\t\\label{equ:diversityreward}\n\\end{equation}\n% \\vspace{-5pt}\nwhere $c_t$ is the concept covered by the question $q_t$ at test step $t$. The binary reward setting is commonly used in RL \\cite{mooinlearning, morlrs}.\n\n"
                    },
                    "subsubsection 4.2.3": {
                        "name": "Novelty",
                        "content": "\nAs mentioned before, a proper selection algorithm should take novelty into account because the lack of novelty can lead to overexposed questions and may affect students' test behaviors \\cite{han2018components}. For example, students can tell the later classmates the answers to the overexposed questions. \n% control the question exposure to ensure fairness and validity \\lt{change},\n\n\nTherefore, we design the novelty reward to control the question exposure. Let $\\mathcal{T}$ denote the set of top $x\\%$ of most popular questions in the training set. We encourage the selection of less popular questions, as these questions are more likely to be novel in the future and lead to a balanced distribution of question exposures. Along this line, the novelty reward is 1 if the selected question $q_t$ is not in $\\mathcal{T}$, and 0 otherwise: \n\\vspace{-5pt}\n\\begin{equation}\n    r_{nov} =\n    \t\\begin{cases}\n\t\t\t\t 1, \\quad \\text{if}\\ q_t \\notin \n \\mathcal{T}\\\\\n\t\t\t\t 0, \\quad \\text{otherwise}\n\t\t\\end{cases}\n\t\t\\label{equ:noveltyreward}\n\\end{equation}\n% \\vspace{-5pt}\nTake note that after determining the training set, $\\mathcal{T}$ is calculated and fixed, and will not change throughout the CAT process. In this paper, we set $x=10$ following \\citet{morlrs}. \n\nSo far, we have defined the vector-valued reward $\\mathbf{r}(\\mathbf{s}_t, q_t)= [r_{qua}, r_{div},r_{nov}]$, which refers to the quality, diversity and novelty reward respectively. From the optimization function in Equation \\ref{eq:objectivefunction}, the reward vector is multiplied by the scalarization function $\\textbf{w}$. The each element of $\\textbf{w}$ can be regarded as the importance of the corresponding objective, and we discuss its role in the Section \\ref{sec:objectivecomparion}.\n\n"
                    }
                },
                "subsection 4.3": {
                    "name": "State Encoder",
                    "content": "\n\\label{sec:stateencoder}\n% Here we describe how to use relation-aware embeddings and state encoder to generate state $\\mathbf{s}_t$. \nGenerally, state encoder takes the historical response records as input to generate the state of GMOCAT: $\\mathbf{s}_t=f_{se}(\\{(q_1,c_1,y_1),\\ldots,\\\\(q_{t-1},c_{t-1},y_{t-1})\\})$. We will detail how the state encoder $f_{se}$ is implemented below.\n\n% \\lt{based on the previous statement, we can remove the subsection titles of both 4.3.1 and 4.3.2, and remove the first paragraph of 4.3.2}\n\nSuppose the number of questions is $Q$, we use embedding matrix $\\mathbf{W}_q \\in \\mathbb{R}^{Q\\times d}$ to map each question $q$ into the real-valued embedding $\\mathcal{E}_q \\in \\mathbb{R}^d$: $\\mathcal{E}_q = \\mathbf{x}_q \\mathbf{W}_q$, where $\\mathbf{x}_q$ is the one-hot vector of $q$, and $d$ is the embedding dimension. $\\mathcal{E}_q$ characterizes information about questions. We apply the same operation to get the concept embedding $\\mathcal{E}_c \\in \\mathbb{R}^d$ of concept $c$ and response embedding $\\mathcal{E}_y \\in \\mathbb{R}^d$ of response $y$.\n\n% \\subsubsection{Relation-aware Embeddings}\nThe relation aggregator is used to extract relational information and learn relation-aware embeddings. By using graph neural networks, the aggregator takes raw question embeddings $\\mathcal{E}_q$ and raw concept embeddings $\\mathcal{E}_c$ as input and outputs corresponding relation-aware embeddings $\\widetilde{\\mathcal{E}}_q$ and $\\widetilde{\\mathcal{E}}_c$ (detailed in the Section \\ref{sec:relationaggregator}). Alternatively, we could use raw embeddings of questions and concepts similar to prior work, but we find that the relation-aware representations perform better in most datasets. The performance of relation-aware representations will be further discussed in Section \\ref{sec:ablation}.\n\n% The choice of using relation-aware embeddings rather than raw embeddings reflects our opinion: \\textit{the relational information included in the questions and concepts benefits the prediction of student ability}.\n\n% \\subsubsection{State Encoder}\n% Generally, state encoder takes the historical response records as input and generates the state, which can be defined as $\\mathbf{s}_t=f_{se}(\\{(q_1,c_1,y_1),\\ldots,(q_{t-1},c_{t-1},y_{t-1})\\})$. We will detail how the state encoder $f_{se}$ is implemented below.\n\nGiven the step $t$, the state encoder represents historical question sequence $\\{q_{1:t-1}\\}$ by relation-aware question embeddings\\footnote{For questions, $\\{q_{1:t-1}\\}$ is short for $\\{q_1,\\ldots,q_{t-1}\\}$, and $\\{\\widetilde{\\mathcal{E}}_q^{1:t-1}\\}$ is short for $\\{\\widetilde{\\mathcal{E}}_q^{1},\\ldots,\\widetilde{\\mathcal{E}}_q^{t-1}\\}$. This also applies to concepts and responses.} $\\{\\widetilde{\\mathcal{E}}_q^{1:t-1}\\}$, represents historical concept sequence $\\{c_{1:t-1}\\}$ by relation-aware concept embeddings $\\{\\widetilde{\\mathcal{E}}_c^{1:t-1}\\}$. The historical response sequence $\\{y_{1:t-1}\\}$ is represented by raw response embeddings $\\{\\mathcal{E}_y^{1:t-1}\\}$. Note that the state encoder's input $\\{(q_{t'},c_{t'},y_{t'})|t'\\in [1,t-1]\\}$ is the response records at all previous steps. Thus, for each previous step $t'\\in [1,t-1]$, the triple $(q_{t'},c_{t'},y_{t'})$ can be represented by $\\mathbf{e}_{t'}$, which is the concatenation of relation-aware question embedding $\\widetilde{\\mathcal{E}}_q^{t'}$, relation-aware concept embedding $\\widetilde{\\mathcal{E}}_c^{t'}$ and response embedding $\\mathcal{E}_y^{t'}$. The formulation of $\\mathbf{e}_{t'} \\in \\mathbb{R}^{D}$ is given by:\n% \\vspace{-3pt}\n\\begin{equation}\n    \\mathbf{e}_{t'} = \\widetilde{\\mathcal{E}}_q^{t'} \\oplus \\widetilde{\\mathcal{E}}_c^{t'} \\oplus \\mathcal{E}_y^{t'}\n% \\vspace{-3pt}\n\\end{equation}\nwhere $D=3d$. If a question contains multiple concepts, we take the mean of relation-aware embeddings of related concepts as $\\widetilde{\\mathcal{E}}_c^{t'}$.\n\nThen the historical response records $\\{(q_{t'},c_{t'},y_{t'})|t'\\in [1,t-1]\\}$ can be represented by a embedding matrix $\\mathbf{E}_t =[\\mathbf{e}_1, \\mathbf{e}_2, \\ldots, \\mathbf{e}_{t-1}]^T \\in \\mathbb{R}^{(t-1)\\times D}$. We note that response records contain different amounts of information. For example, answering a hard question correctly contains more information than answering a simple question correctly. To capture the differences among response records, we apply self-attention mechanism \\cite{mhsa} on  $\\mathbf{E}_t$, which is defined as the scaled dot-product function:\n\n% \\vspace{-11pt}\n\\begin{equation}\n    \\widetilde{\\mathbf{E}}_t=\n    \\text{Softmax}(\\frac{(\\mathbf{E}_t \\mathbf{W}^Q) (\\mathbf{E}_t \\mathbf{W}^K)^T}{\\sqrt{d_k}})(\\mathbf{E}_t \\mathbf{W}^V)\n    \\label{eq:selfattention}\n    % \\vspace{-4pt}\n\\end{equation}\nwhere $\\mathbf{W}^Q, \\mathbf{W}^K, \\mathbf{W}^V \\in \\mathbb{R}^{D \\times D}$ are trainable matrices, $\\sqrt{d_k}$ is scaling factor \\cite{mhsa}. We add LayerNorm \\cite{layernorm} and skip-connection \\cite{skipconnect} behind the self-attention mechanism. We also use Dropout \\cite{dropout} to avoid the overfitting.\n\nNotice that the student’s real ability is unchanged during the CAT process \\cite{cat:primer}, the order of each record is not important. We input $\\widetilde{\\mathbf{E}}_t$ (the embeddings after self-attention) into the average-pooling, and generate the state $\\mathbf{s}_t\\in\\mathbf{R}^D$. The actor-critic recommender uses this state to select the next question.\n\n"
                },
                "subsection 4.4": {
                    "name": "Actor-Critic Recommender",
                    "content": "\n\\label{moppo}\n\nThe actor-critic recommender takes the state $\\mathbf{s}_t$ as input. We utilize a policy network as the actor to generate actions by sampling from the distribution $\\pi(q_t|\\mathbf{s}_t;\\phi_\\pi)$. The actor is a fully connected layer with parameter $\\phi_\\pi$. Besides, we use a value network as the critic to evaluate the state. Given a state $\\mathbf{s}_t$, the critic's output $\\mathbf{V}(\\mathbf{s}_t)$ is a vector that predicts the expected return, each element of which corresponds to an objective, defined by $\\mathbf{V}(\\mathbf{s}_t;\\phi_v) = [V(\\mathbf{s}_t)_{qua}, V(\\mathbf{s}_t)_{div}, V(\\mathbf{s}_t)_{nov}]$. The subscripts $\\{qua, div, nov\\}$ refer to quality, diversity and novelty objectives, respectively. The critic is also a fully connected layer with parameter $\\phi_v$.\n\nTo maximize the weighted-sum return $\\mathcal{J}$ in Equation \\ref{eq:objectivefunction}, we modify PPO method \\cite{ppo} into a multi-objective form. Specifically, the advantage value for selecting $q_t$ is defined as the actual return of a state-action pair minus the expected return of this state:\n\\begin{equation}\n    \\mathbf{A}(\\mathbf{s}_t,q_t)=\\sum_{t'=t}\\gamma^{t'-t}\\mathbf{r}(\\mathbf{s}_{t'},q_{t'})-\\mathbf{V}(\\mathbf{s}_t)\n    \\label{eq:return}\n\\end{equation}\n\\vspace{-5pt}\n\n\nWe use the scalarization function $f_w$ to convert the vectorized advantage $\\mathbf{A}$ into a scalar. As introduced before, we choose linear function $f_w=\\mathbf{w}$, where importance weight $w_i$ corresponds to individual objective. The clipped surrogate loss is applied to update the actor parameters:\n\\vspace{-5pt}\n\\begin{equation}\n\\begin{split}\n\\mathcal{L}_1 = -& \\mathbb{E}_{\\tau \\sim \\pi_{old}} [\\text{Min} \\{\\frac{\\pi(q_t|\\mathbf{s}_t)}{\\pi_{old}(q_t|\\mathbf{s}_t)} \\mathbf{w}^T \\mathbf{A}(\\mathbf{s}_t,q_t),  \\\\ \n&\\text{Clip} \\left( \\frac{\\pi(q_t|\\mathbf{s}_t)}{\\pi_{old}(q_t|\\mathbf{s}_t)},1-\\epsilon , 1+\\epsilon \\right) \\mathbf{w}^T \\mathbf{A}(\\mathbf{s}_t,q_t) \\}] \n\\end{split}\n\\label{eq:actorloss}\n\\end{equation}\n% \\vspace{-5pt}\n\n% where we add an entropy loss on the distribution of the actor output to encourage action exploration, $\\alpha$ is the hyperparameter. \n% \\begin{equation}\n%     \\mathcal{L}_2 = \\sum_{q} [\\pi(q|s_t)\\log \\pi(q|s_t)]\n% \\end{equation}\n\nThe critic loss is based on the purpose that the expected return gets as close to the actual return as possible:\n% \\vspace{-5pt}\n\\begin{equation}\n    \\mathcal{L}_2=\\frac{1}{2} \\mathbf{w}^T \\|\\mathbf{V}(\\mathbf{s}_t) - \\sum_{t'=t}\\gamma^{t'-t}\\mathbf{r}(\\mathbf{s}_{t'},q_{t'})\\|^2 \n\\end{equation}\n% \\vspace{-5pt}\n\nFinally, the Multi-Objective PPO(MOPPO) loss is a weighted sum of two losses with the trade-off hyperparameter $\\alpha \\in\\mathbb R_{+}$:\n\\begin{equation}\n    \\mathcal{L} = \\mathcal{L}_1 + \\alpha \\mathcal{L}_2\n    \\label{equ:moppoloss}\n\\end{equation}\n\n"
                },
                "subsection 4.5": {
                    "name": "Relation Aggregator",
                    "content": "\n\\label{sec:relationaggregator}\n\nAs we discussed above, the relational information included in the questions and concepts is closely related to our three objectives, but is neglected by existing CAT methods. We use the relation aggregator to aggregate relational information. In this part, we describe the aggregation of relational information from the perspectives of concepts and questions. \n\n",
                    "subsubsection 4.5.1": {
                        "name": "Concept Relation",
                        "content": "\nSince the concepts appear in both prerequisite and correlation graphs, concept embedding is influenced by two relations. We apply graph attention network \\cite{gat} (GAT) to aggregate neighbor embeddings in two graphs. For each concept $c$ with raw embedding $\\mathcal{E}_c$, let $N_c^{pre}, N_c^{cor}$ be its neighborhood in the prerequisite and correlation graph. We aggregate neighbor embeddings with the attention weights to get the prerequisite-aware embedding $\\mathbf{g}_{pre}$ and the correlation-aware embedding $\\mathbf{g}_{cor}$:\n\\begin{equation}\n    \\mathbf{g}_{pre} =\\sum_{c'\\in N_c^{pre}} \\alpha_{c,c'}\\mathbf{W}_{pre}\\mathcal{E}_{c'},\\ \\  \\mathbf{g}_{cor} =\\sum_{q'\\in N_c^{cor}} \\beta_{c,q'}\\mathbf{W}_{cor}\\mathcal{E}_{q'}\n\\end{equation}\nIntuitively, the attention weights ($\\alpha_{c,c'}$ or $\\beta_{c,q'}$) are related to the similarity between neighbor embeddings and the concept $c$ embedding, defined by:\n\\begin{align}\n    \\alpha_{c,c'} &= \\text{Softmax}_{c'} \\left( \\text{att}_{pre} \\left([\\mathbf{W}_{pre}\\mathcal{E}_{c},  \\mathbf{W}_{pre}\\mathcal{E}_{c'}]\\right)\\right), c' \\in N_c^{pre} \\\\\n    \\beta_{c,q'} &= \\text{Softmax}_{q'} \\left( \\text{att}_{cor} \\left([\\mathbf{W}_{cor}\\mathcal{E}_{c}, \\mathbf{W}_{cor}\\mathcal{E}_{q'}]\\right)\\right), q' \\in N_c^{cor} \\label{eq:betaweight}\n\\end{align}\nwhere $\\text{att}_\\bullet$ denotes a linear layer with a LeakyReLU activation function. $[\\cdot]$ is the concatenation operation, $\\mathbf{W}_{pre}, \\mathbf{W}_{cor}$ are trainable matrices.\n\nPrerequisite-aware embedding and correlation-aware embedding contain different relational information. To distinguish their different importances, we use the following treatment. Prerequisite-aware embedding's weight $\\mu_{pre}$ is related to the similarity between the attention vector $\\mathbf{P}$ and prerequisite-aware embedding, defined by \n\\begin{equation}\n    \\mu_{pre} = \\mathbf{P}^T \\cdot tanh(\\mathbf{W} \\cdot \\mathbf{g}_{pre}+\\mathbf{b})\n\\end{equation}\n% \\mu_{pre} = \\text{MLP}\\left([\\mathcal{E}_{c}, \\mathbf{g}_{pre}]\\right)\nand the weight $\\mu_{cor}$ can be modeled similarly. These two weights are normalized by a softmax operation. Finally, the relation-aware embedding of concept $c$, denoted as $\\widetilde{\\mathcal{E}}_{c}$, is the weighted sum of prerequisite-aware embedding and correlation-aware embedding:\n\\begin{equation}\n    \\widetilde{\\mathcal{E}}_{c}= \\mu_{pre} \\mathbf{g}_{pre} + \\mu_{cor} \\mathbf{g}_{cor} \n\\end{equation}\n\n\n"
                    },
                    "subsubsection 4.5.2": {
                        "name": "Question Relation",
                        "content": "\nSimilar to the concept, we perform question neighbor aggregation via GAT again. For each question $q$ with raw embedding $\\mathcal{E}_q$, let $N_q^{cor}$ be its neighbor set in the correlation graph. Since questions only contain correlation relation, the relation-aware embedding $\\widetilde{\\mathcal{E}}_{q}$ is the correlation-aware embedding $\\mathbf{h}_{cor}$. The relation-aware embedding of question $q$ is $\\widetilde{\\mathcal{E}}_{q}$, given as:\n\\begin{gather}\n    \\mathbf{h}_{cor}=\\sum_{c'\\in N_q^{cor}} \\xi_{q,c'}{\\mathbf{W}}_{cor}\\mathcal{E}_{c'}, \\quad \\widetilde{\\mathcal{E}}_{q} = \\mathbf{h}_{cor}\n\\end{gather}\nThe weight $\\xi_{q,c'}$ can be modeled similar to the forms in Eq. \\ref{eq:betaweight}. \n\n\n\n\n"
                    }
                }
            },
            "section 5": {
                "name": "Experiments",
                "content": "\nIn this section, we conduct extensive experiments on three real-world educational datasets to evaluate the effectiveness of our proposed GMOCAT method.\n\n",
                "subsection 5.1": {
                    "name": "Data Partition and Experiment Process",
                    "content": "\nWe evaluate our GMOCAT method on three real-world educational datasets: Eedi\\footnote{https://eedi.com/projects/neurips-education-challenge}, ASSIST\\footnote{https://sites.google.com/site/assistmentsdata/home/assistment-2009-2010-data/skill-builder-data-2009-2010} and Junyi\\footnote{https://www.kaggle.com/datasets/junyiacademy/learning-activity-public-dataset-by-junyi-academy}. Eedi \\cite{eedidataset} is from the response logs over the 2018-2020 years on an educational platform Eedi. ASSIST \\cite{assist09} is from the ASSISTments online tutoring platform. Junyi \\cite{junyi} is gathered from the exercise logs over the 2018-2019 year on the online learning website Junyi Academy.\n\nFor all datasets, we remove students with fewer than 40 test records. The statistics of the processed datasets are listed in the Table \\ref{tab:statistics}. We use 80\\%-10\\%-10\\% students for training, validation and testing respectively. The students in the training set do not appear in the validation/testing set. The training set is used to get calibrated question parameters, most popular questions for novelty reward, and to optimize the selection algorithm \\footnote{The static selection algorithms do not require training.}. Furthermore, we partition the samples which contain student $i$'s test records into the candidate question set ($\\mathcal{D}^i_c$, 80\\%) and the meta question set ($\\mathcal{D}^i_m$, 20\\%). These two sets are not the same for each student, and also generated randomly in each training epoch to prevent overfitting \\cite{bobcat}.\n\n\nThe experimental results are averaged over five runs. All our experimental results are obtained on the testing set. For each student $j$ in the testing set, (1) we use the selection algorithm to select a question from $\\mathcal{D}^j_c$; (2) CDM updates ability estimate with the corresponding responses; (3) we evaluate the selection algorithm by different metrics and report the value. \n\n% To meet the requirements of quality reward, we randomly divide one fifth of each student's response records into a meta set, and the remaining part is worked as the , . To be fair, questions in the meta set are not selected to students, and the meta set partitions of the validation and testing students are exactly the same for all methods.\n% For each student, we keep only the first response in case of duplicate questions.\n\n\n\n\n\n"
                },
                "subsection 5.2": {
                    "name": "Evaluation Method",
                    "content": "\n",
                    "subsubsection 5.2.1": {
                        "name": "Quality Metric",
                        "content": "\n\nWe evaluate the accuracy of final ability estimate of student $i$ by predicting binary-valued student responses on her meta question set $\\mathcal{D}^i_m$. Therefore, we take Area Under ROC Curve (AUC) \\cite{auc} and Accuracy (ACC) as quality metrics to assess different selection algorithms.\n\n% The better the selection algorithm is, the more likely it is to choose the most suitable question to improve estimation accuracy. The ability estimate can be evaluated by predicting binary-valued responses on the meta set. Thus we take Area Under ROC Curve (AUC) \\cite{auc} and Accuracy (ACC) as quality metrics to evaluate the performance of different selection algorithms.\n\n"
                    },
                    "subsubsection 5.2.2": {
                        "name": "Diversity Metric",
                        "content": "\nWe use the concept coverage ($Cov$) \\cite{maat} to measure diversity. Specifically, let $\\mathcal{K}$ be concept set, and $\\mathcal{K}_t$ be the set of concepts covered by all selected questions before step $t$. $Cov$ is defined as the proportion of covered concepts by all selected questions:\n\\vspace{-5pt}\n\\begin{equation} \\label{eq:div-cov}\n    Cov = \\frac{1}{|K|}\\sum_{k\\in K} \\mathbbm{1}(k \\in \\mathcal{K}_t)\n\\end{equation}\n% We measure the diversity performance by concept coverage ($Cov$) metric.\n\n"
                    },
                    "subsubsection 5.2.3": {
                        "name": "Novelty Metric",
                        "content": "\nWe measure the novelty using the question exposure rate (the proportion of times a question was selected) and the mean overlap rate (the mean overlap among questions selected by any two students in the student set) \\cite{expandoverlap}:\n\\begin{align}\n    &\\text{Exposure}_q = \\frac{N_q}{|\\mathcal{U}|} \\\\\n    \\text{Overlap} &= \\frac{\\sum\\sum_{i,j \\in \\mathcal{U},j\\neq i} |Q_i \\bigcap Q_j |}{ |\\mathcal{U}|*(|\\mathcal{U}|-1)/2  }\n\\end{align}\nwhere $N_q$ is the count that question $q$ is chosen, $\\mathcal{U}$ is the student set, $Q_i$ is the set of questions tested by student $i$.\n\n% \\subsubsection{\\textbf{Simulated Metric}}\n% We conduct the simulation study to assess whether a CAT accurately predict students' ability. To evaluate the performance, we calculate the Simulated Estimate Error, SEE \\cite{maat}, defined as the mean squared error between the estimated ability ($\\theta_i$) and the simulated ability ($\\theta^*_i$):\n% \\begin{equation}\n%     SEE(\\mathcal{S}) =\\frac{1}{|\\mathcal{S}|} \\sum_{i \\in \\mathcal{S}} (\\theta_i-\\theta^*_i)^2\n% \\end{equation}\n% % where $\\mathcal{S}$ is the student set.\n\n% In the traditional CAT studies, the simulated ability are randomly generated. As we use real datasets in our experiments, we will first learn the student's ability on the whole records and treat this value as the simulated ability.\n% \\vspace{-5pt}\n"
                    }
                },
                "subsection 5.3": {
                    "name": "Baselines",
                    "content": "\nWe apply our method on two CDMs: traditional Item Response Theory (IRT) \\cite{irt} and recent deep learning-based model NeuralCDM (NCD) \\cite{ncd}, and we compare our methods with two groups of selection algorithms. We use the following state-of-the-art selection algorithms as baselines. They are:\n\n\\textit{Static methods}. based on heuristic and unlearnable rules.\n\\begin{itemize}[leftmargin=2pt]\n    \\item Random: the random selection algorithm.\n    \\item MFI \\cite{appofirt}: It selects the question with Maximum Fisher Information. It's only designed for IRT.\n    \\item KLI \\cite{kli}: It selects the question with the maximum moving average of Kullback-Leibler information. It's only designed for IRT.\n    \\item MAAT \\cite{maat}: It's an active learning-based method, which uses Expected Model Change (EMC) of CDM to select questions. It also designs an extra module to enhance concept diversity.\n\\end{itemize}\n\n\\textit{Learnable methods}. They are data-driven and learnable from large-scale datasets.\n\\begin{itemize}[leftmargin=2pt]\n    \\item BOBCAT \\cite{bobcat}: It's a meta learning-based method that recasts CAT as a bilevel optimization problem.\n    \\item NCAT \\cite{ncat}: It's a reinforcement learning-based method that designs an attention-based DQN. It selects questions by sampling from the Boltzmann distribution of Q values to control question exposure.\n\\end{itemize}\n\n\n\n\\vspace{-5pt}\n"
                },
                "subsection 5.4": {
                    "name": "Implementation Details",
                    "content": "\n\nFor all experimental results, except for Section \\ref{sec:objectivecomparion}, we always keep the scalarization function $\\mathbf{w}=[1, 1, 1]$. The implementation of our model is available\\footnote{The MindSpore implementation is available at: \\url{https://gitee.com/mindspore/models/tree/master/research/recommend/GMOCAT}}. We set the maximum test length $T=20$, following \\cite{ncat,rat}. We set $\\gamma=0.5$ in Eq. \\ref{eq:return}, $\\epsilon=0.2$ in Eq. \\ref{eq:actorloss}. The batch size is $128$, the embedding dimension $d=128$. The dropout rate is 0.1 in the self-attention mechanism. The optimizer is Adam \\cite{adam}, and the learning rate is 0.001. The loss trade-off parameter $\\alpha=1.0$. The parameters of the baselines all follow the settings in their original papers to ensure their best performance. In the three datasets, only Junyi provides the prerequisite relation between knowledge concepts. Therefore, we use the implementation by \\citet{rcd} to construct the prerequisite graph for other two datasets, presented in Appendix \\ref{app:graphconstruction}.\n\n% \\subsubsection{Graph Construction}\n% \\label{graphconstruction}\n% In the three datasets, only Junyi provides the prerequisite relation between knowledge concepts. Therefore, we need to construct the prerequisite graph for other two datasets. Here, we use the implementation by \\citet{rcd}. First, we compute correct matrix $C$, where $C_{ij}$ is $\\frac{n_{ij}}{\\sum_k n_{ik}}$ if $i\\neq j$ ,else it's 0. $n_{ij}$ means the count that concept $j$ is answered correctly and immediately after $i$ is answered correctly. Next, we calculate transition matrix $T$, where $T_{i,j}=1$ if $\\frac{C_{ij}-min(C)}{max(C)-min(C)} > threshold$, representing concept $i$ has an edge pointing to $j$. If $T_{ij}=1$ but $T_{ji}\\neq 1$, the relation between concept $i$ and $j$ is prerequisite, i.e., $i$ is a prerequisite for $j$. We set $threshold$ as the average value of matrix $T$.\n\\vspace{-5pt}\n"
                },
                "subsection 5.5": {
                    "name": "Performance Comparison",
                    "content": "\nHere we analyze the performance of GMOCAT on different metrics. The scalarization function $\\mathbf{w}$ is fixed as [1, 1, 1].\n% \\begin{table*}[]\n% \\caption{Exposure rate (Exp.) and mean Overlap rate (Over.) on three datasets at test step 20. Exp.(>0.2) represents the proportion of questions with exposure rate > 0.2.}\n% \\resizebox{\\linewidth}{!}{\n% \\begin{tabular}{ll|cc|cc|cc|cc|cc|cc}\n% \\toprule\n% \\multicolumn{2}{l|}{Dataset}   & \\multicolumn{4}{c}{\\textbf{Eedi}} & \\multicolumn{4}{c}{\\textbf{ASSIST}} & \\multicolumn{4}{c}{\\textbf{Junyi}}  \\\\ \\hline\n% \\multicolumn{2}{l|}{CDM}    & \\multicolumn{2}{c}{IRT}  & \\multicolumn{2}{c}{NCD} & \\multicolumn{2}{c}{IRT}  & \\multicolumn{2}{c}{NCD} & \\multicolumn{2}{c}{IRT}  & \\multicolumn{2}{c}{NCD}  \\\\ \\hline\n% \\multicolumn{2}{l|}{Metric}  & Exp.\\%(>0.2) & Over.\\%  & Exp.\\%(>0.2) & Over.\\%  & Exp.\\%(>0.2) & Over.\\% & Exp.\\%(>0.2) & Over.\\% & Exp.\\%(>0.2) & Over.\\% & Exp.\\%(>0.2) & Over.\\%   \\\\ \\hline \n% \\multicolumn{1}{l|}{\\multirow{2}{*}[-12pt]{Static}} & Random & \\textbf{0} &  \\textbf{3.31} & \\textbf{0} & \\textbf{3.31}   &\t0&\t\\textbf{0.29}  & 0 &  \\textbf{0.29} &\t\\textbf{0.04} & \\textbf{4.60} &\t\\textbf{0.04} &\t\\textbf{4.60}  \\\\ \\cline{2-14} \n% \\multicolumn{1}{l|}{} & MFI  & 2.37 & 20.37  & - & - &\t0 &\t 0.64  & - & - &\t0.18 &\t 6.62   & - & -  \\\\ \\cline{2-14} \n% \\multicolumn{1}{l|}{} & KLI   &\t2.48 &\t  20.31   & - & - &\t0 &\t  0.62    & - & -  &\t0.21 &\t6.73  & - & -  \\\\\\cline{2-14} \n% \\multicolumn{1}{l|}{} & MAAT  &\t3.69 &22.67  &\t3.85 & 22.65 &\t0 &\t  0.58  &\t0 &  0.52  &\t0.63 &\t 17.66   &\t0.67 &  15.22\\\\ \\hline\n% \\multicolumn{1}{l|}{\\multirow{2}{*}[-6pt]{Learnable}}& BOBCAT  & 3.31 &  24.60   & 3.11  &\t21.49  & 0 &  0.49 & 0 &\t0.39 & 0.81 & 15.62 & 0.74 & 15.03\\\\  \\cline{2-14}\n% \\multicolumn{1}{l|}{} & NCAT    & \\underline{3.27} &  22.61    & 3.58 &\t24.47  & 0 &  0.59   & 0 & 0.54 & 0.74 & 17.36   &\t0.88 &\t17.64   \\\\ \\cline{2-14}\n% \\multicolumn{1}{l|}{} & GMOCAT & 3.37 &\t\\underline{20.20}   &\t\\underline{2.95} & \\underline{20.57}  & 0 &\t  \\underline{0.49}   & 0 &\t0.61 &\t\\underline{0.11} &\t\\underline{5.13}  &\t\\underline{0.07} &\t\\underline{4.86}\\\\ \\bottomrule\n% \\end{tabular}}\n% \\label{tab:expandoverlap}\n% \\end{table*}\n\n\n\n",
                    "subsubsection 5.5.1": {
                        "name": "Quality Comparison",
                        "content": "\nTable \\ref{tab:aucandacc} reports the AUC and ACC metrics of different methods at test step $t=5,10,20$. From them, we observe that: \n\\begin{itemize}[leftmargin=12pt]\n    \\item[(1)] Our method outperforms all of the baselines on two different CDMs of three public datasets. On Eedi, GMOCAT achieves up to 2\\% AUC improvements compared to the best baseline (e.g., step 5 on NCD). On ASSIST, GMOCAT achieves up to 1\\% ACC improvements compared to the best baseline (e.g., step 10 on IRT). On Junyi, GMOCAT outperforms the best baseline by 1\\% AUC points (e.g., step 20 on IRT). These results demonstrate that relational information and multi-objective strategies can improve the accuracy of ability estimates.\n    \\item[(2)] NCAT, also as a RL-based method, is the second best on most datasets, which also demonstrates the effectiveness of the RL framework. For example, at the beginning of test(step 5), MAAT is not weak, but at the end(step 20), its AUC/ACC are always beaten by the RL-based methods. This is because MAAT selects questions based on greed rather than a long-term perspective.\n    % All of the data-driven methods outperform the best static methods (MAAT) in most settings. Furthermore, RL-based method \n    \n    % This shows that learning the selection algorithm from large-scale data is beneficial for quality performance. For example, at the beginning of test(step 5), MAAT is not weak, but at the end(step 20), its performance is always beaten by the RL-based methods. This is because MAAT selects questions based on greed rather than a long-term perspective.\n\\end{itemize}\n\n\n"
                    },
                    "subsubsection 5.5.2": {
                        "name": "Diversity Comparison",
                        "content": "\nWe display the $Cov$ curve throughout the CAT process in Figure \\ref{fig:cov}. GMOCAT outperforms much on all datasets with two CDMs, because it has an explicit diversity objective in the MORL framework and a relation-aware selection algorithm, while other methods do not. Compared with other baselines, the Cov curve of GMOCAT grows fastest. In most cases, the second fastest method is MAAT, because it also has an intrinsic diversity goal. But its greedy strategy leads to performance degradation. \n\n\n\n"
                    },
                    "subsubsection 5.5.3": {
                        "name": "Novelty Comparison",
                        "content": "\nTable \\ref{tab:expandoverlap} lists the exposure rate(Exp.) and mean overlap rate(Over.) at step 20 with Junyi dataset, where Exp.(>0.2) represents the proportion of questions with exposure rate > 0.2. We find that: \n\\begin{itemize}[leftmargin=12pt]\n    \\item[(1)] Although Random method has the lowest exposure rate, this does not mean that it is the best method. Because the randomly selected questions are not personalized at all, which violates the intention of CAT. We list Random method here mainly to illustrate the actual lower bound of the exposure rate.\n    \\item[(2)] Among all methods except Random, GMOCAT achieves the smallest exposure rate and overlap rate, which demonstrates the effectiveness of novelty reward. NCAT also gets a low question exposure because it samples actions from a Boltzmann distribution. In contrast, our approach achieves lower question exposure by directly targeting exposure as an optimization objective.\n\\end{itemize}\n\nFrom the above three aspects, we can see that by using GMOCAT method, we can not only achieve a balance between accuracy, diversity and novelty, but also significantly improve all of quantitative metrics. Strengthening diversity and novelty objectives brings a notable improvement in $Cov$ and exposure rate metrics. \n% Moreover, the improvement in the quality metric demonstrates the necessity of recommending diversified test questions and controlling question exposure. \n\n\n\n"
                    }
                },
                "subsection 5.6": {
                    "name": "Ablation Study",
                    "content": "\n\\label{sec:ablation}\nWe conduct ablation studies to further investigate the contribution of each module in GMOCAT. We test all metrics at step 20 on IRT with Junyi dataset. We still set the scalarization function $\\mathbf{w} = [1,1,1]$. The settings are discussed as follows:\n\\begin{itemize}[leftmargin=8pt]\n    \\item GMOCAT-R: remove the relation-aware embedding. That means we ignore the relation graphs, and replace the relation-aware embedding $\\widetilde{\\mathcal{E}}_q,\\widetilde{\\mathcal{E}}_c$ with raw embedding $\\mathcal{E}_q,\\mathcal{E}_c$.\n    % \\item GMOCAT-A: remove the self-attention mechanism in state encoder.\n    \\item GMOCAT-S: remove the scalarization function. That means the reward is changed from a vector to a scalar, weighted by three rewards. Correspondingly, the critic's output becomes a scalar.\n\\end{itemize}\n\nThe results are presented in Table \\ref{tab:ablation}. We can observe that the GMOCAT's performance will decrease no matter which module is removed. This means that both modules contribute to the performance of GMOCAT. We analyze that: (1) GMOCAT-R loses vital relational information between questions and knowledge concepts, which significantly reduces its performance. This allows us to safely conclude that it is advisable to capture the relational information for selecting more appropriate questions. (2) after removing the scalarization function, the performance degradation of GMOCAT-S also proves the necessity of converting the single-objective method to the multi-objective method with vectorized rewards. \n \n\n\n\n\n"
                },
                "subsection 5.7": {
                    "name": "Objective Comparison",
                    "content": "\n\\label{sec:objectivecomparion}\nTo investigate the function of different objectives, in this part we explore the differences when GMOCAT focuses on the subsets of three objectives. In our setting, the first, second, and third entries of $\\mathbf{w}$ correspond to the quality, diversity and novelty objectives respectively. We conduct the experiments with the following configurations of $\\mathbf{w}$:\n% \\begin{equation}\n%     \\mathbf{w} \\in \\{[\\text{QDN}], [Q--], [-D-], [--N],[QD-],[Q-N],[-DN] \\}\\nonumber\n% \\end{equation}\n\\begin{equation}\n    \\mathbf{w} \\in \\{[1,1,1], [1,0,0], [0,1,0], [0,0,1],[1,1,0],[1,0,1],[0,1,1] \\}\\nonumber\n\\end{equation}\nHere, we mainly consider the effect of the presence/absence of each object, so the value of $\\mathbf{w}$ is either 1 (presence) or 0 (absence).\n\nFigure \\ref{fig:rewardweight} displays the performance comparison of GMOCAT on Eedi+IRT setting at test step 20 with different configurations of $\\mathbf{w}$. From the results we find some interesting phenomena:\n\\begin{itemize}[leftmargin=12pt]\n    \\item[(1)] Focusing solely on one objective leads to performance degradation in other metrics. For example, [1,0,0] gets a low coverage (Cov) value. [0,1,0] and [0,0,1] get low AUC/ACC values. This demonstrates the importance and necessity of utilizing multiple objectives simultaneously.\n    \\item[(2)] From Figure \\ref{fig:aucinw} and \\ref{fig:accinw}, we find that adding the diversity objective increases the value of AUC/ACC (e.g., [1,1,0] outperforms [1,0,0] on AUC/ACC). This phenomenon is consistent with our intuition, because the student's ability is multifaceted. We can predict the student's ability more accurately if test questions include diverse knowledge concepts.\n    \\item[(3)] From Figure \\ref{fig:aucinw} and \\ref{fig:accinw}, we also spot that adding novelty objective slightly impairs quality performance (e.g., [1,1,0] outperforms [1,1,1] on AUC/ACC). This phenomenon implies a potential conflict between quality and novelty objectives. The novelty objective attempts to achieve a balanced distribution of test questions, which results in low-quality questions being selected more frequently, and prevents us from predicting the student's ability accurately. \n    % \\item[(2)] From Figure \\ref{fig:covinw}, we note that incorporating diversity objective can significantly enhance diversity performance, while including quality and novelty objective slightly harms the diversity objective.\n    % \\item[(3)] Moreover, Figure \\ref{fig:overinw} indicates that only caring quality or diversity, or only both of them, will result in a relatively high overlap rate, which can be alleviated by including the novelty objective.\n\\end{itemize}\nFrom the above observation, we can conclude that there is both promotion and contradiction between three objectives. GMOCAT provides a flexible way to adapt CAT with different practical needs. For example, if we want to pay more attention to the exposure rate of test questions, we can increase the importance of novelty objectives while ensuring that quality performance does not degrade too much. We leave it to future work to quantitatively analyze the trade-off of multiple objectives and automate the balance to meet various practical applications.\n\n\n\n% \\begin{figure}\n%     \\centering\n%     \\includegraphics[width=\\linewidth]{picture/gamma.pdf}\n%     \\caption{Caption}\n%     \\label{fig:my_label}\n% \\end{figure}\n\n% \\subsection{Sensitivity Analysis}\n\n\n\n% \\begin{table}[]\n% \\resizebox{\\linewidth}{!}{\n% \\begin{tabular}{ll|cccccc}\n% \\toprule\n% \\multicolumn{2}{l|}{Dataset}   & \\multicolumn{6}{c}{\\textbf{Eedi}}  \\\\ \\hline\n% \\multicolumn{2}{l|}{CDM}   & \\multicolumn{3}{c}{IRT}  & \\multicolumn{3}{c}{NCD}  \\\\ \\hline\n% \\multicolumn{2}{l|}{Metric}  & Exp.\\%(>0.2) & \\multicolumn{1}{c|}{Over.\\%}  & Exp.\\%(>0.2) & Over.\\%  \\\\ \\hline \n% \\multicolumn{1}{l|}{\\multirow{2}{*}[-12pt]{Static}} & Random & 0 &  \\multicolumn{1}{c|}{3.31}  &\t0 &\t3.31  \\\\ \\cline{2-6} \n% \\multicolumn{1}{l|}{} & MFI  & 3.37 &\t\\multicolumn{1}{c|}{20.37}  & - & -  \\\\ \\cline{2-6} \n% \\multicolumn{1}{l|}{} & KLI   &\t3.48 &\t  \\multicolumn{1}{c|}{20.31}    & - & -  \\\\\\cline{2-6} \n% \\multicolumn{1}{l|}{} & MAAT  &\t3.69 &\t  \\multicolumn{1}{c|}{22.67}    &\t2.85 & 16.65  \\\\ \\hline\n% \\multicolumn{1}{l|}{\\multirow{2}{*}[-6pt]{Learnable}}& BOBCAT  & 3.31 &  \\multicolumn{1}{c|}{19.6}   & 3.11  &\t21.49   \\\\  \\cline{2-6}\n% \\multicolumn{1}{l|}{} & NCAT    & 3.27 &  \\multicolumn{1}{c|}{22.61}    & 3.58 &\t24.47   \\\\ \\cline{2-6}\n% \\multicolumn{1}{l|}{} & GMOCAT   &\t3.37 &\t  \\multicolumn{1}{c|}{20.2}    &\t2.95 & 20.57 \\\\\\hline \\hline\n\n% \\multicolumn{2}{l|}{Dataset}   & \\multicolumn{6}{c}{\\textbf{ASSIST}}  \\\\ \\hline\n% \\multicolumn{2}{l|}{CDM}   & \\multicolumn{3}{c}{IRT}  & \\multicolumn{3}{c}{NCD}   \\\\ \\hline\n% \\multicolumn{2}{l|}{Metric}   & Exp.\\%(>0.2) & \\multicolumn{1}{c|}{Over.\\%}  & Exp.\\%(>0.2) & Over.\\%  \\\\ \\hline \n% \\multicolumn{1}{l|}{\\multirow{2}{*}[-12pt]{Static}} & Random &\t0&\t \\multicolumn{1}{c|}{0.29}   &\t0&\t0.29   \\\\ \\cline{2-6} \n% \\multicolumn{1}{l|}{} & MFI &\t0 &\t \\multicolumn{1}{c|}{0.64}   & - & -  \\\\ \\cline{2-6} \n% \\multicolumn{1}{l|}{} & KLI  &\t0 &\t  \\multicolumn{1}{c|}{0.62}    & - & -  \\\\\\cline{2-6} \n% \\multicolumn{1}{l|}{} & MAAT  &\t0 &\t  \\multicolumn{1}{c|}{0.58}    &\t0 &  0.52 \\\\ \\hline\n% \\multicolumn{1}{l|}{\\multirow{2}{*}[-6pt]{Learnable}}& BOBCAT  & 0 &  \\multicolumn{1}{c|}{0.49}    & 0 &\t0.39  \\\\  \\cline{2-6}\n% \\multicolumn{1}{l|}{} & NCAT    & 0 &  \\multicolumn{1}{c|}{0.59}    & 0 & 0.54   \\\\ \\cline{2-6}\n% \\multicolumn{1}{l|}{} & GMOCAT    & 0 &\t  \\multicolumn{1}{c|}{0.49}    & 0 &\t0.61  \\\\ \\hline \\hline\n\n% \\multicolumn{2}{l|}{Dataset}   & \\multicolumn{6}{c}{\\textbf{Junyi}}  \\\\ \\hline\n% \\multicolumn{2}{l|}{CDM}   & \\multicolumn{3}{c}{IRT}  & \\multicolumn{3}{c}{NCD}   \\\\ \\hline\n% \\multicolumn{2}{l|}{Metric}   & Exp.\\%(>0.2) & \\multicolumn{1}{c|}{Over.\\%}  & Exp.\\%(>0.2) & Over.\\%  \\\\ \\hline \n% \\multicolumn{1}{l|}{\\multirow{2}{*}[-12pt]{Static}} & Random &\t0.04&\t \\multicolumn{1}{c|}{4.6}   &\t0.04 &\t4.6   \\\\ \\cline{2-6} \n% \\multicolumn{1}{l|}{} & MFI  &\t0.18 &\t \\multicolumn{1}{c|}{6.62}    & - & -  \\\\ \\cline{2-6} \n% \\multicolumn{1}{l|}{} & KLI  &\t0.21 &\t  \\multicolumn{1}{c|}{6.73}   & - & -  \\\\\\cline{2-6} \n% \\multicolumn{1}{l|}{} & MAAT &   &\t0.63 &\t  \\multicolumn{1}{c|}{17.66}    &\t0.67 &  15.22 \\\\ \\hline\n% \\multicolumn{1}{l|}{\\multirow{2}{*}[-6pt]{Learnable}}& BOBCAT  & 0.21 &  \\multicolumn{1}{c|}{7.62}    &\t0.14 &\t 7.03  \\\\  \\cline{2-6}\n% \\multicolumn{1}{l|}{} & NCAT    & 0.74 &  \\multicolumn{1}{c|}{17.36}    &\t0.88 &\t17.64   \\\\ \\cline{2-6}\n% \\multicolumn{1}{l|}{} & GMOCAT    &\t0.11 &\t  \\multicolumn{1}{c|}{5.13}   &\t0.07 &\t4.86  \\\\ \\bottomrule\n \n% \\end{tabular}}\n% \\caption{Exposure rate (Exp.) and mean Overlap rate (Over.) on three datasets at test step 20. Exp.(>0.2) represents the proportion of questions with exposure rate > 0.2.}\n% \\label{tab:expandoverlap}\n% \\end{table}\n\n\n% \\begin{table}[]\n% \\resizebox{\\linewidth}{!}{\n% \\begin{tabular}{ll|cccccc}\n% \\toprule\n% \\multicolumn{2}{l|}{Dataset}   & \\multicolumn{6}{c}{\\textbf{Eedi}}  \\\\ \\hline\n% \\multicolumn{2}{l|}{CDM}   & \\multicolumn{3}{c}{IRT}  & \\multicolumn{3}{c}{NCD}  \\\\ \\hline\n% \\multicolumn{2}{l|}{Metric}  & Exp.\\%(max)  & Exp.\\%(>0.2) & \\multicolumn{1}{c|}{Over.\\%} & Exp.\\%(max)  & Exp.\\%(>0.2) & Over.\\%  \\\\ \\hline \n% \\multicolumn{1}{l|}{\\multirow{2}{*}[-12pt]{Static}} & Random & 7.3 & 0 &  \\multicolumn{1}{c|}{3.31}  & 7.3 &\t0 &\t3.31  \\\\ \\cline{2-8} \n% \\multicolumn{1}{l|}{} & MFI & 46.23  & 3.37 &\t\\multicolumn{1}{c|}{20.37}   & - & - & -  \\\\ \\cline{2-8} \n% \\multicolumn{1}{l|}{} & KLI & 44.81  &\t3.48 &\t  \\multicolumn{1}{c|}{20.31}   & - & - & -  \\\\\\cline{2-8} \n% \\multicolumn{1}{l|}{} & MAAT &  49.9 &\t3.69 &\t  \\multicolumn{1}{c|}{22.67}   & 40.12 &\t2.85 & 16.65  \\\\ \\hline\n% \\multicolumn{1}{l|}{\\multirow{2}{*}[-6pt]{Learnable}}& BOBCAT & 45.48 & 3.31 &  \\multicolumn{1}{c|}{19.6} & 47.77  & 3.11  &\t21.49   \\\\  \\cline{2-8}\n% \\multicolumn{1}{l|}{} & NCAT   & 50.1 & 3.27 &  \\multicolumn{1}{c|}{22.61}   & 49.08 & 3.58 &\t24.47   \\\\ \\cline{2-8}\n% \\multicolumn{1}{l|}{} & GMOCAT   & 43.99 &\t3.37 &\t  \\multicolumn{1}{c|}{20.2}   & 45.01 &\t2.95 & 20.57 \\\\\\hline \\hline\n\n% \\multicolumn{2}{l|}{Dataset}   & \\multicolumn{6}{c}{\\textbf{ASSIST}}  \\\\ \\hline\n% \\multicolumn{2}{l|}{CDM}   & \\multicolumn{3}{c}{IRT}  & \\multicolumn{3}{c}{NCD}   \\\\ \\hline\n% \\multicolumn{2}{l|}{Metric}  & Exp.\\%(max)  & Exp.\\%(>0.2) & \\multicolumn{1}{c|}{Over.\\%} & Exp.\\%(max)  & Exp.\\%(>0.2) & Over.\\%  \\\\ \\hline \n% \\multicolumn{1}{l|}{\\multirow{2}{*}[-12pt]{Static}} & Random & 4.41&\t0&\t \\multicolumn{1}{c|}{0.29}  & 4.41 &\t0&\t0.29   \\\\ \\cline{2-8} \n% \\multicolumn{1}{l|}{} & MFI &  5.15 &\t0 &\t \\multicolumn{1}{c|}{0.64}   & - & - & -  \\\\ \\cline{2-8} \n% \\multicolumn{1}{l|}{} & KLI &  5.15 &\t0 &\t  \\multicolumn{1}{c|}{0.62}   & - & - & -  \\\\\\cline{2-8} \n% \\multicolumn{1}{l|}{} & MAAT &  5.88 &\t0 &\t  \\multicolumn{1}{c|}{0.58}   & 5.88 &\t0 &  0.52 \\\\ \\hline\n% \\multicolumn{1}{l|}{\\multirow{2}{*}[-6pt]{Learnable}}& BOBCAT & 4.41 & 0 &  \\multicolumn{1}{c|}{0.49}   & 4.41 & 0 &\t0.39  \\\\  \\cline{2-8}\n% \\multicolumn{1}{l|}{} & NCAT   & 6.62 & 0 &  \\multicolumn{1}{c|}{0.59}   & 6.62 & 0 & 0.54   \\\\ \\cline{2-8}\n% \\multicolumn{1}{l|}{} & GMOCAT   & 4.41 & 0 &\t  \\multicolumn{1}{c|}{0.49}   & 4.41 & 0 &\t0.61  \\\\ \\hline \\hline\n\n% \\multicolumn{2}{l|}{Dataset}   & \\multicolumn{6}{c}{\\textbf{Junyi}}  \\\\ \\hline\n% \\multicolumn{2}{l|}{CDM}   & \\multicolumn{3}{c}{IRT}  & \\multicolumn{3}{c}{NCD}   \\\\ \\hline\n% \\multicolumn{2}{l|}{Metric}  & Exp.\\%(max)  & Exp.\\%(>0.2) & \\multicolumn{1}{c|}{Over.\\%} & Exp.\\%(max)  & Exp.\\%(>0.2) & Over.\\%  \\\\ \\hline \n% \\multicolumn{1}{l|}{\\multirow{2}{*}[-12pt]{Static}} & Random & 20.35&\t0.04&\t \\multicolumn{1}{c|}{4.6}  & 20.35 &\t0.04 &\t4.6   \\\\ \\cline{2-8} \n% \\multicolumn{1}{l|}{} & MFI &  25.5 &\t0.18 &\t \\multicolumn{1}{c|}{6.62}   & - & - & -  \\\\ \\cline{2-8} \n% \\multicolumn{1}{l|}{} & KLI &  24.67 &\t0.21 &\t  \\multicolumn{1}{c|}{6.73}   & - & - & -  \\\\\\cline{2-8} \n% \\multicolumn{1}{l|}{} & MAAT &  63.36 &\t0.63 &\t  \\multicolumn{1}{c|}{17.66}   & 54.29 &\t0.67 &  15.22 \\\\ \\hline\n% \\multicolumn{1}{l|}{\\multirow{2}{*}[-6pt]{Learnable}}& BOBCAT & 39.28 & 0.21 &  \\multicolumn{1}{c|}{7.62}   &  52.87 &\t0.14 &\t 7.03  \\\\  \\cline{2-8}\n% \\multicolumn{1}{l|}{} & NCAT   & 49.73 & 0.74 &  \\multicolumn{1}{c|}{17.36}   & 58.9 &\t0.88 &\t17.64   \\\\ \\cline{2-8}\n% \\multicolumn{1}{l|}{} & GMOCAT   & 27.81 &\t0.11 &\t  \\multicolumn{1}{c|}{5.13}   & 25.06 &\t0.07 &\t4.86  \\\\ \\bottomrule\n \n% \\end{tabular}}\n% \\caption{Exposure rate (Exp.) and mean Overlap rate (Over.) on three datasets at test step 20. Exp.(max), Exp.(>0.2) represents the maximum exposure rate of all questions, and the proportion of questions with exposure rate > 0.2.}\n% \\label{tab:expandoverlap}\n% \\end{table}\n\n\n% \\begin{figure*}\n%     \\subfigure[Eedi]{\n%     \\centering\n%     \\includegraphics[width=0.3\\linewidth]{picture/cov_eedi_irt.pdf}\n%     }\n%     \\subfigure[ASSIST]{\n%     \\centering\n%     \\includegraphics[width=0.3\\linewidth]{picture/cov_eedi_ncd.pdf}\n%     }\n%     \\subfigure[Junyi]{\n%     \\centering\n%     \\includegraphics[width=0.3\\linewidth]{picture/cov_eedi_irt.pdf}\n%     }\n%     \\caption{}\n%     \\label{fig:see}\n% \\end{figure*}\\vspace{-5pt}\n"
                }
            },
            "section 6": {
                "name": "Conclusion",
                "content": "\nIn this work, we propose GMOCAT, a Graph-Enhanced Multi-Objective method for CAT, that provides a multi-objective approach for learning the selection algorithm. We highlight the three objectives in CAT, namely quality, diversity and novelty, and apply Scalarized Multi-Objective RL to optimize these objectives in a long-term perspective. Furthermore, our method improves upon existing CAT methods by building relation-aware representations of questions and concepts to summarize their relational information. Extensive experiments demonstrated that our method outperforms state-of-the-art methods on three educational datasets, which significantly improves the accuracy of ability estimate, diversifies the test questions and alleviates the question exposure.\n\n% a self-attention mechanism to capture individual differences among past response records\n\\begin{acks}\nThe SJTU team is supported by National Key R\\&D Program of China (2022ZD0114804), Shanghai Municipal Science and Technology Major Project (2021SHZDZX0102) and National Natural Science Foundation of China (62076161, 62177033, U19A2065). The work is also sponsored by Huawei Innovation Research Program. We thank MindSpore \\cite{mindspore} for the partial support of this work.\n\\end{acks}\n%%\n%% The next two lines define the bibliography style to be used, and\n%% the bibliography file.\n\\bibliographystyle{ACM-Reference-Format}\n\\bibliography{bibliography}\n\n\\newpage\n\\appendix\n"
            },
            "section 7": {
                "name": "The process of single-objective selection algorithm",
                "content": "\n\\label{app:training/testing_phase}\n\n\n"
            },
            "section 8": {
                "name": "prerequisite Graph Construction",
                "content": "\n\\label{app:graphconstruction}\nIn the three datasets, only Junyi provides the prerequisite relation between knowledge concepts. Therefore, we need to construct the prerequisite graph for other two datasets. Here, we use the implementation by \\citet{rcd}. First, we compute correct matrix $C$, where $C_{ij}$ is $\\frac{n_{ij}}{\\sum_k n_{ik}}$ if $i\\neq j$ ,else it's 0. $n_{ij}$ means the count that concept $j$ is answered correctly and immediately after $i$ is answered correctly. Next, we calculate transition matrix $T$, where $T_{i,j}=1$ if $\\frac{C_{ij}-min(C)}{max(C)-min(C)} > threshold$, representing concept $i$ has an edge pointing to $j$. If $T_{ij}=1$ but $T_{ji}\\neq 1$, the relation between concept $i$ and $j$ is prerequisite, i.e., $i$ is a prerequisite for $j$. We set $threshold$ as the average value of matrix $T$.\n%%\n%% If your work has an appendix, this is the place to put it.\n% \\appendix\n\n% \\section{Algorithm Procedure}\n% \\label{app:algorithm}\n\n% Here, we give the training procedure of GMOCAT in Algorithm \\ref{algo1}.\n% \\begin{algorithm}[h!]\n%     \\SetAlgoLined\n%     \\caption{Training procedure of GMOCAT}\n% %   \\KwData{this text}\n%   \\KwResult{selection algorithm $\\pi$}\n%     \\While{not converged}{\n%         \\For{batch $\\mathcal{B}$ in all students}{\n%             Randomly split questions in the dataset of student $i$ into candidate question set $\\mathcal{D}^i_c$ and meta question set $\\mathcal{D}^i_m$, $i \\in \\mathcal{B}$\\;\n%             \\For{($t=1;t<=T;t=t+1$)}{\n%                 Selects a question from $\\mathcal{D}^i_c$: $q_t^i \\sim \\pi(s^i_t)$\\;\n%                 The student $i$ gives the response $y_t^i$\\;\n%                 CDM update the current ability estimate $\\theta_t^i$\\;\n%                 Compute the vector-valued reward $\\mathbf{r}_t^i$ (Eq. \\ref{equ:qualityreward},\\ref{equ:diversityreward},\\ref{equ:noveltyreward})\\;\n%                 Store $<s_t,q_t,\\mathbf{r}_t,done>$ into the memory, where $done$=True if $t==T$ else $done$=False\\;\n%             }\n%             Train $\\pi$ using MOPPO with the memory (Eq. \\ref{equ:moppoloss})\\;\n%             Clear the memory\\;\n%         }\n%     }\n%   \\label{algo1}\n% \\end{algorithm}\n\n\n\n\n\n\n"
            }
        },
        "tables": {
            "tab:statistics": "\\begin{table}[]\n    \\centering\n    % \\vspace{-3mm}\n    \\caption{Dataset Statistics}\n    \\vspace{-3mm}\n    \\begin{tabular}{l|c|c|c}\n    \\toprule\n        Dataset & Eedi & ASSIST & Junyi \\\\ \\hline\n        \\#Students & 4,918 & 1,360 & 20,395  \\\\ \\hline\n        \\#Questions & 948 & 17,751 & 2,835\\\\ \\hline\n        \\#Concepts & 86 & 123 & 40 \\\\ \\hline\n        \\#Records & 1,382,727 & 239,919 & 2,537,898\\\\ \\hline\n        \\#Prerequisite Edges & 334 & 1,166 & 306 \\\\ \\hline\n        Concepts Per Question & 4.0 & 1.2 & 1.0 \\\\ \\hline\n        % Questions Per Concept & 42.5 & 61.0 & 19.5 \\\\ \\hline\n        % Records Per Student & 281 & 176 & 124 \\\\ \\hline\n        % Records Per Question & 1458 & 14 & 895 \\\\ \\hline\n        Positive Label Rate & 0.55 & 0.62 & 0.69 \\\\\n    \\bottomrule\n    \\end{tabular}\n    \\vspace{-3mm}\n    \\label{tab:statistics}\n\\end{table}",
            "tab:aucandacc": "\\begin{table*}[h]\n\\caption{The AUC and ACC performance on three public datasets. The best performance is in bold, while the second best value\nis underlined. \"-\" indicates the method can't be applied on NCD. \"$\\ast$\" indicates statistically significant improvement (measured by t-test) with p-value < 0.05.} \n\\vspace{-5pt}\n\\resizebox{\\linewidth}{!}{\n\\begin{tabular}{ll|cccccc|cccccc|cccccc}\n\\toprule\n\\multicolumn{2}{l|}{Dataset}   & \\multicolumn{6}{c|}{\\textbf{Eedi}}& \\multicolumn{6}{c|}{\\textbf{ASSIST}} & \\multicolumn{6}{c}{\\textbf{Junyi}}  \\\\ \\hline\n\\multicolumn{2}{l|}{CDM}   & \\multicolumn{3}{c}{IRT}    & \\multicolumn{3}{c|}{NCD} & \\multicolumn{3}{c}{IRT}    & \\multicolumn{3}{c|}{NCD} & \\multicolumn{3}{c}{IRT}    & \\multicolumn{3}{c}{NCD}                  \\\\ \\hline\n\\multicolumn{2}{l|}{Metric}& \\multicolumn{6}{c|}{AUC}& \\multicolumn{6}{c|}{AUC}& \\multicolumn{6}{c}{AUC}   \\\\ \\hline\n\\multicolumn{2}{l|}{Step}  & 5  & 10 & \\multicolumn{1}{c|}{20} & 5  & 10 & 20  & 5  & 10 & \\multicolumn{1}{c|}{20} & 5  & 10 & 20  & 5  & 10 & \\multicolumn{1}{c|}{20} & 5  & 10 & 20   \\\\ \\hline \n\\multicolumn{1}{l|}{\\multirow{2}{*}[-12pt]{Static}} & Random & 68.38&\t69.73&\t \\multicolumn{1}{c|}{71.98}  & 68.45 &\t70.24 &\t72.98   & 67.68 & 67.89 & \\multicolumn{1}{c|}{ 68.43 }  & 67.73 & 68.51 & 69.70 & 76.72&\t76.99&\t\\multicolumn{1}{c|}{77.44}   &76.80 &\t77.06&\t77.47 \\\\ \\cline{2-20} \n\\multicolumn{1}{l|}{} & MFI &  68.92 &\t70.41 &\t \\multicolumn{1}{l|}{72.66}   & - & - & - & 67.95 & 68.42 & \\multicolumn{1}{l|}{69.26}   & - & - & -  & 77.03&\t77.48&\t \\multicolumn{1}{l|}{78.16}   & - & - & - \\\\ \\cline{2-20} \n\\multicolumn{1}{l|}{} & KLI &  68.69 &\t70.29 &\t  \\multicolumn{1}{l|}{72.60}   & - & - & - &  67.92 & 68.39 &  \\multicolumn{1}{l|}{69.23}   & - & - & - & 76.98&\t77.43&\t\\multicolumn{1}{l|}{78.14}   & - & - & - \\\\\\cline{2-20} \n\\multicolumn{1}{l|}{} & MAAT &  \\underline{69.09} &\t\\underline{70.90} &\t  \\multicolumn{1}{l|}{73.19}   & 69.03 &\t71.03 &  73.75 & 68.24 & 68.82 &  \\multicolumn{1}{l|}{69.70}   & 67.96 & 69.38 &  71.17 & 76.93&\t77.39&\t \\multicolumn{1}{l|}{78.21}   & 77.07&\t77.53&\t 78.40\\\\ \\hline\n\\multicolumn{1}{l|}{\\multirow{2}{*}[-6pt]{Learnable}}& BOBCAT & 68.94 &\t70.50 & \\multicolumn{1}{l|}{73.24}   &  \\underline{69.17} &\t71.44 &\t 74.51 & 68.65 & 69.44 &  \\multicolumn{1}{l|}{70.97}   & \\underline{69.50} & 70.63 & \\underline{71.80} & 77.81&\t78.70 &\t \\multicolumn{1}{l|}{\\underline{79.17}}   & 77.47&\t78.21&\t79.46 \\\\  \\cline{2-20}\n\\multicolumn{1}{l|}{} & NCAT   & 69.04 &\t70.78 &\t \\multicolumn{1}{l|}{\\underline{73.32}}   & 69.09 &\t\\underline{71.45} &\t\\underline{74.55}   & \\underline{68.67} & \\underline{69.49} &  \\multicolumn{1}{l|}{\\underline{71.06}}   & 69.28 & \\underline{70.93} &\t71.68  & \\underline{77.96} & \\underline{78.87} &\t \\multicolumn{1}{c|}{79.13}   & \\underline{77.63} &\t\\underline{78.41} &\t\\underline{79.56}\\\\ \\cline{2-20}\n\\multicolumn{1}{l|}{} & GMOCAT   & \\textbf{69.81*} &\t\\textbf{71.78*} &\t  \\multicolumn{1}{l|}{\\textbf{74.19*}}   & \\textbf{71.25*} &\t\\textbf{73.76*} &\t\\textbf{75.76*}  & \\textbf{69.13*} & \\textbf{70.38*} &  \\multicolumn{1}{l|}{\\textbf{71.91*}}  & \\textbf{69.95*} & \\textbf{71.26*} & \\textbf{72.95*} & \\textbf{78.68*} &\t\\textbf{80.00*} &\t \\multicolumn{1}{c|}{\\textbf{80.24*}}   & \\textbf{78.07*} &\t\\textbf{79.00*} &\t\\textbf{80.30*} \\\\ \\hline \\hline\n\\multicolumn{2}{l|}{Metric}& \\multicolumn{6}{c|}{ACC}& \\multicolumn{6}{c|}{ACC}& \\multicolumn{6}{c}{ACC}   \\\\ \\hline\n\\multicolumn{2}{l|}{Step}  & 5  & 10 & \\multicolumn{1}{c|}{20} & 5  & 10 & 20  & 5  & 10 & \\multicolumn{1}{c|}{20} & 5  & 10 & 20  & 5  & 10 & \\multicolumn{1}{c|}{20} & 5  & 10 & 20   \\\\ \\hline \n\\multicolumn{1}{l|}{\\multirow{2}{*}[-12pt]{Static}} & Random & 63.52 &\t64.36 &\t \\multicolumn{1}{c|}{65.91}  & 63.45\t& 64.83 &\t66.70 & 64.50 & 64.75 &  \\multicolumn{1}{c|}{ 65.21 }  & 65.71&\t66.29&\t67.15 &72.66&\t73.07&\t \\multicolumn{1}{c|}{73.67}   &73.81&\t74.00 &\t74.36 \\\\ \\cline{2-20} \n\\multicolumn{1}{l|}{} & MFI &  63.79 &\t64.63 &\t \\multicolumn{1}{l|}{65.92}   & - & - & - & 64.83&\t65.34&\t \\multicolumn{1}{l|}{66.19}   & - & - & -  & 72.88&\t73.34&\t \\multicolumn{1}{l|}{73.98}   & - & - & - \\\\ \\cline{2-20} \n\\multicolumn{1}{l|}{} & KLI &  63.54 &\t64.44 &\t \\multicolumn{1}{l|}{65.85}   & - & - & - & 64.75&\t65.29&\t \\multicolumn{1}{l|}{66.16}   & - & - & - & 72.87&\t73.33&\t \\multicolumn{1}{l|}{73.97}   & - & - & - \\\\\\cline{2-20} \n\\multicolumn{1}{l|}{} & MAAT &  63.25 &\t64.38 &\t \\multicolumn{1}{l|}{66.15}   & 63.86 &\t64.58 &\t66.71 &  \\underline{65.56} &\t66.30 &\t \\multicolumn{1}{l|}{67.57}   & 66.57&\t67.84&\t \\multicolumn{1}{l|}{69.52} & 73.73&\t74.51&\t \\multicolumn{1}{l|}{75.48}   & 74.31&\t74.88&\t 75.38 \\\\ \\hline\n\\multicolumn{1}{l|}{\\multirow{2}{*}[-6pt]{Learnable}}& BOBCAT & 63.91 & 64.90 &\t \\multicolumn{1}{l|}{\\underline{66.97}}   & 63.95 &\t\\underline{65.62} &\t 67.69 & 65.37&\t66.21&\t  \\multicolumn{1}{l|}{67.88}   & \\underline{67.55} & \\underline{68.63} & \\underline{69.94} & 74.21&\t75.66&\t \\multicolumn{1}{l|}{\\underline{76.51}}   & 74.42&\t75.21&\t\\underline{76.45}\\\\  \\cline{2-20}\n\\multicolumn{1}{l|}{} & NCAT   & \\underline{64.04} & \\underline{64.97} &\t\\multicolumn{1}{l|}{66.92}   & \\underline{64.00} &\t65.59 &\t\\underline{67.84}  & 65.34\t& \\underline{66.32} &\t \\multicolumn{1}{l|}{\\underline{68.36}}   & 67.15&\t68.38&\t69.44  & \\underline{74.74} & \\underline{76.05} & \\multicolumn{1}{c|}{75.70}   &\\underline{74.64} & \\underline{75.47} &\t76.40 \\\\ \\cline{2-20}\n\\multicolumn{1}{l|}{} & GMOCAT   & \\textbf{64.42*} &\t\\textbf{65.70*} &\t\\multicolumn{1}{l|}{\\textbf{67.49*}}   & \\textbf{65.53*} &\t\\textbf{67.36*} &\t\\textbf{68.96*} &  \\textbf{66.16*}&\t\\textbf{67.42*}&\t \\multicolumn{1}{l|}{\\textbf{69.02*}}   & \\textbf{67.63*}&\t\\textbf{68.55*}&\t\\textbf{70.18*} &\\textbf{75.01*} &\t\\textbf{76.68*}&\t\\multicolumn{1}{c|}{\\textbf{77.37*}}   &\\textbf{74.84*}&\t\\textbf{75.83*}&\t\\textbf{77.16*} \\\\  \\bottomrule \n\\end{tabular}}\n\n\\label{tab:aucandacc}\n\\vspace{-5pt}\n\\end{table*}",
            "tab:expandoverlap": "\\begin{table}[]\n\n\\caption{Exposure rate (Exp.) and mean overlap rate (Over.) at test step 20 with Junyi dataset. Exp.(>0.2) represents the proportion of questions with exposure rate > 0.2. The best result is in bold, while the second best is underlined. \"$\\ast$\" indicates statistically significant improvement (measured by t-test) with p-value < 0.05.}\n\\vspace{-5pt}\n\\begin{threeparttable}\n\\resizebox{\\linewidth}{!}{\n\\begin{tabular}{ll|cccc}\n\\toprule\n\\multicolumn{2}{l|}{Dataset}   & \\multicolumn{4}{c}{\\textbf{Junyi}}  \\\\ \\hline\n\\multicolumn{2}{l|}{CDM}   & \\multicolumn{2}{c}{IRT}  & \\multicolumn{2}{c}{NCD}   \\\\ \\hline\n\\multicolumn{2}{l|}{Metric}  & Exp.\\%(>0.2) & \\multicolumn{1}{c|}{Over.\\%}  & Exp.\\%(>0.2) & Over.\\%  \\\\ \\hline \n\\multicolumn{2}{c|}{Random\\tnote{a}}  &0.04 &\t \\multicolumn{1}{c|}{4.6}  & 0.04 & 4.6 \\\\ \\hline \n\\multicolumn{1}{l|}{\\multirow{2}{*}[-5pt]{Static}} & MFI &\t\\underline{0.18} &\t \\multicolumn{1}{c|}{\\underline{6.62}}  & - & -  \\\\ \\cline{2-6}\n\\multicolumn{1}{l|}{} & KLI &\t0.21 &\t  \\multicolumn{1}{c|}{6.73}   & - & -  \\\\\\cline{2-6}\n\\multicolumn{1}{l|}{} & MAAT  &\t0.63 &\t  \\multicolumn{1}{c|}{17.66}   &\t0.67 &  15.22 \\\\ \\hline\n\\multicolumn{1}{l|}{\\multirow{2}{*}[-6pt]{Learnable}}& BOBCAT & 0.74 &  \\multicolumn{1}{c|}{17.36}  &\t0.88 &\t17.64  \\\\  \\cline{2-6}\n\\multicolumn{1}{l|}{} & NCAT  & 0.21 &  \\multicolumn{1}{c|}{7.62}   &\t\\underline{0.14} &\t \\underline{7.03}   \\\\ \\cline{2-6}\n\\multicolumn{1}{l|}{} & GMOCAT  & \\textbf{0.11*} & \\multicolumn{1}{c|}{\\textbf{5.13*}}   &\t\\textbf{0.07*} & \\textbf{4.86*}  \\\\ \\bottomrule\n\\end{tabular}}\n\\begin{tablenotes}\n    \\footnotesize\n    \\item[a] We list Random method here just to illustrate the actual lower bound of the\\\\ exposure rate.\n  \\end{tablenotes}\n\\end{threeparttable}\n\\label{tab:expandoverlap}\n\\vspace{-10pt}\n\\end{table}",
            "tab:ablation": "\\begin{table}[]\n% \\vspace{-3mm}\n\\caption{The results of ablation studies. We test each metric at step 20 on IRT with Junyi dataset. The best results are given in bold. \"$\\ast$\" indicates statistically significant improvement (measured by t-test) with p-value < 0.05.}\n% \\vspace{-3mm}\n\\begin{tabular}{l|ccc}\n\\toprule\nMetric        &  AUC@20   &  Cov@20 & Overlap@20 \\\\ \\hline\nGMOCAT       &  \\textbf{0.8024*} & \\textbf{0.8185*} & \\textbf{0.0513*} \\\\ \\hline\nGMOCAT-R     &  0.7999   &  0.7380    & 0.0599 \\\\ \\hline\n% GMOCAT-A     &  0.7994  & 0.7427   & 0.0584  \\\\ \\hline\nGMOCAT-S   & 0.7983 & 0.7310 & 0.0586 \\\\  \\bottomrule\n\\end{tabular}\n\\vspace{-7pt}\n\\label{tab:ablation}\n\\end{table}"
        },
        "figures": {
            "fig:modelframework": "\\begin{figure*}\n    \\centering\n    \\vspace{-8pt}\n    \\includegraphics[width=\\linewidth]{picture/framework2.png}\n    \\caption{The overall framework of GMOCAT. Relation aggregator learns the relation-aware embeddings of questions and concepts. State encoder converts the historical response records into a low-dimensional state. Actor-critic recommender chooses the next question and then receives the multi-objective reward.}\n    \\vspace{-8pt}\n    \\label{fig:modelframework}\n\\end{figure*}",
            "fig:cov": "\\begin{figure}\n    \\subfigure[IRT on Eedi]{\n    \\centering\n    \\includegraphics[width=0.47\\linewidth]{picture/cov_eedi_irt.pdf}\n    }\n    \\subfigure[NCD on Eedi]{\n    \\centering\n    \\includegraphics[width=0.47\\linewidth]{picture/cov_eedi_ncd.pdf}\n    }\n    \n    \\subfigure[IRT on ASSIST]{\n    \\centering\n    \\includegraphics[width=0.47\\linewidth]{picture/cov_assist_irt.pdf}\n    }\n    \\subfigure[NCD on ASSIST]{\n    \\centering\n    \\includegraphics[width=0.47\\linewidth]{picture/cov_assist_ncd.pdf}\n    }\n    \n    \\subfigure[IRT on Junyi]{\n    \\centering\n    \\includegraphics[width=0.47\\linewidth]{picture/cov_junyi_irt.pdf}\n    }\n    \\subfigure[NCD on Junyi]{\n    \\centering\n    \\includegraphics[width=0.47\\linewidth]{picture/cov_junyi_ncd.pdf}\n    }\n    \\vspace{-7pt}\n    \\caption{Diversity Comparison with the Cov Metric.}\n    \\vspace{-15pt}\n    \\label{fig:cov}\n\\end{figure}",
            "fig:rewardweight": "\\begin{figure*}\n% \\vspace{-10pt}\n    \\subfigure[(a) Quality: AUC@20]{\n    \\centering\n    \\includegraphics[width=0.25\\linewidth]{picture/auc.pdf}\n    \\label{fig:aucinw}\n    }\n    \\hspace{-7pt}\n    \\subfigure[(b) Quality: ACC@20]{\n    \\centering\n    \\includegraphics[width=0.25\\linewidth]{picture/acc.pdf}\n    \\label{fig:accinw}\n    }\n    \\hspace{-7pt}\n    \\subfigure[(c) Diversity: Cov@20]{\n    \\centering\n    \\includegraphics[width=0.24\\linewidth]{picture/cov.pdf}\n    \\label{fig:covinw}\n    }\n    \\hspace{-7pt}\n    \\subfigure[(d) Novelty: Overlap@20]{\n    \\centering\n    \\includegraphics[width=0.24\\linewidth]{picture/overlap.pdf}\n    \\label{fig:overinw}\n    }\n    % \\vspace{-7pt}\n    \\caption{Performance Comparison about GMOCAT using different configurations of $\\mathbf{w}$, which cause to focus on a subset of objectives. The results are at step 20 on IRT with Eedi dataset. The first, second and third entries of $\\mathbf{w}$ corresponds to the importance of quality, diversity and novelty objective, respectively.}\n    \\label{fig:rewardweight}\n\\end{figure*}"
        },
        "equations": {
            "eq:1": "\\begin{align}\n    \\max_{\\pi} \\mathcal{J} &= \\max_{\\pi} \\frac{1}{n} \\sum_{i=1}^{n} \\left[ \\mathbf{w}^T \\left( \\sum_{t'=1}^{T}\\gamma^{t'}\\mathbf{r}\\left(\\mathbf{s}^i_{t'},q^i_{t'}\\right)\\right) \\right] \\\\\n   &=\\max_{\\pi} \\mathbb{E}_{i \\sim \\pi} \\left[ \\mathbf{w}^T \\left( \\sum_{t'=1}^{T}\\gamma^{t'}\\mathbf{r}\\left(\\mathbf{s}^i_{t'},q^i_{t'}\\right)\\right) \\right]\n   \\label{eq:objectivefunction}\n\\end{align}",
            "eq:2": "\\begin{equation}\n    r_{qua} = ACC({\\theta}_t) - ACC({\\theta}_{t-1})\n\\label{equ:qualityreward}\n\\end{equation}",
            "eq:3": "\\begin{equation}\n    r_{div} =\n    \t\\begin{cases}\n\t\t\t\t 1, \\quad \\text{if}\\quad c_t \\setminus \\{c_1 \\cup c_2 \\ldots \\cup c_{t-1}\\} \\neq \\emptyset \\\\\n\t\t\t\t 0, \\quad \\text{otherwise}\n\t\t\\end{cases}\n\t\t\\label{equ:diversityreward}\n\\end{equation}",
            "eq:4": "\\begin{equation}\n    r_{nov} =\n    \t\\begin{cases}\n\t\t\t\t 1, \\quad \\text{if}\\ q_t \\notin \n \\mathcal{T}\\\\\n\t\t\t\t 0, \\quad \\text{otherwise}\n\t\t\\end{cases}\n\t\t\\label{equ:noveltyreward}\n\\end{equation}",
            "eq:5": "\\begin{equation}\n    \\mathbf{e}_{t'} = \\widetilde{\\mathcal{E}}_q^{t'} \\oplus \\widetilde{\\mathcal{E}}_c^{t'} \\oplus \\mathcal{E}_y^{t'}\n% \\vspace{-3pt}\n\\end{equation}",
            "eq:6": "\\begin{equation}\n    \\widetilde{\\mathbf{E}}_t=\n    \\text{Softmax}(\\frac{(\\mathbf{E}_t \\mathbf{W}^Q) (\\mathbf{E}_t \\mathbf{W}^K)^T}{\\sqrt{d_k}})(\\mathbf{E}_t \\mathbf{W}^V)\n    \\label{eq:selfattention}\n    % \\vspace{-4pt}\n\\end{equation}",
            "eq:7": "\\begin{equation}\n    \\mathbf{A}(\\mathbf{s}_t,q_t)=\\sum_{t'=t}\\gamma^{t'-t}\\mathbf{r}(\\mathbf{s}_{t'},q_{t'})-\\mathbf{V}(\\mathbf{s}_t)\n    \\label{eq:return}\n\\end{equation}",
            "eq:8": "\\begin{equation}\n\\begin{split}\n\\mathcal{L}_1 = -& \\mathbb{E}_{\\tau \\sim \\pi_{old}} [\\text{Min} \\{\\frac{\\pi(q_t|\\mathbf{s}_t)}{\\pi_{old}(q_t|\\mathbf{s}_t)} \\mathbf{w}^T \\mathbf{A}(\\mathbf{s}_t,q_t),  \\\\ \n&\\text{Clip} \\left( \\frac{\\pi(q_t|\\mathbf{s}_t)}{\\pi_{old}(q_t|\\mathbf{s}_t)},1-\\epsilon , 1+\\epsilon \\right) \\mathbf{w}^T \\mathbf{A}(\\mathbf{s}_t,q_t) \\}] \n\\end{split}\n\\label{eq:actorloss}\n\\end{equation}",
            "eq:9": "\\begin{equation}\n    \\mathcal{L}_2=\\frac{1}{2} \\mathbf{w}^T \\|\\mathbf{V}(\\mathbf{s}_t) - \\sum_{t'=t}\\gamma^{t'-t}\\mathbf{r}(\\mathbf{s}_{t'},q_{t'})\\|^2 \n\\end{equation}",
            "eq:10": "\\begin{equation}\n    \\mathcal{L} = \\mathcal{L}_1 + \\alpha \\mathcal{L}_2\n    \\label{equ:moppoloss}\n\\end{equation}",
            "eq:11": "\\begin{equation}\n    \\mathbf{g}_{pre} =\\sum_{c'\\in N_c^{pre}} \\alpha_{c,c'}\\mathbf{W}_{pre}\\mathcal{E}_{c'},\\ \\  \\mathbf{g}_{cor} =\\sum_{q'\\in N_c^{cor}} \\beta_{c,q'}\\mathbf{W}_{cor}\\mathcal{E}_{q'}\n\\end{equation}",
            "eq:12": "\\begin{align}\n    \\alpha_{c,c'} &= \\text{Softmax}_{c'} \\left( \\text{att}_{pre} \\left([\\mathbf{W}_{pre}\\mathcal{E}_{c},  \\mathbf{W}_{pre}\\mathcal{E}_{c'}]\\right)\\right), c' \\in N_c^{pre} \\\\\n    \\beta_{c,q'} &= \\text{Softmax}_{q'} \\left( \\text{att}_{cor} \\left([\\mathbf{W}_{cor}\\mathcal{E}_{c}, \\mathbf{W}_{cor}\\mathcal{E}_{q'}]\\right)\\right), q' \\in N_c^{cor} \\label{eq:betaweight}\n\\end{align}",
            "eq:13": "\\begin{equation}\n    \\mu_{pre} = \\mathbf{P}^T \\cdot tanh(\\mathbf{W} \\cdot \\mathbf{g}_{pre}+\\mathbf{b})\n\\end{equation}",
            "eq:14": "\\begin{equation}\n    \\widetilde{\\mathcal{E}}_{c}= \\mu_{pre} \\mathbf{g}_{pre} + \\mu_{cor} \\mathbf{g}_{cor} \n\\end{equation}",
            "eq:15": "\\begin{equation} \\label{eq:div-cov}\n    Cov = \\frac{1}{|K|}\\sum_{k\\in K} \\mathbbm{1}(k \\in \\mathcal{K}_t)\n\\end{equation}",
            "eq:16": "\\begin{align}\n    &\\text{Exposure}_q = \\frac{N_q}{|\\mathcal{U}|} \\\\\n    \\text{Overlap} &= \\frac{\\sum\\sum_{i,j \\in \\mathcal{U},j\\neq i} |Q_i \\bigcap Q_j |}{ |\\mathcal{U}|*(|\\mathcal{U}|-1)/2  }\n\\end{align}",
            "eq:17": "\\begin{equation}\n    \\mathbf{w} \\in \\{[1,1,1], [1,0,0], [0,1,0], [0,0,1],[1,1,0],[1,0,1],[0,1,1] \\}\\nonumber\n\\end{equation}"
        },
        "git_link": "https://github.com/justarter/GMOCAT"
    }
}