{
    "meta_info": {
        "title": "PageRank Bandits for Link Prediction",
        "abstract": "Link prediction is a critical problem in graph learning with broad\napplications such as recommender systems and knowledge graph completion.\nNumerous research efforts have been directed at solving this problem, including\napproaches based on similarity metrics and Graph Neural Networks (GNN).\nHowever, most existing solutions are still rooted in conventional supervised\nlearning, which makes it challenging to adapt over time to changing customer\ninterests and to address the inherent dilemma of exploitation versus\nexploration in link prediction. To tackle these challenges, this paper\nreformulates link prediction as a sequential decision-making process, where\neach link prediction interaction occurs sequentially. We propose a novel fusion\nalgorithm, PRB (PageRank Bandits), which is the first to combine contextual\nbandits with PageRank for collaborative exploitation and exploration. We also\nintroduce a new reward formulation and provide a theoretical performance\nguarantee for PRB. Finally, we extensively evaluate PRB in both online and\noffline settings, comparing it with bandit-based and graph-based methods. The\nempirical success of PRB demonstrates the value of the proposed fusion\napproach. Our code is released at https://github.com/jiaruzouu/PRB.",
        "author": "Yikun Ban, Jiaru Zou, Zihao Li, Yunzhe Qi, Dongqi Fu, Jian Kang, Hanghang Tong, Jingrui He",
        "link": "http://arxiv.org/abs/2411.01410v1",
        "category": [
            "cs.LG",
            "cs.AI",
            "cs.SI"
        ],
        "additionl_info": "Accepted to NeurIPS 2024"
    },
    "latex_extraction": {
        "content": {
            "section 1": {
                "name": "Introduction",
                "content": "\n\n\nLink prediction is an essential problem in graph machine learning, focusing on predicting whether a link will exist between two nodes. Given the ubiquitous graph data in real-world applications, link prediction has become a powerful tool in domains such as recommender systems \\citep{zhang2019inductive} and knowledge graph completion \\citep{nickel2015review, DBLP:conf/sigir/LiAH24}. Considerable research efforts have been dedicated to solving this problem. One type of classic research approaches is heuristic-based methods, which infer the likelihood of links based on node similarity metrics \\citep{liben2003link,lu2011link}.\nGraph Neural Networks (GNNs) have been widely utilized for link prediction. For example, Graph Autoencoders leverage Message Passing Neural Network (MPNN) representations to predict links \\cite{gilmer2017neural}. Recently, MPNNs have been combined with structural features to better explore pairwise relations between target nodes \\citep{zhang2021labeling, yun2021neo, chamberlain2022graph, wang2023neural}.\n\n\n\n\nExisting supervised-learning-based methods for link prediction are designed for either the static \\cite{zhang2021labeling, yun2021neo, chamberlain2022graph, wang2023neural} or relatively dynamic environment  \\citep{xu2020inductive, rossi2020temporal, wang2021inductive, tian2023freedyg, yu2023towards, cong2023we, DBLP:conf/sigir/FuH21, DBLP:conf/kdd/FuFMTH22, DBLP:conf/kdd/ZhengJLTH24}, they (chronologically) split the dataset into training and testing sets. Due to the dynamic and evolving nature of many real-world graphs, ideal link prediction methods should adapt over time to consistently meet the contexts and goals of the serving nodes. For instance, in short-video recommender systems, both video content and user preferences change dynamically over time \\citep{gao2023alleviating}.\nAnother significant challenge is the dilemma of exploitation and exploration in link prediction. The learner must not only exploit past collected data to predict links with high likelihood but also explore lower-confidence target nodes to acquire new knowledge for long-term benefits. For example, in social recommendations, it is necessary to prioritize popular users by \u2018exploiting\u2019 knowledge gained from previous interactions, while also\u2018exploring\u2019 potential value from new or under-explored users to seek long-term benefits \\citep{ban2024neural}.  \nFurthermore, while existing works often analyze time and space complexity, they generally lack theoretical guarantees regarding the performance of link prediction.\nTo address these challenges, in this paper, we make the following contributions:\n\n\n\n\\para{Problem Formulation and Algorithm}. \nWe formulate the task of link prediction as sequential decision-making under the framework of contextual bandits, where each interaction of link prediction is regarded as one round of decision-making. We introduce a pseudo-regret metric to evaluate the performance of this decision process.\nMore specifically, we propose a fusion algorithm named \\sysn (PageRank Bandits), which combines the exploitation and exploration balance of contextual bandits with the graph structure utilization of PageRank~\\citep{tong2006fast,li2023everything}. Compared to contextual bandit approaches, \\sysn leverages graph connectivity for an aggregated representation. In contrast to PageRank, it incorporates the principles of exploitation and exploration from contextual bandits to achieve a collaborative trade-off. Additionally, we extend \\sysn to node classification by introducing a novel transformation from node classification to link prediction, thereby broadening the applicability of \\sysn.\n\n\n\\para{Theoretical Analysis}. \nWe introduce a new formulation of the reward function to represent the mapping from both node contexts and graph connectivity to the reward. We provide one theoretical guarantee for the link prediction performance of the proposed algorithm, demonstrating that the cumulative regret induced by \\sysn can grow sub-linearly with respect to the number of rounds. This regret upper bound also provides insights into the relationship between the reward and damping factor, as well as the required realization complexity of the neural function class.\n%Note that the standard regret analysis in contextual bandits cannot be directly applied here, as their reward formulation \\citep{zhou2020neural,ban2022eenet} that is only associated with arm (node) contexts is different from this work.\n\n\\para{Empirical Evaluation}.\nWe extensively evaluate \\sysn in two mainstream settings. (1) Online Link Prediction. In this setting, each link prediction is made sequentially. In each round, given a serving node, the model is required to choose one target node that has the highest likelihood of forming a link with the serving node. The model then observes feedback and performs corresponding optimizations. The goal is to minimize regret over  $T$ rounds (e.g., $T = 10,000$). We compare \\sysn with state-of-the-art (SOTA) bandit-based approaches (e.g., \\citep{zhou2020neural, ban2022eenet}), which are designed for sequential decision-making. \\sysn significantly outperforms these bandit-based baselines, demonstrating the success of fusing contextual bandits with PageRank for collaborative exploitation and exploration.\n(2) Offline Link Prediction. In this setting, both training and testing data are provided, following the typical supervised learning process. Although \\sysn is designed for online learning, it can be directly applied to offline learning on the training data. We then use the trained model to perform link prediction on the testing data, comparing it with SOTA GNNs-based methods (e.g., \\citep{chamberlain2022graph, wang2023neural}). The superior performance of \\sysn indicates that principled exploitation and exploration can break the performance bottleneck in link prediction. Additionally, we conduct ablation and sensitivity studies for a comprehensive evaluation of \\sysn.\n\n\n\n\n\n\\vspace{-2mm}\n"
            },
            "section 2": {
                "name": "Related Work",
                "content": "\n\\para{Contextual Bandits}. \nThe first line of works studies the linear reward assumption, typically calculated using ridge regression \\citep{2010contextual, ban2020generic, 2011improved, valko2013finite, dani2008stochastic, qi2024meta}. Linear UCB-based bandit algorithms \\citep{2011improved, ban2021local,2016collaborative} and linear Thompson Sampling \\citep{agrawal2013thompson, abeille2017linear} can achieve satisfactory performance and a near-optimal regret bound of \\(\\tilde{\\mathcal{O}}(\\sqrt{T})\\).\nTo learn general reward functions, deep neural networks have been adapted to bandits in various ways \\cite{ban2021multi,ban2024meta}. \\cite{riquelme2018deep, lu2017ensemble} develop \\(L\\)-layer DNNs to learn arm embeddings and apply Thompson Sampling on the final layer for exploration. \\cite{zhou2020neural} introduced the first provable neural-based contextual bandit algorithm with a UCB exploration strategy, and \\cite{zhang2020neural} later extended to the TS framework. \\cite{deb2023contextual} provides sharper regret upper bound for neural bandits with neural online regression.\nTheir regret analysis builds on recent advances in the convergence theory of over-parameterized neural networks \\citep{du2019gradient, allen2019convergence} and uses the Neural Tangent Kernel \\citep{ntk2018neural, arora2019exact} to establish connections with linear contextual bandits \\citep{2011improved}. \\cite{ban2022eenet,ban2023neural} retains the powerful representation ability of neural networks to learn the reward function while using another neural network for exploration. \\cite{qi2023graph,qi2022neural} integrates exploitation-exploration neural networks into the graph neural networks for fine-grained exploration and exploration. Recently, neural bandits have been adapted to solve other learning problems, such as active learning\\cite{ban2022improved,ban2024neural}, meta learning\\cite{qi2024meta}.\n\n\n\n\\para{Link Prediction Models.} Three primary approaches have been identified for link prediction models. Node embedding methods, as described by previous work \\citep{perozzi2014deepwalk,grover2016node2vec,tang2015line, ding2022data, lin2024bemap,lin2024backtime, fu2022disco}, focus on mapping each node to an embedding vector and leveraging these embeddings to predict connections. Another approach involves link prediction heuristics, as explored by \\citep{liben2003link,barabasi1999emergence,adamic2003friends, zhou2009predicting}, which utilize crafted structural features and network topology to estimate the likelihood of connections between nodes in a network. The third category employs GNNs for predicting link existence; notable is the Graph Autoencoder (GAE) \\citep{kipf2016semi}, which learns low-dimensional representations of graph-structured data through an unsupervised learning process. GAE utilizes the inner product of MPNN representations of target nodes to forecast links but might not capture pairwise relations between nodes effectively. More sophisticated GNN models that combine MPNN with additional structural features, such as those by \\citep{zhang2018link, yun2021neo, chamberlain2022graph}, have demonstrated superior performance by integrating both node and structural attributes. One such combined architecture is SF-then-MPNN, as adopted by \\citep{zhang2018link, zhu2021neural}. In this approach, the input graph is first enriched with structural features (SF) and then processed by the MPNN to enhance its expressivity. However, since structural features change with each target link, the MPNN must be re-run for each link, reducing scalability. For instance, the SEAL model \\citep{zhang2018link} first enhances node features by incorporating the shortest path distances and extracting k-hop subgraphs, then applies MPNN across these subgraphs to generate more comprehensive link representations. Another combined architecture is SF-and-MPNN. Models like Neo-GNN \\citep{yun2021neo} and BUDDY \\citep{chamberlain2022graph} apply MPNN to the entire graph and concatenate features such as common neighbor counts to enhance representational fidelity. In addition, \\citep{wang2023neural} has developed the Neural Common Neighbor with Completion (NCNC) which utilizes the MPNN-then-SF architecture to achieve higher expressivity and address the graph incompleteness. \n\nRecently, representation learning on temporal graphs for link prediction has also been widely studied to exploit patterns in historical sequences, particularly with GNN-based methods \\citep{tian2023freedyg, yu2023towards, cong2023we, xu2020inductive, wang2021inductive, rossi2020temporal}. However, these approaches are still conventional supervised-learning-based methods that chronologically split the dataset into training and testing sets. Specifically, these methods train a GNN-based model on the temporal training data and then employ the trained model to predict links in the test data. In contrast, we formulate link predictions as sequential decision-making, where each link prediction is made sequentially. \nNode classification\\cite{bhagat2011node,xu2022graph,xu2023node} is also a prominent direction in graph learning, but it is not the main focus of this paper.\\vspace{-3mm}\n"
            },
            "section 3": {
                "name": "Problem Definition",
                "content": " \\label{sec:problem}\n\\vspace{-2mm}\nLet $G_0 = (V, E_0)$ be an undirected graph at initialization, where $V$ is the set of $n$ nodes, $|V| = n$, and $E_0 \\subseteq V \\times V $ represents the set of edges.  \n$E_0$ can be an empty set in the cold-start setting or include some existing edges with a warm start.\n%$G_0$ can be an empty graph, i.e., $E_0 = \\emptyset$, or have some  \n%Note that $ E_0$ can be $\\emptyset$ or $ E_0 \\neq \\emptyset$ with some prior knowledge\\he{What `prior knowledge'?}.\nEach node $v_i \\in V$ is associated with a context vector $\\bx_{0, i} \\in \\bbr^d$ . \n%Let $A_0$ be the adjacency matrix of $G_0$. Given any two nodes $i,j$, $A_0[i,j] = 1$ if the edge $(i, j) \\in E_0$; otherwise, $A_0[i,j] = 0$.\nThen, we formulate link prediction as the problem of sequential decision-making under the framework of contextual bandits.\nSuppose the learner is required to finish a total of $T$ link predictions. We adapt the above notation to all the evolving $T$ graphs $\\{ G_t = (V, E_t) \\}_{t=0}^{T-1}$ and let  $[T] = \\{1, \\dots, T\\}$. \nIn a round of link prediction $t \\in [T]$, given $G_{t-1} = (V, E_{t-1})$,  the learner is presented with a serving node $v_t \\in V$  and a set of $k$ candidate nodes $\\mathcal{V}_t = \\{v_{t,1}, \\dots, v_{t, k}\\} \\subseteq V$, where  $\\mathcal{V}_t$ is associated with the corresponding $k$ contexts $\\calx_t=\\{ x_{t,1}, \\dots, x_{t, k} \\}$ and $|\\calv_t| = k$.\nIn the scenario of social recommendation, $v_t$ can be considered as the user that the platform (learner) intends to recommend potential friends to, and the other candidate users will be represented by $\\calv_t$.  $\\calv_t$ can be set as the remaining nodes $\\calv_t = V_t/v_t$ or formed by some pre-selection algorithm $\\calv_t \\subset V_t$.\n\n%\\he{How do you decide the serving node and the candidate nodes? An example would be good.}\nThe goal of the learner is to predict which node in $\\mathcal{V}_t$ will generate a link or edge with $v_t$. Therefore, we can consider each node in $\\mathcal{V}_t$ as an arm, and aim to select the arm with the maximal reward or the arm with the maximal probability of generating an edge with $v_t$.\n%\\he{Why just one arm?}. \nFor simplicity, we define the reward of link prediction as the binary reward. Let $v_{t, \\hi} \\in \\calv_t$ be the node selected by the learner. Then, the corresponding reward is defined as \n$r_{t, \\hi} = 1 $ if the link $[v_t, v_{t, \\hi}]$ is really generated; otherwise, $r_{t, \\hi} = 0$. After observing the reward $r_{t, \\hi}$, we update $E_{t-1}$ to obtain the new edge set $E_t$, and thus new $G_t$.\n\n\nFor any node  $v_{t, i} \\in \\calv_t$, denote by $\\cald_{\\caly|x_{t,i}}$ the conditional distribution of the random reward $r_{t, i}$  with respect to $x_{t, i}$, where $\\caly = \\{1, 0\\}$.\nThen, inspired by the literature of contextual bandits, we define the following \\emph{pseudo} regret:\n\\begin{equation} \\label{eq:regretdef}\n\\begin{aligned}\n    \\mathbf{R}_T  = \\sum_{t=1}^T \\left (  \\bbe_{r_{t, i^\\ast} \\sim  \\cald_{\\caly|x_{t,i^\\ast}}} [ r_{t, i^\\ast}]    -   \\bbe_{r_{t, \\hi} \\sim  \\cald_{\\caly|x_{t, \\hi}}} [ r_{t, \\hi}]  \\right)  = \\bbp(r_{t, i^\\ast} =1 | x_{t, i^\\ast}) - \\bbp(r_{t, \\hi} =1 | x_{t, \\hi})\n\\end{aligned}\n\\end{equation}\nwhere $i^\\ast = \\arg \\max_{v_{t,i} \\in \\calv_t} \\bbp(r_{t, i} =1 | x_{t, i})$, the tie is broken randomly, and $\\hi$ is the index of selected node. $\\mathbf{R}_T$ reflects the performance difference of the learned model from the Bayes-optimal predictor. The goal of the learner is to minimize $\\mathbf{R}_T$.\n\n\n\n\n\n\\iffalse\nFinally, regret is defined as follows:\n\\begin{equation}\n    \\mathcal{R}_T =  \\sum_{t=1}^T (r_t^\\ast  - r_{t, \\hi}),\n\\end{equation}\nwhere $r_t^\\ast = \\max_{v_i \\in \\mathcal{V}_t} r_{t, i}$. \n$\\mathcal{R}_T$ is used for the empirical evaluation in the experiment section.\n\nFrom the analysis perspective, i\n\\fi \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\iffalse\n\n\\para{Stochastic contextual Bandits}. We consider the setting of stochastic contextual multi-armed bandit represented by the tuple $(U, N, X, y, T)$. $U$ is the set of users,\n$N$ is the set of arms. In each round $t \\in \\left[T\\right]$, where the sequence $\\left[T\\right] = \\left[1, 2, \\dots, T\\right]$, a user $u_j \\in U$ is presented with $n$ arms $\\mathcal{N}_t \\subseteq N$.\nEach arm $i \\in N$ is represented as a context vector $\\bx_{t,i} \\in \\bbr^d$, where we assume $\\bx_{t,i}$ incorporates both user and arm features. Thus, the $n$ arms $\\mathcal{N}_t$  are represented $n$ context vectors $\\rmX_t = \\left\\{\\bx_{t, 1}, \\dots, \\bx_{t, n}\\right\\}$, and the learner is compelled to select an arm $\\bx_{t,i} \\in \\calx_t $ and receive its reward $r_{t,i}$. The reward is assumed to be governed by the function:\n\\begin{equation}\nr_{t,i} = y\\left(\\bx_{t,i}\\right) + \\eta_{t,i}\n\\end{equation}\nwhere $y$ is an unknown but bounded function that can be either linear or non-linear, and $\\eta$ is the noise associated with the arm subjected to $\\mathbb{E}\\left[\\eta_{t,i}\\right] = 0$.  \n\nLet $\\by_t$ be the expected reward vector for all arms in round $t$, $\\by_t = [y(\\bx_{t,1}), \\dots,  y(\\bx_{t,n}) ]$. \nThe goal of this problem follows the standard multi-armed bandits to minimize the pseudo regret:\n\\begin{equation}\n\\mathbf{R}_r(T) =  \\mathbb{E}\\left[\\sum_{t=1}^T \\left(r_{t, i^\\ast} - r_{t, i_t} \\right) \\right] = \\sum_{t=1}^T \\left( \\by_t[i^\\ast]  -   \\by_t[i_t]  \\right)\n\\end{equation}\nwhere $ i^\\ast = \\arg \\max_{i \\in \\left[n \\right]} \\by_t[i]$ and $i_t$ represents the index of selected arm in round $t$.\n\n\n\n\n\\para{Bandit Graphs}.\nExisting works focus on the mapping from contexts to the observed reward but barely grasp the graph structure formed by the interactions between serving users and arms. Thus, we introduce the following problem definition, where a graph grows incrementally as the interaction round goes.\nAt the initialization, a graph $G_0 = (U \\cup N, E_0)$ is given, which can be either an empty graph or some graph with prior knowledge.\nIn round $t$, with the user $j_t \\in U$, the arm $i_t$ is selected and the reward $r_{t, i_t}$ is observed. \nTherefore, we add an edge $(j_t, i_t, r_{t, i_t})$ is to the graph $G_{(t-1)}$, forming the new graph $G_t$.\n\\ban{To do: Discuss the difference between $G_t$ and $G_{t-1}$. $G_t$ may contain additional knowledge except for this edge.}\n\n\n\nGiven the normalized adjacency matrix of $G_t$, denoted by $\\bp_t$, and the damping factor $\\alpha$, then, the goal of this problem is:\n\\begin{equation}\n\\bv_t^\\ast  = \\arg \\min_{\\bv}  \\alpha  \\underset{I_1}{\\bv^{\\top} (\\mathbf{I} - \\bp_t) \\bv} + \\underset{I_2}{(1-\\alpha) \\|\\bv - \\by_t\\|_2^2}\n\\end{equation}\n\n\\ban{To do: discuss $\\alpha$, $I_1$ and $I_2$.}\n\n\n\\begin{definition} [Popularity]\n$\\bv_t^\\ast$ is the popularity vector derived from the reward vector $\\by_t$. $\\bv_t^\\ast[i]$ represent the proximity of arm $i$ from other arms measured by $\\by_t$. \n\\end{definition}\n\nSolely counting on $\\by_t$ to select arms is not wise enough in many real-world applications. Instead, $\\bv_t^\\ast$ is a more informative and powerful representation in the scenarios with graph structure. \n\n\\begin{remark}\n(1) In a round of online advertising, two pages A and B are presented to a user. Suppose A and B have the same or close click rate (reward) by this user. How shall the learner rank A and B? Given the graph structure, hundreds of webs have linked page A compared to tens of links to B. It is evident that A should be ranked at the front of B. In this case, $\\by_t$ cannot solve this challenge but $\\bv_t^\\ast$ can properly work on it. (2) This challenge also widely exists in online social and item recommendation.\n\\end{remark}\n\n\nAs $\\by_t$ is unknown, $\\bv_t^\\ast$ is also unknown. \nTherefore, we propose the following formulate of pseudo-regret to measure both connectivities and rewards:\n\n\\begin{equation}\n\\mathbf{R}_c(T) = \\sum_{t=1}^T \\left( \\bv_t^\\ast[i^\\ast] - \\bv_t^\\ast[i_t]  \\right)\n\\end{equation}\nwhere $i^\\ast = \\arg \\max_{i \\in [n]} \\bv_t^\\ast[i]$ and $i_t$ is the index of selected arm in round $t$. \n\n\n\n\n%\\jian{some equations have many levels of nested parentheses and brackets, how about using $\\left(\\right)$, $\\left[\\right]$ and $\\left\\{\\right\\}$? Adding those commands will automatically adjust the size of parentheses.}\n%\\ban{Thanks. Will do that.}\n\n\n\\begin{remark}[Application 1: Social recommendation]\nIn round $t$,  a social platform receives a serving user.\nThen the platform observes a set of users (arms) with a set of edges (social connections), forming the graph $G_t$. The platform is required to recommend one or $k$ users to the serving user. If the serving user builds a connection with recommended  (i.e., follows) users, the platform will observe the reward $1$, and one new edge is formed. Otherwise, the observed reward is $0$.\n\\end{remark}\n\n\n\\begin{remark} [Application 2: Item recommendation]\nIn round $t$,  an E-commerce platform receives a serving user and then observes a set of users and items $N_t$ with edges $E_t$, forming the bipartite graph $G_t$. Then, the platform recommends one or $k$ items to the serving user. The reward is $1$ if the user clicks this item; Otherwise, the reward is $0$.\n\\end{remark}\n\n\\begin{remark} [Application 3: Online advertising]\nIn round $t$,  a news platform receives a serving user and then observes a set of websites (arms) $N_t$ with edges (hyperlinks) $E_t$, forming the graph $G_t$. Then, the platform advertises one or $k$ websites to the serving user. The reward is $1$ if the user clicks this website; Otherwise, the reward is $0$.\n\\end{remark}\n\n\\fi\n"
            },
            "section 4": {
                "name": "Proposed Algorithms",
                "content": " \\label{sec:algorithm}\n\n\nAlgorithm \\ref{alg:explore} describes the proposed algorithm \n\\sysn. It integrates contextual bandits and PageRank to combine the power of balancing exploitation and exploration with graph connectivity.\nThe first step is to balance the exploitation and exploration in terms of the reward mapping concerning node contexts, and the second step is to propagate the exploitation and exploration score via graph connectivity.\n\n\n\n\\begin{algorithm}[!t]\n\\renewcommand{\\algorithmicrequire}{\\textbf{Input:}}\n\\renewcommand{\\algorithmicensure}{\\textbf{Output:}}\n\\caption{ \\sysn (PageRank Bandits) }\\label{alg:explore}\n\\begin{algorithmic}[1] \n\\Require $f_1, f_2$,  $T$,  $G_0$,  $\\eta_1, \\eta_2$ (learning rate), $\\alpha$ (damping factor) \n\\State Initialize $\\theta^1_0, \\theta^2_0$\n\\For{ $t = 1 , 2, \\dots, T$}\n\\State Observe serving node $v_t$, candidate nodes $\\calv_t$, contexts $\\calx_t$  and Graph $G_{t-1}$\n\\State $\\bh_t = \\mathbf{0}$\n\\For{each $v_{t,i} \\in \\calv_t$ }\n\\State \n$\\bh_t[i] = f_1\\left(x_{t,i}; \\theta^1_{t-1}\\right) + f_2\\left(\\phi\\left(x_{t,i}\\right); \\theta^2_{t-1}\\right)$\n\\EndFor\n\\State Compute $\\rmP_t$ based on $G_{t-1}$\n\\State Solve $\\bv_t = \\alpha \\rmP_t \\bv_t + \\left(1 - \\alpha\\right) \\bh_t$ \n\\State Select $\\hi = \\arg \\max_{v_{t,i} \\in \\calv_t} \\bv_t\\left[i\\right] $\n\\State Observe $r_{t, \\hi}$\n\\If {$r_{t, \\hi}$ == 1}\n\\State Add $[v_t, v_{t, \\hi}]$ to $G_{t-1}$ and set as $G_t$\n\\Else\n\\State $G_t = G_{t-1}$\n\\EndIf\n\\State   $\\btheta_t^1 = \\btheta_{t-1}^1 -  \\eta_1  \\nabla_{\\btheta_{t-1}^1}  \\call \\left( x_{t,\\hi}, r_{t, \\hi};   \\btheta_{t-1}^1 \\right) $ \n\\State   $\\btheta_t^2 = \\btheta_{t-1}^2 -  \\eta_2  \\nabla_{\\btheta_{t-1}^2}  \\call \\left( \\phi(x_{t,\\hi}), r_{t, \\hi} - f_1(x_{t,\\hi}; \\theta^1_{t-1});   \\btheta_{t-1}^2\\right) $\n\\EndFor\n\\end{algorithmic}\n\\end{algorithm}\n\n\nTo exploit the node contexts, we use a neural network to estimate rewards from the node contexts.\n%The exploitation score is regarded as an inference of a neural network based on the node context.\\he{What do you mean by `AN INFERENCE'?} \nLet $f_1(\\cdot ; \\theta^1)$ be a neural network to learn the mapping from the node context to the reward. Denote the initialized parameter of $f_1$ by $\\theta^1_0$.\n%The exploitation net $f_1$ is a neural network which learns the mapping from arms to rewards.\nIn round $t$, let $\\theta_{t-1}^1$ be parameter trained on the collected data of previous $t-1$ rounds including all selected nodes and the received rewards. \nGiven the serving node $v_t$, for any candidate node $v_{t,i} \\in \\calv_t$, $f_1(x_{t, i} ; \\theta^1_{t-1}), i \\in \\calv_t$ is the estimated reward by greedily exploiting the observed contexts, which we refer to as ``exploitation''.\nSuppose $\\hi$ is the index of selected nodes. To update $\\theta^1_{t-1}$, we can conduct stochastic gradient descent to update $\\theta^1$ based on the collected training sample $(x_{t,\\hi}, r_{t,\\hi})$ with the squared loss function \n$ \\call \\left( x_{t,\\hi}, r_{t, \\hi};   \\btheta_{t-1}^1\\right) = [ f(x_{t,\\hi}; \\theta_{t-1}^1) - r_{t,\\hi}]^2/2$.\nDenote the updated parameters by $\\theta^1_t$ for the next round of link prediction.\n\n\n\nIn addition to exploiting the observed contexts, we employ another neural network to estimate the potential gain of each candidate node in terms of reward for exploration. This idea is inspired by \\citep{ban2022eenet}. Denote the exploration network by $f_2(\\cdot; \\theta^2)$. \n$f_2$ is to learn the mapping from node contexts and the discriminative ability of $f_1$ to the potential gain.\n%potential gain of a candidate node \n%knowledge of exploration from the learning path exploitation network $f_1$, i.e., to estimate the potential gain of the reward of a candidate node, given its context and the discriminative ability of  $f_1$. \nIn round $t \\in [T]$, given node context $x_{t,i} \\in \\calv_t$ and its estimated reward $f_1(x_{t,i}; \\theta^1_{t-1})$, the input of $f_2$ is the gradient of $f_1(x_{t,i}; \\theta^1_{t-1})$ with respect to $\\theta^1_{t-1}$, denoted by $\\phi(x_{t,i})$,  and $f_2(\\phi(x_{t,i}); \\theta^2_{t-1})$ is the estimated potential gain. \nAfter the learner selects the node $x_{t,\\hi}$ and observes the reward $r_{t,\\hi}$, the potential gain is defined as $r_{t,\\hi} - f_1(x_{t,i}; \\theta^1_{t-1})$, which is used to train $f_2$. Thus, after this interaction, we conduct the stochastic gradient descent to update $\\theta^2$ based on the collected sample $(\\phi(x_{t,\\hi}),  r_{t,\\hi} - f_1(x_{t,i}; \\theta^1_{t-1}) )$ with the squared loss function $\\call \\left( \\phi(x_{t,\\hi}), r_{t, \\hi} - f_1(x_{t,\\hi}; \\theta^1_{t-1});   \\btheta_{t-1}^2\\right) = [f(\\phi_{t,i}; \\theta_{t-1}^2) - ( r_{t,\\hi} - f_1(x_{t,i}; \\theta^1_{t-1})) ]^2/2$.\nDenote by $\\theta^2_t$ the updated parameters of $f_2$ for the next round of link prediction.\nThe reasons for setting $\\phi(x_{t,i})$ as the input of $f_2$  are as follows: (1) it incorporates the information of both $x_{t,\\hi}$ and discriminative ability of $f_1(\\cdot; \\theta_{t-1}^1)$; \n(2) the statistical form of the confidence interval for reward estimation can be regarded as the mapping function from $\\phi(x_{t,i})$ to the potential gain, and $f_2$ is to learn the unknown mapping \\citep{ban2022eenet}. \n\n\n\nThe previous steps demonstrate the exploitation and exploration of node contexts to facilitate decision-making in link prediction. Since graph connectivity is also crucial, we next introduce our method of integrating the bandit principle with PageRank to enable collaborative exploitation and exploration. \nPageRank calculates the stationary distribution of the random walker starting from some node, iteratively moving to a random neighbor with probability $\\alpha$ (damping factor) or returning to its original position with probability $1-\\alpha$. Let $\\bv_t$ be the stationary distribution vector calculated based on the graph $G_t$. \nThen, $\\bv_t$ satisfies: \n\\begin{equation}\\label{eq:pagerankvector}\n\\bv_t = \\alpha  \\rmP_t \\bv_t + \\left(1-\\alpha\\right) \\rvh_t\n\\end{equation}\nwhere $\\rmP_t \\in \\bbe^{n \\times n}$ is the transition matrix built on $G_{t-1}$ and $\\rvh_t$ is typically regarded as a position vector to mark the starting node. \n$\\rmP_t$ is computed as $\\mathbf{D}^{-1}_{t-1}\\mathbf{A}_{t-1}$, where $\\mathbf{D}_{t-1} \\in \\bbr^{n\\times n}$ is the degree matrix of $G_{t-1}$ and $\\mathbf{A}_{t-1} \\in \\bbr^{n \\times n}$ is the adjacency matrix of $G_{t-1}$. \n\nHere we propose to use $\\rvh_t$ to include the starting exploitation and exploration scores of candidate nodes, defined as:\n\\begin{equation}\n    i \\in \\calv_t, \\bh_t[i] =  f_1(\\bx_{t, i} ; \\btheta^1_{t-1}) + f_2(x_{t,i}; \\theta^2_{t-1}), \\  \\text{and} \\  \\  i \\in  V/\\calv_t, \\bh_t[i] = 0. \n\\end{equation}\nTherefore, $\\bv_t$ is the vector for the final decision-making based on collaborative exploitation and exploration. Some research efforts have been devoted to accelerating the calculation of Eq.\\ref{eq:pagerankvector} in the evolving graph, e.g., \\citep{li2023everything}, which can be integrated into \\sysn (Line 9 in Algorithm \\ref{alg:explore}) to boost its efficiency and scalability. \n\n\n\n\n\\para{\\sysn for Node Classification}.\nWe also extend \\sysn to solve the problem of node classification as illustrated in Figure \\ref{fig:nodetransform}. \nConsider a $k$-class classification problem. We add $k$ super nodes $\\{\\tilde{v}_1,  \\tilde{v}_2, \\dots, \\tilde{v}_k \\}$ to the graph, which represents $k$ classes, respectively.   \nThen, we transform the node classification problem into the link prediction problem, aiming to predict the link between the serving node and the $k$ super nodes.  \nTo be specific, in round $t \\in [T]$, the learner is presented with the serving node $v_t$ and the $k$ candidate (super) nodes $\\calv_t = \\{ \\tilde{v}_1,  \\tilde{v}_2, \\dots, \\tilde{v}_k \\}$ associated with $k$ corresponding contexts $\\calx_t = \\{ x_{t,1}, x_{t,2}, \\dots,  x_{t,k}\\}$. Recall $x_t$ is the context associated with $v_t$. Then, we define the contexts of super nodes as $x_{t,1} = [x_t^\\top, \n\\mathbf{0}, \\dots, \\mathbf{0}]^\\top, x_{t,2} = [\\mathbf{0}, x_t^\\top, \\dots, \\mathbf{0}]^\\top, \\dots, x_{t,k} = [\\mathbf{0}, \\mathbf{0}, \\dots, x_t]^\\top$,  $x_{t,i} \\in \\bbr^{kd}, i \\in [k]$. This context definition is adopted from neural contextual bandits \\citep{ban2022eenet,zhou2020neural}.\n%\\he{This setup looks a little weird for node classification. Maybe mention this is a common practice in bandit problems with some references?}. \nThen, the learner is required to select one node from $\\calv_t$. Let $\\tilde{v}_{i_t}$ be the selected node and $\\tilde{v}_{i_t^\\ast}$ be ground-truth node ($i_t^\\ast$ is the index of ground-truth class of node $v_t$). Then, after observing the reward $r_{t, i_t}$, one edge $[v_t,  \\tilde{v}_{i_t}]$ is added to the graph $G_{t-1}$, if $v_t$ belongs to the class $i_t$, i.e., $ i_t=  i_t^\\ast$ and reward $r_{t, i_t} = 1$. \nOtherwise,   $r_{t, i_t} = 0$ and the edge $[v_t, \\tilde{v}_{i_t^\\ast}]$ is added to $G_{t-1}$.\nThen, we can naturally apply \\sysn to this problem. We detail our extended algorithm for node classification in Algorithm \\ref{alg:explore_node}.   \n\n\\textbf{PRB Greedy.} We also introduce a greedy version of \\sysn which integrates PageRank solely with contextual bandit exploitation, as outlined in Algorithm \\ref{alg:greedy}. We will compare each variant of algorithms in our experiment section.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"
            },
            "section 5": {
                "name": "Regret Analysis",
                "content": "\n\n\n\n\nIn this section, we provide the theoretical analysis of \\sysn by bounding the regret defined in Eq.\\ref{eq:regretdef}. \nOne important step is the definition of the reward function, as this problem is different from the standard bandit setting that focuses on the arm (node) contexts and does not take into account the graph connectivity.\n%As the studied problem setting is different from the standard contextual bandits, we provide one definition of reward function with the principle of PageRank. \nFirst, we define the following general function to represent the mapping from the node contexts to the reward.\nGiven the serving node $v_t$ and an arm node $v_{t,i} \\in V_t$ associated with the context $x_{t,i}$, the reward conditioned on $v_t$ and $v_{t,i}$ is assumed to be governed by the function:\n\\begin{equation}\n\\bbe[\\tilde{r}_{t,i} | v_t, v_{t,i}] = y\\left(\\bx_{t,i}\\right) \n\\end{equation}\nwhere $y$ is an unknown but bounded function that can be either linear or non-linear.  \nNext, we provide the formulation of the final reward function. In round $t \\in [T]$, let $\\by_t$ be the vector to represent the expected rewards of all candidate arms $\\by_t = [y\\left(\\bx_{t,i}\\right): v_{t,i} \\in V_t]$. \nGiven the graph $G_{t-1}$, its normalized adjacency matrix $\\bp_t$, and the damping factor $\\alpha$, inspired by PageRank, the optimizing problem is defined as:\n$\\bv_t^\\ast  = \\arg \\min_{\\bv} \\alpha  \\bv^{\\top} (\\mathbf{I} - \\bp_t) \\bv + (1-\\alpha) \\|\\bv - \\by_t\\|_2^2/2$.\nThen, its optimal solution is \n\\begin{equation}\n\\bv_t^\\ast = \\alpha  \\rmP_t \\bv_t^\\ast + \\left(1-\\alpha\\right) \\by_t.\n\\end{equation}\nFor any candidate node $v_{t,i} \\in \\calv_t$,  we define its expected reward as $\\bbe_{r_{t, i} \\sim  \\cald_{\\caly|x_{t,i}}} [ r_{t, i}] = \\bv_t^\\ast[i]$.\n%\\he{What's the difference between $\\bv_t^\\ast$ and $\\by_t$?} \n$\\bv_t^\\ast$ is a flexible reward function that reflects the mapping relation of both node contexts and graph connectivity. $\\alpha$ is a hyper-parameter to trade-off between the leading role\n%\\he{What do you mean by `leading efforts'?}\nof graph connectivity and node contexts. When $\\alpha = 0$, $\\bv_t^\\ast$ turns into the reward function in contextual bandits \\citep{zhou2020neural,ban2022eenet}; when $\\alpha = 1$, $\\bv_t^\\ast$ is the optimal solution solely for graph connectivity. Here, we assume $\\alpha$ is a prior knowledge.\nFinally, the pseudo-regret is defined as \n\\begin{equation}\n\\mathbf{R}_T  = \\sum_{t=1}^T \\left ( \\bv_t^\\ast[i^\\ast]   - \\bv_t^\\ast[\\hi] \\right).\n\\end{equation}\nwhere $i^\\ast = \\arg \\max_{v_{t,i} \\in \\calv_t} \\bv_t^\\ast[i]$ and $\\hi$ is the index of the selected node. \nThe regret analysis is associated with the Neural Tangent Kernel (NTK) matrix as follows: \n\n\\begin{definition} [NTK \\cite{ntk2018neural, wang2021neural}] Let $\\mathcal{N}$ denote the normal distribution.\nGiven all data instances $\\{\\bx_t\\}_{t=1}^{Tk}$, for $i, j \\in [Tk]$,  define \n\\[\n\\begin{aligned}\n&\\mathbf{H}_{i,j}^0 = \\Sigma^{0}_{i,j} =  \\langle \\bx_i, \\bx_j\\rangle,   \\ \\ \n\\mathbf{A}^{l}_{i,j} =\n\\begin{pmatrix}\n\\Sigma^{l}_{i,i} & \\Sigma^{l}_{i,j} \\\\\n\\Sigma^{l}_{j,i} &  \\Sigma^{l}_{j,j} \n\\end{pmatrix} \\\\\n&   \\Sigma^{l}_{i,j} = 2 \\mathbb{E}_{a, b \\sim  \\mathcal{N}(\\mathbf{0}, \\mathbf{A}_{i,j}^{l-1})}[ \\sigma(a) \\sigma(b)], \\\\ & \\mathbf{H}_{i,j}^l = 2 \\mathbf{H}_{i,j}^{l-1} \\mathbb{E}_{a, b \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{A}_{i,j}^{l-1})}[ \\sigma'(a) \\sigma'(b)]  + \\Sigma^{l}_{i,j}.\n\\end{aligned}\n\\]\nThen, the NTK matrix is defined as $ \\mathbf{H} =  (\\mathbf{H}^L + \\Sigma^{L})/2$.\n\\end{definition}\n\n\n\\begin{assumption} \\label{assum:ntk}\nThere exists $\\lambda_0 > 0$, such that $\\bbh \\succeq \\lambda_0 \\mathbf{I}$.\n\\end{assumption}\n\nThe assumption \\ref{assum:ntk} is generally made in the literature of neural bandits \\citep{zhou2020neural,zhang2020neural,dai2022federated, jia2021learning, ban2022eenet, ban2021multi, xu2020neural} to ensure the existence of a solution for NTK regression. \n\n\nAs the standard setting in contextual bandits, all node contexts are normalized to the unit length.\nGiven $\\bx_{t,i} \\in \\bbr^d$ with $\\|\\bx_{t,i}\\|_2 = 1$, $t \\in [T], i \\in [k]$,  without loss of generality, we define a fully-connected network with depth $L \\geq 2$ and width $m$:\n\\begin{equation} \\label{eq:structure}\nf(\\bx_{t,i}; \\theta) = \\bw_L \\sigma ( \\bw_{L-1}  \\sigma (\\bw_{L-2} \\dots  \\sigma(\\bw_1 \\bx_{t,i}) ))\n\\end{equation}\nwhere $\\sigma$ is the ReLU activation function,  $\\bw_1 \\in \\bbr^{m \\times d}$, $ \\bw_l \\in \\bbr^{m \\times m}$, for $2 \\leq l \\leq L-1$, $\\bw^L \\in \\bbr^{1 \\times m}$, and \n$\n\\theta = [ \\text{vec}(\\bw_1)^\\top,  \\text{vec}(\\bw_2)^\\top, \\dots, \\text{vec}(\\bw_L )^\\top ]^\\top \\in \\bbr^{p}.\n$\nNote that our analysis can also be readily generalized to other neural architectures such as CNNs and ResNet \\cite{allen2019convergence, du2019gradient}.\nWe employ the following initialization \\citep{cao2019generalization} for $\\theta$: For $l \\in [L-1]$, each entry of $\\bw_l$ is drawn from the normal distribution $\\caln(0, 2/m)$; each entry of $\\bw_L$ is drawn from the normal distribution $\\caln(0, 1/m)$. The network $f_1$ and $f_2$ follows the structure of $f$. Define $\\by = [y(\\bx_{t,i}): t \\in [T], i \\in [k]].$\nFinally, we provide the performance guarantee as stated in the following Theorem.\n\n\\begin{theorem} \\label{theo:main}\nGiven the number of rounds $T$, for any $\\alpha, \\delta \\in (0, 1)$, suppose $m \\geq \\widetilde{\\Omega} ( \\text{poly}(T, L) \\cdot k\\log (1/\\delta))$, $ \\eta_1 = \\eta_2  = \\frac{T^3}{\\sqrt{m}}$ and set $\\tilde{r}_{t,i} = r_{t,i}, t\\in [T], i \\in [k]$.\nThen, with probability at least $1 - \\delta$ over the initialization,  Algorithm \\ref{alg:explore} achieves the following regret upper bound:\n\\begin{equation}\n    \\mathbf{R}_T \\leq  \\widetilde{\\calo}(\\sqrt{\\tilde{d} kT }) \\cdot \\sqrt{\\max(\\tilde{d}, S^2)}\n\\end{equation}\nwhere $\\hd = \\frac{\\log \\det(\\mathbf{I} + \\mathbf{H} )}{\\log (1 + Tk)}$ and $S = \\sqrt{\\by^\\top \\mathbf{H}^{-1} \\by}$.\n\\end{theorem}\n\nTheorem \\ref{theo:main} provides a regret upper bound for \\sysn with the complexity of $\\widetilde{\\calo}(\\hd \\sqrt{kT})$ (see proofs in Appendix \\ref{sec:proof}). Instead, the graph-based methods (e.g., \\citep{chamberlain2022graph,wang2023neural}) lack an upper bound in terms of their performance.\n%and the analysis of the bandit-based approach (e.g., \\cite{zhou2020neural, zhang2020neural}) cannot directly apply due to the different reward definitions.\nTheorem \\ref{theo:main} provides insightful results in terms of \\sysn's performance. First, \\sysn's regret can grow sub-linearly with respective to $T$. Second, \\sysn's performance is affected by the number of nodes $k$. This indicates the larger the graph is, the more difficult the link prediction problem is. Third, $\\hd$ and $S$ in the regret upper bound reflect the complexity of the required neural function class to realize the underlying reward function $\\bv_t^\\ast$, i.e., the difficulty of learning $\\bv_t^\\ast$.\n$\\hd$ is the effective dimension, which measures the actual underlying dimension in the RKHS space spanned by NTK. $S$ is to provide an upper bound on the optimal parameters in the context of NTK regression.\n%Notice that if $y$\\he{What's $y$?} belongs to the RKHS $\\calh$ induced by NTK with bounded RKHS norm $\\|y\\|_\\calh$, we have $S\\leq \\|y\\|_\\calh$.\nBoth $\\hd$ and $S$ are two complexity terms that commonly exist in the literature of neural contextual bandits\\citep{zhou2020neural,zhang2020neural}. \nIn the general case when $ 1 > \\alpha > 0$, learning $\\bv_t^\\ast$ proportionally turns into a bandit optimization problem and the upper bound provided in Theorem \\ref{theo:main} matches the SOTA results in neural bandits~\\citep{zhou2020neural,zhang2020neural}. In fact, the regret upper bound is closely related to the graph structure of $G_t$.\nIn the special case when $\\alpha = 1$, learning $\\bv_t^\\ast$ turns into a simple convex optimization problem (Eq. \\eqref{eq:pagerankvector}) and \\sysn can really find the optimal solution, which leads to zero regrets. When $\\alpha = 0$, the problem turns into a complete bandit optimization problem with the same regret upper bound as Theorem \\ref{theo:main}.\n%However, $1 > \\alpha > 0$ in most cases, because both the node contexts and graph structure play important roles in reward mappings.\n\n\n"
            },
            "section 6": {
                "name": "Experiments",
                "content": "\n\n\nIn this section, we begin by conducting a comprehensive evaluation of our proposed method, PRB, compared with both bandit-based and graph-based baselines across online and offline link prediction settings. Then, we analyze the computational costs associated with each experiment and present additional ablation studies related to \\sysn.\nIn the implementation of \\sysn, we adapt the efficient PageRank algorithm \\cite{li2023everything} to solve Eq. \\eqref{eq:pagerankvector}.\n\n\n\n% \\begin{itemize}[leftmargin=10pt]\n%     \\item How is \\sysn's effectiveness in online link prediction compared with Bandit-based and Graph-based baselines?\n\n%     \\item How is \\sysn's effectiveness in online node classification compared with Bandit-based and Graph-based baselines?\n%     \\item How is \\sysn's  computational cost compared to bandit-based baselines?\n% \\end{itemize}\n%\\subsection{Experiment Settings}\n\n    % PPB - 10\\% represents giving the algorithm 10\\% of graph edges for each dataset as the prior knowledge input. i.e.  $G_0 = (U+ U' \\  or \\ U + I, E = 10\\% \\  E_{origin}$ where $E_{origin}$ is the total edges in the original dataset. \n\n% Graph-based methods:\n\n% \\begin{enumerate}\n%     \\item \\textbf{PPR}. The classic Pagerank algorithm with applications on link prediction.\n%     \\item \\textbf{EvePPR}. \\citep{li2023everything} formulates a personalized PageRank tracking method, which is able to track the exact solution at each timestamp in a fully dynamic setting. \n%     \\item \\textbf{SEAL}: \\citep{zhang2018link} leverage the graph neural network to conduct the link prediction.\n%     \\item \\textbf{NCNC}. \\citep{wang2024neural} makes use of the line graphs in graph theory for link prediction.\n% \\end{enumerate}\n\n% \\iffalse\n% \\dq{NCNC, ICLR 2024. \\url{https://openreview.net/pdf?id=sNFLN3itAd}. First, it is the newest paper. Second, it has outperformance in Bechmark~\\url{https://arxiv.org/pdf/2306.10453.pdf}. Third, it is from a trustworthy team with available code.}\n% \\fi\n% \\iffalse\n% \\dq{Link Prediction Baselines\n% \\begin{itemize}\n%     \\item Classic Graph Theory: Personalized PageRank (PPR)\n%     \\item New Classic Graph Theory: EvePPR\n%     \\item Classic Neural Method: SEAL (\\url{https://arxiv.org/pdf/1802.09691.pdf})\n%     \\item New Neural Method: TBD\n% \\end{itemize}\n% }\n% \\fi\n% \\iffalse\n% \\begin{figure}[htp]\n%     \\centering\n%     \\includegraphics[width= 0.45 \\columnwidth]{kdd2024/sources/Images/edge_prediction/facebook_all.png}\\hfill \n%     \\includegraphics[width= 0.45 \\columnwidth]{kdd2024/sources/Images/edge_prediction/grqc.png}\\hfill \n%     \\caption{Regret comparison on Movielens and Amazon Fashion (mean of 10 runs with standard deviation in shadow, detailed in Table \\ref{tab:cell-selection}.}\n%     \\label{fig:galaxy}\n% \\end{figure}\n% \\fi\n% \\para{Metrics}Two metrics: $R_\\mathbf{v}$ and $R_r$\n\n\\vspace{-0.5em}\n",
                "subsection 6.1": {
                    "name": "Online Link Prediction",
                    "content": " \\label{sec: online_link_prediction}\n\\vspace{-0.5em}\n\n\n\n\n% \\begin{table*}[!t]\n%   \\centering\n%   \\caption{Cumulative regret of all methods on all datasets.}\n%   \\vspace{-0.3em}\n%     % Table generated by Excel2LaTeX from sheet 'Sheet3'\n%     \\scalebox{0.70}{\n%     \\begin{tabular}{lcccccccc}\n%     \\toprule\n%     \\multirow{2}[4]{*}{Methods} &MovieLens & AmazonFashion& Facebook & GrQc & Pubmed & Citeseer & Cora \\\\\n%     \\cmidrule{2-8} & Mean $\\pm$ Std & Mean $\\pm$ Std & Mean $\\pm$ Std & Mean $\\pm$ Std & Mean $\\pm$ Std & Mean $\\pm$ Std & Mean $\\pm$ Std\\\\\n    \n%      \\midrule      \n%       PPR & & & & & & & \\\\\n%     EvePPR           & 9040 $\\pm$ 17.2 & 4477 $\\pm$ 14.4 & 9014 $\\pm$ 17.9 & 9125 $\\pm$ 17.9 & 8983 $\\pm$ 16.8  & 8976 $\\pm$ 21.9  & 9233 $\\pm$ 15.2\\\\\n%     SEAL & & & & & & & \\\\\n%     NCNC & & & & & & & \\\\\n%     \\midrule\n%     EE-Net           & \\cellcolor[rgb]{ .776,  .937,  .808}1638 $\\pm$ 15.3 & \\cellcolor[rgb]{ .776,  .937,  .808} 1698 $\\pm$ 19.3  & 2274 $\\pm$ 27.1 & 3419 $\\pm$ 16.5 & 1659 $\\pm$ 11.3 & 2299 $\\pm$ 33.4  & 1990 $\\pm$ 13.8\\\\  \n%     NeuGreedy   & 1955 $\\pm$ 17.3 & 1952 $\\pm$ 27.4 & 2601 $\\pm$ 14.2 & 3629 $\\pm$ 18.2 & 1693 $\\pm$ 13.5 & \\jiaru{add later} & 2826 $\\pm$ 21.4\\\\\n%     NeuralUCB        & 1737 $\\pm$ 16.8 & 1913 $\\pm$ 18.6 & 2190 $\\pm$ 16.3 & 3719 $\\pm$ 16.4 & 1672 $\\pm$ 14.3 & 3101 $\\pm$ 22.0  & 2713 $\\pm$ 21.7\\\\\n%     NeuralTS         & 1683 $\\pm$ 14.7 & 2055 $\\pm$ 21.9 & 2251 $\\pm$ 19.5 & 3814 $\\pm$ 23.3 & 1647 $\\pm$ 9.3 & 3419 $\\pm$ 39.5  & 1998 $\\pm$ 15.6\\\\\n%     \\midrule\n%     PPB1             & 1892 $\\pm$ 15.1 & 1741 $\\pm$ 24.6 & \\cellcolor[rgb]{ .776,  .937,  .808}1994 $\\pm$ 23.6 & \\cellcolor[rgb]{ .776,  .937,  .808}3332 $\\pm$ 15.9 & 1634 $\\pm$ 12.3  & 2194 $\\pm$ 23.3  &1932 $\\pm$ 24.1 \\\\\n%     PPB2             & \\cellcolor[rgb]{ .776,  .937,  .808}1555 $\\pm$ 21.7 & \\cellcolor[rgb]{ .776,  .937,  .808}1617 $\\pm$ 18.4 & \\cellcolor[rgb]{ .776,  .937,  .808}1929 $\\pm$ 17.0 & \\cellcolor[rgb]{ .776,  .937,  .808}3236 $\\pm$ 18.5 & 1577 $\\pm$ 9.7  & 2168 $\\pm$ 35.7 &1874 $\\pm$ 25.6\\\\\n%     PPB2 (10\\%-G)        & \\cellcolor[rgb]{ .776,  .937,  .808}\\textbf{1521 $\\pm$ 17.6}  & \\cellcolor[rgb]{ .776,  .937,  .808}\\textbf{1565 $\\pm$ 23.5} & \\cellcolor[rgb]{ .776,  .937,  .808}\\textbf{1858 $\\pm$ 15.7} & \\cellcolor[rgb]{ .776,  .937,  .808}\\textbf{3085 $\\pm$ 14.3} & - & - & -\\\\\n%     PPB2 (Full-G)  & - & - & - & - & 1630 $\\pm$ 11.5  & 2158 $\\pm$ 33.1  & 1804 $\\pm$ 23.5\\\\\n\n%     \\bottomrule\n%     \\end{tabular}%\n%  }\n%   \\label{tab:cell-selection}%\n% \\end{table*}\n\n\n\n\n% PRB             & 1555 $\\pm$ 21.7 & 1455 $\\pm$ 18.4 & 1929 $\\pm$ 17.0 & 3236 $\\pm$ 18.5\\\\% \\begin{figure}[htp]\n% \\centering\n%     \\includegraphics[width=0.35\\columnwidth]{sources/Images/link_prediction/MovieLens.png}\n%     \\centering\n%     \\includegraphics[width=0.35\\columnwidth]{sources/Images/link_prediction/AmazonFashion.png}\n    \n%     % \\vspace{2mm} % Adds vertical space between the rows of images\n%     \\includegraphics[width=0.35\\columnwidth]{sources/Images/link_prediction/Facebook.png}\n%     \\includegraphics[width=0.35\\columnwidth]{sources/Images/link_prediction/GrQc.png}\n    \n%     \\caption{Regret comparison of bandit-based methods on online link prediction datasets (average of 10 runs with standard deviation in shadow, detailed in Table \\ref{tab:bandit-based res}.}\n%     \\label{fig:link_prediction}\n% \\end{figure}\n\n\n\n\nIn this sub-section, we evaluate \\sysn on the setting of online link prediction and node classification as described in Sec. \\ref{sec:problem}, compared with bandit-based baselines. \n\n\n\\textbf{Datasets and Setups.} \nWe use three categories of real-world datasets to compare \\sysn with bandit-based baselines. The details and experiment settings are as follows. \n%below:\\he{Mention the specific table.} \n%\\jiaru{TODO: put detailed dataset statistics in appendix}\n\n(1) Recommendation datasets: Movielens~\\citep{harper2015movielens} and Amazon Fashion ~\\citep{ni2019justifying} (Bipartite Graph).\nGiven the user set $U$ and item set $I$,\nlet $G_0$ be the graph with no edges, $G_0 = (V =U+I, E_0 = \\emptyset)$.\nIn round $t \\in [T]$, we randomly select a user $v_t \\in U$, and then randomly pick 100 items (arms) from $I$, including $v_t$'s 10  purchased items, forming $\\calv_t$. \n\\sysn runs based on $G_{t-1}$ and selects an arm (node) $v_{t, \\hi} \\in \\calv_t$.\nIf the selected arm $v_{t, \\hi}$ is the purchased item by $u_t$, the regret is $0$ (or reward is $1$) and we add the edge $[v_t, v_{t,\\hi}]$ to $G_{t-1}$, to form the new graph $G_{t}$; otherwise, the regret is $1$ (or reward is $0$) and $G_t = G_{t-1}$.\n\n(2) Social network datasets: Facebook \\citep{leskovec2012learning} and GR-QC \\citep{leskovec2007graph}. \nGiven the user set $V$, we have $G_0 = (V, E_0 = \\emptyset)$.\nIn a round $t \\in [T]$,  we randomly select a source node $v_t$ that can be thought of as the serving user. Then, we randomly choose 100 nodes, including  $v_t$'s 10 connected nodes but their edges are removed, which form the arm pool $\\calv_t$ associated with the context set $\\calx_t$. \nThen, \\sysn will select one arm $v_{t,\\hi} \\in \\calv_t$.\nIf $v_t$ and $v_{t, \\hi}$ are connected in the original graph, the regret is $0$ and add the edge $[v_t, v_{t,\\hi}]$ to $G_{t-1}$; otherwise, the regret is $1$ and $G_t = G_{t-1}$.\n\n(3) Node classification datasets: Cora, Citeseer, and Pubmed from the Planetoid citation networks \\citep{yang2016revisiting}. Recall the problem setting described in Sec. \\ref{sec:algorithm}. \nConsider a $k$-class node classification problem. \nGiven a graph $G(V, E_0 =\\emptyset)$, we randomly select a node $v_t \\in V$ to predict its belonging class, in a round $t \\in [T]$. Then, \\sysn select one super node $\\tilde{v}_{i_t}$. \nIf  $v_t$ belongs to class $i_t$,  the regret is $0$ and add $[v_t, \\tilde{v}_{i_t}]$ to $G_{t-1}$. Otherwise, the regret is $1$ and $G_t = G_{t-1}$.\n\n\\textbf{Baselines.} For bandit-based methods, we apply Neural Greedy \\citep{ban2022eenet} that leverages the greedy exploration strategy on the exploitation network, NeuralUCB \\citep{zhou2020neural} that uses the exploitation network to learn the reward function along with an UCB-based exploration strategy, NeuralTS \\citep{zhang2020neural} that adopts the exploitation network to learn the reward function along with the Thompson Sampling exploration strategy, and EE-net \\citep{ban2022eenet} that utilizes the exploitation-exploration network to learn the reward function.\n%EvePPR is an efficient variant of PageRank \\citep{}\nFollowing \\cite{zhou2020neural, ban2022eenet}, for all methods, we train each network every 50 rounds for the first 2000 rounds and then every 100 rounds for the remaining rounds. See Appendix \\ref{appendix: experimental_setups} for additional experimental setups. \n\n%\\jiaru{TODO: discuss later}\n\n\\textbf{Online Link Prediction}. \nWe use Figure \\ref{fig:link_prediction} to depict the regret trajectories over 10,000 rounds, and Table \\ref{tab:bandit-based res} to detail the cumulative regret after 10,000 rounds for all methods, where the lower is better. Based on the regret comparison, \\sysn consistently outperforms all other baselines across all datasets. For example, the cumulative regret at 10,000 rounds for \\sysn on MovieLens is considerably lower than the best-performing baseline, EE-Net. Similarly, in the AmazonFashion dataset, PRB achieved the lowest regret, surpassing the strongest baseline EE-Net over 14\\%. This trend is consistent across the Facebook and GrQc datasets, where PRB maintains its lead with the lowest regrets respectively. The consistency in PRB's performance across various datasets suggests the importance of utilizing the graph structure formed by previous link predictions.\n\n% \\begin{table*}[!t]\n%   \\centering\n%   \\caption{Cumulative regret of bandit-based methods on Node Classification.}\n%   \\vspace{-0.3em}\n%     % Table generated by Excel2LaTeX from sheet 'Sheet3'\n%     \\scalebox{0.70}{\n%     \\begin{tabular}{lccc}\n%     \\toprule\n%     \\multirow{2}[4]{*}{Methods} & Pubmed & Citeseer & Cora \\\\\n%     \\cmidrule{2-4} & Mean $\\pm$ Std & Mean $\\pm$ Std & Mean $\\pm$ Std\\\\\n    \n%      \\midrule      \n%     % PPR & & & & & & & \\\\\n%     EvePPR  & 2675 $\\pm$ 16.8  & 6364 $\\pm$ 21.9  & 4786 $\\pm$ 15.2\\\\\n%     % SEAL & & & & & & & \\\\\n%     % NCNC & & & & & & & \\\\\n%     \\midrule\n%     EE-Net   & 1659 $\\pm$ 11.3 & 2299 $\\pm$ 33.4  & 1990 $\\pm$ 13.8\\\\  \n%     NeuGreedy  & 1693 $\\pm$ 13.5 & 2543 $\\pm$ 24.6  & 2826 $\\pm$ 21.4\\\\\n%     NeuralUCB & 1672 $\\pm$ 14.3 & 3101 $\\pm$ 22.0  & 2713 $\\pm$ 21.7\\\\\n%     NeuralTS  & 1647 $\\pm$ 11.3 & 3419 $\\pm$ 39.5  & 1998 $\\pm$ 15.6\\\\\n%     \\midrule\n%     PRB-Greedy & 1634 $\\pm$ 12.3  & 2194 $\\pm$ 23.3  &1932 $\\pm$ 24.1 \\\\\n%     PRB & \\textbf{1577 $\\pm$ 10.7}  & 2168 $\\pm$ 35.7 &1874 $\\pm$ 25.6\\\\\n%     PRB-Prior (Full-G) & 1630 $\\pm$ 11.5  & \\textbf{2158 $\\pm$ 33.1}  & \\textbf{1804 $\\pm$ 23.5}\\\\\n\n%     \\bottomrule\n%     \\end{tabular}%\n%  }\n%   \\label{tab:node classification res}%\n% \\end{table*}\n\n% \\begin{wraptable}{r}{7.5cm}\n% \\caption{Cumulative regret of bandit-based methods on Node Classification.\\jiaru{TODO: for all tables, remive PRB-Greedy and PRB-Pior and add them to additional tables for ablation studies.}}\n% \\label{tab:node classification res}\n% \\scalebox{.75}{\n% \\begin{tabular}{lccc}\\\\\\toprule  \n% \\multirow{2}[4]{*}{Methods} & Pubmed & Citeseer & Cora \\\\\n% \\cmidrule{2-4} & Mean $\\pm$ Std & Mean $\\pm$ Std & Mean $\\pm$ Std\\\\\n% \\midrule      \n% EvePPR  & 2675 $\\pm$ 16.8  & 6364 $\\pm$ 21.9  & 4786 $\\pm$ 15.2\\\\\n% \\midrule\n% EE-Net   & 1659 $\\pm$ 11.3 & 2299 $\\pm$ 33.4  & 1990 $\\pm$ 13.8\\\\  \n% NeuGreedy  & 1693 $\\pm$ 13.5 & 2543 $\\pm$ 24.6  & 2826 $\\pm$ 21.4\\\\\n% NeuralUCB & 1672 $\\pm$ 14.3 & 3101 $\\pm$ 22.0  & 2713 $\\pm$ 21.7\\\\\n% NeuralTS  & 1647 $\\pm$ 11.3 & 3419 $\\pm$ 39.5  & 1998 $\\pm$ 15.6\\\\\n% \\midrule\n% PRB-Greedy & 1634 $\\pm$ 12.3  & 2194 $\\pm$ 23.3  &1932 $\\pm$ 24.1 \\\\\n% PRB & \\textbf{1577 $\\pm$ 10.7}  & 2168 $\\pm$ 35.7 &1874 $\\pm$ 25.6\\\\\n% PRB-Prior (Full-G) & 1630 $\\pm$ 11.5  & \\textbf{2158 $\\pm$ 33.1}  & \\textbf{1804 $\\pm$ 23.5}\\\\\n% \\bottomrule\n% \\end{tabular}\n% }\n% \\end{wraptable} \n\n\n\\iffalse\n\n\\fi\n\n\n\\textbf{Online Node classification}. Figure \\ref{fig:node_classification} and Table \\ref{tab:node classification res} show the regret comparison on online node classification. \\sysn consistently demonstrates the lowest cumulative regret by outperforming other bandit methods at round 10,000, respectively. Overall, \\sysn decreases regrets by 3.0\\%, 1.2\\%, and 3.5\\% compared to one of the best baselines, NeuralTS. This experiment demonstrates that \\sysn is versatile enough for applications beyond online link prediction, extending to other real-world tasks such as online node classification. This highlights \\sysn's advantage of fusing contextual bandits with PageRank for collaborative exploitation and exploration.\n\n\n% \\para{Link Prediction with Prior knowledge}\n\n% \\para{Experiment Results}. \n\n"
                },
                "subsection 6.2": {
                    "name": "Offline Link Prediction",
                    "content": "\n\nIn this subsection, we evaluate \\sysn in the setting of offline link prediction compared with graph-based baselines, where training and testing datasets are provided, following the same evaluation process of \\cite{chamberlain2022graph, wang2023neural}. Here, we train \\sysn on the training dataset using the same sequential optimization method Sec. \\ref{sec: online_link_prediction}. Then, we run the trained \\sysn on the testing dataset. Notice that \\sysn never sees the test data in the training process as other baselines.\n\n\\textbf{Datasets}. In this study, we use real-world link-prediction datasets to compare \\sysn with graph-based baselines. Specifically, we apply Cora, Citeseer, and Pubmed from Planetoid\ncitation networks \\citep{yang2016revisiting}; ogbl-collab, ogbl-ppa, and ogbl-ddi from Open Graph Benchmark \\citep{hu2020open}. (See dataset statistics in Appendix \\ref{apendix:dataset_statistics}.)\n\n\\textbf{Setting:} We strictly follow the experimental setup in \\citep{chamberlain2022graph} and use the Hits@k metric for evaluation. Please also refer to \\ref{appendix: experimental_setups} for additional setups.\n\n\\textbf{Baselines}. For graph-based methods, we choose traditional link-prediction heuristics including CN~\\citep{barabasi1999emergence}, RA~\\citep{zhou2009predicting}, AA~\\citep{adamic2003friends} and common GNNs including GCN~\\citep{kipf2016semi} and SAGE~\\citep{hamilton2017inductive}. Then, we employ SF-then-MPNN models, including SEAL \\citep{zhang2018link} and NBFNet \\citep{zhu2021neural}, as well as SF-and-MPNN models like Neo-GNN \\citep{yun2021neo} and BUDDY\\citep{chamberlain2022graph}. Additionally, we also select the MPNN-then-SF model NCN~\\citep{wang2023neural} and NCNC~\\citep{wang2023neural}. The results of the baselines are sourced from Table 2 of \\cite{wang2023neural}.\n\n\n\n\n\n\n\n\n\n\n\\textbf{Comparison with Graph-based Baselines.}\nWe present the experimental results in Table \\ref{tab:graph-based res} for all methods. The results demonstrate that \\sysn consistently outperforms other baselines across all six datasets. Specifically, compared to the most recent method, NCNC, \\sysn achieves a minimum improvement of 0.68\\% on the Collab dataset, a maximum of 4.2\\%, and an average of 2.42\\% across all datasets. \nGiven that all baselines lack the perspective of exploration,\nthe results demonstrate that fusing the exploitation and exploration in contextual bandits along with learning graph connectivity through PageRank does significantly enhance accuracy for link prediction. \n\n\n\n\n\n\n\n"
                },
                "subsection 6.3": {
                    "name": "Ablation and Sensitivity Studies",
                    "content": "\nTable \\ref{tab: ablation_study_PRB_compare} presents the performance of different variants of \\sysn, including \\sysn-greedy that only use the exploitation network and \\sysn-(10\\%-G) that has the warm start with addition 10\\% edges in $G_0$. The results show that exploration is crucial to the final performance and the additional graph knowledge can boost the performance.\n\nDue to the space limit, we move all other experiment sections to Appendix \\ref{appendix: addititional_experiments}, including computational cost analysis on \\sysn and additional ablation \\& sensitivity studies.\n\n\n\n\n\n\n\n\n\n\n\\iffalse\n\n\\textbf{PRB variants.} To extensively evaluate PRB in our experiments, we provide the following variants. \\textbf{PRB} is the direct implementation of Algorithm \\ref{alg:explore}. The initial graph $G_0$ only contains all nodes without any edges. \\textbf{PRB-Greedy} is the greedy version of Algorithm \\ref{alg:explore} by removing the exploration network, as specified in Algorithm \\ref{alg:greedy}. \\textbf{PRB-Prior (10\\%-G)} is Algorithm \\ref{alg:explore} with prior knowledge by revealing 10\\% of training edges on the initial graph. \\textbf{PRB-Prior (Full-G)} is Algorithm \\ref{alg:explore} with prior knowledge by revealing all training edges on the initial graph. We apply PRB-Prior (10\\%-G) and PRB-Prior (Full-G) in our experiments to demonstrate how extra prior knowledge about the graph improves \\sysn's decision-making process. \n\nFigure \\ref{fig:PRB_compare} and Table \\ref{tab: ablation_study_PRB_compare} highlights the regret comparison of three PRB variants: PRB, PRB-Greedy, and PRB-Prior. For both online link prediction and node classification, \\sysn surpasses \\sysn-Greedy by an average of 5.8\\%, highlighting the robustness of the exploration network embedded within \\sysn. Additionally, in online link prediction, the PRB-Prior (10\\%-G) variant consistently outperforms its counterparts across a majority of datasets. This is particularly evident in the MovieLens and AmazonFashion datasets, where it achieves notably low cumulative regrets of 1521 and 1408. Same in online node classification, PRB-Prior (Full-G) demonstrates exceptional performance on two out of three datasets, recording cumulative regrets of 1804 in Cora and 2158 in Citeseer. These results emphasize the benefits of incorporating prior knowledge within \\sysn to enhance predictive accuracy.\n\\fi\n\n\n\n\n\n\n"
                }
            },
            "section 7": {
                "name": "Conclusion",
                "content": "\nThis paper introduces a fusion algorithm for link prediction, which integrates the power of contextual bandits in balancing exploitation and exploration with propagation on graph structure by PageRank. We further provide the theoretical performance analysis for \\sysn, showing the regret of the proposed algorithm can grow sublinearly.\nWe conduct extensive experiments in link prediction to evaluate \\sysn's effectiveness, compared with both bandit-based and graph-based baselines.\n\n\n\n\\ack \n% \\section*{Acknowledgement}\nThis work is supported by the National Science Foundation under Award No. IIS-2117902 and DARPA (HR001121C0165). The views and conclusions are those of the authors and should not be interpreted as representing the official policies of the funding agencies or the government.\n\n\n\n\\bibliographystyle{plain}\n\\bibliography{main}\n\n\n\n\\newpage \n\n\n\\appendix\n\n\\onecolumn \n\n"
            },
            "section 8": {
                "name": "Additional Experiments",
                "content": " \\label{appendix: addititional_experiments}\n\n\n",
                "subsection 8.1": {
                    "name": "Experiment Setups",
                    "content": "\n\\label{appendix: experimental_setups}\n\\textbf{Online Link Prediction Setups}.\nFor all bandit-based methods including PRB, for fair comparison,  the exploitation network $f_1$ is built by a 2-layer fully connected network with 100-width. For the exploration network of EE-Net and PRB, we use a 2-layer fully connected network with 100-width as well. For NeuralUCB and NeuralTS, following the setting of \\citep{zhou2020neural, zhang2020neural}, we use the exploitation network $f_1$ and conduct the grid search for the exploration parameter $\\nu$ over $\\{0.001, 0.01, 0.1, 1\\}$ and for the regularization parameter $\\lambda$ over $\\{0.01, 0.1, 1\\}$. For the neural bandits NeuralUCB/TS, following their setting, as they have expensive computation costs to store and compute the whole gradient matrix, we use a diagonal matrix to make an approximation. For all grid-searched parameters, we choose the best of them for comparison and report the average results of 10 runs for all methods.\nFor all bandit-based methods, we use SGD as the optimizer for the exploitation network $f_1$. \nAdditionally, for EE-Net and PRB, we use the Adam optimizer for the exploration network $f_2$. \nFor all neural networks, we conduct the grid search for learning rate over $\\{0.01, 0.001, 0.0005, 0.0001\\}$.\nFor PRB, we strictly follow the settings in \\citep{li2023everything} to implement the PageRank component. Specifically, we set the parameter $\\alpha = 0.85$ after grid search over $\\{0.1, 0.3, 0.5, 0.85, 0.9\\}$, and the terminated accuracy $\\epsilon = 10^{-6}$.\nFor each dataset, we first shuffle the data and then run each network for 10,000 rounds ($t = 10,000$). We train each network every 50 rounds when $t < 2000$ and every 100 rounds when $2000 < t < 10,000$.\n\n\n\\textbf{Offline Link Prediction Setups}. For the graph-based methods, we strictly follow the experimental and hyperparameters settings in \\citep{wang2023neural,chamberlain2022graph} to reproduce the experimental results. \nOffline link prediction task requires graph links to play dual roles as both supervision labels and message passing links. For all datasets, the message-passing links at training time are equal to the supervision links, while at test and validation time,\ndisjoint sets of links are held out for supervision that are never seen during training. \nAll hyperparameters are tuned using Weights and Biases random search, exploring the search space of hidden dimensions from 64 to 512, dropout from 0 to 1, layers from 1 to 3, weight decay from 0 to 0.001, and learning rates from 0.0001 to 0.01. Hyperparameters yielding the highest validation accuracy are selected, and results are reported on a single-use test set.\nFor PRB, we use setups similar to those in the online setting. We utilize the exploitation network $f_1$ and exploration network $f_2$ both with 500-width. We set the training epoch to 100 and evaluate the model performance on validation and test datasets. We utilize the Adam optimizer for all baseline models. For PRB implementation, We utilize the SGD optimizer for $f_1$ and the Adam optimizer for $f_2$.    \n\n\n"
                },
                "subsection 8.2": {
                    "name": "Computational Cost Analysis",
                    "content": "\n\n We conduct all of our experiments on an Nvidia 3060 GPU with an x64-based processor. \n\n\n\\para{Time and space complexity}.\nLet $n$ be the number of nodes, $t$ be the index of the current round of link prediction, $k$ be the number of target candidate nodes, $d$ be the number of context dimensions, and $p$ be neural network width. \nFor the online setting, let $m_t$ be the number of edges at round $t$.  In the setting of online link prediction, the time complexity of PRB is $O(kdp + m_t k)$, where the first term is the cost of calculating the exploitation-exploration score for each candidate node and the second term is the cost of running PageRank, following~\\citep{li2023everything}. And, the space complexity is $O(n + m_t)$ to store node weights and edges. \nFor the offline setting, let $m$ be the number of edges in the testing dataset. Let $F$ be the number target links to predict.\nThen, the inference time complexity of PRB for $F$ links is $O(ndp) + \\tilde{O}(mF)$. The first term is the cost of calculating the exploitation-exploration score for each node.  The second term is the cost of PageRank \\citep{li2023everything}.\nThe comparison with existing methods is listed in the following table:\n\n\nIn Figure \\ref{fig:EE_RandomWalk}, we analyze the running time of the internal components of \\sysn and \\sysn-Greedy (Algorithm \\ref{alg:greedy}). The comparison of the internal components reveals that the Random Walk phase accounts for 10\\% (\\sysn) and 6.3\\% (\\sysn-Greedy) on average of the total running time across seven datasets. Previous results also demonstrate that \\sysn significantly outperforms EE-Net which solely relies on the Exploitation-Exploration framework, by dedicating a small additional portion of time to the Random Walk component.\n\n\n\nBy recording the total training time of 10,000 rounds, we also compare \\sysn with other bandit-based baselines in Figure \\ref{fig:running_time}. Across all datasets, NeuralTS achieves the minimum average running time at 10.9 minutes, while \\sysn has the maximum at 17.5 minutes. Additionally, given that the Random Walk component takes only a minimal portion of our algorithm's running time, the average running times are relatively close between \\sysn-Greedy (15.4 minutes) and Neural Greedy (14.8 minutes), and between \\sysn (17.5 minutes) and EE-net (16.7 minutes). The comparative analysis reveals that while \\sysn incurs a relatively extended running time, it remains competitive with established baselines and demonstrates a significant enhancement in performance. This observation underscores the efficacy of \\sysn and supports its potential utility in practical applications despite its temporal demands.\n\n\n\n\n\nTable \\ref{tab:inferbandit} reports the inference time (one round in seconds) of bandit-based methods on three datasets for online link prediction. Although PRB takes a slightly longer time, it remains in the same order of magnitude as the other baselines. We adopt the approximated methods from \\citep{li2023everything} for the PageRank component to significantly reduce computation costs while ensuring good empirical performance.\n\n\n\n\nTable \\ref{tab:infergraph} reports the inference time (one epoch of testing in seconds) of graph-based methods on three datasets for offline link prediction. PRB is faster than SEAL and shows competitive inference time as compared to other baselines.\n\n\n\n\n\n\n\n\n\n\n\n\n\n"
                },
                "subsection 8.3": {
                    "name": "Additional Ablation and Sensitivity Studies",
                    "content": "\n\n\n\n\n\n\n\n\\textbf{PRB variants.} To extensively evaluate PRB in our experiments, we provide the following variants. PRB is the direct implementation of Algorithm \\ref{alg:explore}. The initial graph $G_0$ only contains all nodes without any edges. PRB-Greedy is the greedy version of Algorithm \\ref{alg:explore} by removing the exploration network, as specified in Algorithm \\ref{alg:greedy}. PRB-Prior (10\\%-G) is Algorithm \\ref{alg:explore} with prior knowledge by revealing 10\\% of training edges on the initial graph. We apply PRB-Prior in our experiments to demonstrate how extra prior knowledge about the graph improves \\sysn's decision-making process.\n% PRB-Prior (Full-G) is Algorithm \\ref{alg:explore} with prior knowledge by revealing all training edges on the initial graph.  \n\nFigure \\ref{fig:PRB_compare} and Table \\ref{tab: ablation_study_PRB_compare} highlights the regret comparison of three PRB variants: PRB, PRB-Greedy, and PRB-Prior. For both online link prediction and node classification, \\sysn surpasses \\sysn-Greedy by an average of 5.8\\%, highlighting the robustness of the exploration network embedded within \\sysn. Additionally, in online link prediction, the PRB-Prior (10\\%-G) variant consistently outperforms its counterparts across a majority of datasets. This is particularly evident in the MovieLens and AmazonFashion datasets, where it achieves notably low cumulative regrets of 1521 and 1408. Same in online node classification, PRB-Prior (10\\%-G) demonstrates exceptional performance on two out of three datasets, recording cumulative regrets of 1804 in Cora and 2158 in Citeseer. These results emphasize the benefits of incorporating prior knowledge within \\sysn to enhance predictive accuracy.\n\n\\textbf{Effectiveness of Bandits and PageRank.}  In Figure \\ref{fig:PRB_EvePPR_EEnet}, we compare the performance of \\sysn with that of EvePPR \\citep{li2023everything} and EE-Net \\citep{ban2022eenet}, which represent methodologies based on PageRank and contextual bandits respectively. On one hand, \\sysn significantly outperforms EvePPR by integrating the exploitation and exploration strategy, which enhances PageRank's decision-making capabilities. On the other hand, \\sysn surpasses EE-net by leveraging a more comprehensive understanding of the input graph's structure and connectivity through enhanced PageRank. Overall, \\sysn consistently achieves lower regrets compared to both EvePPR and EE-Net, demonstrating the effectiveness of combining the exploitation-exploration with PageRank.\n"
                }
            },
            "section 9": {
                "name": "Limitations",
                "content": " \\label{appendix: limitations}\nIn this paper, we propose the PRB algorithm that integrates the exploitation-exploration of contextual bandits with PageRank. We do not investigate other integration methods, such as combining such exploitation-exploration with other Random Walk algorithms or GNNs. We also evaluate \\sysn on online link prediction and node classification. Several other real-world tasks, such as Subgraph Matching and Node Clustering, remain unexplored. Our future research will extend \\sysn to these and additional related tasks \\cite{zou2024promptintern,sui2023tap4llm} to assess its broader implications.  \n\n"
            },
            "section 10": {
                "name": "Graph Dataset Statistics",
                "content": " \\label{apendix:dataset_statistics}\n\nThe statistics of each dataset are shown in Table \\ref{tab:datasets}.\nRandom splits use 70\\%,10\\%, and 20\\% edges for training, validation, and test set respectively.\n\\newpage\n"
            },
            "section 11": {
                "name": "Variant Algorithms",
                "content": "\n\\begin{algorithm}[!ht]\n\\renewcommand{\\algorithmicrequire}{\\textbf{Input:}}\n\\renewcommand{\\algorithmicensure}{\\textbf{Output:}}\n\\caption{ \\sysn-N (Node Classification)}\\label{alg:explore_node}\n\\begin{algorithmic}[1] \n\\Require $f_1, f_2$,  $T$,  $G_0$,  $\\eta_1, \\eta_2$ (learning rate) \n\\State Initialize $\\theta^1_0, \\theta^2_0$\n\\For{ $t = 1 , 2, \\dots, T$}\n\\State Observe serving node $v_t$, candidate nodes $\\calv_t = \\{\\tilde{v}_1,  \\tilde{v}_2, \\dots, \\tilde{v}_k \\}$, contexts $\\calx_t$  and Graph $G_{t-1}$\n\\For{each $v_{t,i} \\in \\calv_t$ }\n\\State \n$\\bh_t[i] = f_1\\left(x_{t,i}; \\theta^1_{t-1}\\right) + f_2\\left(\\phi\\left(x_{t,i}\\right); \\theta^2_{t-1}\\right)$\n\\EndFor\n\\State Compute $\\rmP_t$ based on $G_{t-1}$\n\\State Solve $\\bv_t = \\alpha \\rmP_t \\bv_t + \\left(1 - \\alpha\\right) \\bh_t$ \n\\State Select $\\hi = \\arg \\max_{v_{t,i} \\in \\calv_t} \\bv_t\\left[i\\right] $\n\\State Observe $r_{t, \\hi}$\n\\If {$r_{t, \\hi}$ == 1}\n\\State Add $[v_t, v_{t, \\hi}]$ to $G_{t-1}$ and set as $G_t$\n\\Else\n\\State $G_t = G_{t-1}$\n\\EndIf\n\\State   $\\btheta_t^1 = \\btheta_{t-1}^1 -  \\eta_1  \\nabla_{\\btheta_{t-1}^1}  \\call \\left( x_{t,\\hi}, r_{t, \\hi};   \\btheta_{t-1}^1 \\right) $ \n\\State   $\\btheta_t^2 = \\btheta_{t-1}^2 -  \\eta_2  \\nabla_{\\btheta_{t-1}^2}  \\call \\left( \\phi(x_{t,\\hi}), r_{t, \\hi} - f_1(x_{t,\\hi}; \\theta^1_{t-1});   \\btheta_{t-1}^2\\right) $\n\\EndFor\n\\end{algorithmic}\n\\end{algorithm}\n\n\\begin{algorithm}[!ht]\n\\renewcommand{\\algorithmicrequire}{\\textbf{Input:}}\n\\renewcommand{\\algorithmicensure}{\\textbf{Output:}}\n\\caption{ PRB-Greedy }\\label{alg:greedy}\n\\begin{algorithmic}[1] \n\\Require $f_1, f_2$,  $T$,  $G_0$,  $\\eta_1, \\eta_2$ (learning rate) \n\\State Initialize $\\theta^1_0, \\theta^2_0$\n\\For{ $t = 1 , 2, \\dots, T$}\n\\State Observe serving node $v_t$, candidate nodes $\\calv_t$, contexts $\\calx_t$  and Graph $G_{t-1}$\n\\For{each $v_{t,i} \\in \\calv_t$ }\n\\State \n$\\bh_t[i] = f_1\\left(x_{t,i}; \\theta^1_{t-1}\\right)$\n\\EndFor\n\\State Compute $\\rmP_t$ based on $G_{t-1}$\n\\State Solve $\\bv_t = \\alpha \\rmP_t \\bv_t + \\left(1 - \\alpha\\right) \\bh_t$ \n\\State Select $\\hi = \\arg \\max_{v_{t,i} \\in \\calv_t} \\bv_t\\left[i\\right] $\n\\State Observe $r_{t, \\hi}$\n\\If {$r_{t, \\hi}$ == 1}\n\\State Add $[v_t, v_{t, \\hi}]$ to $G_{t-1}$ and set as $G_t$\n\\Else\n\\State $G_t = G_{t-1}$\n\\EndIf\n\\State   $\\btheta_t^1 = \\btheta_{t-1}^1 -  \\eta_1  \\nabla_{\\btheta_{t-1}^1}  \\call \\left( x_{t,\\hi}, r_{t, \\hi};   \\btheta_{t-1}^1 \\right) $ \n\\EndFor\n\\end{algorithmic}\n\\end{algorithm}\n\n\\newpage\n\n\n\n"
            },
            "section 12": {
                "name": "theo:main",
                "content": "\n\\label{sec:proof}\n\n\n\n\n\n\n\n\n\n",
                "subsection 12.1": {
                    "name": "Preliminaries",
                    "content": "\n\n\n\n\nFollowing neural function definitions and Lemmas of \\cite{ban2023neural}, given an instance $\\bx$, we define the outputs of hidden layers of the neural network (Eq. (\\ref{eq:structure})):\n\\[\n\\bh_0 = \\bx,  \\bh_l = \\sigma(\\bw_l \\bh_{l-1}), l \\in [L-1].\n\\]\nThen, we define the binary diagonal matrix functioning as ReLU:\n\\[\n\\bD_l = \\text{diag}( \\mathbbm{1}\\{(\\bw_l \\bh_{l-1})_1 \\}, \\dots, \\mathbbm{1}\\{(\\bw_l \\bh_{l-1})_m \\} ), l \\in [L-1].\n\\]\n\nAccordingly, the neural network (Eq. (\\ref{eq:structure})) is represented by \n\\begin{equation}\nf(\\bx; \\theta) = \\bw_L (\\prod_{l=1}^{L-1} \\bD_l \\bw_l) \\bx,\n\\end{equation}\nand\n\\begin{equation}\n\\nabla_{\\bw_l}f  = \n\\begin{cases}\n[\\bh_{l-1}\\bw_L (\\prod_{\\tau=l+1}^{L-1} \\bD_\\tau \\bw_\\tau)]^\\top, l \\in [L-1] \\\\\n\\bh_{L-1}^\\top,   l = L .\n\\end{cases}\n\\end{equation}\n\nHere, given a constant $R > 0$, we define the following function class:\n\\begin{equation}\n    B(\\theta_0, R) = \\{ \\theta \\in \\bbr^p:  \\| \\theta - \\theta_0\\|_2 \\leq R/m^{1/4}\\}.\n\\end{equation}\n\nLet $\\call_t$ represent the squared loss function in round $t$. We use ${x_1, x_2, \\dots, x_{Tk}}$ represent all the context vectors presented in $T$ rounds.\nThen, we define the following instance-dependent complexity term:\n\\begin{equation} \\label{complexityfunction}\n\\Psi(\\btheta_0, R) = \\underset{\\btheta \\in  \\calb(\\btheta_0, R)}{\\inf} \\sum_{t=1}^{Tk} (f_2(\\bx_t; \\btheta) - r_t)^2 \n\\end{equation}\n\nThen, we have the following auxiliary lemmas.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\begin{lemma} \\label{lemma:xi1}\n Suppose $m, \\eta_1, \\eta_2$ satisfy the conditions in Theorem \\ref{theo:main}.  With probability at least $1 -  \\calo(TkL)\\cdot \\exp(-\\Omega(m \\omega^{2/3}L))$ over the random initialization, for all $t \\in [T], i \\in [k] $,  $\\theta$ satisfying $ \\|\\theta - \\theta_0\\|_2 \\leq \\omega$ with $ \\omega \\leq \\calo(L^{-9/2} [\\log m]^{-3})$, it holds uniformly that\n\\[\n\\begin{aligned}\n&(1), | f(\\bx_{t,i}; \\theta)| \\leq  \\calo(1). \\\\\n&(2), \\| \\nabla_{\\theta}    f(\\bx_{t,i}; \\theta) \\|_2 \\leq \\calo(\\sqrt{L}). \\\\\n&(3), \\|  \\nabla_{\\theta} \\call_t(\\theta_t)  \\|_2 \\leq  \\calo(\\sqrt{L})\n\\end{aligned}\n\\]\n\\end{lemma}\n\n\n\\iffalse\n\n\\begin{proof}\n(1) is a simply application of Cauchy\u2013Schwarz inequality.\n\\[\n\\begin{aligned}\n| f(\\bx_t; \\theta)| & = |  \\bw_L (\\prod_{l=1}^{L-1} \\bD_l \\bw_l) \\bx_{t,i}  | \\\\\n& \\leq \\underbrace{\\|  \\bw_L (\\prod_{l=1}^{L-1} \\bD_l \\bw_l)  \\|_2}_{I_1} \\|\\bx_{t,i} \\|_2 \\\\\n&  \\leq \\calo (1)\n\\end{aligned}\n\\]\nwhere $I_1$ is based on the Lemma B.2 \\cite{cao2019generalization}: $I_1 \\leq \\calo(1)$, and $\\|\\bx_{t,i}\\|_2 = 1$.\nFor (2), it holds uniformly that\n\\[\n \\| \\nabla_{\\theta}    f(\\bx_{t,i}; \\theta) \\|_2  = \\| \\text{vec}( \\nabla_{\\bw_1}f )^\\top,  \\dots, \\text{vec}( \\nabla_{\\bw_L}f )^\\top\\|_2 \n \\leq \\calo(\\sqrt{L})\n\\]\nwhere $\\| \\nabla_{\\bw_1}f\\|_F \\leq \\calo(1) $ is an application of Lemma B.3 \\cite{cao2019generalization} by removing $\\sqrt{m}$.\n\nFor (3), we have  $\\| \\nabla_{\\theta} \\call_t(\\theta_t)\\|_2 \\leq | \\call_t' | \\cdot \\|   \\nabla_\\theta  f(\\bx_{t,i}; \\theta) \\|_2 \\leq \\calo(\\sqrt{L})$.\n\\end{proof}\n\n\\fi\n\n\n\\begin{lemma} \\label{lemma:functionntkbound}\nSuppose $m, \\eta_1, \\eta_2$ satisfy the conditions in Theorem \\ref{theo:main}.  With probability at least $1 -  \\calo(TkL)\\cdot \\exp(-\\Omega(m \\omega^{2/3}L))$, for all $t \\in [T], i \\in [k] $, $\\theta, \\theta'$ (or $\\Theta, \\Theta'$ ) satisfying $ \\|\\theta - \\theta_0\\|_2,  \\|\\theta' - \\theta_0\\|_2 \\leq \\omega$ with $ \\omega \\leq \\calo(L^{-9/2} [\\log m]^{-3})$, it holds uniformly that\n\\[\n| f(\\bx; \\theta) - f(\\bx; \\theta') -  \\langle  \\triangledown_{\\theta'} f(\\bx; \\theta'), \\theta - \\theta'    \\rangle    | \\leq \\mathcal{O} (w^{1/3}L^2 \\sqrt{ \\log m}) \\|\\theta - \\theta'\\|_2.\n\\]\n\\end{lemma}\n\n\\iffalse \n\n\\begin{proof}\nBased on Lemma 4.1 \\cite{cao2019generalization}, it holds uniformly that\n\\[\n|\\sqrt{m} f(\\bx; \\theta) - \\sqrt{m} f(\\bx; \\theta') -  \\langle \\sqrt{m}  \\triangledown_{\\theta'}f(\\bx; \\theta'), \\theta - \\theta'    \\rangle    | \\leq \\mathcal{O} (w^{1/3}L^2 \\sqrt{m \\log(m)}) \\|\\theta - \\theta'\\|_2,\n\\]\nwhere $\\sqrt{m}$ comes from the different scaling of neural network structure. Removing $\\sqrt{m}$ completes the proof.\n\\end{proof}\n\\fi\n\n\n\\begin{lemma}  \\label{lemma:differenceee}\nSuppose $m, \\eta_1, \\eta_2$ satisfy the conditions in Theorem \\ref{theo:main}.  With probability at least $1 -  \\calo(TkL)\\cdot \\exp(-\\Omega(m \\omega^{2/3}L))$, for all $t \\in [T], i \\in [k] $,  $\\theta, \\theta'$ satisfying $ \\|\\theta - \\theta_0\\|_2,  \\|\\theta' - \\theta_0\\|_2 \\leq \\omega$ with $ \\omega \\leq \\calo(L^{-9/2} [\\log m]^{-3})$, it holds uniformly that\n\\begin{equation}\n\\begin{aligned}\n (1) \\qquad  & |f(\\bx; \\theta) - f(\\bx; \\theta')|  \\leq &   \\calo(  \\omega \\sqrt{L})  +  \\mathcal{O} (\\omega^{4/3}L^2 \\sqrt{ \\log m})\n \\end{aligned}\n\\end{equation}\n\\end{lemma}\n\n\n\\iffalse\n\\begin{proof}\nBased on Lemma \\ref{lemma:differenceee}, we have\n\\[\n\\begin{aligned}\n & |f(\\bx; \\theta) - f(\\bx; \\theta')|  \\\\\n\\leq  & |    \\langle  \\nabla_{\\theta'}f(\\bx; \\theta'), \\theta - \\theta'    \\rangle    | +  \\mathcal{O} (\\omega^{1/3}L^2 \\sqrt{ \\log m}) \\|\\theta - \\theta'\\|_2 \\\\\n\\leq & \\| \\nabla_{\\theta'}f(\\bx; \\theta') \\|_2 \\cdot \\| \\theta - \\theta' \\|_2 + \\mathcal{O} (\\omega^{1/3}L^2 \\sqrt{ \\log m}) \\|\\theta - \\theta'\\|_2 \\\\\n\\leq  &\\calo(\\sqrt{L})  \\| \\theta - \\theta' \\|_2 +  \\mathcal{O} (\\omega^{1/3}L^2 \\sqrt{ \\log m}) \\|\\theta - \\theta'\\|_2\n\\end{aligned}\n\\]\nThe proof is completed.\n\\end{proof}\n\\fi\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\begin{lemma} [Almost Convexity]  \\label{lemma:convexityofloss} \nLet $\\call_t(\\theta) = (f(\\bx_t; \\theta) - r_t)^2/2 $.  Suppose $m, \\eta_1, \\eta_2$ satisfy the conditions in Theorem \\ref{theo:main}.   With probability at least $1- \\calo(TkL^2)\\exp[-\\Omega(m \\omega^{2/3} L)] $ over randomness of $\\theta_1$, for all $ t \\in [T]$, and $\\theta, \\theta'$\nsatisfying $\\| \\theta - \\theta_0 \\|_2 \\leq \\omega$ and $\\| \\theta' - \\theta_0 \\|_2 \\leq \\omega$ with $\\omega \\leq \\calo(L^{-6} [\\log m]^{-3/2})$, it holds uniformly that\n\\[\n \\call_t(\\theta')  \\geq  \\call_t(\\theta) + \\langle \\nabla_{\\theta}\\call_t(\\theta),      \\theta' -  \\theta     \\rangle  -  \\epsilon.\n\\]\nwhere $\\epsilon =    \\calo(\\omega^{4/3}L^3 \\sqrt{\\log m}))  $\n\n\\end{lemma}\n\n\n\n\\iffalse\n\n\\begin{proof}\nLet $\\call_t'$ be the derivative of $\\call_t$ with respective to $f(\\bx_t; \\theta)$. Then, it holds that $ |  \\call_t' | \\leq \\calo(1)$ based on Lemma \\ref{lemma:xi1}.\nThen, by convexity of $\\call_t$, we have\n\\[\n\\begin{aligned}\n&\\call_t(\\theta') - \\call_t(\\theta)  \\\\\n\\overset{(a)}{\\geq} &  \\call_t'  [  f(\\bx_t; \\theta')  -  f(\\bx_t; \\theta) ]  \\\\\n\\overset{(b)}{\\geq}  & \\call_t' \\langle \\nabla f(\\bx_t; \\theta) ,  \\theta' -  \\theta\\rangle  \\\\\n & - | \\call_t'| \\cdot  | f(\\bx_t; \\theta')  -  f(\\bx_t; \\theta) -   \\langle \\nabla f(\\bx_t; \\theta) ,  \\theta' -  \\theta\\rangle  |         \\\\\n\\geq & \\langle \\nabla_{\\theta}\\call_t(\\theta ), \\theta' -  \\theta \\rangle   -  | \\call_t'| \\cdot |  f(\\bx_t; \\theta')  -  f(\\bx_t; \\theta) -   \\langle \\nabla f(\\bx_t; \\theta) ,  \\theta' -  \\theta\\rangle  |  \\\\\n \\overset{(c)}{\\geq} &  \\langle \\nabla_{\\theta'}\\call_t, \\theta' -  \\theta \\rangle  -   \\calo(\\omega^{4/3}L^3 \\sqrt{\\log m}))  \\\\.\n \\geq & \\langle \\nabla_{\\theta'}\\call_t, \\theta' -  \\theta \\rangle - \\epsilon\n\\end{aligned}\n\\]\nwhere $(a)$ is due to the convexity of $\\call_t$, $(b)$ is an application of triangle inequality,  and $(c)$ is the application of Lemma \\ref{lemma:functionntkbound}. \nThe proof is completed.\n\\end{proof}\n\\fi\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\begin{lemma}[User Trajectory Ball] \\label{lemma:usertrajectoryball}\nSuppose $m, \\eta_1, \\eta_2$ satisfy the conditions in Theorem \\ref{theo:main}. \nWith probability at least $1- \\calo(TkL^2)\\exp[-\\Omega(m \\omega^{2/3} L)] $ over randomness of $\\theta_0$, for any $R > 0$, it holds uniformly that\n\\[\n\\|\\theta_t - \\theta_0\\|_2 \\leq \\calo(R/m^{1/4}), t \\in [T].\n\\]\n\\end{lemma}\n\n\n\\iffalse\n\n\\begin{proof}\nLet $\\omega \\leq  \\calo(R/m^{1/4})$.\nThe proof follows a simple induction. Obviously, $\\theta_0$ is in $B(\\theta_0, \\omega)$.  Suppose that $\\theta_1, \\theta_2, \\dots, \\theta_T \\in \\mathcal{B}(\\theta_0^2, \\omega)$.\nWe have, for any $t \\in [T]$, \n\\begin{align*}\n\\|\\theta_T -\\theta_0\\|_2 & \\leq \\sum_{t=1}^T \\|\\theta_{t} -  \\theta_{t-1} \\|_2 \\leq \\sum_{t=1}^T \\eta \\|\\nabla \\call_t(\\Theta_t)\\| \\leq  \\sum_{t=1}^T \\eta \\sqrt{L} \\\\\n&  =  \\calo(TR^2 \\sqrt{L} /\\sqrt{m}) \\leq \\calo(R/m^{1/4})\n\\end{align*}\nThe proof is complete.\n\\end{proof}\n\n\\fi\n\n\n\n\n\n\n\n\\begin{lemma} [Instance-dependent Loss Bound] \\label{lemma:instancelossbound}\nLet $\\call_t(\\theta) = (f(\\bx_t; \\theta) - r_t)^2/2$. \n Suppose $m, \\eta_1, \\eta_2$ satisfy the conditions in Theorem \\ref{theo:main}.\nWith probability at least $1- \\calo(TkL^2)\\exp[-\\Omega(m \\omega^{2/3} L)] $ over randomness of $\\theta_1$, given any $R > 0$  it holds that\n\\begin{equation}\n\\sum_t^T \\call_t(\\theta_t)  \\leq  \\sum_t^T  \\call_t(\\theta^\\ast) +  \\calo(1) +  \\frac{TLR^2}{\\sqrt{m}} +  \\calo( \\frac{T R^{4/3} L^2\\sqrt{\\log m}}{m^{1/3}}).\n\\end{equation}\nwhere $\\theta^\\ast =  \\arg \\inf_{\\theta \\in B(\\theta_0, R)}  \\sum_t^T  \\call_t(\\theta)$.\n\\end{lemma}\n\n\n\\iffalse\n\n\n\\begin{proof}\nLet $\\theta' \\in B(\\theta_1, R)$.\nIn round $t$, based on Lemma \\ref{lemma:usertrajectoryball}, \nfor any $t \\in [T]$,  $\\|\\theta_t - \\theta'\\|_2 \\leq \\omega \\leq O(R/m^{1/4})$. Then,  based on \\ref{lemma:convexityofloss}, it holds uniformly\n\n\n\n\n\\begin{align*}\n\\call_t(\\theta_t) - \\call_t(\\theta')  \n\\leq &  \\langle \\nabla \\call_t(\\theta_t),  \\theta_t - \\theta' \\rangle   + \\epsilon ,\\\\ \n\\end{align*}\nwhere $\\epsilon = O(\\omega^{4/3}L^2 \\sqrt{\\log m})$.\n\nTherefore,  for all $t \\in [T], \\theta' \\in B(\\theta_1, R)$,  it holds uniformly\n\\begin{align*}\n    \\call_t(\\theta_t) - \\call_t(\\theta')  \\overset{(a)}{\\leq} &  \\frac{  \\langle  \\theta_t - \\theta_{t+1} , \\theta_t - \\theta'\\rangle }{\\eta}  + \\epsilon ~\\\\\n   \\overset{(b)}{ = }  & \\frac{ \\| \\theta_t - \\theta' \\|_2^2 + \\|\\theta_t - \\theta_{t+1}\\|_2^2 - \\| \\theta_{t+1} - \\theta'\\|_2^2 }{2\\eta}  + \\epsilon ~\\\\\n\\overset{(c)}{\\leq}& \\frac{ \\|\\theta_t  - \\theta'\\|_2^2 - \\|\\theta_{t+1} - \\theta'\\|_2^2  }{2 \\eta}     + O(L\\eta) + \\epsilon\\\\\n\\end{align*}\nwhere $(a)$ is because of the definition of gradient descent, $(b)$ is due to the fact $2 \\langle A, B \\rangle = \\|A \\|^2_F + \\|B\\|_F^2 - \\|A  - B \\|_F^2$, \n$(c)$ is by $ \\|\\theta_t - \\theta_{t+1}\\|^2_2 = \\| \\eta \\nabla_{\\theta} \\call_t(\\theta_t)\\|^2_2  \\leq \\calo(\\eta^2L)$. \n\n\nThen,  for $T$ rounds,  we have\n\\begin{align*}\n   & \\sum_{t=1}^T \\call_t(\\theta_t) -  \\sum_{t=1}^T  \\call_t(\\theta')  \\\\ \n   \\overset{(a)}{\\leq} & \\frac{\\|\\theta_1 - \\theta'\\|_2^2}{2 \\eta} + \\sum_{t =2}^T \\|\\theta_t - \\theta' \\|_2^2 ( \\frac{1}{2 \\eta} - \\frac{1}{2 \\eta}    )   + \\sum_{t=1}^T L \\eta + T \\epsilon    \\\\\n   \\leq & \\frac{\\|\\theta_1 - \\theta'\\|_2^2}{2 \\eta} + \\sum_{t=1}^T L \\eta + T \\epsilon    \\\\\n   \\leq & \\calo(\\frac{R^2}{ \\sqrt{m} \\eta}) + \\sum_{t=1}^T L \\eta + T \\epsilon  \\\\\n   \\overset{(a)}{\\leq} & \\calo(1) +  \\frac{TLR^2}{\\sqrt{m}} +  \\calo( \\frac{T R^{4/3} L^2\\sqrt{\\log m}}{m^{1/3}})\n   \\end{align*}\nwhere $(a)$ is by simply discarding the last term and $(b)$ is by $\\eta = \\frac{R^2}{\\sqrt{m}}$ and replacing $\\epsilon$ with $\\omega = \\calo(R/m^{1/4})$.  \n\nThe proof is completed.\n\\end{proof}\n\n\\fi\n\n\n"
                },
                "subsection 12.2": {
                    "name": "Regret analysis",
                    "content": "\n\n\n\n\n\n\n\n\\begin{proof}\nFirst,  \naccording to Lemma \\ref{lemma:usertrajectoryball}, $\\btheta^2_0, \\dots, \\btheta_{T-1}^2$ all are in $\\mathcal{B}(\\btheta_0, R/m^{1/4})$. \nThen, according to Lemma \\ref{lemma:xi1}, for any $\\bx \\in \\bbr^d, \\|\\bx\\|_2 = 1$, it holds uniformly $|f_1(\\bx_{t, \\hi}; \\btheta^1_t)  + f_2( \\phi(\\bx_{t, \\hi}); \\btheta^2_t) - r_{t, \\hi}| \\leq \\calo(1)$.\n\nThen, for any $\\tau \\in [t]$, define\n\\begin{equation}\n\\begin{aligned}\nV_{\\tau} :=&\\underset{ r_{\\tau, \\hi} }{\\bbe} \\left[ | f_2( \\phi(\\bx_{\\tau, \\hi}); \\btheta^2_{\\tau - 1}) -  (  r_{\\tau, \\hi} - f_1(\\bx_{\\tau, \\hi}; \\btheta^1_{\\tau - 1})) | \\right]  \\\\\n& - | f_2( \\phi(\\bx_{\\tau, \\hi}); \\btheta^2_{\\tau - 1}) -  (  r_{\\tau, \\hi} - f_1(\\bx_{\\tau, \\hi}; \\btheta^1_{\\tau - 1})) |\n\\end{aligned}\n\\end{equation}\n\nThen, we have\n\\begin{equation}\n\\begin{aligned}\n\\bbe[V_{\\tau}| F_{\\tau - 1}]  =&\\underset{r_{\\tau, \\hi} }{\\bbe} \\left[ | f_2( \\phi(\\bx_{\\tau, \\hi}); \\btheta^2_{\\tau - 1}) -  (  r_{\\tau, \\hi} - f_1(\\bx_{\\tau, \\hi}; \\btheta^1_{\\tau - 1}))|\\right] \\\\\n& - \\underset{r_{\\tau, \\hi} }{\\bbe} \\left[ | f_2( \\phi(\\bx_{\\tau, \\hi}); \\btheta^2_{\\tau - 1}) -  (  r_{\\tau, \\hi} - f_1(\\bx_{\\tau, \\hi}; \\btheta^1_{\\tau - 1})) \\right] \\\\\n= & 0\n\\end{aligned}\n\\end{equation}\nwhere $F_{\\tau - 1}$ denotes the $\\sigma$-algebra generated by the history $\\mathcal{H}_{\\tau -1}$. \n\nTherefore, the sequence $\\{V_{\\tau}\\}_{\\tau =1}^t$ is the martingale difference sequence.\nApplying the Hoeffding-Azuma inequality, with probability at least $1-\\delta$, we have\n\\begin{equation}\n    \\bbp \\left[  \\frac{1}{t}  \\sum_{\\tau=1}^t  V_{\\tau}  -   \\underbrace{ \\frac{1}{t} \\sum_{\\tau=1}^t \\underset{r_{i, \\hi} }{\\bbe}[ V_{\\tau} | \\mathbf{F}_{\\tau-1} ] }_{I_1}   >  \\sqrt{ \\frac{2  \\log (1/\\delta)}{t}}  \\right] \\leq \\delta   \\\\\n\\end{equation}    \nAs $I_1$ is equal to $0$, we have\n\\begin{equation}\n\\begin{aligned}\n      &\\frac{1}{t} \\sum_{\\tau=1}^t \\underset{r_{\\tau, \\hi} }{\\bbe} \\left[ \\left |  f_2( \\phi(\\bx_{\\tau, \\hi}); \\btheta^2_{\\tau - 1}) - (  r_{\\tau, \\hi} -  f_1(\\bx_{\\tau, \\hi}; \\btheta^1_{\\tau - 1})) \\right|   \\right]  \\\\\n \\leq  &  \\underbrace{ \\frac{1}{t}\\sum_{\\tau=1}^t  \\left|f_2 ( \\phi(\\bx_{\\tau, \\hi}) ; \\btheta_{\\tau-1}^2)  - (r_{\\tau, \\hi} - f_1(\\bx_{\\tau, \\hi}; \\btheta_{\\tau-1}^1))  \\right| }_{I_3}  +   \\sqrt{ \\frac{2 \\log (1/\\delta) }{t}}   ~.\n    \\end{aligned}  \n\\label{eq:pppuper}\n\\end{equation}\n\nFor $I_3$, based on Lemma \\ref{lemma:instancelossbound}, for any $\\btheta'$ satisfying $\\| \\btheta'  - \\btheta^2_0 \\|_2 \\leq R /m^{1/4}$, with probability at least $1 -\\delta$, we have\n\\begin{equation}\n\\begin{aligned}\nI_3 &\\leq \n\\frac{1}{t}\\sqrt{t}\\sqrt{\n\\sum_{\\tau =1}^t \n\\left(     f_2 ( \\phi(\\bx_{\\tau, \\hi}) ; \\btheta^2_{\\tau-1} ) -   (r_{\\tau, \\hi}\n- f_1(\\bx_{\\tau, \\hi}; \\btheta_{\\tau-1}^1))\n\\right)^2}\n\\\\\n& \\leq \n\\frac{1}{t}\\sqrt{t}\\sqrt{\n\\sum_{\\tau =1}^t \n\\left(     f_2 ( \\phi(\\bx_{\\tau, \\hi}); \\btheta') -   (r_{\\tau, \\hi}\n- f_1(\\bx_{\\tau, \\hi}; \\btheta_{\\tau-1}^1))\n\\right)^2}\n+ \\frac{ \\calo(1)}{\\sqrt{t}} \n \\\\\n& \\overset{(a)}{\\leq} \\frac{ \\sqrt{ \\Psi(\\btheta_0, R) } + \\calo(1) } {\\sqrt{t}}.\n\\end{aligned}\n\\end{equation}\nwhere $(a)$ is based on the definition of instance-dependent complexity term. \nCombining the above inequalities together, with probability at least $1 - \\delta$, we have \n\\begin{equation}\n\\begin{aligned}\n\\frac{1}{t} \\sum_{\\tau=1}^t \\underset{r_{\\tau, \\hi}}{\\bbe} \\left[   \\left| f_2 (\\phi(\\bx_{\\tau, \\hi}); \\btheta^2_{\\tau-1}) - (  r_{\\tau, \\hi} -  f_1(\\bx_{\\tau, \\hi}; \\btheta^1_{\\tau-1}) \\right| \\right] \\\\\n\\leq \\frac{ \\sqrt{ \\Psi(\\btheta_0, R) } + \\calo(1) } {\\sqrt{t}} +  \\sqrt{ \\frac{2  \\log ( \\calo(1)/\\delta) }{t}}.\n\\end{aligned}\n\\end{equation}\nThe proof is completed.\n\\end{proof}\n\n\n\n\n\n\\begin{corollary}\\label{corollary:main1} \nSuppose $m, \\eta_1, \\eta_2$ satisfy the conditions in Theorem \\ref{theo:main}.     For any $t \\in [T]$,  let\n$\\iast$ be the index selected by some fixed policy \nand $r_{t, \\iast}$ is the corresponding reward, and denote the policy by $\\pi^\\ast$.\nLet $\\btheta^{1,\\ast}_{t-1}, \\btheta^{2,\\ast}_{t-1}$ be the intermediate parameters trained by Algorithm \\ref{alg:explore} using the data select by $\\pi^\\ast$.\nThen, with probability at least $(1- \\delta)$  over the random of the initialization, for any $\\delta \\in (0, 1), R > 0$, it holds that\n \\begin{equation}\\label{eq:lemmamain}\n \\begin{aligned}\n \\frac{1}{t} \\sum_{\\tau=1}^t \\underset{r_{\\tau, \\iast}}{\\bbe} \n & \\left[   \\left| f_2 ( \\phi(\\bx_{\\tau, \\iast}) ; \\btheta_{\\tau-1}^{2, \\ast}) - \\left(r_{\\tau, \\iast} - f_1(\\bx_{\\tau, \\iast}; \\btheta_{\\tau-1}^{1, \\ast}) \\right)  \\right| \\mid  \\pi^\\ast, \\mathcal{H}_{\\tau-1}^\\ast \\right] \\\\\n & \\qquad \\qquad \\leq \n \\frac{ \\sqrt{ \\Psi(\\btheta_0, R) } + \\calo(1) } {\\sqrt{t}} +  \\sqrt{ \\frac{2  \\log ( \\calo(1)/\\delta) }{t}},\n \\end{aligned}\n \\end{equation}\nwhere  $\\mathcal{H}_{\\tau-1}^\\ast = \\{\\bx_{\\tau, \\iast},  r_{\\tau, \\iast} \\}_{\\tau' = 1}^{\\tau-1} $ represents the historical data produced by $\\pi^\\ast$ and the expectation is taken over the reward.\n\\end{corollary}\n\n\n\\iffalse\n\n\n\n\n\n\\begin{proof}\nThis a direct corollary of Lemma \\ref{lemma:newthetabound}, given the optimal historical pairs $\\{\\bx_{\\tau, \\iast}, r_{\\tau, \\iast} \\}_{\\tau = 1}^{t-1}$ according to $\\pi^\\ast$.\nFor brevity, let $f_2( \\phi(\\bx);  \\btheta_\\tau^{2, \\ast})$ represent $f_2\\left( \\nabla_{\\btheta^{1, \\ast}_\\tau }f_1(\\bx ; \\btheta_\\tau^{1, \\ast}); \\btheta_\\tau^{2, \\ast}\\right)$. \n\nSuppose that, for each $\\tau \\in [t-1]$, \n%\\abcomment{we may have used both $\\tau \\in [t-1]$ and $\\tau \\in [t]$, pls check}\n$\\btheta_\\tau^{1, \\ast}$ and $\\btheta_\\tau^{2, \\ast}$ are the parameters training on $\\{\\bx_{\\tau'}^\\ast, r_{\\tau'}^\\ast \\}_{\\tau'=1}^\\tau$ according to Algorithm \\ref{alg:explore} according to \n $\\pi^\\ast$. \nNote that these pairs $\\{\\bx_{\\tau'}^\\ast, r_{\\tau'}^\\ast \\}_{\\tau'=1}^\\tau$ are unknown to the algorithm we run, and the parameters $(\\btheta_\\tau^{1, \\ast},\\btheta_\\tau^{2, \\ast})$ are not estimated. However, for the analysis, it is sufficient to show that there exist such parameters so that the conditional expectation of the error can be bounded.\n\n%In round $\\tau \\in [t]$, let $ \\bx_{\\tau, \\iast} = \\arg \\max_{\\bx_{\\tau, i}  i \\in [n]} [h(\\bx_{\\tau,i}) ], $ given $(\\bx_{\\tau, i}, r_{\\tau, i} ) \\sim \\cald, i \\in [n]$.\n%Let $r^\\ast_{\\tau}$ be the corresponding reward. Let $(\\bx'_{\\tau,i},r'_{\\tau,i}) \\sim \\cald, i \\in [n]$ be shadow samples from the same distribution and let $\\bx'^\\ast_{\\tau} = \\arg \\max_{\\bx'_{\\tau, i}, i \\in [n]} h(\\bx'_{\\tau, i})$, with $r'^\\ast_{\\tau}$ being the corresponding reward. \nThen, we define \n\\begin{equation} \n\\begin{aligned}\nV_{\\tau} & := \\underset{ r_{\\tau, \\iast} }{\\bbe}\n\\left[ \\left|f_2( \\phi(\\bx_{\\tau, \\iast}) ; \\btheta_{\\tau-1}^{2, \\ast})  - \\left(r_{\\tau, \\iast} - f_1(\\bx_{\\tau, \\iast}; \\btheta_{\\tau-1}^{1, \\ast})  \\right)  \\right|  \\right] \\\\ \n &\\qquad \\qquad - \\left|f_2( \\phi(\\bx_{\\tau, \\iast}); \\btheta_{\\tau-1}^{2, \\ast})  - \\left(r_{\\tau, \\iast} - f_1(\\bx_{\\tau, \\iast}; \\btheta_{\\tau-1}^{1, \\ast})  \\right) \\right|~.\n\\end{aligned}\n\\end{equation}\n\n\nThen, taking the expectation over reward, we have\n \\begin{equation} \\label{eq:vexp01}\n \\begin{aligned}\n \\bbe[  V_{\\tau} | \\mathbf{F}_{\\tau-1}] & =  \\underset{ r_{\\tau, \\iast}}{\\bbe}\n \\left[ \\left|f_2\\left(  \\phi(\\bx_{\\tau, \\iast}) ;  \\btheta_{\\tau-1}^{2, \\ast}\\right)  - \\left(r_{\\tau, \\iast} - f_1(\\bx_{\\tau, \\iast}; \\btheta_{\\tau-1}^{1, \\ast})  \\right)  \\right|  \\right]  \\\\\n& \\quad -   \\underset{ r_{\\tau, \\iast} }{  \\bbe}\n\\left[  \\left|f_2 \\left( \\phi(\\bx_{\\tau, \\iast}) ; \\btheta_{\\tau-1}^{2, \\ast} \\right)  - \\left(r_{\\tau, \\iast} - f_1(\\bx_{\\tau, \\iast}; \\btheta_{\\tau-1}^{1, \\ast})  \\right) \\right| \\mid \\mathbf{F}_{\\tau-1} \\right] \\\\\n& = 0~,\n\\end{aligned}\n \\end{equation}\nwhere $ \\mathbf{F}_{\\tau-1}$ denotes the $\\sigma$-algebra generated by the history $\\mathcal{H}_{\\tau-1}^\\ast = \\{\\bx_{\\tau, \\iast},  r_{\\tau, \\iast} \\}_{\\tau' = 1}^{\\tau-1} $. \n%Note that $(\\bx_{\\tau}, r_{\\tau}) \\sim D$.\n\n\nTherefore,  $\\{V_{\\tau}\\}_{\\tau = 1}^t$ is a martingale difference sequence.\nSimilarly to Lemma \\ref{lemma:newthetabound}, applying the Hoeffding-Azuma inequality to $V_{\\tau}$, \n%to the bounded random variables $V_{1}, \\dots, V_{t} $,  \nwith probability  $1 - \\delta$,  we have \n\n\\begin{equation}\n\\begin{aligned}\n & \\frac{1}{t} \\sum_{\\tau=1}^t  \\underset{ r_{\\tau, \\iast}}{\\bbe} \\left[ \\left|f_2 ( \\phi(\\bx_{\\tau, \\iast}) ; \\btheta_{\\tau-1}^{2, \\ast} )  - \\left(r_{\\tau, \\iast} - f_1(\\bx_{\\tau, \\iast}; \\btheta_{\\tau-1}^{1, \\ast})  \\right) \\right|  \\right]  \\\\\n \\leq &  \\frac{1}{t}\\sum_{\\tau=1}^t \\left|f_2 ( \\phi(\\bx_{\\tau, \\iast}) ; \\btheta_{\\tau-1}^{2, \\ast} )  - \\left(r_{\\tau, \\iast} - f_1(\\bx_{\\tau, \\iast}; \\btheta_{\\tau-1}^{1, \\ast}) \\right)  \\right|  + \\sqrt{ \\frac{2 \\log (1/\\delta) }{t}}  \\\\\n \\leq &   \n\\frac{1}{t} \\sqrt{t} \\sqrt{ \\sum_{\\tau=1}^t \\left(   f_2 ( \\phi(\\bx_{\\tau, \\iast}) ; \\btheta^{2, \\ast} ) - \\left(r_{\\tau, \\iast} - f_1(\\bx_{\\tau, \\iast}; \\btheta_{\\tau-1}^{1, \\ast})   \\right) \\right)^2 }   + \\sqrt{ \\frac{2 \\log (1/\\delta) }{t}} \\\\\n \\overset{(a)}{ \\leq} &  \\frac{1}{t} \\sqrt{t} \\sqrt{ \\sum_{\\tau=1}^t \\left(   f_2 ( \\phi(\\bx_{\\tau, \\iast}) ; \\btheta' ) - \\left(r_{\\tau, \\iast} - f_1(\\bx_{\\tau, \\iast}; \\btheta_{\\tau-1}^{1, \\ast})   \\right) \\right)^2 }   + \\frac{\\calo(1)}{\\sqrt{t}} + \\sqrt{ \\frac{2 \\log (1/\\delta) }{t}}  \\\\\n\\overset{(b)}{\\leq} &  \\frac{\\sqrt{ \\Psi(\\btheta_0, R)} + \\calo(1) }{\\sqrt{t}} + \\sqrt{ \\frac{2 \\log (1/\\delta) }{t}} ,\n\\end{aligned}\n\\end{equation}\nwhere $(a)$ is an application of Lemma \\ref{lemma:instancelossbound} for all $\\btheta' \\in B(\\btheta_0^2, R/m^{1/4})$ and $(b)$ is based on the definition of instance-dependent complexity term. \nCombining the above inequalities, the proof is complete.\n\\end{proof}\n\\fi\n\n\n\nDefine $g(x_{t}; \\theta) \\nabla_{\\theta}  =   f(x_{t}; \\theta)$ for brevity.\n\n\\begin{lemma} \\label{lemma:stk}\nSuppose $m$ satisfies the conditions in Theorem \\ref{theo:main}. With probability at least $1 - \\delta$ over the initialization, there exists $\\btheta'  \\in  B(\\theta_0, \\widetilde{\\Omega}(T^{3/2}))$, such that\n\\[\n \\sum_{t=1}^{Tk} \\bbe [ ( r_t -  f(\\bx_t; \\theta'))^2/2 ] \\leq \\calo \\left(\\sqrt{ \\widetilde{d} \\log(1 + Tk) - 2 \\log \\delta  } + S + 1 \\right)^2 \\cdot \\widetilde{d} \\log (1+Tk).\n\\]\n\\end{lemma}\n\n\n\\begin{proof}\n\\[\n\\begin{aligned}\n& \\bbe [ \\sum_{t=1}^{Tk} (r_t -  f(\\bx_t; \\theta') )^2 ] \\\\\n = &  \\sum_{t=1}^{TK} ( y(\\bx_t) - f(\\bx_t; \\theta') )^2  \\\\\n\\overset{(a)}{\\leq} &   \\calo \\left ( \\sqrt{  \\log \\left(  \\frac{\\deter(\\mathbf{A}_T)} { \\deter(\\mathbf{I}) }   \\right)   - 2 \\log  \\delta }  +  S  + 1  \\right)^2 \\sum_{t=1}^{TK}   \\| \\gx  \\|_{\\mathbf{A}_{T}^{-1}}^2 +  2TK \\cdot \\calo \\left(\\frac{T^2 L^3 \\sqrt{\\log m}}{m^{1/3}} \\right) \\\\\n \\overset{(b)}{\\leq} &  \\calo \\left(\\sqrt{ \\widetilde{d} \\log(1 + Tk) - 2 \\log \\delta  } + S + 1 \\right)^2 \\cdot \n \\left( \\widetilde{d} \\log (1+Tk) + 1 \\right) + \\calo(1),\n\\end{aligned}\n\\]\nwhere $(a)$ is based on Lemma \\ref{lemma:bounfofsinglethetaprime} and $(b)$ is an application of Lemma 11 in \\cite{2011improved} and Lemma \\ref{lemma:detazero}, and $\\calo(1)$ is induced by the choice of $m$.\nBy ignoring $\\calo(1)$,  The proof is completed.\n\\end{proof}\n\n\n\n\n\\begin{definition} \\label{def:ridge}\nGiven the context vectors $\\{\\bx_i\\}_{i=1}^T$ and the rewards $\\{ r_i \\}_{i=1}^{T} $, then we define the estimation $\\widehat{\\theta}_t$ via ridge regression:  \n\\[\n\\begin{aligned}\n&\\mathbf{A}_t = \\mathbf{I} + \\sum_{i=1}^{t} g(\\bx_i; \\theta_0) g(\\bx_i; \\theta_0)^\\top \\\\\n&\\mathbf{b}_t = \\sum_{i=1}^{t} r_i g(\\bx_i; \\theta_0)  \\\\\n&\\widehat{\\theta}_t = \\mathbf{A}^{-1}_t \\mathbf{b}_t \n\\end{aligned}\n\\]\n\\end{definition}\n\n\n\n\n\n\n\n\n\\begin{lemma}\\label{lemma:bounfofsinglethetaprime}\nSuppose $m$ satisfies the conditions in Theorem \\ref{theo:main}. With probability at least $1 - \\delta$ over the initialization, there exists $\\btheta'  \\in  B(\\theta_0, \\widetilde{\\Omega}(T^{3/2}))$ for all $t \\in [T]$, such that\n\\[\n| \\hx  - f(\\bx_t; \\theta') | \\leq  \\calo \\left ( \\sqrt{  \\log \\left(  \\frac{\\deter(\\mathbf{A}_t)} { \\deter(\\mathbf{I}) }   \\right)   - 2 \\log  \\delta }  +  S  + 1  \\right) \\| \\gx  \\|_{\\mathbf{A}_{t}^{-1}} + \\calo \\left(\\frac{T^2 L^3 \\sqrt{\\log m}}{m^{1/3}} \\right)\n\\]\n\\end{lemma}\n\n\n\n\\begin{proof}\nGiven a set of context vectors $\\{\\bx\\}_{t=1}^{T}$ with the ground-truth function $h$ and a fully-connected neural network $f$, we have\n\\[\n\\begin{aligned}\n &\\left| \\hx  - f(\\bx_t; \\theta')     \\right| \\\\\n\\leq &  \\left  | \\hx  - \\langle \\gx,  \\htheta_t  \\rangle \\right|  + \\left| f(\\bx_t; \\btheta')  -  \\langle \\gx, \\htheta_t \\rangle  \\right|\n\\end{aligned}\n\\]\nwhere $\\btheta'$ is the estimation of ridge regression from Definition \\ref{def:ridge}. Then, based on the Lemma \\ref{lemma:existthetastar},\nthere exists $\\bts \\in \\mathbf{R}^{P}$ such that $ h(\\bx_i) =  \\left \\langle  g(\\bx_i, \\btheta_0), \\bts \\right \\rangle$. Thus, we have\n\\[\n\\begin{aligned}\n& \\ \\   \\left  | \\hx  - \\langle \\gx, \\htheta_t \\rangle \\right| \\\\\n  = & \\left|  \\left \\langle  g(\\bx_i, \\btheta_0),   \\bts \\right \\rangle   -   \\left \\langle  g(\\bx_i, \\btheta_0),  \\htheta_t \\right \\rangle \\right | \\\\\n\\leq   & \\calo \\left ( \\sqrt{  \\log \\left(  \\frac{\\deter(\\mathbf{A}_t)} { \\deter(\\mathbf{I}) }   \\right)   - 2 \\log  \\delta }  +  S   \\right) \\| \\gx  \\|_{\\mathbf{A}_{t}^{-1}}\n\\end{aligned}\n\\]\nwhere the final inequality is based on the the Theorem 2 in \\cite{2011improved}, with probability at least $1-\\delta$, for any $t \\in [T]$.\n\n  \nSecond, we need to bound \n\\[\n\\begin{aligned}\n&\\left| f(\\bx_t; \\theta') -  \\langle g(\\bx_t; \\btheta_0), \\htheta_t \\rangle  \\right| \\\\\n \\leq & \\left |  f(\\bx_t; \\theta') - \\langle g(\\bx_t; \\btheta_0), \\btheta' - \\btheta_0 \\rangle   \\right|  \\\\\n &+    \\left|     \\langle  g(\\bx_t; \\btheta_0), \\btheta' - \\btheta_0 \\rangle   - \\langle  g(\\bx_t; \\btheta_0), \\htheta_t \\rangle \\right|    \n\\end{aligned} \n\\] \nTo bound the above inequality,  we first bound\n\\[\n\\begin{aligned}\n & \\left |  f(\\bx_t; \\theta') - \\langle g(\\bx_t; \\btheta_0), \\btheta' - \\btheta_0 \\rangle   \\right| \\\\\n=& \\left |  f(\\bx_t; \\theta') - f(\\mathbf{x}_t; \\btheta_0)   - \\langle g(\\bx_t; \\btheta_0), \\btheta' - \\btheta_0 \\rangle   \\right| \\\\\n\\leq  & \\calo(\\omega^{4/3} L^3 \\sqrt{ \\log m}) \n\\end{aligned}\n\\] \nwhere  we  initialize $ f(\\mathbf{x}_t; \\btheta_0) = 0$ and the inequality is derived by Lemma \\ref{lemma:functionntkbound} with $\\omega = \\frac{\\calo(t^{3/2})}{m^{1/4}}$. \nNext, we need to bound\n\\[ \n\\begin{aligned}\n &|  \\langle  g(\\bx_t; \\btheta_0), \\btheta' - \\btheta_0 \\rangle - \\langle  g(\\bx_t; \\btheta_0), \\htheta_t \\rangle | \\\\\n = & |\\langle g(\\bx_t; \\btheta_0) ,     (\\btheta' - \\btheta_0 -  \\htheta_t ) \\rangle|  \\\\ \n\\leq & \\| g(\\bx_t; \\btheta_0)\\|_{\\mathbf{A}_t^{-1}} \\cdot  \\| \\btheta' - \\btheta_0  - \\htheta_t\\|_{\\mathbf{A}_t} \\\\\n\\leq & \\| g(\\bx_t; \\btheta_0)  \\|_{\\mathbf{A}_t^{-1}} \\cdot  \\|{\\mathbf{A}_t} \\|_2  \\cdot  \\| \\btheta' - \\btheta_0  - \\htheta_t\\|_2. \\\\\n\\end{aligned} \n\\]\nDue to the Lemma \\ref{lemma:detazero} and Lemma \\ref{lemma:2thetab}, we have\n\\[\n\\begin{aligned}\n & \\|{\\mathbf{A}_t} \\|_2 \\cdot   \\| \\theta' - \\btheta_0  - \\htheta_t\\|_2 \\leq  (1 + t \\mathcal{O}(L))   \\cdot \\frac{1}{1 + \\calo(tL)}  =\\calo(1).\n \\end{aligned}\n\\] \nFinally, putting everything together, we have\n\\[\n\\begin{aligned}\n\\left| \\hx  - f(\\bx_t; \\theta')     \\right| &\\leq \\gamma_1  \\| g(\\bx_t; \\btheta_0)/\\sqrt{m} \\|_{\\mathbf{A}_t^{-1}}  + \\gamma_2.    \\\\\n\\end{aligned}\n\\]\nThe proof is completed.\n\\end{proof}\n\n\n\n\n\n\n\n\n\n\\begin{definition}\n\\[\n\\begin{aligned}\n&\\mathbf{G}^{(0)} = \\left[ g(\\bx_1; \\theta_0), \\dots,   g(\\bx_T; \\theta_0)\\right]  \\in \\bbr^{p \\times T}   \\\\\n&\\mathbf{G}_0 = \\left[ g(\\bx_1; \\theta_0), \\dots,   g(\\bx_{Tk}; \\theta_0) \\right]  \\in \\bbr^{p \\times Tk} \\\\\n&\\mathbf{r}= (r_1, \\cdots, r_T) \\in \\bbr^T\n\\end{aligned}\n\\]\n$\\mathbf{G}^{(0)}$ and $\\mathbf{r}$ are formed by the selected contexts and observed rewards in $T$ rounds, $\\mathbf{G}_0$ are formed by all the presented contexts.\n\nInspired by Lemma B.2 in \\cite{zhou2020neural} , with $\\eta = m^{-1/4}$ we define the auxiliary sequence following :\n\\[\n\\theta_0 = \\theta^{(0)}, \\ \\ \\theta^{(j+1)}   = \\theta^{(j)} - \\eta\\left[ \\bsg^{(0)} \\left( [\\bsg^{(0)}]^\\top (\\theta^{(j)}  - \\theta_0) - \\bsr \\right)  + \\lambda (\\theta^{(j)} - \\theta_0 )  \\right] \n\\]\n\\end{definition}\n\n\n\n\n\n\\begin{lemma} \\label{lemma:existthetastar}\nSuppose $m$ satisfies the conditions in Theorem \\ref{theo:main}. With probability at least $1 - \\delta$ over the initialization, for any $t \\in [T], i \\in [k]$, the result uniformly holds:\n\\[\nh_{u_t}(\\bx_{t,i}) = \\langle g(\\bx_{t,i}; \\theta_0), \\theta^\\ast - \\theta_0 \\rangle.\n\\]\n\n\\end{lemma}\n\\begin{proof}\nBased on Lemma \\ref{lemma:boundgradientandNTK} with proper choice of $\\epsilon$, we have\n\\[\n\\mathbf{G}^\\top_0 \\mathbf{G}_0 \\succeq  \\mathbf{H} - \\|   \\mathbf{G}^\\top_0 \\mathbf{G}_0 - \\mathbf{H}    \\|_F \\mathbf{I} \\succeq \\mathbf{H} -\\lambda_0 \\mathbf{I}/2 \\succeq \\mathbf{H}/2 \\succeq 0.\n\\] \nDefine $\\mathbf{h} = [h_{u_1}(\\bx_1), \\dots, h_{u_T}(\\bx_{Tk})]$.\nSuppose the singular value decomposition of $\\mathbf{G}_0$ is $\\mathbf{PAQ}^\\top,   \\mathbf{P} \\in \\bbr^{p \\times Tk},  \\mathbf{A} \\in \\bbr^{Tk \\times Tk},  \\mathbf{Q} \\in \\bbr^{Tk \\times Tk}$, then, $\\mathbf{A} \\succeq 0$. \nDefine  $\\theta^\\ast = \\theta_0 + \\mathbf{P} \\mathbf{A}^{-1} \\mathbf{Q}^\\top \\mathbf{h}$. Then, we have \n\\[\n\\mathbf{G}^\\top_0 (\\btheta^\\ast - \\btheta_0) = \\mathbf{QAP}^\\top \\mathbf{P}\\mathbf{A}^{-1} \\mathbf{Q}^{\\top} \\mathbf{h} = \\mathbf{h}.\n\\]\nwhich leads to \n\\[\n \\sum_{t=1}^{T}  \\sum_{i = 1}^k ( h_{u_t}(\\bx_{t, i}) - \\langle g(\\bx_{t, i}; \\theta_0), \\theta^\\ast - \\btheta_0 \\rangle ) = 0.\n\\]\nTherefore, the result holds:\n\\begin{equation}\n\\|     \\btheta^\\ast - \\btheta_0       \\|_2^2 = \\mathbf{h}^\\top \\mathbf{QA}^{-2}\\mathbf{Q}^\\top \\mathbf{h} =  \\mathbf{h}^\\top (\\mathbf{G}^\\top_0 \\mathbf{G}_0)^{-1} \\mathbf{h}  \\leq  2 \\mathbf{h}^\\top\\mathbf{H}^{-1} \\mathbf{h} \n\\end{equation}\n\n\\end{proof}\n\n\n\n\n\n\\begin{lemma} \\label{lemma:2thetab}\nThere exist $\\btheta'  \\in  B(\\theta_0, \\wcalo(T^{3/2}L + \\sqrt{T}))$, such that,  with probability at least $1 -\\delta$, the results hold:\n\\[\n\\begin{aligned}\n& (1) \\|         \\btheta' - \\theta_0 \\|_2 \\leq  \\frac{ \\wcalo(T^{3/2}L + \\sqrt{T })}{m^{1/4}} \\\\\n& (2) \\| \\theta' - \\theta_0 - \\widehat{\\theta}_t  \\|_2  \\leq \\frac{1}{1 +  \\calo(TL)} \\\\\n\\end{aligned}\n\\]\n\\end{lemma}\n\n\n\n\n\n\n\\begin{proof}\n\\normalfont\nThe sequence of $\\theta^{(j)}$ is updates by using gradient descent on the loss function:\n\\[\n\\min_{\\theta} \\mathcal{L}(\\theta) = \\frac{1}{2}  \\|[\\bsg^{(0)}]^\\top (\\theta - \\btheta^{(0)} ) - \\bsr  \\|^2_2 + \\frac{m\\lambda}{2} \\|\\theta - \\btheta^{(0)}\\|_2^2 . \n\\]\n\n\\iffalse\nThen, for any $j > 0$, it can be bounded as:\n\\[\n\\begin{aligned}\n\\frac{\\lambda}{2} \\|  \\theta^{(j)} - \\theta^{(0)} \\|_2^2 &  \\leq   \\frac{1}{2}  \\|[\\bsg^{(0)}]^\\top ( \\theta^{(j)} - \\btheta^{(0)} ) - \\bsr  \\|^2_2 + \\frac{\\lambda}{2} \\|\\theta^{(0)} - \\btheta^{(0)}\\|_2^2 \\\\\n&  \\leq   \\frac{1}{2}  \\|[\\bsg^{(0)}]^\\top ( \\theta^{(0)} - \\btheta^{(0)}) - \\bsr  \\|^2_2 + \\frac{\\lambda}{2} \\| \\btheta^{(0)} - \\btheta^{(0)}\\|_2^2  \\\\\n& \\leq   t/2\n\\end{aligned}\n\\]\nwhich, indicates $ \\| \\theta^{(j)} - \\theta^{(0)}   \\|_2 \\leq \\sqrt{t/\\lambda}$.\n\\fi\n\nFor any $j > 0$, the results holds: \n\\[\n\\|   \\bsg^{(0)}  \\|_F  \\leq \\sqrt{T} \\max_{t \\in [T]} \\|   g(\\bx_t; \\theta_0)   \\|_2 \\leq \\calo(\\sqrt{TL}),\n\\]\nwhere the last inequality is held by Lemma \\ref{lemma:xi1}.\nFinally, given the $j>0$, \n\\begin{equation} \\label{eq:boundofthetak}\n\\|  \\theta^{(j)} - \\theta^{(0)} \\|_2^2 \\leq \\sum_{i=1}^{j} \\eta \\left[ \\bsg^{(0)} \\left( [\\bsg^{(0)}]^\\top (\\theta^{(i)}  - \\theta_0) - \\bsr \\right)  + \\lambda (\\theta^{(i)} - \\theta_0 )  \\right]  \\leq \\frac{\\calo(j(TL\\sqrt{T/\\lambda} + \\sqrt{T\\lambda}))}{m^{1/4}}.\n\\end{equation}\nFor (2), by standard results of gradient descent on ridge regression, $\\theta^{(j)}$, and the optimum is $\\btheta^{(0)} + \\widehat{\\btheta}_t $. Therefore, we have \n\\[\n\\begin{aligned}\n\\| \\theta^{(j)} - \\btheta^{(0)} - \\widehat{\\btheta}_t \\|_2^2  & \\leq \\left[  1 -\\eta \\lambda\\right]^j \\frac{2}{\\lambda} \\left(  \\mathcal{L}(\\btheta^{(0)}) -  \\mathcal{L}(\\btheta^{(0)} + \\widehat{\\btheta}_t) \\right) \\\\\n \\leq &  \\frac{2 (1 - \\eta \\lambda)^j}{\\lambda}  \\mathcal{L}(\\btheta^{(0)}) \\\\\n= & \\frac{2 (1 - \\eta m \\lambda)^j}{ \\lambda}  \\frac{\\|\\bsr\\|^2_2}{2} \\\\\n\\leq &\\frac{T(1 - \\eta \\lambda)^j}{ \\lambda}.\n\\end{aligned}\n\\]\nBy setting $\\lambda = 1$ and $j  = \\log ((T + \\calo(T^2L))^{-1})/ \\log (1 - m^{- 1/4})$, we have $ \\| \\theta^{(j)} - \\btheta_0 - \\widehat{\\btheta}_t \\|_2^2 \\leq \\frac{1}{1 +  \\calo(TL)} $.\nReplacing $k$ and $\\lambda$ in  \\eqref{eq:boundofthetak} finishes the proof.\n\\end{proof}\n\n\n\n\\begin{lemma} \\label{lemma:detazero}\nSuppose $m$ satisfies the conditions in Theorem \\ref{theo:main}. With probability at least $1 - \\delta$ over the initialization, the result holds:\n\\[\n\\begin{aligned}\n\\|  \\mathbf{A}_T \\|_2 &\\leq 1  + \\mathcal{O}(TL), \\\\\n\\log \\frac{\\det \\mathbf{A}_T}{ \\det \\mathbf{I}} &\\leq \\widetilde{d} \\log(1 + Tk) + 1.\n\\end{aligned}\n\\]\n\\end{lemma}\n\n\n\\begin{proof}\nBased on the Lemma \\ref{lemma:xi1}, for any $t \\in  [T]$, \n$ \\|g(\\bx_t; \\btheta_0) \\|_2 \\leq \\mathcal{O}(\\sqrt{L})$.\nThen, for the first item:\n\\[\n\\begin{aligned}\n&\\|  \\mathbf{A}_T \\|_2  =  \\|   \\mathbf{I} + \\sum_{t=1}^{T} g(\\bx_t; \\btheta_0) g(\\bx_t; \\btheta_0)^\\top \\|_2 \\\\\n& \\leq   \\| \\mathbf{I} \\|_2 + \\| \\sum_{t=1}^{T} g(\\bx_t; \\btheta_0) g(\\bx_t; \\btheta_0)^\\top \\|_2  \\\\ \n&\\leq  1  +  \\sum_{t=1}^{T} \\| g(\\bx_t; \\btheta_0) \\|_2^2  \\leq 1  + \\mathcal{O}(TL).\n\\end{aligned}\n\\]\nNext, we have\n\\[\n\\log \\frac{\\deter(\\mathbf{A}_T) }{\\deter(   \\mathbf{I})} = \\log \\deter(\\mathbf{I} + \\sum_{t=1}^{Tk} g(\\bx_t; \\btheta_0) g(\\bx_t; \\btheta_0)^\\top  ) = \\deter( \\mathbf{I} + \\mathbf{G}_0 \\mathbf{G}_0^{\\top}) \n\\]\n\nThen, we have \n\\[\n\\begin{aligned}\n &\\log \\det(\\mathbf{I} + \\mathbf{G}_0 \\mathbf{G}^{\\top}_0  ) \\\\\n& = \\log \\deter ( \\mathbf{I} + \\mathbf{H}   +  (\\mathbf{G}_0 \\mathbf{G}^{\\top}_0 - \\mathbf{H})    ) \\\\\n& \\leq   \\log \\deter ( \\mathbf{I} +  \\mathbf{H}  ) + \\langle ( \\mathbf{I} +  \\mathbf{H}   )^{-1},   (\\mathbf{G}_0 \\mathbf{G}^{\\top}_0 - \\mathbf{H})    \\rangle \\\\\n& \\leq \\log \\deter(  \\mathbf{I} +  \\mathbf{H}  ) +  \\| ( \\mathbf{I} +  \\mathbf{H}   )^{-1}    \\|_{F} \\|  \\mathbf{G}_0 \\mathbf{G}^{\\top}_0 - \\mathbf{H}  \\|_F    \\\\\n& \\leq  \\log \\deter(  \\mathbf{I} +  \\mathbf{H}  ) +  \\sqrt{T}\\|  \\mathbf{G}_0 \\mathbf{G}^{\\top}_0 - \\mathbf{H}  \\|_F   \\\\\n&\\leq   \\log \\deter(  \\mathbf{I} +  \\mathbf{H}  ) +  1\\\\\n&= \\widetilde{d} \\log ( 1 + Tk)+  1. \n\\end{aligned}\n\\]\nThe first inequality is because the concavity of $\\log \\deter$ ; The third inequality is due to $  \\| ( \\mathbf{I} +  \\mathbf{H} \\lambda )^{-1} \\|_{F} \\leq  \\| \\mathbf{I}^{-1} \\|_{F}  \\leq \\sqrt{T}$; The last inequality is because of the choice the $m$, based on Lemma \\ref{lemma:boundgradientandNTK}; The last equality is because  of the Definition of $\\hd$.\nThe proof is completed.\n\\end{proof}\n\n\n\\begin{lemma} \\label{lemma:boundgradientandNTK}\nFor any $\\delta \\in (0, 1)$, if $m = \\Omega \\left( \\frac{L^6 \\log(TkL/\\delta)}{(\\epsilon/Tk)^4} \\right)$, then with probability at least $1 - \\delta$, the results hold:\n\\[\n\\|   \\mathbf{G}_0 \\mathbf{G}^{\\top}_0 - \\mathbf{H}  \\|_F \\leq \\epsilon.\n\\]\n\\end{lemma}\n\\begin{proof}\nThis is an application of Lemma B.1 in \\cite{zhou2020neural} by properly setting $\\epsilon$.\n\\end{proof}\n\n\n\n\n\n\n\n\n\n\\begin{lemma} [Exactness of PageRank \\cite{li2023everything}] When PageRank achieves the stationary distribution,  \n$\\bv_t =  \\frac{1-\\alpha}{\\mathbf{I} - \\alpha \\bp_t} \\bh_t$.\n\\end{lemma}\n\n\n\n\nFinally, we provide the proof of Theorem \\ref{theo:main}.\n\\begin{proof}\n\\[\n\\begin{aligned}\n &\\bv_t^\\ast[i^\\ast]  -  \\bv_t^\\ast[\\hi] \\\\\n= & \\bv_t^\\ast[i^\\ast] - \\bv_t[\\hi]  + \\bv_t[\\hi] -  \\bv_t^\\ast[\\hi] \\\\\n\\overset{(1)}{\\leq} & \\bv_t^\\ast[i^\\ast] - \\bv_t[i^\\ast]  + \\bv_t[\\hi] -  \\bv_t^\\ast[\\hi] \\\\\n\\leq & |\\bv_t^\\ast[i^\\ast] - \\bv_t[i^\\ast]|  + |\\bv_t[\\hi] -  \\bv_t^\\ast[\\hi] | \\\\\n\\leq &  2 \\| \\bv_t^\\ast -   \\bv_t \\|_2\\\\\n\\overset{(2)}{=} & 2 \\left \\|   \\frac{1-\\alpha}{\\mathbf{I} - \\alpha \\bp_t} \\by_t -  \\frac{1-\\alpha}{\\mathbf{I} - \\alpha \\bp_t} \\bh_t  \\right\\|_2\\\\\n\\leq & 2  \\left \\|    \\frac{1-\\alpha}{\\mathbf{I} - \\alpha \\bp_t}   \\right \\|_2  \\| \\by_t -  \\bh_t\\|_2 \\\\\n\\end{aligned}\n\\]\nwhere (1) is by the choice of \\sysn and (2) is based on the exact solution of PageRank \\citep{li2023everything}.\nLet $\\lambda_{\\max}$ be the maximal eigenvalue of $\\mathbf{P}_t$.\nBecause $\\mathbf{P}_t$ is a stochastic matrix, $\\lambda_{\\max} = 1$. \nThen, we have\n\\[\n\\mathbf{I} - \\alpha \\mathbf{P}_t \\succeq (1 - \\alpha \\lambda_{\\max}) \\mathbf{I} \\succeq (1 - \\alpha) \\mathbf{I}.\n\\]\nAccordingly, we have\n\\[\n\\left \\|    \\frac{1-\\alpha}{\\mathbf{I} - \\alpha \\bp_t}   \\right\\|_2  \\| \\by_t -  \\bh_t\\|_2  \\leq  \\left  \\|    \\frac{1-\\alpha}{ 1 - \\alpha} \\mathbf{I}   \\right \\|_2  \\| \\by_t -  \\bh_t\\|_2  =  \\| \\by_t -  \\bh_t\\|_2.\n\\]\n\nThen, based on Corollary \\ref{corollary:main1}, Lemma \\ref{lemma:stk}, and Lemma \\ref{lemma:differenceee}, with shadow parameters, we have\n\\[\n\\begin{aligned}\n  &\\| \\by_t -  \\bh_t\\|_2 \\\\ \n =& \\sqrt{ \\sum_{v_{t,i} \\in \\calv_t} [  y(x_{t,i}) - (f_2\\left(\\phi\\left(x_{t,i}\\right); \\theta^2_{t-1}\\right) +  f_1 (x_{t,i}; \\theta^1_{t-1}) )   ]^2       }\\\\\n  =& \\sqrt{ \\sum_{v_{t,i} \\in \\calv_t} [ f_2\\left(\\phi\\left(x_{t,i}\\right); \\theta^2_{t-1}\\right) - ( y(x_{t,i}) -  f_1 (x_{t,i}; \\theta^1_{t-1}) )   ]^2       }\\\\\n=& \\sqrt{ k  \\left[  \\frac{  \\widetilde{\\calo} ( \\sqrt{ \\Psi(\\btheta_0, R) } ) } {\\sqrt{t}}  \\right]^2    } \\\\\n\\leq & \\widetilde{\\calo}(\\sqrt{\\tilde{d} k/T }) \\cdot \\sqrt{\\max(\\tilde{d}, S^2)}.\n\\end{aligned}\n\\]\nTo sum up, we have\n\\[\n\\begin{aligned}\n\\mathbf{R}_T & = \\sum_{t=1}^T (\\bv_t^\\ast[i^\\ast]  -  \\bv_t^\\ast[\\hi]) \\\\\n& \\leq \\sum_{t=1}^T \\| \\by_t -  \\bh_t\\|_2  \\\\\n& \\leq  \\widetilde{\\calo}(\\sqrt{\\tilde{d} kT }) \\cdot \\sqrt{\\max(\\tilde{d}, S^2)} \\\\\n\\end{aligned}\n\\]\nThe proof is completed.\n\\end{proof}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\iffalse\n\n\n\\begin{proof}\n\\[\n\\begin{aligned}\n      & | \\bv_t[i_t] - \\bh_t[i_t] | \\\\\n \\leq & |\\bv_t[i_t] -   \\bv_t^\\ast[i_t] +  \\bv_t^\\ast[i_t] + \\bh_t[i_t] |   \\\\\n \\leq & |\\bv_t[i_t] -   \\bv_t[i_t] | + |\\bv_t[i_t] + \\bh_t[i_t]| \\\\\n\\end{aligned}\n\\]\n\n\n\\end{proof}\n\n\n\n\n\n\n\\begin{lemma}\n$\\|\\bv_t^\\ast  - \\bv_t\\|_2$\n\\end{lemma}\n\n\\begin{proof}\n\\[\n\\begin{aligned}\n&\\|\\bv_t^\\ast  - \\bv_t\\|_2\\\\\n= &  \\|   \\frac{1-\\alpha}{\\mathbf{I} - \\alpha \\bp_t} \\bh_t -  \\frac{1-\\alpha}{\\mathbf{I} - \\alpha \\bp_t} \\bf_t    \\|_2\\\\\n\\leq  & \\|    \\frac{1-\\alpha}{\\mathbf{I} - \\alpha \\bp_t}   \\|_2  \\| \\bh_t -  \\bsf_t\\|_2\\\\\n\\end{aligned}\n\\]\n\\end{proof}\n\n\n\n\n\n\\begin{lemma}\nBound $\\|\\bv_t^\\ast  - \\bh_t\\|_2$\n\\end{lemma}\n\\begin{proof}\nLet  $A = \\mathbf{I} - \\alpha \\bp_t$.\n\n\n\\[\n\\begin{aligned}\n&\\|\\bv_t^\\ast  - \\bh_t\\|_2\\\\\n= &  \\|   \\frac{1-\\alpha}{\\mathbf{I} - \\alpha \\bp_t} \\bh_t - \\bh_t    \\|_2\\\\\n\\leq & \\|    (1- \\alpha)\\ba^{-1}   - \\bi      \\bh_t   \\|_2\\\\\n\\leq & \\|  \\frac{1-\\alpha}{(1- \\alpha \\lambda) \\bi}  - \\bi \\|_2  \\|    \\bh_t   \\|_2\\\\\n\\leq  & \\left | \\frac{ ( 1-\\lambda) \\alpha }{(1- \\alpha \\lambda)} \\right| \\|    \\bh_t   \\|_2\\\\\n\\end{aligned}\n\\]\n\\end{proof}\n\n\\fi\n\n% \\section{Additional Experiments}\n\n\n\n\n\n\\clearpage\n% \\bibliographystyle{iclr2023_conference}\n\n\n\n% \\section*{NeurIPS Paper Checklist}\n% \\begin{enumerate}\n\n% \\item {\\bf Claims}\n%     \\item[] Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope?\n%     \\item[] Answer: \\answerYes{} % Replace by \\answerYes{}, \\answerNo{}, or \\answerNA{}.\n%     \\item[] Justification: We have included discussion for our contributions in the Abstract and Introduction.\n%     \\item[] Guidelines:\n%     \\begin{itemize}\n%         \\item The answer NA means that the abstract and introduction do not include the claims made in the paper.\n%         \\item The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. \n%         \\item The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. \n%         \\item It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. \n%     \\end{itemize}\n\n% \\item {\\bf Limitations}\n%     \\item[] Question: Does the paper discuss the limitations of the work performed by the authors?\n%     \\item[] Answer: \\answerYes{} % Replace by \\answerYes{}, \\answerNo{}, or \\answerNA{}.\n%     \\item[] Justification: We have included the discussion of the limitation in the Appendix \\ref{appendix: limitations}.\n%     \\item[] Guidelines:\n%     \\begin{itemize}\n%         \\item The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. \n%         \\item The authors are encouraged to create a separate \"Limitations\" section in their paper.\n%         \\item The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.\n%         \\item The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.\n%         \\item The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.\n%         \\item The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.\n%         \\item If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.\n%         \\item While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.\n%     \\end{itemize}\n\n% \\item {\\bf Theory Assumptions and Proofs}\n%     \\item[] Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof?\n%     \\item[] Answer: \\answerYes{} % Replace by \\answerYes{}, \\answerNo{}, or \\answerNA{}.\n%     \\item[] Justification: Please see theoretical analysis section and appendix for details.\n%     \\item[] Guidelines:\n%     \\begin{itemize}\n%         \\item The answer NA means that the paper does not include theoretical results. \n%         \\item All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.\n%         \\item All assumptions should be clearly stated or referenced in the statement of any theorems.\n%         \\item The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. \n%         \\item Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.\n%         \\item Theorems and Lemmas that the proof relies upon should be properly referenced. \n%     \\end{itemize}\n\n%     \\item {\\bf Experimental Result Reproducibility}\n%     \\item[] Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)?\n%     \\item[] Answer: \\answerYes{} % Replace by \\answerYes{}, \\answerNo{}, or \\answerNA{}.\n%     \\item[] Justification: Please see appendix and our submitted source code.\n%     \\item[] Guidelines:\n%     \\begin{itemize}\n%         \\item The answer NA means that the paper does not include experiments.\n%         \\item If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.\n%         \\item If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. \n%         \\item Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.\n%         \\item While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example\n%         \\begin{enumerate}\n%             \\item If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm.\n%             \\item If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully.\n%             \\item If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset).\n%             \\item We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.\n%         \\end{enumerate}\n%     \\end{itemize}\n\n\n% \\item {\\bf Open access to data and code}\n%     \\item[] Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?\n%     \\item[] Answer: \\answerYes{} % Replace by \\answerYes{}, \\answerNo{}, or \\answerNA{}.\n%     \\item[] Justification: We include the source code along with our submission.\n%     \\item[] Guidelines:\n%     \\begin{itemize}\n%         \\item The answer NA means that paper does not include experiments requiring code.\n%         \\item Please see the NeurIPS code and data submission guidelines (\\url{https://nips.cc/public/guides/CodeSubmissionPolicy}) for more details.\n%         \\item While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).\n%         \\item The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (\\url{https://nips.cc/public/guides/CodeSubmissionPolicy}) for more details.\n%         \\item The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.\n%         \\item The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.\n%         \\item At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).\n%         \\item Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.\n%     \\end{itemize}\n\n\n% \\item {\\bf Experimental Setting/Details}\n%     \\item[] Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results?\n%     \\item[] Answer: \\answerYes{} % Replace by \\answerYes{}, \\answerNo{}, or \\answerNA{}.\n%     \\item[] Justification: We have shown detailed experimental settings/details in the Experiment and Appendix section.\n%     \\item[] Guidelines:\n%     \\begin{itemize}\n%         \\item The answer NA means that the paper does not include experiments.\n%         \\item The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them.\n%         \\item The full details can be provided either with the code, in appendix, or as supplemental material.\n%     \\end{itemize}\n\n% \\item {\\bf Experiment Statistical Significance}\n%     \\item[] Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments?\n%     \\item[] Answer: \\answerYes{} % Replace by \\answerYes{}, \\answerNo{}, or \\answerNA{}.\n%     \\item[] Justification: We have provided standard deviation as part of our experiment results.\n%     \\item[] Guidelines:\n%     \\begin{itemize}\n%         \\item The answer NA means that the paper does not include experiments.\n%         \\item The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.\n%         \\item The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).\n%         \\item The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)\n%         \\item The assumptions made should be given (e.g., Normally distributed errors).\n%         \\item It should be clear whether the error bar is the standard deviation or the standard error of the mean.\n%         \\item It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96\\% CI, if the hypothesis of Normality of errors is not verified.\n%         \\item For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).\n%         \\item If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.\n%     \\end{itemize}\n\n% \\item {\\bf Experiments Compute Resources}\n%     \\item[] Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments?\n%     \\item[] Answer: \\answerYes{} % Replace by \\answerYes{}, \\answerNo{}, or \\answerNA{}.\n%     \\item[] Justification: Please see the appendix where we mention our computational infrastructure and time of execution.\n%     \\item[] Guidelines:\n%     \\begin{itemize}\n%         \\item The answer NA means that the paper does not include experiments.\n%         \\item The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.\n%         \\item The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. \n%         \\item The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper). \n%     \\end{itemize}\n    \n% \\item {\\bf Code Of Ethics}\n%     \\item[] Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics \\url{https://neurips.cc/public/EthicsGuidelines}?\n%     \\item[] Answer: \\answerYes{} % Replace by \\answerYes{}, \\answerNo{}, or \\answerNA{}.\n%     \\item[] Justification: We confirm this perform conform with the NeurIPS Code of Ethics.\n%     \\item[] Guidelines:\n%     \\begin{itemize}\n%         \\item The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.\n%         \\item If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.\n%         \\item The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).\n%     \\end{itemize}\n\n\n% \\item {\\bf Broader Impacts}\n%     \\item[] Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed?\n%     \\item[] Answer: \\answerNA{} % Replace by \\answerYes{}, \\answerNo{}, or \\answerNA{}.\n%     \\item[] Justification: This paper does not perform societal impact.\n%     \\item[] Guidelines:\n%     \\begin{itemize}\n%         \\item The answer NA means that there is no societal impact of the work performed.\n%         \\item If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.\n%         \\item Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.\n%         \\item The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.\n%         \\item The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.\n%         \\item If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).\n%     \\end{itemize}\n    \n% \\item {\\bf Safeguards}\n%     \\item[] Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)?\n%     \\item[] Answer: \\answerNA{} % Replace by \\answerYes{}, \\answerNo{}, or \\answerNA{}.\n%     \\item[] Justification: This paper does not include any data or models that have a high risk for misuse.\n%     \\item[] Guidelines:\n%     \\begin{itemize}\n%         \\item The answer NA means that the paper poses no such risks.\n%         \\item Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. \n%         \\item Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.\n%         \\item We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make the best faith effort.\n%     \\end{itemize}\n\n% \\item {\\bf Licenses for existing assets}\n%     \\item[] Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected?\n%     \\item[] Answer: \\answerYes{} % Replace by \\answerYes{}, \\answerNo{}, or \\answerNA{}.\n%     \\item[] Justification: We have credited correctly for the existing data and models we referred.\n%     \\item[] Guidelines:\n%     \\begin{itemize}\n%         \\item The answer NA means that the paper does not use existing assets.\n%         \\item The authors should cite the original paper that produced the code package or dataset.\n%         \\item The authors should state which version of the asset is used and, if possible, include a URL.\n%         \\item The name of the license (e.g., CC-BY 4.0) should be included for each asset.\n%         \\item For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.\n%         \\item If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, \\url{paperswithcode.com/datasets} has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.\n%         \\item For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.\n%         \\item If this information is not available online, the authors are encouraged to reach out to the asset's creators.\n%     \\end{itemize}\n\n% \\item {\\bf New Assets}\n%     \\item[] Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets?\n%     \\item[] Answer: \\answerNA{} % Replace by \\answerYes{}, \\answerNo{}, or \\answerNA{}.\n%     \\item[] Justification: No new datasets are introduced.\n%     \\item[] Guidelines:\n%     \\begin{itemize}\n%         \\item The answer NA means that the paper does not release new assets.\n%         \\item Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. \n%         \\item The paper should discuss whether and how consent was obtained from people whose asset is used.\n%         \\item At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.\n%     \\end{itemize}\n\n% \\item {\\bf Crowdsourcing and Research with Human Subjects}\n%     \\item[] Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? \n%     \\item[] Answer: \\answerNA{} % Replace by \\answerYes{}, \\answerNo{}, or \\answerNA{}.\n%     \\item[] Justification: No human subjects are involved.\n%     \\item[] Guidelines:\n%     \\begin{itemize}\n%         \\item The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.\n%         \\item Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. \n%         \\item According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. \n%     \\end{itemize}\n\n% \\item {\\bf Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects}\n%     \\item[] Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained?\n%     \\item[] Answer: \\answerNA{} % Replace by \\answerYes{}, \\answerNo{}, or \\answerNA{}.\n%     \\item[] Justification: No human subjects are involved.\n%     \\item[] Guidelines:\n%     \\begin{itemize}\n%         \\item The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.\n%         \\item Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper. \n%         \\item We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution. \n%         \\item For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.\n%     \\end{itemize}\n\n% \\end{enumerate}\n\n\n\n"
                }
            }
        },
        "tables": {
            "tab:bandit-based res": "\\begin{table*}[!ht]\n  \\centering\n  \n  % \\vspace{-0.3em}\n    % Table generated by Excel2LaTeX from sheet 'Sheet3'\n    \\scalebox{1}{\n    \\begin{tabular}{lccccc}\n    \\toprule\n    \\multirow{2}[5]{*}{Methods} &MovieLens & AmazonFashion& Facebook & GrQc \\\\\n    \\cmidrule{2-5} & Mean $\\pm$ Std & Mean $\\pm$ Std & Mean $\\pm$ Std & Mean $\\pm$ Std\\\\\n    \n %    \\midrule      \n    % PPR & & & & & & & \\\\\n%EvePPR           & 2954 $\\pm$ 17.2 & 2678 $\\pm$ 14.4 & 4165 $\\pm$ 17.9 & 5340 $\\pm$ 17.9 \\\\\n    % SEAL & & & & & & & \\\\\n    % NCNC & & & & & & & \\\\\n    \\midrule\n    EE-Net           & 1638 $\\pm$ 15.3 &  1698 $\\pm$ 19.3  & 2274 $\\pm$ 27.1 & 3419 $\\pm$ 16.5 \\\\  \n    NeuGreedy   & 1955 $\\pm$ 17.3 & 1952 $\\pm$ 27.4 & 2601 $\\pm$ 14.2 & 3629 $\\pm$ 18.2 \\\\\n    NeuralUCB        & 1737 $\\pm$ 16.8 & 1913 $\\pm$ 18.6 & 2190 $\\pm$ 16.3 & 3719 $\\pm$ 16.4 \\\\\n    NeuralTS         & 1683 $\\pm$ 14.7 & 2055 $\\pm$ 21.9 & 2251 $\\pm$ 19.5 & 3814 $\\pm$ 23.3 \\\\\n    \\midrule\n    % PRB-Greedy             & 1892 $\\pm$ 15.1 & 1567 $\\pm$ 24.6 & 1994 $\\pm$ 23.6 & 3332 $\\pm$ 15.9 \\\\\n    \\textbf{PRB} & \\textbf{1555 $\\pm$ 21.7} & \\textbf{1455 $\\pm$ 18.4} & \\textbf{1929 $\\pm$ 17.0} & \\textbf{3236 $\\pm$ 18.5}\\\\\n    % PRB-Prior (10\\%-G)        & \\textbf{1521 $\\pm$ 17.6}  & \\textbf{1408 $\\pm$ 23.5} & \\textbf{1858 $\\pm$ 15.7} & \\textbf{3085 $\\pm$ 14.3}\\\\\n\n    \\bottomrule\n    \\end{tabular}%\n }\n \\caption{Cumulative regret of bandit-based methods on \\textbf{online} link prediction.}\n  \\label{tab:bandit-based res}%\n\\end{table*}",
            "tab:node classification res": "\\begin{table}[!ht]\n  \\centering\n\\scalebox{1.0}{\n\\begin{tabular}{lccc}\\\\\\toprule  \n\\multirow{2}[4]{*}{Methods} & Cora & Citeseer & Pubmed \\\\\n\\cmidrule{2-4} & Mean $\\pm$ Std & Mean $\\pm$ Std & Mean $\\pm$ Std\\\\\n%\\midrule      \n%EvePPR  & 4786 $\\pm$ 15.2 & 6364 $\\pm$ 21.9  & 2675 $\\pm$ 16.8 \\\\\n\\midrule\nEE-Net   & 1990 $\\pm$ 13.8 & 2299 $\\pm$ 33.4  & 1659 $\\pm$ 11.3 \\\\  \nNeuGreedy  & 2826 $\\pm$ 21.4 & 2543 $\\pm$ 24.6  & 1693 $\\pm$ 13.5 \\\\\nNeuralUCB & 2713 $\\pm$ 21.7 & 3101 $\\pm$ 22.0  & 1672 $\\pm$ 14.3 \\\\\nNeuralTS  & 1998 $\\pm$ 15.6 & 3419 $\\pm$ 39.5  & 1647 $\\pm$ 11.3 \\\\\n\\midrule\n% PRB-Greedy & 1932 $\\pm$ 24.1 & 2194 $\\pm$ 23.3  & 1634 $\\pm$ 12.3 \\\\\n\\textbf{PRB} & \\textbf{1874 $\\pm$ 25.6} & \\textbf{2168 $\\pm$ 35.7} & \\textbf{1577 $\\pm$ 10.7} \\\\\n% PRB-Prior (Full-G) & \\textbf{1804 $\\pm$ 23.5} & \\textbf{2158 $\\pm$ 33.1}  & 1630 $\\pm$ 11.5 \\\\\n\\bottomrule\n\\end{tabular}\n}\n\\vspace{2mm}\n\\caption{Cumulative regret of bandit-based methods on \\textbf{online} node classification.}\n\\label{tab:node classification res}\n\\end{table}",
            "tab:graph-based res": "\\begin{table*}[!t]\n  \\centering\n  \n    % Table generated by Excel2LaTeX from sheet 'Sheet3'\n    \\scalebox{0.78}{\n    \\begin{tabular}{lcccccc}\n    \\toprule\n    \\multirow{2}[7]{*}{Methods} &Cora  & Citeseer &  Pubmed & Collab & PPA & DDI\\\\\n    \\cmidrule{2-7} & HR@100  $\\pm$  Std & HR@100  $\\pm$  Std & HR@100  $\\pm$  Std & HR@50  $\\pm$  Std & HR@100  $\\pm$  Std & HR@20  $\\pm$  Std\\\\\n     \\midrule   \n     CN     & 33.92 $\\pm$ 0.46 & 29.79 $\\pm$ 0.90 & 23.13 $\\pm$ 0.15 & 56.44 $\\pm$ 0.00 & 27.65 $\\pm$ 0.00 & 17.73 $\\pm$ 0.00 \\\\\n     AA     & 39.85 $\\pm$ 1.34 & 35.19 $\\pm$ 1.33 & 27.38 $\\pm$ 0.11 & 64.35 $\\pm$ 0.00 & 32.45 $\\pm$ 0.00 & 18.61 $\\pm$ 0.00 \\\\\n     RA     & 41.07 $\\pm$ 0.48 & 33.56 $\\pm$ 0.17 & 27.03 $\\pm$ 0.35 & 64.00 $\\pm$ 0.00 & 49.33 $\\pm$ 0.00 & 27.60 $\\pm$ 0.00 \\\\\n     \\midrule\n     GCN    & 66.79 $\\pm$ 1.65 & 67.08 $\\pm$ 2.94 & 53.02 $\\pm$ 1.39 & 44.75 $\\pm$ 1.07 & 18.67 $\\pm$ 1.32 & 37.07 $\\pm$ 5.07 \\\\\n     SAGE   & 55.02 $\\pm$ 4.03 & 57.01 $\\pm$ 3.74 & 39.66 $\\pm$ 0.72 & 48.10 $\\pm$ 0.81 & 16.55 $\\pm$ 2.40 & 53.90 $\\pm$ 4.74 \\\\\n     \\midrule \n     SEAL & 81.71 $\\pm$ 1.30 & 83.89 $\\pm$ 2.15 & 75.54 $\\pm$ 1.32 & 64.74 $\\pm$ 0.43 & 48.80 $\\pm$ 3.16 & 30.56 $\\pm$ 3.86\\\\\n     NBFnet & 71.65 $\\pm$ 2.27 & 74.07 $\\pm$ 1.75 & 58.73 $\\pm$ 1.99 & OOM             & OOM                  & 4.00 $\\pm$ 0.58  \\\\\n     \\midrule\n     Neo-GNN& 80.42 $\\pm$ 1.31 & 84.67 $\\pm$ 2.16 & 73.93 $\\pm$ 1.19 & 57.52 $\\pm$ 0.37 & 49.13 $\\pm$ 0.60 & 63.57 $\\pm$ 3.52 \\\\\n     BUDDY  & 88.00 $\\pm$ 0.44 & 92.93 $\\pm$ 0.27 & 74.10 $\\pm$ 0.78 & 65.94 $\\pm$ 0.58 & 49.85 $\\pm$ 0.20 & 78.51 $\\pm$ 1.36 \\\\\n     \\midrule\n     NCN    & 89.05 $\\pm$ 0.96 & 91.56 $\\pm$ 1.43 & 79.05 $\\pm$ 1.16 & 64.76 $\\pm$ 0.87 & 61.19 $\\pm$ 0.85 & 82.32 $\\pm$ 6.10 \\\\\n     NCNC & 89.65 $\\pm$ 1.36 & 93.47 $\\pm$ 0.95 & 81.29 $\\pm$ 0.95 & 66.61 $\\pm$ 0.71 & 61.42 $\\pm$ 0.73 & 84.11 $\\pm$ 3.67 \\\\\n     \\midrule\n     \\textbf{PRB} & \\textbf{92.33 $\\pm$ 0.57} & \\textbf{95.13 $\\pm$ 1.28} & \\textbf{84.54 $\\pm$ 0.86} & \\textbf{67.29 $\\pm$ 0.31} & \\textbf{63.47 $\\pm$ 1.75} & \\textbf{88.31 $\\pm$ 4.36}  \n\n     \\\\\n    \\bottomrule\n    \\end{tabular}%\n }\n \\caption{Results on \\textbf{offline} link prediction benchmarks. OOM means out of GPU memory.}\n  \\label{tab:graph-based res}%\n\\end{table*}",
            "tab: ablation_study_PRB_compare": "\\begin{table*}[!t]\n\\vspace{-1em}\n\\scalebox{.75}{\n\\begin{tabular}{lccccccc}\\\\\\toprule  \n\\multirow{2}[8]{*}{Methods} & MovieLens & AmazonFashion& Facebook & GrQc & Cora & Citeseer & Pubmed \\\\\n\\cmidrule{2-8} & Mean $\\pm$ Std & Mean $\\pm$ Std & Mean $\\pm$ Std & Mean $\\pm$ Std & Mean $\\pm$ Std & Mean $\\pm$ Std & Mean $\\pm$ Std\\\\\n\\midrule      \nPRB & 1555 $\\pm$ 21.7 & 1455 $\\pm$ 18.4 & 1929 $\\pm$ 17.0 & 3236 $\\pm$ 18.5 & 1874 $\\pm$ 25.6 & 2168 $\\pm$ 35.7 & \\textbf{1577 $\\pm$ 10.7}\\\\\nPRB-Greedy  & 1892 $\\pm$ 15.1 & 1567 $\\pm$ 24.6 & 1994 $\\pm$ 23.6 & 3332 $\\pm$ 15.9 & 1932 $\\pm$ 24.1 & 2194 $\\pm$ 23.3  & 1634 $\\pm$ 12.3 \\\\\nPRB-(10\\%-G) & \\textbf{1521 $\\pm$ 17.6}  & \\textbf{1408 $\\pm$ 23.5} & \\textbf{1858 $\\pm$ 15.7} & \\textbf{3085 $\\pm$ 14.3} &\\textbf{1804 $\\pm$ 23.5} & \\textbf{2158 $\\pm$ 33.1} & 1630 $\\pm$ 11.5\\\\\n%PRB-Prior (Full-G) & - & - & - & - & \\textbf{1804 $\\pm$ 23.5} & \\textbf{2158 $\\pm$ 33.1} & 1630 $\\pm$ 11.5 \\\\\n\\bottomrule\n\\end{tabular}\n}\n\\vspace{2mm}\n\\caption{Cumulative regrets of PRB variants for online link prediction and node classification.}\n\\label{tab: ablation_study_PRB_compare}\n\\end{table*}",
            "tab:datasets": "\\begin{table}[h]\n\n\\centering\n\\begin{tabular}{lcccccc}\n\\toprule\n                 & \\textbf{Cora} & \\textbf{Citeseer} & \\textbf{Pubmed} & \\textbf{Collab} & \\textbf{PPA} & \\textbf{DDI} \\\\ \\midrule\n\\#Nodes          & 2,708         & 3,327             & 18,717          & 235,868         & 576,289      & 4,267      \\\\\n\\#Edges          & 5,278         & 4,676             & 44,327          & 1,285,465       & 30,326,273   & 1,334,889  \\\\\nSplits           & random        & random            & random          & fixed           & fixed        & fixed     \\\\\nAverage Degree   & 3.9           & 2.74              & 4.5             & 5.45            & 52.62        & 312.84   \\\\ \\bottomrule\n\\end{tabular}\n\\vspace{2mm}\n\\caption{Dataset Statistics}\n\\label{tab:datasets}\n\\end{table}",
            "lemma:newthetabound": "\\begin{restatable}{lemma}{newthetabound}\n\\label{lemma:newthetabound}\nSuppose $m, \\eta_1, \\eta_2$ satisfies the conditions in Theorem \\ref{theo:main}.\nIn round $t \\in [T]$, let $\\hi$ be the index selected by the algorithm.\nThen, For any $\\delta \\in (0, 1), R >0 $,  with probability at least $1-\\delta$, for $t \\in [T]$, it holds uniformly\n\\begin{equation}\n\\begin{aligned}\n\\frac{1}{t} \\sum_{\\tau=1}^t \\underset{ r_{\\tau, \\hi}}{\\bbe} \\left[   \\left| f_1(\\bx_{\\tau, \\hi}; \\btheta^1_{\\tau-1}) + f_2(\\phi(\\bx_{\\tau, \\hi}); \\btheta^2_{\\tau-1})   - r_{\\tau, \\hi} \\right| \\mid \\calh_{\\tau - 1} \\right] \\\\\n\\leq \\frac{ \\sqrt{ \\Psi(\\btheta_0, R) } + \\calo(1) } {\\sqrt{t}} +  \\sqrt{ \\frac{2  \\log ( \\calo(1)/\\delta) }{t}}.\n\\end{aligned}\n\\end{equation}\nwhere $  \\calh_{t} = \\{\\bx_{\\tau, \\hi}, r_{\\tau, \\hi} \\}_{\\tau =1}^t$ represents of historical data selected by ${\\pi_\\tau}$ and expectation is taken over the reward.\n\\end{restatable}"
        },
        "figures": {
            "fig:nodetransform": "\\begin{figure}[!t]\n\\centering\n    \\includegraphics[width= 0.7\\columnwidth]{sources/Images/rebuttal/nodeclass.png}\n    \\caption{\\textbf{Transforming Node Classification to Link Prediction}. Consider a binary node classification problem. In the left figure, given a graph, the learner tries to classify node 4 into one of two classes. First, we add two supernodes to the graph, each representing one of the classes. The node classification problem is then transformed into predicting links between node 4 and the two supernodes in the right figure. Suppose the learner predicts that a link will exist between node 4 and supernode 0. If node 4 belongs to Class 0, the reward is 1, and an edge is added between node 4 and supernode 0; otherwise, the reward is 0, and an edge is added between node 4 and supernode 1.}\n    \\label{fig:nodetransform}\n\\end{figure}",
            "fig:link_prediction": "\\begin{figure}[htp]\n\\centering\n    \\begin{minipage}[b]{0.24\\textwidth}\n        \\centering\n        \\includegraphics[width=\\textwidth]{sources/Images/link_prediction/MovieLens.png}\n    \\end{minipage}\n    \\hfill\n    \\begin{minipage}[b]{0.24\\textwidth}\n        \\centering\n        \\includegraphics[width=\\textwidth]{sources/Images/link_prediction/AmazonFashion.png}\n    \\end{minipage}\n    \\hfill\n    \\begin{minipage}[b]{0.24\\textwidth}\n        \\centering\n        \\includegraphics[width=\\textwidth]{sources/Images/link_prediction/Facebook.png}\n    \\end{minipage}\n    \\hfill\n    \\begin{minipage}[b]{0.24\\textwidth}\n        \\centering\n        \\includegraphics[width=\\textwidth]{sources/Images/link_prediction/GrQc.png}\n    \\end{minipage}\n    \n    \\caption{Regret comparison of bandit-based methods on \\textbf{online} link prediction datasets (average of 10 runs with standard deviation in shadow, detailed in Table \\ref{tab:bandit-based res}).}\n    \\label{fig:link_prediction}\n\\end{figure}",
            "fig:node_classification": "\\begin{figure}[!ht]\n    \\centering\n    \\includegraphics[width= 0.33 \\columnwidth]{sources/Images/node_classification/Cora.png}\\hfill \n    \\includegraphics[width= 0.33 \\columnwidth]{sources/Images/node_classification/Citeseer.png}\\hfill \n    % \\vspace{5mm}\n    \\includegraphics[width= 0.33 \\columnwidth]{sources/Images/node_classification/Pubmed.png}\\hfill \n    \\caption{Regret comparison of bandit-based methods on \\textbf{online} node classification datasets (average of 10 runs with standard deviation in shadow, detailed in Table \\ref{tab:node classification res}.}\n    \\label{fig:node_classification}\n\\end{figure}",
            "fig:running_time": "\\begin{figure}[!ht]\n    \\centering\n    \\includegraphics[width= 0.8 \\columnwidth]{sources/Images/running_time/PPB_baseline.png}\\hfill\n    \\caption{Running time comparison of \\sysn and bandit-based baselines.}\n    \\label{fig:running_time}\n\\end{figure}",
            "fig:EE_RandomWalk": "\\begin{figure}[!ht]\n    \\centering\n    \\includegraphics[width=0.45 \\columnwidth]{sources/Images/running_time/PRB_Greedy.png} \n    \\includegraphics[width= 0.45 \\columnwidth]{sources/Images/running_time/PRB.png}\n    \\caption{Proportion of running time for PRB-Greedy (left) and PRB (right) between exploitation-exploration and random walk.} \n    \\label{fig:EE_RandomWalk}\n\\end{figure}",
            "fig:PRB_compare": "\\begin{figure}[htp]\n    \\centering\n    \\includegraphics[width=0.40\\columnwidth]{sources/Images/PRB_compare/MovieLens.png} \n    \\includegraphics[width=0.40\\columnwidth]{sources/Images/PRB_compare/AmazonFashion.png} \n    \\includegraphics[width=0.40\\columnwidth]{sources/Images/PRB_compare/Facebook.png} \n    \\includegraphics[width=0.40\\columnwidth]{sources/Images/PRB_compare/GrQc.png}\n    \\includegraphics[width=0.40\\columnwidth]{sources/Images/PRB_compare/Cora.png} \n    \\includegraphics[width=0.40\\columnwidth]{sources/Images/PRB_compare/Citeseer.png} \n    \\includegraphics[width=0.40\\columnwidth]{sources/Images/PRB_compare/Pubmed.png}\n    \\caption{Regret Comparison of PRB-Greedy, PRB, and PRB-Prior (mean of 10 runs with standard deviation in shadow, detailed in Table \\ref{tab: ablation_study_PRB_compare} and \\ref{tab:bandit-based res}).}\n    \\label{fig:PRB_compare}\n\\end{figure}",
            "fig:PRB_EvePPR_EEnet": "\\begin{figure}[htp]\n    \\centering\n    \\includegraphics[width=0.40\\columnwidth]{sources/Images/PRB_EvePPR_EEnet/MovieLens.png}\n    \\includegraphics[width=0.40\\columnwidth]{sources/Images/PRB_EvePPR_EEnet/AmazonFashion.png}\n    \\includegraphics[width=0.40\\columnwidth]{sources/Images/PRB_EvePPR_EEnet/Facebook.png}\n    \\includegraphics[width=0.40\\columnwidth]{sources/Images/PRB_EvePPR_EEnet/GrQc.png}\n    \\includegraphics[width=0.40\\columnwidth]{sources/Images/PRB_EvePPR_EEnet/Cora.png}\n    \\includegraphics[width=0.40\\columnwidth]{sources/Images/PRB_EvePPR_EEnet/Citeseer.png} \n    \\includegraphics[width=0.40\\columnwidth]{sources/Images/PRB_EvePPR_EEnet/Pubmed.png}\n    \\caption{Regret Comparison of PRB, EEnet, and EvePPR (mean of 10 runs with standard deviation in shadow, detailed in Table \\ref{tab:bandit-based res}).}\n    \\label{fig:PRB_EvePPR_EEnet}\n\\end{figure}"
        },
        "equations": {
            "eq:1": "\\begin{equation} \\label{eq:regretdef}\n\\begin{aligned}\n    \\mathbf{R}_T  = \\sum_{t=1}^T \\left (  \\bbe_{r_{t, i^\\ast} \\sim  \\cald_{\\caly|x_{t,i^\\ast}}} [ r_{t, i^\\ast}]    -   \\bbe_{r_{t, \\hi} \\sim  \\cald_{\\caly|x_{t, \\hi}}} [ r_{t, \\hi}]  \\right)  = \\bbp(r_{t, i^\\ast} =1 | x_{t, i^\\ast}) - \\bbp(r_{t, \\hi} =1 | x_{t, \\hi})\n\\end{aligned}\n\\end{equation}",
            "eq:2": "\\begin{equation}\n    \\mathcal{R}_T =  \\sum_{t=1}^T (r_t^\\ast  - r_{t, \\hi}),\n\\end{equation}",
            "eq:3": "\\begin{equation}\nr_{t,i} = y\\left(\\bx_{t,i}\\right) + \\eta_{t,i}\n\\end{equation}",
            "eq:4": "\\begin{equation}\n\\mathbf{R}_r(T) =  \\mathbb{E}\\left[\\sum_{t=1}^T \\left(r_{t, i^\\ast} - r_{t, i_t} \\right) \\right] = \\sum_{t=1}^T \\left( \\by_t[i^\\ast]  -   \\by_t[i_t]  \\right)\n\\end{equation}",
            "eq:5": "\\begin{equation}\n\\bv_t^\\ast  = \\arg \\min_{\\bv}  \\alpha  \\underset{I_1}{\\bv^{\\top} (\\mathbf{I} - \\bp_t) \\bv} + \\underset{I_2}{(1-\\alpha) \\|\\bv - \\by_t\\|_2^2}\n\\end{equation}",
            "eq:6": "\\begin{equation}\n\\mathbf{R}_c(T) = \\sum_{t=1}^T \\left( \\bv_t^\\ast[i^\\ast] - \\bv_t^\\ast[i_t]  \\right)\n\\end{equation}",
            "eq:eq:pagerankvector": "\\begin{equation}\\label{eq:pagerankvector}\n\\bv_t = \\alpha  \\rmP_t \\bv_t + \\left(1-\\alpha\\right) \\rvh_t\n\\end{equation}",
            "eq:7": "\\begin{equation}\n    i \\in \\calv_t, \\bh_t[i] =  f_1(\\bx_{t, i} ; \\btheta^1_{t-1}) + f_2(x_{t,i}; \\theta^2_{t-1}), \\  \\text{and} \\  \\  i \\in  V/\\calv_t, \\bh_t[i] = 0. \n\\end{equation}",
            "eq:8": "\\begin{equation}\n\\bbe[\\tilde{r}_{t,i} | v_t, v_{t,i}] = y\\left(\\bx_{t,i}\\right) \n\\end{equation}",
            "eq:9": "\\begin{equation}\n\\bv_t^\\ast = \\alpha  \\rmP_t \\bv_t^\\ast + \\left(1-\\alpha\\right) \\by_t.\n\\end{equation}",
            "eq:10": "\\begin{equation}\n\\mathbf{R}_T  = \\sum_{t=1}^T \\left ( \\bv_t^\\ast[i^\\ast]   - \\bv_t^\\ast[\\hi] \\right).\n\\end{equation}",
            "eq:11": "\\begin{equation} \\label{eq:structure}\nf(\\bx_{t,i}; \\theta) = \\bw_L \\sigma ( \\bw_{L-1}  \\sigma (\\bw_{L-2} \\dots  \\sigma(\\bw_1 \\bx_{t,i}) ))\n\\end{equation}",
            "eq:12": "\\begin{equation}\nf(\\bx; \\theta) = \\bw_L (\\prod_{l=1}^{L-1} \\bD_l \\bw_l) \\bx,\n\\end{equation}",
            "eq:13": "\\begin{equation}\n\\nabla_{\\bw_l}f  = \n\\begin{cases}\n[\\bh_{l-1}\\bw_L (\\prod_{\\tau=l+1}^{L-1} \\bD_\\tau \\bw_\\tau)]^\\top, l \\in [L-1] \\\\\n\\bh_{L-1}^\\top,   l = L .\n\\end{cases}\n\\end{equation}",
            "eq:14": "\\begin{equation}\n    B(\\theta_0, R) = \\{ \\theta \\in \\bbr^p:  \\| \\theta - \\theta_0\\|_2 \\leq R/m^{1/4}\\}.\n\\end{equation}",
            "eq:15": "\\begin{equation} \\label{complexityfunction}\n\\Psi(\\btheta_0, R) = \\underset{\\btheta \\in  \\calb(\\btheta_0, R)}{\\inf} \\sum_{t=1}^{Tk} (f_2(\\bx_t; \\btheta) - r_t)^2 \n\\end{equation}"
        },
        "git_link": "https://github.com/jiaruzouu/PRB"
    }
}