{
    "meta_info": {
        "title": "Neural Bandit with Arm Group Graph",
        "abstract": "Contextual bandits aim to identify among a set of arms the optimal one with\nthe highest reward based on their contextual information. Motivated by the fact\nthat the arms usually exhibit group behaviors and the mutual impacts exist\namong groups, we introduce a new model, Arm Group Graph (AGG), where the nodes\nrepresent the groups of arms and the weighted edges formulate the correlations\namong groups. To leverage the rich information in AGG, we propose a bandit\nalgorithm, AGG-UCB, where the neural networks are designed to estimate rewards,\nand we propose to utilize graph neural networks (GNN) to learn the\nrepresentations of arm groups with correlations. To solve the\nexploitation-exploration dilemma in bandits, we derive a new upper confidence\nbound (UCB) built on neural networks (exploitation) for exploration.\nFurthermore, we prove that AGG-UCB can achieve a near-optimal regret bound with\nover-parameterized neural networks, and provide the convergence analysis of GNN\nwith fully-connected layers which may be of independent interest. In the end,\nwe conduct extensive experiments against state-of-the-art baselines on multiple\npublic data sets, showing the effectiveness of the proposed algorithm.",
        "author": "Yunzhe Qi, Yikun Ban, Jingrui He",
        "link": "http://arxiv.org/abs/2206.03644v2",
        "category": [
            "cs.LG",
            "stat.ML"
        ],
        "additionl_info": "Accepted to SIGKDD 2022"
    },
    "latex_extraction": {
        "content": {
            "section 1": {
                "name": "Introduction",
                "content": " \\label{sec_introduction}\nContextual bandits are a specific type of multi-armed bandit (MAB) problem where the learner has access to the contextual information (contexts) related to arms at each round, and the learner is required to make recommendations based on past contexts and received rewards.\nA variety of models and algorithms have been proposed and successfully applied on real-world problems, such as online content and advertising recommendation \\cite{linucb-Ind_li2010contextual,colla_environ_2016}, clinical trials \\cite{MAB_clinical_trial-durand2018contextual,MAB_clinical_trial_2_villar2015multi} and virtual support agents \\cite{virtual_support_bot_sajeev2021contextual}.\n\nIn this paper, we focus on exploiting the accessible arm information to improve the performance of bandit algorithms. \nAmong different types of contextual bandit algorithms, upper confidence bound (UCB) algorithms have been proposed to balance between exploitation and exploration \\cite{UCB_auer2002finite,Lin_UCB-2011,kernel_ucb-2013}. For conventional UCB algorithms, they are either under the \"pooling setting\" \\cite{Lin_UCB-2011}\nwhere one single UCB model is applied for all candidate arms, or the \"disjoint setting\" \\cite{linucb-Ind_li2010contextual} where each arm is given its own estimator without the collaboration across different arms. Both settings have their limitations: applying only one single model may lead to unanticipated estimation error when some arms exhibit distinct behaviors \\cite{dynamic_ensemble_wu2019dynamic,colla_environ_2016}; on the other hand, assigning each arm its own estimator neglects the mutual impacts among arms and usually suffers from limited user feedback \\cite{CAB_2017,local_clustering-ban2021local}.\n\n\nTo deal with this challenge, adaptively assigning UCB models to arms based on their group information can be an ideal strategy, i.e., each group of arms has one estimator to represent its behavior. This modeling strategy is linked to \"arm groups\" existing in real-world applications.\n%the accessible \\textit{arm group information} associated with the arms can potentially inform a better arm selection strategy, as arms are linked to natural arm groups in many real-world application scenarios. \n%For example, regarding the online movie recommendation scenario, the platform will have easy access to the group information of arms (movies), such as the genre for movies. With each genre being a group of movies, the movies for recommendation are linked to their arm groups.\nFor example, regarding the online movie recommendation scenario, the movies (arms) with the same genre can be assigned to one (arm) group. \nAnother scenario is the drug development, where given a new cancer treatment and a patient pool, we need to select the best patient on whom the treatment is most effective. Here, the patients are the arms, and they can be naturally grouped by their non-numerical attributes, such as the cancer types.\nSuch group information is easily accessible, and can significantly improve the performance of bandit algorithms. \n%%%%%%%%%%%%\n% One work ~\\cite{co_filter_bandits_2016} has been proposed to leverage such group information. However, this work suffers from two limitations. First, it relies on the linear reward assumption,  which may not hold in real-world applications \\cite{Neural-UCB}. Second, it neglects the correlations among arm groups.\n% We emphasize that the correlations among arm groups also play indispensable roles in many decision-making scenarios.\n% For example, in online movie recommendation, with each genre being a group of movies, the users who like \"adventure movies\" may also appreciate \"action movies\". In the drug development, since the alternation of some genes may lead to multiple kinds of tumors \\cite{correlated_cancer-shao2019copy}, different types of cancer can also be significantly correlated.\n% \\cite{kmtl-ucb_2017} embeds arms into a kernel space and tends to capture correlations among arms, but it does not incorporate any group information. Moreover, it is based on the kernel-based parametric reward assumption, which may fail in real-world applications ~\\cite{Neural-UCB}. \n%\nAlthough some works ~\\cite{co_filter_bandits_2016,kmtl-ucb_2017} have been proposed to leverage the arm correlations, they can suffer from two common limitations. First, they rely on the assumption of parametric (linear / kernel-based) reward functions, which may not hold in real-world applications \\cite{Neural-UCB}. Second, they both neglect the correlations among arm groups.\nWe emphasize that the correlations among arm groups also play indispensable roles in many decision-making scenarios.\nFor instance, in online movie recommendation, with each genre being a group of movies, the users who like \"adventure movies\" may also appreciate \"action movies\". Regarding drug development, since the alternation of some genes may lead to multiple kinds of tumors \\cite{correlated_cancer-shao2019copy}, different types of cancer can also be correlated to some extent. \n% \\cite{} embeds arms into a kernel space and tends to capture correlations among arms, but it does not incorporate any group information. Moreover, it is based on the kernel-based parametric reward assumption, which may fail in real-world applications ~\\cite{Neural-UCB}. \n\n%%%%%%%%%%%%\n\n\\iffalse\nparametric assumption \n%\\ban{check here}\\yunzhe{Updated} \nof the reward function (linear \\cite{co_filter_bandits_2016} or kernel-based regressions \\cite{kmtl-ucb_2017}), which may not hold in real-world applications \\cite{Neural-UCB}. Second, they neglect either group information \\cite{kmtl-ucb_2017} or the correlations among arm groups \\cite{co_filter_bandits_2016}.\n\nsuch as~\\cite{co_filter_bandits_2016, kmtl-ucb_2017}. However, most (if not all) of them suffer from two limitations. First, they rely on the parametric assumption \n%\\ban{check here}\\yunzhe{Updated} \nof the reward function (linear \\cite{co_filter_bandits_2016} or kernel-based regressions \\cite{kmtl-ucb_2017}), which may not hold in real-world applications \\cite{Neural-UCB}. Second, they neglect either group information \\cite{kmtl-ucb_2017} or the correlations among arm groups \\cite{co_filter_bandits_2016}.\n%\\he{What do you mean they neglect group information? The have proposed to leverage the group information, right?}\nWe emphasize that the correlations among arm groups also play indispensable roles in many decision making.\nFor example, in online movie recommendation, with each genre being a group of movies, the users who like \"adventure movies\" may also appreciate \"action movies\". In the drug development, since the alternation of some genes may lead to multiple kinds of tumors \\cite{correlated_cancer-shao2019copy}, different types of cancers can also be significantly correlated. \nHowever, \\cite{co_filter_bandits_2016,kmtl-ucb_2017} has two limitations.\n\\fi\n\n\n%\\ban{I suggest, don't talk about \\cite{kmtl-ucb_2017} here. Because \\cite{kmtl-ucb_2017} neglects the group information by leverage the correlations among arms (not groups).}\n\n%which are eminently informative for predicting the treatment result. In this way, each arm group is associated with an unknown distribution, and we can regard the received arms as samples drawn from the context distributions of their respective arm groups.\n\n% \\hide{Motivated by the above observations, \\cite{co_filter_bandits_2016} clusters arms with the same expected rewards into one group and assigns one linear UCB model to each group respectively, to represent the group's behavior for making decisions; \\cite{kmtl-ucb_2017} embeds arms into a kernel space and tends to capture correlations among arms.\n% However, \\cite{co_filter_bandits_2016,kmtl-ucb_2017} has two limitations.}\n\n\n\n\n\n%Despite the solutions for modeling user relationship \\cite{club_2014,SCLUB_li2019improved,local_clustering-ban2021local}, existing work from the arm side \\cite{co_filter_bandits_2016} adopts a parametric model and relies on the linear assumption of the reward function, which may lead to additional estimation error when the underlying reward mapping is non-linear. \n%In addition, due to its negligence of correlations among arm groups, there may exist another performance bottleneck for the existing work since different pairs of arm groups may have different levels of relatedness in terms of, e.g., the estimated reward functions. For example, in online movie recommendation, with each genre being a group of movies, some genres (groups) are highly correlated, such as \"war movies\" and \"action movies\" as opposed to the pair of \"action movies\" and \"documentaries\".\n\n\n\n% Different from some existing works that model the correlations among arms\\he{give some reference}, we propose to model the correlations among arm groups\\he{given one sentence justification here.}\n% \\ban{Compared to \\cite{kmtl-ucb_2017}, this work has two additional advantages, (1) leverage the correlations among groups; (2) non-linear reward assumptions. So, should stress this here and can well-motivate this work.}\n% \\ban {I suggest this should be the third paragraph to motivate our work, following real-world examples}.\n% \\ban{I suggest introduce \"ach arm group is associated with an unknown distribution\" here, then give the following examples}\n% \\ban{Then, stress  \"the correlations among groups exist and we aim to leverage these correlations\".  Next, based on above examples, give new demonstrations}\n\n%Therefore, when such arm group information is available, this problem setting can model this extra information and conceivably offer learners an extra opportunity for better arm selections by collaborating correlated arm groups.\n\n\n%Regarding the huge improvement of neural models made by neural contextual bandits algorithms compared with conventional algorithms \\cite{Neural-UCB,neural_thompson-zhang2020neural,neural_multifacet-ban2021multi}, we propose to collaborate different neural modules to overcome the fore-mentioned performance bottleneck.\n\n%---\n% \\ban{To utilize correlations among groups, we introduce graph to formulate (represent) and then leverage GNN to learn the correlations.}\n\n\n\n%Therefore, to address these two potential performance bottlenecks, we propose to apply neural networks to learn from the arm group correlations and estimate rewards for the received arms without a parametric assumption on the reward function.\n\nTo address these limitations, we first introduce a novel model, AGG (Arm Group Graph), to formulate non-linear reward assumptions and arm groups with correlations. In this model, as arm attributes are easily accessible (e.g., movie's genres and patient's cancer types), the arms with the same attribute are assigned into one group, and represented as one node in the graph.\nThe weighted edge between two nodes represents the correlation between these two groups. \nIn this paper, we assume the arms from the same group are drawn from one unknown distribution. This also provides us with an opportunity to model the correlation of two arm groups by modeling the statistical distance between their associated distributions. Meantime, the unknown non-parametric reward mapping function can be either linear or non-linear.\n\n\n\nThen, with the arm group graph, we propose the \\name\\ framework for contextual bandits. It applies graph neural networks (GNNs) to learn the representations of arm groups with correlations, and neural networks to estimate the reward functions (exploitation).\n%To exploit the fore-mentioned arm group relevance, we first formulate arm groups into an estimated arm group graph (i.e., each node is an arm group), and then leverage the graph neural network (GNN) to associate received arm contexts with related arm groups. \n%GNNs are a kind of neural network designed for learning from graph data and other topological structures \\cite{fastGCN-chen2018fastgcn,SGC_wu2019simplifying,light_GCN-he2020lightgcn,APPNP-klicpera2018predict}. \nIn particular, with the collaboration across arm groups, each arm will be assigned with the group-aware arm representation learned by GNN, which will be fed into a fully-connected (FC) network for the estimation of arm rewards.\nTo deal with the exploitation-exploration dilemma, we also derive a new upper confidence bound based on network-gradients for exploration.\nBy leveraging the arm group information and modeling arm group correlations, our proposed framework provides a novel arm selection strategy for dealing with the aforementioned challenges and limitations.\n%In particular, graph convolutional network (GCN) \\cite{GCN_kipf2016semi} and its variants \\cite{fastGCN-chen2018fastgcn,SGC_wu2019simplifying,light_GCN-he2020lightgcn,APPNP-klicpera2018predict} have proved their superiority on various real world applications such as biological engineering \\cite{GNN_biology-lim2019predicting} and social relationship modeling \\cite{GNN_social-fan2019graph}. Regarding received arm contexts as input graph signal where nodes are their associated arm groups, our goal is to collaborate received arm contexts with the topological information from the estimated arm group graph. \n%  which can be considered as low-pass filters on the input graph signals \\cite{GNN_Low_pass_filter_hoang2021revisiting,SGC_wu2019simplifying}, \n%With the introduced problem settings and all the motivations mentioned above, we propose a novel UCB framework named \\name, which applies the GNN architecture to learn from the arm group correlations encoded in an estimated arm group graph. With the collaboration across highly related arm groups, each received arm will be assigned with a group-aware arm representation. The aggregated representation will then be fed into a fully-connected (FC) network for the estimation of arm rewards. To balance the trade-off between exploitation and exploration, we also derive an upper confidence bound for each arm based on network-gradients. By exploiting the arm group information and modeling arm group correlations, our proposed framework provides a refined arm selection strategy for dealing with the fore-mentioned performance bottlenecks.\nOur main contributions can be summarized as follows: \n\\begin{itemize}\n    \\item First, motivated by real-world applications, we introduce a new graph-based model in contextual bandits to leverage the available group information of arms and exploit the potential correlations among arm groups.\n    \\item Second, we propose a novel UCB-based neural framework called \\name~ for the graph-based model. To exploit the relationship of arm groups, \\name~ estimates the arm group graph with received contexts on the fly, and utilizes GNN to learn group-aware arm representations.\n    % By generating a comprehensive group-aware representation for each received arm for the reward and upper confidence bound estimation.\n    \\item Third,  we prove that AGG-UCB can achieve a near-optimal regret bound in the over-parameterized neural works, and provide convergence analysis of GNN with fully-connected layers, which may be of independent interest.\n    \\item Finally, we conduct experiments on publicly available real data sets, and demonstrate that our framework outperforms state-of-the-art techniques. Additional studies are conducted to understand the properties of the proposed framework.\n\\end{itemize}\n\nThe rest of this paper is organized as following. In Section \\ref{sec_related_works}, we briefly discuss related works. Section \\ref{sec_problem_def} introduces the new problem settings, and details of our proposed framework \\name~ will be presented in Section \\ref{sec_proposed_framework}. Then, we provide theoretical analysis for \\name~in Section \\ref{sec_theoretical_analysis}. After presenting experimental results in Section \\ref{sec_experiments}, we finally conclude the paper in Section \\ref{sec_conclusion}. Due to the page limit, readers may refer to our arXiv version of the paper for the supplementary contents \n%\n(\\url{https://arxiv.org/abs/2206.03644}). \n\n\n\n\n%%% --------------------------------------Related Works\n"
            },
            "section 2": {
                "name": "Related Works",
                "content": " \\label{sec_related_works}\nIn this section, we briefly review the related work on contextual bandits.\nLin-UCB \\cite{Lin_UCB-2011} first formulates the reward estimation through a linear regression with the received context and builds a confidence bound accordingly. Kernel-UCB \\cite{kernel_ucb-2013} further extends the reward mapping to the Reproducing Kernel Hilbert Space (RKHS) for the reward and confidence bound estimation under non-linear settings. Besides, there are algorithms under the non-linear settings. Similarly, CGP-UCB \\cite{CGP_krause2011contextual} models the reward function through a Gaussian process. GCN-UCB \\cite{GCN_UCB-upadhyay2020online} applies the GNN model to learn each context an embedding for the linear regression.\nThen, Neural-UCB \\cite{Neural-UCB} proposes to apply FC neural network for reward estimations and derive a confidence bound with the network gradient, which is proved to be a success, and similar ideas has been applied to some other models \\cite{neural_multifacet-ban2021multi,neural_thompson-zhang2020neural,CNN_UCB-ban2021convolutional}. \n\\cite{ban2022eenet} assigns another FC neural network to learn the confidence ellipsoid for exploration.\nYet, as these works consider no collaboration among estimators, they may suffer from the performance bottleneck in the introduction. \n\nTo collaborate with different estimators for contextual bandits, various approaches are proposed from different perspectives. User clustering algorithms \\cite{club_2014,SCLUB_li2019improved,local_clustering-ban2021local,Ban2022NeuralCF} try to cluster user with alike preferences into user groups for information sharing while COFIBA \\cite{co_filter_bandits_2016} additionally models the relationship of arms. \nThen, KMTL-UCB \\cite{kmtl-ucb_2017} extends Kernel-UCB to multi-task learning settings for a refined reward and confidence bound estimation. \nHowever, these works may encounter with performance bottlenecks as they incline to make additional assumptions on the reward mapping by applying parametric models and neglect the available arm group information.\n\nGNNs \\cite{GCN_kipf2016semi,SGC_wu2019simplifying,APPNP-klicpera2018predict,SDG_fu2021sdg} are a kind of neural models that deal with tasks on graphs, such as community detection \\cite{GNN_community_detection-you2019position}, recommender systems \\cite{GNN_Rec_wei2020fast} and modeling protein interactions \\cite{DPPIN_fu2021dppin}. \nGNNs can learn from the topological graph structure information and the input graph signal simultaneously, which enables \\name~ to cooperate with different arm groups by sharing information over the arm group neighborhood.\n\n\n%%% ------------------------------------------------------------------\n\n"
            },
            "section 3": {
                "name": "Problem Definition and Notation",
                "content": " \\label{sec_problem_def}\nWe suppose a fixed pool $\\mathcal{C} = \\{1, \\dots, N_{c}\\}$ for arm groups with the number of arm groups being $\\abs{\\mathcal{C}} = N_{c}$, and assume each arm group $c \\in \\mathcal{C}$ is associated with an unknown fixed context distribution $\\mathcal{D}_{c}$. At each time step $t$, we will receive a subset of groups $\\mathcal{C}_{t} \\subseteq \\mathcal{C}$.\n%\\ban{the notations subset and set are too similar. Can use $C$ to represent arm groups. }  \nFor each group $c \\in \\mathcal{C}_{t}$, we will have the set of sampled arms $\\mathcal{X}_{c, t} = \\{\\vect{x}^{(1)}_{c, t}, \\cdots \\vect{x}^{(n_{c, t})}_{c, t}\\}$ with the size of $\\abs{\\mathcal{X}_{c, t}} = n_{c, t}$.\nThen, $\\forall i \\in [n_{c, t}] = \\{1, \\dots,  n_{c, t}\\}$, we suppose $\\vect{x}^{(i)}_{c, t} \\sim \\mathcal{D}_{c}$ with the dimensionality $\\vect{x}^{(i)}_{c, t} \\in \\mathbb{R}^{d_{x}}$. \nTherefore, in the $t$-th round, we receive\n\\begin{equation}\n\\{ \\mathcal{X}_{c, t} | c \\in  \\mathcal{C}_{t}\\}  \\ \\text{and} \\  \\mathcal{X}_{c, t} = \\{\\vect{x}^{(1)}_{c, t}, \\cdots \\vect{x}^{(n_{c, t})}_{c, t}\\}, \\forall c \\in  \\mathcal{C}_{t}.\n\\end{equation}\nWith $\\matr{W}^{*} \\in \\mathbb{R}^{N_{c}\\times N_{c}}$ being the unknown affinity matrix encoding the true arm group correlations, the true reward $r_{c, t}^{(i)}$ for arm $\\vect{x}^{(i)}_{c, t}$ is defined as\n\\begin{equation}\n\\begin{split}\n    r_{c, t}^{(i)} = h(\\matr{W}^{*}, ~~ \\vect{x}^{(i)}_{c, t}) + \\epsilon^{(i)}_{c, t}\n\\end{split}\n\\label{reward_func_defi}\n\\end{equation}\nwhere $h(\\cdot)$ represents the unknown reward mapping function, \n% of a sampled arm $\\vect{x}^{(i)}_{c, t}$ associated with group $c$\nand $\\epsilon$ is the zero-mean Gaussian noise. \nFor brevity, let $\\vect{x}_{t}$ be the arm we select in round $t$ and $r_t$ be the corresponding received reward.\n\nOur goal is recommending arm $\\vect{x}_{t}$ (with reward $r_{t}$) \n% \\ban{why use $a$ here, it is confusing showing up here. It is better use $i$ because of below} \nat each time step $t$ to minimize the cumulative pseudo-regret $R(T) = \\sum_{t=1}^{T} \\mathbb{E}\\left[  (r_{t}^{*} -  r_{t}) \\right]$ where $\\mathbb{E}[r_{t}^{*}] = \\max_{(c\\in\\mathcal{C}_{t}, i\\in [n_{c, t}])} \\big[h(\\matr{W}^{*}, \\vect{x}^{(i)}_{c, t})\\big]$. \nAt each time step $t$, the overall set of received contexts is defined as $\\mathcal{X}_{t} = \\{ \\vect{x}^{(i)}_{c, t} \\}_{c \\in \\mathcal{C}_{t}, i\\in [n_{c, t}]}$. \nNote that one arm is possibly associated with multiple arm groups, such as a movie with multiple genres. In other words, for some $c, c'\\in \\mathcal{C}_{t}$, we may have $\\mathcal{X}_{c, t} \\cap \\mathcal{X}_{c', t} \\neq \\emptyset$.\n\nIn order to model the arm group correlations, we maintain an undirected graph $\\mathcal{G}_{t} = (V, E, W_{t})$ at each time step $t$, where each arm group from $\\mathcal{C}$ is mapped to a corresponding node in node set $V$. Then, $E = \\{e(c_{i}, c_{j})\\}_{c_{i}, c_{j}\\in \\mathcal{C}}$ is the set of edges, and $W_{t}$ represents the set of edge weights. Note that by definition, $\\mathcal{G}_{t}$ will stay as a fully-connected graph, and the estimated arm group correlations are modeled by the edge weights connecting pairs of nodes.\nFor a node $v \\in V$, we denote the augmented $k$-hop neighborhood $\\widetilde{\\mathcal{N}}_{k}(v) = \\mathcal{N}_{k}(v) \\cup \\{v\\}$ as the union node set of its $k$-hop neighborhood $\\mathcal{N}_{k}(v)$ and node $v$ itself. For the arm group graph $\\mathcal{G}_{t}$, we denote $\\matr{A}_{t} \\in \\mathbb{R}^{N_{c} \\times N_{c}}$ as the adjacency matrix (with added self-loops) of the given arm group graph and $\\matr{D}_{t} \\in \\mathbb{R}^{N_{c} \\times N_{c}}$ as its degree matrix. For the notation consistency, we will apply a true arm group graph $\\mathcal{G}^{*}$ instead of $\\matr{W}^{*}$ in \\textbf{Eq.} \\ref{reward_func_defi} to represent the true arm group correlation.\n%%% ------------------------------------------------------------------\n\n% ------------------------------------ Algorithm\n"
            },
            "section 4": {
                "name": "Proposed \\name~Framework",
                "content": " \\label{sec_proposed_framework}\nIn this section, we start with an overview to introduce our proposed \\name~framework.\nThen, we will show our estimation method of arm group graph before mentioning the related group-aware arm embedding. Afterwards, the two components of our proposed framework, namely the aggregation module and the reward-estimation module, will be presented.\n\n\\vspace{-0.2cm}\n% -------------------------------------------\n",
                "subsection 4.1": {
                    "name": "Overview of \\name~Framework",
                    "content": "\nIn \\textbf{Algorithm \\ref{algo_1}}, we present the pseudo-code of proposed \\name~framework.\n%\n% \\newlength{\\textfloatsepsave} \n% \\setlength{\\textfloatsepsave}{\\textfloatsep} \n\\setlength{\\textfloatsep}{10pt}  \n%\n\\begin{algorithm}[t]\n\\caption{\\name}\n\\label{algo_1}\n\\textbf{Input:} Number of rounds $T$, exploration parameter $\\gamma$, regularization parameter $\\lambda$, network width $m$, network depth $L$, neighborhood size $k$. \\\\\n\\textbf{Output:} Arm recommendation $\\vect{x}_{t}$ for each time step $t$.\\\\\n\\textbf{Initialization:} Initialize the arm group graph as a connected graph $\\mathcal{G}_{1} = (V, E, W_{1})$. Initialize gradient matrix $\\matr{Z_{0}}=\\lambda\\matr{I}$. Initialize parameter $\\vect{\\Theta_{0}}$ for the model $f(\\mathcal{G}, X;\\vect{\\Theta_{0}})$.\\\\\n\\For{$t = 1, 2, ..., T$}{\n    Receive a set of arm contexts $\\mathcal{X}_{t} = \\{ \\vect{x}^{(i)}_{c, t} \\}_{c \\in \\mathcal{C}_{t}, i\\in [n_{c, t}]}$.\\\\\n    Embed the arm set $\\mathcal{X}_{t}$ into $\\widetilde{\\mathcal{X}}_{t}$ w.r.t. \\textbf{Eq.}\\ref{new_embed_eq}.\\\\\n    \\For{each embedded arm $\\widetilde{\\matr{X}}^{(i)}_{c, t} \\in \\widetilde{\\mathcal{X}}_{t}$}{\n        Obtain the point estimate $\\widehat{r}^{(i)}_{c, t} = f(\\mathcal{G}_{t}, \\widetilde{\\matr{X}}^{(i)}_{c, t}; \\vect{\\Theta_{t-1}})$.\\\\\n        Obtain network gradient $\\vect{g}^{(i)}_{c, t} \\xleftarrow{} \\nabla_{\\Theta}f(\\mathcal{G}_{t}, \\widetilde{\\matr{X}}^{(i)}_{c, t}; \\vect{\\Theta_{t-1}})$. \\\\\n        Calculate confidence bound as $\\widehat{i}^{(i)}_{c, t} = \\sqrt{\\vect{g}_{c, t}^{(i)\\intercal}\\matr{Z}_{t-1}\\vect{g}^{(i)}_{c, t} / m}$. \\\\\n    }\n    Recommend $\\widetilde{\\matr{X}}_{t} = \\operatorname*{argmax}_{\\widetilde{\\matr{X}}^{(i)}_{c, t} \\in \\widetilde{\\mathcal{X}}_{t}} (\\widehat{r}^{(i)}_{c, t} + \\gamma\\cdot\\widehat{i}^{(i)}_{c, t})$ with the received reward represented as $r_{t}$. \\\\\n    Calculate arm group distances w.r.t. \\textbf{Eq.}\\ref{arm_similarity_eq}, and update the arm group graph $\\mathcal{G}_{t}$ to $\\mathcal{G}_{t+1}$. \\\\\n    Update the model parameter $\\vect{\\Theta_{t-1}}$ to $\\vect{\\Theta_{t}}$ according to \\textbf{Algorithm \\ref{algo_2}}.\\\\\n    Retrieve the $\\widetilde{\\matr{X}}_{t}$'s gradient vector $\\vect{g}_{t}$, and update gradient matrix $\\matr{Z}_{t} = \\matr{Z}_{t-1}+\\vect{g}_{t}\\cdot\\vect{g}_{t}^{\\intercal}$. \\\\\n}\n\\end{algorithm}\n% \\setlength{\\textfloatsep}{\\textfloatsepsave}\n%\nAt each time step $t \\in [T]$, \\name~would receive a set of input arm contexts $\\mathcal{X}_{t} = \\{ \\vect{x}^{(i)}_{c, t} \\}_{c \\in \\mathcal{C}_{t}, i\\in [n_{c, t}]}$ (line 5). Then, we embed the arm set $\\mathcal{X}_{t}$ to $\\widetilde{\\mathcal{X}}_{t}$ based on \\textbf{Eq.}\\ref{new_embed_eq} from Subsection \\ref{subsec_group_Aware_Arm_Embedding} (line 6).  \nFor each embedded arm $\\widetilde{\\matr{X}}\\in\\widetilde{\\mathcal{X}}_{t}$, its estimated reward $\\widehat{r}$ and confidence bound $\\widehat{i}$ would be calculated (line 8-10) with the model $f(\\cdot)$ in Subsection \\ref{subsec_reward_est_module}. After recommending the best arm $\\widetilde{\\matr{X}}_{t}$ (line 12) and receiving its true reward $r_{t}$, we update the current arm group graph $\\mathcal{G}_{t}$ based on Subsection \\ref{subsec_arm_graph_est} (line 13).\nThen, the model parameters $\\vect{\\Theta_{t-1}}$ will be trained based on \\textbf{Algorithm \\ref{algo_2}} (line 14), and we incrementally update the gradient matrix to $\\matr{Z}_{t} = \\matr{Z}_{t-1}+\\vect{g}_{t}\\cdot\\vect{g}_{t}^{\\intercal}$ with the gradient vector $\\vect{g}_{t}$ of model $f(\\cdot)$ given the selected arm $\\widetilde{\\matr{X}}_{t}$ (line 15).  \n% Although arm group graph has been modified, we can adopt incremental updates as $\\matr{Z}_{t} = \\matr{Z}_{t-1}+\\vect{g}_{t}\\cdot\\vect{g}_{t}^{\\intercal}$ with the gradient vector $\\vect{g}_{t}$ of model $f(\\cdot)$ given the input $\\widetilde{\\matr{X}}_{t}$. \n% Derivation details are presented in Section \\ref{sec_theoretical_analysis}.\n\n% -----------------\n\\begin{algorithm}[t]\n\\caption{Model Training}\n\\label{algo_2}\n\\textbf{Input:} Initial parameter $\\vect{\\Theta_{0}}$, step size $\\eta$, training steps $J$, network width $m$. Updated arm group graph $\\mathcal{G}_{t+1}$. Selected embedded contexts $\\{\\widetilde{\\matr{X}}_{\\tau}\\}_{\\tau=1}^{t}$.\\\\       \n\\textbf{Output:} Updated model parameter $\\vect{\\Theta_{t}}$.\\\\\n$\\matr{\\Theta}_{t}^{0} \\xleftarrow{} \\matr{\\Theta}_{0}$.\\\\\nLet $\\mathcal{L}(\\matr{\\Theta}) = \\frac{1}{2}\\sum_{\\tau=1}^{t} \\abs{f(\\mathcal{G}_{t+1}, \\widetilde{\\matr{X}}_{\\tau}; \n\\matr{\\Theta}) - r_{\\tau}}^{2}$ \\\\\n\\For{$j = 1, 2, \\dots, J$}{ \n    $\\matr{\\Theta}_{t}^{j} = \\matr{\\Theta}_{t}^{j-1} - \\eta\\cdot\\nabla_{\\matr{\\Theta}} \\mathcal{L}(\\matr{\\Theta}_{t}^{j-1})$ \\\\\n} \nReturn new parameter $\\matr{\\Theta}_{t}^{J}$. \\\\\n\\end{algorithm}\nThe steps from \\textbf{Algorithm \\ref{algo_2}} demonstrate our training process for \\name~ parameters.\nWith the updated arm group graph $\\mathcal{G}_{t+1}$ and the past embedded arm contexts $\\{\\widetilde{\\matr{X}}_{\\tau}\\}_{\\tau=1}^{t}$ until current time step $t$, we define the loss function as the straightforward quadratic loss function (line 4).\nFinally, we run gradient descent (GD) for $J$ steps to derive the new model parameters $\\Theta_{t}$ (lines 5-7) based on the initial parameters $\\matr{\\Theta}_{0}$ (initialized in Subsection \\ref{subsec_model_init}).\nNext, we proceed to introduce the detail of framework components.\n\n% --------------------------------------------\n\\vspace{-0.2cm}\n"
                },
                "subsection 4.2": {
                    "name": "Arm Group Graph Estimation",
                    "content": "     \\label{subsec_arm_graph_est}\nRecall that at time step $t$, we model the similar arms into an arm group graph $\\mathcal{G}_{t}=(V, E, W_{t})$ where the nodes $V$ are corresponding to the arm groups from $\\mathcal{C}$ and edges weights $W_{t}$ formulate the correlations among arm groups. \nGiven two nodes $\\forall c, c' \\in \\mathcal{C}$,  to measure the similarity between them, inspired by the kernel mean embedding in the multi-task learning settings \\cite{kernel_mean_2011,kmtl-ucb_2017}, we define edge weight between $c$ and $c'$ as: % \\ban{why not use $w^\\ast(c,c')$ to denote weight?} \\yunzhe{Updated}\n\\begin{displaymath}\n\\begin{split}\n    w^{*}(c, c') = \\exp(-\\norm{\\mathbb{E}_{\\vect{x}\\sim \\mathcal{D}_{c}}\\big[\\phi_{k_{\\mathcal{G}}}(\\vect{x})\\big] - \\mathbb{E}_{\\vect{x}'\\sim \\mathcal{D}_{c'}}\\big[\\phi_{k_{\\mathcal{G}}}(\\vect{x}')\\big]}^{2} / \\sigma_{s})\n\\end{split}\n\\end{displaymath}\nwhere $\\phi_{k_{\\mathcal{G}}}(\\cdot)$ is the induced feature mapping of a given kernel $k_{\\mathcal{G}}$, e.g., a radial basis function (RBF) kernel.\n%\\ban{Define $k_{\\mathcal{G}}$ here } . \\yunzhe{Updated}\nUnfortunately, $\\forall c \\in \\mathcal{C}$, $\\mathcal{D}_{c}$ is unknown. Therefore, we update the edge weight based on the empirical estimation of arm group correlations. \nHere, let $\\mathcal{X}_{c}^{t} = \\{\\vect{x}^{(i)}_{c, \\tau}\\}_{\\tau\\in[t], i\\in [n_{c, \\tau}]}$ represent the set of all arm contexts from group $c\\in\\mathcal{C}$ up to time step $t$. We define the arm similarity measurement between arms $c, c' \\in \\mathcal{C}$ through a Gaussian-like kernel as\n\\begin{equation}\n\\begin{split}\n    w_{t}(c, c') = \\exp(-\\norm{\\Psi_{t}(\\mathcal{D}_{c}) - \\Psi_{t}(\\mathcal{D}_{c'})}^{2} / \\sigma_{s})\n\\end{split}\n\\label{arm_similarity_eq}\n\\end{equation}\nwhere $\\Psi_{t}(\\mathcal{D}_{c})= \\frac{1}{\\abs{\\mathcal{X}_{c}^{t}}} \\sum_{x \\in \\mathcal{X}_{c}^{t}} k_{\\mathcal{G}}(\\cdot, x)$ denotes the kernel mean estimation of $\\mathcal{D}_{c}$ with a given kernel $k_{\\mathcal{G}}$; and $\\sigma_{s}$ refers to the bandwidth. Then, at time step $t$ and $\\forall c, c' \\in \\mathcal{C}$, we update the corresponding weight of edge $e(c, c')$ in the weight set $W_{t}$ with $w_{t}(c, c')$.\n\n\n\\iffalse\nHere, the edge set $E$ will stay constant across the time steps while the edge weights $W_{t}$ are updated based on the empirical estimation of arm group similarities. To measure the similarity among arms, we follow an approach inspired by the kernel mean embedding in the multi-task learning settings \\cite{kernel_mean_2011,kmtl-ucb_2017}. Here, let $\\mathcal{X}_{c}^{t} = \\{\\vect{x}^{(i)}_{c, \\tau}\\}_{\\tau\\in[t], i\\in [n_{c, \\tau}]}$ representing the set of all arm contexts from group $c\\in\\mathcal{C}$ up to the current time step $t$. Assuming that the contexts for arm group $c$ are drawn from an unknown distribution $\\mathcal{D}_{c}$, we define the arm similarity measurement between arms $c, c' \\in \\mathcal{C}$ through a Gaussian-like kernel as \n\\begin{equation}\n\\begin{split}\n    w_{t}(c, c') = exp(-\\norm{\\Psi_{t}(\\mathcal{D}_{c}) - \\Psi_{t}(\\mathcal{D}_{c'})}^{2} / \\sigma_{s})\n\\end{split}\n\\label{arm_similarity_eq}\n\\end{equation}\nwhere $\\Psi_{t}(\\mathcal{D}_{c})= \\frac{1}{\\abs{\\mathcal{X}_{c}^{t}}} \\sum_{x \\in \\mathcal{X}_{c}^{t}} k_{\\mathcal{G}}(\\cdot, x)$ is the kernel mean estimation of $\\mathcal{D}_{c}$ with a given kernel $k_{\\mathcal{G}}$; and $\\sigma_{s}$ represents the bandwidth parameter. Then, at current time step $t$ and $\\forall c, c' \\in \\mathcal{C}$, we update the corresponding weight of edge $e(c, c')$ in the weight set $W_{t}$ with $w_{t}(c, c')$.\nAssuming there exists an unknown true graph $\\mathcal{G}^{*}$ for the underlying arm group correlations, $\\forall c, c' \\in \\mathcal{C}$, we denote the true edge weight as\n\\begin{displaymath}\n\\begin{split}\n    w^{*}(c, c') = exp(-\\norm{\\mathbb{E}_{\\vect{x}\\sim \\mathcal{D}_{c}}\\big(\\phi_{k_{\\mathcal{G}}}(\\vect{x})\\big) - \\mathbb{E}_{\\vect{x}'\\sim \\mathcal{D}_{c'}}\\big(\\phi_{k_{\\mathcal{G}}}(\\vect{x}')\\big)}^{2} / \\sigma_{s})\n\\end{split}\n\\end{displaymath}\nwhere $\\phi_{k_{\\mathcal{G}}}(\\cdot)$ is the induced feature mapping of kernel $k_{\\mathcal{G}}$.\n\\fi\n\n"
                },
                "subsection 4.3": {
                    "name": "Group-Aware Arm Embedding",
                    "content": " \\label{subsec_group_Aware_Arm_Embedding}\nTo conduct the aggregation operations of GNN, we reconstruct a matrix for each arm context vector.\n%Before proceeding to the forward propagation, we first embed these contexts into long vectors based on their associated arms to partition the weight matrices of the aggregation module \n%\\he{This sentence is confusing. What forward propagation? What neural model?}. \nRecall that for an arm group $c\\in \\mathcal{C}$, if $c \\in \\mathcal{C}_{t}$, we receive the contexts $x^{(i)}_{c, t} \\in \\mathbb{R}^{d_{x}}, i\\in [n_{c, t}]$ at time step $t$. Then, the reconstructed matrix for $\\vect{x}^{(i)}_{c, t}$ is defined as\n\\begin{equation}\n\\widetilde{\\vect{X}}^{(i)}_{c, t} = \n\\left(\\begin{array}{cccc}\n(\\vect{x}^{(i)}_{c, t})^{\\intercal} & \\matr{0} & \\cdots & \\matr{0}\\\\\n\\matr{0} & (\\vect{x}^{(i)}_{c, t})^{\\intercal} & \\cdots & \\matr{0}\\\\\n\\vdots  &       & \\ddots   & \\vdots \\\\\n\\matr{0} & \\matr{0} & \\cdots & (\\vect{x}^{(i)}_{c, t})^{\\intercal}\\\\\n\\end{array}\\right) \\in \\mathbb{R}^{N_{c}\\times d_{\\widetilde{x}}}\n\\label{new_embed_eq}\n\\end{equation}\n% \\ban{consider if you should add transpose to $ \\vect{x}^{(i)}_{c, t}$. Since $\\vect{x}^{(i)}_{c, t} \\in \\mathbb{R}^{d_{x}}$, then $ \\widetilde{\\vect{X}}^{(i)}_{c, t} \\in \\mathbb{R}^{d_{\\widetilde{x}} \\times  N_{c}} $ }\nwhere $d_{\\widetilde{x}} = d_{x} \\cdot N_{c}$ is the column dimension of $\\widetilde{\\vect{X}}^{(i)}_{c, t}$.\n%\\ban{can change $\\widetilde{x}$ to $\\widetilde{x}$ \\ }. \\yunzhe{Updated}\nHere, for the $c'$-th row in matrix $\\widetilde{\\vect{X}}^{(i)}_{c, t}$, the $((c'-1)\\cdot d_{x} + 1)$-th to the $(c'\\cdot d_{x})$-th entries are the transposed original arm context $(\\vect{x}^{(i)}_{c, t})^{\\intercal}$, while the other entries are zeros. \nReceiving a set of arm contexts $\\mathcal{X}_{t}$, we derive the corresponding embedded arm set as $\\widetilde{\\mathcal{X}}_{t} = \\{ \\widetilde{\\vect{X}}^{(i)}_{c, t} \\}_{c \\in \\mathcal{C}_{t}, i\\in [n_{c, t}]}$. \n%For notation simplicity, we use $\\widetilde{\\matr{X}}$ to denote an arbitrary $\\widetilde{\\vect{X}}^{(i)}_{c, t}, c\\in \\mathcal{C}_{t}, i\\in [n_{c, t}]$, and $\\vect{x}$ as the corresponding original arm context for the following sections. \n\n% -------------------------------------------\n\n% AGGR ----------------------------\n\n",
                    "subsubsection 4.3.1": {
                        "name": "Aggregation of arm group representations",
                        "content": "\n\nTo leverage the estimated arm group graph for downstream reward estimations, we propose to aggregate over the arm group neighborhood for a more comprehensive arm representation through the GNN-based module, named as group-aware arm representation. \n%\nIt has been proven that the local averaging operation on the graph neighborhood can be deemed as applying the low-pass filter on the corresponding node features \\cite{GNN_Low_pass_filter_hoang2021revisiting, SGC_wu2019simplifying}, which would give locally smooth node features within the same neighborhood. \nInspired by the SGC model \\cite{SGC_wu2019simplifying}, we propose to aggregate over the $k$-hop arm group neighborhood $\\widetilde{\\mathcal{N}}_{k}(\\cdot)$ for incorporating arm group correlations to obtain the aggregated group-aware embedding for an embedded arm $\\widetilde{\\vect{X}}^{(i)}_{c, t}$, denoted by\n\\begin{equation}\n\\begin{split}\n    \\matr{H}_{gnn} = \\sqrt{\\frac{1}{m}}\\cdot\\sigma(\\matr{S}_{t}^{k}\\cdot \\widetilde{\\vect{X}}^{(i)}_{c, t} \\matr{\\Theta}_{gnn}) \\in \\mathbb{R}^{N_{c} \\times m}\n\\end{split}\n\\label{aggr_Eq}\n\\end{equation}\nwhere \n$\\matr{S}_{t} = \\matr{D}_{t}^{-\\frac{1}{2}}\\matr{A}_{t}\\matr{D}_{t}^{-\\frac{1}{2}}\n$\nis the symmetrically normalized adjacency matrix, and we have\n\\begin{displaymath}\n\\matr{\\Theta}_{gnn} = \n\\left(\\begin{array}{c}\n\\matr{\\Theta}_{gnn}^{1} \\in \\mathbb{R}^{d_{x}\\times m}\\\\\n\\vdots \\\\\n\\matr{\\Theta}_{gnn}^{c'} \\in \\mathbb{R}^{d_{x}\\times m}\\\\\n\\vdots \\\\\n\\matr{\\Theta}_{gnn}^{N_{c}} \\in \\mathbb{R}^{d_{x}\\times m}\\\\\n\\end{array}\\right) \\in \\mathbb{R}^{d_{\\widetilde{x}}\\times m}.\n\\end{displaymath}\nbeing the trainable weight matrix with width $m$. Here, $\\sigma(\\cdot)$ denotes the non-linear activation function, which is added after the aggregation operation to alleviate potential concerns when the contexts are not linearly separable \\cite{GNN_Low_pass_filter_hoang2021revisiting}.\n%\nNote that the $c'$-th row of $(\\widetilde{\\vect{X}}^{(i)}_{c, t}\\cdot\\matr{\\Theta}_{gnn})$, denoted by $[\\widetilde{\\vect{X}}^{(i)}_{c, t} \\cdot\\matr{\\Theta}_{gnn}]_{c',:}$, is the hidden representation of arm $\\vect{x}$ in terms of $c'$-th arm group in $\\mathcal{C}$.    \nThen, these hidden representations will then be aggregated over $\\widetilde{\\mathcal{N}}_{k}(c), c\\in \\mathcal{C}$ by multiplying with $\\matr{S}_{t}^{k}$ to derive the aggregated arm representation for $\\vect{x}$, i.e.,  $\\matr{H}_{gnn}(x)$.\n\n% --------\n\n\n\n% \\iffalse\n% we will be able to encode the arm $\\vect{x}$ from the perspective of $i$-th arm group only as\n% \\begin{equation}\n% \\begin{split}\n%   [\\widetilde{\\matr{X}}\\cdot\\matr{\\Theta}_{gnn}]_{i,:} = \\vect{x}^{\\intercal}\\cdot\\matr{\\Theta}_{gnn}^{i}\n% \\end{split}\n% \\label{eq_matrix_partioning}\n% \\end{equation}\n% which is the $i$-th row of $\\widetilde{\\matr{X}}\\cdot\\matr{\\Theta}_{gnn}$.\\he{What is this???} \n% We have $\\matr{\\Theta}_{gnn}^{i} \\in \\mathbb{R}^{d_{x}\\times m}$ representing the $i$-th $d_{x}\\times m$ block in $\\matr{\\Theta}_{gnn}$ as\n% \\begin{displaymath}\n% \\matr{\\Theta}_{gnn} = \n% \\left(\\begin{array}{c}\n% \\matr{\\Theta}_{gnn}^{1} \\in \\mathbb{R}^{d_{x}\\times m}\\\\\n% \\vdots \\\\\n% \\matr{\\Theta}_{gnn}^{i} \\in \\mathbb{R}^{d_{x}\\times m}\\\\\n% \\vdots \\\\\n% \\matr{\\Theta}_{gnn}^{N_{c}} \\in \\mathbb{R}^{d_{x}\\times m}\\\\\n% \\end{array}\\right) \\in \\mathbb{R}^{d_{\\widetilde{x}}\\times m}.\n% \\end{displaymath}\n% Here, the group-aware representation enables us to assign $i$-th arm with its own weight matrix partition $\\matr{\\Theta}_{gnn}^{i}$ and separately obtain the individual hidden representation $[\\widetilde{\\matr{X}}\\cdot\\matr{\\Theta}_{gnn}]_{i,:}$ for the given arm. \n% % Thus, by the multiplication $\\widetilde{\\matr{X}}\\cdot\\matr{\\Theta}_{gnn} \\in\\mathbb{R}^{N_{c}\\times m}$, we end up with a $m$-dimensional hidden representation for each arm w.r.t. arm $\\widetilde{\\matr{X}}$.\n% These hidden representations will then be aggregated over $\\widetilde{\\mathcal{N}}_{k}(c), c\\in \\mathcal{C}$ by multiplying with $\\matr{S}_{t}^{k}$ to derive the group-aware arm representation for $\\widetilde{\\matr{X}}$ and $\\vect{x}$. \n% \\fi\n\n\n"
                    },
                    "subsubsection 4.3.2": {
                        "name": "Incorporating initial embedded contexts",
                        "content": "\nMoreover, solely aggregating information from neighbors through the GNN-based models can lead to \"over-smoothing\" problems \\cite{JK_Net_xu2018representation,linearized-GNN_xu2021optimization}. \n%For example, assume that there is an isolated complete sub-graph containing three nodes in $\\mathcal{G}_{t}$, which means that each of these nodes are connected with the other two nodes while the rest of the nodes in $\\mathcal{G}_{t}$ are not connected to this sub-graph.\nAggregating from the node neighborhood will end up with identical representations for all the nodes if they form an isolated complete sub-graph,  which may not correctly reflect the relationship among these nodes in real-world applications. \n%This is analogous to the \"over-smoothing\" problem \\cite{JK_Net_xu2018representation,linearized-GNN_xu2021optimization}.\n%In this case, only aggregating from the node neighborhood will end up with identical aggregated contexts for all three nodes and thus the same reward estimations, which may not correctly reflect the relationship among these arm groups in real-world applications. This is analogous to the \"over-smoothing\" problem \\cite{JK_Net_xu2018representation,linearized-GNN_xu2021optimization}.\nTherefore, we propose to apply skip-connections to address this potential problem by combining the initial contexts with the aggregated hidden features. \nSimilar ideas have been applied to boost the performance of neural models. For instance, JK-Net \\cite{JK_Net_xu2018representation} and GraphSAGE \\cite{GraphSAGE_hamilton2017inductive} concatenate hidden features from different levels of node neighborhoods; and ResNet \\cite{resnet_he2016deep} adopts additive residual connections.\n\n\nPutting these two parts together and setting $d' = m~+~d_{\\widetilde{x}}$, we then have\n$\\matr{H}_{0} \\in \\mathbb{R}^{N_{c} \\times d'}$ as the output group-aware arm representation for $\\widetilde{\\vect{X}}^{(i)}_{c, t}$, represented by\n\\begin{equation}\n\\begin{split}\n    \\matr{H}_{0} = f_{gnn}(\\mathcal{G}_{t}, \\widetilde{\\vect{X}}^{(i)}_{c, t}; \\matr{\\Theta}_{gnn}) = [\\sigma(\\matr{S}_{t}^{k}\\cdot\\widetilde{\\vect{X}}^{(i)}_{c, t} \\matr{\\Theta}_{gnn}); \\widetilde{\\vect{X}}^{(i)}_{c, t}]\n\\end{split}\n\\label{SGC_eq}\n\\end{equation}\nwhere $[\\cdot~;~\\cdot]$ refers to the column-wise concatenation of matrices.\n\n% Here, $\\mathcal{F}: \\mathbb{R}^{d_{\\widetilde{x}}} \\mapsto \\mathbb{R}^{d'}$ represents the pre-defined skip-connection mapping, and the possible choices can be simple linear transformations \\cite{resnet_he2016deep}, identity mapping \\cite{identity_mapping_he2016identity}, etc.\n\n\n% --------------------------------------------\n\\vspace{-0.2cm}\n"
                    }
                },
                "subsection 4.4": {
                    "name": "Reward Estimation Module",
                    "content": "   \\label{subsec_reward_est_module}\nIn this subsection, we estimate the rewards with a FC network of $L$ layers and width $m$, based on group-aware arm representation $\\matr{H}_{0}$. \n%For notation simplicity, we use $\\widetilde{\\matr{X}}$ to denote an arbitrary $\\widetilde{\\vect{X}}^{(i)}_{c, t}, c\\in \\mathcal{C}_{t}, i\\in [n_{c, t}]$, and $\\vect{x}$ as the corresponding original arm context for the following sections. \n\n\n",
                    "subsubsection 4.4.1": {
                        "name": "Reward and confidence bound estimation",
                        "content": "\nHere, let $\\matr{\\Theta}_{fc} = \\{\\matr{\\Theta}_{l}\\}_{l \\in [L]}$ be the set of trainable weight matrices of a fully-connected network,\n%\\he{What's their relationship with the matrices in the last subsection?} \nwhere the specifications are: $\\matr{\\Theta}_{1} \\in \\mathbb{R}^{d' \\times m }$, $\\matr{\\Theta}_{L} \\in \\mathbb{R}^{m}$ and $\\matr{\\Theta}_{l} \\in \\mathbb{R}^{m \\times m}, \\forall l \\in \\{2,\\dots, L-1\\}$. \nThen, given the group-aware representation $\\matr{H}_{0}$,  \nwe have the reward estimation module as follows\n\\begin{equation}\n\\begin{split}\n    &\\matr{H}_{l} = \\sqrt{\\frac{1}{m}}\\cdot\\sigma( \\matr{H}_{l-1} \\cdot \\matr{\\Theta}_{l}  ),~~~~~ l \\in \\{1,\\dots, L-1\\}, \\\\\n    &\\widehat{\\vect{r}}_{all} = f_{fc}(\\matr{H}_{0}; \\matr{\\Theta}_{fc}) = \\sqrt{\\frac{1}{m}}\\cdot \\matr{H}_{L-1} \\cdot \\matr{\\Theta}_{L}\n\\end{split}\n\\label{FC_model}\n\\end{equation}\n% ---------\n% \\begin{equation}\n% \\begin{split}\n%     \\widehat{\\vect{r}}_{all} = f_{fc}(\\matr{H}_{0}; \\matr{\\Theta}_{fc}) = \\bigg(\\matr{\\Theta}_{L}\\cdot\\sigma\\bigg(\\matr{\\Theta}_{L-1}\\cdot\\sigma(\\dotsb\\sigma(\\matr{\\Theta}_{1}\\matr{H}_{0}^{\\intercal})\\bigg)^{\\intercal} \\cdot m^{-\\frac{1}{2}}\\bigg)^{\\intercal}\n% \\end{split}\n% \\label{FC_model}\n% \\end{equation}\nwhere $\\widehat{\\vect{r}}_{all} \\in \\mathbb{R}^{N_{c}}$ represents the point-estimation vector for the received contexts embedding $\\matr{H}_{0}$ with respect to all the arms groups. \n%Recall that we use $\\widetilde{\\matr{X}}$ to denote an arbitrary embedded arm $\\widetilde{\\vect{X}}^{(i)}_{c, t}$. \nGiven that the arm $\\widetilde{\\vect{x}}^{(i)}_{c, t}$ belonging to $c$-th group, \n we will then have the reward estimation $\\widehat{\\vect{r}}^{(i)}_{c, t} = [\\widehat{\\vect{r}}_{all}]_{c}\\in\\mathbb{R}$ for the embedded context matrix $\\widetilde{\\vect{X}}^{(i)}_{c, t}$,\nwhich is the $c$-th element of $\\widehat{\\vect{r}}_{all}$.\n\n% -------- Remark of estimation arm embedding\n% \\begin{remark}\n% Remark of estimation arm embedding \\TODO{Fill in}\n% \\end{remark}\n\n% --------\n\n%\\he{This paragraph talks about combining the two modules. Why is it still part of Subsection 4.4?}\nFinally, combining the aggregation module with the reward estimation module, given arm group graph $\\mathcal{G}_{t}$ at time step $t$, the reward estimation for the embedded arm $\\widetilde{\\vect{X}}^{(i)}_{c, t}$ (i.e., the reward estimation given its arm group) can be represented as \n\\begin{displaymath}\n\\begin{split}\n    \\widehat{r}^{(i)}_{c, t} = f(\\mathcal{G}_{t}, \\widetilde{\\vect{X}}^{(i)}_{c, t}&; \\matr{\\Theta})= \\Bigg[\\bigg(f_{fc}(\\cdot; \\matr{\\Theta}_{fc})\\circ f_{gnn}(\\cdot; \\matr{\\Theta}_{gnn})\\bigg)(\\mathcal{G}_{t}, \\widetilde{\\vect{X}}^{(i)}_{c, t}) \\Bigg]_{c}.\n\\end{split}\n\\end{displaymath}\nSetting $p = (2N_{c}\\cdot d)\\cdot m + (L-1)\\cdot m^{2} + m$, we have $\\matr{\\Theta} \\in \\mathbb{R}^{p}$ being the set of all the parameters from these two modules. \n\n\n\n\n\n"
                    },
                    "subsubsection 4.4.2": {
                        "name": "Arm pulling mechanism",
                        "content": "\n%\\he{Why is this subsection part of 4.4?}\nWe obtain confidence bounds for the point estimation with the network gradients as \n$\\widehat{i} = \\sqrt{\\vect{g}^{\\intercal}\\cdot\\matr{Z}_{t-1}\\cdot\\vect{g} / m}$\nwhere\n$\\vect{g} = \\nabla_{\\matr{\\Theta}}f(\\mathcal{G}_{t}, \\widetilde{\\vect{X}}^{(i)}_{c, t}; \\matr{\\Theta}) \\in \\mathbb{R}^{p}$ is the gradient vector, and $\\matr{Z}_{t-1} = \\matr{I}+\\sum_{\\tau=1}^{t-1}\\vect{g}_{\\tau}\\cdot\\vect{g}_{\\tau}^{\\intercal}$ with $\\vect{g}_{\\tau}$ being the gradient vector of the embedded arm which is selected at step $\\tau\\in\\{1,\\dots, t-1\\}$.\nAfter obtaining the reward and confidence bound estimations for all embedded arm in set $\\widetilde{\\mathcal{X}}_{t}$, we choose the best arm as\n$\\widetilde{\\matr{X}}_{t} = \\operatorname*{argmax}_{\\widetilde{\\matr{X}}^{(i)}_{c, t} \\in \\widetilde{\\mathcal{X}}_{t}} (\\widehat{r}^{(i)}_{c, t} + \\gamma\\cdot\\widehat{i}^{(i)}_{c, t})$\n% \\begin{equation}\n%      \\widetilde{\\matr{X}}_{t} = \\operatorname*{argmax}_{\\widetilde{\\matr{X}}^{(i)}_{c, t} \\in \\widetilde{\\mathcal{X}}_{t}} (\\widehat{r}^{(i)}_{c, t} + \\gamma\\cdot\\widehat{i}^{(i)}_{c, t})\n% \\end{equation}\nwhere $\\gamma$ is the exploration parameter, and the theoretical upper confidence bound will be given in Section \\ref{sec_theoretical_analysis}.\nNote that based on our problem definition (Section \\ref{sec_problem_def}), one arm may associate with multiple arm groups. Here, we will separately estimate rewards and confidence bounds of each arm group it belongs to, and consider them as different arms for selection.\n\n% --------------------------------\n\\vspace{-0.2cm}\n"
                    }
                },
                "subsection 4.5": {
                    "name": "Model Initialization",
                    "content": "   \\label{subsec_model_init}\nFor the aggregation module weight matrix $\\matr{\\Theta}_{gnn}$, each of its entries is sampled from the Gaussian distribution $N(0, 1)$.\nSimilarly, the parameters from the first $L-1$ reward estimation module layers ($[\\matr{\\Theta}_{1}, \\dots, \\matr{\\Theta}_{L-1}]$) are also sampled from $N(0, 1)$.\nFor the final ($L$-th) layer, its weight matrix $\\matr{\\Theta}_{L}$ is initialized by drawing the entry values from the Gaussian distribution $N(0, 1 / m)$.\n\n% ---------------------------------------------------------------\n\n"
                }
            },
            "section 5": {
                "name": "Theoretical Analysis",
                "content": " \\label{sec_theoretical_analysis}\nIn this section, we provide the theoretical analysis for our proposed framework. For the sake of analysis, at each time step $t$, we assume each arm group $c\\in \\mathcal{C}$ would receive one arm $\\vect{x}_{c, t}$,\nwhich makes $\\abs{\\mathcal{X}_{1}^{t}} = \\dots = \\abs{\\mathcal{X}_{N_{c}}^{t}} = t$.\nWe also apply the adjacency matrix $\\matr{A}_{t}$ instead of $\\matr{S}_{t}$ for aggregation, and set its elements\n$[\\matr{A}_{t}]_{ij} = \\frac{1}{t\\cdot N_{c}}\\sum_{\\tau=1}^{t}\\phi_{k_{\\mathcal{G}}}(x_{c_{i}, \\tau})^{\\intercal}\\phi_{k_{\\mathcal{G}}}(x_{c_{j}, \\tau})$\nfor arm group similarity between group $c_{i}, c_{j}\\in \\mathcal{C}$. Here, $\\phi_{k_{\\mathcal{G}}}(\\cdot)$ is the kernel mapping given an RBF kernel $k_{\\mathcal{G}}$. With $\\mathcal{G}^{*}$ being the unknown true arm group graph, its adjacency matrix elements are $[\\matr{A}^{*}]_{ij} = \\frac{1}{N_{c}}\\mathbb{E}_{x_{i}\\sim\\mathcal{D}_{c_{i}}, x_{j}\\sim\\mathcal{D}_{c_{j}}} (\\phi_{k_{\\mathcal{G}}}(x_{i})^{\\intercal}\\phi_{k_{\\mathcal{G}}}(x_{j}))$. Note that the norm of adjacency matrices $\\norm{\\matr{A}^{*}}_{2}, \\norm{\\matr{A}_{t}}_{2} \\leq 1$ since $\\inp{\\phi_{k_{\\mathcal{G}}}(x)}{\\phi_{k_{\\mathcal{G}}}(x')} \\leq 1$ for any $x, x' \\in \\mathbb{R}^{d_{x}}$, which makes it feasible to aggregate over $k$-hop neighborhood without the explosion of eigenvalues.\nBefore presenting the main results, we first introduce the following background. \n\\begin{lemma} [\\cite{CNN_UCB-ban2021convolutional,Neural-UCB}]\nFor any $t \\in [T]$, given arm $\\vect{x} \\in \\mathbb{R}^{d_{x}}$ satisfying $\\norm{\\vect{x}}_{2}=1$ and its embedded context matrix $\\widetilde{\\matr{X}}$,  there exists $\\matr{\\Theta}_{t-1}^{*} \\in \\mathbb{R}^{p}$ at time step $t$, and a constant $S > 0$, such that\n\\begin{equation}\n\\begin{split}\n    h(\\mathcal{G}^{*}, \\widetilde{\\matr{X}}) = \\inp{g(\\mathcal{G}^{*}, \\widetilde{\\matr{X}};\\matr{\\Theta}_{t-1})}{\\matr{\\Theta}_{t-1}^{*} - \\matr{\\Theta}_{0}}\n\\end{split}\n\\label{eq_exp_reward}\n\\end{equation}\nwhere $\\norm{\\matr{\\Theta}_{t-1}^{*} - \\matr{\\Theta}_{0}}_{2} \\leq S / \\sqrt{m}$, $\\forall t \\in [T]$, and $\\mathcal{G}^{*}$ stands for the unknown true underlying arm group graph. \n\\label{lemma_expect_rewards}\n\\end{lemma}\n% \\TODO{Explain the $\\matr{\\Theta}_{t-1}^{*}$ difference?}\n% \\ban{We can prove that when$m \\rightarrow \\infty$,  $\\matr{\\Theta}_{t-1}^{*} = \\matr{\\Theta}_{0}^{*},  \\forall t \\in [T] $. We can provide this proof in the Arxiv version. Note that $\\matr{\\Theta}_{t-1}^{*}$ is derived from dynamic NTK while $\\matr{\\Theta}_{0}$ is derived from the initialized NTK. }\nNote that with sufficient network width $m$, we will have $\\matr{\\Theta}_{t-1}^{*} \\approx \\matr{\\Theta}_{0}^{*},  \\forall t \\in [T]$, and we will include more details in the full version of the paper.\nFollowing the analogous ideas from previous works \\cite{Neural-UCB,neural_multifacet-ban2021multi}, this lemma formulates the expected reward as a linear function parameterized by the difference between randomly initialized network parameter $\\matr{\\Theta}_{0}$ and the parameter $\\matr{\\Theta}_{t-1}^{*}$, which lies in the confidence set with the high probability \\cite{improved_linear_bandits_abbasi2011improved}. Then, regarding the activation function $\\sigma(\\cdot)$, we have the following assumption on its continuity and smoothness.\n\\begin{Assumption} [$\\zeta$-Lipschitz continuity and Smoothness \\cite{skip_kernel_du2019gradient,CNN_UCB-ban2021convolutional}]\nFor non-linear activation function $\\sigma(\\cdot)$, there exists a positive constant $\\zeta > 0$, such that $\\forall \\vect{x}, \\vect{x}' \\in \\mathbb{R}$, we have\n\\begin{displaymath}\n\\begin{split}\n    &\\abs{\\sigma(x) - \\sigma(x')} \\leq \\zeta \\cdot \\norm{x - x'}, \\quad\n    \\abs{\\sigma'(x) - \\sigma'(x')} \\leq \\zeta \\cdot \\norm{x - x'}\n\\end{split}\n\\end{displaymath}\nwith $\\sigma'(\\cdot)$ being the derivative of activation function $\\sigma(\\cdot)$.\n\\label{assumption_act_func_Lipschitz}\n\\end{Assumption}\nNote that \\textbf{Assumption}~\\ref{assumption_act_func_Lipschitz} is mild and applicable on many activation functions, such as Sigmoid.\nThen, we proceed to bound the regret for a single time step $t$.\n% ===========================================================\n\n",
                "subsection 5.1": {
                    "name": "Upper Confidence Bound",
                    "content": "\n% Recall that in Lemma~\\ref{lemma_expect_rewards}, we have\nRecall that at time step $t$, given an embedded arm matrix $\\widetilde{\\matr{X}}$, the output of our proposed framework is \n$\\widehat{r} = f(\\mathcal{G}_{t}, \\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1})$\nwith $\\mathcal{G}_{t}$, $\\matr{\\Theta}_{t-1}$ as the estimated arm group graph and trained parameters respectively. The true function $h(\\mathcal{G}^{*}, \\widetilde{\\matr{X}})$ is given in Lemma \\ref{lemma_expect_rewards}. Supposing there exists the true arm group graph $\\mathcal{G}^{*}$,\nthe confidence bound for a single round $t$ will be\n\\begin{equation}\n\\begin{split}\n    & \\textsf{CB}_{t}(\\widetilde{\\matr{X}}) = \\abs{ f(\\mathcal{G}_{t}, \\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1}) - h(\\mathcal{G}^{*}, \\widetilde{\\matr{X}}) } \\\\\n    % & \\leq \\abs{f(\\mathcal{G}_{t}, \\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1}) - h(\\mathcal{G}^{*}, \\widetilde{\\matr{X}})}\n    % + \\underbrace{\\abs{h(\\mathcal{G}^{*}, \\widetilde{\\matr{X}}) - h(\\mathcal{G}^{*}, \\widetilde{\\matr{X}})}}_{R_{h}} \\\\\n    &\\leq \\underbrace{\\abs{ f(\\mathcal{G}_{t}, \\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1}) - h(\\mathcal{G}_{t}, \\widetilde{\\matr{X}}) }}_{R_{1}} + \\underbrace{\\abs{ h(\\mathcal{G}_{t}, \\widetilde{\\matr{X}}) - h(\\mathcal{G}^{*}, \\widetilde{\\matr{X}}) }}_{R_{2}}\n\\end{split}\n\\label{eq_regret_split}\n\\end{equation}\nwhere $R_{1}$ denotes the error induced by network parameter estimations, and $R_{2}$ refers to the error from arm group graph estimations. We will then proceed to bound them separately.\n\n\n% ----------------------\n",
                    "subsubsection 5.1.1": {
                        "name": "1",
                        "content": "\n% Then, we proceed to derive the bound for term $R_{1}$. \nFor simplicity, the $\\mathcal{G}_{t}$ notation is omitted for this subsection.\nTo bridge the network parameters after GD with those at random initialization, we define the gradient-based regression estimator $\\widehat{\\matr{\\Theta}}_{t} = \\matr{Z}_{t}^{-1} \\vect{b}_{t}$ where $\\matr{Z}_{t} = \\lambda\\matr{I} + \\frac{1}{m}\\sum_{\\tau=1}^{t} g(\\widetilde{\\matr{X}}_{\\tau}; \\matr{\\Theta}_{\\tau}) \\cdot g(\\widetilde{\\matr{X}}_{\\tau}; \\matr{\\Theta}_{\\tau})^{\\intercal}, \n\\vect{b}_{t}  = \\sum_{\\tau=1}^{t} r_{\\tau} \\cdot g(\\widetilde{\\matr{X}}_{\\tau}; \\matr{\\Theta}_{\\tau}) / \\sqrt{m}.$\n% \\begin{displaymath}\n% \\begin{split}\n%     & \\matr{Z}_{t} = \\lambda\\matr{I} + \\frac{1}{m}\\sum_{\\tau=1}^{t} g(\\widetilde{\\matr{X}}_{\\tau}, \\matr{\\Theta}_{\\tau})g(\\widetilde{\\matr{X}}_{\\tau}, \\matr{\\Theta}_{\\tau})^{\\intercal}, ~~\\vect{b}_{t}  = \\sum_{\\tau=1}^{t} r_{\\tau} \\cdot g(\\widetilde{\\matr{X}}_{\\tau}, \\matr{\\Theta}_{\\tau}) / \\sqrt{m}.\n% \\end{split}\n% \\end{displaymath}\nThen, we derive the bound for $R_{1}$ with the following lemma.\n\\begin{lemma}\nAssume there are constants $\\beta_{F} > 0, ~~1 < \\beta_{1}, \\beta_{2}, \\beta_{3}, \\beta_{4} < 2,~~ \\beta_{L} = \\max\\{\\beta_{1}, \\beta_{2}, \\beta_{3}, \\beta_{4}\\}$, and\n\\begin{displaymath}\n\\begin{split}\n    & \\beta_{h} = \\max\\{\\zeta \\beta_{1},~~~ \\zeta \\beta_{2} + \\zeta^{2} \\beta_{1} \\beta_{2},~~~ \\zeta \\beta_{L} + 1, \n    ~~~ (\\zeta \\beta_{4})^{L-2}(\\zeta \\beta_{2} + \\zeta^{2} \\beta_{1} \\beta_{2})\\}.\n\\end{split}\n\\end{displaymath}\nWith a constant $\\delta\\in (0, 1)$, and $L$ as the layer number for the FC network, let the network width  \n$m \\geq \\text{Poly}\\big( t, L, \\frac{1}{\\beta_{F}}, \\frac{1}{\\lambda}, (\\zeta \\beta_{L})^{L}, \\log(\\frac{1}{\\delta}) \\big)$, and learning rate $\\eta \\leq \\mathcal{O}\\big((t\\cdot L \\beta_{h}^{2}(2\\zeta \\beta_{L})^{2L})^{-1}\\big)$.\n% \\begin{displaymath}\n% \\begin{split}\n%     & m \\geq \\text{Poly}\\big( t, L, \\frac{1}{\\beta_{F}}, \\frac{1}{\\lambda}, (\\zeta \\beta_{L})^{L}, \\log(\\frac{1}{\\delta}) \\big), ~  \n%     \\eta \\leq \\mathcal{O}\\big((t\\cdot L \\beta_{h}^{2}(2\\zeta \\beta_{L})^{2L})^{-1}\\big).\n% \\end{split}\n% \\end{displaymath}\nDenoting the terms\n\\begin{displaymath}\n\\begin{split}\n    & \\Upsilon = \\frac{2\\sqrt{2}t}{\\beta_{F}}(\\beta_{h}+ \\Lambda)  (\\beta_{L}+ 1)^{L}  \\zeta^{L}, \n    \\quad\\Lambda = \\frac{\\zeta \\Upsilon \\beta_{h}}{m} \\cdot \\frac{(2\\zeta \\beta_{L})^{L}-1}{2\\zeta \\beta_{L}-1} \\\\\n    &\\widetilde{I}_{1} = \\sqrt{t\\cdot (L\\cdot \\beta_{3}^{2}\\cdot (\\beta_{L}\\zeta)^{2L} + m)} + \\Lambda\\cdot \\sqrt{t\\cdot(9L + m^{-1})}, \\\\\n    & \\widetilde{I}_{2} = \\lambda \\sqrt{L+1} \\cdot \\Upsilon / \\sqrt{m},\n\\end{split}\n\\end{displaymath}\nat time step $~t$, given the received contexts and rewards, with probability at least $1-\\delta$ and the embedded context $\\widetilde{\\matr{X}}$, we have\n\\begin{displaymath}\n\\begin{split}\n    & \\abs{h(\\widetilde{\\matr{X}}) - f(\\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1})}\n    \\leq B_{1} \\norm{g(\\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1}) / \\sqrt{m}}_{\\matr{Z}_{t-1}^{-1}} + B_{2} + B_{3}\n\\end{split}\n\\end{displaymath}\nwith the terms \n\\begin{displaymath}\n\\begin{split}\n    & B_{1} = \\sqrt{\\log(\\frac{\\det(\\matr{Z}_{t-1})}{\\det(\\matr{\\lambda I})}) - 2\\log(\\delta)} + \\lambda^{\\frac{1}{2}}S, \\\\\n    & B_{2} = \\big( \n        \\frac{\\widetilde{I}_{1} \\cdot \\sqrt{t} B_{3} +  m\\cdot \\widetilde{I}_{2}}{m\\lambda} + \\sqrt{\\frac{t}{ m\\lambda}} \n        \\big) \\\\\n        &\\qquad \n        \\cdot \\big( \n        \\Lambda\\cdot\\sqrt{9L + m^{-1}} + m^{-1}\\beta_{h} \\cdot \\sqrt{L\\cdot \\beta_{3}^{2}\\cdot (\\beta_{L}\\zeta)^{2L} + m} \n        \\big) \\\\\n    & B_{3} = m^{-0.5} \\big(\n        \\beta_{3} (\\Lambda+\\beta_{h}) + L\\cdot\\Upsilon\\cdot (\\Lambda+\\beta_{h})(\\Lambda / \\beta_{h} + 1) \n      \\big).\n\\end{split}\n\\end{displaymath}\n\n% $B_{1} = \\sqrt{\\log(\\frac{\\det(\\matr{Z}_{t-1})}{\\det(\\matr{\\lambda I})}) - 2\\log(\\delta)} + \\lambda^{0.5}$, \n% $B_{2} = \\big[ \n% \\frac{\\widetilde{I}_{1} \\cdot \\sqrt{t} B_{3} +  m\\cdot \\widetilde{I}_{2}}{m\\lambda} + \\sqrt{\\frac{t}{ m\\lambda}} \n% \\big] \n% \\cdot \\big( \n% \\Lambda\\cdot\\sqrt{9L + m^{-1}} + m^{-1}\\beta_{h} \\cdot \\sqrt{L\\cdot \\beta_{3}^{2}\\cdot (\\beta_{L}\\zeta)^{2L} + m} \n% \\big)$, \n% and $B_{3} = m^{-0.5} \\big(\n%         \\beta_{3} (\\Lambda+\\beta_{h}) + L\\cdot\\Upsilon\\cdot (\\Lambda+\\beta_{h})(\\Lambda / \\beta_{h} + 1) \n% \\big)$. \n\\label{lemma_CB_one_step_same_graph}\n\\end{lemma}\n\n\\textbf{Proof.} \n% \\ban{We can move this part of proof to appendix, to save more space for References.}\nGiven the embedded context $\\widetilde{\\matr{X}}$, and following the statement in Lemma \\ref{lemma_expect_rewards}, we have \n\\begin{displaymath}\n\\begin{split}\n    & \\abs{h(\\widetilde{\\matr{X}}) - f(\\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1})} \\\\\n    & \\quad\\leq \\abs{\\inp{g(\\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1}) / \\sqrt{m}}{\\sqrt{m}(\\matr{\\Theta}_{t-1}^{*} - \\matr{\\Theta}_{0})} - \\inp{g(\\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1}) / \\sqrt{m}}{\\widehat{\\matr{\\Theta}}_{t-1}}} \\\\\n    &\\quad\\qquad + \\abs{\\inp{g(\\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1}) / \\sqrt{m}}{\\widehat{\\matr{\\Theta}}_{t-1}} - \n    f(\\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1})} = R_{3} + R_{4}.\n\\end{split}\n\\end{displaymath}\nWith Theorem 2 from \\cite{improved_linear_bandits_abbasi2011improved}, we have $R_{3} \\leq B_{1} \\norm{g(\\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1}) / \\sqrt{m}}_{\\matr{Z}_{t-1}^{-1}}$.\n% \\begin{displaymath}\n% \\begin{split}\n%     & R_{3} \\leq B_{1} \\norm{g(\\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1}) / \\sqrt{m}}_{\\matr{Z}_{t-1}^{-1}}.\n% \\end{split}\n% \\end{displaymath}\nThen, for $R_{4}$, we have $\\abs{f(\\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1}) - \\inp{g(\\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1} / \\sqrt{m})}{\\widehat{\\matr{\\Theta}}_{t-1}}} $\n\\begin{displaymath}\n\\begin{split}\n   \\leq  R_{5} + R_{6} & = \\abs{f(\\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1}) - \\inp{g(\\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1})}{\\matr{\\Theta}_{t-1} - \\matr{\\Theta}_{0}}} \\\\\n    &\\qquad + \\abs{\\inp{g(\\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1})}{\\matr{\\Theta}_{t-1} - \\matr{\\Theta}_{0} - \\widehat{\\matr{\\Theta}}_{t-1} / \\sqrt{m}}}\n\\end{split}\n\\end{displaymath}\nwhere $R_{5}$ can be bounded by $B_{3}$ with Lemma \\ref{lemma_output_minus_inner_product}. Then, with conclusions from Lemma \\ref{lemma_linking_regre_est_with_net_param} and Lemma \\ref{lemma_after_GD_gradient_for_network_norm}, we have\n\\begin{displaymath}\n\\begin{split}\n     R_{6} &\\leq \\norm{\\matr{\\Theta}_{t-1} - \\matr{\\Theta}_{0} - \\widehat{\\matr{\\Theta}}_{t-1} / \\sqrt{m}}_{2}  \\cdot \\norm{g(\\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1})}_{2} \\\\\n    & \\leq B_{2} = \\big( (\\widetilde{I}_{1} \\cdot \\sqrt{t} B_{3} +  m\\cdot \\widetilde{I}_{2}) / (m\\lambda) + \\sqrt{t / (m\\lambda)} \\big) \\\\\n    &\\quad \\cdot \\big( \\Lambda\\cdot\\sqrt{9L + m^{-1}} + m^{-1}\\beta_{h} \\cdot \\sqrt{L\\cdot \\beta_{3}^{2}\\cdot (\\beta_{L}\\zeta)^{2L} + m} \\big),\n\\end{split}\n\\end{displaymath}\nwhich completes the proof.      $\\blacksquare$\n\n\n% ---------------------------------------------------------\n"
                    },
                    "subsubsection 5.1.2": {
                        "name": "2",
                        "content": " \\label{subsection_R_2}\nRegarding the regret term $R_{2}$ and for the aggregation module, we have\n\\begin{displaymath}\n\\begin{split}\n    \\matr{H}_{gnn} = \\sqrt{\\frac{1}{m}}\\cdot\\sigma(\\matr{A}_{t}^{k}\\cdot \\widetilde{\\matr{X}}\\matr{\\Theta}_{gnn}) \\in \\mathbb{R}^{N_{c} \\times m}\n\\end{split}\n\\end{displaymath}\nas the output where $\\matr{\\Theta}_{gnn}$ refers to the trainable weight matrix. \nThen, we use the following lemma to bound $R_{2}$.\n\\begin{lemma}\nAt this time step $t+1$, given any two arm groups $c_{i}, c_{j} \\in \\mathcal{C}$ and their sampled arm contexts $\\mathcal{X}_{c_{i}}^{t} = \\{\\vect{x}_{c_{i}, \\tau}\\}_{\\tau=1}^{t}$, $\\mathcal{X}_{c_{j}}^{t} = \\{\\vect{x}_{c_{j}, \\tau}\\}_{\\tau=1}^{t}$,\nwith the notation from Lemma \\ref{lemma_CB_one_step_same_graph} and the probability at least $1-\\delta$, we have\n\\begin{displaymath}\n\\begin{split}\n    \\norm{\\matr{A}^{*} - \\matr{A}_{t}}_{\\max} \\leq \\frac{1}{N_{c}}\\cdot\\sqrt{\\frac{1}{2t}\\log(\\frac{N_{c}^{2} - N_{c}}{\\delta})}\n\\end{split}\n\\end{displaymath}\nwhere $\\norm{\\cdot}_{\\max}$ refers to the greatest entry of a matrix. Then, we will have $R_{2} \\leq B_{4} \\sqrt{1 / t}$ with\n\\begin{displaymath}\n\\begin{split}\n    B_{4} = \\frac{ S\\sqrt{L} k }{\\sqrt{m}} (\\beta_{h} + \\Lambda) (\\zeta \\beta_{L} + \\frac{\\Upsilon\\zeta}{m})^{O(L)} \\sqrt{\\frac{1}{2}\\log(\\frac{N_{c}^{2} - N_{c}}{\\delta})},\n\\end{split}\n\\end{displaymath}\nand $N_{c} = \\abs{\\mathcal{C}}$ is the number of arm groups.\n\\label{lemma_adjacency_matrix_concentration}\n\\end{lemma}\n\\textbf{Proof.}\n% ---------------------------\nRecall that for $c_{i}, c_{j} \\in \\mathcal{C}$, the element of matrix\n$[\\matr{A}^{*}]_{ij} = \\\\ \\frac{1}{N_{c}}\\mathbb{E}_{x_{i}\\sim\\mathcal{D}_{c_{i}}, x_{j}\\sim\\mathcal{D}_{c_{j}}} (\\phi_{k_{\\mathcal{G}}}(x_{i})^{\\intercal}\\phi_{k_{\\mathcal{G}}}(x_{j})), \\forall i, j \\in [N_{c}]$, and $[\\matr{A}_{t}]_{ij} = \\frac{1}{t\\cdot N_{c}}\\sum_{\\tau=1}^{t}\\phi_{k_{\\mathcal{G}}}(x_{c_{i}, \\tau})^{\\intercal}\\phi_{k_{\\mathcal{G}}}(x_{c_{j}, \\tau})$. Here, suppose a distribution $\\mathcal{D}_{ij}$ where $\\mathbb{E}[\\mathcal{D}_{ij}] =  \\frac{1}{N_{c}}\\mathbb{E}_{x_{i}\\sim\\mathcal{D}_{c_{i}}, x_{j}\\sim\\mathcal{D}_{c_{j}}} (\\phi_{k_{\\mathcal{G}}}(x_{i})^{\\intercal}\\phi_{k_{\\mathcal{G}}}(x_{j}))$. \n%\nGiven $N_{c}$ arm groups, we have $N_{c}(N_{c} - 1) / 2$ different group pairs. For group pair $c_{i}, c_{j}\\in \\mathcal{C}$, each $\\phi_{k_{\\mathcal{G}}}(x_{c_{i}, \\tau})^{\\intercal}\\phi_{k_{\\mathcal{G}}}(x_{c_{j}, \\tau}), \\tau\\in [t]$ is a sample drawn from $\\mathcal{D}_{ij}$, and the element distance $\\abs{[\\matr{A}_{t}]_{ij} - [\\matr{A}^{*}]_{ij}}$ can be regarded as the difference between the mean value of samples and the expectation. Applying the Hoeffding's inequality and the union bound would complete the proof.\nAs $\\norm{\\cdot}_{2} \\leq n \\norm{\\cdot}_{\\max}$ for an $n\\times n$ square matrix, we have the bound for matrix differences.\n\nThen, consider the power of adjacency matrix $\\matr{A}^{k}$ (for graph $\\mathcal{G}$) as input and fix $\\widetilde{\\matr{X}}$. Analogous to the idea that the activation function with the Lipschitz continuity and smoothness property will lead to Lipschitz neural networks \\cite{conv_theory-allen2019convergence}, applying Assumption \\ref{assumption_act_func_Lipschitz} and with Lemma \\ref{lemma_after_GD_weight_matrices_bounds}, Lemma \\ref{lemma_after_GD_model_results_variables}, we simply have the gradient $g(\\mathcal{G}, \\widetilde{\\matr{X}};\\matr{\\Theta}_{t-1})$ being Lipschitz continuous w.r.t. the input graph as\n\\begin{displaymath}\n\\begin{split}\n    R_{2} & \\leq \n    \\norm{g(\\mathcal{G}^{*}, \\widetilde{\\matr{X}};\\matr{\\Theta}_{t-1}) - g(\\mathcal{G}_{t}, \\widetilde{\\matr{X}};\\matr{\\Theta}_{t-1})}_{2} \\cdot \\norm{\\matr{\\Theta}_{t-1}^{*} - \\matr{\\Theta}_{0}}_{2}  \\\\\n    & \\leq \\frac{S\\sqrt{L} }{\\sqrt{m}} (\\beta_{h} + \\Lambda) (\\zeta \\beta_{L} + \\frac{\\Upsilon\\zeta}{\\sqrt{m}})^{O(L)}\\cdot \\abs{\\norm{(\\matr{A}_{t})^{k}}_{2}  - \\norm{\\matr{(A^{*}})^{k}}_{2}} \\\\\n    % & \\underset{(i)}{=} \\frac{S\\sqrt{L}}{\\sqrt{m}} (\\beta_{h} + \\Lambda) (\\zeta \\beta_{L} + \\frac{\\Upsilon\\zeta}{m})^{O(L)} \\cdot\\abs{\\norm{\\matr{A}_{t}}_{2}^{k} - \\norm{\\matr{A^{*}}}_{2}^{k}} \\\\\n    & \\underset{(i)}{\\leq} \\frac{S\\sqrt{L} k}{\\sqrt{m}} (\\beta_{h} + \\Lambda) (\\zeta \\beta_{L} + \\frac{\\Upsilon\\zeta}{\\sqrt{m}})^{O(L)}\\cdot \\norm{\\matr{A}_{t} - \\matr{A^{*}}}_{2}\n\\end{split}\n\\end{displaymath}\n% where $(i)$ is due to the symmetry of $\\matr{A}_{t}, \\matr{A}^{*}$, while $(ii)$ is because bounded polynomial functions are Lipschitz continuous.\nwhere $(i)$ is because $\\matr{A}_{t}, \\matr{A}^{*}$ are symmetric and bounded polynomial functions are Lipschitz continuous.\nCombining the two parts will lead to the conclusion.\n$\\blacksquare$\n\n\n% ----------------------------------------------------\n"
                    },
                    "subsubsection 5.1.3": {
                        "name": "1",
                        "content": "\nAt time step $t$, with the notation and conclusions from Lemma \\ref{lemma_CB_one_step_same_graph} and Lemma \\ref{lemma_adjacency_matrix_concentration}, re-scaling the constant $\\delta$, we have the confidence bound given embedded arm $\\widetilde{\\matr{X}}$ as\n\\begin{equation}\n\\begin{split}\n    \\textsf{CB}_{t}(\\widetilde{\\matr{X}}) \\leq  B_{1} \\norm{g(\\mathcal{G}_{t}, \\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1}) / \\sqrt{m}}_{\\matr{Z}_{t-1}^{-1}} + B_{2} + B_{3} + B_{4} \\sqrt{\\frac{1}{t}}.\n\\end{split}\n\\label{eq_CB_one_step}\n\\end{equation}\n\n\n\n\n% ======================================================================\n\\vspace{-0.2cm}\n"
                    }
                },
                "subsection 5.2": {
                    "name": "Regret Bound",
                    "content": "\n\nWith the UCB shown in Eq. \\ref{eq_CB_one_step}, we provide the following regret upper bound $R(T)$, for a total of $T$ time steps.\n\n\n\\begin{theorem}\nGiven the received contexts and rewards, with the notation from Lemma \\ref{lemma_CB_one_step_same_graph}, Lemma \\ref{lemma_adjacency_matrix_concentration}, and probability at least $1-\\delta$, if $m, \\eta$ satisfy conditions in Lemma \\ref{lemma_CB_one_step_same_graph}, we will have the regret\n\\begin{displaymath}\n\\begin{split}\n    & R(T) \\leq 2\\cdot (2B_{4}\\sqrt{T} + 2 - B_{4}) + 2\\sqrt{2\\widetilde{d} T \\log(1+T/\\lambda) + 2T} \\\\\n    &\\qquad \\cdot \\big(\\sqrt{\\lambda}S + \\sqrt{1-2\\log(\\delta / 2) + (\\widetilde{d} \\log(1+T/\\lambda))}\\big) \n\\end{split}\n\\end{displaymath}\nwhere the effective dimension $\\widetilde{d} = \\frac{\\log\\det(\\matr{I} + \\matr{G}(0) / \\lambda)}{\\log(1+T/\\lambda)}$\nwith \\\\\n$\\matr{G}(0) = \\matr{G}_{0}\\matr{G}_{0}^{\\intercal}$  \nand $\\matr{G}_{0} = \\big( g(\\widetilde{\\matr{X}}_{1}; \\matr{\\Theta}_{0})^{\\intercal}, \\dots, g(\\widetilde{\\matr{X}}_{t}; \\matr{\\Theta}_{0})^{\\intercal} \\big)$. \n\\label{theorem_regret_bound}\n\\end{theorem}\n\n\\textbf{Proof.}\nBy definition, we have the regret $R_{t}$ for time step $t$ as\n\\begin{displaymath}\n\\begin{split}\n    R_{t} &= \n    h(\\mathcal{G}^{*}, \\widetilde{\\matr{X}}_{t}^{*}) - h(\\mathcal{G}^{*}, \\widetilde{\\matr{X}}_{t}) \\\\\n    & \\leq \\textsf{CB}_{t}(\\widetilde{\\matr{X}}_{t}^{*}) +  f(\\mathcal{G}_{t}, \\widetilde{\\matr{X}}_{t}^{*}; \\matr{\\Theta}_{t-1})\n    - h(\\mathcal{G}^{*}, \\widetilde{\\matr{X}}_{t}) \\\\\n    & \\leq \\textsf{CB}_{t}(\\widetilde{\\matr{X}}_{t}) +  f(\\mathcal{G}_{t}, \\widetilde{\\matr{X}}_{t}; \\matr{\\Theta}_{t-1})\n    - h(\\mathcal{G}^{*}, \\widetilde{\\matr{X}}_{t})\n    \\leq 2\\cdot \\textsf{CB}_{t}(\\widetilde{\\matr{X}}_{t})\n\\end{split}\n\\end{displaymath}\nwhere the second inequality is due to our arm pulling mechanism.\nThen, based on Lemma \\ref{lemma_adjacency_matrix_concentration}, Lemma \\ref{lemma_CB_one_step_same_graph}, and Eq. \\ref{eq_CB_one_step}, we have $R(T) =$\n\\begin{displaymath}\n\\begin{split}\n    \\sum_{t=1}^{T} & R_{t}   \\leq  2\\sum_{t=1}^{T} \\bigg(B_{1} \\norm{g(\\mathcal{G}_{t},  \\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1}) / \\sqrt{m}}_{\\matr{Z}_{t-1}^{-1}} + B_{2} + B_{3} + B_{4} \\sqrt{\\frac{1}{t}} \\bigg)\\\\\n    & \\leq 2\\cdot (2B_{4}\\sqrt{T} + 2 - B_{4}) + 2\\sum_{t=1}^{T} (B_{1} \\norm{g(\\mathcal{G}_{t},  \\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1}) / \\sqrt{m}}_{\\matr{Z}_{t-1}^{-1}})\n\\end{split}\n\\end{displaymath}\nwith the choice of $m$ for bounding the summation of $B_{2}, B_{3}$, and the bound of $\\sum_{i=1}^{T}[t^{-i / 2}]$ in \\cite{bound_sum_sqrt_T_chlebus2009approximate}. Then, with Lemma 11 from \\cite{improved_linear_bandits_abbasi2011improved}, \n\\begin{displaymath}\n\\begin{split}\n    & \\sum_{t=1}^{T} (B_{1} \\norm{g(\\mathcal{G}_{t},  \\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1}) / \\sqrt{m}}_{\\matr{Z}_{t-1}^{-1}}) \\\\\n    & \\leq B_{1} \\sqrt{T\\sum_{t=1}^{T}  \\norm{g(\\mathcal{G}_{t},  \\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1}) / \\sqrt{m}}_{\\matr{Z}_{t-1}^{-1}}^{2}}\n     \\leq \\sqrt{T} B_{1} \\sqrt{2\\log(\\frac{\\det(\\matr{Z}_{T})}{\\det(\\lambda \\matr{I})})} \\\\\n    & \\underset{(i)}{\\leq} \\sqrt{2\\widetilde{d} T \\log(1+T/\\lambda) + 2T} \n     \\big(\\sqrt{\\lambda}S + \\sqrt{1-2\\log(\\delta / 2) + (\\widetilde{d} \\log(1+T/\\lambda))}\\big)\n\\end{split}\n\\end{displaymath}\nwhere $(i)$ is based on Lemma 6.3 in \\cite{CNN_UCB-ban2021convolutional} and Lemma 5.4 in \\cite{Neural-UCB}. \n$\\blacksquare$\n\nHere, the effective dimension $\\widetilde{d}$ measures the vanishing speed of $\\matr{G}(0)$'s eigenvalues, and it is analogous to that of existing works on neural contextual bandits algorithms \\cite{CNN_UCB-ban2021convolutional,Neural-UCB,neural_multifacet-ban2021multi}. As $\\widetilde{d}$ is smaller than the dimension of the gradient matrix $\\matr{G}(0)$, it is applied to prevent the dimension explosion. Our result matches the state-of-the-art regret complexity \\cite{Neural-UCB,neural_thompson-zhang2020neural,CNN_UCB-ban2021convolutional} under the worst-case scenario.\n\n\n\n\n% ---------------------------\n\\vspace{-0.2cm}\n"
                },
                "subsection 5.3": {
                    "name": "Model Convergence after GD",
                    "content": "\nFor model convergence, we first give an assumption of the gradient matrix after $j$ iterations of GD. First, we define $\\matr{G}^{(j)}(\\matr{\\Theta}_{L-1}) =\n\\big( g(\\widetilde{\\matr{X}}_{1}; \\matr{\\Theta}_{L-1}^{(j)}), \\dots, g(\\widetilde{\\matr{X}}_{T}; \\matr{\\Theta}_{L-1}^{(j)}) \\big)^{\\intercal}\n\\big( g(\\widetilde{\\matr{X}}_{1}; \\matr{\\Theta}_{L-1}^{(j)}), \\dots, g(\\widetilde{\\matr{X}}_{T}; \\matr{\\Theta}_{L-1}^{(j)}) \\big)$ \\\\\nwhere $g(\\widetilde{\\matr{X}}; \\matr{\\Theta}_{L-1})$ is the gradient vector w.r.t. $\\matr{\\Theta}_{L-1}$.\n\\begin{Assumption}\nWith width $m \\geq \\mbox{Poly}(T, L, \\frac{1}{\\beta_{F}}, \\frac{1}{\\lambda}, (\\zeta \\beta_{L})^{L}, \\log(\\frac{1}{\\delta}))$ and for $j \\in [J]$, we have the minimal eigenvalue of $\\matr{G}^{(j)}$ as\n    \\begin{displaymath}\n    \\begin{split}\n        \\lambda_{\\min}(\\matr{G}^{(j)}(\\matr{\\Theta}_{L-1})) \\geq \\lambda_{0} / 2\n    \\end{split}\n    \\end{displaymath}\nwhere $\\lambda_{0}$ is the minimal eigenvalue of the neural tangent kernel (NTK) \\cite{NTK_jacot2018neural} matrix induced by \\name.\n\\label{assumption_gradient_matrix_eigenvalue}\n\\end{Assumption}\nNote that Assumption \\ref{assumption_gradient_matrix_eigenvalue} is mild and has been proved for various neural architectures in \\cite{skip_kernel_du2019gradient}. \n% We make this assumption to omit the proof due to page limit. \\TODO{check}\nThe NTK for \\name~ can be derived following a comparable approach as in \\cite{GNTK_du2019graph,NTK_jacot2018neural}.\nThen, we apply the following lemma and theorem to prove the convergence of \\name.\nThe proof of Lemma \\ref{lemma_after_GD_next_iteration_output} is given in the appendix.\n\n\n% ------------------------------------------------------------\n\n\\begin{lemma}\nAfter $T$ time steps, assume the network are trained with the $J$-iterations GD on the past contexts and rewards. Then, with  $\\beta_{F} > 0$ and $\\beta_{F}\\cdot \\eta < 1$, for any $j\\in [J]$:\n\\begin{displaymath}\n\\begin{split}\n    \\norm{\\vect{F}^{(j)}_{T} - \\vect{F}^{(j+1)}_{T}}_{2}^{2} \\leq \\frac{1}{4}\\eta \\beta_{F} \\cdot \\norm{\\vect{F}^{(j)}_{T} - \\vect{Y}_{T}}_{2}^{2}\n\\end{split}\n\\end{displaymath}\nwith network width $m$ defined in Lemma \\ref{lemma_CB_one_step_same_graph}.\n\\label{lemma_after_GD_next_iteration_output}\n\\end{lemma}\nThe Lemma \\ref{lemma_after_GD_next_iteration_output} shows that we are able to bound the difference in network outputs after one step of GD. Then, we proceed to prove the convergence with the theorem below.\n\n% ------------------------------------------------------------\n\\begin{theorem}\nAfter $T$ time steps, assume the model with width $m$ defined in Lemma \\ref{lemma_CB_one_step_same_graph} is trained with the $J$-iterations GD on the contexts $\\{\\widetilde{\\matr{X}}_{\\tau}\\}_{\\tau=1}^{T}$ and rewards $\\{r_{\\tau}\\}_{\\tau=1}^{T}$. With probability at least $1 - \\delta$, a constant $\\beta_{F}$ such that $\\beta_{F}\\cdot \\eta < 1$, set the network width $m \\geq \\mbox{Poly}(T, L, \\frac{1}{\\beta_{F}}, \\frac{1}{\\lambda}, (\\zeta \\beta_{L})^{L}, \\log(\\frac{1}{\\delta}))$ and the learning rate $\\eta \\leq \\mathcal{O}(T^{-1}L^{-1}\\beta_{h}^{-2}(2\\zeta \\beta_{L})^{-2L})$. Then, for any $j\\in [J]$, we have\n\\begin{displaymath}\n\\begin{split}\n    \\norm{\\vect{F}^{(j)}_{T}- \\vect{Y}_{T}}_{2}^{2} \\leq (1 - \\beta_{F}\\cdot \\eta)^{j} \\cdot \\norm{\\vect{F}^{(0)}_{T}- \\vect{Y}_{T}}_{2}^{2}\n\\end{split}\n\\end{displaymath}\nwhere the vector $\\vect{F}^{(j)} = [f(\\mathcal{G}_{T}, \\widetilde{\\matr{X}}_{\\tau};\\matr{\\Theta}^{(j)})]_{\\tau=1}^{T}$, and $\\vect{Y}_{T} = [r_{\\tau}]_{\\tau=1}^{T}$.\n\\label{theorem_after_GD_param_outputs}\n\\end{theorem}\n\n% -----------------\n\\textbf{Proof.}\nFollowing an approach analogous to \\cite{skip_kernel_du2019gradient}, we apply and induction based method for the proof. The hypothesis is that $\\norm{\\vect{F}^{(j)}_{T}- \\vect{Y}_{T}}_{2}^{2} \\leq (1 - \\beta_{F}\\cdot \\eta)^{j} \\cdot \\norm{\\vect{F}^{(0)}_{T}- \\vect{Y}_{T}}_{2}^{2}, j\\in [J]$. With a similar procedure in Condition A.1 of \\cite{skip_kernel_du2019gradient}, we have\n% \\TODO{check}\n\\begin{displaymath}\n\\begin{split}\n    & \\norm{\\vect{F}^{(j+1)}_{T}- \\vect{Y}_{T}}_{2}^{2} \\leq \n    \\norm{\\vect{F}^{(j)}_{T}- \\vect{Y}_{T}}_{2}^{2} - 2\\eta\\norm{\\vect{F}^{(j)}_{T}- \\vect{Y}_{T}}_{\\matr{G}^{(j)}}^{2} \\\\\n    &\\qquad - 2(\\vect{Y}_{T} - \\vect{F}^{(j)}_{T})^{\\intercal} \\matr{V}^{(j)} + \n    \\norm{\\vect{F}^{(j+1)}_{T}- \\vect{F}^{(j)}_{T}}_{2}^{2}\n\\end{split}\n\\end{displaymath}\nwith $\\matr{V}^{(j)} = (\\matr{V}^{(j)}(\\widetilde{\\matr{X}}_{1}), \\dots, \\matr{V}^{(j)}(\\widetilde{\\matr{X}}_{T}))^{\\intercal}$. For $\\matr{\\Theta}' \\in \\{\\matr{\\Theta}_{gnn}, \\dots, \\matr{\\Theta}_{L-1}\\}$,\n\\begin{displaymath}\n\\begin{split}\n    & \\abs{\\matr{V}^{(j)}(\\widetilde{\\matr{X}})} = \n    \\eta \\max_{0\\leq s\\leq \\eta} \\bigg[ \\sum_{\\matr{\\Theta}'} \n    \\norm{\\nabla\\mathcal{L}({\\matr{\\Theta}'}^{(j)})}_{F} \n    \\norm{\\nabla f({\\matr{\\Theta}'}^{(j)}) - \\nabla f({\\matr{\\Theta}'}^{(j)}, s)}_{F}\n    \\bigg]\n\\end{split}\n\\end{displaymath}\nwhere $\\nabla f({\\matr{\\Theta}'}^{(j)}, s) =\n\\nabla f \\big( {\\matr{\\Theta}'}^{(j)} - s\\cdot \\nabla\\mathcal{L}({\\matr{\\Theta}'}^{(j)}) \\big)$. The notation $\\mathcal{G}, \\widetilde{\\matr{X}}$ is omitted for simplicity.\nThen, based on the conclusions from Lemma \\ref{lemma_after_GD_I_2_term}, Lemma \\ref{lemma_after_GD_next_iteration_output} and Assumption \\ref{assumption_gradient_matrix_eigenvalue}, we can have\n\\begin{displaymath}\n\\begin{split}\n    & \\norm{\\vect{F}^{(j+1)}_{T}- \\vect{Y}_{T}}_{2}^{2} \\leq \n    (1-\\eta\\lambda_{0})\\norm{\\vect{F}^{(j)}_{T} - \\vect{Y}_{T}}_{2}^{2} - 2(\\vect{Y}_{T} - \\vect{F}^{(j)}_{T})^{\\intercal} \\matr{V}^{(j)} \\\\\n    & \\qquad+ \\norm{\\vect{F}^{(j+1)}_{T}- \\vect{F}^{(j)}_{T}}_{2}^{2}\n    \\leq (1-\\frac{\\eta\\lambda_{0}}{2})\\norm{\\vect{F}^{(j)}_{T} - \\vect{Y}_{T}}_{2}^{2}\n\\end{split}\n\\end{displaymath}\nby setting $\\beta_{F} = \\lambda_{0} / 2$.         $\\blacksquare$\n\nThis theorem shows that with sufficiently large $m$ and proper $\\eta$, the GD will converge to the global minimum at a linear rate, which is essential for proving the regret bound.\n\n\n\n\n% ===========================================================\n\\vspace{-0.1cm}\n"
                }
            },
            "section 6": {
                "name": "Experiments",
                "content": " \\label{sec_experiments}\nIn this section, we demonstrate the effectiveness of our proposed framework by comparing its performances with state-of-the-art baselines through experiments on four real data sets. As linear algorithms have been outperformed in previous works \\cite{Neural-UCB,neural_thompson-zhang2020neural,kmtl-ucb_2017}, we will not include these linear methods in the experiments below.  \nOur six baseline algorithms are: \n\\begin{itemize}\n    \\item KMTL-UCB \\cite{kmtl-ucb_2017} estimates the \"task similarities\" with received contextual information. The estimations are based on a variant of kernel ridge regression.\n    \\item Kernel-Ind is Kernel-UCB \\cite{kernel_ucb-2013} under the \\textit{\"disjoint setting\"} \\cite{linucb-Ind_li2010contextual} where it learns individual estimators for each arm group. \n    \\item Kernel-Pool represents Kernel-UCB under the \\textit{\"pooling setting\"} where it applies a single estimator for all arm groups.\n    \\item Neural-TS stands for Neural Thompson Sampling \\cite{neural_thompson-zhang2020neural} \n    with group-aware embedding, which enables it to leverage the group information. It applies a neural network for exploitation and Thompson sampling strategy for exploration.\n    \\item Neural-Pool is for Neural-UCB \\cite{Neural-UCB} with a single neural network to evaluate the reward, and calculate the upper confidence bounds with the network gradients. \n    \\item Neural-Ind represents Neural-UCB with group-aware embedding for utilizing the group information. \n\\end{itemize}\n% (1) KMTL-UCB \\cite{kmtl-ucb_2017} estimates the \"task similarities\" with received contextual information. The estimations are based on a variant of kernel ridge regression.\n% (2) Kernel-Ind is Kernel-UCB \\cite{kernel_ucb-2013} under the \\textit{\"disjoint setting\"} \\cite{linucb-Ind_li2010contextual} where it learns individual estimators for each arm group. \n% (3) Kernel-Pool represents Kernel-UCB under the \\textit{\"pooling setting\"} where it applies a single estimator for all arm groups.\n% (4) Neural-TS stands for Neural Thompson Sampling \\cite{neural_thompson-zhang2020neural} \n% with group-aware embedding, which enables it to leverage the group information. Neural-TS applies a neural network for estimation and Thompson sampling strategy for exploration.\n% (5) Neural-Pool is for Neural-UCB \\cite{Neural-UCB} with a single neural network to evaluate the reward, and calculate the upper confidence bounds with the network gradients. \n% (6) Neural-Ind represents Neural-UCB with group-aware embedding for utilizing the group information.\n%\n\nNote that COFIBA \\cite{co_filter_bandits_2016} is naturally Kernel-Ind (with linear kernel) given the arm group information and one single user to serve, so we do not include it in our benchmarks.\nTo find the best exploration parameter, we perform grid searches over the range $\\{10^{-1}, 10^{-2}, 10^{-3}\\}$ for all algorithms. Similarly, the learning rate for neural algorithms are chosen from $\\{10^{-2}, 10^{-3}, 10^{-4}\\}$. For Neural-UCB, Neural-TS and our reward estimation module, we apply a two-layer FC network with $m=500$. RBF kernels are applied for KMTL-UCB and Kernel-UCB as well as our graph estimation module. Kernel-Pool and Neural-Pool will not fit into the multi-class classification setting, as we only receive one arm (context) at each time step without the arm group information.\n\n\n\n% ---------------------------------\n\\vspace{-0.2cm}\n",
                "subsection 6.1": {
                    "name": "Real Data Sets",
                    "content": "\nHere, we compare our proposed model with baseline algorithms on four real data sets with different specifications. \n\n\\textit{MovieLens and Yelp data sets.}\nThe first real data set is the \"MovieLens 20M rating data set\" \n(\\url{grouplens.org/datasets/movielens/20m/})\n. \nTo obtain the user features, we first choose 100 movies and 4000 users with \\textbf{most reviews} to form the user-movie matrix where the entries are user ratings, and the user features $\\vect{v}_{u}\\in\\mathbb{R}^{d}$ are obtained through singular value decomposition (SVD) where the dimension $d=20$. Then, since the  genome-scores of user-specified tags are provided for each movie, we select 20 tags with the highest variance to construct the movie features $\\vect{v}_{i} \\in \\mathbb{R}^{d}$ with their scores on these tags. Then, these movies are allocated into 19 groups based on their genres ($\\abs{\\mathcal{C}}=19$).\nReceiving a user $u_{t}$ at each time step $t$, we follow the idea of Generalized Matrix Factorization (GMF) \\cite{NCF_he2017neural,PURE_zhou2021pure,XRS_Yao_2021} to encode user information into the contexts as $\\widetilde{\\vect{x}}^{(i)}_{c, t} = [\\vect{v}_{u_{t}} \\odot \\vect{v}_{i}] \\in \\mathbb{R}^{d}, c\\in \\mathcal{C}_{t}, i\\in[n_{c, t}]$, and let $\\abs{\\mathcal{X}_{t}} = 20$. Finally, we concatenate a constant 0.01 to each $\\widetilde{\\vect{x}}^{(i)}_{c, t}$ to obtain $\\vect{x}^{(i)}_{c, t} \\in \\mathbb{R}^{d_{x}}$, which makes $d_{x}=21$, before normalizing $\\vect{x}^{(i)}_{c, t}$. Rewards $r_{c, t}^{(i)}$ are user ratings normalized into range [0, 1]. \n\nThen, for the Yelp data set (\\url{https://www.yelp.com/dataset}), we choose 4000 users with \\textbf{most reviews} and restaurants from 20 different categories as arms $(\\abs{\\mathcal{C}}=20)$. Both user features and arm features are obtained through SVD with the dimension $d=20$. Analogous to the MovieLens data set, we follow the GMF based approach and the fore-mentioned constant concatenation to get the arm context $\\vect{x}^{(i)}_{c, t}$ ($d_{x}=21, \\abs{\\mathcal{X}_{t}}=20$) to encode the user information, and the rewards are the normalized user ratings.\n\n\\textit{MNIST data set with augmented classes (MNIST-Aug)}.\nMNIST is a well-known classification data set with 10 original classes where each sample is labeled as a digit from 0 to 9. Here, we further divide the samples from each class into 5 sub-divisions through $K$-means clustering, which gives us a total of 50 augmented sub-classes (i.e., arm groups) for the whole data set. Given a sample $\\vect{x}_{t}$, the reward would be $r_{t}=1$ if the learner accurately predicts its sub-class; or the learner will receive the partial reward $r_{t}=0.5$ when it chooses the wrong sub-class, but this sub-class and the correct one belong to the same digit (original class). Otherwise, the reward $r_{t}=0$.\n\n\n\\textit{XRMB data set}.\nXRMB data set \\cite{XRMB_wang2015unsupervised} is a multi-view classification data set with 40 different labels. Here, we only apply samples from the first 38 classes as there are insufficient samples for the last two classes. The arm contexts $\\vect{x}_{t}$ are the first-view features of the samples. Then, learner will receive a reward of $r_{t}=1$ when they predict the right label, and $r_{t}=0$ otherwise. \n\n\n\n% ------------------------------\n\\vspace{-0.2cm}\n"
                },
                "subsection 6.2": {
                    "name": "Experimental Results",
                    "content": "\n\n% \\begin{figure}[t]\n%   \\centering\n%   \\includegraphics[width=\\linewidth]{Fig/MovieLens_6_algo.png}\n%   \\caption{Cumulative regret for MovieLens data set.}\n%   \\label{figure_MovieLens_result}\n% \\end{figure}\n\n\n\n% \\begin{figure}[t]\n%   \\centering\n%   \\includegraphics[width=\\linewidth]{Fig/MNIST_4_algos.png}\n%   \\caption{Cumulative regret for MNIST data set.}\n%   \\label{figure_MNIST_result}\n% \\end{figure}\n\n% \\begin{figure}[t]\n%   \\centering\n%   \\includegraphics[width=\\linewidth]{Fig/XRMB_4_algo.png}\n%   \\caption{Cumulative regret for XRMB data set.}\n%   \\label{figure_XRMB_result}\n% \\end{figure}\n\n\nFigure \\ref{figure_recommendation_result} shows the cumulative regret results on the two real recommendation data sets where our proposed \\name~ outperforms all strong baselines. In particular, we can find that algorithms with group-aware arm embedding tend to perform better than those without the arm group information (Kernel-Pool, Neural-Pool). This confirms the necessity of exploiting arm group information. Nevertheless, these baselines fed with group-aware are outperformed by \\name, which implies the advantages of of our new graph-based model.\n%\\ban{I don't understand why the former one can lead to the latter one? That Proposed algorithm outperforms group-aware. ones can confirm this.}\n%which confirms the necessity of our new graph-based model.\nMeantime, it can be observed that neural algorithms (\\name, Neural-Ind, Neural-TS) generally perform better compared with other baselines due to the representation power of neural networks. Note that since the user features and arm features of the Yelp data set are directly extracted with SVD, the reward estimation on the Yelp data set is comparably easy compared with others data sets. Therefore, the performances of benchmarks do not differ dramatically with \\name. In opposite, MovieLens data set with true arm features tends to be a more challenging task where a more complex mapping from arms to their rewards can be involved. This can be reason for \\name's superiority over the competitors.\n\nThen, Figure \\ref{figure_classification_result} shows the cumulative regret results on the two classification data sets where our \\name~ achieves the best performance compared with other baselines. In particular, since sub-classes from each digit are highly correlated in the MNIST-Aug data set, our proposed \\name~ tends to perform significantly better due to its ability of leveraging arm group correlations compared with other neural methods. Thus, these two aspects verify our claim that associating the neural models with arm group relationship modeling can lead to better performance.\n\n\n% ------------------------------\n\\vspace{-0.2cm}\n"
                },
                "subsection 6.3": {
                    "name": "Parameter Study",
                    "content": "\n\n\n\nIn this section, we conduct our parameter study for the neighborhood parameter $k$ on the MovieLens data set and MNIST-Aug data set with augmented labels, and the results are presented in Figure \\ref{figure_parameter_study}. For the MovieLens data set, we can observe that setting $k=1$ would give the best result. Although increasing $k$ can enable the aggregation module to propagate the hidden representations for multiple hops, it can potentially fail to focus on local arm group neighbors with high correlations, which is comparable to the aforementioned \"over-smoothing\" problem. In addition, since the arm group graph of MovieLens data set only has 19 nodes, $k=1$ would be enough. Meantime, setting $k=1$ also achieves the best performance on the MNIST data set. The reason can be that the $1$-hop neighborhood of each sub-class can already include all the other sub-classes from the same digit with heavy edge weights within the neighborhood for arm group collaboration. Therefore, unless setting $k$ to considerably large values, the \\name~can maintain robust performances, which reduces the workload for hyperparameter tuning. \n\n\n\n\n% ==========================================\n\\vspace{-0.2cm}\n"
                }
            },
            "section 7": {
                "name": "Conclusion",
                "content": " \\label{sec_conclusion}\nIn this paper, motivated by real applications where the arm group information is available, we propose a new graph-based model to characterize the relationship among arm groups.\nBase on this model, we propose a novel UCB-based algorithm named \\name, which uses GNN to exploit the arm group relationship and share the information across similar arm groups. \nCompared with existing methods, \\name~ provides a new way of collaborating multiple neural contextual bandit estimators for obtaining the rewards.\nIn addition to the theoretical analysis of \\name, we empirically demonstrate its superiority on real data sets in comparison with state-of-the-art baselines.\n\n\n\n\n\n%%\n%% The acknowledgments section is defined using the \"acks\" environment\n%% (and NOT an unnumbered section). This ensures the proper\n%% identification of the section in the article metadata, and the\n%% consistent spelling of the heading.\n\n% ==========================================\n\\begin{acks}\nThis work is supported by National Science Foundation under Award No. IIS-1947203, IIS-2117902, IIS-2137468, and IIS-2002540. The views and conclusions are those of the authors and should not be interpreted as representing the official policies of the funding agencies or the government.\n\\end{acks}\n\n\n%%\n%% The next two lines define the bibliography style to be used, and\n%% the bibliography file.\n\n%\n\\bibliographystyle{ACM-Reference-Format}\n\\bibliography{AGG_UCB}\n%% If your work has an appendix, this is the place to put it.\n\n% ============================================================================================\n\\clearpage\n\\appendix\n\n% \\section{Proof of Confidence Bound}\n% % Recall that in Lemma~\\ref{lemma_expect_rewards}, we have\n% Recall that at time step $t$, given embedded context matrix $\\widetilde{\\matr{X}}\\in \\mathbb{R}^{d_{\\widetilde{x}}}$, the output of our proposed framework is \n% $\\widehat{r}_{t} = f(\\mathcal{G}_{t}, \\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1})$\n% with $\\mathcal{G}_{t}$, $\\matr{\\Theta}_{t-1}$ as the estimated arm group graph and trained parameters separately. The true function $h(\\mathcal{G}^{*}, \\widetilde{\\matr{X}})$ is defined in Lemma \\ref{lemma_expect_rewards}. Suppose that there exist the optimal parameters $\\matr{\\Theta}^{*}$ and the true arm group graph $\\mathcal{G}^{*}$,\n% the regret will be\n% \\begin{equation}\n% \\begin{split}\n%     & \\textsf{CB}_{t}(\\widetilde{\\matr{X}}) = \\abs{f(\\mathcal{G}_{t}, \\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1}) - h(\\mathcal{G}^{*}, \\widetilde{\\matr{X}})} \\\\\n%     &\\leq \\underbrace{\\abs{f(\\mathcal{G}_{t}, \\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1}) - f(\\mathcal{G}_{t}, \\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1}^{*})}}_{R_{1}} + \n%     \\underbrace{\\abs{f(\\mathcal{G}_{t}, \\widetilde{\\matr{X}}; \\matr{\\Theta}^{*}) - h(\\mathcal{G}^{*}, \\widetilde{\\matr{X}})}}_{R_{2}}\n% \\end{split}\n% \\label{eq_regret_split}\n% \\end{equation}\n% where $R_{1}$ denotes the error induced by parameter training and $R_{2}$ refers to the error from arm group graph estimation. \n\n% \\subsection{Bounding $R_{2}$} \\label{subsection_R_2}\n% First, for $R_{2}$, we recall that for the aggregation module\n% \\begin{displaymath}\n% \\begin{split}\n%     \\matr{H}_{gnn} = \\sqrt{\\frac{1}{m}}\\cdot\\sigma(\\matr{A}_{t}^{k}\\widetilde{\\matr{X}}\\cdot\\matr{\\Theta}_{gnn}) \\in \\mathbb{R}^{N_{c} \\times m}\n% \\end{split}\n% \\end{displaymath}\n% as the output of the aggregation module with $\\matr{\\Theta}_{gnn}$ as the trainable parameters. By considering $\\matr{A}_{t}^{k}$ as the input, we simply have \n% \\begin{displaymath}\n% \\begin{split}\n%     R_{2} & \\leq (\\zeta \\beta_{L} + \\frac{\\Upsilon\\zeta}{m})^{O(L)} \\abs{\\norm{(\\matr{A}_{t})^{k}}_{2}  - \\norm{\\matr{(A^{*}})^{k}}_{2}} = (\\zeta \\beta_{L} + \\frac{\\Upsilon\\zeta}{m})^{O(L)} \\\\\n%     & \\quad\\cdot\\abs{\\norm{\\matr{A}_{t}}_{2}^{k} - \\norm{\\matr{A^{*}}}_{2}^{k}} \n%     \\leq (\\zeta \\beta_{L} + \\frac{\\Upsilon\\zeta}{m})^{O(L)} k\\cdot \\norm{\\matr{A}_{t} - \\matr{A^{*}}}_{2}\n% \\end{split}\n% \\end{displaymath}\n% regarding the $\\zeta$-continuous property of $\\sigma(\\cdot)$ \\cite{conv_theory-allen2019convergence} and the bound of trained weight matrices in Lemma \\ref{lemma_after_GD_weight_matrices_bounds}; and the first equality is due to the symmetry of $\\matr{A}_{t}^{k}$ while the last inequality is because the Lipschitz continuity of polynomial functions.\n\n% Given $c_{i}, c_{j} \\in \\mathcal{C}$, \n% $[\\matr{A}^{*}]_{ij} = \\mathbb{E}_{x_{i}\\sim\\mathcal{D}_{c_{i}}, x_{j}\\sim\\mathcal{D}_{c_{j}}} (\\phi_{k_{\\mathcal{G}}}(x_{i})^{\\intercal}\\phi_{k_{\\mathcal{G}}}(x_{j}))$\n% , and the elements in \n% $[\\matr{A}_{t}]_{ij} = \\frac{1}{t}\\sum_{\\tau=1}^{t}\\phi_{k_{\\mathcal{G}}}(x_{c_{i}, \\tau})^{\\intercal}\\phi_{k_{\\mathcal{G}}}(x_{c_{j}, \\tau})$ \n% is calculated with the observed samples. Here, we assume a distribution $\\mathcal{D}_{ij}$ for $c_{i}, c_{j}$ where $\\mathbb{E}[\\mathcal{D}_{ij}] = \\mathbb{E}_{x_{i}\\sim\\mathcal{D}_{c_{i}}, x_{j}\\sim\\mathcal{D}_{c_{j}}} (\\phi_{k_{\\mathcal{G}}}(x_{i})^{\\intercal}\\phi_{k_{\\mathcal{G}}}(x_{j}))$. Then, we use the following lemma to bound $\\norm{\\matr{A}^{*} - \\matr{A}_{t}}_{\\infty}$.\n% \\begin{lemma}\n% At this time step $t+1$, given the any two arm groups $c_{i}, c_{j} \\in \\mathcal{C}$ and their sampled arms $\\{\\vect{x}_{c_{i}, \\tau}\\}_{\\tau=1}^{t}$, $\\{\\vect{x}_{c_{j}, \\tau}\\}_{\\tau=1}^{t}$,\n% with the probability at least $1-\\delta$, we will have\n% \\begin{displaymath}\n% \\begin{split}\n%     \\norm{\\matr{A}^{*} - \\matr{A}_{t}}_{\\infty} \\leq \\sqrt{\\frac{1}{2t}\\log(\\frac{N_{c}^{2} - N_{c}}{\\delta})}\n% \\end{split}\n% \\end{displaymath}\n% where $N_{c}$ is the number of arm groups.\n% \\label{lemma_adjacency_matrix_concentration}\n% \\end{lemma}\n% \\textbf{Proof.}\n% Given $N_{c}$ arm groups, we have $N_{c}(N_{c} - 1) / 2$ different group pairs. For pair $c_{i}, c_{j}\\in \\mathcal{C}$, each $\\phi_{k_{\\mathcal{G}}}(x_{c_{i}, \\tau})^{\\intercal}\\phi_{k_{\\mathcal{G}}}(x_{c_{j}, \\tau}), \\tau\\in [t]$ is a sample drawn from $\\mathcal{D}_{ij}$, and the element distance $\\abs{[\\matr{A}_{t}]_{ij} - [\\matr{A}^{*}]_{ij}}$ can be regarded as the the difference between mean value of samples and the expectation. Applying the Hoeffding's inequality and the union bound would complete the proof.\n\n% Therefore, as $\\norm{\\cdot}_{F} \\leq \\norm{\\cdot}_{\\infty}$, we finally have\n% \\begin{displaymath}\n% \\begin{split}\n%     R_{2} & \\leq k\\cdot(\\zeta \\beta_{L} + \\frac{\\Upsilon\\zeta}{m})^{O(L)} \\sqrt{\\frac{1}{2}\\log(\\frac{N_{c}^{2} - N_{c}}{\\delta})} \\sqrt{\\frac{1}{t}} = B_{4} \\sqrt{\\frac{1}{t}}.\n% \\end{split}\n% \\end{displaymath}\n\n\n% % ----------------------\n% \\subsection{Bounding $R_{1}$}\n% Then, we proceed to derive the bound for term $R_{1}$, and omit the $\\mathcal{G}_{t}$ notation by default.\n% \\begin{lemma}\n% At this time step $t+1$, given the past received contexts and rewards, with the probability at least $1-\\delta$, if we have satisfying $m, \\eta$ \\TODO{Fill in}, we will have\n% \\begin{displaymath}\n% \\begin{split}\n%     & \\abs{f(\\widetilde{\\matr{X}}_{t}; \\matr{\\Theta}_{t-1}^{*}) - f(\\widetilde{\\matr{X}}_{t}; \\matr{\\Theta}_{t-1})}\n%     \\leq B_{1} \\norm{g(\\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1}) / \\sqrt{m}}_{\\matr{Z}_{t-1}^{-1}} + B_{2} + B_{3}\n% \\end{split}\n% \\end{displaymath}\n% where \n% $B_{1} = \\sqrt{\\log(\\frac{\\det(\\matr{Z}_{t-1})}{\\det(\\matr{\\lambda I})}) - 2\\log(\\delta)} + \\lambda^{0.5}$, \n% $B_{2} = \\big[ \n% \\frac{\\widetilde{I}_{1} \\cdot \\sqrt{t} B_{3} +  m\\cdot \\widetilde{I}_{2}}{m\\lambda} + \\sqrt{\\frac{t}{ m\\lambda}} \n% \\big] \n% \\cdot \\big( \n% \\Lambda^{(j)}\\cdot\\sqrt{9L + m^{-1}} + m^{-1}\\beta_{h} \\cdot \\sqrt{L\\cdot \\beta_{3}^{2}\\cdot (\\beta_{L}\\zeta)^{2L} + m} \n% \\big)$, \n% and $B_{3} = m^{-0.5} \\big(\n%         \\beta_{3} (\\Lambda^{(j)}+\\beta_{h}) + L\\cdot\\Upsilon\\cdot (\\Lambda^{(j)}+\\beta_{h})(\\Lambda^{(j)} / \\beta_{h} + 1) \n% \\big)$. \n\n% \\label{lemma_CB_one_step_same_graph}\n% \\end{lemma}\n\n% \\textbf{Proof.}\n% Given the embedded context $\\widetilde{\\matr{X}}_{t}$, and following Lemma \\ref{lemma_expect_rewards}, we have \n% \\begin{displaymath}\n% \\begin{split}\n%     & \\abs{f(\\widetilde{\\matr{X}}_{t}; \\matr{\\Theta}_{t-1}^{*}) - f(\\widetilde{\\matr{X}}_{t}; \\matr{\\Theta}_{t-1})} \\\\\n%     & \\leq \\abs{\\inp{g(\\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1}) / \\sqrt{m}}{\\sqrt{m}(\\matr{\\Theta}_{t-1}^{*} - \\matr{\\Theta}_{0})} - \\inp{g(\\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1}) / \\sqrt{m}}{\\widehat{\\matr{\\Theta}}_{t-1}}} \\\\\n%     &\\qquad + \\abs{\\inp{g(\\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1}) / \\sqrt{m}}{\\widehat{\\matr{\\Theta}}_{t-1}} - \n%     f(\\widetilde{\\matr{X}}_{t}; \\matr{\\Theta}_{t-1})} = R_{3} + R_{4}.\n% \\end{split}\n% \\end{displaymath}\n% For $R_{3}$, based on Theorem 2 from \\cite{improved_linear_bandits_abbasi2011improved}, we have\n% \\begin{displaymath}\n% \\begin{split}\n%     & R_{3} \\leq B_{1} \\norm{g(\\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1}) / \\sqrt{m}}_{\\matr{Z}_{t-1}^{-1}}.\n% \\end{split}\n% \\end{displaymath}\n% For $R_{4}$, \n% \\begin{displaymath}\n% \\begin{split}\n%     & \\abs{f(\\widetilde{\\matr{X}}_{t}; \\matr{\\Theta}_{t-1}) - \\inp{g(\\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1} / \\sqrt{m})}{\\widehat{\\matr{\\Theta}}_{t-1}}} \n%     \\leq \\abs{f(\\widetilde{\\matr{X}}_{t}; \\matr{\\Theta}_{t-1}) - \\inp{g(\\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1})}{\\matr{\\Theta}_{t-1} - \\matr{\\Theta}_{0}}} \\\\\n%     & \\qquad + \\abs{\\inp{g(\\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1})}{\\matr{\\Theta}_{t-1} - \\matr{\\Theta}_{0} - \\widehat{\\matr{\\Theta}}_{t-1} / \\sqrt{m}}} = R_{4} + R_{5}\n% \\end{split}\n% \\end{displaymath}\n% where $R_{4}$ can be bounded by $B_{3}$ with Lemma \\ref{lemma_output_minus_inner_product}. Then, with conclusions from Lemma \\ref{lemma_linking_regre_est_with_net_param} and Lemma \\ref{lemma_after_GD_gradient_for_network_norm}, we have\n% \\begin{displaymath}\n% \\begin{split}\n%     & R_{5} \\leq \\norm{\\matr{\\Theta}_{t-1} - \\matr{\\Theta}_{0} - \\widehat{\\matr{\\Theta}}_{t-1} / \\sqrt{m}}_{2}  \\cdot \\norm{g(\\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1})}_{2} \\\\\n%     & \\leq B_{2} = \\big[ (\\widetilde{I}_{1} \\cdot \\sqrt{t} B_{3} +  m\\cdot \\widetilde{I}_{2}) / (m\\lambda) + \\sqrt{t / (m\\lambda)} \\big] \\\\\n%     &\\quad \\cdot \\big( \\Lambda^{(j)}\\cdot\\sqrt{9L + m^{-1}} + m^{-1}\\beta_{h} \\cdot \\sqrt{L\\cdot \\beta_{3}^{2}\\cdot (\\beta_{L}\\zeta)^{2L} + m} \\big)\n% \\end{split}\n% \\end{displaymath}\n% which completes the proof.\n\n% % ======================================================================\n% \\section{Proof of Regret Bound}\n% By definition, we have regret for one time step $t$ as\n% \\begin{displaymath}\n% \\begin{split}\n%     R_{t} &= f(\\mathcal{G}^{*}, \\widetilde{\\matr{X}}^{*}; \\matr{\\Theta}_{t-1}^{*}) - f(\\mathcal{G}^{*}, \\widetilde{\\matr{X}}_{t}; \\matr{\\Theta}_{t-1}^{*}) \\\\\n%     & \\leq \\textsf{CB}_{t}(\\widetilde{\\matr{X}}^{*}) +  f(\\mathcal{G}_{t}, \\widetilde{\\matr{X}}^{*}; \\matr{\\Theta}_{t-1})\n%     - f(\\mathcal{G}^{*}, \\widetilde{\\matr{X}}_{t}; \\matr{\\Theta}_{t-1}^{*}) \\\\\n%     & \\leq \\textsf{CB}_{t}(\\widetilde{\\matr{X}}_{t}) +  f(\\mathcal{G}_{t}, \\widetilde{\\matr{X}}_{t}; \\matr{\\Theta}_{t-1})\n%     - f(\\mathcal{G}^{*}, \\widetilde{\\matr{X}}_{t}; \\matr{\\Theta}_{t-1}^{*}) \n%     \\leq 2\\cdot \\textsf{CB}_{t}(\\widetilde{\\matr{X}}_{t})\n% \\end{split}\n% \\end{displaymath}\n% where the second inequality is due to the pulling mechanism.\n\n\n% \\begin{theorem}\n% At this time step $t+1$, given the past received contexts and rewards, with the probability at least $1-\\delta$, if we have satisfying $m, \\eta$ \\TODO{Fill in}, we will have the overall regret\n% \\begin{displaymath}\n% \\begin{split}\n%     & R(T) \\leq 2\\cdot (2B_{4}\\sqrt{T} + 1 - B_{4}) + 2\\sqrt{2\\widetilde{d} T \\log(1+T/\\lambda) + 1} \\\\\n%     &\\qquad \\cdot \\big(\\sqrt{\\lambda}S + \\sqrt{1-2\\log(\\delta) + (\\widetilde{d} T \\log(1+T/\\lambda))}\\big) \n% \\end{split}\n% \\end{displaymath}\n\n% \\label{theorem_regret_bound}\n% \\end{theorem}\n\n% \\textbf{Proof.}\n% Based on Lemma \\ref{lemma_CB_one_step_same_graph} and Subsection \\ref{subsection_R_2}, we have \n% \\begin{displaymath}\n% \\begin{split}\n%     & R(T) \\leq 2\\sum_{t=1}^{T} \\bigg(B_{1} \\norm{g(\\mathcal{G}_{t}, \\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1}) / \\sqrt{m}}_{\\matr{Z}_{t-1}^{-1}} + B_{2} + B_{3} + B_{4} \\sqrt{\\frac{1}{t}} \\bigg)\\\\\n%     & \\leq 2\\cdot (2B_{4}\\sqrt{T} + 1 - B_{4}) + 2\\sum_{t=1}^{T} (B_{1} \\norm{g(\\mathcal{G}_{t}, \\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1}) / \\sqrt{m}}_{\\matr{Z}_{t-1}^{-1}})\n% \\end{split}\n% \\end{displaymath}\n% with the choice of $m$ for bounding the summation of $B_{2}, B_{3}$, and the bound of $\\sum_{i=1}^{T}[t^{-i / 2}]$ in \\cite{bound_sum_sqrt_T_chlebus2009approximate}. Then, with Lemma 11 from \\cite{improved_linear_bandits_abbasi2011improved},\n% \\begin{displaymath}\n% \\begin{split}\n%     & \\sum_{t=1}^{T} (B_{1} \\norm{g(\\mathcal{G}_{t}, \\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1}) / \\sqrt{m}}_{\\matr{Z}_{t-1}^{-1}}) \\leq\n%     2B_{1} \\sqrt{T\\sum_{t=1}^{T}  \\norm{g(\\mathcal{G}_{t}, \\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1}) / \\sqrt{m}}_{\\matr{Z}_{t-1}^{-1}}^{2}}\\\\\n%     & \\leq \\sqrt{T} B_{1} \\sqrt{\\log(\\frac{\\det(Z_{T})}{\\det(\\lambda \\matr{I})})}\n%     \\leq \\sqrt{2\\widetilde{d} T \\log(1+T/\\lambda) + 1} \\\\\n%     &\\qquad \\cdot \\big(\\sqrt{\\lambda}S + \\sqrt{1-2\\log(\\delta) + (\\widetilde{d} T \\log(1+T/\\lambda))}\\big) \n% \\end{split}\n% \\end{displaymath}\n% where second inequality with Lemma 11 in \\cite{improved_linear_bandits_abbasi2011improved} and the final inequality is based on Lemma 6.3 \\cite{CNN_UCB-ban2021convolutional} (or similar to Lemma 5.4 \\cite{Neural-UCB}).\n\n\n\n\n\n\n\n% ======================================================================\n"
            },
            "section 8": {
                "name": "Lemmas for Intermediate Variables and Weight Matrices",
                "content": " \\label{sec_appendix_A}\nDue to page limit, we will give the proof sketch for lemmas at the end of each corresponding appendix section. \n%\nRecall that each input context $x^{(i)}_{c, t}, i\\in [n_{c, t}]$ is embedded to $\\widetilde{\\matr{X}}^{(i)}_{c, t}$ (represented by $\\widetilde{\\matr{X}}$ for brevity).\n%\nSupposing $\\widetilde{\\matr{X}}$ belongs to the arm group $c$, denote $\\vect{h}_{\\matr{A}} = [\\matr{A}_{t}^{k}\\widetilde{\\matr{X}}]_{c}$ as the corresponding row in matrix $\\matr{A}_{t}^{k}\\widetilde{\\matr{X}}$ based on index of group $c$ in $\\mathcal{C}$ (if group $c$ is the $c'$-th group in $\\mathcal{C}$, then $\\vect{h}_{\\matr{A}}$ is the $c'$-th row in $\\matr{A}_{t}^{k}\\widetilde{\\matr{X}}$). \n%\nSimilarly, we have $\\vect{h}_{gnn} = [\\matr{H}_{gnn}]_{c}$ and $\\vect{h}_{l} = [\\matr{H}_{l}]_{c}$ respectively. \n% Then, with $\\matr{H}_{0} = [\\matr{H}_{gnn}; \\widetilde{\\matr{X}}]$ and $\\forall l \\in [L-1]$, \n% $\n%     \\matr{H}_{l} = \\sqrt{\\frac{1}{m}}\\sigma\\bigg(\\matr{\\Theta}_{l-1}\\cdot\\sqrt{\\frac{1}{m}}\\sigma(\\dotsb\\sqrt{\\frac{1}{m}}\\cdot\\sigma(\\matr{\\Theta}_{1}\\matr{H}_{0}^{\\intercal}))\\bigg) \\in \\mathbb{R}^{N_{c} \\times m}\n% $\n% represents the intermediate output of the $l$-th layer of the reward estimation module. Then, the outputs of the the reward estimations are\n% $\n%     \\widehat{\\vect{r}}_{all} = \\bigg(\\matr{\\Theta}_{L}\\cdot\\sigma\\bigg(\\matr{\\Theta}_{L-1}\\cdot\\sigma(\\dotsb\\sigma(\\matr{\\Theta}_{1}\\matr{H}_{0}^{\\intercal})\\bigg) \\cdot \\sqrt{\\frac{1}{m}}\\bigg)^{\\intercal} \\in \\mathbb{R}^{N_{c}}\n% $\n% whose entries are the corresponding reward estimation for each arm. Here, $\\{\\matr{\\Theta}_{1}, \\dots, \\matr{\\Theta}_{L}\\}$ are the trainable parameters for the reward estimation module, and $\\sigma(\\cdot)$ denotes the activation function. \n% ----\n% --------------------------------------------------------------------------------\nGiven received contexts $\\{\\widetilde{\\matr{X}}_{\\tau}\\}_{\\tau=1}^{T}$ and rewards $\\{r_{\\tau}\\}_{\\tau=1}^{T}$, the gradient w.r.t. weight matrix $\\matr{\\Theta}_{l}, \\forall l \\in \\{1, \\dots, L-1\\}$ will be\n\\begin{displaymath}\n\\begin{split}\n    \\frac{\\partial~\\mathcal{L}(\\Theta)}{\\partial~\\matr{\\Theta}_{l}} = m^{-\\frac{L-l+1}{2}}\\sum_{\\tau=1}^{T} \n    \\abs{f(\\widetilde{\\matr{X}}_{\\tau};\\matr{\\Theta}) - r_{\\tau}}^{2}  \\bigg( \\vect{h}_{l-1} \\matr{\\Theta}_{L}^{\\intercal} \n    \\big(\\prod_{q=l+1}^{L-1} \\matr{\\Gamma}_{q} \\matr{\\Theta}_{q}^{\\intercal} \\big)\n     \\matr{\\Gamma}_{l} \n    \\bigg)\n\\end{split}\n\\end{displaymath}\nwhere $\\matr{\\Gamma}_{q} = diag([\\sigma'(\\vect{h}_{q-1}\\matr{\\Theta}_{q})])$ is the diagonal matrix whose entries are the elements from $\\sigma'(\\matr{\\vect{h}_{q-1}\\Theta}_{q})$. The coefficient $\\frac{1}{2}$ of the cost function is omitted for simplicity.\nThen, for $\\matr{\\Theta}_{gnn}$, we have\n\\begin{displaymath}\n\\begin{split}\n    \\frac{\\partial~\\mathcal{L}(\\Theta)}{\\partial~\\matr{\\Theta}_{gnn}} = m^{-\\frac{L+1}{2}}\\sum_{\\tau=1}^{T} \n    \\abs{f(\\widetilde{\\matr{X}}_{\\tau};\\matr{\\Theta}) - r_{\\tau}}^{2}  \\bigg(\\vect{h}_{\\matr{A}} \\matr{\\Theta}_{L}^{\\intercal} \n    \\big(\\prod_{q=2}^{L-1} \\matr{\\Gamma}_{q} \\matr{\\Theta}_{q}^{\\intercal} \\big) \\matr{\\Gamma}_{1} \\matr{\\Theta}_{1}^{\\intercal}\n      \\matr{Q} \\matr{\\Gamma}_{gnn} \\bigg)\n\\end{split}\n\\end{displaymath}\nwhere $\\matr{\\Gamma}_{gnn} = diag([\\sigma'(\\vect{h}_{\\matr{A}} \\matr{\\Theta}_{gnn})])$.\n$\\matr{Q} = $\n$\\left(\n\\begin{array}{c} \n  \\matr{I}\\in \\mathbb{R}^{m\\times m} \\\\ \n  \\hline \n  \\matr{0} \\in \\mathbb{R}^{(d' - m)\\times m}\n\\end{array} \n\\right) \\in \\mathbb{R}^{d'\\times m}$. \n%\nGiven the same $\\mathcal{G}_{t}$, we provide lemmas to bound the $R_{1}$ term of \\textbf{Eq.} \\ref{eq_regret_split}.\nFor brevity, the subscript $\\tau\\in [T]$ and notation $\\mathcal{G}_{t}$ are omitted below by default.\n\n\n% ------------------------------------------------------------\n\\begin{lemma}\nGiven the randomly initialized parameters $\\matr{\\Theta}^{(0)} = \\{\\matr{\\Theta}_{gnn}^{(0)}, \\matr{\\Theta}_{1}^{(0)}, \\matr{\\Theta}_{2}^{(0)}, \\dots, \\matr{\\Theta}_{L}^{(0)}\\}$, with the probability at least $1 - O(TL)\\cdot e^{-\\Omega(m)}$ and constants $1 < \\beta_{1}, \\beta_{2}, \\beta_{3}, \\beta_{4} < 2$, we have\n\\begin{displaymath}\n\\begin{split}\n    &\\norm{\\matr{\\Theta}_{gnn}^{(0)}}_{2} \\leq \\beta_{1}\\sqrt{m},~ \n    \\norm{\\matr{\\Theta}_{1}^{(0)}}_{2} \\leq \\beta_{2}\\sqrt{m},~\n    \\norm{\\matr{\\Theta}_{L}^{(0)}}_{2} \\leq \\beta_{3}, \\\\\n    &\\norm{\\vect{h}_{gnn}^{(0)}}_{2} \\leq \\zeta\\cdot \\beta_{1}, \\quad\n    \\norm{\\vect{h}_{1}^{(0)}}_{2} \\leq \\zeta\\cdot \\beta_{2} + \\zeta^{2}\\cdot \\beta_{1} \\beta_{2}, \\\\\n    &\\abs{f(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(0)})} \\leq \\zeta \\cdot \\beta_{3}\\cdot(\\zeta\\cdot \\beta_{4})^{L-2}(\\zeta\\cdot \\beta_{2} + \\zeta^{2}\\cdot \\beta_{1} \\beta_{2}) / \\sqrt{m}, \\\\\n    &\\norm{\\matr{\\Theta}_{l}^{(0)}}_{2} \\leq \\beta_{4}\\sqrt{m},~~ \\norm{\\vect{h}_{l}^{(0)}}_{2} \\leq (\\zeta\\cdot \\beta_{4})^{l-1}(\\zeta\\cdot \\beta_{2} + \\zeta^{2}\\cdot \\beta_{1} \\beta_{2}),~~  \\\\\n    &\\forall l \\in \\{2, \\dots, L-1\\}.\n\\end{split}\n\\end{displaymath}\n\n\\label{lemma_initial_param_outputs}\n\\end{lemma}\n\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PROOF (DELETE IN THE CONFERENCE VERSION)\n% \\textbf{Proof sketch.}\n% The proof of this lemma depends on the random Gaussian matrix properties \\cite{random_matrix-vershynin2010introduction, skip_kernel_du2019gradient} and is analogous to Lemma B.1 in \\cite{CNN_UCB-ban2021convolutional}. Combining with the $\\zeta$-Lipschitz continuity of $\\sigma(\\cdot)$ would complete the proof.   $\\blacksquare$\n\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PROOF (DELETE IN THE CONFERENCE VERSION)\n% ------------------------------------\n\\textbf{Proof.}\nBased on the properties of random Gaussian matrices \\cite{random_matrix-vershynin2010introduction, skip_kernel_du2019gradient, CNN_UCB-ban2021convolutional}, with the probability of at least $1 - e^{-\\frac{(\\beta_{1} - \\sqrt{d_{\\widetilde{x}} / m} - 1)^{2}\\cdot m}{2}} = 1 - e^{-\\Omega(m)}$, we have\n\\begin{displaymath}\n\\begin{split}\n    \\norm{\\matr{\\Theta}_{gnn}^{(0)}}_{2} \\leq \\beta_{1}\\sqrt{m}\n\\end{split}\n\\end{displaymath}\nwhere $\\beta_{1} \\geq \\sqrt{d_{\\widetilde{x}} / m} + 1$ with $m > d_{\\widetilde{x}}$.\nApplying the analogous approach for the other randomly initialized matrices would give similar bounds.\nRegarding the nature of $\\matr{A}$, we can easily have $\\norm{\\vect{h}_{\\matr{A}}}_{2} \\leq 1$. Then,\n\\begin{displaymath}\n\\begin{split}\n    \\norm{\\vect{h}_{gnn}^{(0)}}_{2} = m^{-\\frac{1}{2}}\\norm{\\sigma(\\vect{h}_{\\matr{A}}\\cdot\\matr{\\Theta}_{gnn})}_{2} \\leq \\zeta m^{-\\frac{1}{2}}\\cdot \\norm{\\vect{h}_{\\matr{A}}}_{2} \\norm{\\matr{\\Theta}_{gnn}}_{2} \\leq \\zeta\\cdot \\beta_{1}\n\\end{split}\n\\end{displaymath}\ndue to the assumed $\\zeta$-Lipschitz continuity. Denoting the concatenated input for reward estimation module as $\\vect{x}' = [\\vect{h}_{gnn}^{(0)}; \\widetilde{\\matr{X}}]_{c} \\in \\mathbb{R}^{1\\times (d_{\\widetilde{x}} + m)}$, we can easily derive that $\\norm{\\vect{x}'}_{2} \\leq \\zeta\\cdot \\beta_{1} + 1$. Thus,\n\\begin{displaymath}\n\\begin{split}\n    \\norm{\\vect{h}_{1}^{(0)}}_{2}& = m^{-\\frac{1}{2}}\\norm{\\sigma(\\vect{x}'\\cdot\\matr{\\Theta}_{1})}_{2} \n    \\leq \\zeta m^{-\\frac{1}{2}}\\cdot \\norm{\\vect{x}'}_{2}\\norm{\\matr{\\Theta}_{1}}_{2} \\\\ \n    & \\leq \\zeta\\cdot \\beta_{2} (\\zeta\\cdot \\beta_{1} + 1) =  \\zeta\\cdot \\beta_{2} + \\zeta^{2}\\cdot \\beta_{1} \\beta_{2}.\n\\end{split}\n\\end{displaymath}\nFollowing the same procedure recursively for other intermediate outputs and applying the union bound would complete the proof.\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PROOF (DELETE IN THE CONFERENCE VERSION)\n\n\n\n\n% ------------------------------------------------------------\n\\begin{lemma}\nAfter $T$ time steps, run GD for $J$-iterations on the network with the received contexts and rewards. Suppose $\\norm{\\vect{h}_{l}^{(j)} - \\vect{h}_{l}^{(0)}}_{2} \\leq \\Lambda^{(j)}, \\forall j \\in [J]$. With the probability of at least $1 - O(TL)\\cdot e^{-\\Omega(m)}$ and $\\matr{\\Theta}\\in \\{\\matr{\\Theta}_{gnn}, \\matr{\\Theta}_{1}, \\dots, \\matr{\\Theta}_{L}\\}$, we have\n\\begin{displaymath}\n\\begin{split}\n    &\\norm{\\matr{\\Theta}^{(j)} - \\matr{\\Theta}^{(0)}}_{F} \\leq \\Upsilon / \\sqrt{m}\n\\end{split}\n\\end{displaymath}\nwhere\n$\n    \\Upsilon = \\frac{2\\sqrt{2}t}{\\beta_{F}}(\\beta_{h}+ \\Lambda^{(j)})  (\\beta_{L}+ 1)^{L}  \\zeta^{L}.\n$\n\\label{lemma_after_GD_weight_matrices_bounds}\n\\end{lemma}\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PROOF (DELETE IN THE CONFERENCE VERSION)\n\n% \\textbf{Proof sketch.}\n% The proof of this Lemma follows an induction-based procedure \\cite{skip_kernel_du2019gradient, CNN_UCB-ban2021convolutional}.\n% The hypothesis is $\\norm{\\matr{\\Theta}^{(0)} - \\matr{\\Theta}^{(j)}}_{F} \\leq \\Upsilon/\\sqrt{m},\\\\ \n% \\forall \\matr{\\Theta}\\in \\{\\matr{\\Theta}_{gnn}, \\matr{\\Theta}_{1}, \\dots, \\matr{\\Theta}_{L}\\}$. Since $\\norm{\\matr{\\Theta}^{(j+1)} - \\matr{\\Theta}^{(j)}}_{F} = \\norm{\\matr{\\Theta}^{(j)} -  \\eta\\cdot\\frac{\\partial~\\mathcal{L}(\\matr{\\Theta}^{(j)})}{\\partial~\\matr{\\Theta}^{(j)}}}_{F}$, separately bound the norm of each term after applying the Cauchy-Schwarz inequality and combining Lemma \\ref{theorem_after_GD_param_outputs} would give the conclusion.   $\\blacksquare$\n\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PROOF (DELETE IN THE CONFERENCE VERSION)\n% ------------------------------\n\\textbf{Proof.}\nWe prove this Lemma following an induction-based procedure \\cite{skip_kernel_du2019gradient, CNN_UCB-ban2021convolutional}. The hypothesis is $\\norm{\\matr{\\Theta}^{(0)} - \\matr{\\Theta}^{(j)}}_{F} \\leq \\Upsilon/\\sqrt{m}, \\forall \\matr{\\Theta}\\in \\{\\matr{\\Theta}_{gnn}, \\matr{\\Theta}_{1}, \\dots, \\matr{\\Theta}_{L}\\}$, and let $\\beta_{L} = \\max\\{\\beta_{1}, \\beta_{2}, \\beta_{3}, \\beta_{4}\\}$.\nAccording to \\textbf{Algorithm}~\\ref{algo_2}, we have for the $j+1$-th iteration and $l \\in [L]$, \n\\begin{displaymath}\n\\begin{split}\n    &\\norm{\\matr{\\Theta}_{l}^{(j+1)} - \\matr{\\Theta}_{l}^{(j)}}_{F} \n    =m^{-\\frac{L-l+1}{2}} \\eta\\cdot\\norm{\\sum_{\\tau=1}^{T}\n    \\abs{f(\\widetilde{\\matr{X}}_{\\tau};\\matr{\\Theta}^{(j)}) - r_{\\tau}}^{2} \\cdot \n    \\vect{h}_{l-1}^{(j)} (\\matr{\\Theta}_{L}^{(j)})^{\\intercal}  \\\\\n    &\\qquad\\cdot\\big(\\prod_{q=l+1}^{L-1} \\matr{\\Gamma}_{q}^{(j)}  \\cdot (\\matr{\\Theta}_{q}^{(j)})^{\\intercal} \\big)\n    \\cdot \\matr{\\Gamma}_{l}^{(j)}\n    }_{F} \\\\\n    &\\leq m^{-\\frac{L-l+1}{2}}\\eta\\sqrt{t}\\cdot\\norm{\\vect{F}^{(j)}_{t}- \\vect{Y}_{t}}_{2}\n    \\norm{\\vect{h}_{l-1}^{(j)}\\matr{\\Theta}_{L}^{(j)}}_{F} \n    \\prod_{q=l+1}^{L-1}\\norm{\\matr{\\Theta}_{q}^{(j)}}_{2} \n    \\prod_{q=l}^{L-1} \\norm{\\matr{\\Gamma}_{q}^{(j)}}_{2} \\\\\n    &\\leq m^{-\\frac{L-l+1}{2}}\\eta\\sqrt{t}\\cdot\\norm{\\vect{F}^{(j)}_{t}- \\vect{Y}_{t}}_{2}\n    \\norm{\\vect{h}_{l-1}^{(j)}}_{2} \\norm{\\matr{\\Theta}_{L}^{(j)}}_{2}  \n    \\prod_{q=l+1}^{L-1}\\norm{\\matr{\\Theta}_{q}^{(j)}}_{2} \n    \\prod_{q=l}^{L-1} \\norm{\\matr{\\Gamma}_{q}^{(j)}}_{2}\n\\end{split}\n\\end{displaymath}\nby Cauchy inequality.\nFor $\\norm{\\matr{\\Theta}_{q}^{(j)}}_{2}$, we have\n\\begin{displaymath}\n\\begin{split}\n    \\prod_{q=l+1}^{L-1}\\norm{\\matr{\\Theta}_{q}^{(j)}}_{2} &\\leq \\prod_{q=l+1}^{L-1}\\bigg(\\norm{\\matr{\\Theta}_{q}^{(0)}}_{2} + \\norm{\\matr{\\Theta}_{q}^{(j)} - \\matr{\\Theta}_{q}^{(0)}}_{2}\\bigg)\\\\\n    &\\qquad \\leq (\\beta_{L} \\sqrt{m}+ \\Upsilon/\\sqrt{m})^{L-l-1};\n\\end{split}\n\\end{displaymath}\nwhile for $\\norm{\\matr{\\Gamma}_{q}^{(j)}}_{2}$, we have $\\prod_{q=l}^{L-1} \\norm{\\matr{\\Gamma}_{q}^{(j)}}_{2} \\leq \\zeta^{L-l}$. Combining all the results above and based on Lemma \\ref{theorem_after_GD_param_outputs}, it means that for $l \\in [L]$, \n\\begin{displaymath}\n\\begin{split}\n    &\\norm{\\matr{\\Theta}_{l}^{(j+1)} - \\matr{\\Theta}_{l}^{(j)}}_{F} \n    \\leq m^{-\\frac{L-l+1}{2}}\\eta\\sqrt{t}\\cdot(1 - \\beta_{F}\\cdot \\eta)^{j / 2} \\cdot \\norm{\\vect{F}^{(0)}_{t}- \\vect{Y}_{t}}_{2} \\\\\n    &\\qquad\\cdot \\norm{\\vect{h}_{l-1}^{(j)}}_{2}\\cdot\\norm{\\matr{\\Theta}_{L}^{(j)}}_{2}\\cdot(\\beta_{L} \\sqrt{m}+ \\Upsilon/\\sqrt{m})^{L-l-1} \\cdot \\zeta^{L-l+1} \\\\\n    &\\leq m^{-\\frac{1}{2}}(1 - \\beta_{F} \\eta)^{j / 2}\\eta\\sqrt{t} \\norm{\\vect{F}^{(0)}_{t}- \\vect{Y}_{t}}_{2}\n     ((\\beta_{h}+ \\Lambda^{(j)})  (\\beta_{L}+ \\Upsilon/m)^{L-l}  \\zeta^{L-l}\n\\end{split}\n\\end{displaymath}   \nwhere the last inequality is due to Lemma~\\ref{lemma_after_GD_model_results_variables}. Then, since we have $\\norm{\\matr{\\Theta}_{l}^{(j+1)} - \\matr{\\Theta}_{l}^{(j)}}_{F} \\leq \\norm{\\matr{\\Theta}_{l}^{(j+1)} - \\matr{\\Theta}_{l}^{(j)}}_{F} + \\norm{\\matr{\\Theta}_{l}^{(j)} - \\matr{\\Theta}_{l}^{(0)}}_{F}$, it leads to\n\\begin{displaymath}\n\\begin{split}\n    &\\norm{\\matr{\\Theta}_{l}^{(j+1)} - \\matr{\\Theta}_{l}^{(0)}}_{F} \n    \\leq \\frac{2\\sqrt{t}}{\\beta_{F}\\sqrt{m}}\\norm{\\vect{F}^{(0)}_{t}- \\vect{Y}_{t}}_{2}\n     (\\beta_{h}+ \\Lambda^{(j)})  (\\beta_{L}+ \\Upsilon/m)^{L-l}  \\zeta^{L-l}.\n\\end{split}\n\\end{displaymath}   \n% ---\nFor the last layer $\\matr{\\Theta}_{L}$, the conclusion can be verified through a similar procedure. \n% ---\nAnalogously, for $\\matr{\\Theta}_{gnn}$, we have\n\\begin{displaymath}\n\\begin{split}\n    &\\norm{\\matr{\\Theta}_{gnn}^{(j+1)} - \\matr{\\Theta}_{gnn}^{(j)}}_{F} \\\\\n    & = m^{-\\frac{L+1}{2}}\\eta \\norm{\\sum_{\\tau=1}^{T} \n    \\abs{f(\\widetilde{\\matr{X}}_{\\tau};\\matr{\\Theta}) - r_{\\tau}}^{2} \\cdot \\bigg(\\vect{h}_{\\matr{A}}\\cdot \\matr{\\Theta}_{L}^{\\intercal} \\cdot\n    \\big(\\prod_{q=2}^{L-1} \\matr{\\Gamma}_{q} \\cdot \\matr{\\Theta}_{q}^{\\intercal}\\big)\n    \\cdot \\matr{\\Gamma}_{1} \\matr{\\Theta}_{1}^{\\intercal}\n    \\bigg)\\\\\n    &\\qquad\\qquad \\cdot \\matr{Q} \\cdot \\matr{\\Gamma}_{gnn}}_{F} \\\\\n    &\\leq m^{-\\frac{L+1}{2}}\\eta\\sqrt{t}(1 - \\beta_{F}\\cdot \\eta)^{j/2}  \\norm{\\vect{F}^{(0)}_{t}- \\vect{Y}_{t}}_{2} \\norm{\\vect{h}_{\\matr{A}}}_{2}\\norm{\\prod_{q=1}^{L} \\matr{\\Theta}_{q}}_{2}  \\zeta^{L} \\norm{\\matr{Q}}_{2} \\\\\n    &\\leq \\sqrt{t} m^{-\\frac{1}{2}}(1 - \\beta_{F}\\cdot \\eta)^{j/2}\\eta\\cdot \\norm{\\vect{F}^{(0)}_{t}- \\vect{Y}_{t}}_{2} \\cdot \\zeta^{L} \\cdot(\\beta_{L}+ \\Upsilon/m)^{L},\n\\end{split}\n\\end{displaymath}\nwhich leads to \n\\begin{displaymath}\n\\begin{split}\n    &\\norm{\\matr{\\Theta}_{gnn}^{(j+1)} - \\matr{\\Theta}_{gnn}^{(0)}}_{F} \n    \\leq \\frac{2}{\\beta_{F}} \\sqrt{t} m^{-\\frac{1}{2}}\\cdot \\norm{\\vect{F}^{(0)}_{t}- \\vect{Y}_{t}}_{2} \\cdot \\zeta^{L} \\cdot(\\beta_{L}+ \\Upsilon/m)^{L}.\n\\end{split}\n\\end{displaymath}\nSince $\\norm{\\vect{F}^{(0)}_{t} - \\vect{Y}_{t}}_{2}\\leq \\sqrt{2t}$ (Lemma \\ref{theorem_after_GD_param_outputs}) and $\\Upsilon/m \\leq 1$ with sufficiently large $m$, combining all the results above would give the conclusion.\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PROOF (DELETE IN THE CONFERENCE VERSION)\n\n\n\n\n% ------------------------------------------------------------\n\\begin{lemma}\nAfter $T$ time steps, with the probability of at least $1 - O(TL)\\cdot e^{-\\Omega(m)}$ and running GD of $J$-iterations on the contexts and rewards, we have $\\beta'_{h} = \\max\\{\\zeta\\cdot \\beta_{1}, \\zeta\\cdot \\beta_{2} + \\zeta^{2}\\cdot \\beta_{1} \\beta_{2}, (\\zeta\\cdot \\beta_{4})^{L-2}(\\zeta\\cdot \\beta_{2} + \\zeta^{2}\\cdot \\beta_{1} \\beta_{2})\\}$ and $\\beta_{h}=\\max\\{\\zeta\\cdot \\beta_{L} + 1, \\beta'_{h}\\}$.\nWith $\\vect{h} \\in \\{\\vect{h}_{gnn}, \\vect{h}_{1}, \\dots, \\vect{h}_{L-1}\\}$, we have\n\\begin{displaymath}\n\\begin{split}\n    &\\norm{\\vect{h}^{(j)} - \\vect{h}^{(0)}}_{2} \\leq \\frac{\\zeta \\Upsilon}{m}\\cdot \\beta_{h} \\cdot \\frac{(2\\zeta \\beta_{L})^{L}-1}{2\\zeta \\beta_{L}-1} = \\Lambda^{(j)},~\n    \\norm{\\vect{h}^{(j)}}_{2} \\leq \\beta_{h} + \\Lambda^{(j)}\n\\end{split}\n\\end{displaymath}\n\n\\label{lemma_after_GD_model_results_variables}\n\\end{lemma}\n\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PROOF (DELETE IN THE CONFERENCE VERSION)\n% \\textbf{Proof sketch.}\n% The proof of this lemma follows an analogous approach as in Lemma \\ref{lemma_after_GD_weight_matrices_bounds}, and the initial hypothesis is $\\norm{\\vect{h}^{(j)} - \\vect{h}^{(0)}}_{2} \\leq \\Lambda^{(j)}$. We first apply the $\\zeta$-Lipschitz continuity to remove $\\sigma(\\cdot)$ and Cauchy-Schwarz inequality to break RHS side into norms of individual terms. Then, applying the initial hypothesis and Lemma \\ref{lemma_after_GD_weight_matrices_bounds} and Lemma \\ref{lemma_initial_param_outputs} would give the bound.     $\\blacksquare$\n\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PROOF (DELETE IN THE CONFERENCE VERSION)\n% % ---------------------------------\n\\textbf{Proof.}\nSimilar to the proof of \\textbf{Lemma}~\\ref{lemma_after_GD_weight_matrices_bounds}, we adopt an induction-based approach. For $l \\in [L-1]$, we have \n\\begin{displaymath}\n\\begin{split}\n    &\\norm{\\vect{h}_{l}^{(j)} - \\vect{h}_{l}^{(0)}}_{2} = \\sqrt{\\frac{1}{m}} \\norm{\\sigma( \\vect{h}_{l-1}^{(j)}\\cdot \\matr{\\Theta}_{l}^{(j)} ) - \\sigma(\\vect{h}_{l-1}^{(0)}\\cdot \\matr{\\Theta}_{l}^{(0)})}_{2} \\\\\n    %\n    & \\leq \\sqrt{\\frac{1}{m}}\\zeta\\cdot\\big( \\norm{ \\vect{h}_{l-1}^{(j)}\\cdot \\matr{\\Theta}_{l}^{(j)} - \\vect{h}_{l-1}^{(0)}\\cdot \\matr{\\Theta}_{l}^{(j)} }_{2}~+ \\norm{ \\vect{h}_{l-1}^{(0)}\\cdot \\matr{\\Theta}_{l}^{(j)} - \\vect{h}_{l-1}^{(0)}\\cdot \\matr{\\Theta}_{l}^{(0)} }_{2}\\big) \\\\\n    %\n    & \\leq \\sqrt{\\frac{1}{m}}\\zeta\\cdot( \\norm{\\matr{\\Theta}_{l}^{(0)}}_{2} + \\norm{\\matr{\\Theta}_{l}^{(j)} - \\matr{\\Theta}_{l}^{(0)}}_{F} ) \\cdot\\norm{\\vect{h}_{l-1}^{(j)} - \\vect{h}_{l-1}^{(0)}}_{2}~+\\\\\n    &\\qquad \\sqrt{\\frac{1}{m}}\\zeta \\cdot \\norm{\\vect{h}_{l-1}^{(0)}}_{2}\\cdot \\norm{\\matr{\\Theta}_{l}^{(j)} - \\matr{\\Theta}_{l}^{(0)}}_{F} \\\\\n    & \\leq \\sqrt{\\frac{1}{m}}\\zeta\\cdot( \\beta_{L}\\sqrt{m} + \\Upsilon/\\sqrt{m} ) \\cdot\\norm{\\vect{h}_{l-1}^{(j)} - \\vect{h}_{l-1}^{(0)}}_{2}~+ \\zeta \\cdot \\beta'_{h}\\cdot \\Upsilon/m \\\\\n    & \\leq \\zeta\\cdot( \\beta_{L} + \\Upsilon/m ) \\cdot \\zeta \\frac{\\Upsilon}{m}\\cdot\\Lambda_{l-1}^{(j)} + \\zeta \\cdot \\beta'_{h}\\cdot \\Upsilon/m \\\\\n    &\\leq \\zeta \\frac{\\Upsilon}{m} \\cdot(\\beta_{h} + 2\\zeta \\beta_{L} \\cdot \\Lambda_{l-1}^{(j)})\n    = \\zeta \\frac{\\Upsilon}{m} \\cdot \\Lambda_{l}^{(j)}\n\\end{split}\n\\end{displaymath}\nwhere the last two inequalities are derived by applying \\textbf{Lemma}~\\ref{lemma_after_GD_weight_matrices_bounds} and the hypothesis. For the aggregation module output $\\vect{h}_{gnn}^{(0)}$,\n\\begin{displaymath}\n\\begin{split}\n    &\\norm{\\vect{h}_{gnn}^{(j)} - \\vect{h}_{gnn}^{(0)}}_{2} = \\sqrt{\\frac{1}{m}} \\norm{\\sigma(\\matr{\\Theta}_{gnn}^{(j)}\\cdot \\vect{h}_{S}) - \\sigma(\\matr{\\Theta}_{gnn}^{(0)}\\cdot \\vect{h}_{S})}_{2} \\\\\n    & \\leq \\frac{\\zeta}{\\sqrt{m}} \\norm{\\matr{\\Theta}_{gnn}^{(j)} - \\matr{\\Theta}_{gnn}^{(0)}}_{F} \\cdot \\norm{\\vect{h}_{S}}_{2} \\leq \\frac{\\zeta\\Upsilon}{m}\\beta_{h}.\n\\end{split}\n\\end{displaymath}\nThen, for the first layer $l=1$, we have\n\\begin{displaymath}\n\\begin{split}\n    &\\norm{\\vect{h}_{1}^{(j)} - \\vect{h}_{1}^{(0)}}_{2} = \\sqrt{\\frac{1}{m}} \\norm{\\sigma(\\vect{x}'\\cdot \\matr{\\Theta}_{1}^{(j)} ) - \\sigma(\\vect{x}'\\cdot \\matr{\\Theta}_{1}^{(0)} )}_{2} \\\\\n    & \\leq \\frac{\\zeta}{\\sqrt{m}} \\norm{\\matr{\\Theta}_{gnn}^{(j)} - \\matr{\\Theta}_{1}^{(0)}}_{F} \\cdot \\norm{\\vect{x}'}_{2} \\leq \\frac{\\zeta\\Upsilon}{m} \\cdot (\\zeta\\cdot \\beta_{L} + 1) \\leq \\frac{\\zeta\\Upsilon}{m}\\cdot \\beta_{h}.\n\\end{split}\n\\end{displaymath}\nCombining all the results, for $\\vect{h} \\in \\{\\vect{h}_{gnn}, \\vect{h}_{1}, \\dots, \\vect{h}_{L-1}\\}$, it has\n\\begin{displaymath}\n\\begin{split}\n    &\\norm{\\vect{h}^{(j)} - \\vect{h}^{(0)}}_{2} \\leq \\frac{\\zeta \\Upsilon}{m}\\cdot \\beta_{h} \\cdot \\frac{(2\\zeta \\beta_{L})^{L}-1}{2\\zeta \\beta_{L}-1} = \\Lambda^{(j)},\n\\end{split}\n\\end{displaymath}\nwhich completes the proof.\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PROOF (DELETE IN THE CONFERENCE VERSION)\n\n\n\n% ------------------------------------------------------------\n% Then we proceed to bound the network gradients w.r.t. weight matrices. \n% For $\\matr{\\Theta}_{l}, l\\in[L-1]$, we have the derivative\n% $\n%     \\nabla_{\\matr{\\Theta}_{l}}f(\\widetilde{\\matr{X}};\\matr{\\Theta}) = \n%     m^{-\\frac{L-l}{2}} \\cdot \\vect{h}_{l-1} \\cdot \\bigg(\\matr{\\Theta}_{L} \\cdot \n%     \\big(\\prod_{q=l+1}^{L-1} \\matr{\\Gamma}_{q}  \\cdot \\matr{\\Theta}_{q}\\big)\n%     \\cdot \\matr{\\Gamma}_{l} \n%     \\bigg).\n% $\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PROOF (DELETE IN THE CONFERENCE VERSION)\n\n\n\n\\begin{lemma}\nWith initialized network parameters $\\matr{\\Theta}$ and the probability of at least $1 - O(TL)\\cdot e^{-\\Omega(m)}$, we have\n\\begin{displaymath}\n\\begin{split}\n    &\\norm{\\nabla_{\\matr{\\Theta}}f(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(0)})}_{F} \\leq \\beta_{h}\\beta_{3}\\cdot (\\beta_{L}\\zeta)^{L}/ m, \\norm{\\nabla_{\\matr{\\Theta}_{L}}f(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(0)})}_{F} \\leq \\beta_{h}/\\sqrt{m},\n\\end{split}\n\\end{displaymath}\nand the norm of gradient difference\n\\begin{displaymath}\n\\begin{split}\n    &\\norm{\\nabla_{\\matr{\\Theta}}f(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(0)}) - \\nabla_{\\matr{\\Theta}}f(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(j)})}_{F} \\leq 3\\cdot \\Lambda^{(j)}, \\\\\n    &\\norm{\\nabla_{\\matr{\\Theta}_{L}}f(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(0)}) - \\nabla_{\\matr{\\Theta}_{L}}f(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(j)})}_{F} \\leq \\Lambda^{(j)} / \\sqrt{m}.\n\\end{split}\n\\end{displaymath}\nwith $\\matr{\\Theta} \\in \\{\\matr{\\Theta}_{gnn}, \\matr{\\Theta}_{1}, \\dots, \\matr{\\Theta}_{L-1}\\}$.\n\n\\label{lemma_after_GD_gradient_matrix_norm}\n\\end{lemma}\n\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PROOF (DELETE IN THE CONFERENCE VERSION)\n% \\textbf{Proof sketch.}\n% Similar to the proofs of above lemmas, we prove by breaking each $\\norm{\\nabla_{\\matr{\\Theta}}f(\\widetilde{\\matr{X}};\\matr{\\Theta})}_{F}$ into the norms of individual terms.\n% Then, with the bounds for intermediate outputs $\\vect{h}$ and weight matrices $\\matr{\\Theta}$ in Lemma \\ref{lemma_initial_param_outputs}, Lemma \\ref{lemma_after_GD_weight_matrices_bounds} and Lemma \\ref{lemma_after_GD_model_results_variables}, we bound each term to give the overall bound for the gradients.      $\\blacksquare$\n\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PROOF (DELETE IN THE CONFERENCE VERSION)\n% ---------------------------------------------------------\n\\textbf{Proof.}\nFirst, for $l\\in[L-1]$, we have\n\\begin{displaymath}\n\\begin{split}\n    &\\norm{\\nabla_{\\matr{\\Theta}_{l}}f(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(0)})}_{F} = \n    m^{-\\frac{L-l+1}{2}}  \n    \\norm{\\vect{h}_{l-1}^{(0)}  \\big(\\matr{\\Theta}_{L}^{(0)}  \n    \\big(\\prod_{q=l+1}^{L-1} \\matr{\\Gamma}_{q}  \\cdot \\matr{\\Theta}_{q}^{(0)}\\big)\n    \\cdot \\matr{\\Gamma}_{l} \n    \\big)}_{F} \\\\\n    & \\leq m^{-\\frac{L-l+1}{2}} \\cdot \\norm{\\vect{h}_{l-1}^{(0)}\\matr{\\Theta}_{L}^{(0)}}_{F} \\cdot \\norm{\\prod_{q=l}^{L-1} \\matr{\\Gamma}_{q}}_{2} \\cdot \\norm{\\prod_{q=l+1}^{L-1} \\matr{\\Theta}_{q}^{(0)}}_{2} \\\\\n    & \\leq m^{-\\frac{L-l+1}{2}} \\cdot \\norm{\\vect{h}_{l-1}^{(0)}}_{2} \\cdot \\norm{\\matr{\\Theta}_{L}^{(0)}}_{2} \\cdot \\norm{\\prod_{q=l}^{L-1} \\matr{\\Gamma}_{q}}_{2} \\cdot \\norm{\\prod_{q=l+1}^{L-1} \\matr{\\Theta}_{q}^{(0)}}_{2} \\\\\n    & \\leq m^{-\\frac{L-l+1}{2}}\\cdot \\beta_{h}\\beta_{3} \\cdot \\zeta^{L-l} \\cdot (\\beta_{L} \\sqrt{m})^{L-l-1}\n    \\leq \\beta_{h}\\beta_{3}\\cdot (\\beta_{L}\\zeta)^{L}/ m.\n\\end{split} \n\\end{displaymath}\nFor $\\matr{\\Theta}_{gnn}$, we can also derive similar results. For $\\matr{\\Theta}_{L}$,\n\\begin{displaymath}\n\\begin{split}\n    &\\norm{\\nabla_{\\matr{\\Theta}_{L}}f(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(0)})}_{F} = \n    m^{-0.5}\\cdot \\norm{\\vect{h}_{L-1}^{(0)}}_{2} \\leq \\beta_{h} / \\sqrt{m}\n\\end{split}\n\\end{displaymath}\nThen, with $\\nabla_{l}^{(j)} = m^{-\\frac{L-l+1}{2}}\\cdot (\\matr{\\Theta}_{L}^{(j)})^{\\intercal} \\cdot \n\\big(\\prod_{q=l+1}^{L-1} \\matr{\\Gamma}_{q}  \\cdot (\\matr{\\Theta}_{q}^{(j)})^{\\intercal}\\big)\n\\cdot \\matr{\\Gamma}_{l}$, we have the norm of gradient difference \n\\begin{displaymath}\n\\begin{split}\n    &\\norm{\\nabla_{\\matr{\\Theta}_{l}}f(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(j)}) - \\nabla_{\\matr{\\Theta}_{l}}f(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(0)})}_{F} \n    =  \\norm{\\vect{h}_{l-1}^{(0)} \\cdot \\nabla_{l}^{(0)} - \\vect{h}_{l-1}^{(j)} \\cdot \\nabla_{l}^{(j)}}_{F} \\\\\n    & \\leq \\norm{\\vect{h}_{l-1}^{(0)} \\cdot \\nabla_{l}^{(0)} - \\vect{h}_{l-1}^{(j)} \\cdot \\nabla_{l}^{(0)}}_{F} \n    + \\norm{\\vect{h}_{l-1}^{(j)} \\cdot \\nabla_{l}^{(0)} - \\vect{h}_{l-1}^{(j)} \\cdot \\nabla_{l}^{(j)}}_{F} \\\\\n    % -\n    & \\leq \\norm{\\vect{h}_{l-1}^{(j)}}_{F} \\cdot \\norm{\\nabla_{l}^{(0)} - \\nabla_{l}^{(j)}}_{F}\n    + \\norm{\\nabla_{l}^{(0)}}_{F} \\cdot \\norm{\\vect{h}_{l-1}^{(0)} - \\vect{h}_{l-1}^{(j)}}_{F} \\\\\n    & \\leq \\big(\\beta_{h} + \\Lambda^{(j)}\\big)\\cdot \\norm{\\nabla_{l}^{(0)} - \\nabla_{l}^{(j)}}_{F} + \\Lambda^{(j)}\\cdot \\norm{\\nabla_{l}^{(0)}}_{F}.\n\\end{split} \n\\end{displaymath}\nHere, for the difference of $\\nabla$, we have\n\\begin{displaymath}\n\\begin{split}\n    &\\norm{\\nabla_{l}^{(0)} - \\nabla_{l}^{(j)}}_{F} \\\\\n    &= m^{-\\frac{L-l+1}{2}} \\norm{\\matr{\\Theta}_{L}^{(0)} \\cdot \n    \\big(\\prod_{q=l+1}^{L-1} \\matr{\\Gamma}_{q}  \\cdot \\matr{\\Theta}_{q}^{(0)}\\big)\n     \\matr{\\Gamma}_{l} \n    - \\matr{\\Theta}_{L}^{(j)}  \n    \\big(\\prod_{q=l+1}^{L-1} \\matr{\\Gamma}_{q}   \\matr{\\Theta}_{q}^{(j)}\\big)\n     \\matr{\\Gamma}_{l}}_{F} \\\\\n    & = m^{-\\frac{1}{2}}\\cdot \\norm{\n        \\nabla_{l+1}^{(0)} \\matr{\\Gamma}_{l}  \\cdot \\matr{\\Theta}_{l+1}^{(0)} - \n        \\nabla_{l+1}^{(j)} \\matr{\\Gamma}_{l}  \\cdot \\matr{\\Theta}_{l+1}^{(j)}\n    }_{F} \\\\\n    & \\leq \\frac{\\zeta}{\\sqrt{m}}\\cdot( \\norm{\n        \\nabla_{l+1}^{(0)} \\cdot \\matr{\\Theta}_{l+1}^{(0)} -\n        \\nabla_{l+1}^{(0)} \\cdot \\matr{\\Theta}_{l+1}^{(j)}\n    }_{F} + \n    \\norm{\n        \\nabla_{l+1}^{(0)} \\cdot \\matr{\\Theta}_{l+1}^{(j)} - \n        \\nabla_{l+1}^{(j)} \\cdot \\matr{\\Theta}_{l+1}^{(j)}\n    }_{F}) \\\\\n    & \\leq \\frac{\\zeta}{\\sqrt{m}}\\cdot (\\norm{\\nabla_{l+1}^{(0)}}_{F}\\norm{\n          \\cdot \\matr{\\Theta}_{l+1}^{(0)} - \\matr{\\Theta}_{l+1}^{(j)}\n    }_{F} + \\norm{\\matr{\\Theta}_{l+1}^{(j)}}_{F}\n    \\norm{\n        \\nabla_{l+1}^{(0)} - \\nabla_{l+1}^{(j)}\n    }_{F}).\n\\end{split} \n\\end{displaymath}\nTo continue the proof, we need to bound the term $\\norm{\\nabla_{l}^{(0)}}_{F}$ as\n\\begin{displaymath}\n\\begin{split}\n    \\norm{\\nabla_{l}^{(0)}}_{F} = m^{-0.5} \\norm{\\matr{\\Gamma}_{l}\\matr{\\Theta}_{l+1}^{(0)}\\cdot\\nabla_{l+1}^{(0)}}_{F} \\leq \\zeta \\beta_{L}\\cdot \\norm{\\nabla_{l+1}^{(0)}}_{F}.\n\\end{split} \n\\end{displaymath}\nSince for $l=L-1$ we have\n\\begin{displaymath}\n\\begin{split}\n    \\norm{\\nabla_{L - 1}^{(0)}}_{F} \\leq \\frac{\\zeta \\beta_{3}}{m},\n\\end{split} \n\\end{displaymath}\nwe can derive\n\\begin{displaymath}\n\\begin{split}\n    \\norm{\\nabla_{l}^{(0)}}_{F} \\leq \\frac{\\beta_{3}}{m}\\cdot (\\zeta\\cdot \\beta_{L})^{L} \\leq 1\n\\end{split} \n\\end{displaymath}\nwith sufficiently large $m$, and this bound also applies to $\\norm{\\nabla_{gnn}^{(0)}}_{F}$. For \n\\begin{displaymath}\n\\begin{split}\n    &\\norm{\\nabla_{L}^{(0)} - \\nabla_{L}^{(j)}}_{F} = m^{-0.5} \\norm{\\vect{h}_{L-1}^{(0)} - \\vect{h}_{L-1}^{(j)}}_{F} \\leq \\Lambda^{(j)} / \\sqrt{m}\n\\end{split} \n\\end{displaymath}\nTherefore, we have\n\\begin{displaymath}\n\\begin{split}\n    &\\norm{\\nabla_{l}^{(0)} - \\nabla_{l}^{(j)}}_{F}\n    \\leq \\frac{\\zeta\\Upsilon}{m}\n    + \\zeta\\cdot (\\beta_{L} + \\Upsilon / m)\n    \\norm{\n        \\nabla_{l+1}^{(0)} - \\nabla_{l+1}^{(j)}\n    }_{F}.\n\\end{split} \n\\end{displaymath}\nBy following a similar approach as in Lemma~\\ref{lemma_after_GD_model_results_variables}, we will have\n\\begin{displaymath}\n\\begin{split}\n    &\\norm{\\nabla_{l}^{(0)} - \\nabla_{l}^{(j)}}_{F} \n    \\leq \\frac{\\zeta \\Upsilon}{m} \\cdot \\frac{(2\\zeta \\beta_{L})^{L}-1}{2\\zeta \\beta_{L}-1} = \\frac{\\Lambda^{(j)}}{\\beta_{h}}.\n\\end{split} \n\\end{displaymath}\nTherefore, we will have\n\\begin{displaymath}\n\\begin{split}\n    \\norm{\\nabla_{\\matr{\\Theta}_{l}}f(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(j)}) &- \\nabla_{\\matr{\\Theta}_{l}}f(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(0)})}_{F}  \n    \\leq \\big(\\beta_{h} + \\Lambda^{(j)}\\big)\\cdot \\frac{\\Lambda^{(j)}}{\\beta_{h}} + \\Lambda^{(j)} \\\\\n    &\\leq \\frac{\\Lambda^{(j)}}{\\beta_{h}}\\cdot (2\\beta_{h} + 1) = \\Lambda^{(j)}\\cdot (2 + \\frac{1}{\\beta_{h}}) \\leq 3\\cdot \\Lambda^{(j)}\n\\end{split} \n\\end{displaymath}\nwith sufficiently large $m$. This bound can also be derived for $\\norm{\\nabla_{\\matr{\\Theta}_{gnn}}f(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(0)})}_{2}$ with a similar procedure.\nFor $L$-th layer, we have\n\\begin{displaymath}\n\\begin{split}\n    \\norm{\\nabla_{\\matr{\\Theta}_{L}}f(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(j)}) &- \\nabla_{\\matr{\\Theta}_{L}}f(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(0)})}_{F}  \n    \\leq m^{-0.5}\\cdot \\norm{\\vect{h}_{L-1}^{(0)} - \\vect{h}_{L-1}^{(j)}}_{F} \\\\\n    & \\leq \\Lambda^{(j)} / \\sqrt{m},\n\\end{split} \n\\end{displaymath}\nwhich completes the proof.\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PROOF (DELETE IN THE CONFERENCE VERSION)\n\n\n\n% ------------------------------------------------------------\n\\begin{lemma}\nWith the probability of at least $1 - O(TL)\\cdot e^{-\\Omega(m)}$, we have the gradient for all the network as\n\\begin{displaymath}\n\\begin{split}\n    &\\norm{g(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(0)})}_{2} \\leq m^{-1}\\beta_{h} \\cdot \\sqrt{L\\cdot \\beta_{3}^{2}\\cdot (\\beta_{L}\\zeta)^{2L} + m}, \\\\\n    &\\norm{g(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(j)})}_{2} \\leq \\Lambda^{(j)}\\cdot\\sqrt{9L + m^{-1}} + m^{-1}\\beta_{h} \\cdot \\sqrt{L\\cdot \\beta_{3}^{2}\\cdot (\\beta_{L}\\zeta)^{2L} + m} \\\\\n    &\\norm{g(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(0)}) - g(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(j)})}_{2} \\leq \\Lambda^{(j)}\\cdot\\sqrt{9L + m^{-1}}.\n\\end{split}\n\\end{displaymath}\n\\label{lemma_after_GD_gradient_for_network_norm}\n\\end{lemma}\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PROOF (DELETE IN THE CONFERENCE VERSION)\n% \\textbf{Proof sketch.}\n% Since the whole gradient is\n% $\n%     \\norm{g(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(0)})}_{2} = \\sqrt{\n%     \\norm{\\nabla_{\\matr{\\Theta}_{gnn}}f(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(0)})}_{2}^{2}\n%     + \\sum_{l=1}^{L} \\norm{\\nabla_{\\matr{\\Theta}_{l}}f(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(0)})}_{2}^{2}\n%     },\n% $\n% we can therefore bound it with the conclusions from Lemma \\ref{lemma_after_GD_gradient_matrix_norm}, and similar procedure is applied to bound the difference $\\norm{g(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(0)}) - g(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(j)})}_{2}$. Then,  $\\norm{g(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(j)})}_{2}$ can be bounded accordingly.  $\\blacksquare$\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PROOF (DELETE IN THE CONFERENCE VERSION)\n% -------------------------------------------------------------\n\\textbf{Proof.}\nFirst, for the gradient before GD, we have\n\\begin{displaymath}\n\\begin{split}\n    &\\norm{g(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(0)})}_{2} = \\sqrt{\n    \\norm{\\nabla_{\\matr{\\Theta}_{gnn}}f(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(0)})}_{2}^{2}\n    + \\sum_{l=1}^{L} \\norm{\\nabla_{\\matr{\\Theta}_{l}}f(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(0)})}_{2}^{2}\n    } \\\\\n    & \\leq m^{-1}\\beta_{h} \\cdot \\sqrt{L\\cdot \\beta_{3}^{2}\\cdot (\\beta_{L}\\zeta)^{2L} + m}.\n\\end{split}\n\\end{displaymath}\nThen, for the norm of gradients, $\\matr{\\Theta} \\in \\{\\matr{\\Theta}_{gnn}, \\matr{\\Theta}_{1}, \\dots, \\matr{\\Theta}_{L-1}\\}$, we have\n\\begin{displaymath}\n\\begin{split}\n    &\\norm{g(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(0)}) - g(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(j)})}_{2} \\\\\n    & = \\sqrt{\n    \\sum_{\\matr{\\Theta}} \\norm{\\nabla_{\\matr{\\Theta}}f(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(0)}) - \\nabla_{\\matr{\\Theta}}f(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(j)})}_{2}^{2}\n    } \\\\\n    & \\leq \\sqrt{9L\\cdot (\\Lambda^{(j)})^{2} + (\\Lambda^{(j)})^{2} / m}  = \\Lambda^{(j)}\\cdot\\sqrt{9L + m^{-1}}.\n\\end{split}\n\\end{displaymath}\nThen, for the network gradient after GD, we have\n\\begin{displaymath}\n\\begin{split}\n    &\\norm{g(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(j)})}_{2} \\leq \\norm{g(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(0)}) - g(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(j)})}_{2} + \\norm{g(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(0)})}_{2} \\\\\n    & \\leq \\Lambda^{(j)}\\cdot\\sqrt{9L + m^{-1}} + m^{-1}\\beta_{h} \\cdot \\sqrt{L\\cdot \\beta_{3}^{2}\\cdot (\\beta_{L}\\zeta)^{2L} + m}\n\\end{split}\n\\end{displaymath}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PROOF (DELETE IN THE CONFERENCE VERSION)\n\n\n% ------------------------------------------------------------\n\\begin{lemma}\nWith the probability of at least $1 - O(TL)\\cdot e^{-\\Omega(m)}$, for the initialized parameter $\\matr{\\Theta}^{(0)}$, we have \n\\begin{displaymath}\n\\begin{split}\n    &\\abs{f(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(j)}) - \\inp{g(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(0)})}{\\matr{\\Theta}^{(j)} - \\matr{\\Theta}^{(0)}}} \\\\\n    &\\qquad\\qquad \\leq m^{-0.5} \\cdot \\big( \\Lambda^{(j)} (1 + \\beta_{3}) + \\beta_{3}\\beta_{h} + L\\cdot \\beta_{h} \\Upsilon \\big),\n\\end{split}\n\\end{displaymath}\nand for the network parameter after GD, $\\matr{\\Theta}^{(j)}$, we have\n\\begin{displaymath}\n\\begin{split}\n    \\abs{f&(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(j)}) - \\inp{g(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(j)})}{\\matr{\\Theta}^{(j)} - \\matr{\\Theta}^{(0)}}} \\leq B_{3} \\\\\n    & = m^{-0.5} \\big(\n        \\beta_{3} (\\Lambda^{(j)}+\\beta_{h}) + L\\cdot\\Upsilon\\cdot (\\Lambda^{(j)}+\\beta_{h})(\\Lambda^{(j)} / \\beta_{h} + 1) \\big).\n\\end{split}\n\\end{displaymath}\n\\label{lemma_output_minus_inner_product}\n\\end{lemma}\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PROOF (DELETE IN THE CONFERENCE VERSION)\n% \\textbf{Proof sketch.}\n% Since the LHS of the inequality is\n% \\begin{displaymath}\n% \\begin{split}\n%     &\\abs{f(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(j)}) - \\inp{g(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(0)})}{\\matr{\\Theta}^{(j)} - \\matr{\\Theta}^{(0)}}}  = \\abs{\\frac{1}{\\sqrt{m}}\\inp{\\vect{h}_{L-1}^{(j)}}{\\matr{\\Theta}_{L}^{(j)}} \\\\\n%     & \\qquad - \\frac{1}{\\sqrt{m}} \\inp{\\vect{h}_{L-1}^{(0)}}{\\matr{\\Theta}_{L}^{(0)} - \\matr{\\Theta}_{L}^{(j)}} - \\sum_{l=0}^{L-1} (\\vect{h}_{l-1}^{(0)})^{\\intercal} (\\matr{\\Theta}_{l}^{(0)} - \\matr{\\Theta}_{l}^{(j)})\\nabla_{l}^{(0)}) }\n% \\end{split}\n% \\end{displaymath}\n% with $\\nabla_{l}^{(j)} = m^{-\\frac{L-l+1}{2}}\\cdot \\matr{\\Theta}_{L}^{(j)} \\cdot \n% \\big(\\prod_{q=l+1}^{L-1} \\matr{\\Gamma}_{q}  \\cdot \\matr{\\Theta}_{q}^{(j)}\\big)\n% \\cdot \\matr{\\Gamma}_{l}$, we can follow a comparable approach in Lemma \\ref{lemma_after_GD_gradient_matrix_norm} to decompose it into the norms of single terms. Then, applying the conclusions from Lemma \\ref{lemma_initial_param_outputs}, Lemma \\ref{lemma_after_GD_weight_matrices_bounds} and Lemma \\ref{lemma_after_GD_model_results_variables} finishes the proof. Similar procedure is also applied for $\\abs{f(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(j)}) - \\inp{g(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(j)})}{\\matr{\\Theta}^{(j)} - \\matr{\\Theta}^{(0)}}}$.     $\\blacksquare$\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PROOF (DELETE IN THE CONFERENCE VERSION)\n% --------------------------------------------\n\\textbf{Proof.}\nFor the sake of enumeration, we let $\\matr{\\Theta}_{0} = \\matr{\\Theta}_{gnn}, \\nabla_{0} = \\nabla_{gnn}, \\vect{h}_{0} = \\vect{h}_{gnn}$ and $\\vect{h}_{-1} = \\vect{h}_{S}$. Then, we can derive\n\\begin{displaymath}\n\\begin{split}\n    &\\abs{f(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(j)}) - \\inp{g(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(0)})}{\\matr{\\Theta}^{(j)} - \\matr{\\Theta}^{(0)}}}  = \\abs{\\frac{1}{\\sqrt{m}}\\inp{\\vect{h}_{L-1}^{(j)}}{\\matr{\\Theta}_{L}^{(j)}} \\\\\n    & \\qquad - \\frac{1}{\\sqrt{m}} \\inp{\\vect{h}_{L-1}^{(0)}}{\\matr{\\Theta}_{L}^{(0)} - \\matr{\\Theta}_{L}^{(j)}} - \\sum_{l=0}^{L-1} (\\vect{h}_{l-1}^{(0)})^{\\intercal} (\\matr{\\Theta}_{l}^{(0)} - \\matr{\\Theta}_{l}^{(j)})\\nabla_{l}^{(0)}) } \\\\\n    & \\leq m^{-0.5}\\norm{\\vect{h}_{L}^{(j)} - \\vect{h}_{L}^{(0)}}_{2} \\norm{\\matr{\\Theta}_{L}^{(j)}}_{2}\n    + m^{-0.5} \\norm{\\vect{h}_{L-1}^{(0)}}_{2} \\norm{\\matr{\\Theta}_{L}^{(0)}}_{2} \\\\\n    & \\qquad\\qquad + \\sum_{l=0}^{L-1} \\norm{\\vect{h}_{l-1}^{(0)}}_{2} \\norm{\\matr{\\Theta}_{l}^{(0)} - \\matr{\\Theta}_{l}^{(j)}}_{F} \\norm{\\nabla_{l}^{(0)}}_{F} \\\\\n    & \\leq m^{-0.5}\\Lambda^{(j)} (\\Upsilon / \\sqrt{m} + \\beta_{3}) + m^{-0.5} \\beta_{3} \\beta_{h} \n    + L\\cdot \\beta_{h} \\frac{\\Upsilon}{\\sqrt{m}} \\\\\n    & \\leq m^{-0.5} \\cdot \\big( \\Lambda^{(j)} (1 + \\beta_{3}) + \\beta_{3}\\beta_{h} + L\\cdot \\beta_{h} \\Upsilon \\big).\n\\end{split}\n\\end{displaymath}\nOn the other hand, for network parameter after GD, we can have\n\\begin{displaymath}\n\\begin{split}\n    &\\abs{f(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(j)}) - \\inp{g(\\widetilde{\\matr{X}};\\matr{\\Theta}^{(j)})}{\\matr{\\Theta}^{(j)} - \\matr{\\Theta}^{(0)}}}  = \\abs{\\frac{1}{\\sqrt{m}}\\inp{\\vect{h}_{L-1}^{(j)}}{\\matr{\\Theta}_{L}^{(j)}} \\\\\n    & \\qquad - \\frac{1}{\\sqrt{m}} \\inp{\\vect{h}_{L-1}^{(j)}}{\\matr{\\Theta}_{L}^{(j)} - \\matr{\\Theta}_{L}^{(0)}} - \\sum_{l=0}^{L-1} (\\vect{h}_{l-1}^{(j)})^{\\intercal} (\\matr{\\Theta}_{l}^{(0)} - \\matr{\\Theta}_{l}^{(j)})\\nabla_{l}^{(j)}) } \\\\\n    %\n    & \\leq \\abs{m^{-0.5} \\inp{\\vect{h}_{L-1}^{(j)}}{\\matr{\\Theta}_{L}^{(0)}} -\n    \\sum_{l=0}^{L-1} (\\vect{h}_{l-1}^{(j)})^{\\intercal} (\\matr{\\Theta}_{l}^{(0)} - \\matr{\\Theta}_{l}^{(j)})\\nabla_{l}^{(j)}} \\\\\n    & \\leq m^{-0.5} \\norm{\\vect{h}_{L-1}^{(j)}}_{2}\\norm{\\matr{\\Theta}_{L}^{(0)}}_{2}\n    + \\sum_{l=0}^{L-1} \\norm{\\vect{h}_{l-1}^{(j)}}_{2} \\norm{\\matr{\\Theta}_{l}^{(0)} - \\matr{\\Theta}_{l}^{(j)}}_{F} \\norm{\\nabla_{l}^{(j)}}_{F} \\\\\n    & \\leq m^{-0.5} \\beta_{3} (\\Lambda^{(j)}+\\beta_{h}) + L\\cdot (\\Lambda^{(j)}+\\beta_{h}) (\\Upsilon / \\sqrt{m}) (\\Lambda^{(j)} / \\beta_{h} + 1) \\\\ \n    & \\leq m^{-0.5} \\big(\n        \\beta_{3} (\\Lambda^{(j)}+\\beta_{h}) + L\\cdot\\Upsilon\\cdot (\\Lambda^{(j)}+\\beta_{h})(\\Lambda^{(j)} / \\beta_{h} + 1) \n    \\big).\n\\end{split}\n\\end{displaymath}\nThis completes the proof.\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PROOF (DELETE IN THE CONFERENCE VERSION)\n\n\n\n\n% ------------------------------------\n\\textbf{Proof sketch for Lemmas \\ref{lemma_initial_param_outputs}-\\ref{lemma_output_minus_inner_product}.}\nFirst we derive the conclusions in Lemma \\ref{lemma_initial_param_outputs} with the property of Gaussian matrices. Then, Lemmas \\ref{lemma_after_GD_weight_matrices_bounds} and \\ref{lemma_after_GD_model_results_variables} are proved through the induction after breaking the target into norms of individual terms (variables, weight matrices) and applying Lemma \\ref{lemma_initial_param_outputs}. Finally, for Lemmas \\ref{lemma_after_GD_gradient_matrix_norm}-\\ref{lemma_output_minus_inner_product}, we also decompose targets into norms of individual terms. Then, applying Lemmas \\ref{lemma_initial_param_outputs}-\\ref{lemma_after_GD_model_results_variables} the to bound these terms (at random initialization / after GD) would give the result.        $\\blacksquare$\n\n\n\n\n% ============================================================================\n"
            },
            "section 9": {
                "name": "Lemmas for Gradient Matrices",
                "content": "\nInspired by \\cite{Neural-UCB,CNN_UCB-ban2021convolutional} and with sufficiently large network width $m$, the trained network parameter can be related to ridge regression estimator where the context is embedded by network gradients.  \nWith the received contexts and rewards up to time step $t$, we have the estimated parameter $\\widehat{\\matr{\\Theta}}$ as\n$\n    \\widehat{\\matr{\\Theta}}_{0} = (\\matr{Z}_{0})^{-1}\\cdot \\vect{b}_{0}\n$\nwhere \n$\n    \\matr{Z}_{0} = \\lambda\\matr{I} + \\frac{1}{m}\\sum_{\\tau=1}^{t} g(\\widetilde{\\matr{X}}_{\\tau}; \\matr{\\Theta}_{0})g(\\widetilde{\\matr{X}}_{\\tau}; \\matr{\\Theta}_{0})^{\\intercal},  \\vect{b}_{0}  = \\frac{1}{\\sqrt{m}}\\sum_{\\tau=1}^{t} r_{\\tau} \\cdot g(\\widetilde{\\matr{X}}_{\\tau}; \\matr{\\Theta}_{0}).\n$\nWe also define the gradient matrix w.r.t. the network parameters as\n\\begin{displaymath}\n\\begin{split}\n    & \\matr{G}^{(j)} = \\big( g(\\widetilde{\\matr{X}}_{1}; \\matr{\\Theta}^{(j)}), \\dots, g(\\widetilde{\\matr{X}}_{t}; \\matr{\\Theta}^{(j)}) \\big) \\\\\n    & \\vect{f}^{(j)} = \\big( f(\\widetilde{\\matr{X}}_{1}; \\matr{\\Theta}^{(j)}), \\dots, f(\\widetilde{\\matr{X}}_{t}; \\matr{\\Theta}^{(j)}) \\big), \n    \\quad \\vect{r} = \\big( r_{1}, \\dots, r_{t} \\big) \\\\\n    & \\matr{\\Theta}^{(j+1)} = \\matr{\\Theta}^{(j)} - \\eta\\cdot \\big( (\\matr{G}^{(j)})^{\\intercal} (\\vect{f}^{(j)} - \\vect{r}) \\big).\n\\end{split}\n\\end{displaymath}\nwhere the $t$ notation is omitted by default. Then, we use the following Lemma to bound the above matrices.\n\n% ------------------------------------------------------------\n\\begin{lemma}\nAfter $j$ iterations, with the probability of at least $1 - O(L)\\cdot e^{-\\Omega(m)}$, we have \n\\begin{displaymath}\n\\begin{split}\n    & \\norm{\\matr{G}^{(0)}}_{F} \\leq G_{1} = m^{-1}\\beta_{h} \\cdot \\sqrt{t\\cdot (L\\cdot \\beta_{3}^{2}\\cdot (\\beta_{L}\\zeta)^{2L} + m)}, \\\\\n    & \\norm{\\matr{G}^{(0)} - \\matr{G}^{(j)}}_{F} \\leq \\Lambda^{(j)}\\cdot\\sqrt{t\\cdot(9L + m^{-1})}, \\\\\n    & \\norm{\\matr{G}^{(j)}}_{F} \\leq \\widetilde{I}_{1} = \\sqrt{t\\cdot (L\\cdot \\beta_{3}^{2}\\cdot (\\beta_{L}\\zeta)^{2L} + m)} + \\Lambda^{(j)}\\sqrt{t\\cdot(9L + m^{-1})}\\\\\n    & \\norm{\\vect{f}^{(j)} - (\\matr{G}^{(j)})^{\\intercal}(\\widehat{\\matr{\\Theta}}^{(j)} - \\widehat{\\matr{\\Theta}}^{(0)})}_{2} \\leq \\sqrt{t}\\cdot B_{3} \\\\\n    & ~~ = \\sqrt{t}\\cdot  m^{-0.5} \\big(\n        \\beta_{3} (\\Lambda^{(j)}+\\beta_{h}) + L\\cdot\\Upsilon\\cdot (\\Lambda^{(j)}+\\beta_{h})(\\Lambda^{(j)} / \\beta_{h} + 1) \\big)\n\\end{split}\n\\end{displaymath}\n\n\\label{lemma_bounding_gradient_matrix_at_init}\n\\end{lemma}\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PROOF (DELETE IN THE CONFERENCE VERSION)\n% \\textbf{Proof sketch.}\n% Since \n% $\n% \\norm{\\matr{G}^{(0)}}_{F} = \\sqrt{\\sum_{\\tau=1}^{t} \\norm{g(\\widetilde{\\matr{X}}_{\\tau}; \\matr{\\Theta}^{(0)})}_{2}^{2}},\n% $\n% we bound it with the conclusion from Lemma \\ref{lemma_after_GD_gradient_for_network_norm}, and the same approach also applies to $\\norm{\\matr{G}^{(0)} - \\matr{G}^{(j)}}_{F}$. \n% For $\n% \\norm{\\vect{f}^{(j)} - (\\matr{G}^{(j)})^{\\intercal}(\\widehat{\\matr{\\Theta}}^{(j)} - \\widehat{\\matr{\\Theta}}^{(0)})}_{2}\n% $, we can bound it with Lemma \\ref{lemma_output_minus_inner_product}.       $\\blacksquare$\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PROOF (DELETE IN THE CONFERENCE VERSION)\n% --------------------------------------------\n\\textbf{Proof.}\nFor the gradient matrix after random initialization, we have\n\\begin{displaymath}\n\\begin{split}\n    & \\norm{\\matr{G}^{(0)}}_{F} = \\sqrt{\\sum_{\\tau=1}^{t} \\norm{g(\\widetilde{\\matr{X}}_{\\tau}; \\matr{\\Theta}^{(0)})}_{2}^{2}}\n    \\leq m^{-1}\\beta_{h} \\cdot \\sqrt{t\\cdot L\\cdot \\beta_{3}^{2}\\cdot (\\beta_{L}\\zeta)^{2L} + m}\n\\end{split}\n\\end{displaymath}\nwith the conclusion from Lemma \\ref{lemma_after_GD_gradient_for_network_norm}. Then, \n\\begin{displaymath}\n\\begin{split}\n    & \\norm{\\matr{G}^{(0)} - \\matr{G}^{(j)}}_{F} = \\sqrt{\\sum_{\\tau=1}^{t} \\norm{g(\\widetilde{\\matr{X}}_{\\tau}; \\matr{\\Theta}^{(0)}) - g(\\widetilde{\\matr{X}}_{\\tau}; \\matr{\\Theta}^{(j)})}_{2}^{2}} \\\\\n    & \\qquad\\qquad \\leq \\Lambda^{(j)}\\cdot\\sqrt{t\\cdot(9L + m^{-1})}.\n\\end{split}\n\\end{displaymath}\nFor the third inequality in this Lemma, we have\n\\begin{displaymath}\n\\begin{split}\n    & \\norm{\\vect{f}^{(j)} - (\\matr{G}^{(j)})^{\\intercal}(\\widehat{\\matr{\\Theta}}^{(j)} - \\widehat{\\matr{\\Theta}}^{(0)})}_{2} \\\\\n    & = \\sqrt{\\sum_{\\tau=1}^{t} \\abs{f(\\widetilde{\\matr{X}}_{\\tau}; \\matr{\\Theta}^{(j)}) - \n    \\inp{g(\\widetilde{\\matr{X}}_{\\tau};\\matr{\\Theta}^{(j)})}{\\matr{\\Theta}^{(j)} - \\matr{\\Theta}^{(0)}})\n    }^{2}} \\\\\n    & \\leq \\sqrt{t}\\cdot  m^{-0.5} \\big(\n        \\beta_{3} (\\Lambda^{(j)}+\\beta_{h}) + L\\cdot\\Upsilon\\cdot (\\Lambda^{(j)}+\\beta_{h})(\\Lambda^{(j)} / \\beta_{h} + 1) \\big)\n\\end{split}\n\\end{displaymath}\nbased on Lemma \\ref{lemma_output_minus_inner_product}.\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PROOF (DELETE IN THE CONFERENCE VERSION)\n\n\n\n% ------------------------------------------------------------\nAnalogous to \\cite{CNN_UCB-ban2021convolutional,Neural-UCB}, we define another auxiliary sequence to bound the parameter difference. With $\\widetilde{\\matr{\\Theta}}^{(0)} = \\matr{\\Theta}^{(0)}$, we have\n% \\begin{displaymath}\n% \\begin{split}\n%     & \\widetilde{\\matr{\\Theta}}^{(j+1)} = \\\\\n%     & \\widetilde{\\matr{\\Theta}}^{(j)} - \\eta\\cdot \\bigg( \\matr{G}^{(j)} \\big((\\matr{G}^{(j)})^{\\intercal}(\\widetilde{\\matr{\\Theta}}^{(j)} - \\widetilde{\\matr{\\Theta}}^{(0)}) - \\vect{r}\\big) + m\\lambda (\\widetilde{\\matr{\\Theta}}^{(j)} - \\widetilde{\\matr{\\Theta}}^{(0)})\\bigg)\n% \\end{split}\n% \\end{displaymath}\n$\n    \\widetilde{\\matr{\\Theta}}^{(j+1)} = \\\\\n     \\widetilde{\\matr{\\Theta}}^{(j)} - \n     \\eta\\cdot \\bigg( \\matr{G}^{(j)} \\big((\\matr{G}^{(j)})^{\\intercal}(\\widetilde{\\matr{\\Theta}}^{(j)} - \\widetilde{\\matr{\\Theta}}^{(0)}) - \\vect{r}\\big) + m\\lambda (\\widetilde{\\matr{\\Theta}}^{(j)} - \\widetilde{\\matr{\\Theta}}^{(0)})\\bigg)\n$. \n% We have the following Lemma to bridge $\\matr{\\Theta}^{(0)}$ with $\\widehat{\\matr{\\Theta}}_{t-1}$.\n\\begin{lemma}\nAfter $j$ iterations, with the probability of at least $1 - O(L)\\cdot e^{-\\Omega(m)}$, we have \n\\begin{displaymath}\n\\begin{split}\n    & \\norm{\\widetilde{\\matr{\\Theta}}^{(j)} - \\matr{\\Theta}^{(0)} - \\widehat{\\matr{\\Theta}}_{t} / \\sqrt{m}}_{2}\n    \\leq \\sqrt{t / (m\\lambda)}\n\\end{split}\n\\end{displaymath}\n\n\\label{lemma_bounding_auxiliary_parameter}\n\\end{lemma}\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PROOF (DELETE IN THE CONFERENCE VERSION)\n% ----------------------------------------\n\\textbf{Proof.}\nThe proof is analogous to Lemma 10.2 in \\cite{CNN_UCB-ban2021convolutional} and Lemma C.4 in \\cite{Neural-UCB}. Switching $\\matr{G}_{0}$ to $\\matr{G}_{j}$ would give the result.   $\\blacksquare$\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PROOF (DELETE IN THE CONFERENCE VERSION)\n\n\n\n\n\n\n\n\n\n% ----------------------------------------------------------------------------------------------------------------------------------------------------\nThen, we can have the following lemma to bridge the difference between the regression estimator $\\widehat{\\matr{\\Theta}}$ and the network parameter $\\matr{\\Theta}$.\n\n\\begin{lemma}\nAt this time step $t$, with the notation defined in Lemma \\ref{lemma_CB_one_step_same_graph} and the probability at least $1 - O(L)\\cdot e^{-\\Omega(m)}$, we will have\n\\begin{displaymath}\n\\begin{split}\n    & \\norm{\\matr{\\Theta}_{t} - \\matr{\\Theta}_{0} - \\widehat{\\matr{\\Theta}}_{t} / \\sqrt{m}}_{2} \\leq (\\widetilde{I}_{1} \\cdot \\sqrt{t} B_{3} +  m\\cdot \\widetilde{I}_{2}) / (m\\lambda) + \\sqrt{t / (m\\lambda)}\n\\end{split}\n\\end{displaymath}\nwith proper $m, \\eta$ as in Lemma \\ref{lemma_CB_one_step_same_graph}\n\\label{lemma_linking_regre_est_with_net_param}\n\\end{lemma}\n\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PROOF (DELETE IN THE CONFERENCE VERSION)\n% \\textbf{Proof sketch.}\n% For the LHS of the inequality, we have\n% \\begin{displaymath}\n% \\begin{split}\n%     & \\norm{\\widetilde{\\matr{\\Theta}}^{(j+1)} - \\matr{\\Theta}^{(j+1)}}_{2} \n%     \\leq I_{1} + I_{2} + I_{3} \\\\\n%     & =\n%     \\eta \\norm{\\matr{G}^{(j)}}_{2} \\norm{\\vect{f}^{(j)}  - (\\matr{G}^{(j)})^{\\intercal} (\\matr{\\Theta}^{(j)} - \\matr{\\Theta}^{(0)})}_{2} + \\eta m\\lambda\\norm{\\matr{\\Theta}^{(0)} - \\matr{\\Theta}^{(j)}}_{2} \\\\\n%     & \\quad + \\norm{\\matr{I} - \\eta\\cdot (m\\lambda \\matr{I} + \\matr{G}^{(j)}(\\matr{G}^{(j)})^{\\intercal})}_{2}\n%     \\norm{\\matr{\\Theta}^{(j)} - \\widetilde{\\matr{\\Theta}}^{(j)}}_{2}.\n% \\end{split}\n% \\end{displaymath}\n% where $I_{1}, I_{2}$ can be bounded based on Lemma \\ref{lemma_bounding_gradient_matrix_at_init} following an analogous approach as Lemma 6.2 in \\cite{CNN_UCB-ban2021convolutional}. For $I_{3}$, with proper $m$ and $\\eta$, we can prove $\\eta\\cdot (m\\lambda \\matr{I} + \\matr{G}^{(0)}(\\matr{G}^{(0)})^{\\intercal}) \\preceq \\matr{I}$. Based on Lemma \\ref{lemma_bounding_auxiliary_parameter} the second term of $I_{3}$ can be bounded by induction with $\\widetilde{\\matr{\\Theta}}^{(0)} = \\matr{\\Theta}^{(0)}$.    $\\blacksquare$\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PROOF (DELETE IN THE CONFERENCE VERSION)\n% ------------------------------------------------\n\\textbf{Proof.}\nWith an analogous approach from Lemma 6.2 in \\cite{CNN_UCB-ban2021convolutional}, we can have\n\\begin{displaymath}\n\\begin{split}\n    & \\norm{\\widetilde{\\matr{\\Theta}}^{(j+1)} - \\matr{\\Theta}^{(j+1)}}_{2} \\\\\n    & \\leq\n    \\eta \\norm{\\matr{G}^{(j)}}_{2} \\norm{\\vect{f}^{(j)}  - (\\matr{G}^{(j)})^{\\intercal} (\\matr{\\Theta}^{(j)} - \\matr{\\Theta}^{(0)})}_{2} + \\eta m\\lambda\\norm{\\matr{\\Theta}^{(0)} - \\matr{\\Theta}^{(j)}}_{2} \\\\\n    & + \\norm{\\matr{I} - \\eta\\cdot (m\\lambda \\matr{I} + \\matr{G}^{(j)}(\\matr{G}^{(j)})^{\\intercal})}_{2}\n    \\norm{\\matr{\\Theta}^{(j)} - \\widetilde{\\matr{\\Theta}}^{(j)}}_{2} = I_{1} + I_{2} + I_{3}.\n\\end{split}\n\\end{displaymath}\nWith Lemma \\ref{lemma_bounding_gradient_matrix_at_init}, we can bound them as\n\\begin{displaymath}\n\\begin{split}\n    & I_{1} \\leq \\eta \\cdot \\widetilde{I}_{1} \\cdot \\sqrt{t} B_{3}  \\\\\n    & I_{2} \\leq \\eta m\\lambda \\sqrt{\\sum_{i=0}^{L} \\norm{\\matr{\\Theta}_{l}^{(0)} - \\matr{\\Theta}_{l}^{(j)}}_{F}^{2}} \\leq \\eta m\\cdot \\widetilde{I}_{2} =\\eta m \\lambda \\sqrt{L+1} \\cdot \\Upsilon / \\sqrt{m} .\n\\end{split}\n\\end{displaymath}\nbased on the conclusion from Lemma \\ref{lemma_after_GD_weight_matrices_bounds}. \nFor $I_{3}$, we have\n\\begin{displaymath}\n\\begin{split}\n    & \\eta\\cdot (m\\lambda \\matr{I} + \\matr{G}^{(0)}(\\matr{G}^{(0)})^{\\intercal}) \\preceq \n    \\eta\\cdot \\matr{I}\\\\\n    & \\qquad\\qquad \\cdot \\big(m\\lambda + (m^{-1}\\beta_{h} \\cdot \\sqrt{t\\cdot (L\\cdot \\beta_{3}^{2}\\cdot (\\beta_{L}\\zeta)^{2L} + m)})^{2}\\big) \n    \\preceq \\matr{I}\n\\end{split}\n\\end{displaymath}\nwith proper choice of $m$ and $\\eta$.\nIt leads to \n\\begin{displaymath}\n\\begin{split}\n    & \\norm{\\widetilde{\\matr{\\Theta}}^{(j+1)} - \\matr{\\Theta}^{(j+1)}}_{2} \n    \\leq (1 - \\eta m \\lambda) \\norm{\\widetilde{\\matr{\\Theta}}^{(j)} - \\matr{\\Theta}^{(j)}}_{2} + \\widetilde{I}_{1} \\cdot \\sqrt{t} B_{3} + \\eta m\\cdot \\widetilde{I}_{2}\n\\end{split}\n\\end{displaymath}\nwhich by induction and $\\widetilde{\\matr{\\Theta}}^{(0)}=\\matr{\\Theta}^{(0)}$, we have\n\\begin{displaymath}\n\\begin{split}\n    & \\norm{\\widetilde{\\matr{\\Theta}}^{(j)} - \\matr{\\Theta}^{(j)}}_{2} \n    \\leq (\\widetilde{I}_{1} \\cdot \\sqrt{t} B_{3} +  m\\cdot \\widetilde{I}_{2}) / (m\\lambda).\n\\end{split}\n\\end{displaymath}\nFinally, \n\\begin{displaymath}\n\\begin{split}\n    & \\norm{\\matr{\\Theta}_{t} - \\matr{\\Theta}_{0} - \\widehat{\\matr{\\Theta}}_{t} / \\sqrt{m}}_{2} \\leq \\norm{\\widetilde{\\matr{\\Theta}}^{(j)} - \\matr{\\Theta}^{(j)}}_{2} + \n    \\norm{\\widetilde{\\matr{\\Theta}}_{t} - \\matr{\\Theta}_{0} - \\widehat{\\matr{\\Theta}}_{0} / \\sqrt{m}}_{2} \\\\\n    & \\leq (\\widetilde{I}_{1} \\cdot \\sqrt{t} B_{3} +  m\\cdot \\widetilde{I}_{2}) / (m\\lambda) + \\sqrt{t / (m\\lambda)},\n\\end{split}\n\\end{displaymath}\nwhich completes the proof. \n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PROOF (DELETE IN THE CONFERENCE VERSION)\n\n\n% --------------------------------------------------------------\n% We also have the following bound for gradient matrices.\n\\begin{lemma}\nAt this time step $t$, with the probability at least $1 - O(L)\\cdot e^{-\\Omega(m)}$, we will have\n\\begin{displaymath}\n\\begin{split}\n    & \\norm{\\matr{Z}_{t}}_{2} \\leq \\lambda + \\\\\n    & \\quad \\frac{t(L+1)}{m}\\big(\\Lambda^{(j)}\\cdot\\sqrt{9L + m^{-1}} + m^{-1}\\beta_{h} \\cdot \\sqrt{L\\cdot \\beta_{3}^{2}\\cdot (\\beta_{L}\\zeta)^{2L} + m}\\big)^{2}, \\\\\n    & \\norm{\\matr{G}_{t}^{\\intercal}\\matr{G}_{t} - \\matr{G}_{0}^{\\intercal}\\matr{G}_{0}}_{F} \\leq \n    2 t\\cdot m^{-1}(\\Lambda^{(j)}\\cdot\\sqrt{9L + m^{-1}}) \\\\\n    &\\quad \\cdot \\big(\\Lambda^{(j)}\\sqrt{9L + m^{-1}} + m^{-1}\\beta_{h} \\cdot \\sqrt{L\\cdot \\beta_{3}^{2}\\cdot (\\beta_{L}\\zeta)^{2L} + m} \\big) = B_{G} / m\n\\end{split}\n\\end{displaymath}\nwith proper $m, \\eta$ as in Lemma \\ref{lemma_CB_one_step_same_graph}.\n\\label{lemma_bound_G_t_A_t}\n\\end{lemma}\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PROOF (DELETE IN THE CONFERENCE VERSION)\n% \\textbf{Proof sketch.}\n% Since $\n%     \\norm{\\matr{Z}_{t}}_{2} \\leq \\lambda + m^{-1}\\sum_{\\tau=1}^{t} \\norm{g(\\widetilde{\\matr{X}}_{\\tau}; \\matr{\\Theta}_{t})}_{2}^{2},\n% $\n% we can bound this term with Lemma \\ref{lemma_after_GD_gradient_for_network_norm}. As \n% $\n% \\norm{\\matr{G}_{t}^{\\intercal}\\matr{G}_{t} - \\matr{G}_{0}^{\\intercal}\\matr{G}_{0}}_{F} \n%     \\leq m^{-1} \\cdot \n%     \\sqrt{\n%     \\sum_{i, j = 1}^{T} \n%     \\norm{g(\\widetilde{\\matr{X}}_{i}; \\matr{\\Theta}_{t}) + g(\\widetilde{\\matr{X}}_{j}; \\matr{\\Theta}_{0})}_{2}^{2} + \n%     \\norm{g(\\widetilde{\\matr{X}}_{i}; \\matr{\\Theta}_{t}) - g(\\widetilde{\\matr{X}}_{j}; \\matr{\\Theta}_{0})}_{2}^{2}},\n% $\n% we adopt the Lemma \\ref{lemma_after_GD_gradient_for_network_norm} again to complete the proof.  $\\blacksquare$\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PROOF (DELETE IN THE CONFERENCE VERSION)\n\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PROOF (DELETE IN THE CONFERENCE VERSION)\n% -----------------------------------------------------------------\n\\textbf{Proof.}\nFor the gradient matrix of ridge regression, we have\n\\begin{displaymath}\n\\begin{split}\n    & \\norm{\\matr{Z}_{t}}_{2} \n    \\leq \\lambda + m^{-1}\\sum_{\\tau=1}^{t} \\norm{g(\\widetilde{\\matr{X}}_{\\tau}; \\matr{\\Theta}_{t})}_{2}^{2} \\leq \\lambda + \\\\\n    & \\quad \\frac{t(L+1)}{m}\\big(\\Lambda^{(j)}\\cdot\\sqrt{9L + m^{-1}} + m^{-1}\\beta_{h} \\cdot \\sqrt{L\\cdot \\beta_{3}^{2}\\cdot (\\beta_{L}\\zeta)^{2L} + m}\\big)^{2}\n\\end{split}\n\\end{displaymath}\nwith the results from Lemma \\ref{lemma_after_GD_gradient_for_network_norm}. Then,\n\\begin{displaymath}\n\\begin{split}\n    & \\norm{\\matr{G}_{t}^{\\intercal}\\matr{G}_{t} - \\matr{G}_{0}^{\\intercal}\\matr{G}_{0}}_{F} \n    \\leq m^{-1} \\cdot \\\\\n    & \\sqrt{\n    \\sum_{i, j = 1}^{t} \n    \\norm{g(\\widetilde{\\matr{X}}_{i}; \\matr{\\Theta}_{t}) + g(\\widetilde{\\matr{X}}_{j}; \\matr{\\Theta}_{0})}_{2}^{2} + \n    \\norm{g(\\widetilde{\\matr{X}}_{i}; \\matr{\\Theta}_{t}) - g(\\widetilde{\\matr{X}}_{j}; \\matr{\\Theta}_{0})}_{2}^{2}\n    } \\\\\n    %\n    & \\leq 2 t\\cdot m^{-1} \\cdot \\big(\\Lambda^{(j)}\\sqrt{9L + m^{-1}} + m^{-1}\\beta_{h} \\cdot \\sqrt{L\\cdot \\beta_{3}^{2}\\cdot (\\beta_{L}\\zeta)^{2L} + m} \\big) \\\\\n    & \\qquad (\\Lambda^{(j)}\\cdot\\sqrt{9L + m^{-1}}) = B_{G} / m.\n\\end{split}\n\\end{displaymath}\nThe proof is then completed. \n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PROOF (DELETE IN THE CONFERENCE VERSION)\n\n\n\n% ----------------------------------------------------\n% \\begin{lemma} [Lemma 6.3 \\cite{CNN_UCB-ban2021convolutional}, Lemma 5.4 \\cite{Neural-UCB}]\n% At this time step $t$, with notation in Theorem \\ref{theorem_regret_bound} and the probability at least $1-\\delta$, if given satisfying $m, \\eta$ as in Lemma \\ref{lemma_CB_one_step_same_graph}, we will have\n% \\begin{displaymath}\n% \\begin{split}\n%     \\log\\frac{\\det(\\matr{Z}_{t})}{\\det(\\lambda\\matr{I})} \\leq \\widetilde{d}\\log(1+T/\\lambda) + 1\n% \\end{split}\n% \\end{displaymath}\n% \\label{lemma_bounding_gradient_matrix_t}\n% \\end{lemma}\n\n\n\n% -------------------------------------------\n\\textbf{Proof sketch for Lemmas \\ref{lemma_bounding_gradient_matrix_at_init}-\\ref{lemma_bound_G_t_A_t}.}\nAnalogous to lemmas in Section \\ref{sec_appendix_A}, Lemma \\ref{lemma_bounding_gradient_matrix_at_init} is proved by Lemmas \\ref{lemma_after_GD_gradient_for_network_norm}, \\ref{lemma_output_minus_inner_product} by breaking the target into the product of norms. The proof of Lemma \\ref{lemma_bounding_auxiliary_parameter} is analogous to Lemma 10.2 in \\cite{CNN_UCB-ban2021convolutional} and Lemma C.4 in \\cite{Neural-UCB}, then replacing $\\matr{G}_{0}$ with $\\matr{G}_{j}$ would give the result. Then, based on Lemma \\ref{lemma_bounding_auxiliary_parameter} results, Lemma \\ref{lemma_linking_regre_est_with_net_param} will be proved with after bounding $\\norm{\\widetilde{\\matr{\\Theta}}^{(j+1)} - \\matr{\\Theta}^{(j+1)}}_{2}$ by induction. Finally, \nLemma \\ref{lemma_bound_G_t_A_t} is proved by decomposing the norm into sum of individual terms, and bounding these terms with bounds on gradients in Lemma \\ref{lemma_after_GD_gradient_for_network_norm}.\n$\\blacksquare$\n\n\n\n\n% -------------------------------------------------------\n\n% ==================================================================\n% ------------------------------------------------------------\n"
            },
            "section 10": {
                "name": "Lemmas for Model Convergence",
                "content": "\n% To prove the model convergence, we first give an assumption regarding the gradient matrix $\\matr{G}^{(j)}(\\matr{\\Theta}_{L-1})$. Here, $\\matr{G}^{(j)}(\\matr{\\Theta}_{L-1}) = \n% \\big( g(\\widetilde{\\matr{X}}_{1}; \\matr{\\Theta}_{L-1}^{(j)}), \\dots, g(\\widetilde{\\matr{X}}_{t}; \\matr{\\Theta}_{L-1}^{(j)}) \\big)^{\\intercal}\n% \\big( g(\\widetilde{\\matr{X}}_{1}; \\matr{\\Theta}_{L-1}^{(j)}), \\dots, g(\\widetilde{\\matr{X}}_{t}; \\matr{\\Theta}_{L-1}^{(j)}) \\big)$\n% \\begin{Assumption}\n% With $m \\geq \\mbox{Poly}(t, L, \\frac{1}{\\beta_{F}}, \\frac{1}{\\lambda}, (\\zeta \\beta_{L})^{L}, \\log(\\frac{1}{\\delta}))$ and for $j \\in [J]$, we have the minimal eigenvalue of $\\matr{G}^{(j)}$ as\n%     \\begin{displaymath}\n%     \\begin{split}\n%         \\lambda_{\\min}(\\matr{G}^{(j)}(\\matr{\\Theta}_{L-1})) \\geq \\lambda_{0} / 2\n%     \\end{split}\n%     \\end{displaymath}\n% where $\\lambda_{0}$ is the minimal eigenvalue of the neural tangent kernel (NTK) \\cite{NTK_jacot2018neural} induced by \\name.\n% \\label{assumption_gradient_matrix_eigenvalue}\n% \\end{Assumption}\n% Note that Assumption \\ref{assumption_gradient_matrix_eigenvalue} is mild and has been proved for a various of neural architectures in \\cite{skip_kernel_du2019gradient}. We make this assumption to omit the proof due to page limit.\n% The NTK for \\name~ can be derived following a comparable approach as in \\cite{GNTK_du2019graph}.\n% Then, we apply the following lemma to prove the convergence of \\name.\n\n% % ------------------------------------------------------------\n% \\begin{lemma}\n% After $T$ time steps, assume the model with width $m$ defined in Lemma \\ref{lemma_CB_one_step_same_graph} are trained with the $J$-iterations GD on the contexts $\\{\\widetilde{\\matr{X}}_{\\tau}\\}_{\\tau=1}^{T}$ and rewards $\\{r_{\\tau}\\}_{\\tau=1}^{T}$. With the probability of at least $1 - \\delta$, a constant $\\beta_{F}$ such that $\\beta_{F}\\cdot \\eta < 1$, set the network width $m \\geq \\mbox{Poly}(t, L, \\frac{1}{\\beta_{F}}, \\frac{1}{\\lambda}, (\\zeta \\beta_{L})^{L}, \\log(\\frac{1}{\\delta}))$ and the learning rate $\\eta \\leq \\mathcal{O}(t^{-1}L^{-1}\\beta_{h}^{-2}(2\\zeta \\beta_{L})^{-2L})$. Then, for any $j\\in [J]$, we have\n% \\begin{displaymath}\n% \\begin{split}\n%     \\norm{\\vect{F}^{(j)}_{T}- \\vect{Y}_{T}}_{2}^{2} \\leq (1 - \\beta_{F}\\cdot \\eta)^{j} \\cdot \\norm{\\vect{F}^{(0)}_{T}- \\vect{Y}_{T}}_{2}^{2}\n% \\end{split}\n% \\end{displaymath}\n% where $\\vect{F}^{(j)} = [f(\\mathcal{G}_{T}, \\widetilde{\\matr{X}}_{\\tau};\\matr{\\Theta}^{(j)})]_{\\tau=1}^{T}$, and $\\vect{Y}_{T} = [r_{\\tau}]_{\\tau=1}^{T}$.\n\n% \\label{theorem_after_GD_param_outputs}\n% \\end{lemma}\n\n% --------------------------------------------------------------\n% \\textbf{Proof of Theorem \\ref{theorem_after_GD_param_outputs}.}\n% Following an approach analogous to \\cite{skip_kernel_du2019gradient}, we apply and induction based method for the proof. The hypothesis is that $\\norm{\\vect{F}^{(j)}_{T}- \\vect{Y}_{T}}_{2}^{2} \\leq (1 - \\beta_{F}\\cdot \\eta)^{j} \\cdot \\norm{\\vect{F}^{(0)}_{T}- \\vect{Y}_{T}}_{2}^{2}, \\forall j\\in [J]$. With a similar procedure in Condition A.1 in \\cite{skip_kernel_du2019gradient}, we have\n% \\begin{displaymath}\n% \\begin{split}\n%     & \\norm{\\vect{F}^{(j+1)}_{T}- \\vect{Y}_{T}}_{2}^{2} \\leq \n%     \\norm{\\vect{F}^{(j)}_{T}- \\vect{Y}_{T}}_{2}^{2} - 2\\eta\\norm{\\vect{F}^{(j)}_{T}- \\vect{Y}_{T}}_{\\matr{G}^{(j)}}^{2} \\\\\n%     &\\qquad - 2(\\vect{Y}_{T} - \\vect{F}^{(j)}_{T})^{\\intercal} \\matr{V}^{(j)} + \n%     \\norm{\\vect{F}^{(j+1)}_{T}- \\vect{F}^{(j)}_{T}}_{2}^{2}\n% \\end{split}\n% \\end{displaymath}\n% with $\\matr{V}^{(j)} = (\\matr{V}^{(j)}(\\widetilde{\\matr{X}}_{1}), \\dots, \\matr{V}^{(j)}(\\widetilde{\\matr{X}}_{T}))$ and \n% \\begin{displaymath}\n% \\begin{split}\n%     & \\abs{\\matr{V}^{(j)}(\\widetilde{\\matr{X}})} \\leq \n%     \\eta \\max_{0\\leq s\\leq \\eta} \\bigg[ \\sum_{\\Theta'} \n%     \\norm{\\nabla\\mathcal{L}({\\Theta'}^{(j)})}_{F} \n%     \\norm{\\nabla f({\\Theta'}^{(j)}) - \\nabla f({\\Theta'}^{(j)}, s)}_{F}\n%     \\bigg].\n% \\end{split}\n% \\end{displaymath}\n% where $\\nabla f({\\Theta'}^{(j)}, s) =\n% \\nabla f \\big[{\\Theta'}^{(j)} - s\\cdot \\nabla\\mathcal{L}({\\Theta'}^{(j)}) \\big]$.\n% Then, based on the conclusions from Lemma \\ref{lemma_after_GD_I_2_term}, Lemma \\ref{lemma_after_GD_next_iteration_output} and Assumption \\ref{assumption_gradient_matrix_eigenvalue}, we can have\n% \\begin{displaymath}\n% \\begin{split}\n%     & \\norm{\\vect{F}^{(j+1)}_{T}- \\vect{Y}_{T}}_{2}^{2} \\leq \n%     (1-\\eta\\lambda_{0})\\norm{\\vect{F}^{(j)}_{T} - \\vect{Y}_{T}}_{2}^{2} - 2(\\vect{Y}_{T} - \\vect{F}^{(j)}_{T})^{\\intercal} \\matr{V}^{(j)} \\\\\n%     & \\qquad+ \\norm{\\vect{F}^{(j+1)}_{T}- \\vect{F}^{(j)}_{T}}_{2}^{2}\n%     \\leq (1-\\frac{\\eta\\lambda_{0}}{2})\\norm{\\vect{F}^{(j)}_{T} - \\vect{Y}_{T}}_{2}^{2}.\n% \\end{split}\n% \\end{displaymath}\n% Setting $\\beta_{F} = \\lambda_{0} / 2$ would complete the proof.     $\\blacksquare$\n\n\n\n\n\n% ------------------------------------------------------------\n\\begin{lemma}\nAfter $T$ time steps, assume the model with width $m$ defined in Lemma \\ref{lemma_CB_one_step_same_graph} are trained with the $J$-iterations GD on the past contexts and rewards. Then, there exists a constant $\\beta_{F}$, such that $\\beta_{F}\\cdot \\eta < 1$, for any $j\\in [J]$:\n\\begin{displaymath}\n\\begin{split}\n    \\norm{\\matr{V}^{(j)}}_{2} \\leq \\frac{1}{4}\\eta \\beta_{F} \\cdot \\norm{\\vect{F}^{(j)}_{T} - \\vect{Y}_{T}}_{2}\n\\end{split}\n\\end{displaymath}\nwhere $\\vect{F}^{(j)} = [f(\\mathcal{G}_{T}, \\widetilde{\\matr{X}}_{\\tau};\\matr{\\Theta}^{(j)})]_{\\tau=1}^{T}$, and $\\vect{Y}_{T} = [r_{\\tau}]_{\\tau=1}^{T}$.\n\n\\label{lemma_after_GD_I_2_term}\n\\end{lemma}\n\n\\textbf{Proof.}\nWe prove this lemma following an analogous approach as Lemma B.6 in \\cite{skip_kernel_du2019gradient}.\nGiven $\\widetilde{\\matr{X}}$, we denote \n$\\nabla\\mathcal{L}({\\matr{\\Theta}}^{(j)}) = \\frac{\\partial~\\mathcal{L}(\\matr{\\Theta}^{(j)})}{\\partial~\\matr{\\matr{\\Theta}}}$, and \n$\\nabla f({\\matr{\\Theta}}^{(j)}) = \\frac{\\partial~f(\\mathcal{G}_{T}, \\widetilde{\\matr{X}}; \\matr{\\Theta}^{(j)})}{\\partial~\\matr{\\Theta}}$, where $\\matr{\\Theta}\\in\\{\\matr{\\Theta}_{gnn}, \\matr{\\Theta}_{1}, \\dots, \\matr{\\Theta}_{L}\\}$. \nBy the definition of $\\norm{\\matr{V}^{(j)}}$, we have its element $\\abs{\\matr{V}^{(j)}(\\widetilde{\\matr{X}})}$\n\\begin{displaymath}\n\\begin{split}\n    &  \\leq \\eta \\cdot \\max_{0\\leq s\\leq \\eta} \\bigg[ \\sum_{\\Theta} \n    \\norm{\\nabla\\mathcal{L}({\\Theta}^{(j)})}_{F} \n    \\norm{\\nabla f({\\Theta}^{(j)}) - \\nabla f({\\Theta}^{(j)}, s)}_{F}\n    \\bigg].\n\\end{split}\n\\end{displaymath}\n% $\n%     \\abs{\\matr{V}^{(j)}(\\widetilde{\\matr{X}})} \\leq \n%     & \\eta \\cdot \\max_{0\\leq s\\leq \\eta} \\bigg[ \\sum_{\\Theta'} \n%     \\norm{\\nabla\\mathcal{L}({\\Theta'}^{(j)})}_{F} \n%     \\norm{\\nabla f({\\Theta'}^{(j)}) - \\nabla f({\\Theta'}^{(j)}, s)}_{F}\n%     \\bigg].\n% $\n\n\n%\nWith the notation and conclusion from Lemma \\ref{lemma_after_GD_weight_matrices_bounds}, we have\n\\begin{displaymath}\n\\begin{split}\n    & \\norm{\\nabla\\mathcal{L}({\\Theta}^{(j)})}_{F} \n    % \\leq \\Upsilon^{(j)} /\\sqrt{m} \n    \\leq m^{-\\frac{1}{2}} 2\\sqrt{T} \\norm{\\vect{F}^{(j)}_{T}- \\vect{Y}_{T}}_{2} \\cdot \\zeta^{L} \\cdot(2\\beta_{L})^{L} \\beta_{h}\n\\end{split}\n\\end{displaymath}\n\n%\nMeantime,\n$\n    \\norm{\\nabla f({\\Theta}_{l}^{(j)}) - \\nabla f({\\Theta}_{l}^{(j)}, s)}_{F} = m^{-\\frac{L-l+1}{2}} \\\\ \n    \\norm{ \\vect{h}^{(j)}_{l-1} (\\matr{\\Theta}^{(j)}_{L})^{\\intercal}\n    \\big(\\prod_{q=l+1}^{L-1} \\matr{\\Gamma}^{(j)}_{q}  (\\matr{\\Theta}^{(j)}_{q})^{\\intercal} \\big) \n    \\cdot \\matr{\\Gamma}^{(j)}_{l} \n    - \n    \\vect{h}^{(j), s}_{l-1} (\\matr{\\Theta}^{(j), s}_{L})^{\\intercal}  \\\\\n    \\big(\\prod_{q=l+1}^{L-1} \\matr{\\Gamma}^{(j), s}_{q}  \\cdot (\\matr{\\Theta}^{(j), s}_{q})^{\\intercal} \\big)\n    \\cdot \\matr{\\Gamma}^{(j), s}_{l} }_{F}.\n$\nA similar form can also be derived for $\\matr{\\Theta}_{gnn}$.\n\n% \\begin{displaymath}\n% \\begin{split}\n%     & \\norm{\\nabla f({\\Theta}_{l}^{(j)}) - \\nabla f({\\Theta'}_{l}^{(j)}, s)}_{F} = m^{-\\frac{L-l+1}{2}}  \n%     \\norm{\\big(\\vect{h}^{(j)}_{l-1}\\matr{\\Theta}^{(j)}_{L}\\big)  \n%     \\big(\\prod_{q=l+1}^{L-1} \\matr{\\Gamma}^{(j)}_{q}  \\matr{\\Theta}^{(j)}_{q}\\big) \\\\\n%     & \n%     \\cdot \\matr{\\Gamma}^{(j)}_{l} \n%     - \n%     \\big(\\vect{h}^{(j), s}_{l-1}\\matr{\\Theta}^{(j), s}_{L}\\big)  \n%     \\big(\\prod_{q=l+1}^{L-1} \\matr{\\Gamma}^{(j), s}_{q}  \\cdot \\matr{\\Theta}^{(j), s}_{q}\\big)\n%     \\cdot \\matr{\\Gamma}^{(j), s}_{l} }_{F}.\n% \\end{split}\n% \\end{displaymath}\n% Similarly, we also have \n% \\begin{displaymath}\n% \\begin{split}\n%     & \\norm{\\nabla f({\\Theta}_{gnn}^{(j)}) - \\nabla f({\\Theta'}_{gnn}^{(j)}, s)}_{F}  \n%     % m^{-\\frac{L+1}{2}}\n%     % \\norm{\n%     % \\bigg(\\vect{h}_{\\matr{A}}\\cdot\\matr{\\Theta}_{1}^{\\intercal}\\matr{\\Theta}_{L} \\cdot\n%     % \\big(\\prod_{q=2}^{L-1} \\matr{\\Gamma}_{q} \\cdot \\matr{\\Theta}_{q}\\big)\\\\ \n%     % &\\quad \\cdot \\matr{\\Gamma}_{1} \n%     % \\bigg) \\cdot \\matr{Q} \\cdot \\matr{\\Gamma}_{gnn} -\n%     % \\bigg(\\vect{h}_{\\matr{A}}\\cdot\\matr{\\Theta}_{1}^{\\intercal}\\matr{\\Theta}_{L} \\cdot\n%     % \\big(\\prod_{q=2}^{L-1} \\matr{\\Gamma}_{q} \\cdot \\matr{\\Theta}_{q}\\big) \\cdot \\matr{\\Gamma}_{1} \n%     % \\bigg) \\cdot \\matr{Q} \\cdot \\matr{\\Gamma}_{gnn} \n%     % }_{F} \\\\\n%     \\leq \n%     m^{-\\frac{L+1}{2}} \\\\\n%     &\\norm{\n%     \\bigg(\\matr{\\Theta}_{1}^{\\intercal}\\matr{\\Theta}_{L} \n%     \\big(\\prod_{q=2}^{L-1} \\matr{\\Gamma}_{q}  \\matr{\\Theta}_{q}\\big)  \\matr{\\Gamma}_{1} \n%     \\bigg)  \\matr{\\Gamma}_{gnn} \n%     - \\bigg(\\matr{\\Theta}_{1}^{\\intercal}\\matr{\\Theta}_{L} \n%     \\big(\\prod_{q=2}^{L-1} \\matr{\\Gamma}_{q}  \\matr{\\Theta}_{q}\\big)  \\matr{\\Gamma}_{1} \n%     \\bigg)  \\matr{\\Gamma}_{gnn} \n%     }_{F}\n% \\end{split}\n% \\end{displaymath}\n\nWith $\\Upsilon / \\sqrt{m} \\leq 1$ and $\\Lambda^{(j)}\\leq \\beta_{h}$ and a similar procedure as in Lemma \\ref{lemma_after_GD_model_results_variables} and Lemma \\ref{lemma_after_GD_weight_matrices_bounds}, we have\n\\begin{displaymath}\n\\begin{split}\n    &\\norm{\\matr{\\Theta}^{(j+1)} - \\matr{\\Theta}^{(j)}}_{F} \\leq \\eta \\frac{\\Upsilon^{(j)}}{\\sqrt{m}},\n    \\quad \\norm{\\matr{\\Theta}^{(j)}}_{F} \\leq 2\\beta_{L}\\sqrt{m}  \\\\\n    & \\norm{\\vect{h}^{(j+1)} - \\vect{h}^{(j)}}_{2} \\leq \\eta\\frac{2\\zeta \\beta_{h}}{\\sqrt{m}}(2\\zeta \\beta_{L})^{L}\\Upsilon^{(j)},\n    \\quad \\norm{\\vect{h}^{(j)}}_{2} \\leq 2 \\beta_{h}, \\\\\n    & \\norm{\\matr{\\Gamma}^{(j+1)} - \\matr{\\Gamma}^{(j)}}_{F} \\leq 2\\eta\\zeta^{2} \\beta_{h}(2\\zeta \\beta_{L})^{L}\\Upsilon^{(j)}, \\quad \\norm{\\matr{\\Gamma}^{(j)}}_{2} \\leq \\zeta \n\\end{split}\n\\end{displaymath}\nWith Lemma G.1 from \\cite{skip_kernel_du2019gradient}, for $\\matr{\\Theta}\\in \\{\\matr{\\Theta}_{gnn}, \\matr{\\Theta}_{1}, \\dots, \\matr{\\Theta}_{L}\\}$,  \n\\begin{displaymath}\n\\begin{split}\n    \\norm{\\nabla f({\\matr{\\Theta}}^{(j)}) - \\nabla f({\\matr{\\Theta}}^{(j)}, s)}_{F} \\leq \n    \\frac{4\\zeta}{\\sqrt{m}} \\eta\\Upsilon^{(j)}\\beta_{h}L\n    (2\\zeta \\beta_{L})^{2L}.\n\\end{split}\n\\end{displaymath}\nCombining with $\\norm{\\nabla\\mathcal{L}({\\Theta'}^{(j)})}_{F}$, we have\n\\begin{displaymath}\n\\begin{split}\n    \\abs{\\matr{V}^{(j)}(\\widetilde{\\matr{X}})} \\leq \\eta^{2}\\frac{4T}{m} (L+2)^{2} \\beta_{h}^{3} \\cdot\\norm{\\vect{F}^{(j)}_{T} - \\vect{Y}_{T}}_{2}^{2} (2\\zeta \\beta_{L})^{4L}.\n\\end{split}\n\\end{displaymath}\nSince this inequality holds for an arbitrary $\\widetilde{\\matr{X}}\\in \\{\\widetilde{\\matr{X}}_{\\tau}\\}_{\\tau\\in [T]}$ and $\\norm{\\vect{F}^{(0)}_{T} - \\vect{Y}_{T}}_{2}=\\mathcal{O}(\\sqrt{T})$, given network width $m$, we finally have \n\\begin{displaymath}\n\\begin{split}\n    \\norm{\\matr{V}^{(j)}} \\leq \\frac{1}{4}\\eta \\beta_{F} \\norm{\\vect{F}^{(j)}_{T} - \\vect{Y}_{T}}_{2}^{2}.\n\\end{split}\n\\end{displaymath}\nwith the choice of learning rate $\\eta \\leq \\mathcal{O}(T^{-1}L^{-1}\\beta_{h}^{-2}(2\\zeta \\beta_{L})^{-2L})$.\n$\\blacksquare$\n\n% ------------------------------------------------------------\n\n\\textbf{Proof of Lemma \\ref{lemma_after_GD_next_iteration_output}.}\nWe prove this lemma following an analogous approach as Lemma B.7 in \\cite{skip_kernel_du2019gradient}.\nBy the model definition and substituting $\\Upsilon^{(j)} /\\sqrt{m}$ with $m^{-\\frac{1}{2}} 2\\sqrt{T} \\norm{\\vect{F}^{(j)}_{T}- \\vect{Y}_{T}}_{2} \\cdot \\zeta^{L} (2\\beta_{L})^{L} \\beta_{h}$ as the upper bound based on Lemma \\ref{lemma_after_GD_weight_matrices_bounds}, with $\\Lambda^{(j)} \\leq \\beta_{h}$, we have\n% By the model definition and $\\Upsilon^{(j)} /\\sqrt{m} \\leq 1$ based on Lemma \\ref{lemma_after_GD_weight_matrices_bounds}, with $\\Lambda^{(j)} \\leq \\beta_{h}$, we have\n\\begin{displaymath}\n\\begin{split}\n    & \\norm{\\vect{F}^{(j)}_{T} - \\vect{F}^{(j+1)}_{T}}_{2}^{2} = \n    \\frac{1}{m}\\sum_{\\tau=1}^{T} \\big( (\\vect{h}_{L-1, \\tau}^{(j+1)})^{\\intercal}\\matr{\\Theta}_{L}^{(j+1)} -\n    (\\vect{h}_{L-1, \\tau}^{(j)})^{\\intercal}\\matr{\\Theta}_{L}^{(j)}\\big)^{2} \\\\\n    & \\leq \\frac{2}{m}\\bigg(\\norm{\\matr{\\Theta}_{L}^{(j+1)} - \\matr{\\Theta}_{L}^{(j)}}_{2}^{2} \n    \\sum_{\\tau=1}^{T} \\norm{\\vect{h}_{L-1, \\tau}^{(j+1)}}_{2}^{2} + \n    \\norm{\\matr{\\Theta}_{L}^{(j)}}_{2}^{2} \\sum_{\\tau=1}^{T} \\norm{\\vect{h}_{L-1, \\tau}^{(j+1)} - \\vect{h}_{L-1, \\tau}^{(j)}}_{2}^{2}\\bigg) \\\\\n    & \\leq \\frac{2}{m}\\bigg(\n    \\frac{T}{m}\\eta^{2} (2\\beta_{h})^{4} \\norm{\\vect{F}^{(j)}_{T} - \\vect{Y}_{T}}_{2}^{2}\n    + T(2\\beta_{3})^{2} (\\eta\\frac{2\\zeta \\beta_{h}}{\\sqrt{m}}(2\\zeta \\beta_{L})^{L}\\Upsilon^{(j)})^{2} \n    \\bigg) \\\\\n    & \\leq \\frac{1}{4}\\eta \\beta_{F} \\norm{\\vect{F}^{(j)}_{T} - \\vect{Y}_{T}}_{2}^{2}\n\\end{split}\n\\end{displaymath}\nwhere the last inequality is due to sufficiently large $m$ and the choice of learning rate $\\eta$.  $\\blacksquare$\n\n\n\n\n\n\n\n\n\n\n\n\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% NEURAL KERNEL (DELETE IN THE CONFERENCE VERSION)\n% ----------------------------------------------------------------------------------------------------------------------------------------------------\n% \\newpage\n\n% \\section{Modeling with Neural Kernels}\n% As basically any neural network can be modeled into a neural tangent kernel (NTK) \\cite{NTK_jacot2018neural} when certain conditions are satisfied \\cite{NTK_any_arch_yang2020tensor}, the goal in this section is to model our proposed model into a neural kernel for analyzing the confidence bound and the regret. Given two graphs $G = (V, E)$ and $G = (V', E')$, the graph neural tangent kernel (GNTK) \\cite{GNTK_du2019graph} formulate the GNN model into a graph kernel denoted as $k_{GNTK}(G, G') \\in \\mathbb{R}$. Different from the GNTK whose target is dealing with graph classification tasks, our proposed model focuses on the node-level attributes to predict the rewards for given contexts. \n\n% Recall the definition of our arm group graph $\\mathcal{G}_{t} = (V, E, W_{t})$ which consists of $\\abs{\\mathcal{C}} = \\abs{V} = N_{c}$ nodes. At each time step $t$, we may model all the past contexts $X_{\\tau} = \\{\\vect{x}_{c, \\tau}\\}_{c=1}^{N_{c}}, \\forall \\tau \\in \\{1, \\dots, t\\}$ into context graphs $G_{\\tau, t} = (V, E, X_{\\tau})$ where the nodes and edges are identical to the current arm group graph $\\mathcal{G}_{t}$, and the node attributes $X_{\\tau}$ are the contexts related to corresponding arms for this past time step $\\tau$. As we focus on the node-level attributes $X_{\\tau}$, we first define the initial co-variance matrix for the contexts. Here, given two context graphs $G = (V, E, X), G' = (V', E, X')$ at time step $t$, their node attributes (contexts) will be $x_{v} \\in X$ and $x_{v'} \\in X'$ separately $\\forall v \\in V, \\forall v' \\in V'$. Again, according to the our definition of context graphs, $V$ and $V'$ represent same set of nodes (i.e., the arms) with different attributes.\n% Then, we define the initial co-variance matrix and kernel values as $[\\matr{K}_{0}(G, G')]_{vv'}=[\\matr{\\Sigma}_{0}(G, G')]_{vv'} = x_{v}^{\\intercal}x_{v'}$ where $\\matr{K}_{0}(G, G'), \\matr{\\Sigma}_{0}(G, G') \\in \\mathbb{R}^{N_{c} \\times N_{c}}$.\n\n% \\textbf{Aggregation over the Neighborhood.}\n% Corresponding to our aggregation module, we want to first aggregate the context over the $k$-th arm group neighborhood. Here, we let $d' = m$ where $m$ is also the hidden size for the reward estimation module. Inspired by GNTK \\cite{GNTK_du2019graph}, we model this process by calculating the co-variance matrices $\\matr{\\Sigma}_{j}(G, G') \\in \\mathbb{R}^{N_{c} \\times N_{c}}$ and intermediate kernel values $\\matr{K}_{j}(G, G') \\in \\mathbb{R}^{N_{c} \\times N_{c}}$, $\\forall j \\in \\{1, \\dots, k\\}$, recursively. Then, with $\\widetilde{\\mathcal{N}}(v)$ as the first-order neighborhood of node $v$ including itself and for a single aggregation step, we have\n% \\begin{displaymath}\n% \\begin{split}\n%     [\\matr{\\Sigma}_{j}(G, G')]_{vv'} = c_{v}c_{v'} \\sum_{u \\in \\widetilde{\\mathcal{N}}(v), u' \\in \\widetilde{\\mathcal{N}}(v')} [\\matr{\\Sigma}_{(j-1)}(G, G')]_{uu'}\n% \\end{split}\n% \\end{displaymath}\n% \\begin{displaymath}\n% \\begin{split}\n%     [\\matr{K}_{j}(G, G')]_{vv'} = c_{v}c_{v'} \\sum_{u \\in \\widetilde{\\mathcal{N}}(v), u' \\in \\widetilde{\\mathcal{N}}(v')} [\\matr{K}_{(j-1)}(G, G')]_{uu'}\n% \\end{split}\n% \\end{displaymath}\n% where $c_{v}=\\frac{1}{\\abs{\\widetilde{\\mathcal{N}}(v)}}$ is the scaling coefficient. Then, as for the transformation with the non-linear activation, we have\n% \\begin{displaymath}\n% \\begin{split}\n%     [\\matr{\\Sigma}_{trans}(G, G')]_{vv'} = 2\\cdot \\mathbb{E}_{(a,b)\\sim N(\\matr{0}, [\\matr{A}_{trans}(G, G')]_{vv'})} [\\sigma(a)\\sigma(b)]\n% \\end{split}\n% \\end{displaymath}\n% \\begin{displaymath}\n% \\begin{split}\n%     [\\matr{\\Sigma}'_{trans}(G, G')]_{vv'} = 2\\cdot \\mathbb{E}_{(a,b)\\sim N(\\matr{0}, [\\matr{A}_{trans}(G, G')]_{vv'})} [\\sigma'(a)\\sigma'(b)]\n% \\end{split}\n% \\end{displaymath}\n% where\n% \\begin{displaymath}\n% \\begin{split}\n%     [\\matr{A}_{trans}(G, G')]_{vv'} = \n%     \\left(\n%         \\begin{array}{c|c} \n%           [\\matr{\\Sigma}_{k}(G, G')]_{vv} & [\\matr{\\Sigma}_{k}(G, G')]_{vv'} \\\\ \n%           \\hline \n%           [\\matr{\\Sigma}_{k}(G, G')]_{vv'} & [\\matr{\\Sigma}_{k}(G, G')]_{v'v'}\n%         \\end{array} \n%     \\right) \\in \\mathbb{R}^{2 \\times 2}\n% \\end{split}\n% \\end{displaymath}\n% and $\\sigma'(\\cdot)$ represents the derivative of the function $\\sigma(\\cdot)$. Then, kernel values after the aggregation step are\n% \\begin{displaymath}\n% \\begin{split}\n%     [\\matr{K}_{trans}&(G, G')]_{vv'} \\\\\n%     &= [\\matr{K}_{k}(G, G')]_{vv'}[\\matr{\\Sigma}'_{trans}(G, G')]_{vv'}+[\\matr{\\Sigma}_{trans}(G, G')]_{vv'}.\n% \\end{split}\n% \\end{displaymath}\n\n% \\textbf{Skip-connection.}\n% For the sake of analysis, we adopt a slight modification and re-formulate \\textbf{Eq.} \\ref{SGC_eq} to\n% \\begin{displaymath}\n% \\begin{split}\n%     f_{gnn}(\\widetilde{\\matr{X}}, \\mathcal{G}; \\matr{\\Theta}_{gnn}) = [\\matr{\\Theta}_{gnn} \\cdot \\sigma(\\matr{S}_{t}^{k}\\widetilde{\\matr{X}}\\cdot\\matr{\\Theta}_{gnn}); \\mathcal{F}(\\widetilde{\\matr{X}})]\n% \\end{split}\n% \\end{displaymath}\n% with $\\matr{\\Theta}_{gnn} \\in \\mathbb{R}^{m \\times m}$ as the added transformation matrix.\n% Then, we choose the skip-connection mapping function $\\mathcal{F}$ to be a simple linear transformation as $\\mathcal{F}(\\widetilde{\\matr{X}})=\\sqrt{\\frac{1}{m}}\\cdot\\matr{\\Theta}_{\\widetilde{\\matr{x}}}\\widetilde{\\matr{X}}$ where $\\matr{\\Theta}_{\\widetilde{\\matr{x}}} \\in \\mathbb{R}^{d_{\\widetilde{x}} \\times m}$ is the transformation matrix for initial features. Since $\\matr{\\Theta}_{\\widetilde{\\matr{x}}}$ is only used for matching dimensionality, we consider it to be static after random initialization following a similar strategy from \\cite{resnet_analysis_huang2020deep}. Initialize them as $\\matr{\\Theta}_{\\widetilde{\\matr{x}}}, \\matr{\\Theta}_{gnn} \\sim N(\\matr{0}, \\matr{I})$. Combining with the aggregation part above, the co-variance matrix and final kernel values for the aggregation module are\n% \\begin{displaymath}\n% \\begin{split}\n%     [\\matr{\\Sigma}_{gnn}(G, G')]_{vv'} = [\\matr{\\Sigma}_{trans}&(G, G')]_{vv'} + [\\matr{\\Sigma}_{0}(G, G')]_{vv'}\n% \\end{split}\n% \\end{displaymath}\n\n\n\n% \\begin{displaymath}\n% \\begin{split}\n%     [\\matr{\\Sigma}_{gnn}(G, G')]_{vv'} = [\\matr{\\Sigma}_{trans}&(G, G')]_{vv'} + [\\matr{\\Sigma}_{0}(G, G')]_{vv'}\n% \\end{split}\n% \\end{displaymath}\n% \\begin{displaymath}\n% \\begin{split}\n%     [\\matr{K}_{gnn}(G, G')]_{vv'} = [\\matr{K}_{trans}&(G, G')]_{vv'} + [\\matr{K}_{0}(G, G')]_{vv'}\n% \\end{split}\n% \\end{displaymath}\n\n% \\textbf{Reward Estimation with the FC Network.}\n% As for the reward estimation module with the FC network, we follow a process inspired by Neural-UCB \\cite{Neural-UCB} and NTK \\cite{NTK_jacot2018neural} after inheriting results from the previous module. Here, we define the initial co-variance matrix and the kernel values separately as $\\matr{K}_{0}^{est}(G, G')=\\matr{K}_{gnn}(G, G') \\in \\mathbb{R}^{N_{c} \\times N_{c}}$ and $\\matr{\\Sigma}_{0}^{est}(G, G')=\\matr{\\Sigma}_{gnn}(G, G') \\in \\mathbb{R}^{N_{c} \\times N_{c}}$. For the $l$-th FC layer of our FC network, $\\forall l \\in [L]$, we have\n% \\begin{displaymath}\n% \\begin{split}\n%     [\\matr{\\Sigma}_{l}^{est}(G, G')]_{vv'} = 2\\cdot \\mathbb{E}_{(a,b)\\sim N(\\matr{0}, [\\matr{A}_{l-1}^{est}(G, G')]_{vv'})} [\\sigma(a)\\sigma(b)]\n% \\end{split}\n% \\end{displaymath}\n% \\begin{displaymath}\n% \\begin{split}\n%     [(\\matr{\\Sigma}_{l}^{est})'(G, G')]_{vv'} = 2\\cdot \\mathbb{E}_{(a,b)\\sim N(\\matr{0}, [\\matr{A}_{l-1}^{est}(G, G')]_{vv'})} [\\sigma'(a)\\sigma'(b)]\n% \\end{split}\n% \\end{displaymath}\n% where\n% \\begin{displaymath}\n% \\begin{split}\n%     [\\matr{A}_{l}^{est}(G, G')]_{vv'} = \n%     \\left(\n%         \\begin{array}{c|c} \n%           [\\matr{\\Sigma}_{l}^{est}(G, G')]_{vv} & [\\matr{\\Sigma}_{l}^{est}(G, G')]_{vv'} \\\\ \n%           \\hline \n%           [\\matr{\\Sigma}_{l}^{est}(G, G')]_{vv'} & [\\matr{\\Sigma}_{l}^{est}(G, G')]_{v'v'}\n%         \\end{array} \n%     \\right),\n% \\end{split}\n% \\end{displaymath}\n% and the intermediate kernel value can be represented as \n% \\begin{displaymath}\n% \\begin{split}\n%     [\\matr{K}_{l}^{est}&(G, G')]_{vv'} = \\\\\n%     &[\\matr{K}_{l-1}^{est}(G, G')]_{vv'}[(\\matr{\\Sigma}_{l}^{est})'(G, G')]_{vv'}+[\\matr{\\Sigma}_{l}^{est}(G, G')]_{vv'}.\n% \\end{split}\n% \\end{displaymath}\n% Finally, the final kernel matrix is denoted as $\\matr{K}(G, G') = \\bigg(\\matr{\\Sigma}_{L}^{est}(G, G') + \\matr{K}_{L}^{est}(G, G')\\bigg) / 2$. Here, $\\matr{K}(G, G') \\in \\mathbb{R}^{N_{c} \\times N_{c}}$ only contains the kernel values for contexts from context graphs $G$ and $G'$; and the full kernel matrix $\\matr{K}_{t} \\in \\mathbb{R}^{(t\\cdot N_{c}) \\times (t\\cdot N_{c})}$ for all past contexts $\\{x_{a, \\tau}| \\forall a \\in \\mathcal{C}, \\forall \\tau \\in [t]\\}$, can be derived by calculating the kernel value of all past context graphs $\\matr{K}(G_{i}, G_{j}), \\forall G_{i}, G_{j} \\in \\{G_{\\tau, t}\\}_{\\tau=1}^{t}$.\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% NEURAL KERNEL (DELETE IN THE CONFERENCE VERSION)\n\n\n\n"
            }
        },
        "figures": {
            "figure_recommendation_result": "\\begin{figure}[t]\n  \\centering\n  \\includegraphics[width=\\linewidth]{Fig/rec_figure.pdf}\n  \\vspace{-0.7cm}\n  \\caption{Cumulative regrets for recommendation data sets.}\n  \\label{figure_recommendation_result}\n  \\vspace{-0.1cm}\n\\end{figure}",
            "figure_classification_result": "\\begin{figure}[t]\n  \\centering\n  \\includegraphics[width=\\linewidth]{Fig/cla_figure.pdf}\n  \\vspace{-0.7cm}\n  \\caption{Cumulative regrets for classification data sets.}\n  \\label{figure_classification_result}\n  \\vspace{-0.2cm}\n\\end{figure}",
            "figure_parameter_study": "\\begin{figure}[t]\n  \\centering\n  \\includegraphics[width=\\linewidth]{Fig/parameter_study_figure.pdf}\n  \\vspace{-0.7cm}\n  \\caption{Cumulative regrets on MovieLens and MNIST-Aug data sets with different neighborhood parameter $k$.}\n  \\label{figure_parameter_study}\n  \\vspace{-0.2cm}\n\\end{figure}"
        },
        "equations": {
            "eq:1": "\\begin{equation}\n\\{ \\mathcal{X}_{c, t} | c \\in  \\mathcal{C}_{t}\\}  \\ \\text{and} \\  \\mathcal{X}_{c, t} = \\{\\vect{x}^{(1)}_{c, t}, \\cdots \\vect{x}^{(n_{c, t})}_{c, t}\\}, \\forall c \\in  \\mathcal{C}_{t}.\n\\end{equation}",
            "eq:2": "\\begin{equation}\n\\begin{split}\n    r_{c, t}^{(i)} = h(\\matr{W}^{*}, ~~ \\vect{x}^{(i)}_{c, t}) + \\epsilon^{(i)}_{c, t}\n\\end{split}\n\\label{reward_func_defi}\n\\end{equation}",
            "eq:3": "\\begin{equation}\n\\begin{split}\n    w_{t}(c, c') = \\exp(-\\norm{\\Psi_{t}(\\mathcal{D}_{c}) - \\Psi_{t}(\\mathcal{D}_{c'})}^{2} / \\sigma_{s})\n\\end{split}\n\\label{arm_similarity_eq}\n\\end{equation}",
            "eq:4": "\\begin{equation}\n\\begin{split}\n    w_{t}(c, c') = exp(-\\norm{\\Psi_{t}(\\mathcal{D}_{c}) - \\Psi_{t}(\\mathcal{D}_{c'})}^{2} / \\sigma_{s})\n\\end{split}\n\\label{arm_similarity_eq}\n\\end{equation}",
            "eq:5": "\\begin{equation}\n\\widetilde{\\vect{X}}^{(i)}_{c, t} = \n\\left(\\begin{array}{cccc}\n(\\vect{x}^{(i)}_{c, t})^{\\intercal} & \\matr{0} & \\cdots & \\matr{0}\\\\\n\\matr{0} & (\\vect{x}^{(i)}_{c, t})^{\\intercal} & \\cdots & \\matr{0}\\\\\n\\vdots  &       & \\ddots   & \\vdots \\\\\n\\matr{0} & \\matr{0} & \\cdots & (\\vect{x}^{(i)}_{c, t})^{\\intercal}\\\\\n\\end{array}\\right) \\in \\mathbb{R}^{N_{c}\\times d_{\\widetilde{x}}}\n\\label{new_embed_eq}\n\\end{equation}",
            "eq:6": "\\begin{equation}\n\\begin{split}\n    \\matr{H}_{gnn} = \\sqrt{\\frac{1}{m}}\\cdot\\sigma(\\matr{S}_{t}^{k}\\cdot \\widetilde{\\vect{X}}^{(i)}_{c, t} \\matr{\\Theta}_{gnn}) \\in \\mathbb{R}^{N_{c} \\times m}\n\\end{split}\n\\label{aggr_Eq}\n\\end{equation}",
            "eq:7": "\\begin{equation}\n\\begin{split}\n    \\matr{H}_{0} = f_{gnn}(\\mathcal{G}_{t}, \\widetilde{\\vect{X}}^{(i)}_{c, t}; \\matr{\\Theta}_{gnn}) = [\\sigma(\\matr{S}_{t}^{k}\\cdot\\widetilde{\\vect{X}}^{(i)}_{c, t} \\matr{\\Theta}_{gnn}); \\widetilde{\\vect{X}}^{(i)}_{c, t}]\n\\end{split}\n\\label{SGC_eq}\n\\end{equation}",
            "eq:8": "\\begin{equation}\n\\begin{split}\n    &\\matr{H}_{l} = \\sqrt{\\frac{1}{m}}\\cdot\\sigma( \\matr{H}_{l-1} \\cdot \\matr{\\Theta}_{l}  ),~~~~~ l \\in \\{1,\\dots, L-1\\}, \\\\\n    &\\widehat{\\vect{r}}_{all} = f_{fc}(\\matr{H}_{0}; \\matr{\\Theta}_{fc}) = \\sqrt{\\frac{1}{m}}\\cdot \\matr{H}_{L-1} \\cdot \\matr{\\Theta}_{L}\n\\end{split}\n\\label{FC_model}\n\\end{equation}",
            "eq:9": "\\begin{equation}\n\\begin{split}\n    & \\textsf{CB}_{t}(\\widetilde{\\matr{X}}) = \\abs{ f(\\mathcal{G}_{t}, \\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1}) - h(\\mathcal{G}^{*}, \\widetilde{\\matr{X}}) } \\\\\n    % & \\leq \\abs{f(\\mathcal{G}_{t}, \\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1}) - h(\\mathcal{G}^{*}, \\widetilde{\\matr{X}})}\n    % + \\underbrace{\\abs{h(\\mathcal{G}^{*}, \\widetilde{\\matr{X}}) - h(\\mathcal{G}^{*}, \\widetilde{\\matr{X}})}}_{R_{h}} \\\\\n    &\\leq \\underbrace{\\abs{ f(\\mathcal{G}_{t}, \\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1}) - h(\\mathcal{G}_{t}, \\widetilde{\\matr{X}}) }}_{R_{1}} + \\underbrace{\\abs{ h(\\mathcal{G}_{t}, \\widetilde{\\matr{X}}) - h(\\mathcal{G}^{*}, \\widetilde{\\matr{X}}) }}_{R_{2}}\n\\end{split}\n\\label{eq_regret_split}\n\\end{equation}",
            "eq:10": "\\begin{equation}\n\\begin{split}\n    \\textsf{CB}_{t}(\\widetilde{\\matr{X}}) \\leq  B_{1} \\norm{g(\\mathcal{G}_{t}, \\widetilde{\\matr{X}}; \\matr{\\Theta}_{t-1}) / \\sqrt{m}}_{\\matr{Z}_{t-1}^{-1}} + B_{2} + B_{3} + B_{4} \\sqrt{\\frac{1}{t}}.\n\\end{split}\n\\label{eq_CB_one_step}\n\\end{equation}"
        }
    }
}