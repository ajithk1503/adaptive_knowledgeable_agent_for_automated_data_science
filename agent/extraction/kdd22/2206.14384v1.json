{
    "meta_info": {
        "title": "Framing Algorithmic Recourse for Anomaly Detection",
        "abstract": "The problem of algorithmic recourse has been explored for supervised machine\nlearning models, to provide more interpretable, transparent and robust outcomes\nfrom decision support systems. An unexplored area is that of algorithmic\nrecourse for anomaly detection, specifically for tabular data with only\ndiscrete feature values. Here the problem is to present a set of\ncounterfactuals that are deemed normal by the underlying anomaly detection\nmodel so that applications can utilize this information for explanation\npurposes or to recommend countermeasures. We present an approach -- Context\npreserving Algorithmic Recourse for Anomalies in Tabular data (CARAT), that is\neffective, scalable, and agnostic to the underlying anomaly detection model.\nCARAT uses a transformer based encoder-decoder model to explain an anomaly by\nfinding features with low likelihood. Subsequently semantically coherent\ncounterfactuals are generated by modifying the highlighted features, using the\noverall context of features in the anomalous instance(s). Extensive experiments\nhelp demonstrate the efficacy of CARAT.",
        "author": "Debanjan Datta, Feng Chen, Naren Ramakrishnan",
        "link": "http://arxiv.org/abs/2206.14384v1",
        "category": [
            "cs.LG",
            "cs.AI",
            "stat.ME"
        ],
        "additionl_info": "ACM SigKDD 2022, Research Track"
    },
    "latex_extraction": {
        "content": {
            "section 1": {
                "name": "Introduction",
                "content": "\nAlgorithmic recourse can be defined as a a set of actions or changes that can change the outcome for a data instance with respect to a machine learning model, typically from an unfavorable outcome to a favorable one~\\cite{joshi2019towards}.\nThis is an important and challenging task with practical applicability in domains such as healthcare, hiring, insurance, and commerce that incorporate machine learning models into decision support systems~\\cite{prosperi2020causal,karimi2020survey}.\nAlgorithmic recourse is closely related to explainability, specifically counterfactual explanations that are important to improve fairness, transparency, and trust in output of machine learning (ML) models. \nIndeed the most cited and intuitive explanation of algorithmic recourse presents an example how to change input features of bank loan application decided by a black-box ML algorithm to obtain a favorable outcome~\\cite{karimi2021algorithmic}.\n\nAlthough the primary focus of algorithmic recourse has been in supervised learning contexts~\\cite{mothilal2020explaining}, specifically classification based scenarios, it is also applicable in other scenarios. \nIn this work, we address the research of how to frame algorithmic recourse for outcomes of unsupervised anomaly detection.\nSpecifically, we seek to obtain a set of actions to modify the feature values of a data instance deemed anomalous by a black-box anomaly detection model such that it is no longer anomalous.\nA motivating example would be the case of a shipment transaction that is flagged as suspicious or illegal by a monitoring system employing anomaly detection, and our exploring what needs to be modified in this transaction to no longer merit that outcome.\n% The interpretability of anomalies is highly dependant on application scenario, and false positives are produced by anomaly detection system. \n% For instance fraud detection systems may flag a transaction anomalous, but on further investigation byexperts may reveal the transaction to be not illegal.\n%The interpretability of anomalies is highly dependant on application scenario and on further investigation of a flagged transaction by experts may reveal it to be not illegal but unusual.\nAn entity such as a trading company might seek to address its future shipment patterns, by adjusting routes, products or suppliers to avoid getting flagged as potentially fraudulent -- thus motivating the problem of algorithmic recourse for anomaly detection.\n% Algorithmic recourse is the tool required in such a scenario, and can suggest a set of feasible actions that can change the outcome of similar future transactions by the trading entity with respect to the machine learning model. \n\nAlgorithmic recourse for anomaly detection has some factors that differentiates it from the classification based scenario due to the underlying ML model w.r.t. which one tries to achieve a different but favorable outcome.\n% is similar to that of classification scenarios, there are some distinct differences.\nWhile classification models are supervised, anomaly detection models are mostly unsupervised, and archetypes of anomalies are difficult to determine and are application scenario dependant. \n% The underlying model with respect to which the desired outcome is computed is different. Most classification models are supervised models. However, anomaly detection models are primarily unsupervised, the definition and archetypes of anomalies are seldom known, and are application scenario dependant. \n% Tabular data is one of the most ubiquitous formats of data. \nPrior works consider tabular data for algorithmic recourse in the context of classification~\\cite{karimi2020survey,rawal2020beyond}, and use comparatively simpler datasets where features are mostly real-valued. \nWe explore the scenario where features are strictly categorical with high dimensionality (cardinality), such as found in real world data from commerce, communication and shipping~\\cite{cao2018collective,datta2020detecting}.\nConcepts such as \\textit{proximity} in the context of counterfactuals are simpler to define for real-valued data.\nMoreover, metrics used in classification specific algorithmic recourse do not directly translate to the scenario of anomaly detection.\n% We propose a novel approach to address this problem setting and a new set of metrics that are applicable in such a scenario.\nOur key contributions in this work are:\n\\begin{enumerate}[label=(\\textbf{\\roman*})]\n\\item A novel formulation for the unexplored problem of algorithmic recourse for unsupervised anomaly detection.\n\\item A novel approach \\textit{CARAT} to generate counterfactuals for anomalies in tabular data with categorical features. \n\\textit{CARAT} is demonstrated to be effective, scalable and agnostic to the underlying anomaly detection model.\n\\item A new set of metrics that can effectively quantify the quality of the generated counterfactuals w.r.t. multiple objectives.\n\\item Empirical results on multiple real world shipment datasets along with a case study highlighting the practical utility of our approach.\n\\end{enumerate}\n% We can summarize the challenges as follows:  \n% \\begin{enumerate*}[label=(\\roman*)]\n% \\item Metrics used in classification specific recourse do not directly translate to the scenario of anomaly detection. \n% \\item The combined dimensionality of the feature space can be very large.\n% \\item Distance measures applicable for real-valued do not translate well to discrete data.\n% \\end{enumerate*}\n% Firstly the combined size of the feature space can be very large, if there are large number of categories and associated feature values. \n% Secondly, some of the concepts which are easily defined for real-valued data such as distance and are crucial to the definition of counterfactuals are significantly more difficult to meaningfully define for discrete data.\n% Thirdly, the metrics that have been used in classification specific recourse do not directly translate to the scenario of anomaly detection.\n% Moreover, detection and interpretation of anomalies in tabular data with only categorical variables is difficult.\n\n% In this work, we present an approach towards algorithmic recourse for anomalies detected in tabular data with  \n\n% TODO : motivating example \\section{Preliminaries}\\label{sec:preliminaries}\nTabular data with strictly categorical attributes can be formally represented in terms of \\textit{domains} and \\textit{entities}~\\cite{datta2020detecting}. \nA \\textit{domain} or attribute or categorical feature is defined as a set of elements sharing a common property, e.g. \\textit{Port}. \nA domain consists of a set of \\textit{entities} which are the set of possible values for the categorical variable, e.g. \\textit{Port}: \\{ Baltimore, New York, \\dots\\}.\n\\textit{Context}~\\cite{datta2020detecting} is defined as the reference group of entities with which an entity occurs, implying an entity can be present in multiple contexts.\nA data instance (record) is anomalous if it contains unexpected co-occurrence among two or more of its entities~\\cite{das2007detecting,hu2016embedding,datta2020detecting}.\n\n\\begin{definition}[Anomalous Record]\nAn anomalous record is a record where certain domains have entity values that are not consistent with the remaining entity values, termed as the context, with respect to the expected data distribution. \n\\end{definition}\n\n\\textit{Explanation} for a model typically refers to an attempt to convey the internal state or logic of an algorithm that leads to a decision~\\cite{wachter2017counterfactual}.\nClosely related to the idea of explanations are counterfactuals.\n\\textit{Counterfactuals} are hypothetical examples that demonstrate to an user how a different and desired prediction can be obtained.\n\\textit{Algorithmic recourse} has been defined as an actionable set of changes that can be made to change the prediction of a system with respect to a data instance from an unfavourable one to a desirable one~\\cite{joshi2019towards}.\nThe idea is to change one or more of the feature values of the input in an feasible manner in order to produce a favorable outcome. \n% TODO : might remove this next line\nAlgorithmic recourse has been explored in the context of mostly classification problems, with a generalized binary outcome scenario.\nAlgorithmic recourse for anomaly detection is an important yet mostly unexplored problem.\nIn this work, the hypothetical instances that are the result of algorithmic recourse on a data instance are referred to as \\textit{counterfactuals} or \\textit{recourse candidates}. \nIt is important to note that while \\textit{counterfactual explanations} provide explanations through contrasting examples, \\textit{algorithmic recourse} refers to the set of actions that provides the desired outcome.\n\nWhile nominal points are assumed to be generated from an underlying data distribution $\\mathcal{D}$, anomalies can be assumed to be generated from a different distribution $\\mathcal{D'}$.\nIt can be hypothesized that an anomaly $\\textbf{x}_a \\sim \\mathcal{D'}$, is generated from some $\\textbf{x}_n \\sim \\mathcal{D}$ through some transformation function set $\\mathcal{F}$, such that $\\textbf{x}_a = \\mathcal{F}(\\textbf{x}_n) \\sim \\mathcal{D'}$. \nA simplifying view of $\\mathcal{F}$ can be a process of feature value perturbation or corruption.\nTherefore, we can also hypothesize that there exists some arbitrary function set $\\mathcal{G}$, such that $\\mathcal{G}(\\textbf{x}_a) \\sim \\mathcal{D}$ and possibly $\\mathcal{G}(\\textbf{x}_a)\\neq \\textbf{x}_n$ --- which is emulated through algorithmic recourse. \n\n\\begin{definition}[Algorithmic Recourse for Anomaly Detection]\nAlgorithmic recourse for anomaly detection can be defined as a set of actionable changes on an anomalous data instance, such that it is no longer considered an anomaly with respect to the underlying anomaly detection model. \n\\end{definition}\n\nSpecifically, we consider the research question that given a row of tabular data, with strictly categorical values, which is deemed anomalous by an anomaly detection model $\\mathcal{M}_{AD}$ --- how can we generate a set of hypothetical records such which would be deemed normal by $\\mathcal{M}_{AD}$. \nIn this setting, without loss of generality we consider $\\mathcal{M}_{AD}$ to be \n\\begin{enumerate*}[label=(\\roman*)]\n\\item trained using a training set which is assumed to be clean~\\cite{chen2016entity,datta2020detecting},\n\\item a likelihood based model that produces real-valued scores,\n\\item a queriable black box model\n\\end{enumerate*}\n% is a likelihood based model and trained using a training set which is assumed to be clean~\\cite{chen2016entity,datta2020detecting}. \n% Further, without loss of generality we can assume that $\\mathcal{M}_{AD}$ is a likelihood based model that produces real-valued output and $\\mathcal{M}_{AD}$ is a queriable black box model.\n\\begin{problem}[]\nGiven data instance $\\textbf{x}_a$ which is deemed anomalous by a given \\textit{anomaly detection} model $\\mathcal{M}_{AD}$, the objective is to generate a set of counterfactuals $Y_{cf}$ such that $\\textbf{x}_{cf} \\in Y_{cf}$ is not an anomaly according to $\\mathcal{M}_{AD}$.\n\\end{problem}\n\nSince in the case of unsupervised anomaly detection an application or dataset specific threshold is often used which is difficult to determine, we can relax the definition of recourse to a obtain a set of counterfactuals $Y$ such that $\\textbf{x}_{cf}\\in Y_{cf}$ are ranked lower by $\\mathcal{M}_{AD}$ in terms of anomaly score. \n% set of actions that modifies the given anomalous $\\textbf{x}_a$ such that it is ranked lower in terms of anomaly score by $\\mathcal{M}_{AD}$. \n% In generating counterfactuals, the objective is to modify the features $\\textbf{x}_a$ in a meaningful way such that the modified data instance is deemed nominal by $\\mathcal{M}_{AD}$.\nThere are multiple objectives that require optimization to obtain counterfactuals that satisfy different criterion~\\cite{karimi2020model} such as \\textit{sparsity}, \\textit{diversity}, \\textit{prolixity}~\\cite{keane2020good}, \\textit{proximity} to the anomalous record, low \\textit{cost} to the end user, along with \\textit{feasibility}, \\textit{actionability} and \\textit{non-discriminatory} nature which depend on application scenario. \n% Some of of the other desirable characteristics of recourse include \\textit{feasibility}, \\textit{actionability} and \\textit{non-discriminatory} nature which depend on application scenario. \n% These are however dependant on the application scenario and require designing problem specific constraints, beyond the general setting we consider.\n% Prolixity~\\cite{keane2020good} that relates to meaningful counterfactuals and plausibility are also important criteria.\nSince we address a general scenario without apriori application specific knowledge, some of these problem specific objectives such as user specific cost or feasibility are not applicable.\nWe consider the key criterion such as validity, diversity and sparsity and discuss them on evaluation metrics in Section~\\ref{sec:metrics}.\n% \\vspace{-1em}\n\n\\vspace{-2mm}\n"
            },
            "section 2": {
                "name": "Related Work",
                "content": "\nIn this section, we discuss the prior literature that explores the concepts of algorithmic recourse, counterfactuals and anomaly explanation, which are relevant in this discourse. \n\nExplainability in machine learning models has gained burgeoning research focus over the last decade due to the need for building trust and achieving transparency in decision support systems that often employ black-box models.\nPost-hoc explanations through feature importance has been proposed to explain prediction of classifiers.\n\\textit{LIME}~\\cite{ribeiro2016should} presents an approach to obtaining explanations through locally approximating a model  in the neighborhood of of a prediction of a prediction. \n~\\textit{DeepLIFT}~\\cite{shrikumar2017learning} proposed a method to decompose the prediction of a neural network by  recursively calculating the contributions by individual neurons. \n~\\textit{SHAP}~\\cite{SHAP}present a unified framework that assigns each feature an additive importance measure for a particular prediction, based on \\textit{Shapley} Values.\n\\textit{InterpretM}L~\\cite{nori2019interpretml} presents an unified framework for Ml interpretability. \n\n\nThere has been recent work on explaining outcome for anomaly detection models~\\cite{antwarg2021explaining, macha2018explaining, yepmo2022anomaly}.\n\\textit{ACE}~\\cite{zhang2019ace} proposes an approach for explaining anomalies in cybersecurity datasets.\n% , through a local approximate model with a regularized regression objective to model the anomaly score.\nWhile some some anomaly detection methods such as \\textit{LODI}~\\cite{dang2013local} and \\textit{LOGP}~\\cite{dang2014discriminative} provide feature importance to explain anomalies by design, most methods employ a post-hoc explanation approach.\nDIFFI~\\cite{carletti2020interpretable} provides explanations for outputs from an Isolation Forest.\nExplanation through gradient based approaches have been proposed in anomaly detection based methods on neural networks~\\cite{amarasinghe2018toward,nguyen2019gee,kauffmann2020towards}.\n\n\\citeauthor{karimi2020survey}~\\cite{karimi2020survey} presents a comprehensive survey on algorithmic recourse.\n\\citeauthor{ustun2019actionable}~\\cite{ustun2019actionable} introduced the notion of actionable recourse, that ensures that the counterfactuals are  obtained through appropriate feature value modification.\n\\textit{DiCE}~\\cite{mothilal2020explaining} presents an a framework for generating and evaluating a diverse set of counterfactuals based on determinantal point processes. \nNeural network model based approaches for generating counterfactuals have also been proposed ~\\cite{pawelczyk2020learning,mahajan2019preserving, chapman2021fimap}.\n% CEILS~\\cite{crupi2021counterfactual} presents a method to generate feasible counterfactual explanations capturing by design the underlying causal relations.\nCausal reasoning has also been explored towards algorithmic recourse~\\cite{karimi2020model,prosperi2020causal,karimi2021algorithmic,crupi2021counterfactual}.\n% While causal inference has been explored for algorithmic recourse,  difficulty in estimating underlying causal structure limits its practical applicability in sizable and complex datasets.\nApproaches for recourse based on heuristics, specifically using genetic algorithms have also been explored~\\cite{sharma2019certifai, barredo2020plausible, dandl2020multi}.\nTo our knowledge, only one method RCEAA~\\cite{RCEAA} has been proposed towards recourse in anomaly detection based on autoencoders with real valued inputs.  \n\n\n% ===========================================================\n\n\n"
            },
            "section 3": {
                "name": "Algorithmic Recourse Through Modeling Context",
                "content": "\\label{sec:model}\nAlgorithmic recourse consists of two steps:\n\\begin{enumerate*}[label=(\\roman*)]\n    \\item Understanding what is causing a data instance to be an anomaly,\n    \\item How to define a set of actions to modify the feature values in order to remedy the unfavorable outcome.\n\\end{enumerate*}\nWe propose \\textbf{CARAT}: \\textbf{C}ontext preserving \\textbf{A}lgorithmic \\textbf{R}ecourse for \\textbf{A}nomalies in \\textbf{T}abular Data that decomposes the task into these two sequential logical steps and address them.\n\\textit{CARAT} comprises of a model based approach to identify the presence of entities that causes the record to be anomalous,\nand an algorithm to modify those feature values in the record for recourse.\n\n\\vspace{-2mm}\n\n",
                "subsection 3.1": {
                    "name": "Explainer Model",
                    "content": "\\label{sec:xformer}\n% The interpretation of anomalies is inherently tied to the \\textit{context}.\nGiven a record or data instance with categorical features, the tuple of entities is anomalous when one or more of the entities are out-of-context with respect to the remaining entities~\\cite{das2007detecting} with unexpected co-occurrence patterns.\nWe use a Transformer~\\cite{vaswani2017attention} based architecture to jointly model the context of the entities of records. \nTransformers have been extensively utilized in other applications on text, image and tabular data~\\cite{huang2020tabtransformer}. \nA record can be considered as a sequence of entities, without a predefined ordering of domains or any semantic interpretation of the relative ordering.\nTransformer based architectures are appropriate for tabular data with categorical features since\n\\begin{enumerate*}[label=(\\roman*)]\n\\item they can handle large cardinality values for each category and are scalable\n\\item can provide contextual representations of entities\n\\item can model context with a prespecified ordering of domains\n\\end{enumerate*} and do not consider any relative ordering among the domains (categories).\nWe adopt an encoder-decoder architecture, similar to language models~\\cite{devlin-etal-2019-bert} with the objective to predict the likelihood of each entity in a given record with possible corruptions.\nThe predicted likelihood for each entity is conditioned on the context---implicitly capturing the pair-wise and higher order co-occurrence patterns among entities.\n\n\\vspace{-1mm}\n",
                    "subsubsection 3.1.1": {
                        "name": "Pretrained Row Encoder",
                        "content": "\\label{sec:pretrain}\nThe encoder has a transformer based architecture and consists of multiple layers.\nSequential architectures are not effective for rows of tabular data where the relative ordering of entities (and domains) do not have any semantic interpretation.\nTo handle domains with large number of entities, a $m$ parallel domain specific embedding layers are used with same dimensionality.\nTo inform the model which domain an entity embedding vector belongs to, we utilize \\textit{positional encoding}~\\cite{devlin-etal-2019-bert} vectors which is concatenated to each of the entity embedding vectors.\nThe tuple of vectors is then passed to the subsequent transformer block comprising of multiple layers of transformers.\n\nTo train the encoder such that it learns contextual representation for each entity in a record, we require a corresponding decoder and training objective which we design as follows.\nWe refer to this decoder as \\textit{decoder-R}, which is used for pretraining the encoder and not in the final objective.\n\\textit{Decoder-R} comprises of multiple fully connected layers and is trained to reconstruct data. \nIn order to aid the network to retain information and reconstruct it accurately, the contextual entity embeddings from the encoder layer are augmented with positional vectors through concatenation, after the first fully connected layer.\nNote that both the encoder and \\textit{decoder-R} utilize positional encoding to indicate domain and help the model reconstruct the entity for a given domain using the contextual embedding. \nThe remainder of the \\textit{decoder-R} consists of $m$ parallel dense layers with GELU activation, with the last layer being \\textit{softmax} to obtain the index of the entity for a specific domain.\nNote that while the first transformation layer is shared for entity embedding of all domains, the latter layers are domain specific.\nThe encoder and \\textit{decoder-R} are jointly trained, using a reconstruction based objective, similar to Masked Language Model where we randomly perturb or remove entities from records and train the model to predict the correct one from the partial context. \nThe trained encoder captures the shallow embedding in the first layer as well as the contextual representation of entities in the record. \n\n\\vspace{-1mm}\n"
                    },
                    "subsubsection 3.1.2": {
                        "name": "Entity Likelihood Prediction Model",
                        "content": "\\label{sec:decoder-p}\nThe \\textit{decoder-P} is designed to predict the likelihood of each entity in a record as output---using the outputs from the pretrained encoder as it's input.\nThe input to \\textit{decoder-P} consists of \n\\begin{enumerate*}[label=(\\roman*)]\n\\item The embedding representation for the $j^{th}$ entity $e^j$, obtained from the first embedding layer of the encoder ($x_0^j \\in R^d$) \n\\item The contextual representation of the entity $e^j$, obtained from the last layer of the encoder, $z^j$. \n\\end{enumerate*}\nDomain specific \\textit{positional encoding} vector ($p^j \\in R^d $) is concatenated with $x_0^j$ to obtain $x^j \\in R^{2d}$.\nWe want to capture the semantic coherence and interaction between $x^j$, and the contextual representation of the entity $z^j$.\nTo accomplish this we use a \\textit{Bilinear} layer.\nThe output of this Bilinear layer is fed to a dense network with multiple hidden layers, and finally a sigmoid activation function to obtain a likelihood of whether an entity should occur in the given record. \nWe utilize a simple 2-layered architecture with ReLU activation for this domain specific dense layer. \nBinary cross-entropy loss is used to train \\textit{decoder-P}, keeping the weights of the pretrained encoder fixed.\nThe training of \\textit{decoder-R} differs from \\textit{decoder-P} due to the divergent objective.\nWe generate labelled samples from the training data, where we perturb samples with a probability $1-\\alpha$. For $\\alpha$ fraction of samples, the model is given unchanged records from the training set to enable it to recognize expected patterns and predict higher likelihood scores for co-occurring entities.\nFor the remaining samples, we randomly perturb one or more of its entities and task the decoder to recognize which of the entities have been perturbed.\nIt is important to note that the objective of the \\textit{explainer} model is not anomaly detection, but  to predict the likelihoods of individual entities in a record.\n\n\n\n\n"
                    }
                },
                "subsection 3.2": {
                    "name": "Generating Counterfactuals",
                    "content": "\n\n\nRecords in tabular data with categorical features can be considered as tuple of entities, with data specific inherent relationships between the domains (attributes).\nFor instance in the case of shipment records, products being shipped are closely related to the company trading them and their origin.\nMany real-life applications involve tabular data which can be represented as a heterogeneous graph or Heterogeneous Information Network (HIN). \nA HIN~\\cite{sun2011pathsim} is formally defined as a graph $\\mathrm{G}=(V,E)$ with a object type mapping function $\\phi: V \\rightarrow \\mathcal{A}$ and edge type mapping function $\\psi: E \\rightarrow\\mathcal{R}$.\nHere $v\\in V$ are the nodes representing entities, $\\phi(v) \\in \\mathcal{A}$ are the domains, $e \\in E$ are the edges representing co-occurrence between entities and $\\psi(e)\\in \\mathcal{R}$.\nA \\textbf{metapath}~\\cite{sun2011pathsim} or metapath schema is an abstract path defined on the graph network schema of a heterogeneous network that describes a composite relation $\\mathbf{R}=R_1 o R_2 \\ldots R_l$ between nodes of type $A_1, A_2 \\ldots A_{l+1}$, capturing relationships between entities of different domains.\nThere can exist multiple metapaths, and we consider $\\mathcal{R}$ and thus the metapaths to be symmetric in our problem setting. \nMetapaths have been utilized in similarity search in complex data, and to find patterns through capturing relevant entity relationships~\\cite{cao2018collective}.\nRecent approaches on \\textit{knowledge graph embeddings} (KGE)~\\cite{wang2017knowledge} have demonstrated their effectiveness in capturing the semantic relationships between objects of different types in knowledge graphs which are HINs. \nMany approaches for KGE consider symmetric relationships as in our case, and is more generally applicable.\n% We choose one such model \\textit{DistMult}~\\cite{distmult2014}, a semantic matching model, to obtain KGE for the entities in our data. \nWe choose one such model \\textit{DistMult}~\\cite{distmult2014} to obtain KGE for the entities in our data.\n% \\textit{DistMult} is a semantic matching model which uses a similarity based scoring function, to measure the plausibility of entities having a particular type of relation.\n\\textit{DistMult} uses both node and edge embeddings to predict semantically similar nodes, since it models relationships between entities in form of $<e_a, R , e_b>$. \n\n\nIn generating counterfactuals for an anomalous record, we intend to replace the entity $e_j$(or entities) which is predicted to have low likelihood by the explainer model, given the context comprising of the other entities in the record.\nThe intuition is to replace such entities with other entities (of the corresponding domain) which are semantically similar to the other entities in the record.\nLet $\\textbf{x}_a$ be the anomalous record and let entity $e_j^p$ in domain $d_j$ be selected for replacement. \nIn this task, we utilize the associated HIN constructed from the data, along with the set of metapaths $MP = \\{mp_1, mp_2 \\ldots mp_q\\}$ that are defined using domain knowledge.\nHere metapath $mp_i$ is of the form $\\{d_a, d_b \\ldots d_i\\}$.\nThus, candidates to replace $e_j^p$ are selected using the metapaths that contain $d_j$.\nLet us consider one such metapath $mp_p$ such that $d_j \\in mp_p$, with relations of $(d_i,d_j)$ and $(d_j,d_k)$. Let the respective entities in $\\textbf{x}_a$ for $d_i$ and $d_k$ be $e_i^a$ and $e_k^a$.\nIn a generated counterfactual $\\textbf{x}_{cf}$, the entity $e_j^{cf}$ that replaces $e_j^a$ should ideally be semantically similar to $e_i^a$ and $e_k^a$.\nKGE can be effectively used for this task. This idea is described in Figure~\\ref{fig:semantic}.\nWe find $K$ nearest entities to $e_i^a$ and $e_k^a$, belonging to domain $d_j$.\nNote that it is possible that $d_i$ or $d_k$ is null based on the schema of $mp_p$.\nWe replace the entities in the domains with low likelihood with all combinations of the candidate replacements for the respective domains to obtain the set of candidate counterfactuals, of which $K$ least anomalous are chosen.\nThe steps are summarized in Algorithm~\\ref{alg:recourse_gen_xformer}.\n% =======================\n% Definition of recourse\n"
                }
            },
            "section 4": {
                "name": "Evaluation Metrics",
                "content": "\\label{sec:metrics}\nEvaluation metrics are crucial to understanding the performance of counterfactual generation methods, more so due to the fact that generated counterfactuals have multiple objectives and associated trade-offs. \nWe discuss some of the metrics proposed in prior literature, and their limitations in the current problem setting.\nFurther, we propose a set of new metrics that are more appropriate.\n% given the problem setting and the data characteristics. \n\n",
                "subsection 4.1": {
                    "name": "Existing Metrics for Counterfactuals",
                    "content": "\n\n\\textbf{Recourse Correctness} or \\textbf{validity}~\\cite{mothilal2020explaining} captures the ratio of counterfactuals\nthat are accurate in terms obtaining the desired outcome from the blackbox prediction model.  \nFor unsupervised anomaly detection since $\\mathcal{M}_{AD}$ provides a real valued likelihood (or anomaly score), a direct prediction (decision value) is unavailable. \n\\textbf{Recourse Coverage}~\\cite{rawal2020beyond} refers to quantification of the criterion that the algorithmic recourse provided covers as many instances as possible.\n\\textbf{Distance}~\\cite{crupi2021counterfactual,karimi2020survey} or \\textbf{proximity} measures the mean feature-wise distance between the original data instance and the set of recourse candidates. Distance is often calculated separately for categorical and continuous attributes. \nFor continuous attributes $l_p$ norms~\\cite{dhurandhar2018explanations} or their combinations are used whereas\nfor categorical(discrete) variables overlap measure~\\cite{chandola2007similarity} $\\mathbbm{1}(x_i=x_j)$ has been used. \nWith purely categorical attributes, this measure however fails to convey any information other than merely how many of the attributes are different in the counterfactual.\n\n\\textbf{Cost}~\\cite{crupi2021counterfactual,karimi2020model} refers to the cost incurred in changing a particular feature value in a recourse candidate. \nPrior works have utilized $l_p$ norms to quantify this criteria, for real-valued features.\nIn our problem scenario, this metric is directly not applicable without any external real-world constraints which can help quantify the difference in cost in changing $x_i$ to $x_j$ vs. $x_k$.\n% Distance bears relationship to \\textit{cost} of recourse, but are not the same given cost can be affected by other factors~\\cite{karimi2020survey}. \n\\textbf{Diversity}~\\cite{mothilal2020explaining} refers to the feature-wise distances between the set of recourse candidates. \nDiversity encourages sufficient variation among the set of recourse candidates so that it increases the chance of finding a feasible solution. However, it has been noted that in certain cases diversity as an objective correlates poorly with user cost~\\cite{yadav2021low}.\n\\textbf{Sparsity}~\\cite{mothilal2020explaining} refers to the number of features that are different in the recourse candidates, with respect to the original data instance. \n\n\n"
                },
                "subsection 4.2": {
                    "name": "Proposed Metrics",
                    "content": "\\label{sec:metrics_new}\nWe propose a new set of metrics based on previously defined metrics, which are more suited to our problem setting. \n% ===================\n\n\\textbf{Sparsity-Index}: \nSparsity is an important objective along with diversity that encourages minimal change is made to a data instance in terms of features.\n% It is preferred that changes are \\textit{sparse}.\nTo capture this notion, we define \\textit{Sparsity Index} for tabular data with categorical features. Let $\\textbf{x}_a$ be the anomalous record, and $d_j$ be the $j^{th}$ domain or feature.\n\\begin{equation}\n    Sparsity \\,Index = \\frac{1}{\\vert Y \\vert}\\Sigma_{\\textbf{x} \\in Y}\\frac{1}{1 + \\Sigma_{d_j}\\mathbbm{1}(x_j \\neq x_j^a) }\n\\end{equation}\nThe values of Sparsity Index $\\in[0.5,1)$, with the low value corresponding to modification of all feature values and the maximum value corresponding to none.\n% ====================\n\n\\textbf{Coherence}: We define \\textit{coherence} as measure to quantify the consistency of the counterfactuals similar to density consistency~\\cite{karimi2020survey}.\nLet $\\mathcal{D}_p$ be the set of domains which are modified in $\\textbf{x}_a$ to obtain a counterfactual $\\textbf{x}_{cf}$, $\\mathcal{D}_r$ be the remaining domains. Let $e_j$ be the entity in $\\textbf{x}_{cf}$ for domain $j$.\n\\textit{Coherence} measures the mean probability of co-occurrence of the entities $e_i \\in D_p$ with $e_j \\in D_r$.\nMaximizing coherence implies $e_j^r$ in $\\textbf{x}_a$ is replaced with a candidate entity $e_j^{cf}$ in $\\textbf{x}_{cf}$ which has a high probability of co-occurrence given the context of other entities of $D_r$ in $\\textbf{x}_a$, and leads to plausible counterfactuals.\n% Let the entities in the of a counterfactual record be $e_1, e_2, ... e_m$.\n% This can be considered as a measure of density consistency.\n\\begin{equation}\n    coherence = \\Sigma_{e_i \\in D_p} \\frac{1}{|\\mathcal{D}_r|} \\Sigma_{e_j \\in \\mathcal{D}_r}P(e_i,e_j)\n\\end{equation}\n% ====================\n\n\\textbf{Conditional Correctness}: This metric quantifies the validity of the counterfactuals, \\textit{conditional} upon the underlying anomaly detection model $\\mathcal{M}_{AD}$ which has a scoring function   $score_\\mathcal{M}()$.\nLet $\\mathcal{D}_k$ be a set of randomly chosen data instances from the training and testing set. \nLet $\\textbf{x}_a$ be the anomalous record and let the rank of $\\textbf{x}_a$ in $\\textbf{x}_a \\cap \\mathcal{D}_k$ be $r$, sorted by $score_\\mathcal{M}()$ with appropriate order.\nWithout loss of generalization, we can assume a higher score indicates a more \\textit{normal} or nominal data instance and a low score indicates anomalousness.\nFor $x \\in Y$, where Y is the set of counterfactuals, \\textit{conditional correctness} can be defined as \n\\begin{equation}\n    CC = \\frac{1}{|Y|}\\Sigma_{x \\in Y} \\mathbbm{1}(Rank(x) - r > 0 )\n\\end{equation}\nThis implies that $x$ is ranked lower in terms of being an anomaly, since higher ranked data instances are more anomalous.\nRanking is a more suitable approach to designing a metric than utilizing thresholds which are data and application dependant an is difficult to determine.\nThe relative ordering of records are important in this setting, since test instances are sorted based on $score_\\mathcal{M}()$.\n% ===================\n\n\\textbf{Feature Accuracy}: The concept of anomaly in tabular data with categorical variables has been described as one or more attributes being \\textit{out of context} with respect to the others, as discussed in Section~\\ref{sec:preliminaries}. \n% With that being said, it can be posited, without loss of generalization that one or more of the categorical features are \\textit{perturbed} with respect to normal samples that arise from the underlying data generating process --- and require rectification.\n% Identification and explanation based on feature importance has been explored in literature for conterfactuals~\\cite{chapman2021fimap}.\n% As noted in Section~\\ref{sec:preliminaries}, we can consider anomalies to be generated from an underlying transformation or perturbation process where one or more of the domain values are perturbed.\nTherefore, it is important to accurately measure how well can a model identify which of the domain values should be modified in $\\textbf{x}_a$, and relates to the explanation aspect of algorithmic recourse.\nThis requires having a Gold Standard (ground truth) knowledge where we know  which domain values (features) have been corrupted and the entities for those domains are out of context. \n% This metric helps us capture how effectively a model or approach correctly identifies the features to be modified to provide recourse candidate.\nLet $dom$ be the set of domains (features) with $m$ domains. \n% Let $\\mathbbm{q()}$ be a binary valued function that indicates whether a \\textit{perturbed} domain(feature) is modified in a counterfactual, and  $\\mathbbm{p()}$ be a binary valued function that indicates whether a known unperturbed domain is not modified in the counterfactual. \nLet $\\mathbbm{q()}$ be a binary valued function that has value $1$ if the domain value is changed in counterfactual $\\textbf{x}_{cf}$ from $\\textbf{x}_a$ $(r_j \\in \\textbf{x}_a \\rightarrow x_j\\in \\textbf{x}_{cf})$ is an actual cause of the anomaly or if a domain value remains unchanged if it was not a cause of the anomaly. \n\\begin{equation}\n    FA = \\frac{1}{\\vert Y \\vert}\\Sigma_{\\textbf{x}_{cf}} \\frac{1}{m} \\Sigma_{j \\in dom}\\mathbbm{1}(\\mathbbm{q}(r^j \\rightarrow x^j )=1)\n\\end{equation}\n% a \\textit{perturbed} domain (feature) is modified in a counterfactual, and  $\\mathbbm{p()}$ be a binary valued function that indicates whether a known unperturbed domain is not modified in the counterfactual. \n% \\begin{equation}\n%     FA = \\frac{1}{\\vert Y \\vert}\\Sigma_{\\textbf{x}_{cf}} (\\Sigma_{j \\in dom}\\frac{1}{m}\\mathbbm{1}(\\mathbbm{q}(r^j,x^j )=1) + \\mathbbm{1}(\\mathbbm{p}(r^j,x^j )=1)\n% \\end{equation}\n\n\\textbf{Heterogeneity}: Although diversity is an important objective for recourse candidates, existing diversity metrics like \\textit{Count Diversity}~\\cite{mothilal2020explaining} are inadequate.\nA trivial random modification of all feature values will maximize such metrics for our setting with strictly categorical features, where distance between discrete feature values is computed using overlap measure. \nTwo factors are important here: \\begin{enumerate*}[label=(\\roman*)]\n    \\item the variation among the entities that are proposed to replace original entity in $\\textbf{x}_a$ and\n    \\item the correct domain's value is modified or not.\n\\end{enumerate*} \nWe require the Gold Standard (ground truth) to determine whether the counterfactual modifies the a correct domain's value.\nIn our experiments, use of synthetic anomalies enables calculation of this metric.\nBetween any two pair of recourse candidates, \\textit{heterogeneity} encourages dissimilarity while taking into account if both the pair of counterfactuals modify the correct domain's value. \n% The first is. The second is whether the correct entity is replaced. \n% While the set of correct replacements can be exhaustively large, we utilize the Gold Standard (ground truth) to calculate this metric.\nLet $m$ be the number of domains, $K$ be the size of the set of counterfactuals $Y$, and $\\mathbbm{1}(\\mathbbm{q})$ be 1 if the correct domain has been modified.\n\\begin{equation}\n\\centering\n\\begin{multlined}\n    H = \\frac{1}{K^2m}\\Sigma_{i=1}^{K-1} \\Sigma_{j=i+1}^{K} \\Sigma_{l=1}^{m} w_{ij}^l \\mathbbm{1}(x_i^l\\neq x_j^l) \\\\\n    w_{ij}^{l} = \\mathbbm{1}(\\mathbbm{q}(r^l\\rightarrow x_i^l )=1) * \\mathbbm{1}(\\mathbbm{q}(r^l \\rightarrow x_j^l )=1)\n\\end{multlined}\n\\end{equation}\n% Simply adopting prior definitions of diversity can lead to an incorrect interpretation, since a trivial random modification of all feature values will maximize diversity value. \n% Heterogeneity on the other hand accounts for correct modifications, which are minimal, but encourages variation among feature values.\n\n\n\n\n"
                }
            },
            "section 5": {
                "name": "Empirical Evaluation",
                "content": "\\label{sec:results}\n% The key research problem being investigated in this work is generation of recourse candidates for anomalies in tabular data with categorical features in an effective and efficient manner. \nThe key objective here is to obtain counterfactuals for for anomalies in tabular data with categorical features.\n% that satisfy the desiderata.\n% We choose \\textit{MEAD}~\\cite{datta2020detecting} as the base anomaly detection model for our experiments, since it is a recently proposed approach for tabular data with categorical features.\nWe consider \\textit{MEAD}~\\cite{datta2020detecting} and \\textit{APE}~\\cite{chen2016entity} as the base anomaly detection models suited to categorical tabular data.\nFor our comparative evaluation against baselines we use \\textit{MEAD}.\n% since it is a recently proposed approach for tabular data with categorical features.\nFor an objective and quantifiable analysis of the performance of our approach with possible alternatives, we perform extensive experiments to capture the varied desiderata in terms of the metrics defined in Section~\\ref{sec:metrics_new}. Further, we analyze the computational cost as well as the stability of the proposed approach.\n\n% =====\n% \\input{Sections/Results/settings_hyperparams}\n\n\\vspace{-0.5em}\n\n"
            },
            "section 6": {
                "name": "Conclusion and Future Work",
                "content": "\nIn this work we address the previously unexplored problem of algorithmic recourse for anomaly detection in tabular data with categorical features with high cardinality. \nWe propose a novel deep learning based approach \\textit{CARAT} to find counterfactuals for detected anomalies. \nWe also define a set of relevant metrics that can enable effective evaluation of counterfactuals in such a problem setting.\nThe scalability and efficacy of our model in terms of the applicable metrics as well computational cost is demonstrated through extensive experiments.\nHowever the current research leads to further research questions.\nWhile we consider multiple objectives to optimize in the process of algorithmic recourse there are application scenario specific constraints that are not considered. \nOne of the questions that has practical implications and requires domain knowledge is the actual cost incurred by the user. \nAnother aspect is feasibility and actionability of counterfactuals, which are often dependant on extrinsic factors that need to explicitly considered and incorporated into the algorithmic recourse for anomalies.\n% Trust, non-discrimination and fairness are important factors for real-life systems utilizing anomaly detection, and it is important to understand how to include those constraints in such a problem setting. \nThus there are multiple continuing research directions which are a natural progression of the problem we address in this work.\n\n\n% \\begin{table}[htb]\n%     \\centering\n%     \\begin{tabular}{c|c|c|c }\n%     \\toprule\n%         Dataset & \\makecell{Total entity \\\\count} & \\makecell{Domain \\\\Count} & Train data size\\\\\n%         \\midrule\n%         us import 1     &  6353 &  8 & 38291 \\\\\n%         us import 2     &  6151 &  8 & 35177 \\\\\n%         us import 3     &  7340 &  8 & 43495 \\\\\n%         colombia export &  4008 &  5 & 16758 \\\\\n%         ecuador export  &  3198 &  7 & 13956 \\\\\n%     \\bottomrule\n%     \\end{tabular}\n%     \\caption{Caption}\n%     \\label{tab:my_label}\n% \\end{table}\n\n\n% \\begin{table}[htb]\n%     \\centering\n%     \\begin{tabular}{c|c|c}\n%      \\toprule\n%         Dataset & \\makecell{Perturbation \\\\ count = 1} & \\makecell{Perturbation \\\\count = 2}\\\\\n%         \\midrule\n%         us import 1     & 0.9833    & 0.9684  \\\\\n%         us import 2     & 0.9835    & 0.9671  \\\\\n%         us import 3     & 0.9889    & 0.9708  \\\\\n%         colombia export & 0.8953    & 0.8006  \\\\\n%         ecuador export  & 0.9097    & 0.8486  \\\\\n%     \\bottomrule\n%     \\end{tabular}\n%     \\caption{Accuracy of Transformer Model in detecting which domain has perturbed values}\n%     \\label{tab:my_label}\n% \\end{table}\n\n\\begin{acks}\nThis work was supported in part by US NSF grants CCF-1918770, NRT DGE-1545362, and OAC-1835660 to NR, and IIS-1954376 and IIS-1815696 to FC.\n\\end{acks}\n\n\\bibliographystyle{ACM-Reference-Format}\n\\bibliography{references}\n\n%% If your work has an appendix, this is the place to put it.\n\n\n\n\\appendix\n"
            },
            "section 7": {
                "name": "Dataset Background",
                "content": "\nThe datasets used in the empirical evaluation are from shipping domain and are proprietary due to security and legal reasons.\nWe discuss some of the attributes of this real world data and their interpretations.\n\n\\textit{HS Code} or Harmonized Tariff Schedule Codes are globally standardized codes that define what type of goods are being transported. \n\\textit{Carrier} is the transporting entity that operates between ports. \nThe ports of \\textit{lading} and \\textit{unlading} are the points where the cargo is laden onto the transporting vessel or vehicle and and unladen from it.\nWe have received help of collaborating domain experts who deal with shipping data to help us understand the data characteristics and the relationships between attributes. The original data has many attributes which contain redundant information, and we select only meaningful attributes from the raw data. Also we remove rows with missing values and perform standard data cleaning to obtain our datasets.\n\nThe metapaths that describe these relationships are shown in Table~\\ref{tab:metapaths}. These are designed with the knowledge of the structure of supply chains that are captured in this \\textit{Bill of Lading} corpus.\n\n\n% ===============================================\n"
            },
            "section 8": {
                "name": "Experimental Setup Details",
                "content": "\n\n",
                "subsection 8.1": {
                    "name": "Hardware and Libraries",
                    "content": "\nWe provide the implementation details to faithfully reproduce the results obtained. \nAll implementation is done in \\textit{Python 3.9}, and uses standard libraries such as \\textit{Numpy}, \\textit{Pandas} and \\textit{scikit-learn}.\nFor optimization and neural network based models, \\textit{PyTorch} (version 1.10) is used.\nAll data preprocessing, training and evaluation presented in this work are performed on a 40-core machine, with a single GPU and distributed training required.\nTo train our Knowledge Graph Embedding model, we use the library \\textit{StellarGraph}, which provides an implementation of \\textit{DistMult}.\n\n"
                },
                "subsection 8.2": {
                    "name": "Experimental Settings and Hyperparameters",
                    "content": "\n",
                    "subsubsection 8.2.1": {
                        "name": "Anomaly Detection Model",
                        "content": "\nAnomaly detection for tabular data with strictly categorical features, especially where the attributes have high dimensionality (cardinality) is a challenging task.\nWe choose Multi-relational Embedding based Anomaly Detection~\\cite{datta2020detecting} as the base anomaly detection model for our experiments.\n\\textit{MEAD} uses an additive model based on shallow embedding, where the likelihood of a record is a function of the magnitude of transformed sum of the entity embeddings.\nWe use an embedding size of $32$ for anomaly detection models our experiments.\n\n"
                    },
                    "subsubsection 8.2.2": {
                        "name": "Synthetic Anomalies",
                        "content": "\nSynthetic anomalies are generated using the approach followed in prior works~\\cite{chen2016entity,datta2020detecting}. \nFor each record, randomly one or more feature values are perturbed i.e. replaced with a random but valid feature value for the categorical attribute. Since our data has at most $8$ categorical attribute we limit the number of perturbations to 2. In generating counterfactuals we consider a balanced mix for all cases.\n\n"
                    },
                    "subsubsection 8.2.3": {
                        "name": "CARAT Explainer Model Details",
                        "content": "\nFor the \\textit{explainer} in \\textit{CARAT} presented in Section~\\ref{sec:model} we an entity embedding dimension of 64. \nThe encoder employs 4 layers of transformer blocks with 8 heads for multi-headed self-attention. \nThe fully connected layers Decoder-R has 3 layers, with $256$,$128$ and $64$.\nThe fully connected layers Decoder-P has 3 layers, with $32$ and $16$.\nWe use the same architecture across all datasets.\n\nIn pretraining the encoder with decoder-R, the training objective is similar to Masked Language Model but not identical.\nSpecifically we replace approximately $20\\%$ of entities in each records to \\textit{mask}, and $20\\%$ of entities are perturbed by replacement with a randomly sample entity from the same domain. \nIn the second phase of training the \\textit{decoder-P}, $\\alpha$ --- the fraction of records which are not changed is set to $0.3$.\n\nBoth the pre-training phase of the encoder and the final explainer architecture are trained for 250 epochs with a batch size of 512 and learning rate of $0.0005$. \nAll optimization for our model and the baselines are performed using Adam.\n\n"
                    },
                    "subsubsection 8.2.4": {
                        "name": "CARAT KGE Details",
                        "content": "\nThe knowledge graph embedding model adopted here is \\textit{DistMult}. We use an embedding size of $100$.\nThe training batch size used is 1024, and we train the model for 300 epochs.\nWe use both the node and edge embeddings to find entities that are similar to a target entity. \nSince \\textit{DistMult} uses $<$head,rel,tail$>$ format to calculate similarity, we perform nearest neighbor search for the tail entity using precomputed embedding of head nodes and relation type. \n\n\n"
                    }
                },
                "subsection 8.3": {
                    "name": "Empirical Evaluation Setup",
                    "content": "\nWe generate counterfactuals for synthetic anomalies. For each approach, we use a set of 400 anomalies and we generate 50 counterfactuals for each anomaly. \nWe use the same set of anomalies for all approaches to perform a fair comparative evaluation.\nFor RCEAA we are able generate counterfactuals for 40 anomalies, due to the excessively long execution time as explained in Section~\\ref{sec:time}. \n\n\n"
                },
                "subsection 8.4": {
                    "name": "Additional Detail on Competing Baselines",
                    "content": "\nFor the baseline models, we adapt the models to the current problem setting in an appropriate manner. \nWe utilize the hyperparameters provided in the original work and do not perform significant hyperparameter tuning for these approaches. \nSimilarly, we do not perform significant hyperparameter tuning for our model to tune performance as well since the objective is to demonstrate the validity of our approach in a general setting.\n\n",
                    "subsubsection 8.4.1": {
                        "name": "RCEAA",
                        "content": "\nIn our implementation of RCEAA~\\cite{RCEAA}, we adapt the original approach.\nFirstly, we replace the autoencoder based anomaly detection model with our likelihood based model.\nIn the loss function, we use $10^{th}$ percentile scores of training data as the threshold so that the generated counterfactuals have a low anomaly score (higher likelihood) according to our anomaly model. We set $\\omega$ to 2. \nAdditionally in place of euclidean distance, we use cosine distance since the dimensionality of the vectors is high.\nIn order to reduce the computational complexity due to grid search of hyperparameters, we set the upper and lower bounds of $\\lambda_1$ and $\\lambda_2$ to $0.25$ and $0.75$, and adopt step size of $0.25$. \nThe training epochs are increased from $15$ mentioned in the paper, to $20$. We report the results with the lowest optimization loss.\n\n"
                    },
                    "subsubsection 8.4.2": {
                        "name": "FIMAP",
                        "content": "\nFor FIMAP, which is an approach for generating counterfactuals in a classification based setting, we adapt it to our problem setting appropriately. We adopt a more complex neural network architecture that follows that archetype proposed in the original work. Specifically, an embedding projection layer of dimensionality 32 is used for each categorical variable, whose output is concatenated and fed to a fully connected network for both proxy classifier network and perturbation network.\nThe fully connected network for proxy classifier has size $(256,256])$, following the original work that uses a 3 layered neural network.\nThe fully connected network for perturbation model has size $(256,128,128)$ and uses dropout of $0.2$. The value of $\\tau$ in Gumbel softmax set to $0.5$.\nWe use $10000$ data points to train the proxy classifier for each dataset, with samples from training set and synthetic anomalies. The batch size used is 512, and the networks are trained for 100 epochs, with early stopping.\n\n"
                    }
                }
            },
            "section 9": {
                "name": "Code and Data Link",
                "content": "\nPlease find the code for this work at : \n\n% \\url{ https://anonymous.4open.science/r/1235-637C/ }\n\\url{https://github.com/ddatta-DAC/Algorithmic_Recourse_AnomalyDetection}\n\n"
            },
            "section 10": {
                "name": "Ethical Implications of Algorithmic Recourse for Anomaly Detection",
                "content": "\nSince algorithmic recourse provides an approach towards generating counterfactuals that are not deemed anomalous by an anomaly detection model which may be part of a decision support system, it raises an obvious ethical question.\n\\textit{Is algorithmic recourse adverserial to anomaly detection i.e. intended to help nefarious actors attempting to evade detection?}\n\nThat is not our motivation here. First, data and anomaly detection models are expected to be secured and adverserial agents would have no access to them in order to circumvent the detection process.\nRecourse for anomaly detection is intended to help the decision making process. It can enable organizations like enforcement agencies in our case study, that make use of anomaly detection systems to better handle false positive cases. Verified agents, whose transactions  may be erroneously flagged, could be intimated of the issue and may be provided alternatives or countermeasures. The issue of false positives exist since it is not feasible to always incorporate the application specific notions of anomaly into anomaly detection models. This effectively aids the decision support system user as well the agents whose data is being assessed.\nIn practical scenarios, systems that utilize algorithmic recourse do require transparency and human surveillance to ensure they are used as intended. There is a minimal risk, as in any system, that unscrupulous personnel who are insiders might utilize algorithmic recourse to provide alternatives to nefarious agents enabling them avoid detection. This however can be eliminated through correct operational and access protocols where such a system is deployed.\n\n\n\n\n\n\n\n\n\n% \\section{Research Methods}\n\n% \\subsection{Part One}\n\n\n\n"
            }
        },
        "tables": {
            "tab:metapaths": "\\begin{table}[pb!]\n    \\centering\n    \\caption{Metapaths for the datasets belonging to the three data sources, viz. US Import, Colombia Export and Ecuador Export.}\n    \\begin{subtable}[h]{0.95\\columnwidth}\n    \\centering\n    \\caption{Schema of the metapaths describing the relationships between attributes of the data for US Import }\n    \\begin{tabular}{l}\n    \\toprule\n            Shipment Origin $\\leftrightarrow$ HS Code $\\leftrightarrow$Port Of Lading\\\\\n            Shipment Destination $\\leftrightarrow$ HS Code $\\leftrightarrow$ Port Of Unlading\\\\\n            Port Of Lading $\\leftrightarrow$ HS Code $\\leftrightarrow$ Carrier\\\\\n            HS Code $\\leftrightarrow$ Carrier $\\leftrightarrow$Port Of Unlading\\\\\n            Shipper $\\leftrightarrow$ Shipment Origin $\\leftrightarrow$ Port Of Lading\\\\\n            Consignee $\\leftrightarrow$ Shipment Destination$\\leftrightarrow$Port Of Unlading\\\\\n            Consignee $\\leftrightarrow$ Carrier $\\leftrightarrow$ Shipment Destination\\\\\n            Shipper $\\leftrightarrow$ Carrier $\\leftrightarrow$ Shipment Origin\\\\\n            Consignee $\\leftrightarrow$ Carrier $\\leftrightarrow$ Port Of Unlading\\\\\n            Shipper $\\leftrightarrow$ Carrier $\\leftrightarrow$ Port Of Lading\\\\\n     \\bottomrule      \n    \\end{tabular}\n    \n    \\label{tab:metapaths_US}\n    \n\\end{subtable}\n\n \\begin{subtable}[h]{0.95\\columnwidth}\n    \\centering\n    \\caption{Schema of the metapaths describing the relationships between attributes of the data for exports from Colombia. }\n    \\begin{tabular}{l}\n    \\toprule\n    Shipper $\\leftrightarrow$ Shipment Origin $\\leftrightarrow$ HS Code\\\\\n    Consignee $\\leftrightarrow$ Shipment Destination $\\leftrightarrow$ HS Code\\\\\n    Shipment Destination $\\leftrightarrow$ HS Code $\\leftrightarrow$ Shipment Origin\\\\\n    Shipper $\\leftrightarrow$ HS Code $\\leftrightarrow$ Consignee \\\\\n    \\bottomrule      \n    \\end{tabular}\n    \n    \\label{tab:metapaths_colombia}\n\\end{subtable}\n\n \\begin{subtable}[h]{0.95\\columnwidth}\n    \\centering\n    \\caption{Schema of the metapaths describing the relationships between attributes of the data for exports from Ecuador. }\n    \\begin{tabular}{l}\n    \\toprule\n    Shipment Destination,Goods Shipped,Port Of Unlading\\\\\n    Shipper $\\leftrightarrow$ Goods Shipped $\\leftrightarrow$ Shipment Origin\\\\\n    Goods Shipped $\\leftrightarrow$ Carrier $\\leftrightarrow$ Port Of Unlading\\\\\n    Consignee $\\leftrightarrow$ Shipment Destination $\\leftrightarrow$ Port Of Unlading\\\\\n    Consignee $\\leftrightarrow$ Carrier $\\leftrightarrow$ Shipment Destination \\\\\n    Shipper $\\leftrightarrow$ Carrier $\\leftrightarrow$ Shipment Origin \\\\\n    Consignee $\\leftrightarrow$ Carrier $\\leftrightarrow$ Port Of Unlading \\\\\n    \\bottomrule      \n    \\end{tabular}\n  \n    \\label{tab:metapaths_ecuador}\n    \\end{subtable}\n    \\label{tab:metapaths}\n\\end{table}"
        },
        "figures": {
            "fig:xformer": "\\begin{figure*}[t]\n\\begin{subfigure}[b]{0.49\\textwidth}\n  \\centering\n  % include first image\n  \\includegraphics[width=0.975\\linewidth]{Figures/Xformer_pretrain.pdf}\n  \\caption{Architecture of the Encoder and the Decoder-R used in the first phase of pretraining the Encoder to learn the representation the entities and capture overall context of the record (Section~\\ref{sec:pretrain}). }\n  \\label{Lill fig:sub-first}\n\\end{subfigure}\\hfill\n\\begin{subfigure}[b]{0.5\\textwidth}\n  \\centering\n  % include second image\n  \\includegraphics[ width=0.975\\linewidth]{Figures/Xformer_explain_decoderP.pdf}\n  \\caption{Architecture of Decoder-P, which takes both the embeddings and the contextual representation  of entities from the  encoder, and predicts likelihood of each entity in the record (Section~\\ref{sec:decoder-p}) }\n  \\label{Lill fig:sub-second}\n\\end{subfigure}\\hfill\n\n\\vspace{-3mm}\n\\caption{Architecture of the Explainer model in \\textit{CARAT}, comprising of the encoder and decoder-P, which captures likelihood of each entity in the input record.}\n\\label{fig:xformer}\n\\vspace{-3mm}\n\\end{figure*}",
            "fig:semantic": "\\begin{figure}[tp]\n    \\centering\n    \\includegraphics[width=0.700\\columnwidth]{Figures/semantic_v1.pdf}\n    \\caption{Finding counterfactuals through replacing a lower likelihood entity in a record with another entity based on semantic similarity with respect to the other entities. }\n    \\label{fig:semantic}\n\\end{figure}",
            "fig:time_complexity": "\\begin{figure}[pt!]\n    \\centering\n    \\includegraphics[width=0.80\\columnwidth]{Figures/time_complexity_v3.pdf}\n    \\caption{Computational time of compared approaches. Our proposed approach \\textit{CARAT} shows a clear advantage.}\n    \\label{fig:time_complexity}\n\\end{figure}"
        },
        "equations": {
            "eq:1": "\\begin{equation}\n    Sparsity \\,Index = \\frac{1}{\\vert Y \\vert}\\Sigma_{\\textbf{x} \\in Y}\\frac{1}{1 + \\Sigma_{d_j}\\mathbbm{1}(x_j \\neq x_j^a) }\n\\end{equation}",
            "eq:2": "\\begin{equation}\n    coherence = \\Sigma_{e_i \\in D_p} \\frac{1}{|\\mathcal{D}_r|} \\Sigma_{e_j \\in \\mathcal{D}_r}P(e_i,e_j)\n\\end{equation}",
            "eq:3": "\\begin{equation}\n    CC = \\frac{1}{|Y|}\\Sigma_{x \\in Y} \\mathbbm{1}(Rank(x) - r > 0 )\n\\end{equation}",
            "eq:4": "\\begin{equation}\n    FA = \\frac{1}{\\vert Y \\vert}\\Sigma_{\\textbf{x}_{cf}} \\frac{1}{m} \\Sigma_{j \\in dom}\\mathbbm{1}(\\mathbbm{q}(r^j \\rightarrow x^j )=1)\n\\end{equation}",
            "eq:5": "\\begin{equation}\n\\centering\n\\begin{multlined}\n    H = \\frac{1}{K^2m}\\Sigma_{i=1}^{K-1} \\Sigma_{j=i+1}^{K} \\Sigma_{l=1}^{m} w_{ij}^l \\mathbbm{1}(x_i^l\\neq x_j^l) \\\\\n    w_{ij}^{l} = \\mathbbm{1}(\\mathbbm{q}(r^l\\rightarrow x_i^l )=1) * \\mathbbm{1}(\\mathbbm{q}(r^l \\rightarrow x_j^l )=1)\n\\end{multlined}\n\\end{equation}"
        },
        "git_link": "https://github.com/ddatta-DAC/Algorithmic_Recourse_AnomalyDetection"
    }
}