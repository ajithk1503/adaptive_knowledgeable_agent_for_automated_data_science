{
    "meta_info": {
        "title": "LPNL: Scalable Link Prediction with Large Language Models",
        "abstract": "Exploring the application of large language models (LLMs) to graph learning\nis a emerging endeavor. However, the vast amount of information inherent in\nlarge graphs poses significant challenges to this process. This work focuses on\nthe link prediction task and introduces $\\textbf{LPNL}$ (Link Prediction via\nNatural Language), a framework based on large language models designed for\nscalable link prediction on large-scale heterogeneous graphs. We design novel\nprompts for link prediction that articulate graph details in natural language.\nWe propose a two-stage sampling pipeline to extract crucial information from\nthe graphs, and a divide-and-conquer strategy to control the input tokens\nwithin predefined limits, addressing the challenge of overwhelming information.\nWe fine-tune a T5 model based on our self-supervised learning designed for link\nprediction. Extensive experimental results demonstrate that LPNL outperforms\nmultiple advanced baselines in link prediction tasks on large-scale graphs.",
        "author": "Baolong Bi, Shenghua Liu, Yiwei Wang, Lingrui Mei, Xueqi Cheng",
        "link": "http://arxiv.org/abs/2401.13227v3",
        "category": [
            "cs.CL",
            "cs.AI",
            "cs.LG",
            "cs.SI"
        ],
        "additionl_info": ""
    },
    "latex_extraction": {
        "content": {
            "section 1": {
                "name": "Introduction",
                "content": "\n\n% The emergence of large language models (LLMs) has elevated the field of natural language processing to unprecedented levels. By designing and fine-tuning with various prompts, LLMs adeptly integrate diverse knowledge domains to tackle the complexities of non-traditional languages. Recently, numerous researchers have been exploring the use of language models to address problems on graphs. Traditional approachs generally utilise LLMs to encode the textual information of the nodes into feature vectors, and then aggregate the encoded features through message passing in Graph Neural Networks (GNNs). However, this approach is influenced by the compatibility between the two models and often fails to fully leverage the immense capabilities of large-scale models.\n\n% Therefore, attempting to solve graph problems solely using language models without GNNs represents a novel approach. The central concept involves transforming graph problems and structures into textual format, enabling extensive language models to effectively address the task. Some studies have recognised this on the node classification task, but they overlook the means to effectively describe larger and more complex graphs to LLMs. Consider link prediction on a large-scale graph: as the number of candidate nodes for prediction grows, so does the text fed into LLMs. And due to token length limitations, extensive inputs become unfeasible. \n\n% \\begin{figure}[h]\n%     \\centering\n%     \\includegraphics[width=0.5\\textwidth]{link_prediction.png}\n%     \\caption{Link Prediction on Heterogeneous Graphs}\n%     \\label{fig:fig1}\n% \\end{figure}\n\n% Large-scale heterogeneous graphs(LSHGs) can be considered as networks of connections that resemble the real world more closely than conventional graph structures, such as social network or academic networks. Hence, this paper pay attention to the more realistic task of link prediction on large-scale heterogeneous graphs. This task presents greater challenges due to the significantly large and undetermined number of candidate nodes, as opposed to the node classification task. The key challenges as follows: 1)How to formulate the link prediction problem into a textual format so that it can be well understood by large models. 2)How to find out crucial information on LSHGs, enabling LLMs to capture it within limited inputs. 3) How to address lengthy prompts generated by an excess of candidate nodes.\n\n% To tackle the above challenges, in this paper, we propose \\textbf{LPNL}(link prediction via natural language), a comprehensive framework to link prediction on large-scale graphs using language models. LPNL designs specific prompts for link prediction that express graph information in natural language, aiding better understanding by large language models. We also introduced a sampling and filtering pipeline that utilizes normalized degree-based heterogeneous subgraph sampling and personalized PageRank-based ranking. This process selects more crucial node information from the graph, ensuring that the model focuses more on these nodes. For a large number of candidate nodes, we utilize a divide-and-conquer method. We partition the original node set into multiple equally sized smaller sets, sequentially input them into the link prediction pipeline to obtain partial answers, and recursively reconstruct the candidate set to arrive at the final unique answer.\n\n% We conducted extensive experiments on the Open Academic Graph (OAG), one of the largest publicly available heterogeneous graphs with over 178 million nodes. Specifically, we divided the dataset by time and domain, and conducted self-supervised training on the OAG using LPNL. The results demonstrate that LPNL outperforms various state-of-the-art baselines, including various GNNs, significantly in performance.\n\nHeterogeneous graphs~\\cite{shi2016survey} are commonly employed for modeling complex systems, wherein entities of diverse types interact with each other via various relations. \nFigure \\ref{fig:fig1} shows the heterogeneous nodes and their relationships sourced from the Open Academic Graph (OAG)~\\cite{huang2020analysis}.\n% Large-scale heterogeneous graphs resemble real-world structures, such as social network~\\cite{robins2007introduction} or academic networks~\\cite{kong2019academic}. \nLink prediction~\\cite{zhang2018link, cai2021line} is a fundamental task in graph learning. \nHowever, due to the vast quantity of nodes and edges with their complex structure, addressing the link prediction task on large-scale heterogeneous graphs is challenging.  \n\n\n% The emergence of large language models (LLMs) has elevated the field of natural language processing to unprecedented levels~\\cite{devlin2018bert, raffel2020exploring, brown2020language}.\nRecently, some research~\\cite{fatemi2023talk, ye2023natural} has explored the use of large language models (LLMs) in graph learning. \nA popular paradigm of link prediction on graphs with LLMs is to transform graph problems and structures into description texts, and then feed the texts to LLMs to obtain the predictions. \nHowever, it remains under explored that how to perform scalable link prediction on large graphs through LLMs with the input window constraints, which poses serious challenges in capturing distant information and rich semantics.  \nAs the number of nodes increases, the text fed into LLMs grows. Consequently, extensive inputs become unfeasible due to token length limitations.\n% Figure \\ref{fig:fig1} shows two pipelines for link prediction~\\cite{daud2020applications, lichtenwalter2010new} based on Graph Neural Networks (GNNs) and LLMs. The former employs GNNs for graph learning, followed by a matcher to compute similarity to link predict~\\cite{zhang2018link, cai2021line}. Meanwhile, the latter generates textual prompts based on sampled subgraphs and utilizes LLMs for prediction.\n\n% In contrast to the conventional approach of GNNs that aggregate encoded features via message passing~\\cite{hamilton2017inductive, abu2019mixhop}, \\reminder{LLMs exhibit superior learning capabilities and enhanced flexibility~\\cite{tamkin2021understanding, liang2022holistic}. }\n\n% However, it remains under explored on how to effectively learn from larger and more complex graphs with LLMs, which poses high challenges to capturing distant information and richer semantics. \n\n\n\n\nIn this work, we explore the scalable link prediction with large language models on large-scale heterogeneous graphs. The key challenges can be described as follows: 1) how to fomulate the prompt template for scalable link prediction task. 2) how to find out crucial information on large graphs, enabling LLMs to capture it within limited inputs. 3) how to address lengthy prompts generated by an excess of candidate neighbors. To tackle the above challenges, we propose \\textbf{LPNL} (\\textbf{L}ink \\textbf{P}rediction via \\textbf{N}atural \\textbf{L}anguage), a large language model based framework for scalable link prediction on large-scale graphs. \n\n\nWe design novel prompts for link prediction that articulating graph details in natural language. This involves establishing a selective query prompt template, furnishing a description of the link prediction task, and integrating heterogeneous information concerning the source node and candidate neighbors.\n\nIn dealing with vast amounts of relevant graph information within large graphs, LPNL selects crucial node information from the graph, ensuring that the model focuses more on them. We design a two-stage sampling pipeline that utilizes normalized degree-based heterogeneous subgraph sampling and personalized pagerank-based ranking. This approach avoids the interference of superfluous contextual information while ensuring compliance with specified token limitations. \n\n\n\n\n\nWith a large number of candidate neighbors, the token length constraints make it challenging to fully describe all candidate neighbor information.\nTo address this issue, we employ a divide-and-conquer method. The original node set is partitioned into multiple sets with smaller size, which are sequentially input into the link prediction pipeline to obtain partial answers. \nSubsequently, we recursively refine the candidate set to predict the final answer.\n\nWe conduct extensive experiments on the OAG and fine-tune the language model T5~\\cite{raffel2020exploring} based on our self-supervised learning to serve as the backbone model for LPNL on the OAG . \nThe results demonstrate that LPNL significantly outperforms various enhanced GNN-based baselines, achieving an average improvement of 30.52\\% on Hits@1. \nFurthermore, through extensive experimentation, LPNL also exhibits remarkable few-shot capability. \nUnlike traditional models training, LPNL's fine-tuning merely requires simple alignment formatting, enabling swift convergence in predictions. \nAdditionally, experiments demonstrate the model's robust knowledge transferability, maintaining consistent performance across various cross-domain tasks. \nThis further emphasizes that LPNL's self-supervised fine-tuning is not confined to fixed graph labels, it can make direct predictions on different graphs without the need for additional learning.\n\n\n"
            },
            "section 2": {
                "name": "The LPNL Architecture",
                "content": "\nIn this section, we introduce the details of our proposed \\textbf{L}ink \\textbf{P}rediction via \\textbf{N}atural \\textbf{L}anguage, i.e. \\textbf{LPNL}, a framework utilizing natural language to solve link prediction task on large-scale \nheterogeneous graphs. \nWe start with the notation setup, followed by the prompt design, the sampling methods, and our divide-and-conquer and self-supervised strategy with more details.\n\n",
                "subsection 2.1": {
                    "name": "Preliminary",
                    "content": "\nFormally, a heterogeneous graph is denoted by $\\mathcal{G} = \\{\\mathcal{V}, \\mathcal{E}, \\mathcal{A}, \\mathcal{R}\\} $, where $\\mathcal{V}$ and $\\mathcal{E}$ denote the sets of nodes and edges (links), respectively. \nEach node $v\\in\\mathcal{V}$ and each link $e\\in\\mathcal{E}$ are associated with their mapping function $\\phi(v):v\\rightarrow \\mathcal{A}$ and $\\varphi(e):e\\rightarrow \\mathcal{R}$. \n$\\mathcal{A}$ represents the set of node types, and $\\mathcal{R}$ represents the set of edge types. \n\nGiven a source node $s$ and a set of candidate neighbors $\\mathcal{C}=\\{c_1, c_2, ..., c_n\\}$, satisfying a existed meta-relation $\\langle \\phi(s), \\varphi(e), \\phi(c_i) \\rangle$ where $e \\in \\mathcal{E}$ and $c_i \\in \\mathcal{C}$, a standard link prediction task on heterogeneous graphs aims to predict a candidate neighbor $c \\in \\mathcal{C}$ for a source node $s$ with the highest probability of $\\langle s, e, c\\rangle$.\n\nFinally, let $\\mathcal{G}_{sub}^h(v) = \\{\\mathcal{V}_v^h, \\mathcal{E}_v^h, \\mathcal{A}_v^h, \\mathcal{R}_v^h\\}$ denote the $h$-hop ego-subgraph around $v$, consisting of $h$-hop neighbor nodes of $v$ and all interconnecting edges.\nWe also denote $\\mathcal{N}^h(v)$ as the set of all neighbor nodes on $\\mathcal{G}_{sub}^h(v)$, which means $\\mathcal{N}^h(v) = \\{v'\\vert v' \\in \\mathcal{V}_v^h,v'\\neq v\\}$.\nAdditionally, $\\mathcal{AN}^h_k(v)$ is denoted as the sequence of top-$k$ anchor nodes selected from $\\mathcal{N}^h(v)$. Note that all the above definitions are heterogeneous.\n\n"
                },
                "subsection 2.2": {
                    "name": "Prompt Design for Link Prediction",
                    "content": "\\label{subsec:prompt}\nIn order to comprehensively represent the link prediction task along with the essential graph information, we meticulously design a uniform prompt template $\\mathcal{T}(\\cdot)$ for heterogeneous link prediction.\nIts fundamental mode involves a selective query, providing both the link prediction problem description and information regarding the source node and candidate neighbors. This prompts the large language models to identify the node most likely to be linked within the candidate set.\n\nFirst, we define $d(v)$ as the description of node $v$, which consists of a sequence of textual features of itself and also its top-$k$ anchor nodes:\n% \\begin{equation}\n%     d(v) = \\mathcal{S}(v) + \\sum_{i=1}^k\\mathcal{S}(v'_i \\vert v'_i \\in \\mathcal{AN}^h_k(v))\n% \\end{equation}\n\\begin{equation}\\label{eq:eq1}\n    d(v) = \\{v: \\mathcal{S}_v\\} \\text{ is related with } \\sum_{i=1}^k\\{v'_i:\\mathcal{S}_{v'_i}\\}\n\\end{equation}\nwhere $\\mathcal{S}_v$ denotes the textual description of node $v$ and $v'_i$ represents the anchor node of node $v$ satisfying $v'_i \\in \\mathcal{AN}^h_k(v)$. \n\nSubsequently, given a source node $s$ and the set of candidate neighbors $\\mathcal{C}$, we formally obtain the link prediction prompt template as follows:\n\\begin{equation}\\label{eq:eq2}\n    \\mathcal{T}(s, \\mathcal{R}, \\mathcal{C}) = q(\\mathcal{R}) + d(s) + \\sum_{i=1}^n d(c_i\\vert c_i \\in \\mathcal{C})\n\\end{equation}\nwhere $\\mathcal{R}$ is the relation type between the source node and  candidate neighbors and $n$ is the number of candidate neighbors.\nAnd $q(\\mathcal{R})$ represents a link prediction query, e.g., \"which $\\phi(c)$ is linked by $\\phi(u)$?\". Notably, in the above equation, the addition operators are redefined as the textual concatenation with separators. \n\n\n\nTo enhance the capability of the large language models in distinguishing between various types of heterogeneous nodes, we additionally assign distinct type identifiers to the backend of each node. For example, a paper node could be described as \"<p>[PA]\". Following the formal definition provided above, Figure \\ref{fig:fig3} illustrates a more intuitive prompt example for author disambiguation.\n\nOur designed prompts do not explicitly capture the link information between nodes in the graph. Instead, we choose to describe key nodes in textual form based on their order of importance.\nThis decision arises from the complexity of inter-node connections, which often result in redundant contexts~\\cite{fatemi2023talk}, making it challenging for large language models to comprehend. \nConsequently, there is a risk of LLMs diminishing the emphasis on node features, which are pivotal for our tasks. Nonetheless, the links among heterogeneous nodes remain crucial as they reflect their relationships and node significance. \nIn following Sec.\\ref{subsec:two-stage sampling}, we introduce a two-stage sampling approach to leverage structural information, prioritizing critical nodes and thereby enhancing the description of graph information.\n\n\n\n"
                },
                "subsection 2.3": {
                    "name": "Two-Stage Sampling",
                    "content": "\\label{subsec:two-stage sampling}\nIn the previous subsection, we designed the unified prompt template for link prediction. However, as graph data becomes more complex, resembling the real world, employing a single prompt engineering approach becomes challenging in addressing practical application problems. \nFirstly, in large-scale graphs, attempting to describe the node information of $v$ using all $h$-hop neighbors, i.e. $k=\\lvert\\mathcal{V}_v^h\\rvert$ formally, as shown in Eq.(\\ref{eq:eq1}), leads to an uncontrollable prompt length.\nAnothor issue arises due to substantial variations in the degrees of different node types. For example, the number of nodes in the $h$-hop subgraph around a paper node is significantly smaller than that around a field-type node. The two problems pose significant challenges to the input and contextual comprehension of LLMs.\n\nIn this work, we provide a two-stage sampling pipeline. The first stage aims to sample subgraphs $\\mathcal{G}_{sub}^h(v)$ based on normalized degree from large-scale heterogeneous graphs while mitigating sampling bias caused by heterogeneous types. Subsequently, we obtain the top-$k$ anchor nodes sequence $\\mathcal{AN}^h_k(v)$ through the second stage sampling with personalized pagerank to generate $d(v)$ in Eq.(\\ref{eq:eq1}). The further details are as follows.\n\n\\noindent\\textbf{Normalized Degree based Sampling} Inspired by previous studies ~\\cite{hu2020heterogeneous, leskovec2006sampling}, we adopt a strategy for sampling heterogeneous subgraphs based on normalized degree. Specifically, this approach specifies the sampling probability of each hop's neighbors as their normalized degree. The normalized degree is defined as the node's degree normalized among all nodes of the same type in the same layer. Therefore, for the $l$-th layer subgraph sampling around central node $s$, the sampling probability of node $v$ can be described as follows:\n\\begin{equation}\n    prob^{l}_s(v)=\\frac{deg(v)^2}{\\sum{deg(u)^2}}\n\\end{equation}\nwhere node $u$ represents the neighbor node at the $l$-th layer within the subgraph, satisfying $u\\in\\mathcal{V}_s^h\\setminus\\mathcal{V}_s^{h-1}$ and $ \\phi(v)=\\phi(u)$.\n\nThe normalized degree based sampling in our first stage ensures that differences between node types are not ignored, preventing bias against certain node types (e.g., nodes with higher degrees are not indiscriminately considered more important). \nThis approach maintains a similar number of different types of nodes in the subgraphs, thereby preserving richer semantic information. \nFurthermore, previous studies have demonstrated that leveraging up to 3-hop connectivity is effective for achieving excellent performance~\\cite{kipf2016semi, velivckovic2017graph, hamilton2017inductive}. However, extending the information beyond 3-hop generally has a marginal impact on improvement and, in some cases, may even result in negative effects~\\cite{cai2020note, zhang2021evaluating}. Therefore, we set the maximum value for multi-hop to 2-hop or 3-hop in our two-stage sampling approach.\n\n\n\\noindent\\textbf{Sampling with Personalized PageRank} Through the sampling in the first stage, the heterogeneous subgraphs we obtain eliminate biases between different types, allowing all types of nodes to be compared regarding their importance on an equal footing. In the second stage, we directly compute the importance of all neighbor nodes within the subgraph $\\mathcal{G}_{sub}^h(v)$ for the source node $s$ using Personalized PageRank (PPR)~\\cite{bojchevski2020scaling, vattani2011preserving}. We then obtain the PPR vector $\\vec{\\pi_s}$ for the source node $s$ by iteratively updating the following:\n\\begin{equation}\n    \\vec{\\pi_s}=\\alpha * \\vec{e_s} + (1-\\alpha) * A^{\\top} D^{-1}\\vec{\\pi_s}\n\\end{equation}\nwhere $\\alpha$ denotes the damping factor, $A$ stands for the adjacency matrix, $D^{-1}$ denotes the diagonal degree matrix and $\\vec{\\pi_s}$ signifies the unit vector.\n\nThis work employs a queue-based implementation of the equivalent random walk \\cite{spitzer2013principles, wu2021unifying} to approximate PPR. Subsequently, the top-$k$ anchor nodes sequence $\\mathcal{AN}^h_k(s)$ is obtained based on the ranking derived from PPR, which characterizes the top-$k$ neighbor nodes that are most critical for the source node $s$ within the whole hetero-graph.\n\nThe two-stage sampling restricts the generated link prediction prompt length to suit LLMs inputs while maximizing the retention of crucial neighborhood information pertaining to the target node within the subgraphs. It also makes use of the structural information on the graph, so that the generated anchor nodes $\\mathcal{AN}^h_k(s)$ can be seen as a hub converting the graph structure into textual descriptions. This enables our prompts generated in Sec.\\ref{subsec:prompt} to encompass not only node features but also implicit structural information.\n\n\n\n\n\n"
                },
                "subsection 2.4": {
                    "name": "Divide-and-Conquer Prediction",
                    "content": " \\label{subsec:Divide-and-conquer}\nWhile the sampling pipeline addresses the potential issue of prompts length caused by Eq.(\\ref{eq:eq1}), a careful observation of Eq.(\\ref{eq:eq2}) reveals that an excessive number of candidate neighbors in link prediction, denoted as $\\vert\\mathcal{C}\\vert$, also makes the prompt length uncontrollable. Especially in large-scale graphs, the high number of candidate neighbors poses a challenge in describing all of them within a single LLM's input window. For instance, in a link prediction task with 100 candidate neighbors, each node requires an average of approximately 200 tokens in the prompt for description. This results in a total of 20,000 tokens needed to describe all candidate neighbors, far exceeding the maximum token limit for a usual LLM's input window. Furthermore, the excessive number of candidate neighbors leads to redundant contexts, making it challenging for the LLMs to comprehend the input text.\n\n\nLPNL avoids the aforementioned token overload by employing a divide-and-conquer strategy. Figure \\ref{fig:fig4} provides an intuitive example of the divide-and-conquer prediction, allowing us to observe the descent of candidate neighbors and prompt tokens throughout the process. We set a length limit $L$ for the candidate set, ensuring that the length of all processed candidate sets does not exceed $L$. We represent $\\mathcal{C}^i_j$ as the $j$-th candidate set of the $i$-th divide-and-conquer round. Specifically, for an original candidate set of length $\\vert\\mathcal{C}^0\\vert$ where $\\vert\\mathcal{C}^0\\vert > L$, we randomly divide it into $m$ sub-candidate sets, ensuring $m=\\lceil\\frac{\\vert\\mathcal{C}^{0}\\vert}{L}\\rceil$. This results in sets denoted as $\\mathcal{C}_{1}^1, \\mathcal{C}_{2}^1, ..., \\mathcal{C}_m^1$, with the constraint that $max(\\vert\\mathcal{C}_{1}^1\\vert, \\vert\\mathcal{C}_{2}^1\\vert, ..., \\vert\\mathcal{C}_m^1\\vert) \\leq L$. \n\nAs illustrated in Figure \\ref{fig:fig1}, by employing the fine-tuned large language models to predict the candidate neighbor of the source node with the maximum link probability for each sub-candidate set, we can subsequently eliminate low-probability candidate neighbors. And the process generates new candidate sets based on the predicted results by refining the candidate sets. Specifically, for the candidate sets $C_{j+1}^i, C_{j+2}^i, ..., C_{j+k}^i$, a new candidate set $C_{k'}^{i+1}$ is generated in the following round based on their prediction results. The values of $k$ and $k'$ are determined based on the order of generation, ensuring that the condition $k \\leq L$ is met. Following this divide-and-conquer process by refining candidate sets and making predictions, ultimately, we can obtain a unique prediction answer for the entire original candidate set $\\mathcal{C}^0$.   \n\n\n"
                },
                "subsection 2.5": {
                    "name": "Self-Supervised Fine-tuning",
                    "content": "\nAs a more relevant graph structure, large-scale graphs lack labelled data.\nLPNL uses self-supervised learning for large language model fine-tuning. During the end-to-end prompt fine-tuning, it automatically constructs a candidate set containing ground truth, aligned with downstream prediction formats. The ground truth is used as the correct answer for link prediction. To ensure training correctness, the ground truth appears randomly within the candidate neighbor sequence. Notably, during the heterogeneous subgraph sampling process in Sec.\\ref{subsec:two-stage sampling}, the edges between the ground truth and the source node are masked. Because the self-supervised fine-tuning does not require training labels provided by graph tasks, a fine-tuned LPNL model can make direct predictions on different graphs without the need of extra tuning.\n\n\n\n"
                }
            },
            "section 3": {
                "name": "Experiments",
                "content": "\n",
                "subsection 3.1": {
                    "name": "Experiment Settings",
                    "content": "\n\n\n\\textbf{Models}\nWe fine-tune T5-base model~\\cite{chung2022scaling} with a 1024 input window constraint as the backbone language model for our LPNL. The numbers of sampling hops $h=2$, top anchor nodes sequence $k=50$, and candidate length limit $L=3$ are used for all following experiments.\n\\\\\n\\textbf{Datasets}\nWe conducted all experiments on the OAG, known as one of the largest publicly available heterogeneous graphs, comprising 178 million nodes and 2.236 billion edges. It includes five types of nodes (denoted as papers (P), authors (A), venues (V), institutes (I) and fields (F)) and their interrelations. In our specific experiments, we utilized four representative domain-specific subgraphs from OAG: Computer Science (CS), Material Science (Mater), Engineering (Engin) and Chemistry (Chem)~\\cite{jiang2021pre}. The graph statistics are listed in Table \\ref{tab:stat}. We partition each dataset into fine-tuning, validation, and test sets based on distinct time periods. Specifically, in the OAG dataset, papers are published between 1900 and 2019. Consequently, we utilize publications preceding 2015 for fine-tuning, data from 2015 to 2016 for validation, and information from 2016 onwards for testing.\n\\\\\n\\textbf{Task}\nWe consider real-world link prediction tasks to evaluate the performance of our LPNL, specifically, author name disambiguation~\\cite{ferreira2012brief}. Author name disambiguation is a fundamental challenge for curating academic publication and author information, as duplicated names are common. The objective is to predict the true author who has a genuine link with a given paper among all authors with the same name.\n\\\\\n\\textbf{Baselines}\nWe select a series of supervised baselines, all of which are advanced graph neural network models. These include GCN~\\cite{li2018deeper}, GraphSage~\\cite{hamilton2017inductive} and GAT~\\cite{velivckovic2017graph}, designed for homogeneous graphs, as well as RGCN~\\cite{schlichtkrull2018modeling} and HGT~\\cite{hu2020heterogeneous}, tailored for heterogeneous graphs.\n\n"
                },
                "subsection 3.2": {
                    "name": "Overall Performance",
                    "content": "\n\nIn this experiment, we compare the T5 model as the backbone version of LPNL to advanced GNN based baseline models across the four domain-specific subgraphs. We fine-tune the model separately across various subgraphs and evaluate the performance of the models in link prediction. The experimental results of the proposed method and baselines are summarized in Table \\ref{tab:result}. All experiments for the author name disambiguation task over all datasets are evaluated in terms of NDCG, MRR and Hits@1~\\cite{li2022learning, liu2009learning}.\n\nThe results show that in terms of all three metrics, the proposed LPNL significantly and consistently outperforms all baselines for all tasks on all datasets. Overall, our LPNL consistently yields the best performance among all methods, leading to an average improvement of 6.93\\%, 15.92\\% and 30.52\\%, compared to the second best baseline method. Surprisingly, LPNL exhibited significant improvements in all settings, particularly in the Hit@1 metric. The substantial leap in achieving correct predictions with just a single attempt holds significant implications for practical applications. These improvements over GNNs indicate the efficacy of our proposed LPNL in enabling large language models to comprehend link prediction tasks within complex graphs and large language models have tremendous potential in addressing graph-related problems.\n\n\n\n\n"
                },
                "subsection 3.3": {
                    "name": "Cross-Domain Knowledge Transfer",
                    "content": "\nTo explore the generalization capabilities of LPNL, we set up experiments for cross-domain knowledge transfer. Specifically, we fine-tune the T5 model using LPNL on a graph corresponding to one domain and subsequently conducted testing on subgraphs from other domains. The experimental outcomes, visualized in Figure \\ref{fig:cross_domain} as a heatmap, reveal that in most instances, the model exhibits optimal performance when fine-tuned within its original domain. Surprisingly, the models fine-tuned on other domains also demonstrate remarkably strong performance, often closely matching or even surpassing the best performance achieved by fine-tuning within the original domain (e.g., Mater-Engin). This highlights the robust knowledge transferability of our approach, which means it can make direct predictions on different graphs without the need for additional learning.\n\n\n\n"
                },
                "subsection 3.4": {
                    "name": "Few-Shot Learning",
                    "content": "\nThe extensive pretraining of large language models across various natural language tasks has endowed them with robust reasoning and generalization capabilities. In contrast to traditional GNN models, they require minimal training samples to converge and exhibit superior performance. We further investigates the few-shot learning capabilities of LPNL by comparing it with the top-performing homogeneous GNN and heterogeneous GNN in terms of overall performance. We configure the evaluate results to be printed every 1 batch, with each batch consisting of 50 link prediction tasks. We compare the few-shot results for the first 20 batches. The results in Table \\ref{fig:few-shot} demonstrate that our LPNL swiftly converges with minimal sample fine-tuning, displaying comparable performance to the best fine-tuning outcomes. This showcases the portability of large language models in addressing graph-related tasks.\n\n\n\n\n% \\subsection{Zero-shot with chatGpt}\n% To further assess the zero-shot capability of LPNL, we conducte experiments using the chatGPT 3.5 turbo model for zero-shot inference. To minimize the potential influence of ground truth-related knowledge learned during chatGPT's pretraining, we utilize prompts that did not include any graph-related knowledge for comparison. As depicted in Figure 4, chatGPT with graph demonstrates promising overall performance without specific task learning. In particular, in the Author ND task, there is a significant disparity compared to fine-tuned T5. However, in the paper-field and paper-venue tasks, it only shows a minor performance lag, even displaying a significant lead across multiple datasets in the paper-venue task. This can be attributed to the robust reasoning capabilities and relevant priors obtained during chatGPT's pretraining.\n\n% Furthermore, through the comparison between chatGPT without graph and chatGPT with graph, we observe that in the author ND task, LPNL's provided graph knowledge notably assists chatGPT in predictions. However, in the paper-field task, the effect is reversed, indicating that even chatGPT without specific fine-tuning struggles to effectively utilize the provided graph information, thus interfering with its original priors and resulting in decreased performance.\n\n\n\n\n\n"
                },
                "subsection 3.5": {
                    "name": "Ablation Study",
                    "content": "\n\nWe conduct an ablation study on CS dataset to evaluate the effectiveness of our approach in employing large language models combined with graph knowledge strategies. We compare the performance among different versions of sampling methods: the standard LPNL, a version without any graph information, and another two sampling versions, each independently utilizing distinct stages. \nAs illustrated in Table \\ref{tab:ablation1}, the model's performance significantly diminishes when graph information is excluded. Furthermore, the performance of the versions without stage 1 and stage 2 shows a notable gap compared to LPNL. It \nindicates that employing our designed two-stage sampling pipeline enables LPNL to capture crucial information within the graph after balanced heterogeneous sampling, resulting in improved predictive outcomes.\n\n\n\n\nIn our experiments, two critical operations contributing significantly to the outstanding performance of LPNL in link prediction are 2-hop and anchor nodes, which provide essential information to the LLMs. To assess the impact of these two key components on model performance, we conducted another ablation experiments, and the results are presented in Table \\ref{tab:ablation2} and \\ref{tab:ablation3}. It shows that incorporating multi-hop and more anchor nodes information can both enhance the LPNL's performance. However, further experiments indicate that increasing the number of hops and anchor nodes beyond a certain threshold does not lead to significant performance improvement. On the contrary, it may result in additional costs without notable benefits.\n\n\n\n\n"
                }
            },
            "section 4": {
                "name": "Related Work",
                "content": "\n\n\\noindent\\textbf{Graph Representation Learning Based on GNNs}\nGraph Neural Networks (GNNs) are the forefront of graph representation learning methods and have gained significant popularity across a range of graph-related tasks~\\cite{wu2020comprehensive,zhou2020graph}. In these tasks, such as node classification and link prediction, GNNs-based approaches usually preprocess the corresponding text by a language model and encode the resulting embedding as node features. The final node representation is then obtained by aggregating the neighborhood features through spectral methods~\\cite{bruna2013spectral,defferrard2016convolutional} and message passing~\\cite{abu2019mixhop,hamilton2017inductive,schlichtkrull2018modeling}. Besides, some studies have attempted to propose the GNNs architectures on heterogeneous graphs~\\cite{dong2020heterogeneous,wang2019heterogeneous, hu2020heterogeneous}. Notably, influenced by large language models, recent studies~\\cite{sun2023all, huang2023prodigy}have explored the potential of GNNs in prompt learning. And there have also been attempts~\\cite{ioannidis2022efficient, zhao2022learning} to explore collaborative training between Language Models and GNNs.\n\n\n\n\n\\noindent\\textbf{Large Language Models with Graph Knowledge}\nThe emergence of large language models (LLMs) has propelled natural language processing (NLP) to new heights.~\\cite{qiu2020pre}. For example, models like BERT~\\cite{devlin2018bert} and T5~\\cite{raffel2020exploring} demonstrate excellent performance in a wide range of downstream tasks, such as text classification and question answering. Besides, some works ~\\cite{zhang2019ernie, liu2022oag, liu2020k}attempts to inject external graph knowledge into LLMs, thus enabling LLMs to gain the ability to solve problems on graphs. Recently, due to the powerful inferential capabilities of large language models, a burgeoning body of work~\\cite{fatemi2023talk, ye2023natural, liu2023one} attempt to utilize natural language descriptions of graph features, employing generated prompts to instruct large language models in addressing various problems on graphs.\n\n"
            },
            "section 5": {
                "name": "Discussion",
                "content": "\nFrom our experiments, we found that describing graphs using natural language does not follow the principle of \"more information is better\". Sampling more nodes can introduce additional information, but it may lead to information redundancy, resulting in a decline in the inferential capabilities of large language models. Therefore, the key lies in the setting of the sampling and divide-and-conquer length limits, which should align with the input window size and inferential capabilities of the large language models.\nWhile designing prompts, we observe that complex relationships between nodes are challenging to articulate in text, especially in large or dense graphs, potentially leading to redundant contexts. LPNL leverages structural information during the sampling phase and, in the prompt generation, only conveys information about the sampled nodes. This approach aims to minimize context redundancy while maximizing the utilization of graph information.\n\n"
            },
            "section 6": {
                "name": "Conclusion",
                "content": "\nIn this paper, we explore, for the first time, the application of large language models to address the link prediction task on large-scale heterogeneous graphs. We introduce LPNL, a large language models based framework for scalable link prediction on large-scale graphs. We design specific prompt templates for the link prediction task and generate the prompts based on anchor nodes obtained through a two-stage sampling approach. These prompts are then input to the large language models for predictions. To tackle the token overload issue arising from an excessive number of candidate neighbors, we employ a divide-and-conquer strategy. Empirical evaluations demonstrate that LPNL achieves significant improvements compared to GNN baselines, showcasing its robust capability in cross-domain knowledge transfer and few-shot learning scenarios.\n\n"
            },
            "section 7": {
                "name": "Limitations",
                "content": "\nSome efforts in solving graph-related problems using LLMs involve supervised fine-tuning, resulting in limited ability for knowledge transfer. Although LPNL supports unsupervised learning without the need for labels, it is currently confined to link prediction tasks and has not been applied to a broader spectrum of graph-related tasks. LPNL has not yet explored larger parameter scales for large language models and their zero-shot potentials, which could provide increased input window sizes and enhanced inferential capabilities. Integrating our approach with other graph tasks and larger language models holds the potential to significantly improve predictive capabilities.\n\n"
            },
            "section 8": {
                "name": "Ethics Statement",
                "content": "\nEthical considerations are of utmost importance in our research endeavors.  In this paper, we conscientiously adhere to ethical principles by exclusively utilizing open-source datasets and employing models that are either open-source or widely recognized in the scientific community.  Moreover, our proposed method is designed to ensure that the model does not produce any harmful or misleading information.  We are committed to upholding ethical standards throughout the research process, prioritizing transparency, and promoting the responsible use of technology for the betterment of society.\n\n% \\section*{Acknowledgements}\n\n\n% Entries for the entire Anthology, followed by custom entries\n\\bibliography{anthology,custom}\n\\bibliographystyle{acl_natbib}\n\n% \\appendix\n\n% \\section{Example Appendix}\n% \\label{sec:appendix}\n\n% This is a section in the appendix.\n\n"
            }
        },
        "tables": {
            "tab:stat": "\\begin{table*}[th]\n\\centering\n\\renewcommand\\arraystretch{1.2}\n\\resizebox{\\textwidth}{!}{%\n\\begin{tabular}{c|cc|ccccc|ccccc} \n\\toprule\nDataset & $\\#$nodes & $\\#$edges & $\\#$papers & $\\#$authors & $\\#$fields & $\\#$venues & $\\#$institutes & $\\#$P-A & $\\#$P-F & $\\#$P-V & $\\#$A-I & $\\#$P-P \\\\ \n\\midrule\nCS & 11,918,983 & 107,263,811 & 5,597,605 & 5,985,759 &  119,537&  27,433 & 16,931   & 15,571,614 & 47,462,559 & 5,597,606 & 7,190,480 & 31,441,552\\\\\n\\midrule\nMater & 4,552,941 & 42,161,581 & 2,442,235 & 2,005,362&  79,305 &  15,141&  10,898  &5,582,765 & 19,119,947&2,442,235 & 2,005,362& 13,011,272\\\\\n\\midrule\nEngin & 5,191,920 & 36,146,719  & 3,239,504 & 1,819,100 &  99,444&  19,867&  14,005 & 3,741,135&  22,498,822&  3,239,504&  1,819,100 & 4,848,158\\\\\n\\midrule\nChem & 12,158,967 & 159,537,437  & 7,193,321 & 4,748,812 &  183,782&  19,142&  13,910 & 16,414,176&  57,162,528&  7,193,321&  4,748,812 & 74,018,600\\\\\n\\bottomrule\n\\end{tabular}%\n}\n\\caption{OAG statistics.} \n\\label{tab:stat} \n\\end{table*}",
            "tab:result": "\\begin{table*}[t]\n\\centering\n\\small\n\\renewcommand\\arraystretch{1.5}\n\\setlength{\\tabcolsep}{7pt}\n\\begin{tabular}{c||c||ccccc||c||l} \n\\toprule\n\\midrule\n{Dataset} & {Metric} & GraphSage  & HGT & RGCN & GCN  & GAT & LPNL & \\ \\ \\ \\ \\ \\ $\\Delta$% & LPNL-LLama \n\\\\ \\midrule\n\n    \\multirow{3}{*}{\\makecell{CS}} \n        ~  & NDCG &.814$\\pm$.025 & .847$\\pm$.042& .843$\\pm$.056&.887$\\pm$.031 & .911$\\pm$.033 & \\textbf{.985$\\pm$.008} & $\\uparrow 8.12\\%$\\\\ ~& MRR &.640$\\pm$.045&.712$\\pm$.024 & .685$\\pm$.056 &.727$\\pm$.032 & .797$\\pm$.051 &\\textbf{.939$\\pm$.018} &$\\uparrow17.81\\%$ \\\\~  & Hits@1 &.469$\\pm$.012 & .562$\\pm$.022& .532$\\pm$.056&.568$\\pm$.011 & .686$\\pm$.014 & \\textbf{.894$\\pm$.004} & $\\uparrow 30.32\\%$% & \\textbf{.894$\\pm$.034} \n        \\\\\\midrule\n    \\multirow{3}{*}{\\makecell{Mater}} \n        ~  & NDCG &.765$\\pm$.017 & .841$\\pm$.034& .854$\\pm$.042&.818$\\pm$.016 & .897$\\pm$.065 & \\textbf{.954$\\pm$.014} & $\\uparrow6.35\\%$\\\\ ~& MRR &.519$\\pm$.052&.643$\\pm$.031 & .665$\\pm$.027 &.667$\\pm$.036 & .747$\\pm$.058 &\\textbf{.881$\\pm$.011} & $\\uparrow17.93\\%$ \\\\~  & Hits@1 &.278$\\pm$.016 & .447$\\pm$.019& .476$\\pm$.028&.524$\\pm$.032 & .597$\\pm$.018 & \\textbf{.809$\\pm$.007} & $\\uparrow35.51\\%$%  & \\textbf{.894$\\pm$.021} \n        \\\\\\midrule\n    \\multirow{3}{*}{\\makecell{Engin}} \n        ~  & NDCG &.798$\\pm$.021 & .876$\\pm$.022& .874$\\pm$.061&.912$\\pm$.041 & .913$\\pm$.037 & \\textbf{.977$\\pm$.017} &$\\uparrow7.01\\%$ \\\\ ~& MRR &.570$\\pm$.027&.691$\\pm$.041 & .699$\\pm$.034 &.747$\\pm$.023 & .769$\\pm$.041 &\\textbf{.917$\\pm$.017} &$\\uparrow16.14\\%$\n        \\\\~  & Hits@1 &.342$\\pm$.023 & .506$\\pm$.018& .523$\\pm$.056&.583$\\pm$.021 & .624$\\pm$.011 & \\textbf{.858$\\pm$.012} & $\\uparrow37.50\\%$ %  & \\textbf{.894$\\pm$.004} \n        \\\\\\midrule\n    \\multirow{3}{*}{\\makecell{Chem}} \n        ~  & NDCG &.821$\\pm$.015 & .863$\\pm$.015& .835$\\pm$.036&.893$\\pm$.017 & .899$\\pm$.023 & \\textbf{.955$\\pm$.018} &$\\uparrow 6.23\\%$\\\\ ~& MRR &.649$\\pm$.034&.724$\\pm$.027 & .678$\\pm$.031 &.749$\\pm$.023 & .780$\\pm$.029 &\\textbf{.872$\\pm$.038} &$\\uparrow11.79\\%$ \\\\~  & Hits@1 &.485$\\pm$.024 & .523$\\pm$.031& .530$\\pm$.016&.609$\\pm$.020 & .667$\\pm$.022 & \\textbf{.792$\\pm$.007} &$\\uparrow18.74\\%$% & \\textbf{.894$\\pm$.014} \n        \\\\\n        \n\\midrule\n\\bottomrule\n\n\\end{tabular}\n\n\\caption{Experimental results of different methods over the four datasets.} \n\\label{tab:result} \n\\end{table*}",
            "tab:ablation1": "\\begin{table}[ht]\n\\centering\n\\small\n\\renewcommand\\arraystretch{1.1}\n\\setlength{\\tabcolsep}{5pt}\n\\begin{tabular}{lccc} \n\\toprule\n \\textbf{Method} & \\textbf{NDCG}  & \\textbf{MRR} & \\textbf{Hits@1}\\\\ \\midrule \n LPNL & \\textbf{97.86} & \\textbf{94.37} & \\textbf{89.47} \\\\\n \\midrule\n w/o Graph Info & 68.98 & 50.51 & 35.97 \\\\ \n w/o Stage 1 & 76.31 & 57.29 & 41.83  \\\\ \n w/o Stage 2 & 87.67 & 70.67 & 53.33  \\\\ \n\\bottomrule\n\\end{tabular}\n\\caption{Ablation study results of sampling methods.} \n\\label{tab:ablation1} \n\\end{table}",
            "tab:ablation2": "\\begin{table}[ht]\n\\centering\n\\small\n\\renewcommand\\arraystretch{1.1}\n\\setlength{\\tabcolsep}{5pt}\n\\begin{tabular}{cccc} \n\\toprule\n \\ \\textbf{Hop} & \\textbf{NDCG}  & \\textbf{MRR} & \\textbf{Hits@1}\\\\ \\midrule \n 2-hop & \\textbf{97.86} & \\textbf{94.37} & \\textbf{89.47} \\\\ \n 1-hop & 94.15 & 91.56 & 85.09 \\\\ \n\n\\bottomrule\n\\end{tabular}\n\\caption{Ablation study results of multi-hop sampling.} \n\\label{tab:ablation2} \n\\end{table}",
            "tab:ablation3": "\\begin{table}[ht]\n\\centering\n\\small\n\\renewcommand\\arraystretch{1.1}\n\\setlength{\\tabcolsep}{5pt}\n\\begin{tabular}{cccc} \n\\toprule\n \\ \\textbf{\\#Anchor Nodes} & \\textbf{NDCG}  & \\textbf{MRR} & \\textbf{Hits@1}\\\\ \\midrule \n Top-30 & 92.86 & 76.48 & 62.05  \\\\ \n Top-50 & 97.86 & \\textbf{94.37} & \\textbf{89.47} \\\\ \n  Top-70 & \\textbf{98.06} & 93.84 & 88.69  \\\\ \n\\bottomrule\n\\end{tabular}\n\\caption{Ablation study results of top-k anchor nodes} \n\\label{tab:ablation3} \n\\end{table}"
        },
        "figures": {
            "fig:fig1": "\\begin{figure}[t]\n    \\centering\n    \\includegraphics[width=0.36\\textwidth]{Picture_HG.png}\n    \\caption{An example of heterogeneous graph}\n    \\label{fig:fig1}\n    \\vspace{-5mm}\n\\end{figure}",
            "fig:fig2": "\\begin{figure*}[t]\n  \\centering\n  \\includegraphics[width=0.95\\textwidth]{framework.png}\n  \\caption{The framework of LPNL. For an input heterogeneous graph with link prediction tasks, LPNL consists of three steps: (1) conduct a two-stage sampling on the source node and each candidate neighbor from the original candidate set to acquire anchor nodes. (2) Generate prompts based on these anchor nodes and input them into LLMs for predictions. (3) Refine the candidate set based on prediction results and iteratively apply this divide-and-conquer process to obtain the distinct link prediction result\n  $c^*$.}\n  \\label{fig:fig2}\n\\end{figure*}",
            "fig:fig3": "\\begin{figure}[ht]\n    \\centering\n\\begin{tcolorbox}[fonttitle=\\bfseries, title=Author Disambiguation Example, size = normal, label=mybox, center title]\n% \\textbf{Template:} <Query> <Source description> <Candidate descriptions>\n% \\tcbline\n\\textbf{prefix\\_question}: Which following candidate author writes the paper p$_{1}$?   \n\\tcbline\n\n\\textbf{source\\_node\\_description}: p$_{1}$: <\\textit{paper title}> is related with f$_{25}$: <\\textit{field name}>, v$_{13}$: <\\textit{journal info}>, p$_{46}$: <\\textit{paper title}>, a$_{38}$: <\\textit{author info}>, p$_{27}$: <\\textit{paper title}>...\n\\tcbline\n\n\\textbf{candidate\\_nodes\\_description}: a$_{1}$: <\\textit{author info}> is related with p$_{15}$: <\\textit{paper title}>...;\n \\ a$_{2}$: ...;  \\ a$_{3}$: ...\n\\end{tcolorbox}\n    \\caption{The prompt example consists of three components: prefix\\_question: a selective question; source\\_node\\_description: the description of the source node and its corresponding anchor nodes; candidate\\_nodes\\_description: the description of candidate neighbors and the anchor nodes corresponding to each candidate neighbor.}\n    \\label{fig:fig3}\n\\end{figure}",
            "fig:fig4": "\\begin{figure}[t]\n    \\centering\n    \\includegraphics[width=0.50\\textwidth]{divide.png}\n    \\caption{For a link prediction task involving 100 candidate neighbors, we set the candidate length limit $L$ to 5. The candidate neighbors can be divided into 20 sets, followed by three rounds of divide-and-conquer. This process ultimately yields a unique prediction result.}\n    \\label{fig:fig4}\n\\end{figure}",
            "fig:cross_domain": "\\begin{figure}[ht]\n    \\centering\n    \\includegraphics[width=0.5\\textwidth]{cross_domain.pdf}\n    \\caption{Cross-domain transfer results.}\n    \\label{fig:cross_domain}\n\\end{figure}",
            "fig:few-shot": "\\begin{figure}[ht]\n  \\begin{subfigure}{4cm}\n    \\centering\n    \\includegraphics[width=1\\linewidth]{fig_ab_ndcg.pdf}\n    \\label{fig:sub1}\n  \\end{subfigure}%\n  \\begin{subfigure}{4cm}\n    \\centering\n    \\includegraphics[width=1\\linewidth]{fig_ab_mrr.pdf}\n    \\label{fig:sub2}\n  \\end{subfigure}\n  \\vspace{-2.5em}\n  \\caption{LPNL converges fast in few-shot learning compared to GNNs.}\n  \\label{fig:few-shot}\n\\end{figure}"
        },
        "equations": {
            "eq:eq:eq1": "\\begin{equation}\\label{eq:eq1}\n    d(v) = \\{v: \\mathcal{S}_v\\} \\text{ is related with } \\sum_{i=1}^k\\{v'_i:\\mathcal{S}_{v'_i}\\}\n\\end{equation}",
            "eq:eq:eq2": "\\begin{equation}\\label{eq:eq2}\n    \\mathcal{T}(s, \\mathcal{R}, \\mathcal{C}) = q(\\mathcal{R}) + d(s) + \\sum_{i=1}^n d(c_i\\vert c_i \\in \\mathcal{C})\n\\end{equation}",
            "eq:1": "\\begin{equation}\n    prob^{l}_s(v)=\\frac{deg(v)^2}{\\sum{deg(u)^2}}\n\\end{equation}",
            "eq:2": "\\begin{equation}\n    \\vec{\\pi_s}=\\alpha * \\vec{e_s} + (1-\\alpha) * A^{\\top} D^{-1}\\vec{\\pi_s}\n\\end{equation}"
        }
    }
}