{
    "meta_info": {
        "title": "Disentangling Popularity and Quality: An Edge Classification Approach  for Fair Recommendation",
        "abstract": "Graph neural networks (GNNs) have proven to be an effective tool for\nenhancing the performance of recommender systems. However, these systems often\nsuffer from popularity bias, leading to an unfair advantage for frequently\ninteracted items, while overlooking high-quality but less popular items. In\nthis paper, we propose a GNN-based recommendation model that disentangles\npopularity and quality to address this issue. Our approach introduces an edge\nclassification technique to differentiate between popularity bias and genuine\nquality disparities among items. Furthermore, it uses cost-sensitive learning\nto adjust the misclassification penalties, ensuring that underrepresented yet\nrelevant items are not unfairly disregarded. Experimental results demonstrate\nimprovements in fairness metrics by approximately 2-74%, while maintaining\ncompetitive accuracy, with only minor variations compared to state-of-the-art\nmethods.",
        "author": "Nemat Gholinejad, Mostafa Haghir Chehreghani",
        "link": "http://arxiv.org/abs/2502.15699v1",
        "category": [
            "cs.IR"
        ],
        "additionl_info": ""
    },
    "latex_extraction": {
        "content": {
            "section 1": {
                "name": "Introduction",
                "content": "\n\t\\label{sec:introduction}\n\t\n\tRecommender systems have become a cornerstone of the digital experience,\n\tguiding users through vast amounts of content by suggesting items such as movies, books, or products based on their preferences.\n\tAs these systems have evolved,\n\tGraph Neural Networks (GNNs)~\\cite{gcmc,DBLP:journals/natmi/Chehreghani22,10.1145/3700790,lightgcn,pinsage} have emerged as a powerful approach for capturing complex user-item interactions, due to their ability to model complex and nonlinear structures and relationships within graph-based data. However, recent research in GNN-based recommendation continues to rely on the same well-known Bayesian Personalized Ranking (BPR)~\\cite{bpr} objective function previously used in traditional methods~\\cite{lightgcn, ngcf, dgrec, dgcf}. BPR operates on the principle that observed interactions should be ranked higher than unobserved ones. However, this method tends to reinforce the popularity of already well-known items, further marginalizing long-tail items and effectively treating all un-interacted items as irrelevant.\n\tUsers might not be aware of the existence of many of these items. If they were to encounter them, they might prefer some over those they have already seen.\n\tThis problem leads to a situation where items with high previous visit rates are increasingly promoted by the recommender system, while less-visited items remain overlooked.\n\tThis issue is commonly referred to as exposure bias or popularity bias in the literature.\n\tThe item degree distribution in recommender systems follows a power law distribution, where a small number of items have a large number of interactions, while the majority have only a few interactions. The former group is referred to as short-head or popular items, while the latter is known as long-tail or unpopular items.\n\t\n\tMoreover, despite the existence of popularity bias or exposure bias, not all items in the non-interaction category suffer from this issue. Some items simply lack the quality needed to be recommended as desirable by recommender systems~\\cite{zhao2022popularity}. Current recommender systems designed to address this bias~\\cite{adjnorm, apda, popularitymetrics, hetrofair} treat all long-tail items equally. Objective functions such as BPR also do not have a way to distinguish between these two categories.\n\n\t\n\tTo address these issues, recent research has explored various approaches, such as regularization techniques, where authors try to add fairness metrics as an objective to the loss function and penalize discrimination against unpopular items~\\cite{wan2020addressing, li2021user}.\n\tA few other works concentrate on causal methods~\\cite{ge2022explainable, huang2022achieving, zhao2022popularity} to solve popularity bias. The main goal of causal methods is to explore the connections within the data and model, focusing on how sensitive variables influence decisions.\n\tGNN-based methods have also been explored to tackle popularity bias by changing the inner mechanisms of GNNs, such as the neighborhood aggregation process~\\cite{adjnorm, apda, hetrofair}.\n\tHowever, many of these solutions do not adequately differentiate between bias stemming from item popularity and legitimate quality-based filtering. Moreover, the inherent exposure bias of the BPR objective function remains a significant challenge, as it tends to favor items with higher degrees in the graph, leading to unfair recommendations.\n\t\n\t\n\tTo address these challenges, in this paper, we propose a novel approach that directly tackles the exposure bias introduced by the BPR objective function through an edge classification framework. This method reclassifies the edges within the user-item interaction graph, distinguishing between high-quality and low-quality long-tail items. Our approach ensures that popularity bias is mitigated without sacrificing the recommendation of genuinely relevant items. Furthermore, we enhance this framework with cost-sensitive learning, which adjusts the misclassification penalties, particularly for unpopular items. This adjustment encourages the model to fairly recommend items that might otherwise be unjustly overlooked due to their lack of popularity.\n\t\n\tWe distinguish between popularity caused by item quality and popularity caused by the model's tendency to interact with popular items. This distinction enhances user-centricity by helping users get closer to their true preferences. By introducing edge classification and cost-sensitive learning together, we ensure that less popular items in a user\u2019s profile are not wrongly considered negative. Our fairness improvement stems not from recommending less popular items to users with mostly popular items, but from recommending more relevant items to those with a profile made up of less popular items. The final evaluation, based on the equal chance method, focuses on users\u2019 preferences and interests to assess the model\u2019s performance in improving fairness, demonstrating its effectiveness.\n\t\n\tWe conduct experiments on several well-known datasets and demonstrate that our proposed model significantly outperforms state-of-the-art methods in terms of fairness metrics, achieving improvements in fairness measures by approximately 2\\% to 74\\% compared to existing approaches. Moreover, it achieves accuracy results very close to those of best existing methods, with accuracy metrics showing only a slight decline from the top-performing models. This indicates that our method balances the trade-off between fairness and accuracy,\n\teffectively. Additionally, through ablation studies, we highlight the importance of the fairness-oriented component of our model.\n\t\n\tThe structure of this paper is as follows: Section 2 offers a brief overview of related work, followed by the necessary preliminaries and definitions in Section 3. Section 4 presents a detailed description of our proposed method.\n\tIn Section 5, we discuss the results of our extensive experiments, highlighting the performance of the proposed method.\n\tFinally, Section 6 concludes the paper.\n\t\n\t\n\t"
            },
            "section 2": {
                "name": "Related work",
                "content": "\n\t\\label{sec:relatedwork}\n\t\n\tIn this section, we explore recent developments in three areas closely connected to our work: GNN-based recommendation, data-driven fair recommendation, and strategies for mitigating popularity bias.\n\t\n\t",
                "subsection 2.1": {
                    "name": "GNN-based recommendation",
                    "content": "\n\t\n\tThe success of GNN-based methods in graph-related tasks has led to their application in recommender systems. GCMC~\\cite{gcmc} uses this technique for matrix completion tasks on user-item bipartite graphs. NGCF~\\cite{ngcf} is the first attempt to acquire users' and items' representations based on multi-hop neighborhoods. GTN~\\cite{gtn} adaptively captures the reliability of user-item interactions, aiming to enhance the robustness of recommendations by mitigating the impact of unreliable behaviors. Wei and Chow~\\cite{wei2023fgcr} propose the Fused Graph Context-aware Recommender system (FGCR), which integrates GCN and traditional models to enhance user-item-context interactions. They introduce a masked graph convolution strategy that improves information aggregation across different types of nodes.\n\tPeng et al.~\\cite{peng2024powerful} address limitations in GCN-based recommendation systems by introducing generalized graph normalization to handle noise across different data densities and an individualized graph filter to enhance expressive power. After introducing SGC~\\cite{wu2019simplifying}, which shows that non-linearity is an unnecessary function in GCN~\\cite{gcn}, LRGCCF~\\cite{lrgccf} and LightGCN~\\cite{lightgcn} both work on simplifying NGCF inspired by SGC. The former removes non-linearity from NGCF, while the latter removes feature transformation in addition to non-linearity. The only trainable parameters of LightGCN are the nodes' initial embeddings.\n\tRecently, Peng et al.~\\cite{peng2024less} identified three key redundancies in GNN-based recommendation methods: feature, structure, and distribution redundancies. The authors propose a Simplified Graph Denoising Encoder that reduces complexity by using only the top-$K$ singular vectors and introduces a scalable contrastive learning framework to enhance model robustness.\n\t\n\t"
                },
                "subsection 2.2": {
                    "name": "Data-driven fair recommendation",
                    "content": "\n\tThis approach tries to improve fairness by modifying the training data.\n\tResearch in this domain is limited. Ekstrand et al.~\\cite{ekstrand2018all} use demographic features to divide users into different groups and apply re-sampling to modify the distribution of various user groups within the training dataset. Rastegarpanah et al.~\\cite{rastegarpanah2019fighting} tackle user-side unfairness by adding antidote data to the training data, introducing unreal user nodes. The fairness objective function is optimized using gradient descent to update the augmented antidote data. Chen et al.~\\cite{chen2023improving} introduce a model-agnostic framework that improves fairness through data augmentation, generating synthetic user-item interactions based on the hypothesis that users with different sensitive attributes may have similar item preferences. However, most existing works have focused on user-side fairness, while research on item-side fairness using a data-driven approach is very rare.\n\t\t\n\t"
                },
                "subsection 2.3": {
                    "name": "Popularity debiasing",
                    "content": "\n\tFair recommendation is closely related to popularity bias, which refers to the tendency of recommender systems to favor popular items, often at the expense of long-tail items. In recent years, various methods have been proposed to tackle this problem. SGL~\\cite{sgl} introduces a self-supervised setting for GNN-based recommendation, creating multiple views for each node in the graph and using contrastive learning to maximize agreement between these views. Zhu et al.~\\cite{popularitymetrics} propose  a regularization term to achieve a balanced recommendation list between popular and long-tail items, introducing two metrics to evaluate bias from both the user and item sides. The r-AdjNorm method~\\cite{adjnorm} adjusts the power of the symmetric square root normalization term in graph neural networks to control the normalization process during neighborhood aggregation, aiming for improved results, especially for low-degree items. APDA~\\cite{apda} assigns lower weights to connected edges during the aggregation process and employs residual connections to achieve unbiased and fair representations for users and items in graph collaborative filtering. Anelli et al.~\\cite{anelli2023auditing} analyze both consumer and producer fairness in the graph collaborative filtering approach. Zhao et al.~\\cite{zhao2022popularity} differentiate popularity bias into benign and harmful categories, arguing that item quality can influence popularity bias and introducing a time-aware disentangled framework to identify and mitigate harmful bias. Chen et al.~\\cite{chen2024graph} theoretically assess how graph convolution exacerbates popularity bias, demonstrating that stacking multiple graph convolution layers accelerates users' gravitation towards popular items in the representation space. \n\t\n\t"
                }
            },
            "section 3": {
                "name": "Preliminaries",
                "content": "\n\t\\label{sec:preliminaries}\n\t\n\tIn this section, we introduce the key notations and definitions used throughout the paper, followed by an overview of the Light Graph Convolutional (LightGCN) model~\\cite{lightgcn}.\n\t\n\t",
                "subsection 3.1": {
                    "name": "Notations and definitions",
                    "content": "\n\t\n\tIn graph collaborative filtering based recommender systems, historical interactions between users and items are formulated as an undirected bipartite graph $G = (V, E)$,\n\twhere $V = U \\cup I$. Here, \\(U = \\{u_1,u_2,\\ldots,u_{|U|}\\}\\) is a set of users and \\(I=\\{i_1,i_2,\\ldots, i_{|I|}\\}\\) is a set of items.\n\tThe term bipartite means that there are no internal edges within the user group or the item group. Instead, users have interactions with different items.\n\tThese interactions consider all user behaviors, such as buying, clicking, viewing, etc.\n\tThese interactions are represented by $E$.\n\tThe adjacency matrix $A$ of the graph $G$ is defined as $A \\in \\mathbb{R}^{\\left(\\left|U\\right| + \\left|I\\right|\\right) \\times \\left(\\left|U\\right| + \\left|I\\right|\\right)}$,\n\twhere $A_{ui} = A_{iu} = 1$ if $(u,i) \\in E$ and otherwise $0$.\n\t\n\t"
                },
                "subsection 3.2": {
                    "name": "Long-tail distribution",
                    "content": "\n\tA power law degree distribution is a pattern where the majority of items have very few occurrences, while a small number of items have a large number of occurrences. This type of distribution is common in many systems, especially where certain items are much more popular than others. In the context of recommender systems, the item degree distribution follows this  power law pattern. A small group of items, often called short-head or popular items, receive the majority of user interactions, meaning they are frequently recommended and interacted with. On the other hand, the majority of items, referred to as long-tail or unpopular items, receive far fewer interactions and tend to be less visible to users. This imbalance in item interactions is a typical challenge in many recommendation systems, where a few items dominate user attention, while most items remain relatively undiscovered. This phenomenon can be visually represented through a long-tail distribution curve, where the short-head items create a steep initial drop, followed by a long, gradually declining tail that represents the many less popular items. Figure~\\ref{fig:powerlaw} demonstrates this curve, highlighting the stark contrast between the highly popular items and the vast number of less popular items.\n\t\n\t\t\n\t\n\t"
                },
                "subsection 3.3": {
                    "name": "Light graph convolutional model",
                    "content": "\n\t\n\tOne of the pioneering studies in graph collaborative filtering\n\tsimplifies GCN  due to the nature of collaborative filtering graphs, where nodes do not have rich initial features like those in citation networks such as Cora or CiteSeer. The simplification process involves removing two components: non-linearity and feature transformation. Therefore, the standard GCN changes to the following form~\\cite{lightgcn}: \n\t\\begin{equation}\n\t\tH^{\\left(k+1\\right)} = (D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}})H^{\\left(k\\right)},\n\t\t\\label{eq:eq3}\n\t\\end{equation}\n\twhere \\(D\\)  is the diagonal degree matrix that has the same dimension as\n\tthe adjacency matrix \\(A\\) of the graph, \\(D_{ii} = \\sum_{j} A_{ij}\\), and\n\t$H^{\\left(k\\right)}$ is the embedding matrix at layer $k$. \n\t\\(H^{\\left(0\\right)} = [h_{1}^{\\left(0\\right)}, h_{2}^{\\left(0\\right)}, \\ldots, h_{|U|+|I|}^{\\left(0\\right)} ]^T\\) is the initial embedding matrix of\n\tthe nodes in the collaborative filtering graph, and $h^{k} \\in \\mathbb{R}^{d\\times1}.$\n\t\n\t\n\t\n\t"
                }
            },
            "section 4": {
                "name": "Our proposed method",
                "content": "\n\t\\label{sec:ourmethod}\n\t\n\tIn this section, we first introduce our method for disentangling popularity and quality in GNN-based recommendation systems. We then describe our edge classification technique, followed by our approach to cost-sensitive learning.\n\t\n\t",
                "subsection 4.1": {
                    "name": "Disentangled popularity and quality",
                    "content": "\n\t\\label{disentangled}\n\t\n\tNot all items that fall into the long tail part of the item degree distribution are wrongly discriminated against by popularity bias. Some of these items simply do not have the necessary quality to be recommended by recommender systems. Therefore, we must categorize long-tail items in terms of quality and distinguish between popularity bias that causes high-quality items to be ignored and bias that filters out low-quality items. For this purpose, we use a combination of the baseline estimation method and the degree of nodes (here, items) to identify low-quality items.\n\tThe baseline estimation method is as follows:\n\t$$b_{ui} = \\mu + b_{u} + b_{i},$$\n\twhere $b_{ui}$ is the baseline estimation for user $u$'s rating on item $i$,\n\t$\\mu$ is the average rating over all items, and\n\t$b_{u}$ and $b_{i}$ indicate the observed deviations of user $u$ and item $i$, respectively.\n\t\n\tFor each edge $(u, i) \\in E$, we calculate the baseline estimation and determine the difference between this value and the score given by user $u$ to item $i$, which we call the error. Specifically, we subtract the baseline estimation from the actual score. A positive number indicates that user $u$ is interested in item $i$, as the score is higher than the baseline estimation based on $\\mu$, $b_u$, and $b_i$. Conversely, a negative number indicates a relative lack of interest. After calculating the baseline estimation, we remove the edge $(u, i)$ from the adjacency matrix if less than two-thirds of users have given a positive score to item $i$ and if item $i$ has a degree of less than $\\gamma$.\n\tIn general, we set $\\gamma$ to $20$, but we study the effect of this hyperparameter in Section \\ref{sec:gamma_effect}\n\t\n\tIt is crucial to emphasize that not all popularity is inherently negative. Distinguishing between quality and popularity allows us to remove noise from the graph and optimally combat that part of popularity which is caused by popularity bias. This approach results in a more fair model.  Importantly, we avoid treating all low-degree and poor-quality items as victims of popularity bias. Simply recommending these items without considering their actual quality would lower user satisfaction and worsen the user experience, as users may be presented with irrelevant or low-quality content. By balancing this, we ensure that recommendations are fair without compromising the quality and relevance of the items recommended to the user.\n\t\t\n\t"
                },
                "subsection 4.2": {
                    "name": "Edge classification",
                    "content": "\n\t\n\tAlthough implicit feedback-based classification is a special kind of edge classification where all existing edges are labeled as $1$, we can extend it to binary classification with the help of negative sampling. Therefore, we can provide the following definition:\n\t\t\n\t\\newtheorem{definition}{Definition}\n\t\\begin{definition}\n\t\t\\label{thm:edgeclassificationdefiniton}\n\t\tIn an undirected bipartite graph $G=\\left(V,E\\right)$ with users $U$ and items $I$ and known positive interactions $(u,i) \\in E$ the edge classification problem in recommender systems involves predicting whether unknown edges $(u,i) \\notin E$, should be classified as $1$ indicating potential positive interactions or $0$ indicating no interaction.\n\t\\end{definition}\n\t\n\tThe reason for using this method instead of the well-known BPR method is investigated in recent research~\\cite{nipsunbiased, damak2021debiased, apda}. BPR, a widely used pairwise objective function for recommendation, has been shown to be vulnerable to popularity or exposure bias in multiple studies. It assumes that any positive interaction should be ranked higher than all other unobserved potential interactions.\n\tSatio~\\cite{nipsunbiased} demonstrates that the estimator optimized in the BPR algorithm is biased against the ideal pairwise loss. Zhou et al.~\\cite{apda} investigate how the gradient magnitude of the BPR algorithm causes the interest scores of users and items to be positively correlated with the degree of the aggregated nodes in the $k$-hop neighborhood.\n\tTo tackle this problem, we introduce a new edge classification setting for the recommender system, as defined in Definition~\\ref{thm:edgeclassificationdefiniton}, and use cross-entropy as the objective function, instead of BPR. The binary cross-entropy can be defined as follows:\n\t\\begin{equation}\n\t\tL = - \\sum_{i \\in I} y_{ui} \\ log \\ \\tilde{y}_{ui} + \\left(1- y_{ui}\\right) \\ log\\left(1- \\tilde{y}_{ui}\\right).\n\t\\end{equation}\n\tHere, $y_{ui}$ can be considered a label: it will be $1$ if user $u$ has item $i$ in his profile and $0$ otherwise. $\\tilde{y}_{ui}$ is the model-predicted score (interest score) and is in the range of $\\left[0,1\\right]$. This loss function is also known as the negative log-likelihood loss.\n\t\n\tNot suppressing items that could potentially attract the user's attention increases the likelihood of those items being noticed, which can improve user satisfaction. Based on the degree distribution of items, most of the items in the negative category are less popular. Therefore, the limitations imposed by the BPR method cause the user to miss many items they might like, simply due to a lack of past interactions. To address this, we use an edge classification approach to improve the user experience by increasing the diversity and relevance of recommendations, giving less popular but relevant items a chance to be discovered. In other words, we do not filter items solely based on the lack of past visits, aiming to build user trust in the process.\n \n\t"
                },
                "subsection 4.3": {
                    "name": "Cost-sensitive learning",
                    "content": "\n\t\\label{sec:constsensitive}\n\t\n\tMisclassification costs are not the same in supervised machine-learning tasks; different misclassification errors incur different penalties~\\cite{elkan2001foundations, ijcnncost}. For example, the cost of failing to diagnose an incurable disease is much higher than misclassifying a negative case as positive. This issue also occurs in recommender systems. In systems affected by popularity bias, unpopular items are often erroneously considered false negatives. Despite their relevance, these items have fewer interactions, making them susceptible to popularity bias and thus not recommended to users.  In our recommendation model, we address this issue as follows:\n\tLet class one denote items that the user interacted with in the past (positive interactions), and class zero refers to negative (un-interacted) items.\n\tWe proportionally increase the misclassification cost for class zero and decrease it for class one.\n\tIn this scenario, $80\\%$ of randomly selected negatively sampled items (class zero) belong to the unpopular category. Therefore, increasing the loss weight for class zero encourages the model to recognize that it is more costly to predict an item as negative when it should be positive.\n\t\tThe new loss function is defined as follows:\n\t\t\\begin{equation}\n\t\t\tLoss_{total} = (1-\\lambda) Loss_{c=1} + (1+ \\lambda) Loss_{c=0}\\ ,\n\t\t\\end{equation}\n\t\twhere $\\lambda$ is a hyperparameter that controls the weights of positive and negative classes:\n\t$c=1$ denotes items that the user has interacted with in the past (positive interactions), and $c=0$ refers to negative (uninteracted) items.\n\tIn Section~\\ref{sec:hyperparameterstudy}, we investigate the role of $\\lambda$ in model's performance.\n\tThe new loss function can also be represented as a cost matrix, as follows:\n\t\\[\n\t\\begin{array}{c|c|c}\n\t\t& \\text{Predicted irrelevant} & \\text{Predicted relevant} \\\\\n\t\t\\hline\n\t\t\\text{Actual irrelevant} & 0 & (1-\\lambda) Loss_{c=1} \\\\\n\t\t\\hline\n\t\t\\text{Actual relevant} & (1+ \\lambda) Loss_{c=0} & 0 \\\\\n\t\\end{array}\n\t\\]\n\t\n\t"
                },
                "subsection 4.4": {
                    "name": "The algorithm",
                    "content": "\n\t\n\tIn this section, we discuss the details of our two new algorithms, that form the key components of our proposed method: the disentangled popularity and quality algorithm,\n\tand the cost-sensitive edge classification training process.\n\tThese algorithms address the issues of popularity bias and misclassification costs in recommendation systems, providing a fairer and more accurate model.\n\t\t\n\t\\paragraph{Disentangled popularity and quality}\n\tAlgorithm~\\ref{alg:disentangled_quality} (the disentangled popularity and quality algorithm) aims to filter out low-quality items from the recommendation process by distinguishing between popularity bias and the inherent quality of items.\n\tIt consists of the following steps:\n\t\\begin{itemize}\n\t\t\\item \n\tFirst, in Lines $3-8$, we calculate the average rating $\\mu$ across all items and compute the observed deviations $b_u$ and $b_i$ for each user $u$ and item $i$, respectively.\n\tThese deviations are used to estimate the baseline rating $b_{ui}$ for each user-item pair $\\left(u,i\\right)$.\n\t\t\\item \n\t\tThen, in Lines $10-15$, the baseline estimation is compared to the actual user rating to calculate the error $e_{ui}$. If an item has a degree of less than $\\gamma$ and less than two-thirds of users have given a positive score to that item, the edge between that user and item is removed from the graph,\n\t\teffectively filtering out low-quality items that are not wrongly discriminated by popularity bias.\n\t\\end{itemize}\n\n%\t if less than two-thirds of users have given a positive score to item i\n\t\\paragraph{Cost-sensitive edge classification training process}\n\tThe algorithm for the cost-sensitive edge classification training process (Algorithm~\\ref{alg:proposed_method}) addresses the limitations of the BPR loss by replacing it with the negative log-likelihood loss and applying cost-sensitive learning to tackle the misclassification costs associated with popularity bias in recommendation systems.\n\tIt consists of the following steps:\n\t\\begin{itemize}\n\t\t\\item \n\t\tFirst, in Lines $3-6$, the input features are initialized using Xavier initialization, and a Light Graph Convolution is applied to generate node embeddings.\n\t\t\\item \n\t\tThen, in Line $7$, the algorithm iterates through each user-item pair in the current batch $O_{batch}$.\n\t\tFor each pair, a negative item is sampled, and the interest scores\n\t\t$\\tilde{y}_{ui}$\n\t\tand $\\tilde{y}_{uj}$ are computed for the positive and negative items,\n\t\trespectively in Lines $8-10$. \n\t\t\\item \n\t\tIn Lines $11-12$, instead of the BPR loss, the negative log-likelihood loss is used to calculate the loss for positive interactions $L_{c=1}$ and negative interactions $L_{c=0}$.\n\t\t\\item \n\t\tTo further enhance fairness, cost-sensitive learning is applied by adjusting the total loss $L_{total}$ based on misclassification costs, controlled by the hyperparameter $\\lambda$.\n\t\tIn Lines $13-19$, the algorithm accumulates the losses\n\t\tand updates the model parameters through backpropagation.\n\t\tThis approach not only replaces the BPR loss with a more robust alternative but also ensures that the model is less biased against unpopular items by accounting for different misclassification costs.\n\t\\end{itemize}\n\t\n\t\\begin{algorithm}[H]\n\t\t\\caption{The disentangled popularity and quality algorithm.\\label{alg:disentangled_quality}}\n\t\t\\begin{algorithmic}[1]\n\t\t\t\\State \\textbf{Input:} Graph \\(G\\left(V,E\\right)\\), original rating matrix \\(R\\)\n\t\t\t\\State \\textbf{Output:} New graph \\(G'\\left(V,E'\\right)\\) with filtered edges\n\t\t\t\\State Calculate \\(\\mu \\gets\\) average rating over all items\n\t\t\t\\For{each user \\(u\\)}\n\t\t\t\\State Calculate \\(b_u \\gets\\) observed deviation of user \\(u\\)\n\t\t\t\\EndFor\n\t\t\t\\For{each item \\(i\\)}\n\t\t\t\\State Calculate \\(b_i \\gets\\) observed deviation of item \\(i\\)\n\t\t\t\\EndFor\n\t\t\t\\State Initialize new edge set \\(E' = E\\)\n\t\t\t\\For{each edge \\((u, i) \\in E\\)}\n\t\t\t\\State Calculate \\(b_{ui} \\gets \\mu + b_u + b_i\\) \\Comment{Baseline estimation}\n\t\t\t\\State Calculate \\(e_{ui} \\gets r_{ui} - b_{ui}\\) \\Comment{Calculate error}\n\t\t\t\\If{\\(\\text{degree}(i) < \\gamma\\) and \\( \\frac{|\\{(u, i) \\mid e_{ui} > 0 \\}|}{|\\{(u, i)\\}|} < \\frac{2}{3}\\)}\n\t\t\t\\State Remove edge \\((u, i)\\) from \\(E'\\)\n\t\t\t\\EndIf\n\t\t\t\\EndFor\n\t\t\t\\State \\Return new graph \\(G'\\left(V, E'\\right)\\)\n\t\t\\end{algorithmic}\n\t\\end{algorithm}\n\t\n\t\n\t\\begin{algorithm}[H]\n\t\t\\caption{Cost-sensitive edge classification training process.\\label{alg:proposed_method}}\n\t\t\\begin{algorithmic}[1]\n\t\t\t\\State \\textbf{Input:} Graph \\(G\\left(V,E\\right)\\), hyperparameters \\(\\lambda\\) and $\\gamma$\n\t\t\t\\State \\textbf{Output:} Updated model parameters \\(\\Theta\\)\n\t\t\t\\State \\(X \\gets\\) Xavier initialization \\Comment{Initialize input features}\n\t\t\t\\State $H \\gets X$\n\t\t\t\\State $L \\gets 0$\n\t\t\t\\State $H \\gets Light Graph Convolution()$\n\t\t\t\\For{$(u, i) \\in O_{batch}$} \\Comment{$O_{batch}$ is the set of $\\left(u,i\\right)$ pairs in the current batch}\n\t\t\t\\State Sample a negative item $j$ uniformly at random from $I \\setminus O_u^+$\n\t\t\t\\State $\\tilde{y}_{ui} \\gets H[u] \\cdot H[i]$ \n\t\t\t\\State $\\tilde{y}_{uj} \\gets H[u] \\cdot H[j]$ \n\t\t\t\n\t\t\t\\State $L_{c=1} \\gets - \\log(\\tilde{y}_{ui})$ \\Comment{Loss for positive interaction}\n\t\t\t\\State $L_{c=0} \\gets - \\log(1 - \\tilde{y}_{uj})$ \\Comment{Loss for negative interaction}\n\t\t\t\n\t\t\t\\State \\Comment{Cost-Sensitive Learning}\n\t\t\t\\State $L_{total} \\gets (1 - \\lambda)L_{c=1} + (1 + \\lambda)L_{c=0}$\n\t\t\t\\State $L \\gets L + L_{total}$\n\t\t\t\\EndFor\n\t\t\t\n\t\t\t\\State \\textbf{Backpropagate and update} model parameters using gradient descent on $L$\n\t\t\t\\State \\textbf{return} $\\Theta$\n\t\t\\end{algorithmic}\n\t\\end{algorithm}\n\t\n\t\\paragraph{Time complexity}\n\tWe analyze time complexity of our proposed method and compare it to LightGCN, as discussed in \\cite{graph-augment}. Time complexity of LightGCN is divided into three main components: graph  (adjacency matrix) operations, graph convolution, and loss computation. For graph operations, LightGCN requires $O(2|E|)$ time to normalize the adjacency matrix. In our proposed method, we additionally compute average ratings, user/item deviations, and filter low-quality items based on their error. This results in a time complexity of $O(|U| + |I| + |E|)$. The graph convolution stage in LightGCN has a time complexity of $O(2|E|Kd)$, where $K$ is the number of layers and $d$ is the embeddings' size. Our method, which uses Light Graph Convolution, maintains the same time complexity $O(2|E|Kd)$, during this stage.\n\tLastly, for computing the loss function, LightGCN (which employs BPR loss) has a time complexity of $O(2Bd)$, where $B$ is the batch size. Our method replaces BPR loss with cross-entropy and incorporates cost-sensitive learning, but its overall time complexity for this component remains $O(2Bd)$. \n\tAs a result, the whole time complexity of our proposed method is\n\t$O(2|E|Kd + |U| + |I| +2Bd)$ = $O(|E|Kd + Bd)$,\n\twhich is the same as the whole time complexity of LightGCN.\n%\t whereas it is $O(2|E|Kd + 2Bd)$ for LightGCN.\n\tTherefore, our fairness-aware approach does not introduce any extra overhead in terms of time complexity, keeping our model as efficient as LightGCN.\n\n\t\n\t"
                }
            },
            "section 5": {
                "name": "Experiments",
                "content": "\n\t\\label{sec:experiments}\n\t\n\tIn this section, we explore the effect of the proposed fairness-aware method on both recommendation utility and fairness. We first compare our model with state-of-the-art GNN-based models for a fair recommendation. Subsequently, we study the impact of different components and hyperparameters on the performance of our proposed method.\n\t\n\t",
                "subsection 5.1": {
                    "name": "Experimental setup",
                    "content": "\n\t\n\t",
                    "subsubsection 5.1.1": {
                        "name": "Datasets",
                        "content": "\n\t\n\tWe show the effectiveness of \n\tour proposed method over three real-world datasets: Bookcrossing\\footnote{\\url{http://www.bookcrossing.com}}~\\cite{book-crossing}, Amazon CDs\\footnote{\\label{amazondata-footnote}\\url{https://cseweb.ucsd.edu/~jmcauley/datasets/amazon/links.html}}~\\cite{amazon-data}, and Amazon Electronics\\textsuperscript{\\ref{amazondata-footnote}}~\\cite{amazon-data}.\n\tFor all datasets, we adopt a $10$-core setting, filtering out users and items with fewer than \n\t$10$ interactions. We randomly select $70\\%$ of each user\u2019s interactions as the training set, $10\\%$ for validation, and the last $20\\%$ for testing. We use the validation set for hyperparameter tuning and early stopping and report our model performance on the test set as the final result. Table~\\ref{tbl:dataset} shows the statistics of the datasets.\n\t\n\t\n\t\n\t\n\t\n\t"
                    },
                    "subsubsection 5.1.2": {
                        "name": "Baselines",
                        "content": "\n\t\n\tWe compare our proposed method against the following baselines:\n\t\t\\begin{itemize}\n\t\t\\item\n\t\tLightGCN~\\cite{lightgcn}: This model simplifies graph convolution by removing non-linearity and weight transformation. The final embedding is obtained by averaging the embeddings from all layers.\n\t\t\n\t\t\\item Reg~\\cite{popularitymetrics}:\n\t\tThis method is based on regularization and takes into account the correlation between an item's popularity and its predicted score by the model. As in the original paper, we carefully adjust the hyperparameter $\\gamma$ of this model to balance accuracy and fairness in the results.\n\t\t\n\t\t\\item r-AdjNorm~\\cite{adjnorm}:\n\t\tThis model controls the strength of the normalization term to regulate the process during neighborhood aggregation, with a focus on improving results for low-degree items. Based on the paper's guidance, we fine-tune the parameter \\(r\\) within the range of \\([0.5,1.5]\\) using a step size of \\(0.05\\).\n\t\t\\item\n\t\tAPDA~\\cite{apda}: This method assigns lower weights to connected edges during the aggregation process and uses residual connections to ensure unbiased and fair representations for users and items in graph collaborative filtering. Following the approach in the original paper, we fine-tune the residual parameter $\\lambda$ within the range $\\left[0, 1.0\\right]$.\n\t\\end{itemize}\n\t\n\t"
                    },
                    "subsubsection 5.1.3": {
                        "name": "Evaluation metrics",
                        "content": "\n\t\n\tTo evaluate the models, we leverage a wide range of evaluation metrics from classical machine learning metrics to ranking metrics as well as fairness metrics.\n\tFor utility measurement, we use Recall, NDCG, MAP (mean average precision), and MRR (mean reciprocal rank). We also utilize three fairness evaluation metrics:\n\t \\textit{popularity-rank correlation for users (PRU)}~\\cite{popularitymetrics}, \\textit{popularity-rank correlation for items (PRI)}~\\cite{popularitymetrics}, and \\textit{equality of opportunity (EO)}.\n\t In the following, we briefly introduce each of the metrics. Recall is computed as the ratio of relevant items retrieved to the total number of relevant items.\n\t \\begin{equation}\n\t \tRecall@M = \\frac{1}{|U|} \\sum_{u \\in U} \\frac{|\\text{Rel}_u(M) \\cap \\text{GT}_u|}{|\\text{GT}_u|},\n\t \\end{equation}\n\t where $M$ is the number of top recommended items, $GT_u$ is the set of items user $u$ likes during testing, $REL_{u}\\left(M\\right)$ is the set of top $M$ recommended items for user $u$. NDCG stands for normalized discounted cumulative gain, and \n\t $NDCG@N$ for top $N$ recommended items is defined as follow:\n \t\\begin{equation}\n\t \t\\small\n\t \tNDCG@N = \\frac{\\sum_{i=1}^{N} \\frac{2^{r\\left(i\\right)}-1}{log_{2}(i+1)}}{\\sum_{i=1}^{REL_N}\\frac{2^{r\\left(i\\right)} - 1}{log_{2}(i+1)}}\\cdot\\label{eq:eq18} \n\t \\end{equation}\n\t Here, \\( REL_N \\) represents a list of the top \\( N \\) most relevant items, sorted in ascending order. The function \\( r(i) \\) indicates the relevance of the item ranked at position \\( i \\), where \\( r(i) \\) takes a value of \\( 1 \\) if the item is relevant, and \\( 0 \\) if it is irrelevant.\n\t MRR focuses on the rank of the first relevant item in the recommendation list:\n \t\\begin{equation}\n\t \tMRR = \\frac{1}{|U|}\\sum_{u \\in U}\\frac{1}{first_{u}},\\label{eq:eq21}\n\t \\end{equation}\n\t where \\(first_{u}\\) represents the rank or position of the first relevant item for user \\(u\\).\n\t MAP is calculated as the mean of the average precision values across all users:\n \t\\begin{equation}\n\t \tMAP = \\frac{1}{|U|}\\sum_{u \\in U} \\frac{1}{number\\ of\\ relevant\\ documents}\\sum_{i=1}^{N}P@i \\cdot r(i),\\label{eq:eq22}\n\t \\end{equation}\n\t where \\(P@i\\) is precision at $i$. We next introduce fairness metrics.\n\t\n\t\\begin{equation}\n\t\tPRU = -\\frac{1}{|U|} \\sum_{u \\in U} SRC\\left(d_{\\tilde{O}_{u}^{+}}, rank_{u}\\left(\\tilde{O}_{u}^{+}\\right)\\right)\\cdot\\label{eq:pru}\n\t\\end{equation}\n\tHere, \\(SRC\\left(\\cdot,\\cdot\\right)\\) calculates Spearman's rank correlation, \\(\\tilde{O}_{u}^{+}\\) represents items in the test profile of user $u$, \\(rank_{u}\\left(x\\right)\\) signifies the ranking of item $x$ that the model predicts for user $u$ and \\(d_{x}\\) is the degree of node \\(x\\).\n\tPRU investigates the correlation between items' popularity and their ranking position\n\tin each user's recommendation list.\n\tThis metric ranges between $-1$ and $1$, where $-1$ indicates the model is in its best state considering fairness, and $1$ means unpopular items are placed at the tail of the recommendation list.\n\t$PRI$ is defined as follows:\t\n\t\\begin{equation}\n\t\tPRI = -\\sum_{i \\in I} SRC\\left(d_{i}, \\frac{1}{U_{i}}\\sum_{u \\in U_{i}} rank_{u}\\left(i\\right)\\right)\\cdot\\label{eq:pri}\n\t\\end{equation}\n\tHere \\(U_{i}\\) is a set of users whose item \\(i\\) already exists in their test profiles.\n\tPRI analyzes the correlation between items' average position across all users and their popularity. This metric's range is the same as PRU.\n\t$EO$ is defined as follows:\n\t\\begin{equation}\n\t\tEO = \\frac{1}{|U|} \\sum_{u \\in U} \\left| \\frac{\\sum_{v \\in G_0} \\mathbf{1}_{v \\in \\text{TopK}_u \\& v \\in \\text{Test}_u} - \\sum_{v \\in G_1} \\mathbf{1}_{v \\in \\text{TopK}_u \\& v \\in \\text{Test}_u}}{\\sum_{v \\in G_0} \\mathbf{1}_{v \\in \\text{TopK}_u \\& v \\in \\text{Test}_u} + \\sum_{v \\in G_1} \\mathbf{1}_{v \\in \\text{TopK}_u \\& v \\in \\text{Test}_u}} \\right|,\n\t\\end{equation}\n\twhere $Test_u$ represents the set of items that user $u$ likes during testing.\n \tLarger values for the EO metric are considered indicative of unfairness against unpopular items.\n\n\n"
                    },
                    "subsubsection 5.1.4": {
                        "name": "Initialization of hyperparameters",
                        "content": "\n\n\tWe set $\\gamma$ to 20 as its default value, but also explore values such as 15, 25, and 30 in Section~\\ref{sec:gamma_effect} for comparative insights.\n\tFor $\\lambda$, we use 0.1 for the CDs and Bookcrossing datasets, and 0.3 for the Electronics dataset, partly due to the differing characteristics of these datasets and their respective misclassification penalties.\n\tAdditionally, our early-stopping mechanism halts training if NDCG does not improve after 20 epochs. This ensures we first identify the model with optimal accuracy before evaluating its fairness capabilities. This approach emphasizes that a fair model should also maintain accuracy.\n\tFigures~\\ref{fig:lambda1} to~\\ref{fig:lambda3} show that NDCG remains relatively stable as $\\lambda$ moves from 0.0 to 0.4, while fairness metrics exhibit more substantial shifts. This leads us to select 0.1 as the optimal $\\lambda$ in some cases.\n\n\t"
                    }
                },
                "subsection 5.2": {
                    "name": "Performance comparison",
                    "content": "\n\tIn this section, we present a detailed comparison of the performance of our model against the mentioned baselines. The results are shown for two experimental settings, with evaluations at top 100 and top 300 recommendation cutoffs.\n\tWe report the results in Tables \\ref{tbl:performance_comparison1} and \\ref{tbl:performance_comparison2}.\n\tOver each dataset and for every metric, the best performance is highlighted in bold, while the second-best is underlined. The key observations are as follows:\n\t\\begin{itemize}\n\t\t\\item\n\t\tLightGCN and LightGCN+Reg: These models provide a solid baseline but generally underperform in comparison to state-of-the-art approaches. Their performance is consistent but lower across most datasets and cutoffs. LightGCN+Reg, which incorporates a fairness-based regularization term, shows a slight improvement in ranking metrics. However, it does not significantly enhance the overall recommendation quality.\n\t\tOn the other hand, considering fairness, these two models perform well on some fairness metrics. LightGCN+Reg even achieves the best PRU score in certain instances and is a close second in others.\n\t\tThis indicates that the added regularization can enhance fairness to some extent.\n\t\tHowever, despite these improvements, the models still struggle with overall fairness. This is evident in other metrics such as EO and PRI, where they exhibit disparities in recommendation quality.\n\t\tWhile they make some strides towards fairness, they lack mechanisms specifically designed to ensure equity across all item groups, which limits their broader fairness impact.\n\t\t\\item\n\t\tr-AdjNorm: This model performs well in both large and sparse datasets. It is generally ranked second or third in performance metrics. r-AdjNorm strikes a good balance between improving the quality of recommendations and maintaining simplicity, but falls behind more complex models in certain cases, especially at lower cutoffs. r-AdjNorm also struggles with fairness: while it is slightly better than LightGCN and LightGCN+Reg, it is still less effective than our proposed method.\n\t\t\\item\n\t\tAPDA: This model can be considered the most powerful baseline, particularly in performance-related metrics such as Recall, NDCG, MRR, and MAP.\n\t\tIt consistently performs best across the datasets at both cutoffs, making it the top model in terms of accuracy and quality metrics.\n\t\tHowever, its focus on performance comes at the cost of low fairness.\n\t\tThis makes it less ideal in scenarios where fairness is a crucial consideration, despite its superior accuracy.\n\t\t\\item\n\t\tOur model: In terms of overall performance, our model is highly competitive, often ranking second (or third) after APDA. While it occasionally falls short in absolute performance compared to APDA, it consistently provides robust results across all datasets and cutoffs. The key distinction is that our model maintains high performance while also incorporating fairness considerations, making it a balanced solution.\n\t\tIt consistently achieves the best fairness results across all datasets, with the lowest EO, PRU, and PRI scores. This means our model is fairer in its treatment of different item groups, ensuring that no group is disproportionately favored or disadvantaged.\n\t\\end{itemize}\n\t\n\n\t\n\t\n\t\n\t\n\n\n\t"
                },
                "subsection 5.3": {
                    "name": "Ablation study",
                    "content": "\n\t\n\tIn this section, we explore the effect of different components of our proposed method on its final output. Since we applied the changes that we introduced in Section~\\ref{disentangled} to all the baseline models, it is not possible to compare the model in the case where the data is in the original form. Therefore, we only investigate the effect of our cost-sensitive learning technique on the model. We refer to this as case as \"w/o Cost\",\n\tand present the results in the last columns of Tables~\\ref{tbl:performance_comparison1} and \\ref{tbl:performance_comparison2}.\n\t\n\tConsidering recommendation accuracy, removing the cost-sensitive component from our model generally leads to a slight decline in performance, especially at lower cutoffs (e.g., 100).\n\tHowever, even without this component, our model still outperforms LightGCN and LightGCN+Reg.\n\tThe \"w/o Cost\" version of our model shows a significant decline in fairness.\n\tOur complete model exhibits better EO, PRU, and PRI scores, underscoring the importance of the fairness component in ensuring equitable treatment.\n\n\t"
                },
                "subsection 5.4": {
                    "name": "Hyperparameters study",
                    "content": "\n\t\\label{sec:hyperparameterstudy}\n\t\n\t\t",
                    "subsubsection 5.4.1": {
                        "name": "Effect of $\\lambda$",
                        "content": "\n\t\t\n\t\tIn this section, we analyze the impact of tuning the cost-sensitive learning hyperparameter $\\lambda$ on recommendation accuracy and fairness across three datasets: Electronics, Bookcrossing, and CDs. We evaluate the model's behavior by varying $\\lambda$ between 0 and 1 in increments of 0.1, using metrics such as PRU, PRI, and NDCG. The results are shown in Figures \\ref{fig:lambda1} to \\ref{fig:lambda3}.\n\t\t\n\t\tWith all datasets demonstrating a similar pattern in PRU, PRI, and NDCG metrics, we can observe a consistent trend in how the fairness and accuracy metrics respond to increasing values of \\(\\lambda\\).\n\t\tAcross the datasets, PRU initially improves as \\(\\lambda\\) increases, indicating that the model better considers under-recommended, unpopular items. However, this improvement plateaus and even reverses as \\(\\lambda\\) reaches higher values, where PRU begins to decline or stabilize without further gains in fairness.\n\t\tFor PRI, the values follow a similar trend, initially improving fairness by approaching zero or slightly negative values, but starting to drop at higher $\\lambda$ values.\n\t\tIn terms of accuracy, NDCG generally decreases as $\\lambda$ increases across all the datasets, with the steepest declines at high $\\lambda$ values. This decline underscores the challenge of maintaining accuracy when penalization for misclassifying popular items becomes too strong.\n\t\tSo we can say that, across the three datasets, increasing $\\lambda$ initially helps improve fairness by focusing more on under-recommended, unpopular items. However, beyond a certain threshold, this focus leads to overcompensation, reducing the accuracy of predictions, particularly for popular items. The analysis highlights that while tuning $\\lambda$ can improve fairness, it must be done cautiously to prevent a significant loss of accuracy in the recommendation system.\n\t\t\n\t\t"
                    },
                    "subsubsection 5.4.2": {
                        "name": "Effect of $\\gamma$",
                        "content": "\n\t\t\\label{sec:gamma_effect}\n\t\t\n\t\tIn this section, we analyze the impact of adjusting the hyperparameter $\\gamma$ in intervals from $15$ to $30$, with steps of $5$. This parameter study investigates how $\\gamma$ influences recommendation accuracy and fairness, focusing on three metrics: PRU, PRI, and NDCG.\n\t\tThe results are depicted in Figures \\ref{fig:gamma1} to \\ref{fig:gamma3}.\n\t\tAs can be observed, as $\\gamma$ increases with a fixed value for $\\lambda$,\n\t\tNDCG consistently improves across all datasets, indicating an accuracy boost as the model accommodates a wider range of item interactions. For example, in the Bookcrossing dataset, NDCG increases from $0.1201$ to $0.1554$, demonstrating a positive impact on recommendation relevance as $\\gamma$ grows. This suggests that higher $\\gamma$ values help the model capture popular items more effectively.\n\t\t\n\t\tRegarding fairness, PRU generally decreases with higher $\\gamma$ values, signaling reduced focus on popular items and more balanced recommendation outputs. For instance, in the CDs dataset, PRU falls from $0.305$ to $0.2657$. PRI values show varied behavior: in Bookcrossing and Electronics, PRI rises slightly with higher $\\gamma$, while in CDs it briefly dips negative at $\\gamma = 25$, then stabilizes. These shifts indicate that adjusting $\\gamma$ allows for finer control over fairness, balancing exposure for both popular and less popular items without sacrificing the overall accuracy.\n\n\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\n\t"
                    }
                }
            },
            "section 6": {
                "name": "Conclusion",
                "content": "\n\t\\label{sec:conclusion}\n\t\t\n\tIn this paper, we proposed a novel approach that tackles exposure bias in recommendation systems through an edge classification framework. Our method reclassifies the edges within the user-item interaction graph, distinguishing between high-quality and low-quality long-tail items. This ensures that popularity bias is mitigated without sacrificing the recommendation of genuinely relevant items. Furthermore, it uses cost-sensitive learning to adjust the misclassification penalties, particularly for unpopular items.\n\tOur experiments on several well-known datasets demonstrated that our proposed model significantly outperforms state-of-the-art methods in terms of fairness metrics. Moreover, it achieves accuracy results very close to those of the best existing methods.\n\t\n\t"
            },
            "section 7": {
                "name": "Acknowledgment",
                "content": "\n\t\n\tThis work is supported by the Iran National Science Foundation (INSF)\n\tunder project No.4034377.\n%\tWe would like to express their gratitude for \tthis support.\n\t\n\t\\bibliography{cite}\n\t\\bibliographystyle{IEEEtran}\n\t\n"
            }
        },
        "equations": {
            "eq:1": "\\begin{equation}\n\t\tH^{\\left(k+1\\right)} = (D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}})H^{\\left(k\\right)},\n\t\t\\label{eq:eq3}\n\t\\end{equation}",
            "eq:2": "\\begin{equation}\n\t\tL = - \\sum_{i \\in I} y_{ui} \\ log \\ \\tilde{y}_{ui} + \\left(1- y_{ui}\\right) \\ log\\left(1- \\tilde{y}_{ui}\\right).\n\t\\end{equation}",
            "eq:3": "\\begin{equation}\n\t\t\tLoss_{total} = (1-\\lambda) Loss_{c=1} + (1+ \\lambda) Loss_{c=0}\\ ,\n\t\t\\end{equation}",
            "eq:4": "\\begin{equation}\n\t \tRecall@M = \\frac{1}{|U|} \\sum_{u \\in U} \\frac{|\\text{Rel}_u(M) \\cap \\text{GT}_u|}{|\\text{GT}_u|},\n\t \\end{equation}",
            "eq:5": "\\begin{equation}\n\t \t\\small\n\t \tNDCG@N = \\frac{\\sum_{i=1}^{N} \\frac{2^{r\\left(i\\right)}-1}{log_{2}(i+1)}}{\\sum_{i=1}^{REL_N}\\frac{2^{r\\left(i\\right)} - 1}{log_{2}(i+1)}}\\cdot\\label{eq:eq18} \n\t \\end{equation}",
            "eq:6": "\\begin{equation}\n\t \tMRR = \\frac{1}{|U|}\\sum_{u \\in U}\\frac{1}{first_{u}},\\label{eq:eq21}\n\t \\end{equation}",
            "eq:7": "\\begin{equation}\n\t \tMAP = \\frac{1}{|U|}\\sum_{u \\in U} \\frac{1}{number\\ of\\ relevant\\ documents}\\sum_{i=1}^{N}P@i \\cdot r(i),\\label{eq:eq22}\n\t \\end{equation}",
            "eq:8": "\\begin{equation}\n\t\tPRU = -\\frac{1}{|U|} \\sum_{u \\in U} SRC\\left(d_{\\tilde{O}_{u}^{+}}, rank_{u}\\left(\\tilde{O}_{u}^{+}\\right)\\right)\\cdot\\label{eq:pru}\n\t\\end{equation}",
            "eq:9": "\\begin{equation}\n\t\tPRI = -\\sum_{i \\in I} SRC\\left(d_{i}, \\frac{1}{U_{i}}\\sum_{u \\in U_{i}} rank_{u}\\left(i\\right)\\right)\\cdot\\label{eq:pri}\n\t\\end{equation}",
            "eq:10": "\\begin{equation}\n\t\tEO = \\frac{1}{|U|} \\sum_{u \\in U} \\left| \\frac{\\sum_{v \\in G_0} \\mathbf{1}_{v \\in \\text{TopK}_u \\& v \\in \\text{Test}_u} - \\sum_{v \\in G_1} \\mathbf{1}_{v \\in \\text{TopK}_u \\& v \\in \\text{Test}_u}}{\\sum_{v \\in G_0} \\mathbf{1}_{v \\in \\text{TopK}_u \\& v \\in \\text{Test}_u} + \\sum_{v \\in G_1} \\mathbf{1}_{v \\in \\text{TopK}_u \\& v \\in \\text{Test}_u}} \\right|,\n\t\\end{equation}"
        }
    }
}