{
    "meta_info": {
        "title": "Balancing Bias and Variance for Active Weakly Supervised Learning",
        "abstract": "As a widely used weakly supervised learning scheme, modern multiple instance\nlearning (MIL) models achieve competitive performance at the bag level.\nHowever, instance-level prediction, which is essential for many important\napplications, remains largely unsatisfactory. We propose to conduct novel\nactive deep multiple instance learning that samples a small subset of\ninformative instances for annotation, aiming to significantly boost the\ninstance-level prediction. A variance regularized loss function is designed to\nproperly balance the bias and variance of instance-level predictions, aiming to\neffectively accommodate the highly imbalanced instance distribution in MIL and\nother fundamental challenges. Instead of directly minimizing the variance\nregularized loss that is non-convex, we optimize a distributionally robust bag\nlevel likelihood as its convex surrogate. The robust bag likelihood provides a\ngood approximation of the variance based MIL loss with a strong theoretical\nguarantee. It also automatically balances bias and variance, making it\neffective to identify the potentially positive instances to support active\nsampling. The robust bag likelihood can be naturally integrated with a deep\narchitecture to support deep model training using mini-batches of\npositive-negative bag pairs. Finally, a novel P-F sampling function is\ndeveloped that combines a probability vector and predicted instance scores,\nobtained by optimizing the robust bag likelihood. By leveraging the key MIL\nassumption, the sampling function can explore the most challenging bags and\neffectively detect their positive instances for annotation, which significantly\nimproves the instance-level prediction. Experiments conducted over multiple\nreal-world datasets clearly demonstrate the state-of-the-art instance-level\nprediction achieved by the proposed model.",
        "author": "Hitesh Sapkota, Qi Yu",
        "link": "http://arxiv.org/abs/2206.05682v1",
        "category": [
            "cs.LG"
        ],
        "additionl_info": "KDD2022"
    },
    "latex_extraction": {
        "content": {
            "section 1": {
                "name": "Introduction",
                "content": "%\\vspace{-2mm}\nMultiple Instance Learning (MIL) offers an attractive weakly supervised learning paradigm, where instances are naturally organized into bags and training labels are assigned at the bag level to reduce annotation cost \\cite{Dietterich1997, Settles2008, Li2015, Sultani2018}. State-of-the-art MIL models achieve competitive performance at the bag level. However, instance-level prediction, which is essential for many important applications (\\eg anomaly detection from surveillance videos~\\cite{Sultani2018} and medical image segmentation~\\cite{Ilse2018}) remains largely unsatisfactory. \n\nIn MIL, a bag is considered to be positive if at least one of the instances is positive otherwise negative \\cite{Dietterich1997, Haubmann2017}. To achieve a high bag level prediction, most existing MIL models primarily focus on the most positive instance from a positive bag that is mainly responsible for determining the bag label \\cite{Andrews2002, Kim2010, Sultani2018, Haubmann2017}. However, they suffer from two major limitations, which lead to poor instance-level predictions. First, solely focusing on the most positive instance is sensitive to outliers, which are negative instances that look very different from other negative ones \\cite{Carbonneau2018MultipleIL}. As a result, these instances may be wrongly assigned a high score indicating they are positive. \n%If these outliers are from a positive bag, the model may still predict the bag label correctly but via the wrongly identified positive instances. \nSecond, there may be multiple types (\\ie multimodal) of positive instances  in a single bag (\\eg different types of anomalies in a surveillance video or different types of skin lesions in a dermatology image). Thus, focusing on a single most positive instance will miss other positive ones. Both cases will result in a low instance-level prediction performance. A possible solution to improve the detection of positive instances is to consider the top-$k$ most positive instances. However, the number of positive instances may vary significantly across different bags and applying the same $k$ to all bags may be inappropriate. Furthermore, finding an optimal $k$ for each bag is highly challenging as it takes a discrete value. \n\n \n\n\nThe underlying reason for the less accurate instance-level prediction is due to the lack of instance labels. For positive instances that are relatively rare across bags, detecting them by only relying on bag labels is inherently challenging as the weakly supervised signal (\\ie bag label) cannot be propagated to the instance level without sufficient statistical evidence. One promising direction to tackle this challenge is to augment MIL with active learning (AL). Multiple instance AL (or MI-AL) aims to select a small number of informative instances to improve the instance level prediction in MIL. In most MIL problems, the data is highly imbalanced at the instance level, where the positive ones are much more sparse. Since the positive instances usually carry more important information, a primary goal of MI-AL is to effectively sample the positive instances from a candidate pool dominated by the negative ones. If a true positive instance can be sampled and labeled, it can help to identify other similar positive instances in the same and different bags, which will significantly improve the instance-level predictions. \n\n\nHowever, existing MIL models may easily miss some rare positive instances \\cite{Sultani2018}. They may also focus on the wrongly identified negative instances due to their sensitivity to outliers or incapability of handling multimodal bags. Thus, the true positive instances may be assigned a low prediction score, indicating that they are predicted as negative with a high confidence. As a result, commonly used uncertainty based sampling will miss these important instances. Figure~\\ref{fig: illustrative_examples_max_vs_proposed} (a) shows a challenging bag, which is an image that contains the shadow of a bird (as the positive class). The positive instances are patches that cover (part of) the bird shadow. Figure~\\ref{fig: illustrative_examples_max_vs_proposed} (b) shows that combining uncertainty sampling with a maximum score based MIL model (the green curve) is not able to sample effectively so that instance-level prediction remains very low over the AL process. Figure~\\ref{fig: illustrative_examples_max_vs_proposed} (c) further confirms that the initial prediction score (F-score) of the positive instance is close to 0, making it hard to be sampled. \n\n \nWe propose a novel MI-AL model for effective instance sampling to significantly boost the instance-level prediction in MIL. We design an unique variance regularized MIL loss that encourages a high variance of the prediction scores to address bags with a highly imbalanced instance distribution and/or those with outliers and multimodal scenarios. Since the variance regularizer is non-convex, we propose to optimize a distributionally robust bag likelihood (DRBL), which provides a good convex approximation of the variance based loss with a strong theoretical guarantee. The DRBL automatically adjusts the impact of the bag-level variance, making it more effective to detect potentially positive instances to support active sampling. It can also be naturally integrated with a deep architecture to support deep MIL model training using mini-batches of positive-negative bag pairs. Finally, a novel P-F sampling function is developed  that combines a probability vector (\\ie $\\bf p$) and predicted instance scores (\\ie $\\bf f$), obtained by optimizing the DRBL. By leveraging the key MIL assumption, the sampling function can explore the most challenging bags and effectively detect their positive instances for annotation, which significantly improves the instance-level prediction. Novel batch-mode sampling is developed to work seamlessly with the deep MIL, leading to a powerful active deep MIL (ADMIL) model to support sampling of high-dimensional data used in most MIL applications. Figure~\\ref{fig: illustrative_examples_max_vs_proposed} (b) shows the proposed model (purple curve) that significantly improves instance predictions. Figures~\\ref{fig: illustrative_examples_max_vs_proposed} (c)-(e) show P-F sampling dynamically updates the probability $\\bf p$ and score $\\bf f$ values to effectively sample the positive instance from the highly challenging bag in a few steps. \n\nOur main contribution includes: (i) an unique variance regularized MIL loss and its convex surrogate that address inherent MIL challenges to best support active sampling, (ii) a novel P-F sampling function to effectively explore most challenging bags with rare positive instances, (iii) mini-batch training and batch-mode active sampling to support ADMIL in broader MIL applications, and (iv) state-of-the-art instance prediction performance in MIL while maintaining low instance annotations.\n\n\\vspace{-4mm}\n"
            },
            "section 2": {
                "name": "Related Work",
                "content": "\n\n%In this section, we will discuss the related work that is most relevant to ours, including active learning and multiple instance learning.  \n\n{\\bf Multiple Instance Learning (MIL).}\n %After being introduced by Dietterich et al.~\\citep{Dietterich1997},  various approaches have been proposed to address MIL problems  \\citep{Zhou2002, Zhang2017, Wei2014}. \nExisting supervised learning models have been leveraged to tackle MIL problems, including SVM \\cite{Andrews2002}, boosting \\cite{Xu2004}, graph-based models \\cite{Zhou2009}, attention based \\cite{Ilse2018, Hsu2020QueryDrivenML}, conditional random field  \\cite{Deselaers2010} and Gaussian Processes  \\cite{Haubmann2017, Kim2010}. Other approaches try to relax the MIL assumption, which allows positive instances in a negative bag to handle noisy bags \\cite{Li2015}. As MIL is commonly applied to video anomaly detection and image segmentation that involve high dimensional data, deep neural networks (DNNs) have become a popular choice for training MIL models \\cite{Ilse2018,Sultani2018,Hsu2020QueryDrivenML}. Despite the significant progress made so far, most existing models focus on improving the bag-level predictions. As a result, instance-level performance still falls short in meeting the high standard in critical applications~\\cite{Sultani2018,Ilse2018,Haubmann2017}. The proposed ADMIL model aims to fill out this critical gap by augmenting MIL with novel active sampling strategies to significantly boost instance predictions using limited labeled instances to maintain a low annotation cost. \n\n\\vspace{1mm}\\noindent{\\bf Active Learning (AL).} %A central component of AL is an acquisition function to sample informative data samples for annotation.  Design of acquisition functions depends on the specific machine learning task. \n%Design of AL models depends on the specific machine learning task. For binary classification problems, the primary goal is to estimate a data point's impact on the current decision boundary~\\citep{tong2001support,seung1992query,schohn2000less,freund1997selective}.  For multi-class problems,  significant statistics of the data, such as \nUncertainty and margin based measures are commonly leveraged in existing AL models to achieve efficient data sampling~\\cite{settles2009active}. %~\\cite{roy2001toward,holub2008entropy,rajan2008active,joshi2009multi}. \nDistributionally robust optimization has also been adopted in multi-class AL to address sampling bias and imbalanced data distribution~\\cite{Zhu2019}. \n%For multi-label problems, AL mainly focuses on leveraging label correlation as an additional source to guide sampling in the label space~\\citep{li2013active,reyes2018effective,vasisht2014active,yang2009effective,Kapoor:2012:MCU:2999325.2999430,vasisht2014active}. \nDeep learning (DL) models are good candidates for AL because of their high-dimensional data processing and automatic feature extraction capability. Existing models mainly target at improving uncertainty quantification of the network for reliable sampling~\\cite{wang2016cost,gal2015bayesian,kendall2015bayesian,leibig2017leveraging}. Batch-mode sampling is commonly used in active DL to avoid frequent model re-training. It focuses on constructing representative batches to avoid redundant information given by similar instances~\\cite{kirsch2019batchbald,sener2017active,ash2019deep}. AL in the MIL setting has been rarely investigated. One exception is the MI logistic model and its three uncertainty measures to simultaneously consider both instance and bag level uncertainty~\\cite{settles2007multiple}. However, uncertainty sampling is ineffective to explore challenging bags, where all instances are confidently predicted as negative. In addition, the original model is a simple linear model, which does not provide sufficient capacity for high-dimensional data. There is no systematic way to support batch-mode sampling, either. A reinforcement learning based AL technique is developed in \\cite{Casanova2020ReinforcedAL}, where segments are chosen to be labeled in each AL step . However, segmentation level annotations are required to compute the reward during the training process, which violates the assumption of MIL.  Another AL framework is developed for MIL tasks in \\cite{Yuan2021}. However, sampling is conducted at the bag level (\\ie choosing bags instead of instances).  Thus, it is essentially a multi-label AL model, aiming to improve the bag-level predictions with fewer annotated bags. This is fundamentally different from the design goal of ADMIL. \n\n\\vspace{-2mm}\n"
            },
            "section 3": {
                "name": "Methodology",
                "content": "\n\n%Based on a standard MIL assumption, we consider that for a positive bag, there is at least one positive instance whereas in case of negative bag, all instances are of negative type. Further, in our setting we consider that the number of instances may vary from one bag to another.\n%Let ${\\bf X} = \\{{\\bf x}_1, ..., {\\bf x}_N\\}$ denote a set of training bag instances with \nLet $\\{{\\bf x}_1,...,{\\bf x}_n\\}$ denote a set of instances associated with each bag $\\mathcal{B}$, where each ${\\bf x}_i\\in \\mathbb{R}^D$ is a feature vector. Let $t_{\\mathcal{B}} \\in \\{+1,-1\\}$ indicates the bag type.  \n%All symbols are summarized by Table~\\ref{tab: symbol_table}.\nFollowing the standard MIL assumption discussed earlier, active sampling will focus on instances in the positive bags as all instances in a negative bag are negative. We also allow the number of instances to vary from one bag to another.\n\n\n\n\\vspace{-2mm}\n",
                "subsection 3.1": {
                    "name": "Variance Regularization",
                    "content": "%\\vspace{-1mm}\n%\\qi{Only bold the symbol not the subscript. Make sure the symbols are used consistently, e.g., bold for vectors.} \nLet ${\\bf x}_i^+$ (or ${\\bf x}_j^-$) be the $i^{th}$ (or $j^{th}$) instance in a positive bag $\\mathcal{B}_{pos}$ (or a negative bag $\\mathcal{B}_{neg}$). Following the MIL assumption, a commonly used loss function for training deep MIL models is to make the maximum prediction score of instances from a positive bag to be higher than a negative bag \\cite{Sultani2018}. We define as\n\\begin{align}\n     \\mathcal{L}^\\text{MS}=\\left\\{1-\\max_{i\\in \\mathcal{B}_{pos}}[f({\\bf x}_i^+;{\\bf w})]+\\max_{j\\in \\mathcal{B}_{neg}}[f({\\bf x}_j^-;{\\bf w})]\\right\\}_+\\label{eq:max_mil}\n\\end{align}\nwhere $f({\\bf x};{\\bf w}) \\in [0,1]$ is the prediction score of instance ${\\bf x}$ provided by a deep neural network parameterized by ${\\bf w}$ and $[a]_+ = \\max\\{0, a\\}$. We will omit ${\\bf w}$ from $f({\\bf x};{\\bf w})$ to keep the notation uncluttered. The above objective function aims to maximize the gap between the maximum prediction score of instances from a positive bag and maximum score from a negative bag. Model training can be performed by sampling pairs of positive and negative bags $(\\mathcal{B}_{pos}, \\mathcal{B}_{neg})$, using their bag-level labels to evaluate the loss, and performing back-propagation. The maximum score based MIL (referred to as MS-MIL) models are designed primarily for bag label prediction as it aims to identify a single most positive instance from a positive bag and maximizes its prediction score. In this way, it fully leverages the MIL assumption (\\ie at least one positive instance in $\\mathcal{B}_{pos}$) and the weakly supervised signal (\\ie bag-level label). \n\n\nAs discussed earlier, MS-MIL and its top-$k$ extensions suffer from key limitations that impact their instance-level prediction performance. Meanwhile, they provide inadequate support to sample the most informative instances to enhance the instance predictions. Inspired by the recent advances in learning theory to automatically balance bias and variance in risk minimization~\\cite{Duci2019}, we propose a novel variance regularized MIL loss function to capture the inherent characteristics of  MIL, aiming to collectively address highly imbalanced instance distribution, existence of outliers, and multimodal scenarios. As a result, minimizing the new MIL loss can effectively improve the prediction scores of the positive instances, making them easier to be sampled for annotation by the proposed sampling function. In particular, the variance regularized loss introduces {\\em two novel changes} to \\eqref{eq:max_mil}, which are formalized below:\n\\begin{align}\n \\mathcal{L}^\\text{VAR} = \\left\\{1-\\left[\\frac{1}{n}\\sum_{i=1}^nf({\\bf x}_i^+)+C\\sqrt{\\frac{\\text{Var}_n[f(X^+)]}{n}}\\right]+\\max_{j\\in \\mathcal{B}_{neg}}\\left[f({\\bf x}_j^-)\\right]\\right\\}_+\\label{eq:variance_regularized}\n\\end{align}\nwhere $\\forall i \\in [1,n], {\\bf x}_i^+\\in \\mathcal{B}_{pos}$, $n$ is the size of $\\mathcal{B}_{pos}$, $\\text{Var}_n$ is the empirical variance of $f(X^+)$ with $X^+$ being a random variable representing an instance from a positive bag, and parameter $C$ balances the mean score and the variance. \n\nThe first key change is to use the mean score to replace the maximum score in \\eqref{eq:max_mil}, which avoids the model to only focus on the most positive instance in a bag to make it robust to outliers and multimodal scenarios. Since positive bags are guaranteed to include positive instances and instances in a negative bag are all negative, it is desirable that the mean score for a positive bag should be high. Maximizing the mean score in a positive bag using a complex model (\\eg a DNN) could effectively reduce the training loss (by reducing the bias) in estimating the bag-level labels. However, using the mean score alone is problematic as most instances in a positive bag are usually negative in a typical MIL setting. As a result, such a low bias model will lead to a very high false positive rate, which negatively impacts the overall instance-level prediction. The proposed loss function addresses this issue through the novel variance term, which effectively handles the highly imbalanced instance distribution. With only a small number of instances being truly positive, the empirical variance $\\text{Var}_n$ for the bag should be high due to the large deviation of a small number of high scores from the majority of low scores. It is worth to note that the variance term in \\eqref{eq:variance_regularized} plays a distinct role than risk minimization in standard supervised learning, where it is minimized to control the estimation error. In contrast, the variance in \\eqref{eq:variance_regularized} is encouraged to be large to allow a small set of instances in a bag to be positive, aiming to precisely capture the imbalanced distribution. To our best knowledge, this is the first bias-variance formulation in the MIL setting. \n\nConducting MI-AL using variance regularization still faces two  challenges. First, its effectiveness  hinges on an optimal balance between the mean score and the empirical variance, which is controlled by the hyperparameter $C$. Similar to the standard supervised learning, there lacks a systematic way of setting such a hyperparameter to achieve an optimal trade-off. Second, the variance term is non-convex with multiple local minima~\\cite{Duci2019}, which makes model training much more difficult and time-consuming. Thus, it is not suitable for real-time interactions to support active sampling. \n\n\n\\vspace{-2mm}\n"
                },
                "subsection 3.2": {
                    "name": "Distributionally Robust Bag Likelihood",
                    "content": "\\label{sec:drbl}%\\vspace{-1mm}\nTo address the challenges as outlined above, we propose to formulate a distributionally robust bag level likelihood (DRBL) as a convex surrogate of the variance regularized loss in \\eqref{eq:variance_regularized}. By extending the distributionally robust optimization framework developed for risk minimization in supervised learning~\\cite{Namkoong2017,Duci2019}, we theoretically prove the equivalence between DRBL and variance regularization with high probability. Being convex, DRBL is easier to optimize that  facilitates MIL model training to support fast active sampling. Furthermore, by setting a proper uncertainty set as introduced next, we show that the  parameter $C$ is directly obtained when optimizing the DRBL, where the instance distribution in the bag is constrained by the uncertainty set. As a result, it achieves automatic trade-off between the mean prediction score and the variance. \n\nWe first introduce a probability vector ${\\bf p}=(p_1,...,p_n)^{\\top}$, where $\\sum_i p_i=1,p_i\\ge 0, \\forall i \\in \\{1,...,n\\}$ and let $p_i$ denote the probability that instance ${\\bf x}_i^+\\in \\mathcal{B}_{pos}$ can represent the bag. We further introduce a binary indicator vector ${\\bf z}=(z_1,...,z_n)^{\\top}$, where $p(z_i=1)=p_i$. Let $Y$ be a binary random variable that denotes the bag label. Conditioning on all the instances in the bag, the (conditional) bag likelihood for bag $\\mathcal{B}_{pos}$ is given by $p(Y=1|{\\bf z},{\\bf f})=\\prod_i f({\\bf x}_i^+)^{z_i}$, where ${\\bf f}=(f({\\bf x}_1^+),...,f({\\bf x}_n^+))^{\\top}$. By integrating out the indicator variables, we have the marginal bag likelihood as $p(Y=1|{\\bf p},{\\bf f})=\\sum_i p_if({\\bf x}_i^+)$. Instead of letting a single most positive instance to determine the bag label, where $p(y=1|{\\bf p},{\\bf f})= f({\\bf x}_k^+)$ with $k=\\arg \\max_i f({\\bf x}_i^+)$, which is equivalent to MS-MIL, or assigning equal probability to each instance (\\ie $p_i=1/n$), which is equivalent to the mean score, we introduce an uncertainty set $\\mathcal{P}_n$ that allows ${\\bf p}$ to deviate from a uniform distribution to some extent:\n\\begin{equation}\n\\mathcal{P}_n :=\\left\\{{\\bf p}\\in \\mathbb{R}^n, {\\bf p}^{\\top}\\mathbbm{1}=1, 0\\leq {\\bf p}, D_f\\left({{\\bf p}||\\frac{\\mathbbm{1}}{n}}\\right)\\leq \\frac{\\lambda}{n}  \\right\\}\\label{eq:uncertainty_dro}\n\\end{equation}\nwhere $D_{f}({\\bf p}||{\\bf q})$ is the $f$-divergence between two distributions $\\bf p$ and $\\bf q$, $\\mathbbm{1}$ is a $n$-dimensional unit vector, and $\\lambda$ controls the extent that ${\\bf p}$ can deviate from a uniform vector, which essentially corresponds to the imbalanced instance distribution in the bag. Note that $\\mathcal{P}_n$ only specifies a neighborhood that ${\\bf p}$ may deviate from a uniform distribution. Since $\\mathcal{P}_n$ is a convex set, an optimal ${\\bf p}$ can be easily computed for each specific bag by optimizing the robust bag likelihood according to its specific imbalanced instance distribution. This is fundamentally more advantageous than a top-$k$ approach, where $k$ is discrete and hard to optimize. Next, we show that the optimal robust bag likelihood is equivalent to the variance regularized mean prediction score with high probability, which allows us to define a new MIL loss based on DRBL.  \n\n\n%To solve the limitations presented in the variance-regularized technique, we propose DRO based objective function that can approximate the variance regularized by high probability.\n\n\\begin{theorem}\nLet $X^+$ be a random variable representing an instance from a positive bag, $f(X^+) \\in [0, 1]$ is the score assigned to an instance, $\\sigma^2=\\text{Var}[f(X^+)]$ and $\\text{Var}_n[f(X^+)]$ denote the population and sample variance of $f(X^+)$, respectively, and $D_{f}$ takes the form of $\\chi^{2}$-divergence. For a fixed $\\lambda$ and with $n\\geq \\max(2, \\frac{\\lambda}{\\sigma^2}\\max(8\\sigma, 44))$, \n%$\\theta \\in \\Omega$ and $D_{f}(p, q)$ be the squared Euclidean distance between two distributions $p$ and $q$. If $n\\geq \\max(2, \\frac{\\lambda}{\\sigma^2}\\max(8\\sigma, 44)$ then with probability at least $1-\\exp\\left(-{\\frac{3n\\sigma^2}{10}}\\right)$ we have\n\\begin{equation}\n\\max_{{\\bf p}\\in {\\mathcal{P}_n}}\\sum_{i=1}^np_if({\\bf x}_i^+) = \\frac{1}{n}\\sum_{i=1}^nf({\\bf x}_i^+)+\\sqrt{\\frac{\\lambda Var_n[f(X^+)]}{n}} \n\\label{eq:dro-variance-eqivalence}\n\\end{equation}\nwith probability at least $1-\\exp\\left(-{\\frac{7n\\sigma^2}{20}}\\right)$, where $\\mathcal{P}_n$ is an uncertainty set defined by \\eqref{eq:uncertainty_dro}. \n\\label{th:dro_variance_equi_formula}\n\\end{theorem}\nIt is worth to note that given the highly imbalanced positive instances in a typical MIL setting, the true variance $\\sigma^2$ should be high. For a bag with a decent size, it guarantees the equivalence in \\eqref{eq:dro-variance-eqivalence} with high probability. Furthermore, maximizing the robust bag likelihood given on the l.h.s. of \\eqref{eq:dro-variance-eqivalence} assigns $C=\\sqrt{\\lambda}$, which automatically adjusts the impact of variance based on the uncertainty set. \n%In Theorem \\ref{th:dro_variance_equi_formula}, $D_f$ takes the form of $\\chi^{2}$-divergence between two distributions.\nTheorem \\ref{th:KL} below further generalizes this result to the KL-divergence.\n\n\\begin{theorem}\nLet $X^+$ be a random variable representing an instance from a positive bag, $f(X^+) \\in [0, 1]$ is the score assigned to an instance, $\\sigma^2=\\text{Var}[f(X^+)]$ and $\\text{Var}_n[f(X^+)]$ denote the population and sample variance of $f(X^+)$, respectively, and $D_{f}$ takes the form of KL-divergence. We have\n\\begin{equation}\n\\begin{aligned}\n\\max_{{\\bf p}\\in {\\mathcal{P}_n}} & \\sum_{i=1}^np_if({\\bf x}_i^+) = \\frac{1}{n}\\sum_{i=1}^nf({\\bf x}_i^+)+\\sqrt{\\frac{2\\lambda \\text{Var}_n[f(X^+)]}{n}}+\\epsilon\\left(\\frac{\\lambda}{n}\\right)\\\\\n%\\text{s.t.~} & \\mathcal{P}_n :=\\left\\{{\\bf p}\\in \\mathbb{R}^n, {\\bf p}^{\\top}\\mathbbm{1}=1, 0\\leq {\\bf p}, D_{KL}\\left({{\\bf p}||{\\bf p}_0}\\right)\\leq \\frac{\\lambda}{n} \\right\\}\n    \\label{eq:dro_kl_variance_equivalence}    \n\\end{aligned}\n\\end{equation}\n\\label{th:KL}\nwhere %${\\bf p}_0 = \\frac{\\mathbbm{1}}{n}$ is the uniform distribution indicating the center of the ball,\n$\\epsilon\\left(\\frac{\\lambda}{n}\\right)=\\frac{\\lambda}{3n}\\frac{\\mathcal{\\kappa}_3(f(X^+))}{\\text{Var}_n[f(X^+)]}+\\mathcal{O}\\left(\\left(\\frac{\\lambda}{n}\\right)^{3/2}\\right)$ with $\\kappa_3 = \\mathbb{E}_0[(f(X^+)-\\mathbb{E}_0[f(X^+)])^3]$ and $\\mathbb{E}_0$ denotes the expectation taken over ${\\bf p}_0$.\n\\end{theorem}\n{\\bf Remark}: Given a bag with a decent size $n\\gg 1$ and since $\\lambda$ is usually set to $\\lambda \\ll 1$ ($0.01$ is used in our experiments), we have $\\epsilon\\left(\\frac{\\lambda}{n}\\right)\\to 0$. When the empirical variance $\\text{Var}_n[f(X^+)]$ is sufficiently large (which is true for MIL), the r.h.s. of \\eqref{eq:dro_kl_variance_equivalence} is dominated by the first two terms, which implies \n\\begin{equation}\n\\begin{aligned}\n\\max_{{\\bf p}\\in {\\mathcal{P}_n}} \\sum_{i=1}^np_if({\\bf x}_i^+) \\approx \\frac{1}{n}\\sum_{i=1}^nf({\\bf x}_i^+)+\\sqrt{\\frac{2\\lambda \\text{Var}_n[f(X^+)]}{n}}\n\\end{aligned}\n\\end{equation}\n\n\n\nDetailed proofs are given in Appendix~\\ref{app:proof}.  %For a detailed proof of both Theorems, please refer to Appendix~\\ref{app:proof}.    \nLeveraging the above theoretical results, we formulate a DRBL-based MIL loss as \n%The corresponding loss after using DRO loss is given as\n\\begin{equation}\n    \\mathcal{L}^\\text{DRBL} = \\left\\{1-\\max_{{\\bf p}\\in \\mathcal{P}_{n}}\\left[\\sum_{i=1}^np_if({\\bf x}_i^+)\\right]+\\max_{j\\in \\mathcal{B}_{neg}}\\left[f({\\bf x}_j^-)\\right]\\right\\}_+\\label{eq:dro_loss_single_bag}\n\\end{equation}\nThe DRBL loss offers a very intuitive interpretation on the newly introduced probability vector $\\bf p$. Since it can deviate from the uniform distribution as specified by the uncertainty set $\\mathcal{P}_{n}$, each entry $p_i$ essentially corresponds to the contribution (or weight) of ${\\bf x}_i^+$ to the bag likelihood (being positive). As a result, to maximize the robust bag likelihood, instances with a higher prediction score should receive a higher weight. Meanwhile, constrained by $\\mathcal{P}_{n}$, multiple instances will contribute to the bag likelihood with a sizable weight as $\\bf p$ cannot deviate too much from being uniform. Hence, their prediction scores will simultaneously be brought up by the model. This makes DRBL robust to the outlier and multimodal cases as it increases the chance for the true positive instances or multiple types of true positive instances to be assigned a high prediction score. This provides fundamental support to the proposed P-F active sampling function that combines the probability vector $\\bf p$ and the prediction score $\\bf f$ in a novel way to choose the most informative instances in a bag for annotation. \n\n\\vspace{-2mm}\n"
                },
                "subsection 3.3": {
                    "name": "P-F Active Sampling",
                    "content": "%\\vspace{-1mm}\nSince we have the prediction score $f({\\bf x}_i^+) \\in [0,1]$, it can be naturally interpreted as the probability of instance ${\\bf x}_i^+$ being positive. A straightforward way to perform uncertainty based instance sampling is to compute the $f$-score based entropy of the instances, referred to F-Entropy: \n\\begin{align}\n    {\\bf x}_*&= \\arg \\max_{i \\in \\mathcal{B}_{pos}} H[f({\\bf x}_i^+)],  %\\quad \\text{where}\\\\\n    \\label{eq:f-entropy}\n\\end{align}\nwhere $ H[f] =-[f\\log f+(1-f)\\log (1-f)]$.\nSince the sampled instance has the largest prediction uncertainty (according to F-Entropy), labeling such an instance can effectively improve the model's instance-level performance. Active sampling using \\eqref{eq:f-entropy} is straightforward, which involves evaluating $H[f({\\bf x}^+)]$ for all the instances from positive training bags (note that all the instances in a negative bag are negative). Since we consider a deep learning model to better accommodate high-dimensional data, \n%including images and videos, which are common for MIL problems,  \nsampling one instance at a time requires frequent model training, which is computationally expensive. Instead, we sample a small batch of instances in each step based on their predicted F-Entropy. It is worth to note that, due to the highly imbalanced instance distribution, the majority of the prediction scores, including many positive instances, may be very low. The goal is to assign a relatively higher score to the potentially positive instances so that their entropy is not too low, indicating a confident negative prediction, which will be missed by the sampling function. \n\n\n\nAs discussed earlier, using the robust bag likelihood as the MIL loss can directly benefit instance sampling by increasing the chance to assign a higher prediction score to a positive instance so that it is more likely to be sampled. However, F-Entropy sampling still suffers from two major limitations. First, for some very difficult bags, such as the sample image shown in Figure~\\ref{fig: illustrative_examples_max_vs_proposed} (a), identifying the positive instances (\\eg the patch in the image containing the shadow of a bird) can be highly challenging. As a result, they may be assigned a very low $f$ score. In fact, as shown in Figure~\\ref{fig: illustrative_examples_max_vs_proposed} (c), all the instances in this bag receive a very low score with the highest less than 0.01, leading to a very low entropy.  Some additional examples of challenging bags from the 20NewsGroup dataset are shown in Figure~\\ref{fig:morebagexamples} of Appendix~\\ref{app:examplebags}, where all the instances are predicted with a very low score. Hence, all these instances are predicted as negative with low uncertainty, making them less likely to be chosen by entropy based sampling. \nSecond, since batch-mode sampling is adopted to reduce the training cost of a deep network, it is essential to diversify the selected instances in the same batch to minimize the annotation cost. However, choosing data instances solely based on their predicted entropy may lead to the annotation of similar instances, which is not cost-effective.  \n\n\nThe proposed P-F active sampling overcomes the above two limitations simultaneously through effective bag exploration by combining the probability vector $\\bf p$ and the prediction score $\\bf f$ through a $\\min\\max$ function according to their distinct roles in a bag. The key design rationale of P-F sampling is rooted in the standard MIL assumption that ensures at least one positive instance in each positive bag to guide effective bag exploration. Both $\\bf p$'s and $\\bf f$'s along with the bag structure are dynamically updated during bag exploration to increase the chance of sampling the positive instances in an under-explored bag. A hybrid loss function further utilizes labels of  sampled negative instances in the same bag to boost the prediction scores of the positive instances. More specifically, let $B$ be the total number of positive training bags, P-F sampling will choose the following data instance:\n%for a positive $\\mathcal{B}_b$, where $b\\in \\{1,...,B\\}$ with $B$ being the total number of positive training bags, we choose instance with the max entry from its probability vector ${\\bf p}_b$: \n\\begin{equation}\n    {\\bf x}^{PF}_*=\\arg \\min_{b\\in \\{1,...,B\\}} f({\\bf x}^+_{b_*}), \\quad \\text{and } b_*=\\arg \\max {\\bf p}_b\n    \\label{eq:pfsampling}\n\\end{equation}\nwhere ${\\bf p}_b$ is the probability vector of bag $b$. For each bag, the sampling function first identifies the instance ${\\bf x}^+_{b_*}$ with the largest $p$ value in each bag. Such an instance can be regarded as the most representative instance in the bag as it makes the largest contribution (according to ${\\bf p}_b$) to the bag likelihood. According to the prediction score of ${\\bf x}^+_{b_*}$, we can categorize bags into three groups: (1) easy bags, where $f({\\bf x}^+_{b_*})$ takes a large value, indicating that the model makes confidently correct predictions, (2) confusing bags, where $f({\\bf x}^+_{b_*})$ is reasonably large but uncertain, indicating the model is still confusing about its prediction, and (3) difficult bags, where $f({\\bf x}^+_{b_*})$ is very low, indicating the model makes confidently wrong predictions. It is desirable to sample from both confusing and difficult bags as the model already makes accurate instance predictions for easy bags. Sampling instances from the confusing bags can be achieved through the proposed F-Entropy as the model makes uncertain predictions, which leads to a high entropy. Finally, sampling from the difficult bags is fundamentally more challenging due to low prediction scores for the entire bag. However, the MIL assumption provides a general direction for bag-level exploration of positive instances as there must be at least one positive instance in each positive bag. The P-F sampling function in \\eqref{eq:pfsampling} chooses the representative instance from the bag with the lowest prediction score. Such an instance is guaranteed to be sampled from an under-explored (\\ie difficult) bag as it has the lowest prediction score despite being predicted as the most positive instance in the bag. \n\nExtension to the batch-mode sampling is conducted in two directions, within a bag and across bags, for more effective exploration while ensuring diversity of the sampled instances. First, instead of only sampling the most positive instance from the identified under-explored bag, we propose to sample $k>1$ instances as the positive instances may be ranked lower than multiple negative instances in the bag according to the current prediction scores (see Figure~\\ref{fig: illustrative_examples_max_vs_proposed} (c) for an example). This helps to more effectively explore very difficult bags. To ensure diversity among the sampled instances, we keep $k$ small but sample across multiple bags simultaneously. Only bags with a max prediction score $f({\\bf x}^+_{b_*})$ less than a threshold (0.3 is used in our experiments) will be explored as these represent the difficult bags as discussed above. For bags with a larger $f({\\bf x}^+_{b_*})$, they are either easy bags or confusing bags that can be effectively sampled using F-Entropy. Our overall P-F sampling function integrates bag exploration and F-Entropy and gives priority to the former to perform diversity-aware bag exploration first. As more bags are successfully explored along with MI-AL, less instances will be sampled by exploration and the focus will be naturally shifted to F-Entropy to perform model fine-tuning. The detailed sampling process is summarized by Algorithm~\\ref{alg: sampling}. \n\nSimilar to AL in standard supervised learning, the sampled annotated instances should be used to improve the model prediction performance. However, the MIL loss primarily focuses on the bag-level labels due to the lack of instance labels. To this end, we propose a hybrid loss function that integrates the bag and instance labels.  Let ${\\bf X}^l=\\{{\\bf x}^l_1, {\\bf x}^l_2,..., {\\bf x}^l_m\\}$ be the $m$ labeled instances queried by the proposed active learning function and ${\\bf t}^l = \\{t^l_1,  t^l_2,..., t^l_m\\}$ with $t_l^i\\in \\{0, 1\\}$ be the corresponding instance labels. We formulate a supervised binary cross-entropy (BCE) loss as\n\\begin{equation}\n    L^\\text{BCE} = -\\frac{1}{m}\\sum_{i=1}^m\\left[t_i^l\\log(f({\\bf x}_i^l))+(1-t_i^l)\\log(1-f({\\bf x}_i^l))\\right] \\label{eq:bce_loss}\n\\end{equation}\nIt is clear that the sampled positive instances provide important supervised signals so that the model will predict a high score for similar positive instances, which will directly benefit instance-level prediction. In contrast, the sampled negative instances, especially those chosen from the under-explored bags, contribute less to improve the prediction performance as their original prediction scores are already low. However, they play a subtle but essential role to achieve more effective bag-level exploration. First, if a sampled instance is labeled as negative, it will be removed from the bag, which does not violate the MIL assumption. Meanwhile, since we have $\\sum_ip_i=1$, the $p$ values will be redistributed and the chance for each remaining instance to be sampled is therefore increased. Furthermore, the BCE loss will further bring down the prediction scores of negative instances that are similar to the sampled one. This may help to improve the score of the positive instance so that it can have a higher chance to be sampled in the future. Finally, the hybrid loss that combines the MIL loss and the supervised loss is used to retrain the model after a new batch of instances are queried:\n\\begin{equation}\n\\mathcal{L}^\\text{Hybrid}= \\mathcal{L}^{DRBL}(\\mathcal{B}_{pos}, \\mathcal{B}_{neg})+\\beta \\mathcal{L}^{BCE}({\\bf X}^l, {\\bf t}^l)\n    \\label{eq:total_loss}\n    %\\vspace{-2mm}\n\\end{equation}\nwhere $\\beta$ is used to trade-off bag- and instance-level losses.\n\\vspace{-2mm}\n\n\\begin{algorithm}\n\n\\DontPrintSemicolon\n  \n  \\KwInput{${\\bf p}_{{\\mathcal B}_{pos}}$, ${\\mathcal Q}_{prev}$, $Th_{PF}$, $Th_{H}$, $BSize$, $k$}\n  \\KwOutput{$\\mathcal{Q}$}\n  \\KwData{$B$ positive training bags \\tcp{Feature vector for each bag}} \n {\\bf Initialization:}  $\\mathcal{U}_B = \\{\\}$, count = 0, $\\mathcal{Q}_{P-F} =\\{\\}$, $\\mathcal{Q}_{F} =\\{\\}$ \\;\n  \\For{$b \\in [B]$}{\n  ${\\bf p}_b\\leftarrow {\\bf p}_{\\mathcal{B}_{pos}}[b]$,\n  $b_{*}\\leftarrow \\argmax {\\bf p}_{b} \\setminus \\mathcal{Q}_{prev}[b]$ \\;\n  \\If{$f({\\bf x}_{b_*}^+)\\leq Th_{PF}$ } \n    {\n        $\\mathcal{U}_{B} \\leftarrow b_*$ \\;\n    }\n  \n  }\n  \\tcc{Adding instances from unexplored bags}\n  $\\mathcal{U}_{B} = \\argsortAsc_{b_* \\in {\\mathcal{U}_{B}}}f({\\bf x}_{b_*}^+)$ \\;\n  \n  \\For{$b_*$ $\\in$ $\\mathcal{U}_{B}$}{\n  \\If{$b_{*}$ $\\in$ $\\mathcal{Q}_{prev}$}\n    {\n       \\If{positive ins $\\in$ $\\mathcal{Q}_{prev}[b]$}\n        {continue}\n        }\n        \n    \n    \\Else{\n    $\\mathcal{X}^{PF} = \\argsortDesc_{b_{*}} \\left(f({\\bf x}_{b_*}^+) \\setminus \\mathcal{Q}_{prev}[b_{*}]\\right)$[:$k$] \\;\n    \\For{${\\bf x}_i \\in \\mathcal{X}^{PF}$}\n    {\n    \\If{count$\\geq$ BSize}\n        {break}\n        $\\mathcal{Q}_{P-F}[b_{*}] \\leftarrow {\\bf x}_i$ \\;\n        count $\\leftarrow$ count+1\\;\n    }\n    \n    \n        \n  \n    }\n  \n  }\n  \n   \n$\\mathcal{Q}_{prev} = \\mathcal{Q}_{prev} \\cup \\mathcal{Q}_{P-F}$ \\;\n\n\n\\tcc{Adding instances with highest F-Entropy; $H[f({\\bf x}_i^+)] = -\\left[f({\\bf x}_i^+\\log f({\\bf x}_i^+))+(1-f({\\bf x}_i^+))\\log(1-f({\\bf x}_i^+))\\right]$}\n\n$\\mathcal{C}_{idx} = \\argsortDesc_{i} \\left( H[f({\\bf x}_i^+)]\\geq Th_H\\right)$ \\;\n \\For{$i \\in \\mathcal{C}_{idx}$}\n    {\n    \\If{count$\\geq$ BSize}\n        {break}\n        \n    \\If{${\\bf x}^+_i \\in \\mathcal{Q}_{prev}[b_i]$}\n        {break}\n        \n        $\\mathcal{Q}_{F}[b_{i}] \\leftarrow {\\bf x}^+_i$ \\;\n        count $\\leftarrow$ count+1\\;\n    }\n    \n    \n\n  \n$\\mathcal{Q} = \\mathcal{Q}_{prev} \\cup Q_{F}$\n \n\\caption{{\\bf P-F Active Sampling \\label{alg: sampling}}}\n\\vspace{-1mm}\n\\end{algorithm}\n%\\vspace{-1mm}\n"
                }
            },
            "section 4": {
                "name": "Experiments",
                "content": "\nWe conduct extensive experimentation  over multiple real-world MIL datasets \nto justify the effectiveness of the proposed  ADMIL model.  The purpose of our experiments is to demonstrate: (i) the state-of-the-art instance prediction performance  by comparing with existing competitive baselines, (ii) effectiveness of the proposed P-F active sampling function through comparison with other sampling mechanisms, (iii) impact of key model parameters through a detailed ablation study, and (iv) qualitative evaluation through concrete examples to provide deeper and intuitive insights on the working rationale of the proposed model.\n\n\n\n\\vspace{-2mm}\n",
                "subsection 4.1": {
                    "name": "Experimental Setup",
                    "content": "\\vspace{-1mm}\n\n\\vspace{1mm}\\noindent{\\bf Datasets.} Our experiments involve four datasets covering both textual and image data: 20NewGroup~\\cite{Zhou2009}, Cifar10~\\cite{Krizhevsky2009LearningML},  Cifar100~\\cite{Krizhevsky2009LearningML}, and Pascal VOC \\cite{Everingham15}.\nThe detailed description of each dataset is given below and bag level statistics is summarized in the Table \\ref{tab: bag_level_distribution}\n\n%For 20NewsGroup, the dataset is already available in the MIL setting, which consists of 20 topics where each topic contains 50 positive and 50 negative bags. For Cifar10 and Cifar100 datasets, bags are constructed by treating each image as an instance. For Cifar10, images corresponding to 'automobile', 'bird', and 'dog' are regarded as a positive instance otherwise negative. In case of Cifar100, images in superclass flowers are treated as positive and the rest as negative. In Pascal VOC, we perform image segmentation so each image is regarded as a bag and corresponding patches cropped from the image are treated as instances. In our experiments, images containing birds as a positive bags and others as negative. Table \\ref{tab: bag_level_distribution}  summarizes the bag statistics.\n\n\\begin{itemize}[leftmargin=*]\n    \\item {\\bf 20NewsGroup:}  In this dataset, an instance refers to a post from a particular topic. % represented by a 200 dimensional TF-IDF feature vector \\citep{Zhou2009}. \n    For each topic, a bag is considered as positive if it contains at least one instance from that topic and negative otherwise. This dataset is particularly challenging because of the severe imbalance where there are very few ($\\approx 3\\%$) positive instances in each positive bag. While number of instances per bag may vary, on average there are around 40 instances per bag.\n    \\item {\\bf Cifar10:} In the original dataset, there are 50,000 training and 10,000 testing images with 10 classes indicating different images. The bags are constructed as follows. First, we pick `automobile', `bird', and `dog' related images as positive instances and the rest as negative. To construct a positive bag, we choose a random number from 1 to 3 and pick the positive instances equal to the randomly generated number. The rest of the instances are selected from a negative instances pool. For negative bags, all instances are selected from the negative instance pool. For each bag, we consider 32 instances. %For training purpose, we construct bags from original training set whereas, for validation purpose we construct bags from original testing set. %The detailed bag level distribution is presented in the Table \\ref{tab: bag_level_distribution}. \n    \\item {\\bf Cifar100:} The dataset consists of 50,000 training and 10,000 testing images with 20 different superclasses indicating different species. Bag construction is similar to Cifar10, where images in superclass flowers are treated as positive and the rest as negative.  \n    \n    \\item {\\bf Pascal VOC:} This dataset consists of 2,913 images, where images are used for segmentation. Each image is treated as a bag and instances are obtained as follows. We define a grid size of $60\\times 75$ and partition the images. Depending on the image size, the number of instances may vary. We treat an instance as positive if at least $5\\%$ of the total pixels in a given instance are related to the object of interest otherwise negative. In our case, we considerthe  bird as the object of interest. All the images consisting of bird are regarded as positive bags and others as negative. %We randomly split positive bags into 60:40 ratio to yield training and validation set. We select the same number of negative bags that is equal to positive bags. The detailed bag level statistics is presented in the Table \\ref{tab: bag_level_distribution}.\n\\end{itemize}\n\n \n\n \n%\\vspace{-2mm}\n\\noindent{\\bf Evaluation metric and model training.}\nTo assess the model performance, we report the instance-level mean average precision (mAP) score, which summarizes a precision-recall curve as a weighted mean of precision achieved at each threshold, with the increase in recall from the previous threshold as the weight. mAP explicitly places much stronger emphasis on the correctness of the few top ranked instances than other metrics (\\eg AUC)~\\cite{su2015relationship}. This makes it particularly suitable for instance prediction evaluation as a small subset of instances with the highest prediction scores will eventually be identified as positive for further inspection (by human experts) with the rest being ignored. For Cifar10, Cifar100, and Pascal VOC datasets, we extract the visual features from the second-to-the last layer of a VGG16 network pre-trained using the imagenet dataset, yielding a 4,096 dimensional feature vector for each instance. For 20NewsGroup, we use the available 200-dimensional feature vector. In terms of network architecture, we use a 3-layer FC neural network. The first layer has 32 units followed by 16 units and 1 unit FC layers. We adopt $60\\%$ dropout between FC layers. ReLU and sigmoid activations are used for the first and last FC layers. Learning rate 0.01 is used for all dataset except for 20NewsGroup which is 0.1.\n\n\\vspace{-2mm}\n"
                },
                "subsection 4.2": {
                    "name": "Performance Comparison",
                    "content": "%\\vspace{-1mm}\n%{\\bf Performance comparison.} \nTo demonstrate the instance prediction performance achieved by the proposed ADMIL model, we compare it with competitive baselines. First, the two MI-AL sampling strategies: MIAL-Uncertainty and MIAL-MIU \\cite{settles2007multiple}, from the MI logistic model are included. Since our datasets involve high-dimensional data, we replace the original linear model by the exact DNN model used in our ADMIL so we can focus on comparing MI active sampling. The EGL sampling technique in \\cite{settles2007multiple} was not included due to the prohibitive computational cost to evaluate the gradient of each instance output with respect to the large number of DNN parameters. We also implement an MS-MIL model and its top-$k$ variant with uncertainty sampling using entropy. Given the different sizes of the datasets, we query maximum 15 instances per step in 20NewsGroup, 30 instances in Pascal VOC, and 150 instances in Cifar10 and Cifar100. Figure~\\ref{fig: al_curve_comparison_mean_sd} shows the MI-AL curves with one standard deviation (computed over three runs) represented by vertical black line for all four datasets. ADMIL achieves the best performance in all cases. For most datasets, it shows a much better initial performance, which results from the proposed DRBL-based MIL loss that significantly benefits MIL performance in passive learning. Overall the entire MI-AL process, ADMIL consistently stays the best and converges to a higher point in the end for all datasets. For the Pascal VOC, the top-$k$ MIL model with entropy sampling achieves closer performance towards the end, which is mainly due to the limited positive instances in this dataset. Hence, no testing bags contain similar positive instances in the challenging bags that are explored by P-F sampling. While ADMIL achieves much better instance predictions in those bags, the advantage does not transfer to the testing bags. For reference, we also compare ADMIL with two recently developed MIL models, including Ilse et al. \\cite{Ilse2018} and  Hsu et al. \\cite{Hsu2020QueryDrivenML}, under the passive setting. \nAs shown in Table~\\ref{tab: dro_passive_performance}, ADMIL achieves better or at least comparable performance as compared with these competitive baselines. \n%comparable (better) to the state-of-the-art techniques which \nThis clearly justifies of using ADMIL as a base model for active sampling. After labeling a small set of actively sampled instances, the performance is significantly boosted (as shown in the parenthesis), which further justifies the benefits of combining AL with MIL. Our qualitative study will provide a more detailed analysis on this.\n\n\n\n\n \n\n\n\n \n\n\n\n\\vspace{1mm}\\noindent{\\bf Effectiveness of active sampling.} To demonstrate the effectiveness of the proposed P-F active sampling function, \nwe compare it with two other sampling methods, F-Entropy and random sampling, while keeping all other parts of the model the same. As shown in Figure \\ref{fig: al_curve_ablation}, P-F sampling clearly outperforms others with a large margin in the first three datasets. It's advantage over F-Entropy is smaller on Pascal VOC due to the same reason as explained above. The performance gain is mainly attributed to the effective exploration of P-F sampling over the most challenging bags.\n\n\\vspace{-3mm}\n"
                },
                "subsection 4.3": {
                    "name": "Ablation Study",
                    "content": "\\vspace{-1mm}\n\n\\vspace{1mm}\\noindent{\\bf Impact of $\\lambda$ and $\\beta$:}\nFigures~\\ref{fig: ablation_lambda} and ~\\ref{fig: ablation_beta} demonstrate the impact of  $\\lambda$ (with $\\beta = 1$) and $\\beta$ (with $\\lambda$ = 0.01) to the model performance. In particular, $\\lambda$ can be set according to the imbalanced instance distribution within bags, where a larger $\\lambda$ corresponds to a higher imbalanced distribution. We vary $\\lambda$ in $[10^{-10},1]$ and since most bags in the MIL setting are highly imbalanced,  relatively higher $\\lambda$ value  gives very good performance in general. Figure~\\ref{fig: ablation_lambda}  shows that $\\lambda=0.0001$ clearly outperforms too large (or small) $\\lambda$ values. As for $\\beta$, placing less emphasis on an instance level loss (small $\\beta$), we may not fully leverage labels of queried instances. Meanwhile, with too much emphasis on the instance level loss (large $\\beta$), the model overly focuses on the limited queried instances with less attention to the bag labels. Therefore, a good balance  results in an optimal performance, shown in Figures~\\ref{fig: ablation_beta}.  %Figure~\\ref{fig: ablation_hyperparameters_cifar10_20newsgroup} show the impact of $\\lambda$ and $\\beta$ on Cifar10 and 20NewsGroup datasets. Similar to the findings on the other two datasets, Figures~\\ref{fig: ablation_hyperparameters_cifar10_20newsgroup} (b) and (d)  demonstrate that a $\\lambda$ in the middle range outperforms too large (or small) $\\lambda$ values. In case of $\\beta$, placing too less  (or too much) emphasis may result in overly (or poorly) leveraging annotated instances. Therefore, a good balance between the bag-level and instance-level losses achieves the best result, as shown in Figures~\\ref{fig: ablation_hyperparameters_cifar10_20newsgroup} (a) and (c). \n\n\n\n\n\\vspace{1mm}\\noindent{\\bf Impact of $k$:}\nFigure~\\ref{fig: al_curve_ablation_k} shows the impact of the hyperparameter $k$, which is the number of instances queried in each unexplored bag, on model performance. As can be seen, $k=2$ achieves a generally decent performance across all the datasets. For datasets with a larger size (\\eg Cifar100), a larger $k$ leads to a slightly better performance. \n\n\n\n\n\n%Figure~\\ref{fig: al_curve_comparison_mean_sd} reports the performance comparison with one standard deviation (computed over three runs), which is represented by the vertical black line. As discussed in the main paper, the mean MI-AL curve of ADMIL clearly outperforms other competitive baselines. Meanwhile, the standard deviation of the proposed ADMIL model is also relatively small, which indicates its overall stable MI-AL performance across different datasets in multiple runs.\n\n\n \n\n\n\\vspace{-2mm}\n"
                },
                "subsection 4.4": {
                    "name": "Qualitative analysis",
                    "content": "\n To further justify why the proposed ADMIL model and its P-F sampling function work better than other baselines, we provide a few illustrative examples to offer deeper insights on its good performance. First, we show two challenging bags in addition to the one shown in Figure~\\ref{fig: illustrative_examples_max_vs_proposed} (a). As shown in Figure~\\ref{fig: poorly_explored_bags} (a-b), B$_2$ presents a side view of a bird while only a small portion of the bird is visible in B$_3$. For those difficult cases, the model originally predicts all instances as a negative with high confidence. However, by coupling the P-F sampling and the hybrid loss in \\eqref{eq:total_loss}, the positive instances from those bags are successfully queried. Figure \\ref{fig: poorly_explored_bags} (c) shows a clear advantage in the mAP scores between P-F sampling and F-Entropy. As a further evidence, we investigate the number of true positive (TP) bags being explored by both P-F sampling and F-Entropy. TP bags refer to those that the model is being able to query at least one true positive instance. Instead of reporting the actual number of bags, which is affected by the size of the dataset, we show the additional percentage TP bags being explored by P-F sampling in Figure~\\ref{fig: poorly_explored_bags} (d). It is worth to note that neither method tries to query the easy bags as their positive instances are correctly predicted with high confidence. The major difference is from the challenging bags and the percentage of these bags varies among different datasets. Nevertheless, P-F sampling consistently explores more effectively than F-Entropy across all datasets. \n\\vspace{-2mm}\n"
                }
            },
            "section 5": {
                "name": "Conclusion",
                "content": "\nTo tackle the low instance-level prediction performance of existing MIL models that is essential for many critical applications, \nwe develop a novel MI-AL model to sample a small number of most informative instances, especially those from confusing and challenging bags, to enhance the instance-level prediction while keeping a low annotation cost. \n%Considering the inherent challenges in the MIL setting, including imbalanced data distribution and existence of noises and multimodal scenarios, \nWe propose to optimize a robust bag likelihood as a convex surrogate of a variance regularized MIL loss to identify a subset of potentially positive instances. Active sampling is conducted by properly balancing between exploring the challenging bags (through P-F sampling) and refining the model by sampling the most confusing instances (through F-Entropy). The design of the loss function naturally supports mini-batch training, which coupled with the batch-mode sampling, makes the MI-AL model work seamlessly with a deep neural network to support broader MIL applications that involve high-dimensional data. Our extensive experiments conducted on multiple MIL datasets show clear advantage over existing baselines. \n%\\vspace{-2mm}\n"
            },
            "section 6": {
                "name": "Acknowledgement",
                "content": "\nThis research was supported in part by an NSF IIS award IIS-1814450 and an ONR award N00014-18-1-2875. The views and conclusions contained in this paper are those of the authors and should not be interpreted as representing any funding agency. \n%\\vspace{-2mm}\n\\bibliographystyle{ACM-Reference-Format}\n\\bibliography{ref}\n\\newpage\n\\appendix\n\n%Finally, we provide the link to the source code in Appendix~\\ref{app:sourcecode}.\n\n\n"
            },
            "section 7": {
                "name": "Proofs of Theorems",
                "content": " \\label{app:proof}\nIn this section, we provide the detailed proofs for both theorems. \n\n%{\\bf Proof of Theorem 1.} \n\\paragraph{Proof of Theorem 1} \n%\\begin{proof}\nOur proof of Theorem 1 is adapted from~\\cite{Duci2019} by making extensions that fit the unique design of the distributionally robust bag likelihood (DRBL). We start by introducing the following lemma, which will later be used in our proof. \n\n\n\\begin{lemma}[Maurer and Pontil Theorem 10]\\label{le:variance}\nLet $Y$ be a random variable taking values in [0, L]. Let $\\sigma^2=\\text{Var}[Y]$ and $\\text{Var}_n[Y]=\\frac{1}{n}\\sum_{i=1}^nY_i^2-(\\frac{1}{n}\\sum_{i=1}^nY_i)^2$ be the population and sample variance of $Y$, respectively. Then for for $n\\geq 2$,\n\\begin{align}\n\\label{eq:lemma}\nP(\\sigma-t\\leq \\sqrt{Var_n[Y]}\\leq\\sigma+t)\\geq 1-\\exp\\left({-\\frac{nt^2}{2L^2}}\\right)    \n\\end{align}\n%$$P(\\sigma-t\\leq \\sqrt{\\text{Var}_n[f(X^+)]}\\leq\\sigma+t)\\geq 1-\\exp\\left({-\\frac{nt^2}{2M^2}}\\right)$$\n\\end{lemma}\nThe distributionally robust bag likelihood (DRBL), \\ie the l.h.s. of \\eqref{eq:dro-variance-eqivalence}, can be formulated as the following constrained optimization problem:\n\\begin{equation}\n\\begin{aligned}\n\\max_{{\\bf p}\\in {\\mathcal{P}_n}} & \\sum_{i=1}^np_if({\\bf x}_i^+) \\\\\n\\text{s.t.~} & \\mathcal{P}_n :=\\left\\{{\\bf p}\\in \\mathbb{R}^n, {\\bf p}^{\\top}\\mathbbm{1}=1, 0\\leq {\\bf p}, D_f\\left({{\\bf p}||\\frac{\\mathbbm{1}}{n}}\\right)\\leq \\frac{\\lambda}{n} \\right\\}\n    \\label{eq:dro_optimization_function}    \n\\end{aligned}\n\\end{equation}\n%\\max_{{\\bf p}}\\sum_{i=1}^n p_if({\\bf x}_i^+) \\quad \\text{s.t.~} \\mathcal{P}_n:=\\{{\\bf p}\\in R^n_+, ||n{\\bf p}-1||_2^2\\leq\\lambda, {\\bf p}^T\\mathbbm{1} = 1\\}\nSince the $D_f ({\\bf p}||{\\bf q})$ is assumed to be the $\\chi^2$-divergence and ${\\bf q}$ follows the uniform distribution, $D_f ({\\bf p}||{\\bf q})$ is reduced to the squared Euclidean distance.\n%\\textbf{Note:} Since the second term in $D_f\\left({{\\bf p}||\\frac{\\mathbbm{1}}{n}}\\right)$ is the uniform distribution and in this case, the $\\chi^2$ divergence becomes proportional to the square Euclidean distance. Therefore, in our proof, we proceed using the squared Euclidean distance metric. \nWe first introduce the mean of $f({\\bf x}_i^+)$'s, which is denoted as $\\bar{f} = \\frac{1}{n}\\sum_{i=1}^nf({\\bf x}_i^+)$. Also, recall we denote the score vector by ${\\bf f}=(f({\\bf x}_1^+),...,f({\\bf x}_n^+))^{\\top}$ in Section~\\ref{sec:drbl}. Thus, the empirical variance of $f(X^+)$ is given by $\\text{Var}_n[f(X^+)] = \\frac{1}{n}||{\\bf f}||_2^2-\\bar{f}^2 = \\frac{1}{n}||{\\bf f}-\\bar{f}\\mathbbm{1}||_2^2$. We further introduce  ${\\bf u} = {\\bf p}-\\frac{\\mathbbm{1}}{n}$, so the objective in \\eqref{eq:dro_optimization_function} can be transformed as \n\\begin{equation}\n{\\bf p}^{\\top}{\\bf f} = ({\\bf u}+\\frac{\\mathbbm{1}}{n})^{\\top}{\\bf f}=\\bar{f}+{\\bf u}^{\\top}{\\bf f} = \\bar{f}+{\\bf u}^{\\top}({\\bf f}-\\bar{f}\\mathbbm{1})   \n\\end{equation}\nwhere the last equality holds because ${\\bf u}^{\\top}\\mathbbm{1} = 0$. Thus, the optimization problem in \\eqref{eq:dro_optimization_function} can be further transformed into\n%indicates the mean. \\qi{Please update the notation in the proof. We introduced $f(X^+)=(f({\\bf x}_1^+),...,f({\\bf x}_n^+))^{\\top}$ to represent a vector of $f({\\bf x}_i^+)$'s in the main paper. Only bold vectors not scalars. Use $^{\\top}$ for transpose not $^T$.} Further to keep notations uncluttered, let $f(X^+)=(f({\\bf x}_1^+),...,f({\\bf x}_n^+))^{\\top}$. Further, consider $\\text{Var}_n[f(X^+)] = \\frac{1}{n}||f(X^+)||_2^2-\\bar{f}^2 = \\frac{1}{n}||f(X^+)-\\bar{f}||_2^2$ denotes the empirical variance of the vector $\\bf f$.\n%Then by introducing the variable ${\\bf u} = {\\bf p}-\\frac{\\mathbbm{1}}{n}$ then the objective in problem \\ref{eq:dro_optimization_function}, satisfies ${\\bf p}^{\\top}f(X^+) = \\bar{f}+{\\bf u}^{\\top}f(X^+) = \\bar{f}+{\\bf u}^{\\top}(f(X^+)-\\bar{f})$ with ${\\bf u}^{\\top}\\mathbbm{1} = 0$. Thus the above problem is equivalent to solving\n\\begin{equation}\n\\max_{{\\bf u}\\in {\\mathbb R}^n}\\bar{f}+{\\bf u}^{\\top}({\\bf f}-\\bar{f}\\mathbbm{1}) \\quad \\text{s.t.} \\quad ||{\\bf u}||_2^2\\leq\\frac{\\lambda}{n^2}, {\\bf u}^{\\top}\\mathbbm{1} = 0, {\\bf u}\\geq -\\frac{1}{n}\n    \\label{eq:dro_optimization_u}\n\\end{equation}\nwhere the first constraint is derived by replacing $D_f$ with the $\\chi^2$-divergence. Now, using the Cauchy-Schwarz inequality, which states that ${\\bf u}^{\\top}{\\bf v}\\leq ||{\\bf u}||_2||{\\bf v}||_2$, gives the following condition\n\\begin{equation}\n    {\\bf u}^{\\top}({\\bf f}-\\bar{f}\\mathbbm{1}) \\leq \\frac{\\sqrt{\\lambda}}{n}||{\\bf f}-\\bar{f}\\mathbbm{1}||_2 =\\sqrt\\frac{{\\lambda \\text{Var}_n[f(X^+)]}}{n}\n    \\label{eq:cauchy_schwarz}\n\\end{equation}\nwhere the equality holds if and only if \n\\begin{equation}\nu_i=\\frac{\\sqrt{\\lambda} (f({\\bf x}_i^+)-\\bar{f})}{n||{\\bf f}-\\bar{f}\\mathbbm{1}||_2} = \\frac{\\sqrt{\\lambda} (f({\\bf x}_i^+)-\\bar{f})}{n\\sqrt{n\\text{Var}_n[f(X^+)]}}\n    \\label{eq:cauchy_schwarz_equality}\n\\end{equation}\nSince we also have a constraint ${\\bf u}\\geq -\\frac{1}{n}$, which satisfies if and only if \n\\begin{equation}\n\\min_{i\\in [n]}\\frac{\\sqrt{\\lambda}(f({\\bf x}_i^+)-\\bar{f})}{\\sqrt{n\\text{Var}_n[f(X^+)]}} \\geq -1\n    \\label{eq:equality_condition}\n\\end{equation}\n\nThus, if inequality \\eqref{eq:equality_condition} holds for vector $\\bf f$, we have\n\\begin{equation}\n\\max_{{\\bf p}\\in \\mathcal{P}_n}{\\bf p}^{\\top}{\\bf f} = \\bar{f}+\\sqrt{\\frac{\\lambda \\text{Var}_n[f(X^+)]}{n}}\n    \\label{eq:dro_variance}\n\\end{equation}\nwhich will prove the Theorem given in \\eqref{eq:dro-variance-eqivalence}. \n\nWhat remains is to prove inequality \\eqref{eq:equality_condition} holds with a high probability. To show this, we leverage the concentration inequality given by Lemma~\\ref{le:variance}. Since $f({\\bf x}_i^+) \\in [0,1]$, we have $|f({\\bf x}_i^+)-\\bar{f}| \\leq 1$. To satisfy inequality \\eqref{eq:equality_condition}, it is sufficient to have\n\\begin{align}\n  \\frac{\\lambda}{n\\text{Var}_n[f(X^+)]}\\leq 1\\quad  \n    &\\text{or} \\quad \\text{Var}_n[f(X^+)]\\geq \\frac{\\lambda}{n} \\label{eq:sufficient}\n\\end{align}\n%Now with the probability $1-\\exp\\left(-{\\frac{77n\\sigma^2}{125}}\\right)$, we show that above inequality holds.\nLet us define the following event \n\\begin{equation}\n\\epsilon_n:=\\left\\{\\text{Var}_n[f(X^+)]\\geq \\frac{1}{43}\\sigma^2\\right\\}\n    \\label{eq:event}\n\\end{equation}\nIn Theorem 1, we suppose $n\\geq\\frac{4\\lambda}{\\sigma^2}\\max\\{2\\sigma, 11\\})$. Then, on event $\\epsilon_n$, we have $n\\geq \\frac{44\\lambda}{\\sigma^2}\\geq \\frac{\\lambda}{\\text{Var}_n[f(X^+)]}$, so that the sufficient condition \\eqref{eq:sufficient} holds and the \\eqref{eq:dro_variance} becomes true. \n\nNow we find the probability of holding the above event in \\eqref{eq:event} using Lemma~\\ref{le:variance}. \n%\\begin{lemma}[Maurer and Pontil Theorem 10]\n%Let $f({\\bf x}_i^+)$ be i.i.d. random variable taking the values in [0, M] and $\\text{Var}_n[f(X^+)] = \\frac{1}{n}||f(X^+)||_2^2-\\bar{f}^2$. Then for for $n\\geq 2$\n%$$P(\\sigma-t\\leq \\sqrt{\\text{Var}_n[f(X^+)]}\\leq\\sigma+t)\\geq 1-\\exp\\left({-\\frac{nt^2}{2M^2}}\\right)$$\n%\\end{lemma}\n%In our case M = 1 and \nFirst, $L=1$ in our case, which gives\n$$P(\\sigma-t\\leq \\sqrt{\\text{Var}_n[f(X^+)]}\\leq\\sigma+t)\\geq 1-\\exp\\left({-\\frac{nt^2}{2}}\\right)$$\nThe following also holds true:\n$$P\\left(\\sigma-t\\leq \\sqrt{\\text{Var}_n[f(X^+)]}\\right)\\geq P(\\sigma-t\\leq \\sqrt{\\text{Var}_n[f(X^+)]}\\leq\\sigma+t)$$\n$$\\geq 1-\\exp\\left({-\\frac{nt^2}{2}}\\right)$$\nLet $t = \\left(1-\\sqrt{\\frac{1}{43}}\\right)\\sigma$, which gives $\\sigma-t = \\sqrt{\\frac{1}{43}}\\sigma$. Substituting this to \\eqref{eq:lemma} leads to\n$$P\\left(\\sqrt{\\frac{1}{43}}\\sigma\\leq \\sqrt{\\text{Var}_n[f(X^+)]}\\right)\\geq 1-\\exp\\left({-\\frac{nt^2}{2}}\\right); P(\\epsilon_n)\\geq 1-\\exp\\left({-\\frac{nt^2}{2}}\\right)$$\nFurther substituting the value of $t = \\left(1-\\sqrt{\\frac{1}{43}}\\right)\\sigma$ gives rise to\n$$P(\\epsilon_n)\\geq 1-\\exp\\left({-0.359n\\sigma^2}\\right) \\geq 1-\\exp\\left({-\\frac{7n\\sigma^2}{20}}\\right)$$\n\nThis completes the proof of Theorem 1.\n%\\end{proof}\n\n%It is worth noting that the equivalence is not limited to the  $\\chi^2$ divergence and we can use other divergence metrics such as KL divergence. As an example, we show the equivalence between DRBL under KL-divergence metric and the variance regularized likelihood. Mathematically, we present the following theorem\n\n%\\begin{theorem}\n%Consider $D_{KL}({{\\bf p}||{\\bf p_0}})$ be the KL divergence between two distributions ${\\bf %p}$ and ${\\bf p}_0$, we have the following\n%\\begin{equation}\n%\\begin{aligned}\n%\\max_{{\\bf p}\\in {\\mathcal{P}_n}} & \\sum_{i=1}^np_if({\\bf x}_i^+) = \\bar{f}+\\sqrt{\\frac{2\\lambda \\text{Var}_n[f(X^+)]}{n}}+\\frac{1}{3n}\\frac{\\mathcal{\\kappa}_3(f(X^+))}{\\text{Var}_n[f(X^+)]}\\lambda+\\mathcal{O}\\left(\\left(\\frac{\\lambda}{n}\\right)^{3/2}\\right)\\\\\n%\\text{s.t.~} & \\mathcal{P}_n :=\\left\\{{\\bf p}\\in \\mathbb{R}^n, {\\bf p}^{\\top}\\mathbbm{1}=1, 0\\leq {\\bf p}, D_{KL}\\left({{\\bf p}||{\\bf p}_0}\\right)\\leq \\frac{\\lambda}{n} \\right\\}\n%    \\label{eq:dro_kl_variance_equivalence}    \n%\\end{aligned}\n%\\end{equation}\n%where ${\\bf p}_0 = \\frac{\\mathbbm{1}}{n}$ be the uniform distribution indicating the center of the ball.\n\n%\\end{theorem}\n\n%In the above theorem, the the higher order terms are functions of $\\frac{\\lambda}{n}$ and the power is increasing. For the lower $\\lambda<1$ value, the ratio  $\\frac{\\lambda}{n}<1$ as we have number of instances in a bag $n>=1$. Therefore, for the higher orders, the term becomes smaller and smaller. In case of $\\lambda<<n$ meaning we have large number of instances, we can consider only first and second term and therefore, the Distributionally robust likelihood term (left side of the Eq \\ref{eq:dro_kl_variance_equivalence}) becomes closely equal to the first two terms (variance regularized) in the right side of the above Equation.\n\\paragraph{Proof of Theorem 2}\n\n%\\begin{proof}\nIn order to prove this theorem, we consider two assumptions, which both hold true for our MIL setting.  \n\n%The first assumption is related to the finiteness which is as follow\n\n\n  \n \n\n{\\bf Assumption 1:} Random variable $f(X^+)$ has a finite exponential moment in a neighborhood of 0 under the distribution ${\\bf p}_0$ \\ie $\\mathbb{E}_0[\\exp(\\tau f(X^+))]<\\infty$ for $\\tau \\in [-\\tau_0, \\tau_0]$ for some $\\tau_0>0$.\n\n%The second assumption is related to the non-degeneracy condition as specified below.\n{\\bf Assumption 2:} Random variable $f(X^+)$ is non-constant under ${\\bf p}_0$. \n\nAssumption 1 is true in our case as $f(X^+)$ is bounded in [0, 1]; Assumption 2 also empirically holds true as there are both positive and negative instances in a positive bag so the output scores are distinct over different instances in a bag. The second assumption ensures that the uniform distribution ${\\bf p}_0$ is not a locally optimum, which means there exists an opportunity to upgrade the value by re-balancing the probability between positive and negative instances in a positive bag. \n\n\nConsider ${\\bf p}$ that is absolutely continuous with respect to ${\\bf p}_0$ and therefore the likelihood ratio $g=\\frac{d{\\bf p}}{d{\\bf p}_0}$ (a.k.a., RadonNikodym derivative) exists. Using a change of measure, the optimization problem in the l.h.s. of \\eqref{eq:dro_kl_variance_equivalence} can be written as\n\n\\begin{equation}\n\\begin{aligned}\n    \\max_{g \\in \\mathcal{L}_1({\\bf p}_0)} \\mathbb{E}_0[g f(X^+)]\n    \\; \\text{s.t.} \\left\\{\\mathbb{E}_0[g\\log g]\\leq \\frac{\\lambda}{n}, \\mathbb{E}_0[g] = 1, {g\\geq 0}\\right\\} \n  \\end{aligned}  \n  \\label{eq: optimization_likelihood_space}\n\\end{equation}\n%where $\\mathcal{L}: = \\left\\{g \\in \\mathcal{L}_1({\\bf p}_0)\\right\\}$ and we denote ${\\mathcal L}_1({\\bf p}_0)$ as $\\mathcal{L}_1$-space with respect to the measure ${\\bf p}_0$. The key in the above optimization is to find the optimal solution $g^*$ first.\nwhere ${\\mathcal L}_1({\\bf p}_0)$ is $\\mathcal{L}_1$-space with respect to the measure ${\\bf p}_0$. To solve the optimization problem above, we formulate its Lagrangian, \n\\begin{equation}\n    \\max_{g \\in \\mathcal{L}_1({\\bf p}_0)} \\mathbb{E}_0[g f(X^+)]-\\alpha\\left(\\mathbb{E}_0[g\\log g]-\\frac{\\lambda}{n}\\right)\n    \\label{eq: lagrangian_kl_dro}\n\\end{equation}\nwhere $\\alpha$ is the Lagrange's multiplier. The solution of the above objective function is given by the following proposition \\cite{Petersen,Lam2016RobustSA}:\n\\begin{proposition}\nUnder Assumption 1, when $\\alpha>0$ is sufficiently large, there exists an unique optimizer of \\eqref{eq: lagrangian_kl_dro} given by\n\\begin{equation}\n    g^*({\\bf x}^+) = \\frac{\\exp(\\frac{f({\\bf x}^+)}{\\alpha})}{\\mathbb{E}_0\\left[\\exp{\\frac{f(X^+)}{{\\alpha}}}\\right]}\n    \\label{eq:optimal_l}\n\\end{equation}\n\\end{proposition}\n%{\\bf Proposition 1} \n%This result is known (e.g., \\citep{Petersen}, \\citep{Lam2016RobustSA}) and for the complete proof please refer to the appendix section Proof of Proposition 3.1 from \\citep{Lam2016RobustSA}.\n\n%By the sufficiency result in Chapter 8, Theorem 1 in \\citep{Luenberger1968OptimizationBV}, suppose that we can find $\\alpha^*\\geq 0$ and $g^*\\in \\mathcal{L}$ such that $g^*$ maximizes \\ref{eq: lagrangian_kl_dro} for $\\alpha = \\alpha^*$ and $\\mathbb{E}_0[g^*\\log g^*] = \\frac{\\lambda}{n}$ then $g^*$ is the optimal solution for  \\ref{eq: optimization_likelihood_space}. \nAssume that such $\\alpha^*$ and $g^*$ exist and that $\\alpha^*$ is sufficiently large then \n$$\\frac{\\lambda}{n} = \\mathbb{E}_0[g^*\\log g^*] = \\frac{\\mathbb{E}_0[{g^*}f(X^+)]}{\\alpha} -\\log\\mathbb{E}_0\\left[\\exp\\left({\\frac{f(X^+)}{\\alpha^*}}\\right)\\right] $$\n$$= \\frac{\\beta^*\\mathbb{E}_0[f(X^+)\\exp(\\beta^*f(X^+))]}{\\mathbb{E}_0[\\exp(\\beta^*f(X^+))]}-\\log \\mathbb{E}_0[\\exp{\\beta^*f(X^+)}]$$\n$$ = \\beta^*\\psi^{'}(\\beta^*)-\\psi(\\beta^*)$$\nwhere we define $\\beta^*=\\frac{1}{\\alpha^*}$ and ${\\psi}(\\beta) = \\log \\mathbb{E}_0[\\exp(\\beta f(X^+))]$ is the logarithmic moment generating function of $f(X^+)$.\n\nWe can write the optimal solution of the objective function \\eqref{eq: optimization_likelihood_space} as follows\n\\begin{equation}\n    \\mathbb{E}_0[f(X^+)g^*] = \\frac{\\mathbb{E}_0[f(X^+)\\exp(\\frac{f(X^+)}{\\alpha^*})]}{\\mathbb{E}_0[\\exp(\\frac{f(X^+)}{\\alpha^*})]} = \\psi^{'}(\\beta^*)\n    \\label{eq: solution1_dro}\n\\end{equation}\nNow let us perform Taylor expansion of the following\n$$\\beta \\psi^{'}(\\beta) - \\psi(\\beta) = \\sum_{m=0}^\\infty \\frac{1}{m!}\\kappa_{m+1}\\beta^{m+1}-\\sum_{m=0}^\\infty\\frac{1}{m!}\\kappa_m\\beta^{m}$$\n$$=\\sum_{m=1}^\\infty \\left[\\frac{1}{(m-1)!}-\\frac{1}{m!}\\right]\\kappa_m\\beta^m $$\n$$= \\sum_{m=2}^\\infty \\frac{1}{m(m-2)!}\\kappa_m\\beta^m = \\frac{1}{2}\\kappa_2\\beta^2+\\frac{1}{3}\\kappa_3\\beta^3+\\frac{1}{8}\\kappa_4\\beta^4+\\mathcal{O}(\\beta^5)$$\nIn the above expression, $\\kappa_m = \\psi^{(m)}(0)$ is the m-th derivative of $\\psi$ with evaluated at $\\beta = 0$ and $\\mathcal{O}(\\beta^5)$ is continuous in $\\beta$. By Assumption 2, we have $\\kappa_2>0$. Therefore, for small enough $\\frac{\\lambda}{n}$, above equation reveals that there is a small $\\beta^{*}>0$ that is root to the equation $\\frac{\\lambda}{n} = \\beta\\psi^{'}(\\beta)-\\psi(\\beta)$ and the root is unique. This is because by Assumption 2, $\\psi(.)$ is strictly convex, and therefore, $\\frac{d (\\beta\\psi^{'}-\\psi(\\beta)}{d\\beta}) = \\beta\\psi^{''}(\\beta)>0$ for $\\beta>0$, so that $\\beta\\psi^{'}(\\beta)-\\psi(\\beta)$ is strictly increasing. \n\nSince $\\alpha^*=\\frac{1}{\\beta^*}$, this shows that for any sufficiently small $\\frac{\\lambda}{n}$, we can find a large $\\alpha^*>0$ such that the corresponding $g^*$ in \\ref{eq:optimal_l} satisfies $\\frac{\\lambda}{n} = \\mathbb{E}_0[g^*\\log g^*]$. This means we can write the following\n\\begin{equation}\n    \\frac{\\lambda}{n} = \\frac{1}{2}\\kappa_2\\beta^{*^{2}}+\\frac{1}{3}\\kappa_3\\beta^{*^{3}}+\\frac{1}{8}\\kappa_4\\beta^{*^{4}}+\\mathcal{O}(\\beta^{*^{5}})\n\\end{equation}\n\nWe can obtain $\\beta^*$ as follow\n\n\n$$    \\beta^* = \\sqrt{\\frac{2\\lambda}{n\\kappa_2}}\\left(1+\\frac{2}{3}\\frac{\\kappa_3}{\\kappa_2}\\beta^*+\\frac{1}{4}\\frac{\\kappa_4}{\\kappa_2}\\beta^{*^{2}}+\\mathcal{O}(\\beta^{*^{3}})\\right)^{-\\frac{1}{2}}$$\n$$= \\sqrt{\\frac{2\\lambda}{n\\kappa_2}}\\left(1-\\frac{1}{3}\\frac{\\kappa_3}{\\kappa_2}\\beta^*+\\mathcal{O}(\\beta^{*^{2}})\\right) \n= \\sqrt{\\frac{2}{\\kappa_2}}\\left(\\frac{\\lambda}{n}\\right)^{1/2}-\\frac{2}{3}\\frac{\\kappa_3}{\\kappa_2^2}\\frac{\\lambda}{n}+\\mathcal{O}\\left(\\left(\\frac{\\lambda}{n}\\right)^{\\frac{3}{2}}\\right)$$\nIn the above expression, first we use the binomial expansion $(1+x)^{\\frac{-1}{2}} = 1-\\frac{1}{2}x+\\frac{3}{8}x^2.... $ followed by substitution of $\\beta^*$ in the second term.\nNow, the corresponding optimal solution becomes following\n\n$$\\mathbb{E}_0[f(X^+)g^*] = \\psi^{'}(\\beta^*) = \\kappa_1+\\kappa_2\\beta^*+\\kappa_3\\frac{\\beta^{*^2}}{2}+\\mathcal{O}(\\beta^{*^{3}})$$\n$$=\\kappa_1+\\sqrt{2\\kappa_2}\\left(\\frac{\\lambda}{n}\\right)^{\\frac{1}{2}}+\\frac{1}{3}\\frac{\\kappa_3}{\\kappa_2}\\frac{\\lambda}{n}+\\mathcal{O}\\left(\\left(\\frac{\\lambda}{n}\\right)^{\\frac{3}{2}}\\right)$$\nIn the above equation $\\kappa_1 = \\bar{f}, \\kappa_2 = \\text{Var}_n[f(X^+)], \\kappa_3 = \\mathbb{E}_0[(f(X^+)-\\mathbb{E}_0[f(X^+)])^3]$. This completes the proof of Theorem 2.\n%\\end{proof}\n\n\n\n\n"
            },
            "section 8": {
                "name": "More Examples of Challenging Bags",
                "content": "\\label{app:examplebags}\\label{app:example_of_20news}\n Figure~\\ref{fig:morebagexamples} shows the $p$-$f$ plots for three example challenging bags from three different topics in the 20NewsGroup dataset. As shown, the highest $f$-score from those bags is very low. This implies that the passive learning model predicts all the instances as negative with a high confidence. Using F-Entropy, we may not be able to query any instance from those bags because of low uncertainty. In contrast, by leveraging the standard MIL assumption, the proposed P-F sampling will effectively explore those bags. Once the positive instances from these bags are queried, they  help to accurately identify similar positive instances in the same and different bags to boost the instance prediction performance, as evidenced by our experimental results.\n \n\n \n \n"
            },
            "section 9": {
                "name": "Link to Source Code",
                "content": "\\label{app:sourcecode}\nFor the source code of our experiments, please \\href{https://github.com/ritmininglab/ADMIL-P-F}{click here}.\n\n"
            }
        },
        "figures": {
            "fig: illustrative_examples_max_vs_proposed": "\\begin{figure*}[t!]\n\\centering\n\\begin{subfigure}{0.19\\textwidth}\n  \\centering\n  \\vspace{0mm}\n  \\includegraphics[width=0.96\\linewidth]{Figs/unexplored_bag_bird.pdf}\n\\vspace{4mm}\n  \\caption{{\\sc Sample bag B$_1$}}\n\\end{subfigure}%\n\\begin{subfigure}{0.19\\textwidth}\n  \\centering\n  \\includegraphics[width=\\linewidth]{Figs/al_curve_unexplored_bags.png}\n  \\vspace{-4.5mm}\n  \\caption{MAP Score}\n\\end{subfigure}%\n\\begin{subfigure}{0.19\\textwidth}\n  \\centering\n  \\includegraphics[width=\\linewidth]{Figs/0.pdf}\n  \\vspace{-5mm}\n  \\caption{Step 0}\n\\end{subfigure}%\n\\begin{subfigure}{0.19\\textwidth}\n  \\centering\n  \\includegraphics[width=\\linewidth]{Figs/240.pdf}\n  \\vspace{-5mm}\n  \\caption{Step 8}\n\\end{subfigure}%\n\\begin{subfigure}{0.19\\textwidth}\n  \\centering\n  \\includegraphics[width=\\linewidth]{Figs/300.pdf}\n  \\vspace{-5mm}\n  \\caption{Step 10}\n\\end{subfigure}%\n\\vspace{-2mm}\n\\caption{(a) Example of a challenging bag; (b) MI-AL performance on instance-level predictions; (c)-(e) Prediction scores of instances in the bag in different MI-AL steps}\n\\label{fig: illustrative_examples_max_vs_proposed}\n\\vspace{-4mm}\n\\end{figure*}",
            "fig: al_curve_comparison_mean_sd": "\\begin{figure*}[t!]\n\\centering\n\\begin{subfigure}{0.24\\textwidth}\n  \\centering\n  \\includegraphics[width=1.0\\linewidth]{Figs/al_curve_20newsgroup_mean_sd.pdf}\n  \\vspace{-18mm}\n  \\caption{20NewsGroup}\n  \n\\end{subfigure}\n\\begin{subfigure}{0.24\\textwidth}\n  \\centering\n  \\includegraphics[width=1.0\\linewidth]{Figs/al_curve_cifar10_mean_sd.pdf}\n  \\vspace{-18mm}\n  \\caption{Cifar10}\n\\end{subfigure}\n\\begin{subfigure}{0.24\\textwidth}\n  \\centering\n  \\includegraphics[width=1.0\\linewidth]{Figs/al_curve_cifar100_mean_sd.pdf}\n  \\vspace{-18mm}\n  \\caption{Cifar100}\n\\end{subfigure}%\n\\begin{subfigure}{0.24\\textwidth}\n  \\centering\n  \\includegraphics[width=1.0\\linewidth]{Figs/al_curve_pascal_voc_mean_sd.pdf}\n  \\vspace{-18mm}\n  \\caption{Pascal VOC}\n\\end{subfigure}\n\\vspace{-3mm}\n\\caption{MI-AL performance}\n\\label{fig: al_curve_comparison_mean_sd}\n\\vspace{-14mm}\n\\end{figure*}",
            "fig: al_curve_ablation": "\\begin{figure*}[t!]\n\\centering\n\\begin{subfigure}{0.24\\textwidth}\n  \\centering\n  \\includegraphics[width=1.0\\linewidth]{Figs/al_curve_20newsgroup_ablation.pdf}\n  \\vspace{-18mm}\n  \\caption{20NewsGroup}\n  \n\\end{subfigure}\n\\begin{subfigure}{0.24\\textwidth}\n  \\centering\n  \\includegraphics[width=1.0\\linewidth]{Figs/al_curve_cifar10_ablation.pdf}\n  \\vspace{-18mm}\n  \\caption{Cifar10}\n\\end{subfigure}\n\\begin{subfigure}{0.24\\textwidth}\n  \\centering\n  \\includegraphics[width=1.0\\linewidth]{Figs/al_curve_cifar100_ablation.pdf}\n  \\vspace{-18mm}\n  \\caption{Cifar100}\n\\end{subfigure}%\n\\begin{subfigure}{0.24\\textwidth}\n  \\centering\n  \\includegraphics[width=1.0\\linewidth]{Figs/al_curve_pascal_voc_ablation.pdf}\n  \\vspace{-18mm}\n  \\caption{Pascal VOC}\n\\end{subfigure}\n\\vspace{-3mm}\n\\caption{Effectiveness of P-F active sampling}\n\\label{fig: al_curve_ablation}\n\\vspace{-4mm}\n\\end{figure*}",
            "fig: ablation_lambda": "\\begin{figure*}[t!]\n\\vspace{-5mm}\n\\centering\n\\begin{subfigure}{0.24\\textwidth}\n  \\centering\n  \\includegraphics[width=1.0\\linewidth]{Figs/al_curve_lambda_20newsgroup_ablation.pdf}\n  \\vspace{-18mm}\n  \\caption{20NewsGroup}\n\\end{subfigure}%\n\\begin{subfigure}{0.24\\textwidth}\n  \\centering\n  \\includegraphics[width=1.0\\linewidth]{Figs/al_curve_lambda_cifar10_ablation.pdf}\n\\vspace{-18mm}\n  \\caption{Cifar10}\n\\end{subfigure}%\n\\begin{subfigure}{0.24\\textwidth}\n  \\centering\n  \\includegraphics[width=1.0\\linewidth]{Figs/al_curve_lambda_cifar100_ablation.pdf}\n  \\vspace{-18mm}\n  \\caption{Cifar100}\n\\end{subfigure}%\n\\begin{subfigure}{0.24\\textwidth}\n  \\centering\n  \\includegraphics[width=1.0\\linewidth]{Figs/al_curve_lambda_pascal_voc_ablation.pdf}\n\\vspace{-18mm}\n  \\caption{Pascal VOC}\n\\end{subfigure}%\n\\vspace{-4mm}\n\\caption{Impact of model parameter $\\lambda$}\n\\label{fig: ablation_lambda}\n\\vspace{-14mm}\n\\end{figure*}",
            "fig: ablation_beta": "\\begin{figure*}[t!]\n\\centering\n\\begin{subfigure}{0.24\\textwidth}\n  \\centering\n  \\includegraphics[width=1.0\\linewidth]{Figs/al_curve_beta_20newsgroup_ablation.pdf}\n   \\vspace{-18mm}\n  \\caption{20NewsGroup }\n\\end{subfigure}%\n\\begin{subfigure}{0.24\\textwidth}\n  \\centering\n  \\includegraphics[width=1.0\\linewidth]{Figs/al_curve_beta_cifar10_ablation.pdf}\n  \\vspace{-18mm}\n  \\caption{Cifar10}\n\\end{subfigure}%\n\\begin{subfigure}{0.24\\textwidth}\n  \\centering\n  \\includegraphics[width=1.0\\linewidth]{Figs/al_curve_beta_cifar100_ablation.pdf}\n   \\vspace{-18mm}\n  \\caption{Cifar100}\n\\end{subfigure}%\n\\begin{subfigure}{0.24\\textwidth}\n  \\centering\n  \\includegraphics[width=1.0\\linewidth]{Figs/al_curve_beta_pascal_voc_ablation.pdf}\n  \\vspace{-18mm}\n  \\caption{Pascal VOC}\n\\end{subfigure}%\n\\vspace{-4mm}\n\\caption{Impact of model parameter $\\beta$}\n\\label{fig: ablation_beta}\n\\vspace{-14mm}\n\\end{figure*}",
            "fig: al_curve_ablation_k": "\\begin{figure*}[t!]\n\\centering\n\\begin{subfigure}{0.24\\textwidth}\n  \\centering\n  \\includegraphics[width=1.0\\linewidth]{Figs/al_curve_ablation_k20NewsGroup.pdf}\n  \\vspace{-18mm}\n  \\caption{20NewsGroup}\n  \n\\end{subfigure}\n\\begin{subfigure}{0.24\\textwidth}\n  \\centering\n  \\includegraphics[width=1.0\\linewidth]{Figs/al_curve_ablation_kCifar10.pdf}\n  \\vspace{-18mm}\n  \\caption{Cifar10}\n\\end{subfigure}\n\\begin{subfigure}{0.24\\textwidth}\n  \\centering\n  \\includegraphics[width=1.0\\linewidth]{Figs/al_curve_ablation_kCifar100.pdf}\n  \\vspace{-18mm}\n  \\caption{Cifar100}\n\\end{subfigure}%\n\\begin{subfigure}{0.24\\textwidth}\n  \\centering\n  \\includegraphics[width=1.0\\linewidth]{Figs/al_curve_ablation_kPascal_VOC.pdf}\n  \\vspace{-18mm}\n  \\caption{Pascal VOC}\n\\end{subfigure}\n\\vspace{-4mm}\n\\caption{Impact of hyperparameter $k$}\n\\label{fig: al_curve_ablation_k}\n\\vspace{-5mm}\n\\end{figure*}",
            "fig: poorly_explored_bags": "\\begin{figure*}[t!]\n\\vspace{2mm}\n\\centering\n\\begin{subfigure}{0.24\\textwidth}\n  \\centering\n    \\vspace{-3mm}\n  \\includegraphics[width=1\\linewidth]{Figs/2008_006481.jpg}\n  \\vspace{-1mm}\n  \\caption{{\\sc Sample bag B$_2$}}\n  \n\\end{subfigure}%\n~\n\\begin{subfigure}{0.24\\textwidth}\n  \\centering\n    \\vspace{-2mm}\n  \\includegraphics[width=\\linewidth, height = 2.5cm]{Figs/2010_003820.jpg}\n  \\vspace{-1mm}\n  \\caption{{\\sc Sample bag B$_3$}}\n\\end{subfigure}%\n\\begin{subfigure}{0.24\\textwidth}\n  \\centering  \n  \\vspace{-2mm}\n  %\\includegraphics[width=1.1\\linewidth]{Figs/2010_004348.jpg}\n\\scalebox{.9}{\n\\begin{tabular}{|c|c|c|}\n\\hline\n\\textbf{Bag} & \\textbf{P-F} & \\textbf{F-Entropy} \\\\\n\\hline\n{\\sc B$_1$} & $1.00$  & $0.04$  \\\\\n\\hline\n{\\sc B$_2$} & $0.53$ &  $0.07$  \\\\\n\\hline\n{\\sc B$_3$}  & $0.64$  & $0.55$  \\\\\n\\hline\n{\\sc B$_1$} &\\multicolumn{2}{| l |}{Shadow of a bird} \\\\ \\hline\n{\\sc B$_2$} &\\multicolumn{2}{| l |}{Side view of a bird} \\\\ \\hline\n{\\sc B$_3$} &\\multicolumn{2}{| l |}{Part of a bird} \\\\ \\hline\n\\end{tabular}}\n  \\vspace{3mm}\n  \\caption{{\\sc mAP scores}}\n\\end{subfigure}%\n~\n\\begin{subfigure}{0.24\\textwidth}\n\\centering\n\\vspace{-15mm}\n    \\includegraphics[width = 1.\\textwidth]{Figs/percent_tp_bags.pdf}\n    \\vspace{-18mm}\n    \\caption{Percentage of TP bags}\n \\label{fig: tp_bags}\n\\end{subfigure}\n\\vspace{-2mm}\n\\caption{(a-b) Poorly explored bags in Pascal VOC;  (c) Description of these bags and their mAP scores; (d) Additional true positive bags successfully explored by P-F sampling}\n\\label{fig: poorly_explored_bags}\n\\vspace{-3mm}\n\\end{figure*}"
        },
        "equations": {
            "eq:1": "\\begin{align}\n     \\mathcal{L}^\\text{MS}=\\left\\{1-\\max_{i\\in \\mathcal{B}_{pos}}[f({\\bf x}_i^+;{\\bf w})]+\\max_{j\\in \\mathcal{B}_{neg}}[f({\\bf x}_j^-;{\\bf w})]\\right\\}_+\\label{eq:max_mil}\n\\end{align}",
            "eq:2": "\\begin{align}\n \\mathcal{L}^\\text{VAR} = \\left\\{1-\\left[\\frac{1}{n}\\sum_{i=1}^nf({\\bf x}_i^+)+C\\sqrt{\\frac{\\text{Var}_n[f(X^+)]}{n}}\\right]+\\max_{j\\in \\mathcal{B}_{neg}}\\left[f({\\bf x}_j^-)\\right]\\right\\}_+\\label{eq:variance_regularized}\n\\end{align}",
            "eq:3": "\\begin{equation}\n\\mathcal{P}_n :=\\left\\{{\\bf p}\\in \\mathbb{R}^n, {\\bf p}^{\\top}\\mathbbm{1}=1, 0\\leq {\\bf p}, D_f\\left({{\\bf p}||\\frac{\\mathbbm{1}}{n}}\\right)\\leq \\frac{\\lambda}{n}  \\right\\}\\label{eq:uncertainty_dro}\n\\end{equation}",
            "eq:4": "\\begin{equation}\n\\begin{aligned}\n\\max_{{\\bf p}\\in {\\mathcal{P}_n}} \\sum_{i=1}^np_if({\\bf x}_i^+) \\approx \\frac{1}{n}\\sum_{i=1}^nf({\\bf x}_i^+)+\\sqrt{\\frac{2\\lambda \\text{Var}_n[f(X^+)]}{n}}\n\\end{aligned}\n\\end{equation}",
            "eq:5": "\\begin{equation}\n    \\mathcal{L}^\\text{DRBL} = \\left\\{1-\\max_{{\\bf p}\\in \\mathcal{P}_{n}}\\left[\\sum_{i=1}^np_if({\\bf x}_i^+)\\right]+\\max_{j\\in \\mathcal{B}_{neg}}\\left[f({\\bf x}_j^-)\\right]\\right\\}_+\\label{eq:dro_loss_single_bag}\n\\end{equation}",
            "eq:6": "\\begin{align}\n    {\\bf x}_*&= \\arg \\max_{i \\in \\mathcal{B}_{pos}} H[f({\\bf x}_i^+)],  %\\quad \\text{where}\\\\\n    \\label{eq:f-entropy}\n\\end{align}",
            "eq:7": "\\begin{equation}\n    {\\bf x}^{PF}_*=\\arg \\min_{b\\in \\{1,...,B\\}} f({\\bf x}^+_{b_*}), \\quad \\text{and } b_*=\\arg \\max {\\bf p}_b\n    \\label{eq:pfsampling}\n\\end{equation}",
            "eq:8": "\\begin{equation}\n    L^\\text{BCE} = -\\frac{1}{m}\\sum_{i=1}^m\\left[t_i^l\\log(f({\\bf x}_i^l))+(1-t_i^l)\\log(1-f({\\bf x}_i^l))\\right] \\label{eq:bce_loss}\n\\end{equation}",
            "eq:9": "\\begin{equation}\n\\mathcal{L}^\\text{Hybrid}= \\mathcal{L}^{DRBL}(\\mathcal{B}_{pos}, \\mathcal{B}_{neg})+\\beta \\mathcal{L}^{BCE}({\\bf X}^l, {\\bf t}^l)\n    \\label{eq:total_loss}\n    %\\vspace{-2mm}\n\\end{equation}",
            "eq:10": "\\begin{equation}\n\\begin{aligned}\n\\max_{{\\bf p}\\in {\\mathcal{P}_n}} & \\sum_{i=1}^np_if({\\bf x}_i^+) \\\\\n\\text{s.t.~} & \\mathcal{P}_n :=\\left\\{{\\bf p}\\in \\mathbb{R}^n, {\\bf p}^{\\top}\\mathbbm{1}=1, 0\\leq {\\bf p}, D_f\\left({{\\bf p}||\\frac{\\mathbbm{1}}{n}}\\right)\\leq \\frac{\\lambda}{n} \\right\\}\n    \\label{eq:dro_optimization_function}    \n\\end{aligned}\n\\end{equation}",
            "eq:11": "\\begin{equation}\n{\\bf p}^{\\top}{\\bf f} = ({\\bf u}+\\frac{\\mathbbm{1}}{n})^{\\top}{\\bf f}=\\bar{f}+{\\bf u}^{\\top}{\\bf f} = \\bar{f}+{\\bf u}^{\\top}({\\bf f}-\\bar{f}\\mathbbm{1})   \n\\end{equation}",
            "eq:12": "\\begin{equation}\n\\max_{{\\bf u}\\in {\\mathbb R}^n}\\bar{f}+{\\bf u}^{\\top}({\\bf f}-\\bar{f}\\mathbbm{1}) \\quad \\text{s.t.} \\quad ||{\\bf u}||_2^2\\leq\\frac{\\lambda}{n^2}, {\\bf u}^{\\top}\\mathbbm{1} = 0, {\\bf u}\\geq -\\frac{1}{n}\n    \\label{eq:dro_optimization_u}\n\\end{equation}",
            "eq:13": "\\begin{equation}\n    {\\bf u}^{\\top}({\\bf f}-\\bar{f}\\mathbbm{1}) \\leq \\frac{\\sqrt{\\lambda}}{n}||{\\bf f}-\\bar{f}\\mathbbm{1}||_2 =\\sqrt\\frac{{\\lambda \\text{Var}_n[f(X^+)]}}{n}\n    \\label{eq:cauchy_schwarz}\n\\end{equation}",
            "eq:14": "\\begin{equation}\nu_i=\\frac{\\sqrt{\\lambda} (f({\\bf x}_i^+)-\\bar{f})}{n||{\\bf f}-\\bar{f}\\mathbbm{1}||_2} = \\frac{\\sqrt{\\lambda} (f({\\bf x}_i^+)-\\bar{f})}{n\\sqrt{n\\text{Var}_n[f(X^+)]}}\n    \\label{eq:cauchy_schwarz_equality}\n\\end{equation}",
            "eq:15": "\\begin{equation}\n\\min_{i\\in [n]}\\frac{\\sqrt{\\lambda}(f({\\bf x}_i^+)-\\bar{f})}{\\sqrt{n\\text{Var}_n[f(X^+)]}} \\geq -1\n    \\label{eq:equality_condition}\n\\end{equation}",
            "eq:16": "\\begin{equation}\n\\max_{{\\bf p}\\in \\mathcal{P}_n}{\\bf p}^{\\top}{\\bf f} = \\bar{f}+\\sqrt{\\frac{\\lambda \\text{Var}_n[f(X^+)]}{n}}\n    \\label{eq:dro_variance}\n\\end{equation}",
            "eq:17": "\\begin{align}\n  \\frac{\\lambda}{n\\text{Var}_n[f(X^+)]}\\leq 1\\quad  \n    &\\text{or} \\quad \\text{Var}_n[f(X^+)]\\geq \\frac{\\lambda}{n} \\label{eq:sufficient}\n\\end{align}",
            "eq:18": "\\begin{equation}\n\\epsilon_n:=\\left\\{\\text{Var}_n[f(X^+)]\\geq \\frac{1}{43}\\sigma^2\\right\\}\n    \\label{eq:event}\n\\end{equation}",
            "eq:19": "\\begin{equation}\n\\begin{aligned}\n    \\max_{g \\in \\mathcal{L}_1({\\bf p}_0)} \\mathbb{E}_0[g f(X^+)]\n    \\; \\text{s.t.} \\left\\{\\mathbb{E}_0[g\\log g]\\leq \\frac{\\lambda}{n}, \\mathbb{E}_0[g] = 1, {g\\geq 0}\\right\\} \n  \\end{aligned}  \n  \\label{eq: optimization_likelihood_space}\n\\end{equation}",
            "eq:20": "\\begin{equation}\n    \\max_{g \\in \\mathcal{L}_1({\\bf p}_0)} \\mathbb{E}_0[g f(X^+)]-\\alpha\\left(\\mathbb{E}_0[g\\log g]-\\frac{\\lambda}{n}\\right)\n    \\label{eq: lagrangian_kl_dro}\n\\end{equation}",
            "eq:21": "\\begin{equation}\n    \\mathbb{E}_0[f(X^+)g^*] = \\frac{\\mathbb{E}_0[f(X^+)\\exp(\\frac{f(X^+)}{\\alpha^*})]}{\\mathbb{E}_0[\\exp(\\frac{f(X^+)}{\\alpha^*})]} = \\psi^{'}(\\beta^*)\n    \\label{eq: solution1_dro}\n\\end{equation}",
            "eq:22": "\\begin{equation}\n    \\frac{\\lambda}{n} = \\frac{1}{2}\\kappa_2\\beta^{*^{2}}+\\frac{1}{3}\\kappa_3\\beta^{*^{3}}+\\frac{1}{8}\\kappa_4\\beta^{*^{4}}+\\mathcal{O}(\\beta^{*^{5}})\n\\end{equation}"
        },
        "git_link": "https://github.com/ritmininglab/ADMIL-P-F"
    }
}