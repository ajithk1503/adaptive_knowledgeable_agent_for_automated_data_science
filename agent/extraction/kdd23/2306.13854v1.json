{
    "meta_info": {
        "title": "Similarity Preserving Adversarial Graph Contrastive Learning",
        "abstract": "Recent works demonstrate that GNN models are vulnerable to adversarial\nattacks, which refer to imperceptible perturbation on the graph structure and\nnode features. Among various GNN models, graph contrastive learning (GCL) based\nmethods specifically suffer from adversarial attacks due to their inherent\ndesign that highly depends on the self-supervision signals derived from the\noriginal graph, which however already contains noise when the graph is\nattacked. To achieve adversarial robustness against such attacks, existing\nmethods adopt adversarial training (AT) to the GCL framework, which considers\nthe attacked graph as an augmentation under the GCL framework. However, we find\nthat existing adversarially trained GCL methods achieve robustness at the\nexpense of not being able to preserve the node feature similarity. In this\npaper, we propose a similarity-preserving adversarial graph contrastive\nlearning (SP-AGCL) framework that contrasts the clean graph with two auxiliary\nviews of different properties (i.e., the node similarity-preserving view and\nthe adversarial view). Extensive experiments demonstrate that SP-AGCL achieves\na competitive performance on several downstream tasks, and shows its\neffectiveness in various scenarios, e.g., a network with adversarial attacks,\nnoisy labels, and heterophilous neighbors. Our code is available at\nhttps://github.com/yeonjun-in/torch-SP-AGCL.",
        "author": "Yeonjun In, Kanghoon Yoon, Chanyoung Park",
        "link": "http://arxiv.org/abs/2306.13854v1",
        "category": [
            "cs.LG",
            "cs.AI",
            "cs.CR"
        ],
        "additionl_info": "9 pages; KDD'23"
    },
    "latex_extraction": {
        "content": {
            "section 1": {
                "name": "Introduction",
                "content": "\n\n\n%% The Importance of Graph and GCL.\n\\looseness=-1\nA graph is a ubiquitous data structure that appears in diverse domains such as chemistry, biology, and social networks. Thanks to their usefulness, a plethora of studies on graph neural networks (GNNs) have been conducted in order to effectively exploit the node and structural information inherent in a graph. However, real-world graphs are usually large-scale, and it is difficult to collect labels due to the expensive cost. Hence, unsupervised graph representation learning methods such as  \\cite{deepwalk, node2vec, sage, line} have received steady attention. \n% The purpose of these methods is to capture the patterns in a graph without any label information by mapping a graph itself or each node in a graph into a low-dimensional vector. \nMost recently, the graph contrastive learning (GCL) framework has taken over the mainstream of unsupervised graph representation learning \\cite{dgi, mvgrl, grace, gca, lee2022augmentation, lee2022relational}. GCL aims to learn node representations by pulling together semantically similar instances (i.e., positive samples) and pushing apart different instances (i.e., negative samples) in the representation space. In particular, instance discrimination-based approaches \\cite{grace, gca}, which treat nodes in differently augmented graphs as self-supervision signals, are dominant among the recent GCL methods. \n\n\n%The obtained representations have shown their usefulness to solve various downstream tasks such as node classification and graph classification, link prediction problems, or to pre-train a model before performing specific tasks. \n\n\n%% Adversarial Vulnerability of Graph\nAlthough deep learning-based models on graphs have achieved promising results, recent studies have revealed that GNNs are vulnerable to adversarial attacks \\cite{pmlr-dai18b-advattack-on-graph, ijacai-19-pgd-topology-attack-defense}. \\textit{Adversarial attack on a graph} refers to imperceptible perturbations on the graph structure and node features that rapidly degrade the performance of GNN models. In other words, even with a slight change in the graph structure (e.g., adding/removing a few edges) and node features, GNN models lose their predictive power\\footnote{Following recent studies \\cite{kdd20-prognn, rsgnn, pagnn}, we mainly focus on the graph structural attack in this work as it is known to be more effective than the node feature attack.}. Existing studies mainly focus on enhancing the robustness of the GNN models, aiming at facilitating robust predictions given an attacked graph. To this end, they introduce novel GNN architectures \\cite{NEURIPS2020_GRAND,NEURIPS2020_ReliableAGG, simpgcn, pagnn} or propose to learn a graph structure by purifying the attacked structure \\cite{kdd20-prognn, chen2020iterative, rsgnn}. Although the aforementioned approaches have shown effectiveness in training robust GNN models, most of them rely on the label information of nodes and graphs (i.e., supervised setting), and thus they are not applicable when the label information is absent (i.e., unsupervised setting). However, as most real-world graphs are without any label information and the labeling process is costly, developing unsupervised GNN models that are robust to adversarial attacks is important.\n% \\cite{kdd-19-rgcn, kdd19-certifiable-robustgnn,NEURIPS2020_GRAND,NEURIPS2020_gnnguard,NEURIPS2020_ReliableAGG, simpgcn}\n% \\cite{zheng2020robust, kdd20-prognn, chen2020iterative, rsgnn, ijcai2019-advexamples-for-graph}\n%% Adversarial Vulnerability of Unsupervised Graph Representation Learning\nRecently, it has been highlighted that unsupervised methods for graphs are also vulnerable to adversarial attacks \\cite{pmlr-19a-advattack-on-nodeembedding,clga}, and some approaches have addressed the robustness of unsupervised GNNs by adopting adversarial training (AT) to the GCL framework \\cite{grv,ariel}. \nTheir main idea is to find the worst-case perturbations on the graph structure and the node features, and use the attacked graph as an adversarial view to train GNN models such that the learned node representations do not vary much despite the adversarial messages propagated from the perturbed edges. In other words, by considering the adversarial view as an augmentation under the GCL framework, they achieve adversarial robustness against adversarial attacks.\n% In other words, by considering the attacked graph as an augmentation under the GCL framework, they achieve adversarial robustness against adversarial attacks.\n\n{\nHowever, we find out that an adversarially trained GCL model achieves robustness \\emph{at the expense of not being able to preserve the similarity among nodes in terms of the node features}, which is an unexpected consequence of applying AT to GCL models~\\cite{grv,ariel}. In other words, nodes with similar features do not have similar representations when AT is applied to GCL models. This is mainly due to the fact that applying AT on GCL models force the representations of nodes in the (original) clean graph to be close to those of the attacked graphs in which nodes with dissimilar features are deliberately forced to be connected via adversarial attacks \\cite{pmlr-dai18b-advattack-on-graph,kdd20-prognn}. For this reason, the node representations obtained from adversarially trained GCL models fall short of preserving the \nnode feature similarity\\footnote{\\label{note1}This will be empirically shown in Fig. \\ref{fig:observation}(b).} despite being robust to graph structural attacks. \n% That is, AT encourages the learned node representations to contain less feature information. \nHowever, as demonstrated by previous studies \\cite{kdd20-prognn, simpgcn, rsgnn}, the node feature information is crucial for defending against graph structure attacks. Moreover, preserving the node feature similarity becomes especially useful for most real-world graphs that are incomplete in nature, where a graph network contains noisy node labels and heterophilous neighbors \\cite{dai2021nrgnn, simpgcn}.}\n\n% since the graph structure is associated with the node feature information in general.\n% Moreover, the node feature similarity becomes especially useful for most real-world graphs that are incomplete in nature, where graphs are heterophilous, and contains the structural information that is not helpful for training GNN models (i.e., contain missing links and nodes are mostly of low-degree) \\cite{simpgcn, geomgcn}.}\n\n% However, we argue that preserving the node feature similarity is crucial considering that most real-world graphs are incomplete in nature (i.e., contain missing links and nodes are mostly of low-degree). Besides, the node feature similarity becomes especially useful when graphs are poisoned (e.g., adversarially attacked graph) or heterophilous in nature, in which case the given structural information is not particularly helpful for training GNN models.\n \n%Despite the effectiveness of existing robust unsupervised GNNs with adversarial training[cite], we argue that these methods fail to address the adversarial attack in a holistic manner. That is, some works focus on generating adversarial graphs with feature perturbation only, and other works perform the topological attack \\textcolor{red}{cite}. Besides, existing feature attack methods perturb the node feature matrix using FGSM \\cite{fgsm}, which is a widely used attack method on images whose features are continuous values. However, as the node features in grzaphs are usually discrete (i.e., binary), the small perturbation attack is not suitable for the graph data due to the nature of the graph data containing a lot of binary features \\textcolor{red}{why problematic is binary feature}. Based on the facts, there is room to increase the performance and robustness of the model by generating an adversarial graph that comprehensively considers the feature and the topology attack. Further, the previous graph poisoning attack methods require a high computational cost. Gradient-based attacks are targeted at the entire graph and it is not scalable as the number of nodes in the graph quadratically increases the cost. For PGD attack \\cite{ijacai-19-pgd-topology-attack-defense}, it requires the additional calculation caused by inherent iterations of PGD Attack.\n\n\\looseness=-1\nIn this paper, we propose a similarity-preserving adversarial graph contrastive learning (\\proposed) framework that preserves the feature similarity information and achieves adversarial robustness. More precisely,~\\proposed~contrasts the (original) clean graph with two auxiliary views of different properties (i.e., node similarity-preserving view and adversarial view). The node similarity-preserving view helps preserve the node feature similarity by providing self-supervision signals generated from the raw features of nodes. It is important to note that as the node similarity-preserving view is constructed solely based on the raw features of nodes regardless of the graph structure (i.e., structure-free), the model is particularly robust against graph structural attacks. \n% Existing AT methods achieve robustness by simply training models with adversarial examples (view) made by graph adversarial attack methods \\cite{pgd, ijcai2019-advexamples-for-graph, ariel, grv}. However, most of the adversarial attack methods only perform the structural perturbations, though some works apply a feature flipping based on gradients together, the flipping severely changes the co-occurrence/correlation statistics of node features. More precisely, two features that have never occurred together in a graph can happen to co-occur if we perturbs the node feature by flipping. Such a change may have a negative effect on the AT by making the clean view and the adversarial view too differently. To this end, we generate an adversarial view that not only contains structural and feature perturbation, but also maintains the inherent statistics of features. Specifically, we measure the important features for each node based on their gradients, and thus mask them to retain their statistics. By that, the node representations of \\proposed~can exploit more feature information and become more robust against a variety of structural attacks. Furthermore, it allows \\proposed~ to simplify the AT procedure compared to the existing works \\cite{ariel} utilizing PGD \\cite{ijacai-19-pgd-topology-attack-defense}, which needs several iterations to solve the complex optimization.  \n\\looseness=-1\n% Professor Edit\n% Besides the node similarity-preserving view, we generate the adversarial view, which enhances the robustness of node representations against both structural and feature perturbations. Most existing adversarial training methods for GNNs only consider structural perturbations without considering feature perturbations \\cite{dai2018adversarial, wang2019graphdefense, ijacai-19-pgd-topology-attack-defense, adgcl}.\n% Although recent studies apply both types of perturbations~\\cite{ariel, grv}, they rely on the feature flipping approach (i.e., change from 0 to 1 and from 1 to 0), which may significantly alter the co-occurrence/correlation statistics of node features.\n% For example, two features that have never co-occurred in a clean graph may co-occur if some of the node features are changed from 0 to 1, and such a behavior may have an adverse effect on the AT by making the clean view and the adversarial view too distant from each other. To this end, we present an adversarial view generation method that considers both the structural and feature perturbations, while retaining the co-occurrence/correlation statistics of node features. The main idea is to mask (i.e., only change from 1 to 0) important features, and combine the masked feature matrix with the perturbed structure to generate the adversarial view. We expect the generated adversarial view to not only exploit the feature information by focusing on insensitive features that do not affect the loss greatly, but also obtain robustness against structure perturbations. A further benefit of adopting the feature masking instead of flipping is increased scalability as masking requires less computations for the gradient computations.\n% In summary, the main contributions of this paper is three-fold.\n% Remaining sentences\n% , which turns out to only focus on low-degree nodes as will be later shown in our theoretical analysis and empirical study in Sec.~\\ref{subsec:4.2}.\n% ~\\textsuperscript{\\ref{note1}}.\n% is problematic as structural perturbations mainly focus on low-degree nodes\\textsuperscript{\\ref{note1}}. \n% generate the adversarial view that only contains the structural perturbations without considering the feature perturbation \\cite{ijacai-19-pgd-topology-attack-defense}. \n% Though some works apply a feature flipping based on gradients with structural perturbations together, flipping the features still changes the co-occurrence/correlation statistics of node features severely \\cite{ijcai2019-advexamples-for-graph, ariel, grv}. \n% Additionally, generating the adversarial view is scalable since it does not require any iterations to generate.\n\nBesides, to further exploit the node feature information, we additionally generate an adversarial view by introducing an adversarial feature mask. Specifically, we mask the node features that greatly change the original contrastive loss to generate the adversarial view, which is then used as another view in the GCL framework. The main idea is to learn node representations that are invariant to masked features, which encourages the GCL model to fully exploit the node feature information.\n% contributes to another contrastive loss measured with an augmented view.\n\n% which encourages the model to focus on the remaining features\n\n% \\textcolor{blue}{Besides, we enhance the adversarial robustness by presenting the adversarial feature masking to the adversarial view, which exploits more node feature information. Specifically, we mask the node features that change loss greatly for the adversarial view, and the generated adversarial view focuses on the other features that remain after masking. This facilitates more feature information to be exploited by learning node representations that are invariant to feature masking.}\n\n% Specifically, we find the feature mask based on the contrastive objective, and generate the adversarial view by combining the feature mask with graph structure attacks. By masking node features that change loss greatly, the generated adversarial view focuses on the other features that remain after masking, and this facilitates more feature information to be exploited by learning node representations that are invariant to feature masking.\n\n% To exploit more node feature information, we present the adversarial feature masking for generating the adversarial view. Specifically, we find the feature mask based on the contrastive objective, and generate the adversarial view with the feature mask and strutural attacks. By masking node features that change loss greatly, the generated adversarial view focuses on the other features that remain after masking, and this facilitates more feature information to be exploited by learning node representations that are invariant to feature masking.\n\n% \\textcolor{blue}{To exploit more node feature information, we present the adversarial feature masking for generating the adversarial view. Specifically, we find the feature mask based on the contrastive objective, and generate the adversarial view with the feature mask and strutural attacks. By masking sensitive node features that change loss greatly, the generated adversarial view focuses on insensitive features that remain after masking, and this facilitates more feature information to be exploited by learning node representations that are invariant to feature masking.}\n\n\n% Besides the node similarity-preserving view, we present the adversarial feature masking for generating an informative adversarial view. Existing AT methods \\cite{grv, ariel} for GCL models consider graphs with perturbed edges and flipped node features as augmentations to obtain adversarial robustness. However, they fall short of exploiting the feature information from the adversarial view, since flipping the features is not helpful to AT as it greatly changes important data characteristics (e.g., co-occurrence/correlation of node features). \n% Even with structural perturbations, it can change the overall graph statistics. We simply avoid this problem by masking sensitive node features that change loss greatly instead of flipping the node features. Thereby, the generated adversarial view focuses on insensitive features that remain after masking, and this facilitates more feature information to be exploited by learning node representations that are invariant to feature masking.\n% the sensitive features. \nIn summary, the main contributions of this paper are three-fold.\n\n% Besides the node similarity-preserving view, we generate an adversarial view, which enhances the robustness of node representations against the graph attack. Most existing AT approaches generate the adversarial view that only contains the structural perturbations without considering the feature perturbation \\cite{ijacai-19-pgd-topology-attack-defense}. Though some works apply a feature flipping based on gradients with structural perturbations together, flipping the features still changes the co-occurrence/correlation statistics of node features severely \\cite{ijcai2019-advexamples-for-graph, ariel, grv}. For example, two features that have never occurred together in a graph is happen to co-occur if we perturb the node feature by flipping. Thereby, the adversarial view with the feature flips may have an adverse effect on the AT by making the clean view and the adversarial view too differently. Thus, we present an adversarial view generation method that perturbs both structure and feature together, while retaining the co-occurrence/correlation statistics of node features. The main idea is to mask a sensitive feature among feature matrix, and then apply it with structural perturbations. This adversarial view exploits the feature information by focusing insensitive feature, and obtains robustness to structure perturbations. Additionally, generating the adversarial view is scalable since it does not require any iterations to generate.\n\n% Besides the node similarity-preserving view, we generate an informative adversarial view, which incorporates both the graph structural and node feature information. Distinguished from existing adversarial view generation methods that alternatively generate the structural and feature perturbations, we propose an adversarial feature masking technique that facilitates a \\textit{collaborative generation of structural and feature perturbations}. We argue that the existing strategy of alternating between the structural and feature perturbations overlooks the dependency between the structure and features. For example, structural perturbations, which generally connect nodes with dissimilar features as will be shown in Fig. \\ref{fig:observation}(a), may need to change the target nodes to be connected, if the node features are perturbed at the same time. Moreover, the alternating strategy requires expensive computations, which is neither scalable nor practical in reality.\n% we construct the adversarial view by adopting an adversarial feature masking technique, which helps exploit the node feature information by masking sensitive features and focusing more on other features in the adversarial view. Based on our observation that existing feature perturbation \n%%%%%%%%%%\n% Besides the node similarity-preserving view, we construct the adversarial view by adopting a novel adversarial feature masking technique, which helps exploit the node feature information by masking sensitive features and focusing more on other features in the adversarial view.\n% we propose a novel adversarial feature masking technique for generating the adversarial view. The adversarial mask helps to exploit the node feature by masking sensitive features and focusing more on other features in the adversarial view. \n% By combining the adversarial feature masking technique with structural attack methods, the generated adversarial view enhances the robustness of node representations. Note that the adversarial feature masking technique differs from existing graph attack methods that flip the binary node feature (i.e., 0 to 1, or 1 to 0) in that we only mask the node features (i.e., 1 to 0). We argue that flipping the node features rather disturbs the AT because it changes the correlation/co-occurrence statistics of node features. More precisely, if two features that have never occurred together in a graph happened to co-occur due to the flipping of node features from 0 to 1, such a change may have an adverse effect on the AT.\n%%%%%%%%%%\n% the perturbation is a significant change for model, which is not helpful for AT.\n% To illustrate such behaviors, consider an example on citation network, where nodes are papers and its feature represents the occurrence of words in the paper, i.e. bag-of-words. If a paper published in Computer Science is to contain the word \"Mitochondrion\", it does not make sense in a context of the paper and thus is a noticeable attack. \n% We verify that the adversarial masking is more effective in achieving robustness, even when it is applied with the structural perturbation. \n\n\n\n\n% 강훈이형이 쓴거\n% More precisely, the node similarity-preserving view gives self-supervision signals generated from the node features, which not only prevents the node feature similarity from decreasing but also makes the model robust against the structural attack as the view is constructed solely based on the raw features  of nodes (i.e., structure-free). Moreover, to enhance the effectiveness of AT procedure, we develop an adversarial feature masking technique for adversarial view generations. Different from the adversarial view generated by existing graph attacking methods, which alternatively perturb the graph structure or the node features, our proposed adversarial feature masking can be simultaneously applied with the structure perturbations so that the generated adversarial view contains both the structure-level and feature-level information, and the procedure of generating the adversairal view becomes scalable. We verify that~\\proposed~is more effective in achieving robustness, when the adversarial view considers the collaborative effect of the perturbation of the structure and features. In summary, the main contributions of this paper is three-fold.\n\n\\begin{itemize}[leftmargin=0.5cm]\n    \\item We conduct both theoretical and empirical studies to show that adversarially trained GCL models indeed fail to preserve the node feature similarity. \n    % We first present a study for an adversarially trained GCL models that suffer from preserving the node feature similarity information. \n    \\item We present a novel GCL framework, called \\proposed, that achieves adversarial robustness, while preserving the node feature similarity by introducing a similarity-preserving view, and an adversarial view generated from an adversarial feature mask.\n    % through a similarity-preserving view, and enhances adversarial robustness through an adversarial view.\n    % \\item We introduce a novel GCL framework, called \\proposed, that preserves the node similarity information through a similarity-preserving view, and enhances adversarial robustness through an adversarial view.\n    % \\textcolor{blue}{with the adversarial feature masking.}\n    % collaboratively captures the graph structural and node feature information.\n    % incorproates both the graph structural and node feature information with the similarity-preserving view and the adversarial feature masking technique.\n    \\item\\proposed~achieves a competitive performance compared with state-of-the-art baselines on several downstream tasks, and we show its effectiveness in various scenarios, e.g., adversarial attacks, noisy node labels, and heterophilous neighbors.\n    % , and fraudsters.\n\\end{itemize}\n\n\n\n%Improving the predictive performance by preserving the feature similarity on the representation space, the view generated view does not change\n% More concretely, the generated adversarial view has adversarial mask for features and perturbed graph structure. By comprehensively considering the feature-level and topological attack,~\\proposed~learns the robust representation by performing the adversarial training with the adversarial view. Moreover, we design a feature similarity view that preserves the robustness and feature similarity of the representation. From the above observation, in order to reduce the viciousness of an adversarial attack connecting nodes with different features, the representation should maintain the local similarity of features (i.e., the representation of two connected nodes has smoothness). The feature similarity view ensures that the smoothness of the representations are preserved as that of the features by receiving information from nodes in a similar feature space, regardless of the topology. Also, since the similarity view is generated based on features only, the model is robust to the topological attack.\n\n\n\\vspace{-1ex}\n"
            },
            "section 2": {
                "name": "Related Works",
                "content": "\n\n",
                "subsection 2.1": {
                    "name": "Graph Contrastive Learning",
                    "content": "\nGraph Contrastive Learning (GCL) is a well-known representation learning framework that pulls semantically similar instances and pushes semantically different instances. Inspired by Deep InfoMax \\cite{dim}, DGI \\cite{dgi} presents a contrastive learning method that learns node representations by maximizing the mutual information between the local patch and the global summary of a graph. \n% MVGRL leverages the diffusion of nodes, and then contrasts node representations with an augmented global graph representation \\cite{mvgrl}. \nRecently, GRACE \\cite{grace} and GCA \\cite{gca}, motivated by SimCLR \\cite{simclr}, present methods that contrast two differently augmented views with each other, where the different views are generated by various augmentations to edges and node features. GRACE obtains the representations by maximizing the agreements between the representations of the same nodes in the two augmented views, and minimizing the agreements between all other nodes. In this paper, we develop a method that makes GCL models robust against adversarial attacks.\n\n\n% Despite the success\n% of contrastive methods on graphs, they are criticized for the\n% problem raised by the “sampling bias” (Bielak, Kajdanowicz, and Chawla 2021). Moreover, these methods require a\n% large amount of negative samples for the model training,\n% which incurs high computational and memory costs (Grill\n% et al. 2020)\n\n\n\\vspace{-1ex}\n"
                },
                "subsection 2.2": {
                    "name": "Adversarial Attacks on Graph",
                    "content": "\n\\looseness=-1\nDeep learning models on graphs have been shown to be vulnerable to adversarial attacks. \\emph{Nettack} \\cite{nettack} is a targeted attack that aims to fool the predictions for specific target nodes. \n% where important data characteristics (e.g., node degree distribution and co-occurrence of node features) are preserved to make the attack imperceptible. \n\\emph{Metattack} \\cite{metattack} presents a non-targeted attack method based on meta-learning that deteriorates the overall performance of GNNs. PGD and min-max methods \\cite{ijacai-19-pgd-topology-attack-defense} employ loss functions such as negative cross-entropy and CW-type loss to perturb the graph structure using projected gradient descent. However, these attack methods are designed for supervised learning, and thus not applicable under unsupervised settings. \nMost recently, CLGA \\cite{clga} introduces an unsupervised graph structural attack method that flips the edges based on the largest gradient of the GCL objectives. In this paper, we focus on developing a GCL framework based on AT, where such adversarially attacked graphs are used as an augmentation to obtain adversarial robustness.\n\n\n\n\\vspace{-1ex}\n"
                },
                "subsection 2.3": {
                    "name": "Adversarial Defense on Graph",
                    "content": " \nAlong with the growing interest in adversarial attacks on a graph, research on defense methods have also received attention. A strategy for defending the adversarial attack can be categorized into two types. The first line of research focuses on designing novel GNN architectures. Specifically, they achieve robustness by adjusting messages from other nodes based on uncertainty~\\cite{kdd-19-rgcn} or node feature similarity information~\\cite{simpgcn}.\n% Specifically, RGCN \\cite{kdd-19-rgcn} adopts a probabilistic approach that assumes the node representations follow the Gaussian distribution, and achieves robustness by receiving fewer messages from uncertain nodes captured by the variance of node representations. SimP-GCN \\cite{simpgcn} exploits the feature similarity information by introducing similarity-preserving aggregation, and shows that the robustness can be achieved by preserving the feature similarity. \nAnother line of research on the adversarial defense focuses on purifying the graph structure by removing noisy edges. They denoise the graph structure with the feature smoothness~\\cite{kdd20-prognn} or limited label information~\\cite{rsgnn}.\n% ProGNN \\cite{kdd20-prognn} learns the graph structure by using graph properties such as the feature smoothness and a low-rank constraint of the adjacency matrix. RSGNN \\cite{rsgnn} presents a link prediction model that effectively denoises the graph with limited label information. \nHowever, the aforementioned approaches are heavily dependent on the supervision signals (i.e., node labels), and thus their performance easily deteriorates with noisy labels. Most importantly, they are not applicable when the label information is absent. \n\nTraining robust GNN models in an unsupervised manner is even more challenging because these models receive (self-) supervision signals from the augmented views of the original graph that may have been already attacked before being augmented, which would not provide helpful supervisory signals. \n%Hence, a robust training technique should be developed to suit the unsupervised models. Most recently, a few attempts have been made towards robust graph representation learning that can be trained without supervision signals. Thanks to the success of the GCL framework, the adversarial GCL models, which adopt AT to the GCL framework, are dominant among unsupervised robust GNN models. \nMost recently, adversarial GCL models, which apply AT to the GCL framework, have been adopted to unsupervised adversarial defense models. DGI-ADV \\cite{grv} \n% measures graph representation vulnerability based on information theory to assess the robustness of representation for unsupervised models. It \nadopts a training strategy that alternately performs DGI and AT according to the vulnerability of graph representations. ARIEL \\cite{ariel} incorporates AT into GRACE, where adversarial augmentation views are generated by adversarial attacks on graph. \n% Although these works show promising results, they sacrifice the node feature similarity to obtain robustness against the attack. \nHowever, these works sacrifice the node feature similarity to obtain robustness against the attack. \n% In Section \\ref{sec:4}, we investigate a major drawback of existing adversarial GCL models in that they fail to preserve the node feature similarity, which plays an important role in the robustness of GNN models under adversarial attacks. \nTo this end, we propose an adversarial GCL scheme that preserves the node feature similarity.\n\n\n% The Adversarial contrastive learning is first introduced in computer vision domain \\cite{adv_vision1_jiang2020robust, adv_vision2_fan2021does, adv_vision3_minseonkim, adv_vision4_ho2020contrastive}. They achieve adversarial robustness by adversarial training where adversarial example is generated as the another view, i.e. data augmentation, using contrastive loss. In graph domain, some methods firstly have been proposed which are designed for graph level tasks.  ADGCL\\cite{adgcl} and GASSL\\cite{gassl} adopt adversarial training to graph domain. However, ADGCL considers only edge perturbation, in specific edge dropping, and GASSL does only feature perturbation. Furthermore, their aims is at generating an augmented view to improve contrastive learning instead of adversarial robustenss. More recently, DGI-ADV \\cite{grv} and ARIEL\\cite{ariel}\n% - DGI-ADV: \n% Even, the latest graph contrastive learning methods receive supervision signals from augmented views, i.e., unlike the label supervision which is always clean given adversarial attacks, the augmentation-based supervision contains the corrupted signal of the poisoned graph. Hence, a robust training technique should be developed to suit the GCL framework. \n\n\n\n\\vspace{-1ex}\n"
                }
            },
            "section 3": {
                "name": "Preliminary",
                "content": "\n\\textbf{Notations.} \\@  Let us denote $\\mathcal{G}= \\langle \\mathcal{V},\\mathcal{E}, \\mathbf{X} \\rangle$ as a graph, where $\\mathcal{V}=\\{v_1,...,v_N\\}$ is the set of nodes, $\\mathcal{E}\\in \\mathcal{V}\\times \\mathcal{V}$ is the set of edges, and $N$ is the number of nodes. We denote $\\mathbf{A}\\in\\mathbb{R}^{N\\times N}$ as the adjacency matrix with $\\mathbf{A}_{ij}=1$ if $v_i$, $v_j$ are connected, otherwise $\\mathbf{A}_{ij}=0$. $\\mathbf{X}\\in\\mathbb{R}^{N\\times F}$ and $\\mathbf{Z}\\in\\mathbb{R}^{N\\times d}$ are the feature and the representation matrix of nodes, respectively, where $F$ and $d$ are the dimensions of the feature and representation, respectively, and $\\mathbf{x}_i$ and $\\mathbf{z}_{i}$ denote $i$-th row of $\\mathbf{X}$ and $\\mathbf{Z}$, respectively. \n%We also denote $\\bar{\\mathbf{A}}$, $\\bar{\\mathbf{X}}$, $\\bar{\\mathbf{Z}}$ as the submatrice of $\\mathbf{A}$, $\\mathbf{X}$ and $\\mathbf{Z}$ to represent the subgraph $\\bar{\\mathcal{G}}$.\n\n\n\n\n\\smallskip\n\\looseness=-1\n\\noindent \\textbf{Graph Contrastive Learning.} \\@ \nSince ~\\proposed~follows a procedure similar to recent GCL models, we begin by explaining the GCL framework. Particularly, we focus on the instance discrimination models that try to maximize the agreement of representations between different views \\cite{grace,gca}. To be specific, given the input $(\\mathbf{A},\\mathbf{X})$, \nGCL models first generate two different views $(\\mathbf{A}^1, \\mathbf{X}^1)$ and $(\\mathbf{A}^2, \\mathbf{X}^2)$ by randomly dropping edges and node features. Then, a GCN \\cite{Kipf:2016-gcn} layer $f: (\\mathbf{A},\\mathbf{X})\\rightarrow \\mathbf{Z}$ encodes these views into the representations $\\mathbf{Z}^1=f(\\mathbf{A}^1, \\mathbf{X}^1)$ and $\\mathbf{Z}^2=f(\\mathbf{A}^2, \\mathbf{X}^2)$. Finally, the contrastive loss is optimized to enforce the representations of the same nodes in different views to be close, and the representations of different nodes to be distant. Following the common multi-view graph contrastive learning, the pairwise contrastive loss~\\cite{grace, gca} is given by: \n\n\\vspace{-3ex}\n\\begin{equation}\n\\small\n    \\mathcal{L}(\\mathbf{Z}^1, \\mathbf{Z}^2) = \\frac{1}{2N}\\sum_{i=1}^{N} l(\\mathbf{z}_i^1, \\mathbf{z}_i^2) + l(\\mathbf{z}_i^2, \\mathbf{z}_i^1)\n    \\label{eq:cl_loss}\n    \\vspace{-3ex}\n\\end{equation}\n% \\begin{equation}\n% \\small\n%     l(\\mathbf{z}_{i}^{1}, \\mathbf{z}_{i}^{2}) = \\log \\frac{e^{\\theta(\\mathbf{z}_{i}^{1}, \\mathbf{z}_{i}^{2})/\\tau}}{e^{\\theta(\\mathbf{z}_{i}^{1}, \\mathbf{z}_{i}^{2})/\\tau} + \\sum_{k\\neq i} e^{\\theta(\\mathbf{z}_{i}^{1}, \\mathbf{z}_{k}^{2})/\\tau} + \\sum_{k\\neq i}e^{\\theta(\\mathbf{z}_{i}^{1}, \\mathbf{z}_{k}^{1})/\\tau}}\n%     \\label{eq:info_nce}\n% \\end{equation}\n% \\vspace{-1ex}\n% \\begin{equation}\n% \\small\n%     \\mathcal{L}(\\mathbf{Z}^1, \\mathbf{Z}^2) = \\frac{1}{2N}\\sum_{i=1}^{N} l(\\mathbf{z}_i^1, \\mathbf{z}_i^2) + l(\\mathbf{z}_i^2, \\mathbf{z}_i^1)\n%     \\label{eq:cl_loss}\n% \\end{equation}\n\\noindent where $l(\\mathbf{z}_{i}^{1}, \\mathbf{z}_{i}^{2}) = \\log \\frac{e^{\\theta(\\mathbf{z}_{i}^{1}, \\mathbf{z}_{i}^{2})/\\tau}}{e^{\\theta(\\mathbf{z}_{i}^{1}, \\mathbf{z}_{i}^{2})/\\tau} + \\sum_{k\\neq i} e^{\\theta(\\mathbf{z}_{i}^{1}, \\mathbf{z}_{k}^{2})/\\tau} + \\sum_{k\\neq i}e^{\\theta(\\mathbf{z}_{i}^{1}, \\mathbf{z}_{k}^{1})/\\tau}}$, and $\\theta(z_i^1,  z_i^2)= \\frac{g(z_i^1) \\cdot g(z_i^2)}{\\norm{g(z_i^1)} \\norm{g(z_i^2)}}$ is the cosine similarity function with a 2-layer MLP $g$, and $\\tau$ is the temperature parameter that scales the distribution. Optimizing the above loss encourages semantically similar nodes to be pulled together and different nodes to be apart in the representation space. \n\n\n\n\n\n\n"
            },
            "section 4": {
                "name": "Analysis on Adversarial GCL",
                "content": "\n\\label{sec:4}\n\nIn this section, we perform a theoretical analysis and an empirical study to show that adversarial GCL models indeed fail to preserve the node feature similarity. First, we define adversarial attacks on GCL models and describe how AT is applied to train robust GNN models given an attacked graph (\\textbf{Section \\ref{subsec:4.1}}). Then, we theoretically analyze how a graph can be effectively attacked, followed by an empirical study to show the characteristics of adversarial attacks on graphs (\\textbf{Section \\ref{subsec:4.2}}). Lastly, based on the characteristics of adversarial attacks and the AT procedure on GCL, we describe a limitation of existing adversarial GCL models (\\textbf{Section \\ref{subsec:4.3}}).\n\n% , and empirically show that the perturbations for graph contain a specific tendency to change the graph property. After that, we connect the tendency of the graph perturbations with the adversarial training, and examine how the adversarial robustness of learned representations are achieved on adversarially trained GCL models. In this process, we argue that the adversarial trained GCL models have a potential risk to lose the node feature similarity information in the original feature space. Finally, we verify this claim through empirical studies with the state-of-art adversarially trained GCL models.\n\n",
                "subsection 4.1": {
                    "name": "Applying AT on GCL models",
                    "content": "\n\\label{subsec:4.1}\n\n\\noindent \\textbf{Adversarial Attack on GCL.} \\@ We start with the formulation of the adversarial attack in GCL models. Note that we only consider unsupervised adversarial attacks, where a contrastive loss is employed instead of a supervised loss. Adversarial attacks based on the contrastive loss are conducted as follows:\n\\begin{equation}\n\\small\n    \\delta_{\\mathbf{A}}^{*}, \\delta_{\\mathbf{X}}^{*} = \\arg\\max_{\\delta_{\\mathbf{A}}, \\delta_{\\mathbf{X}}\\in \\Delta} \\mathbb{E}  \\left[{ \\mathcal{L}( f(\\mathbf{A}^1 +\n    \\delta_{\\mathbf{A}}, \\mathbf{X}^1 + \\delta_{\\mathbf{X}}), f(\\mathbf{A}^2, \\mathbf{X}^2))} \\right]\n    \\label{eq:attack_gcl}\n\\end{equation}\n\\noindent where $\\Delta=\\{(\\delta_{\\mathbf{A}}, \\delta_{\\mathbf{X}})| \\norm{\\delta_{\\mathbf{A}}}_{0}\\leq \\Delta_{\\mathbf{A}}, \\norm{\\delta_{\\mathbf{X}}}_{0} \\leq \\Delta_{\\mathbf{X}} \\}$ is the possible set of the perturbations, and $\\Delta_{\\mathbf{A}}$, $\\Delta_{\\mathbf{X}}$ are perturbation budgets for the edge perturbations $\\delta_{\\mathbf{A}}$ and the feature perturbations $\\delta_{\\mathbf{X}}$, respectively. When $\\mathbf{A}$ is a discrete matrix and $\\mathbf{X}$ consists of binary variables, we use the $l_0$-norm (i.e., count the number of nonzero elements of a vector) for the distance of $\\delta_{\\mathbf{A}}$ and $\\delta_{\\mathbf{X}}$. When $\\mathbf{X}$ is continuous variables, we use $l_{\\infty}$-norm. Hence, the above formulation aims to find the optimal edges and node features to flip (i.e., $\\delta_{\\mathbf{A}}^*$ and $\\delta_{\\mathbf{X}}^*$) for the first view that maximally increase the contrastive loss, which in turn makes the representation of the attacked view $f(\\mathbf{A}^1+\\delta^*_{\\mathbf{A}}, \\mathbf{X}^1 + \\delta^*_{\\mathbf{X}})$ to be dissimilar from the representation of the clean view $f(\\mathbf{A}^2, \\mathbf{X}^2)$. This formulation can be applied to the second view, but here we use the above equation for simplicity.\n\n\\smallskip\n\n\\noindent \\textbf{Training Adversarially Robust GCL.} \\@ We explain the adversarial GCL procedure whose goal is to learn robust GCL models based on AT. The main idea of the adversarial GCL is to force the representations of nodes in the clean graph to be close to those of the attacked graphs. Using the attacked graph as an additional augmentation, the adversarial GCL minimizes the training objective \n% $ \\mathcal{L}(\\mathbf{Z}^1,\\mathbf{Z}^2) + \\lambda_1 \\mathcal{L}(\\mathbf{Z}^1, \\mathbf{Z}^{\\text{adv}})$\n\\begin{equation}\n\\small\n    \\min_{\\Theta}  { \\mathcal{L}(\\mathbf{Z}^1,\\mathbf{Z}^2) + \\lambda_1 \\mathcal{L}(\\mathbf{Z}^1, \\mathbf{Z}^{\\text{adv}})}\n    \\label{eq:at}\n\\end{equation}\n where $\\mathbf{Z}^{\\text{adv}} = f(\\mathbf{A}^1 + \\delta_{\\mathbf{A}}^*, \\mathbf{X}^1 + \\delta_{\\mathbf{X}}^*)$ is the representation of the attacked graph with optimal perturbations, $\\Theta$ is the set of model parameters, and $\\lambda_1$ is a hyperparameter. We hereafter denote the optimally attacked graph $(\\mathbf{A}^1 + \\delta^*_{\\mathbf{A}}, \\mathbf{X}^1 + \\delta^*_{\\mathbf{X}})$ by the \\emph{adversarial view}. The first term in the Eqn. (\\ref{eq:at}) is the contrastive loss for the two stochastically augmented views, and the second term is the AT loss for learning robust node representations. This adversarial GCL framework regularizes the representation of the original view to be consistent with the representation of the adversarial view.\n\\looseness=-1\n"
                },
                "subsection 4.2": {
                    "name": "Characteristic of Adversarial Attacks on GCL",
                    "content": "\n\\label{subsec:4.2}\n\nBased on the above formulation, we theoretically analyze how a graph can be effectively attacked, which results in degrading the performance of GCL models. Note that adversarial attacks on GNNs under the supervised setting tend to connect nodes with dissimilar features, and it has been shown to greatly change the model prediction results \\cite{kdd20-prognn}. Here, we show that similar attack strategies are still effective in degrading the performance of GCL models, which are trained in an unsupervised manner.\n\n\n\n\\smallskip\n",
                    "subsubsection 4.2.1": {
                        "name": "Analyses on effective graph attacks",
                        "content": "~\\\\\n\\noindent \\textbf{1) Theoretical Analysis.} \\@\n% \\noindent \\textbf{Analysis on effective graph attacks.} \\@ \\textbf{1) Theoretical analysis:}\n\\looseness=-1\nConsider a GCL model with a 1-layer GCN encoder without nonlinearity, and assume that there is an arbitrary edge perturbation connecting $v_i$ and $v_k$ where $k \\notin \\mathcal{N}_{\\mathbf{A}}^i$, which is the neighbor set of $v_i$ given the adjacency matrix $\\mathbf{A}$. Our goal is to find a single perturbation that greatly increases the contrastive loss \n\\footnote{In this analysis, we only consider the structural attack (i.e., $\\delta_A$) for simplicity.}. Following Eqn. (\\ref{eq:attack_gcl}), this goal can be cast as a problem of finding the optimal perturbation $\\delta_{\\mathbf{A}}^*$ that makes the representation of the attacked view $\\mathbf{Z}^{atk}=f(\\mathbf{A}^1 + \\delta_{\\mathbf{A}}, \\mathbf{X})$ dissimilar from those of the second clean view $\\mathbf{Z}^2$. Then, the difference in the representations between the clean and the attacked views for node $v_i$ is computed as follows:\n% \\begin{align*}\n%     &\\mathbf{z}_i^2 - \\mathbf{z}_i^{\\text{adv}} \\\\\n%     &= \\mathbf{e}_i +  \\sum_{j\\in\\mathcal{N}(i)\\cup \\{i\\}} \\frac{{\\mathbf{W}\\mathbf{x}_j}}{\\sqrt{|\\mathcal{N}(i)|}\\sqrt{|\\mathcal{N}(j)|}} - \\sum_{j\\in\\mathcal{N}(i)\\cup \\{i,k\\}} \\frac{{\\mathbf{W}\\mathbf{x}_j}}{\\sqrt{|\\mathcal{N}(i)|+1}\\sqrt{|\\mathcal{N}(j)|}} \\\\\n%     \\begin{split}\n%     &= \\mathbf{e}_i +  \\frac{1}{\\sqrt{|\\mathcal{N}(i)|+1}} \\left(\\sum_{j\\in\\mathcal{N}(i)\\cup \\{i\\}} \\frac{\\alpha{\\mathbf{W}\\mathbf{x}_j}}{\\sqrt{|\\mathcal{N}(i)|}\\sqrt{|\\mathcal{N}(j)|}} - \\frac{\\mathbf{W}{\\mathbf{x}_k}}{\\sqrt{|\\mathcal{N}(k)|+1}}\\right)\n%     \\end{split}\n%     \\label{eq:diff}\n% \\end{align*}\n\\vspace{-2ex}\n\\begin{align}\n\\small\n& \\mathbf{z}_i^2 - {\\mathbf{z}_i^{\\text{atk}}} = (\\mathbf{z}_i^2 - \\mathbf{z}_i^1) + (\\mathbf{z}_i^1 - {\\mathbf{z}_i^{\\text{atk}}}) \\nonumber \\\\ \n&= \\mathbf{e}_i \\!+ \\!\\!\\!\\!\\!\\sum_{j\\in\\mathcal{N}_{\\mathbf{A}^1}^i\\cup \\{i\\}} \\frac{{\\mathbf{W}\\mathbf{x}_j}}{\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1}^i|}\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1}^j|}} - \\!\\!\\!\\!\\!\\sum_{j\\in  \\mathcal{N}_{\\mathbf{A}^1+\\delta_{\\mathbf{A}}}^i \\!\\!\\!\\cup \\{i\\}} \\frac{{\\mathbf{W}\\mathbf{x}_j}}{\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1+\\delta_{\\mathbf{A}}}^i|}\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1+\\delta_{A}}^j|}} \\nonumber \\\\\n&= \\mathbf{e}_i + \\frac{1}{\\underbrace{\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1}^i|+1}}_{\\text{Degree term}}} \\underbrace{\\left(\\sum_{j\\in\\mathcal{N}_{\\mathbf{A}^1}^i\\cup \\{i\\}} \\frac{\\alpha{\\mathbf{W}\\mathbf{x}_j}}{\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1}^i|}\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1}^j|}} - \\frac{\\mathbf{W}{\\mathbf{x}_k}}{\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1}^k|+1}}\\right)}_{\\text{Feature difference term}}\n\\label{eq:diff}\n\\raisetag{20pt}\n\\end{align}\n\n\n% \\begin{align}\n% &\\mathbf{z}_i^2 - \\mathbf{z}_i^{\\text{adv}} \\nonumber \\\\ \n% &= \\mathbf{e}_i +  \\sum_{j\\in\\mathcal{N}(i)\\cup \\{i\\}} \\frac{{\\mathbf{W}\\mathbf{x}_j}}{\\sqrt{|\\mathcal{N}(i)|}\\sqrt{|\\mathcal{N}(j)|}} - \\sum_{j\\in\\mathcal{N}(i)\\cup \\{i,k\\}} \\frac{{\\mathbf{W}\\mathbf{x}_j}}{\\sqrt{|\\mathcal{N}(i)|+1}\\sqrt{|\\mathcal{N}(j)|}} \\nonumber \\\\\n% &= \\mathbf{e}_i +  \\frac{1}{\\sqrt{|\\mathcal{N}(i)|+1}} \\left(\\sum_{j\\in\\mathcal{N}(i)\\cup \\{i\\}} \\frac{\\alpha{\\mathbf{W}\\mathbf{x}_j}}{\\sqrt{|\\mathcal{N}(i)|}\\sqrt{|\\mathcal{N}(j)|}} - \\frac{\\mathbf{W}{\\mathbf{x}_k}}{\\sqrt{|\\mathcal{N}(k)|+1}}\\right)\n% \\label{diff}\n% \\end{align}\n\n\n\\noindent where $\\mathbf{e}_i=\\mathbf{z}_i^2-\\mathbf{z}_i^1$ is the difference between the two clean views, $\\alpha$ is a small constant less than $1$, and $\\mathbf{W}\\in\\mathbb{R}^{d\\times F}$ is the feature transformation matrix in the GCN encoder. Note that the trained GCL model discriminates two different instances, and $\\mathbf{e}_i$ is close to a zero vector as the difference between the two clean views is negligible (i.e., $\\mathbf{e}_i\\approx \\mathbf{0}$). From Eqn. (\\ref{eq:diff}), we observe that the distance between the node representations $\\mathbf{z_i^{\\text{atk}}}$ and $\\mathbf{z_i^2}$ is large 1) when the degree of an attacked node $i$ (i.e., $|\\mathcal{N}_{\\mathbf{A}^1}^i|$) is small, and/or 2) when the feature of the added node through perturbation (i.e., $\\mathbf{W}\\mathbf{x}_k$) is very different from the aggregation of the neighbor features of $v_i$ (i.e., 1 layer diffusion for $v_i$). This implies that GCL models are vulnerable to adversarial attacks that connect two nodes that are of \\emph{low-degree} and exhibit \\emph{low feature similarity} with each other. \n\n\\smallskip\n\\noindent \\textbf{2) Empirical Study.} \\@\nWe further conduct an empirical study to verify whether such perturbations are indeed effective in attacking GCL models. We first train a simple GCL model (i.e., GRACE) on Citeseer and Co.CS datasets. Then, since edges (i.e., elements of $\\mathbf{A}$) with high gradients greatly change the loss, we visualize the gradient values of the contrastive loss with respect to $\\mathbf{A}$ as shown in Fig. \\ref{fig:observation}(a). As expected, we observe that the adversarial attacks on GRACE are mainly generated between low-degree and dissimilar nodes, which corroborates our theoretical analysis.\n\n\n"
                    }
                },
                "subsection 4.3": {
                    "name": "Limitation of Existing Adversarial GCL",
                    "content": "\n\\label{subsec:4.3}\n% Recent robust GCL methods have succeeded in obtaining robustness under the graph attack by adopting AT in the vision domain. The adversarially trained model takes account of the perturbed edge, and outputs robust representations although the perturbed graph is fed into the GCL model. However, we argue that such robustness to the structural attack carries a burden in a graph domain, losing the node feature information. In other words, applying AT to GCL has a potential risk to lose the node feature similarity information, while obtaining robustness against the structural attacks.\n% \\smallskip\n\n% \\noindent \\textbf{AT fails to preserve the node similarity.} \\@ \n%This tendency appears due to the nature that the structure and the node features in a graph are dependent on each other. \n%and it is the major discrepancy between the adversarial attacks in the vision domain, where an image get imperceptible perturbations that does not change the meaning of the image itself. %We explain that the dependency can cause a problem when AT proceeds on a GCL models. \n% Nevertheless, many GCL models adopt AT as-is in the vision domain without taking into account the altered property of the attack. \n% \\textcolor{red}{YJ PROPOSES} As mentioned in the previous sections, the adversarial attacks on a graph tend to connect dissimilar nodes in the feature space. In other words, the adversarial attacks in a graph change the feature distribution of neighbors. It is problematic \nAs previously demonstrated, adversarial attacks on graphs tend to connect nodes with dissimilar features. Given such an attacked graph, an adversarial GCL model aims to learn robust node representations by reducing the distance between the clean view and the adversarial view (Eqn. (\\ref{eq:attack_gcl}),(\\ref{eq:at})), where the adversarial view contains more edges that connect nodes with dissimilar features (Eqn. (\\ref{eq:diff})). However, although the perturbations in the adversarial view are imperceptible, the neighborhood feature distribution of each node has changed due to the aforementioned characteristic of adversarial attacks on graphs. Hence, we argue that as existing adversarial GCL models force the clean view to be close to the adversarial view while neglecting such changes in the neighborhood feature distributions in the adversarial view, they obtain robustness at the expense of losing the feature information, which is an unexpected consequence of applying AT to GCL models. \n\n\n\n\n\n\\smallskip\n\\noindent \\textbf{Empirical Study.} \\@ \n% \\noindent \\textbf{AT fails to Preserve Node Similarity.} \\@ \nTo verify our argument, we conduct empirical studies on several recent adversarial GCL models to investigate whether AT indeed fails to preserve the node feature similarity (Fig.~\\ref{fig:observation}(b)). To this end, we measure how much feature similarity in the node features $\\mathbf{X}$ is preserved in the node representations $\\mathbf{Z}$ learned by adversarial GCL model. Specifically, we first construct $k$-nearest neighbor graphs using $\\mathbf{X}$ and $\\mathbf{Z}$, and denote them by $\\mathbf{A}^{k\\text{NN}(\\mathbf{X})}$ and $\\mathbf{A}^{k\\text{NN}(\\mathbf{Z})}$, respectively, and compute the overlapping (OL) score between the two graphs as follows \\cite{simpgcn}:\n\\begin{equation}\n\\small\nOL(\\mathbf{A}^{k\\text{NN}(\\mathbf{Z})} , \\mathbf{A}^{k\\text{NN}(\\mathbf{X})})=\\frac{|\\mathbf{A}^{k\\text{NN}(\\mathbf{Z})} \\cap \\mathbf{A}^{k\\text{NN}(\\mathbf{X})}|}{|\\mathbf{A}^{k\\text{NN}(\\mathbf{X})}|}\n\\label{eq:ol}\n\\end{equation}\n\\noindent where $|\\mathbf{A}^{k\\text{NN}(\\mathbf{X})}|$ is the number of nonzero elements in $\\mathbf{A}^{k\\text{NN}(\\mathbf{X})}$, and $\\mathbf{A}^{k\\text{NN}(\\mathbf{Z})} \\cap \\mathbf{A}^{k\\text{NN}(\\mathbf{X})}$ is the intersection of two matrices, i.e., element-wise product of two matrices. Note that a high $OL$ score indicates a high overlap between two matrices $\\mathbf{A}^{k\\text{NN}(\\mathbf{Z})}$ and $\\mathbf{A}^{k\\text{NN}(\\mathbf{X})}$, which implies that nodes with similar representations also have similar features. In other words, if the $OL$ score is high, the node representations contain more information about the node features.\n\n\\smallskip\n\\noindent \\textbf{AT fails to Preserve Node Similarity.} \\@ \n\\looseness=-1\nFig. \\ref{fig:observation}(b) shows the $OL$ score of GRACE and GRACE-AT, which is the adversarially trained GCL model built upon GRACE. We observe that the $OL$ scores of GRACE-AT is lower than those of GRACE, which does not employ AT, across all the perturbation ratios, although they outperform GRACE in terms of node classification accuracy. This implies that the learned representations of adversarial GCL model (i.e., GRACE-AT) fail to preserve the feature information while becoming robust to structural attacks, {which means that AT encourages the learned node representations to contain less feature information. However, as demonstrated by previous studies \\cite{kdd20-prognn, simpgcn, rsgnn}, the node feature information is crucial for defending against graph structure attacks, and we argue that \n\\textit{the robustness against structure attacks of adversarially trained GCL model can be further enhanced fully exploiting the node feature information}.\n% such that fully exploiting the node feature information is required to enhance the robustness against structure attacks of adversarially trained GCL model}. \nHence, in the following section, we propose an adversarial GCL framework that aims to preserve the node feature similarity information while being robust to adversarial attacks. Hence, in the following section, we propose an adversarial GCL framework that aims to preserve the node feature similarity information while being robust to adversarial attacks.}\n% This implies that the learned representations of adversarial GCL models (i.e., GRACE-ADV and ARIEL) fail to preserve the feature information as they obtain the adversarial robustness against graph structural attacks. However, we argue that preserving node feature similarity is crucial considering that most real-world graphs are incomplete in nature (e.g., low-degree nodes). Besides, the node feature similarity becomes especially useful when graphs are poisoned (e.g., adversarially attacked graph) or heterophilous in nature, in which case the given structural information is not particularly helpful for training GNN models. Hence, in the next section, we propose an adversarial GCL framework that aims to preserve the node feature similarity information.\n\n% similarity-preserving adversarial graph contrastive learning (\\proposed) framework.\n\n"
                }
            },
            "section 5": {
                "name": "Proposed Method:~\\proposed",
                "content": "\n% To alleviate the effect that adversarial GCL reduces the feature similarity information, \nIn this section, we propose \\textbf{S}imilarirty \\textbf{P}reserving \\textbf{A}dversarial \\textbf{G}raph \\textbf{C}ontrastive \\textbf{L}earning (\\proposed), a framework for the robust unsupervised graph representation learning.~\\proposed~achieves adversarial robustness, while preserving the node feature similarity by introducing two auxiliary views for contrastive learning, i,e. the similarity-preserving view and the adversarial view.\n% preserves the node feature similarity and \\textcolor{blue}{enhances the adversarial robustness by introducing two auxiliary views, i,e. the similarity-preserving view and the adversarial view.}\n\n\n\n% \\subsection{Model Overview}\n\\smallskip\n\\noindent \\textbf{Model Overview.} \\@\n% \\proposed~introduces the similarity-preserving view in addition to the adversarial view with the cross-view contrastive objective that contrasts the auxiliary views with each other. \nThe overall architecture of~\\proposed~is described in Fig. \\ref{app-fig:architecture} of Appendix~\\ref{app-sec:overall_framework}. First, ~\\proposed~generates four views that contain different properties: two stochastically augmented views, one similarity preserving view for retaining the feature similarity, and one adversarial view for achieving the adversarial robustness against graph attacks. We then encode the views with GCN layers. Finally, we optimize the cross-view contrastive learning objective based on the encoded views. By optimizing the cross-view objective, the learned node representations obtain the adversarial robustness and enriched feature information.\n\n\n\n",
                "subsection 5.1": {
                    "name": "View Generation",
                    "content": "\nGiven a graph $\\mathbf{(A,X)}$, we first generate two stochastically augmented views $(\\mathbf{A}^1, \\mathbf{X}^1)$ and $(\\mathbf{A}^2,\\mathbf{X}^2)$ both of which are processed by randomly dropping edges and node features as in \\cite{grace}. Then, we construct auxiliary views, i.e., the similarity-preserving view and the adversarial view. % Consequently,~\\proposed~obtains robust node representations against adversarial attacks while preserving the node feature similarity.\n",
                    "subsubsection 5.1.1": {
                        "name": "Similarity-preserving view",
                        "content": "\nThe similarity-preserving view aims to preserve the node similarity information in terms of node features (i.e., $\\mathbf{X}$). We first construct a top-$k$ similarity matrix (i.e., ${\\mathbf{A}}^{k\\text{NN}(\\mathbf{X})}$) based on $\\mathbf{X}$ using the $k$-nearest neighbor algorithm \\cite{knn1, knn2}. More precisely, we select the top-$k$ most similar nodes for each node based on the node feature matrix $\\mathbf{X}$. \nThe main reason for introducing the similarity-preserving view (i.e., $({\\mathbf{A}}^{k\\text{NN}(\\mathbf{X})}, \\mathbf{X})$) is to provide self-supervision signals regarding the node feature information to other views, so that the representations of nodes with similar features are pulled together, which in turn preserves the node feature similarity. This is in contrast to existing adversarial GCL models that obtain robustness against adversarial attacks at the expense of losing the node feature similarity information. % Although we cannot remove such effects directly, the similarity-view can preserve the feature information by converting the feature similarity information to the structural form as an individual view. \nIt is important to note that as the node similarity-preserving view is constructed solely based on the raw features of nodes regardless of the graph structure (i.e., structure-free), the model is particularly robust against structure poisoning attacks . As a result,~\\proposed~ is relatively robust even on severly attacked graph, as will be later shown in the experiments.\n\n% It is important to note that the similarity-preserving view is solely based on the raw features of nodes (i.e., structure-free), and thus it is not affected by any edge perturbations, which makes it beneficial even on severely attacked graphs.\n\n\n\n\n"
                    },
                    "subsubsection 5.1.2": {
                        "name": "Adversarial view",
                        "content": "\n\\label{sec:adv_view}\n\\looseness=-1\nThe adversarial view $(\\mathbf{A}^{\\text{adv}}, \\mathbf{X}^{\\text{adv}})$ is an augmented view generated by attacking the clean view $(\\mathbf{A}^1, \\mathbf{X}^1)$ following Eqn. (\\ref{eq:attack_gcl}). \n% We herein focus on generating \\textcolor{blue}{an adversarial view that is helpful for robustness of an adversarially trained model. In this regard, we present the adversarial feature masking that is applied with structural perturbations together.}\nWe herein focus on generating an adversarial view that further exploits the node feature information to achieve robustness of an adversarially trained model. In this regard, we present the adversarial feature mask that is applied along with the structural perturbations.\n% \\textcolor{blue}{an adversarial view that exploits more feature information to achieve robustness of an adversarially trained model. In this regard, we present the adversarial feature masking that is applied with structural perturbations together.}\n%, which incorporates both the structural and feature perturbations. \nThe most common approach for finding the structural and feature perturbations (i.e., $\\delta_{\\mathbf{A}}^*$ and $\\delta_{\\mathbf{X}}^*$) is to utilize the gradient-based perturbations that greatly change the contrastive loss. \n\n\\smallskip\n\n\\noindent \\textbf{1) Structural Perturbations.} \\@ For structural perturbations, we follow the similar procedure as \\cite{clga} to flip edges by computing the following gradients: $\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{A}^1} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{Z}^1}\n    \\frac{\\partial f(\\mathbf{A}^1, \\mathbf{X}^1)}{\\partial \\mathbf{A}^1}$ and $\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{A}^2} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{Z}^2}\n    \\frac{\\partial f(\\mathbf{A}^2, \\mathbf{X}^2)}{\\partial \\mathbf{A}^2}$, where $\\mathcal{L}$ is the first term in Eqn.~(\\ref{eq:at}).\n% \\begin{equation}\n% \\small\n%     \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{A}^1} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{Z}^1}\n%     \\frac{\\partial f(\\mathbf{A}^1, \\mathbf{X}^1)}{\\partial \\mathbf{A}^1}, \\quad\n%     \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{A}^2} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{Z}^2}\n%     \\frac{\\partial f(\\mathbf{A}^2, \\mathbf{X}^2)}{\\partial \\mathbf{A}^2}\n% \\end{equation}\n% \\begin{equation}\n%     \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{A}^1} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{Z}^1}\n%     \\frac{\\partial f(\\mathbf{A}^1, \\mathbf{X}^1)}{\\partial \\mathbf{A}^1}\n%     \\label{eq:grad_a1}\n% \\end{equation}\n% \\begin{equation}\n%     \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{A}^2} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{Z}^2}\n%     \\frac{\\partial f(\\mathbf{A}^2, \\mathbf{X}^2)}{\\partial \\mathbf{A}^2}\n% \\label{eq:grad_a2}\n% \\end{equation}\nBased on the sum of the gradients (i.e., $\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{A}^1}+\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{A}^2}=\\mathbf{G}_\\mathbf{A}\\in\\mathbb{R}^{N\\times N}$), the optimal edges to flip (i.e., $\\delta_{\\mathbf{A}}^*$) are determined. \nMore precisely, for positive elements of $\\mathbf{G}_\\mathbf{A}$, we take the corresponding edges with large gradients and add them to $\\mathbf{A}^1$ to generate $\\mathbf{A}^{\\text{adv}}$. Moreover, for negative elements of $\\mathbf{G}_\\mathbf{A}$, we take the corresponding edges with small gradients, and delete them from $\\mathbf{A}$ to generate $\\mathbf{A}^{\\text{adv}}$. Note that the number of edges to add and delete is within the perturbation budget (i.e., $\\norm{\\delta_{\\mathbf{A}}}_0 \\leq \\Delta_{\\mathbf{A}}$).\n\\smallskip\n\n\n% \\begin{algorithm}[t]\n% \\caption{\\textcolor{red}{TO BE RE-WRITTEN} Algorithm of \\proposed~}\n% \\begin{algorithmic}\n%     \\State \\textbf{Input data}: Graph $\\mathcal{G}= (\\mathbf{A, X})$\n%     \\State Randomly initialize $\\mathbf{\\Theta}$, parameter of graph encoder \n%     \\State Generate similarity-preserving view $\\mathcal{G}^{\\mathbf{sp}}=(\\mathbf{A^{kNN(X)}}, \\mathbf{X})$\n    \n%     \\ForAll{epoch}\n%         \\State Sample a subgraph $\\mathcal{G}_s=(\\mathbf{A_s, X_s})$, $\\mathcal{G}^{\\mathbf{sp}}_s=(\\mathbf{A_s^{kNN(X)}}, \\mathbf{X}_s)$\n%         \\State Generate two augmented views $\\mathcal{G}_s^1$ and $\\mathcal{G}_s^2$ from $\\mathcal{G}_s$ \n%         \\State Encode two views $\\mathcal{G}_s^1$ and $\\mathcal{G}_s^2$ to $\\mathbf{Z^1}$ and $\\mathbf{Z^2}$\n%         \\State Calculate contrastive loss $\\mathcal{L}(\\mathbf{Z^1, Z^2})$ by Eq.\\ref{eq:cl_loss}\n%         \\State Generate the adversarial view $\\mathcal{G}_s^{\\mathbf{adv}}$ by Algorithm.\\ref{algo2}\n%         \\State Encode four views $\\mathcal{G}_s^1$, $\\mathcal{G}_s^2$, $\\mathcal{G}_s^{\\mathbf{sp}}$, and $\\mathcal{G}_s^{\\mathbf{adv}}$ to $\\mathbf{Z^1}$, $\\mathbf{Z^2}$, $\\mathbf{Z^{\\mathbf{sp}}}$, and $\\mathbf{Z^{\\mathbf{adv}}}$\n%         \\State Update model parameter $\\mathbf{\\Theta}$ by optimizing Eq.\\ref{final_loss}\n%     \\EndFor\n%     \\State \\textbf{return:} model parameter $\\mathbf{\\Theta}$\n% \\end{algorithmic}\n% \\label{algo1}\n% \\end{algorithm}\n\n\n\n\n\\noindent \\textbf{2) Adversarial Feature Mask.} \\@ \n% For node feature perturbations, a strategy similar to the structural perturbation can be adopted to flip the node features. % However, it is challenging to collaboratively apply both the structural and the feature perturbations due to their dependency on each other. \n% For example, structural perturbations, which generally connect nodes with dissimilar features, may need to change the target nodes to be connected, if the node features are perturbed (or flipped) at the same time.\n% Hence, to avoid the problem incurred by the dependency between the graph structure and the node features, existing methods generally adopt a strategy that alternatively generates the structural and feature perturbations~\\cite{nettack,pmlr-19a-advattack-on-nodeembedding,ijacai-19-pgd-topology-attack-defense}.\n% Besides, the alternative perturbation of the graph structure and the node feature requires expensive computations, which is neither scalable nor practical in reality.\n% To this end, we propose adversarial feature masking technique that collaboratively works with the structural perturbation, which finds the feature masks that greatly increase the contrastive loss.\nFor node feature perturbations, a strategy similar to the structural perturbation can be adopted to flip the node features (i.e., change from 0 to 1 and from 1 to 0) as in \\cite{grv,ariel}. However, when the feature flipping strategy is applied to node feature perturbations, the co-occurrence/correlation statistics of nodes are significantly altered~\\cite{nettack}. Such a behavior may have an adverse effect on the AT by making the clean view and the adversarial view too distant from each other.\n% may significantly alter the co-occurrence/correlation statistics of node features, and such a behavior may have an adverse effect on the AT by making the clean view and the adversarial view too distant from each other.\nHence, to perturb node features while retaining the co-occurrence/correlation statistics of node features, we propose to mask (i.e., only change from 1 to 0) features that greatly increase the contrastive loss. \n% More formally, we mask the node features with negatively small gradients since it will greatly increase the loss. \nSpecifically, considering that we are interested in changing the 1s in the feature matrix $\\textbf{X}$ to 0s, we mask the node features with small gradients in the negative direction, since doing so will greatly increase the loss. \nMore formally, to obtain the adversarial mask, we compute the following gradients: $\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{X}^1} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{Z}^1}\n    \\frac{\\partial f(\\mathbf{A}^1, \\mathbf{X}^1)}{\\partial \\mathbf{X}^1}$ and $\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{X}^2} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{Z}^2}\n    \\frac{\\partial f(\\mathbf{A}^2, \\mathbf{X}^2)}{\\partial \\mathbf{X}^2}$, where $\\mathcal{L}$ is the first term in Eqn.~(\\ref{eq:at}). Based on the sum of the gradients with respect to the node features (i.e., $\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{X}^1}+\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{X}^2}=\\mathbf{G}_\\mathbf{X}\\in\\mathbb{R}^{N\\times F}$), the adversarial feature mask $\\mathbf{M}$ is obtained. \nMore precisely, for negative $\\mathbf{G}_\\mathbf{X}$, we take the node features with small gradients to generate the mask $\\textbf{M}$. That is, $\\mathbf{M}_{ij}=0$ if the $j$-th feature of node $i$ has a small gradient, otherwise $\\mathbf{M}_{ij}=1$, where the number of zeros in the mask $\\mathbf{M}$ is within the perturbation budget (i.e., $\\norm{\\mathbf{M}}_0 \\leq \\Delta_{\\mathbf{X}}$). Then, we apply $\\mathbf{M}$ to obtain the node features of the adversarial view (i.e., $\\mathbf{X}^{\\text{adv}}$) as follows:\n$\\mathbf{X}^{\\text{adv}} = \\mathbf{M}\\odot \\mathbf{X}^1$, where $\\odot$ is hadamard product for matrices. \n% As the \n% The main intuition is mask node features that are important, so that by reconstructing the original representation $\\mathbf{Z}^1$\n% \\textcolor{blue}{Note that we mask the node features that are important to construct the original representation $\\mathbf{Z}^1$.}\n% That is, the remaining (i.e., unmasked) features in $\\mathbf{X}^{\\text{adv}}$ will construct the representation $\\mathbf{Z}^{\\text{adv}}$ close to $\\mathbf{Z}^1$ when AT is applied to the GCL model. Hence, the adversarial masking exploits more feature information since it facilitates remaining node features.\n% \\textcolor{blue}{For example, if an observed feature (e.g., a word in a document) has a negatively small gradient, then masking the feature (e.g., removing the word in the document) will greatly increase the loss.}\nBy masking the node features that play an important role in the contrastive learning, and using it as another view in the GCL framework, we expect to learn node representations that are invariant to masked features, which encourages the GCL model to fully exploit the node feature information.\n% that the adversarial view focuses on the remaining features after masking, and it exploits more feature information by learning node representations that are invariant to masked features. \n\n\n% \\textcolor{blue}{Note that the remaining (i.e., unmasked) features in $\\mathbf{X}^{\\text{adv}}$ are unnoticed node features for the node representations, which does not change the contrastive loss greatly.}\n% \\textcolor{blue}{Then we obtain the node features of the adversarial view $\\mathbf{X}^{\\text{adv}} = \\mathbf{M}\\odot \\mathbf{X}^1$, where $\\odot$ is hadamard product for matrices. Note that remaining elements in $\\mathbf{X}^{\\text{adv}}$ are unnoticed node features for the node representations, which does not change the contrastive loss greatly.}\n% \\textcolor{blue}{Then we obtain the node features of the adversarial view $\\mathbf{X}^{\\text{adv}} = \\mathbf{M}\\odot \\mathbf{X}^1$, where $\\odot$ is hadamard product for matrices. Note that remaining elements in $\\mathbf{X}^{\\text{adv}}$ are unnoticed node features for the node representations, which does not change the contrastive loss greatly.}\n% Then we apply $\\mathbf{M}$ to obtain $\\mathbf{X}^{\\text{adv}}$ as follows:\n% $\\mathbf{X}^{\\text{adv}} = \\mathbf{M}\\odot \\mathbf{X}^1$, where $\\odot$ is hadamard product for matrices. \n\n\n% \\textcolor{blue}{Then we obtain the node features of the adversarial view $\\mathbf{X}^{\\text{adv}} = \\mathbf{M}\\odot \\mathbf{X}^1$, where $\\odot$ is hadamard product for matrices. Note that $\\mathbf{X}^{\\text{adv}}$ consists of remaining features after masking the features in X1 that are important for predicting the representations. }\n\n\n\n\n\\smallskip\n\\noindent\\textbf{3) Adversarial View Generation.}\nCombining the result of structural perturbations (i.e., $\\mathbf{A}^{\\text{adv}}$) and the result of adversarial feature masking (i.e., $\\mathbf{X}^{\\text{adv}}$), the adversarial view can be obtained (i.e., $(\\mathbf{A}^{\\text{adv}}, \\mathbf{X}^{\\text{adv}})$), and this view\n% The adversarial view generated by the above technique, i.e., $(\\mathbf{A}^{\\text{adv}}, \\mathbf{X}^{\\text{adv}})$, \ncontains both structural and feature perturbations, \nwhich makes the adversarial view more helpful for achieving adversarial robustness.\n% Moreover, ~\\proposed~ is more scalable than existing adversarial GCL models \\cite{ariel, grv} in terms of adversarial view generation\\footnote{This will be empirically shown in Fig. \\ref{fig:converge}}. \n% Regarding the computational efficiency, our proposed feature masking strategy only computes the gradients of loss with respect to the elements of $\\textbf{X}$ whose values equal to 1 (i.e., sparse), whereas feature flipping requires the computation of the gradients with respect to all the elements in $\\textbf{X}$. This implies that~\\proposed~is computationally efficient over existing works that adopt feature flipping \\cite{ariel, grv}.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n% \\proposed~ is more scalable than existing adversarial GCL models \\cite{ariel, grv} in terms of adversarial view generation\\footnote{This will be empirically shown in Fig. \\ref{fig:converge}}. More precisely,~\\proposed~requires only a single step of back-propagation of the loss for perturbing the structure and features different from an existing multiple steps method (i.e., projected gradient descent). Moreover,~\\proposed~computes only the gradients of sparse elements (i.e., non-zero elements of $\\mathbf{X}$) as~\\proposed~ utilizes feature masking rather than flipping.\n\n\\smallskip\n\\looseness=-1\n\\noindent \\textbf{Applicability to large networks.} \\@ \nSince computing the gradient with respect to both $\\mathbf{A}$ and $\\mathbf{X}$ requires expensive cost, adversarial GCL models are generally not scalable to large graphs. Hence, we generate all the views, i.e., $(\\mathbf{A}^1,\\mathbf{X}^1),(\\mathbf{A}^2,\\mathbf{X}^2),({\\mathbf{A}}^{k\\text{NN}(\\mathbf{X})}, \\mathbf{X})$, and $(\\mathbf{A}^{\\text{adv}}, \\mathbf{X}^{\\text{adv}})$, for only a subset of the original graph by randomly sampling a subgraph $\\bar{\\mathcal{G}}$ with $(\\bar{\\mathbf{A}},\\bar{\\mathbf{X}})$ from the original graph $\\mathcal{G}$ \\cite{ariel, mvgrl}, and then apply the same view generation procedure described above. \n% Moreover, we select a simple perturbing method that requires only single step of back-propagation for scalability.\n\n"
                    }
                },
                "subsection 5.2": {
                    "name": "Cross-view Training for Robust GCL",
                    "content": "\nBased on the representations obtained from different views, we train~\\proposed~by using the cross-view contrastive objective:\n% . By extending Equation (\\ref{eq:at}), our final objective is\n\\begin{equation}\n\\small\n    \\min_{\\Theta} \\mathcal{L}(\\mathbf{Z}^1, \\mathbf{Z}^2) + \\lambda_1 \\mathcal{L}(\\mathbf{Z}^1, \\mathbf{Z}^{\\text{adv}}) + \\lambda_2 \\mathcal{L}(\\mathbf{Z}^1, \\mathbf{Z}^{k\\text{NN}(\\mathbf{X})})\n\\label{final_loss}\n\\end{equation}\n\\noindent where $\\lambda_1$ and $\\lambda_2$ are hyperparameters. The first term trains a GCL model, the second term contrasts a clean view with an adversarial view, and the last term contrasts the clean view with the similarity preserving view. Training the above objective enhances the robustness and preserves the feature similarity of the node representation. We empirically discovered that replacing $\\mathbf{Z}^1$ in $\\mathcal{L}(\\mathbf{Z}^1, \\mathbf{Z}^{\\text{adv}})$ and $\\mathcal{L}(\\mathbf{Z}^1, \\mathbf{Z}^{k\\text{NN}(\\mathbf{X})})$ with $\\mathbf{Z}^2$ does not make a significant difference to the model performance.\n% learn the representation. \n% unless we change the view either $\\mathcal{L}(\\mathbf{Z}^1, \\mathbf{Z}^{\\text{adv}})$ or $\\mathcal{L}(\\mathbf{Z}^1, \\mathbf{Z}^{k\\text{NN}(\\mathbf{X})})$. \n% The entire procedure of~\\proposed~is illustrated in algorithm \\ref{algo1}.\n\n\n\n\n"
                }
            },
            "section 6": {
                "name": "Experiment",
                "content": "\n% In this section, we conduct extensive experiments to verify the effectiveness of~\\proposed~under various scenarios. \n% Specifically, we aim to answer the following research questions:\n% \\begin{itemize}\n%     \\item \\textbf{RQ1:} How robust is~\\proposed~given an adversarially attacked graph compared with the state-of-the-art adversarial GCL methods on various downstream tasks?\n%     \\item \\textbf{RQ2:} Does \\proposed~ also perform well under the real-world scenarios, e.g. networks with incomplete labels and heterophilous networks?\n%     \\item \\textbf{RQ3:} Does \\proposed~preserve the node feature similarity better than the state-of-the-art adversarial GCL methods?\n% \\end{itemize}\n\n\n\n\n% \\begin{table}[t]\n% \\centering\n% % \\small\n% \\caption{Statistics for datasets.}\n% \\vspace{-2ex}\n% \\renewcommand{\\arraystretch}{0.95}\n% {\\small\n% \\scalebox{0.8}{\n% \\begin{tabular}{c|c|cccc}\n% % \\noalign{\\smallskip}{\\smallskip}\n% \\hline\n%  Domain & Dataset & \\# Nodes & \\# Edges & \\# Features & \\# Classes \\\\\n% \\hline \n% \\multirow{3}{*}{Citation} & Cora     & 2,485          & 5,069         & 1,433      & 7   \\\\  \n% & Citeseer   & 2,110        & 3,668         & 3,703      & 6   \\\\\n% & Pubmed     & 19,717       & 44,338        & 500        & 3   \\\\\n% \\hline \n% \\multirow{2}{*}{Co-purchase} & Am.Photo   & 7,650        & 119,081       & 745        & 8   \\\\\n% & Am.Comp    & 13,752       & 245,861       & 767        & 10  \\\\\n% \\hline \n% \\multirow{2}{*}{Co-author}& Co.CS      & 18,333       & 81,894        & 6,805      & 15  \\\\\n% & Co.Physics   & 34,493     & 247,962       & 8,415      & 5    \\\\\n%  \\hline\n\n% \\multirow{6}{*}{Heterohpily} & Chameleon   &    2,277      &   36,101        &    2,325 & 5    \\\\\n% & Squirrel   &    5,201      &   217,073        &    2,089       &       5    \\\\\n% & Actor   &    7,600      &   33,544        &    931       &       5    \\\\\n% & Cornell   &    183      &   295        &    1,703       &       5    \\\\\n% & Texas   &    183      &   309        &    1,703       &       5    \\\\\n% & Wisconsin   &    251      &   499        &    1,703       &       5    \\\\\n% \\hline\n\n% \\end{tabular}\n% }}\n% \\label{tab:dataset}\n% \\vspace{-9ex}\n% \\end{table}\n\n\n\n% \\begin{table*}\n% \\vspace{-5ex}\n% \\captionof{table}{Left: Averaged running time of 100 duration  over 4000 epochs on Co.Physics dataset. Right: Validation Acc. of node classification on Co.Physics dataset.}\n% \\begin{minipage}[t]{.4\\linewidth}\n% \\centering\n% \\scriptsize\n% \\renewcommand{\\arraystretch}{0.9}\n% \\resizebox{1.2\\linewidth}{!}{\n% \\begin{tabular}{c|l|c|ccccc}\n%     \\toprule\n%     \\multirow{1}{*}{} & \\multirow{1}{*}{Methods}& {} & \\multicolumn{5}{c}{Poisoning (Acc.)} \\\\\n%     \\hline\n%     {Datasets}&{Ptb rate}&{Clean}&{5\\%}& 10\\% & 15\\% & 20\\% & 25\\% \\\\\n%     \\midrule\n%     %\\hline\n%     \\multirow{5}{*}{Cora} & GRACE   \n%     & 82.1±1.0            & 78.4±1.5          & 75.5±1.1          & 66.1±1.6          & 55.2±1.8          & 51.3±2.0               \\\\\n%     & GCA     \n%     & 81.5±0.9          & 79.8±0.8          & 75.8±0.6          & 68.4±1.6          & 53.4±1.7          & 49.5±1.3             \\\\\n%     & BGRL   \n%     & 82.7±1.0            & 78.2±2.1          & 74.3±1.8          & 66.2±1.9          & 53.8±1.7          & 50.2±2.3             \\\\\n%     & DGI-ADV \n%     & 83.7±0.7          & 79.4±0.9          & 73.3±0.6          & 63.5±0.6          & 52.2±0.7          & 48.1±0.7             \\\\\n%     & ARIEL   \n%     & 80.9±0.5          & 79.2±0.4          & 77.7±0.6          & 69.8±0.7          & 57.7±0.7          & 52.8±1.0            \\\\\n%     \\hline\n    \n%     & \\proposed \n%     & \\textbf{83.9±0.7} & \\textbf{81.7±0.7} & \\textbf{78.2±1.5} & \\textbf{72.3±1.1} & \\textbf{62.3±0.6} & \\textbf{56.9±0.9} \\\\\n    \n%     \\midrule\n%     \\multirow{5}{*}{Citeseer} \n%     & GRACE \n%     & 74.9{±0.6}          & 74.1{±0.6}          & 72.5{±0.9}          & 71.2{±1.3}          & 59.2{±1.4}          & 61.2{±1.5}                   \\\\\n%     & GCA\n%     & 74.2{±0.7}          & 73.5{±0.9}          & 73.0{±0.6}            & 71.5{±0.9}          & 60.2{±1.7}          & 60.1{±1.6}                 \\\\\n%     & BGRL    \n%     & 73.4{±1.0}            & 72.1{±1.1}          & 69.1{±1.0}            & 67.5{±1.4}          & 57.7{±1.3}          & 58.2{±2.8}                  \\\\\n%     & DGI-ADV \n%     & 76.6{±0.3}          & 74.8{±0.3}          & 71.0{±0.5}            & 70.1{±0.3}          & 57.9{±0.8}          & 60.6{±1.2}                   \\\\\n%     & ARIEL   \n%     & \\textbf{76.7{±0.5}} & \\textbf{75.2{±0.4}} & 72.8{±0.5}          & 70.2{±0.5}          & 60.1{±1.1}          & 62.7{±0.5}                  \\\\\n%     \\hline\n%     & \\proposed  \n%     & 75.9{±0.4}          & 74.8{±0.8}          & \\textbf{73.3{±0.8}} & \\textbf{72.5{±1.1}} & \\textbf{65.3{±1.4}} & \\textbf{67.9{±0.7}} \\\\\n    \n%     \\midrule\n%     \\multirow{5}{*}{Pubmed} \n%     & GRACE \n%     & 85.9{±0.1}          & 81.3{±0.2}          & 78.2{±0.4}          & 76.1{±1.3}          & 73.9{±1.7}          & 71.3{±2.6}                   \\\\\n%     & GCA     \n%     & \\textbf{86.5±{0.2}} & 81.2{±0.5}          & 78.1{±0.5}          & 75.9{±1.2}          & 74.2{±0.4}          & 72.0{±1.8}                   \\\\\n%     & BGRL    \n%     & 85.1{±0.2}          & 81.3{±0.3}          & 79.0{±0.4}            & 76.6{±0.9}          & 74.8{±0.9}          & 73.0{±0.5}                   \\\\\n%     & DGI-ADV \n%     & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}                        \\\\\n%     & ARIEL   \n%     & 81.2{±0.4}          & 77.8{±0.3}          & 75.8{±0.4}          & 74.0{±0.5}            & 72.3{±0.5}          & 70.7{±0.3}        \\\\\n%     \\hline              \n%     & \\proposed  \n%     & 85.5{±0.3}          & \\textbf{81.9{±0.2}} & \\textbf{79.7{±0.3}} & \\textbf{77.4{±0.3}} & \\textbf{75.6{±0.3}} & \\textbf{73.3{±0.3}} \\\\\n    \n%     \\bottomrule\n% \\end{tabular}}\n% \\end{minipage}\n% \\hfill%\n% \\begin{minipage}[HT]{.5\\linewidth}\n% \\scriptsize\n% \\resizebox{1.2\\linewidth}{!}{\n% \\begin{tabular}{c|l|c|ccccc}\n%     \\toprule\n%     \\multirow{1}{*}{} & \\multirow{1}{*}{Methods}& {} & \\multicolumn{5}{c}{Poisoning (Acc.)} \\\\\n%     \\hline\n%     {Datasets}&{Ptb rate}&{Clean}&{5\\%}& 10\\% & 15\\% & 20\\% & 25\\% \\\\\n    \n%     \\midrule\n%     \\multirow{5}{*}{Am.Photo} \n%     & GRACE\n%     & 92.0{±0.4}          & 89.5{±0.5}          & 88.3{±1.1}          & 87.6{±0.9}          & 87.5{±1.2}          & 87.1{±1.2}              \\\\\n%     & GCA     \n%     & 92.2{±0.4}          & 89.4{±0.6}          & 88.3{±0.8}          & 87.8{±0.7}          & 87.6{±1.0}          & 87.5{±0.7}                \\\\\n%     & BGRL    \n%     & 92.1{±0.4}          & 89.2{±0.6}          & 88.7{±0.5}          & 88.8{±0.5}          & 89.0{±0.7}          & 89.2{±0.4}                \\\\\n%     & DGI-ADV \n%     & 91.6{±0.5}          & 83.5{±0.5}          & 80.7{±0.6}          & 79.3{±0.6}          & 78.1{±0.6}          & 77.3{±0.6}                  \\\\\n%     & ARIEL   \n%     & 92.5{±0.2}          & 90.1{±0.4}          & 89.9{±0.5}          & 89.9±0.5          & 89.9{±0.5}          & \\textbf{89.8{±0.6}} \\\\\n%     \\hline              \n%     & \\proposed \n%     & \\textbf{93.3{±0.3}} & \\textbf{91.4{±0.5}} & \\textbf{90.6{±0.6}} & \\textbf{90.5{±0.8}} & \\textbf{90.2{±0.9}} & \\textbf{89.8{±1.0}}\\\\\n    \n%     \\midrule\n%     \\multirow{5}{*}{Am.Comp} \n%     & GRACE \n%     & 86.4{±0.5}          & 83.7{±0.3}          & 82.5{±0.6}          & 81.3{±0.5}          & 80.3{±0.7}          & 78.8{±1.0}               \\\\\n%     & GCA     \n%     & 86.6{±0.4}          & 84.6{±0.4}          & 83.4{±0.3}          & 82.3{±0.4}          & 81.4{±0.4}          & 80.1{±0.5}             \\\\\n%     & BGRL    \n%     & 88.0{±0.4}          & 85.2{±0.6}          & 84.2{±0.6}          & 83.7{±0.6}          & 83.3{±0.7}          & 83.4{±0.6}         \\\\\n%     & DGI-ADV\n%     & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               \\\\\n%     & ARIEL   \n%     & 87.4{±0.4}          & 85.4{±0.5}          & 84.5{±0.4}          & 83.8{±0.4}          & 83.7{±0.5}          & 83.6{±0.5}                 \\\\\n%     \\hline              \n%     & \\proposed  \n%     & \\textbf{89.1{±0.4}} & \\textbf{86.9{±0.3}} & \\textbf{85.6{±0.5}} & \\textbf{85.1{±0.4}} & \\textbf{85.0{±0.5}} & \\textbf{84.8{±0.7}} \\\\\n    \n%     \\midrule\n%     \\multirow{5}{*}{Co.CS} \n%     & GRACE \n%     & 92.3{±0.2}          & 91.2{±0.1}          & 90.6{±0.2}          & 90.0{±0.2}          & 89.4{±0.1}          & 88.9{±0.2}                 \\\\\n%     & GCA     \n%     & 92.5{±0.1}          & 91.4{±0.2}          & 90.7{±0.2}          & 90.2{±0.2}          & 89.7{±0.2}          & 89.3{±0.1}                  \\\\\n%     & BGRL    \n%     & 92.4{±0.2}          & 91.3{±0.1}          & 90.5{±0.2}          & 89.9{±0.2}          & 89.3{±0.2}          & 88.7{±0.2}                \\\\\n%     & DGI-ADV\n%     & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}                 \\\\\n%     & ARIEL   \n%     & 92.3{±0.2}          & 91.0{±0.1}          & 90.2{±0.2}          & 89.6{±0.3}          & 88.8{±0.2}          & 88.1{±0.2}               \\\\\n%     \\hline              \n%     & \\proposed \n%     & \\textbf{93.6{±0.2}} & \\textbf{92.8{±0.2}} & \\textbf{92.3{±0.2}} & \\textbf{91.8{±0.3}} & \\textbf{91.6{±0.2}} & \\textbf{91.3{±0.2}} \\\\\n    \n%     \\midrule\n%     \\multirow{5}{*}{Co.Physics} \n%     & GRACE  \n%     & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}                            \\\\\n%     & GCA  \n%     & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}                          \\\\\n%     & BGRL    \n%     & 95.2{±0.1}          & 94.1{±0.2}          & 93.2{±0.2}          & 92.5±0.1          & 91.6{±0.2}          & 91.0{±0.1}                 \\\\\n%     & DGI-ADV \n%     & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}                       \\\\\n%     & ARIEL   \n%     & 95.1{±0.1}          & 93.2{±0.2}          & 92.4{±0.2}          & 91.6{±0.2}          & 90.7{±0.3}          & 90.2{±0.2}                \\\\\n%     \\hline              \n%     & \\proposed  \n%     & \\textbf{95.8{±0.1}} & \\textbf{94.9±{0.2}} & \\textbf{94.4{±0.1}} & \\textbf{93.6±{0.1}} & \\textbf{93.0{±0.1}} & \\textbf{92.5±0.1} \\\\\n%     \\bottomrule\n% \\end{tabular}}\n% \\end{minipage}\n% \\vspace{-2ex}  \n% \\label{tab:converge}\n%\\end{table*}\n\n\n% \\begin{table*}[t]\n% \\scriptsize\n% \\begin{tabular}{c|l|c|ccccc}\n%     \\toprule\n%     \\multirow{1}{*}{} & \\multirow{1}{*}{Methods}& {} & \\multicolumn{5}{c}{Poisoning (Acc.)} \\\\\n%     \\hline\n%     {Datasets}&{Ptb rate}&{Clean}&{5\\%}& 10\\% & 15\\% & 20\\% & 25\\% \\\\\n%     \\midrule\n%     %\\hline\n%     \\multirow{5}{*}{Cora} & GRACE   \n%     & 82.1±1.0            & 78.4±1.5          & 75.5±1.1          & 66.1±1.6          & 55.2±1.8          & 51.3±2.0               \\\\\n%     & GCA     \n%     & 81.5±0.9          & 79.8±0.8          & 75.8±0.6          & 68.4±1.6          & 53.4±1.7          & 49.5±1.3             \\\\\n%     & BGRL   \n%     & 82.7±1.0            & 78.2±2.1          & 74.3±1.8          & 66.2±1.9          & 53.8±1.7          & 50.2±2.3             \\\\\n%     & DGI-ADV \n%     & 83.7±0.7          & 79.4±0.9          & 73.3±0.6          & 63.5±0.6          & 52.2±0.7          & 48.1±0.7             \\\\\n%     & ARIEL   \n%     & 80.9±0.5          & 79.2±0.4          & 77.7±0.6          & 69.8±0.7          & 57.7±0.7          & 52.8±1.0            \\\\\n%     \\hline\n    \n%     & \\proposed \n%     & \\textbf{83.9±0.7} & \\textbf{81.7±0.7} & \\textbf{78.2±1.5} & \\textbf{72.3±1.1} & \\textbf{62.3±0.6} & \\textbf{56.9±0.9} \\\\\n    \n%     \\midrule\n%     \\multirow{5}{*}{Citeseer} \n%     & GRACE \n%     & 74.9{±0.6}          & 74.1{±0.6}          & 72.5{±0.9}          & 71.2{±1.3}          & 59.2{±1.4}          & 61.2{±1.5}                   \\\\\n%     & GCA\n%     & 74.2{±0.7}          & 73.5{±0.9}          & 73.0{±0.6}            & 71.5{±0.9}          & 60.2{±1.7}          & 60.1{±1.6}                 \\\\\n%     & BGRL    \n%     & 73.4{±1.0}            & 72.1{±1.1}          & 69.1{±1.0}            & 67.5{±1.4}          & 57.7{±1.3}          & 58.2{±2.8}                  \\\\\n%     & DGI-ADV \n%     & 76.6{±0.3}          & 74.8{±0.3}          & 71.0{±0.5}            & 70.1{±0.3}          & 57.9{±0.8}          & 60.6{±1.2}                   \\\\\n%     & ARIEL   \n%     & \\textbf{76.7{±0.5}} & \\textbf{75.2{±0.4}} & 72.8{±0.5}          & 70.2{±0.5}          & 60.1{±1.1}          & 62.7{±0.5}                  \\\\\n%     \\hline\n%     & \\proposed  \n%     & 75.9{±0.4}          & 74.8{±0.8}          & \\textbf{73.3{±0.8}} & \\textbf{72.5{±1.1}} & \\textbf{65.3{±1.4}} & \\textbf{67.9{±0.7}} \\\\\n    \n%     \\midrule\n%     \\multirow{5}{*}{Pubmed} \n%     & GRACE \n%     & 85.9{±0.1}          & 81.3{±0.2}          & 78.2{±0.4}          & 76.1{±1.3}          & 73.9{±1.7}          & 71.3{±2.6}                   \\\\\n%     & GCA     \n%     & \\textbf{86.5±{0.2}} & 81.2{±0.5}          & 78.1{±0.5}          & 75.9{±1.2}          & 74.2{±0.4}          & 72.0{±1.8}                   \\\\\n%     & BGRL    \n%     & 85.1{±0.2}          & 81.3{±0.3}          & 79.0{±0.4}            & 76.6{±0.9}          & 74.8{±0.9}          & 73.0{±0.5}                   \\\\\n%     & DGI-ADV \n%     & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}                        \\\\\n%     & ARIEL   \n%     & 81.2{±0.4}          & 77.8{±0.3}          & 75.8{±0.4}          & 74.0{±0.5}            & 72.3{±0.5}          & 70.7{±0.3}        \\\\\n%     \\hline              \n%     & \\proposed  \n%     & 85.5{±0.3}          & \\textbf{81.9{±0.2}} & \\textbf{79.7{±0.3}} & \\textbf{77.4{±0.3}} & \\textbf{75.6{±0.3}} & \\textbf{73.3{±0.3}} \\\\\n    \n%     \\bottomrule\n% \\end{tabular}\n% \\vspace{-1ex}\n% \\label{tab:main_table}\n% \\end{table*}\n\n\n\n\n\n\n\n\n% \\begin{table*}[t]\n% % \\small\n% % \\centering\n% \\caption{Node classification performance under targeted attack (\\emph{nettack}). We report the average performance of 10 runs.}\n% \\vspace{-3ex}\n% \\renewcommand{\\arraystretch}{1}\n% \\begin{center}\n% {\\scriptsize\n% \\scalebox{1.1}{\n% \\begin{tabular}{c|l|c|ccccc|ccccc}\n%     \\toprule\n%     \\multirow{1}{*}{} & \\multirow{1}{*}{Methods} & {} & \\multicolumn{5}{c}{Poisoning (Acc.)} & \\multicolumn{5}{c}{Evasive (Acc.)} \\\\\n%     \\hline\n%     {Datasets}&{\\# Ptb}&{Clean}&{1}& 2 & 3 & 4 & 5 & 1 & 2 & 3 & 4 & 5 \\\\\n%     \\midrule\n%     %\\hline\n%     \\multirow{5}{*}{Cora} & GRACE   \n%     & 82.2±2.2          & 76.9±1.5          & 70.2±2.4          & 65.9±3.0          & 64.6±1.4          & 58.9±2.1          & 77.7±2.6          & 71.1±2.5          & 67.1±2.5          & 65.1±2.3          & 60.2±3.3          \\\\\n%     & GCA     \n%     & 81.3±1.7          & 77.7±2.1          & 71.6±2.2          & 67.2±2.3          & 63.9±2.2          & 59.2±2.0          & 79.2±1.2          & 73.0±0.8          & 69.2±1.2          & 67.1±1.5          & 62.3±3.0          \\\\\n%     & BGRL   \n%     & \\textbf{83.0±2.3}          & 78.6±1.9          & 73.0±3.9          & 69.3±2.9          & 63.7±5.0          & 60.5±3.1          & 79.2±2.8          & 74.5±2.1          & 70.7±3.2          & 66.9±2.8          & 64.1±3.0          \\\\\n%     & DGI-ADV \n%     & 81.7±0.7          & 78.0±2.3          & 71.1±2.1          & 69.9±1.1          & 65.7±1.8          & 60.7±1.9          & 78.1±1.6          & 73.0±2.1          & 70.6±1.3          & 66.5±1.2          & 63.4±1.4          \\\\\n%     & ARIEL   \n%     & 76.0±1.7          & 71.9±2.2          & 64.9±1.3          & 63.5±1.6          & 63.0±1.6          & 53.7±1.7          & 71.7±2.0          & 65.4±1.2          & 63.5±1.5          & 64.1±1.3          & 54.6±1.6          \\\\\n%     \\hline\n    \n%     & \\proposed \n%     & 82.5±2.0 & \\textbf{79.5±1.8} & \\textbf{75.3±2.5} & \\textbf{73.4±1.7} & \\textbf{67.4±2.2} & \\textbf{63.6±2.4} & \\textbf{80.2±2.4} & \\textbf{78.7±3.0} & \\textbf{77.1±3.2} & \\textbf{73.5±3.4} & \\textbf{72.8±3.7} \\\\\n    \n%     \\midrule\n%     \\multirow{5}{*}{Citeseer} \n%     & GRACE \n%     & 82.4±0.5          & 81.8±1.1          & 77.6±4.2          & 68.2±4.4          & 64.3±3.0          & 59.0±2.7          & 82.2±0.6          & 81.1±1.3          & 78.1±3.2          & 72.4±4.8          & 66.4±3.9          \\\\\n%     & GCA     \n%     & \\textbf{82.5±0.0}          & 82.4±0.5          & 78.2±2.9          & 69.4±5.9          & 65.9±2.0          & 58.2±4.0          & \\textbf{82.5±0.0}          & 81.1±1.5          & 79.2±2.5          & 77.0±2.6          & 71.3±4.4          \\\\\n%     & BGRL    \n%     & \\textbf{82.5±0.7 }         & 81.4±1.2          & 79.7±4.6          & 75.1±7.3          & 72.7±7.6          & 67.3±8.5          & 81.6±1.0          & 80.0±3.3          & 78.9±4.0          & 76.7±5.6          & 73.3±6.5          \\\\\n%     & DGI-ADV \n%     & \\textbf{82.5±0.0}          & 81.4±0.7          & 80.2±1.5          & 74.3±3.7          & 68.6±1.2          & 65.6±1.2          & 82.4±0.5          & 81.3±1.0          & 79.7±0.6          & 78.7±1.3          & 76.5±1.6          \\\\\n%     & ARIEL   \n%     & \\textbf{82.5±0.0} & 81.1±0.8 & 80.6±0.6          & 74.3±3.9          & 66.2±1.6          & 63.2±1.0          & 81.9±0.8 & 81.3±0.6          & 81.0±0.0          & \\textbf{80.2±0.8} & \\textbf{78.6±1.5} \\\\\n%     \\hline\n%     & \\proposed  \n%     & \\textbf{82.5±0.0 }         & \\textbf{82.5±0.0}          & \\textbf{81.6±1.0} & \\textbf{80.0±3.0} & \\textbf{75.4±6.1} & \\textbf{72.7±5.3} & 82.4±0.5          & \\textbf{82.1±1.0} & \\textbf{81.6±1.6} & \\textbf{80.2±4.2} & 78.1±4.9          \\\\\n    \n%     \\midrule\n%     \\multirow{5}{*}{Pubmed} \n%     & GRACE \n%     & 87.8±0.6          & 86.6±0.5          & 84.3±0.8          & 81.7±0.8          & 77.9±1.5          & 73.0±1.3          & 86.3±0.4          & 84.4±0.7          & 81.8±1.0          & 78.3±1.2          & 74.5±1.3          \\\\\n%     & GCA     \n%     & \\textbf{88.0±0.5} & \\textbf{87.1±0.6}          & \\textbf{84.7±0.7}          & 82.2±1.5          & 77.7±1.2          & 73.6±1.7          & \\textbf{87.0±0.5}          & \\textbf{85.2±0.7}          & 82.7±1.1          & 79.2±0.7          & 75.5±1.2          \\\\\n%     & BGRL    \n%     & 87.4±0.8          & 85.8±0.8          & 83.2±1.0          & 79.3±1.0          & 75.4±1.2          & 70.2±1.2          & 85.8±1.1          & 83.7±1.0          & 80.3±1.2          & 76.1±1.0          & 72.3±1.0          \\\\\n%     & DGI-ADV \n%     & OOM               & OOM               & OOM               & OOM               & OOM               & OOM               & OOM               & OOM               & OOM               & OOM               & OOM               \\\\\n%     & ARIEL   \n%     & 83.9±0.8          & 82.0±1.0          & 79.4±1.5          & 75.2±1.4          & 72.0±1.3          & 67.5±2.6          & 81.9±0.7          & 78.8±1.6          & 76.1±1.2          & 72.0±1.2          & 68.2±1.6          \\\\\n%     \\hline              \n%     & \\proposed  \n%     & 87.4±0.8          & 85.9±0.7 & 84.3±1.0 & \\textbf{82.7±1.1} & \\textbf{80.0±1.6} & \\textbf{77.7±2.2} & 86.2±0.5 & 84.5±0.7 & \\textbf{82.9±0.6} & \\textbf{81.0±1.0} & \\textbf{78.1±1.6} \\\\\n%     \\bottomrule\n% \\end{tabular}}}\n% \\end{center}\n% \\vspace{-1ex}\n% \\label{tab:main_table2}\n% \\end{table*}\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
                "subsection 6.1": {
                    "name": "Experimental Settings",
                    "content": "\n\\noindent \\textbf{Datasets.} \\@ We evaluate~\\proposed~and baselines on \\textbf{thirteen} benchmark datasets, including three citation networks \\cite{metattack, nettack}, two co-purchase networks \\cite{shchur2018pitfalls}, two co-authorship networks \\cite{shchur2018pitfalls}, and six heterophilous networks \\cite{geomgcn}. The statistics of the datasets are given in Appendix~\\ref{app-sec:dataset}.\n\n\\smallskip\n\n\\noindent \\textbf{Baselines.} \\@ The baselines include the state-of-the-art unsupervised graph representation learning (i.e., GRACE, GCA, BGRL) and defense methods (i.e., DGI-ADV, ARIEL). \nAdditionally, we include GRACE-MLP, which uses an MLP encoder instead of a GCN encoder, as a baseline that focuses on the node feature information rather than the graph structure.\n% \\textcolor{blue}{We further include GRACE-MLP, which uses MLP encoder instead of GCN encoder}. \nWe describe the details of baseline models in Appendix~\\ref{app-sec:baseline}.\n\n% Specifically, GRACE \\cite{grace} and GCA \\cite{gca} are augmentation-based GCL models, and BGRL \\cite{bgrl} is the state-of-the-art non-GCL method that minimizes the distance of two node representations from different augmentations without negative samples. Besides, DGI-ADV is trained by alternatively optimizing DGI and AT. ARIEL \\cite{ariel} is the state-of-the-art adversarial GCL model that adopts AT to GRACE framework with an information regularizer for stabilizing the model training.\n\n\\smallskip\n\n\\noindent \\textbf{Evaluation Protocol.} \\@\nWe evaluate~\\proposed~and the baselines under the poisoning attack and evasive attack. The poisoning attack indicates that the graph is attacked before the model training, whereas the evasive attack contains the perturbations only after the model parameters are trained on the clean graph \\cite{adv_survey}.\n% On the other hand, . While non-targeted attack aims to fool the overall performace of GNNs, targeted attack's goal is to deteriorate GNNs' performace on specific nodes. We adopt \\emph{metattack}\\cite{metattack} and \\emph{nettack} \\cite{nettack} as non-targeted and targeted attack, respectively. \nFor each setting, we use the public attacked graph datasets offered by \\cite{kdd20-prognn} that contain both untargeted attacks \\emph{metattack} and targeted attacks \\emph{nettack} for the three citation networks. For the co-purchase and co-authorship networks, we create attacked graphs  using \\cite{li2020deeprobust} by repeatedly sampling 3,000 nodes and attacking with \\emph{metattack} due to the large size of these datasets.\n% For heterophilious networks, we use the original graph data, not the attacked one, as the same setting as \\cite{geomgcn}. \n\n\\noindent \\textbf{Implementation Details.} \\@ The implementation details are described in Appendix~\\ref{app-sec:imp_detail}.\n\n% \\smallskip\n\n% \\noindent \\textbf{Evaluation Metrics.} \\@\n% The performance of models on node classification, link prediction, and node clustering is evaluated in terms of accuracy, area under curve (AUC), and normalized mutual information (NMI), respectively.\n\n\n\n\n\n\n\n"
                },
                "subsection 6.2": {
                    "name": "Performance of Adversarial Defense",
                    "content": "\n% We evaluate the model performance on node classification, link prediction, and node clustering under various attack scenarios. \n% The comparison results for node classification both under poisoning and evasive \\emph{metattack} on seven homophilous network datasets are summarized in Table \\ref{tab:main_table}. Note that while we use the perturbed citation graphs, i.e. Cora, CiteSeer, Pubmed, which are available on Github of \\cite{kdd20-prognn}, the attacked one of the remaining four graphs have yet to be made and published. \n% Accordingly, we repeatedly sample 3,000 nodes and employ the \\emph{metattack} to generate the perturbed graph until a given perturbation rate is satisfied, i.e. the ratio of changed edges varying from 5\\% to 25\\% by 5\\%,  because of a scalability issue of the \\emph{metattack}. (github address). \n\n\n\n\n\n",
                    "subsubsection 6.2.1": {
                        "name": "metattack",
                        "content": "\n\\label{sec:metattack}\n\\hfill\\\\\n\\noindent \\textbf{Setting.} \\@ We first train each model in an unsupervised manner, and then evaluate it with the linear evaluation protocol as in \\cite{dgi}. We use the same split as in \\cite{kdd20-prognn} for the three citation networks, and use the random 1:1:8 split for training, validation, and testing for the co-purchase and the co-authorship networks.\n\n\\smallskip\n\n\\noindent \\textbf{Result.} \\@\nWe first evaluate the robustness of~\\proposed~under non-targeted attack (\\emph{metattack}). \nIn Table~\\ref{tab:main_table}, we have the following two observations: \n\\textbf{1)} ~\\proposed~consistently outperforms other baselines under both the poisoning and the evasive attacks, which indicate that~\\proposed~ effectively achieves adversarial robustness with similarity-preserving view and the adversarial view. \n\\textbf{2)} The improvements of GRACE-MLP and ~\\proposed~ are especially larger under severe perturbation ratios. This implies the benefit of exploiting the node feature information for learning robust representations under severe perturbation ratios.\n% It implies that utilizing feature information is effective to learn robust representations under severe perturbation ratios. \n% The above observations imply that~\\proposed~effectively achieves robustness by exploiting both the node feature similarity information and graph structure information.\n% In Table~\\ref{tab:main_table}, we observe that~\\proposed~consistently outperforms other baselines under both the poisoning and the evasive attacks. \n% In Table \\ref{tab:main_table2}, we observe that~\\proposed~achieves the state-of-art performance under targeted attack (\\textit{nettack}). Similar to the results in Table~\\ref{tab:main_table}, the performance of~\\proposed~is enhanced when the number of perturbations for each targeted node increases. \n% The above results imply that~\\proposed~effectively defends non-targeted adversarial attacks by exploiting both the node feature similarity information and graph structure information. \\textcolor{blue}{Although GRACE-MLP is better than~\\proposed~under severe perturbation cases, in the real-world, }\n\n\n\n\n\n\n\n% Interestingly,~\\proposed~achieves a superior accuracy even in clean graphs on Am.Photo, Am.Comp, Co.CS, and Co.Physics datasets, whose node features are inherently of high-quality. We attribute this to the fact that the view generation process provides more useful signals for training as the quality of the node features gets higher. This implies that~\\proposed~makes better use of the feature information compared with other baselines.\n% as~\\proposed~incorporates the node feature information during the view generation process,\n% benefits from the node feature informationfocuses on the node feature information, \n% , implying that~\\proposed~can be improved if the data includes a high quality node feature information.\n% From the result and Figure 1(b), we claim that \\proposed~ succeeds to preserve node feature similarity, and its success leads GCL method to learn robust representation against adversarial attack by enjoying richer feature information. \n\nWe further investigate the performance  of~\\proposed~and baselines according to the degree of nodes. Fig. \\ref{fig:low_degree} shows that \\proposed~outperforms all the baselines on low-degree nodes, and particularly outperforms under severe perturbations, which corroborates our theoretical and empirical studies conducted in Section~\\ref{subsec:4.2}.\n% particularly noticeably boosts the model robustness under higher perturbation rate. \nThat is, as adversarial attacks on GCL models tend to be generated between low-degree nodes as shown in Section~\\ref{subsec:4.2}, it becomes particularly crucial to preserve the node feature similarity for low-degree nodes under severe perturbations. \nIn this respect, as~\\proposed~focuses on preserving the node feature similarity, it is relatively more robust against attacks on low-degree nodes compared with existing adversarial GCL models.\n% are vulnerable to adversarial attacks that connect nodes that are of low-degree\n% Since they lack the connections to other nodes and consequently suffer from an edge perturbation much more than the higher ones, taking full advantage of node feature information can be beneficial.\n% From the result, we claim that \\proposed~ succeeds to leverage much richer feature information by adversarial feature masking and node feature similarity preservation. Under poisoning attack, since structure information is incomplete, feature information becomes more important for achieving adversarial robustness. \n% \\noindent \\textbf{1)} \\proposed~ consistently outperforms other baselines under poisoning attack. From the result, we claim that \\proposed~ succeeds to leverage much richer feature information by adversarial feature masking and node feature similarity preservation. Under poisoning attack, since structure information is incomplete, feature information becomes more important for achieving adversarial robustness. \n% and its success leads GCL method to learn robust representation against adversarial attack by enjoying richer feature information. \\textbf{2)} Furthermore, It is well known that preserving node similarity can benefit the low-degree nodes, i.e. degree $\\leq$ 5 \\cite{simpgcn}. Since they lack the connections to other nodes and consequently suffer from an edge perturbation much more than the higher ones, taking full advantage of node feature information can be beneficial. Fig. \\ref{fig:degree} demonstrates that the node classification accuracy decreases as perturbation gets strong. Also, \\proposed~ outperforms all baselines for low-degree nodes, especially noticeably boosts the model robustness under higher perturbation rate. \n% \\textbf{2)} \\proposed~ consistently outperforms other baselines under evasive attack, while it performs better under poisoning than evasive attack. Since evasive attack is a test time attack, \n\n\n\n\n\n"
                    },
                    "subsubsection 6.2.2": {
                        "name": "nettack",
                        "content": " \n\\label{sec:nettack}\n\\hfill\\\\\n\\textbf{Setting.} \\@ Following the same evaluation procedure described in Section 6.2.1 of the main paper, we train each model (i.e., the node representations) in an unsupervised manner, and then evaluate it with the linear evaluation protocol as in \\cite{dgi}. We use the same split and attacked graph structure as in \\cite{kdd20-prognn} for the three citation networks, where \\emph{nettack} \\cite{nettack} is used to generate attacks on specific nodes, which aims at fooling GNNs predictions on those attacked nodes. To be specific, we increase the number of adversarial edges, which are connected to the targeted attacked nodes, from 1 to 5 to consider various targeted attack setups. Then, we evaluate the node classification accuracy on dozens of targeted test nodes with degree larger than 10.\n\n\\noindent \\textbf{Result.} \\@\nIn Table~\\ref{tab:main_table2}, we observe that ~\\proposed~ achieves the state-of-the-art performance under targeted attack (\\emph{nettack}). Similar to the results in Section. \\ref{sec:metattack}, {the performance gap between ~\\proposed~ and the baselines gets larger as the number of perturbations for each targeted node increases}. \n% Similar to the results in 6.2.1, the performance of ~\\proposed~ is enhanced as the number of perturbations for each targeted node increases. \nThe above result implies that exploiting more feature information is helpful for defending the targeted attack, which verifies the effectiveness of ~\\proposed.\n\n\n\n\n\n\n"
                    },
                    "subsubsection 6.2.3": {
                        "name": "Node classification under random perturbations",
                        "content": "\n\\hfill\\\\\n\\noindent \\textbf{Setting.} \\@ We randomly add fake edges into the graph structure to generate attacked graph structure, and then evaluate each model in the same way as above. {We use the three citation networks with the same data split as in \\cite{kdd20-prognn} and set the number of added faked edges as from 20\\% to 100\\% of the number of clean edges.}\n% The data split is used offered by \\cite{kdd20-prognn} for the three citation networks.\n\n\\noindent \\textbf{Result.} \\@\n\\looseness=-1\nIn Table~\\ref{tab:main_table3}, we observe that~\\proposed~consistently outperforms other baselines given randomly perturbed graph structure. Specifically, ~\\proposed~demonstrates its robustness under both the poisoning and the evasive attacks setting, showing similar results as reported in Section. \\ref{sec:metattack} and Section~\\ref{sec:nettack}. The result implies that~\\proposed~is robust to random perturbations by preserving the feature similarity and exploiting more feature information.\n\n\n\n\n\n\n\n\n\n\n\n"
                    }
                },
                "subsection 6.3": {
                    "name": "Preserving Feature Similarity",
                    "content": "\n\\noindent \\textbf{Analysis on Feature Similarity.} \\@ To verify whether~\\proposed~preserves the node feature similarity, we compute $OL$ scores of~\\proposed~in Fig. \\ref{fig:observation}(b) (Refer to Eqn.~(\\ref{eq:ol})). We observe that~\\proposed~has the highest $OL$ scores on Citeseer and Co.CS datasets. This implies that~\\proposed~preserves the feature similarity information unlike the adversarially trained GCL model whose node representations lose the feature similarity. \n\n\n\n\\smallskip\n\\noindent \\textbf{Benefit of Preserving Feature similarity.} \\@\nWe further investigate the benefits of preserving feature similarity in other downstream tasks (i.e., link prediction \\& node clustering). Fig.~\\ref{fig:link_cluster_low_high_degree}(a) and (b) show the result on Co.CS and Co.Physics datasets under \\emph{metattack}.\nFor \\textit{link prediction}, we closely follow a commonly used setting~\\cite{zhang2018link,asp2vec} and use area under curve (AUC) as the evaluation metric. \nWe observe that \\proposed~consistently predicts reliable links compared with other baselines across all the perturbation ratios. Furthermore, ARIEL, the state-of-the-art adversarial GCL model, shows the worst performance. We argue that node feature information is beneficial to predicting reliable links since nodes with similar features tend to be adjacent in many real-world graphs \\cite{rsgnn, kdd20-prognn}. Hence, our proposed adversarial feature masking and similarity-preserving view play an important role in predicting reliable links since they make the node representations retain more feature information. \nFor \\textit{node clustering}, we perform $k$-means clustering on the learned node representations, where $k$ is set to the number of classes, to verify whether the clusters are separable in terms of the class labels. We use normalized mutual information (NMI) as the evaluation metric.\nWe observe that~\\proposed~consistently outperforms ARIEL in node clustering as well, which demonstrates that preserving the node feature information is crucial as it is highly related to class information.\n\n% Fig.~\\ref{fig:link_cluster_low_high_degree}(b) and (c) show the result on Co.CS and Co.Physics datasets under \\emph{metattack}. We observe that for link prediction, \\proposed~consistently predicts reliable links compared with other baselines across all the perturbation ratios. Furthermore, ARIEL, the state-of-the-art adversarial GCL model, shows the worst performance. We argue that node feature information is beneficial to predicting reliable links since nodes with similar features tend to be adjacent in many real-world graphs \\cite{rsgnn, kdd20-prognn}. Hence, our proposed adversarial feature masking and similarity-preserving view play an important role in predicting reliable links since they make the node representations retain more feature information. \n% Moreover, we observe that~\\proposed~consistently outperforms ARIEL in node clustering as well, which demonstrates that preserving the node feature information is crucial as it is highly related to class information.\n% thanks to the robust node representations\n% For node clustering, \\proposed~constructs the cluster well based on robust representations. Besides, we observe that ARIEL performs poorly in node clustering too, which stems from the fact that ARIEL loses the node feature information, which is highly related to class information, due to AT.\n% \\vspace{-4ex}\n\\smallskip\n\\noindent \\textbf{Visualization of Representation Space.} \\@ We visualize the node representations of ARIEL and \\proposed~ via t-SNE \\cite{tsne} to intuitively see the effect of preserving the node feature information in the representation space. Fig. \\ref{fig:tsne} shows the node representations of ARIEL and \\proposed~ trained on a citeseer graph under 25\\% \\textit{metattack}. We observe that the representations of ARIEL are separable but widely distributed resulting in vague class boundaries. On the other hand, the representations of \\proposed~ are more tightly grouped together, resulting in more separable class boundaries. We attribute such a difference to the AT of ARIEL that incurs a loss of node feature information, which is preserved in \\proposed. Furthermore, the vague class boundaries of ARIEL explain the poor performance of ARIEL in the node clustering task shown in Fig. \\ref{fig:link_cluster_low_high_degree}(b).\n\n% \\textcolor{blue}{These results can be explained as a perspective of preserving feature similarity. Since ARIEL loses the node feature information due to the AT, which is preserved in \\proposed, the learned representations form vague class boundaries, thereby leading to the poor performance of node clustering. }\n\n\n\n\n\n\n\n\n\n"
                },
                "subsection 6.4": {
                    "name": "Experiments on Real-World Scenarios",
                    "content": "\n\\noindent \\textbf{Node classification with Noisy Label.} \\@ \nWe compare ~\\proposed~ with both supervised (i.e., RGCN~\\cite{kdd-19-rgcn}, ProGNN~\\cite{kdd20-prognn}, and SimP-GCN~\\cite{simpgcn}) and unsupervised defense methods (i.e., DGI-ADV and ARIEL) to confirm the effectiveness of models when the label information contains noise. We train the models on the clean and poisoned Citeseer dataset, whose label noise rates are varied. In Fig. \\ref{fig:noisy}, we observe that the unsupervised methods (especially~\\proposed) outperform the supervised methods at relatively high noise rates (i.e., 40\\% and 50\\%). This is because the node representations of the supervised defense methods are not well generated in terms of the downstream task since they heavily rely on the supervision signals obtained from the noisy node labels. \nMoreover, we observe that~\\proposed~outperforms unsupervised methods (i.e., DGI-ADV and ARIEL), and the performance gap gets larger as the label noise rate increases. \nWe argue that this is mainly because~\\proposed~better exploits feature information, which results in more robust node representations under noisy labels demonstrating practicality of~\\proposed~in reality.\n% which implies that~\\proposed~\n% \\textcolor{blue}{Furthermore, we also observe that \\proposed~ outperforms the other unsupervised methods. We argue that this is mainly because \\proposed~ exploits more feature information so that generates more effective node representations. From the above results it is shown that ~\\proposed~ is most practical in reality.}\n\n\n\n% This is because as the supervised defense methods heavily rely on the supervision signals obtained from the node labels, the quality of the node labels is crucial for achieving the model robustness. \n\n\n% In unsupervised node representation learning, the most important thing to several downstream tasks is to generate representation space where the representations of semantically similar nodes are \n\n% The reason is that the \\proposed~ exploits more feature information so that its node representations are tightly grouped together according to their corresponding node labels than the others.\n\n\n% node representations of thanks to exploiting more feature informations. Specifically, as \\proposed~ generating   node representations than others (illustrated in \\ref{sec:6_4}), the downstream task accuracy can be maintained even when the label noise rate is high, which shows the practicality of ~\\proposed~ in reality.}\n\n\n% \\textcolor{blue}{Furthermore, \\proposed~ also outperforms the other unsupervised methods thanks to exploiting more feature informations. Specifically, as \\proposed~ generating discriminative node representations than others (illustrated in \\ref{sec:6_4}), the downstream task accuracy can be maintained even when the label noise rate is high, which shows the practicality of ~\\proposed~ in reality.}\n% On the other hand, as~\\proposed~mainly focuses on the graph structure and the node feature information rather than the node labels, the robustness can be maintained even when the label noise rate is high, which shows the practicality of~\\proposed~in reality.\n\n% We compare~\\proposed~with both supervised (i.e., RGCN~\\cite{kdd-19-rgcn}, ProGNN~\\cite{kdd20-prognn}, and SimP-GCN~\\cite{simpgcn}) and unsupervised defense methods (i.e., DGI-ADV and ARIEL) to confirm the effectiveness of models when the label information contains noise. We train the models on the clean and poisoned Citeseer dataset, whose label noise rates are varied. In Fig. \\ref{fig:noisy}, we observe that the unsupervised methods (especially~\\proposed) outperform the supervised methods at relatively high noise rates (i.e., 40\\% and 50\\%).\n% This is because as the supervised defense methods heavily rely on the supervision signals obtained from the node labels, the quality of the node labels is crucial for achieving the model robustness. On the other hand, as~\\proposed~mainly focuses on the graph structure and the node feature information rather than the node labels, the robustness can be maintained even when the label noise rate is high, which shows the practicality of~\\proposed~in reality.\n\n\n% This is due to the fact that the supervised defense methods are affected by the supervision signals. We claim that~\\proposed~is much beneficial to robustness when the label information is incomplete.\n\n\n\n\n\n\n\n\n\n\\smallskip\n\\noindent \\textbf{Node classification on Heterophilous Networks.} \\@ \nThroughout this paper, we showed that preserving node feature similarity is crucial when graphs are poisoned/attacked. In fact, a heterophilous network~\\cite{zhu2021graph} in which nodes with dissimilar properties (e.g., node features and labels) are connected can be considered as a poisoned/attacked graph considering the behavior of adversarial attacks described in Section~\\ref{sec:4}. Hence, in this section, we evaluate~\\proposed~on six commonly used heterophilous networks benchmark in terms of node classification. In Table~\\ref{tab:hetero}, we observe that~\\proposed~outperforms baselines on heterophilous networks.\nMoreover, ARIEL, which is an adversarially trained variant of GRACE, performs worse than GRACE. This implies that adversarial training fails to preserve the feature similarity, and that the feature similarity should be preserved when the given structural information is not helpful (as in heterophilous networks).\n% hile ~\\proposed~outperforms GRACE, ARIEL, which is an adversarially trained GRACE, performs worse lower accuracy. It shows the effectiveness of~\\proposed~in heterophilous scenario by preserving the feature similarity.\n% As we mentioned, the feature similarity information is important in real-world graph such as heterophilous networks, where the connected nodes have usually dissimilar properties, e.g. node features and labels, with each other. Since the property is similar with that of an attacked graph in Section \\ref{sec:4}. We herein consider heterophilous networks as a naturally poisoned graph in the real-world, and compare~\\proposed~with other baselines. Table \\ref{tab:hetero} shows the node classification performance on six heterophilious benchmark datasets. \n% We can see that~\\proposed~ surpasses the graph representation learning methods under heterophilous networks. While ~\\proposed~obtains the higher accuracy compared to GRACE, ARIEL, which is an adversarially trained GRACE, has lower accuracy. It shows the effectiveness of~\\proposed~in heterophilous scenario by preserving the feature similarity.\n% GNNs generally perform well on homophily graph because of their inherent assumption and learning mechanism. However in real world, there are non-homophilous graphs, called heterophily, such as dating relationship networks or predator-prey networks in ecology. \n% On such graphs, the methods only assuming homophily can not perform well. Recently, it is shown that an adversarial edge tend to be a heterophily edge, i.e. a link between nodes with different labels \\cite{heterophily-adv-attack}. That is, heterophily network can be seen as a naturally poisoned graph. \n\n\n\n\n\\smallskip\n\n% \\noindent \\textbf{Visualization of Representation Space.} \\@ We visualize the node representations of ARIEL and~\\proposed~via t-SNE \\cite{tsne} to intuitively see the effect of AT in the representation space. Fig. \\ref{fig:tsne} shows the node representations of ARIEL and~\\proposed~trained on a clean graph and a 25$\\%$ \\emph{metattack} graph. We observe that the representations of ARIEL are separable but widely distributed, resulting in vague class boundaries. \n% On the other hand, the representations of~\\proposed~are tightly grouped together, resulting in more separable class boundaries.\n% We attribute such a difference to the AT of ARIEL that incurs a loss of node feature information, which is preserved in~\\proposed.\n% % It is in contrast to the representations of \\proposed, which has more separable class boundaries and tightly grouped together. \n% % We argue that this phenomenon appears due to the loss of feature information by AT. By simply preserving the feature information, the representation space of~\\proposed~is much refined than that of ARIEL. \n% Furthermore, the vague class boundaries of ARIEL explain the poor performance of ARIEL in the node clustering task shown in \n% % support the degeneration of ARIEL in node clustering performance in \n% Fig. \\ref{fig:link_cluster_low_high_degree}(c). \n\n% \\begin{figure}[h]\n% \\vspace{-2ex}\n%   \\includegraphics[width=0.95\\linewidth]{figures/tsne_1x4.pdf}\n%   \\vspace{-2ex}\n%   \\caption{t-SNE visualization of nodes in Citeseer dataset.}\n%   \\label{fig:tsne}\n% \\vspace{-3ex}\n% \\end{figure}\n\n\n\n% \\begin{figure}[t]\n%   \\includegraphics[width=0.6\\linewidth]{figures/tsne.pdf}\n%   \\vspace{-2ex}\n%   \\caption{t-SNE visualization of nodes in Citeseer dataset.}\n%   \\label{fig:tsne}\n% \\vspace{-3.5ex}\n% \\end{figure}\n\n% \\vspace{-3.5ex}\n"
                },
                "subsection 6.5": {
                    "name": "Ablation Study",
                    "content": "\n\\label{sec:ablation}\n% SP and Feat. Ptb represents the existence of similarity-preserving view and the type of feature perturbation, respectively.\nTo evaluate the importance of each component of~\\proposed, i.e., similarity-preserving view (\\textit{SP}), and the feature perturbation in adversarial view generation (\\textit{Feat. Ptb}), we incrementally add them to a baseline model, which is GRACE~\\cite{grace} with structural perturbations described in Section \\ref{sec:adv_view}.1.\n% GRACE that is adversarilly trained with structurally attacked graphs.\nAs for the adversarial view generation, we compare our proposed feature masking strategy with the feature flipping strategy~\\cite{grv,ariel}.\nWe have the following observations in Table \\ref{tab:ablation}.\n% For feature masking, we compare it with feature flip (i.e., changes the features both from 0 to 1 and from 1 to 0).  \n\\textbf{1) } Adding the similarity-preserving view is helpful, especially under severe structural perturbations, which demonstrates the benefit of preserving the node feature similarity in achieving adversarial robustness against graph structural attacks.\n\\textbf{2) } When considering the adversarial view, adding the feature masking component is helpful in general, which again demonstrates the importance of exploiting the node feature information.\n\\textbf{3) } Comparing the strategies for the feature perturbations, our proposed masking strategy outperforms the flipping strategy, even though the masking strategy requires less computations. We attribute this to the fact that the feature flip greatly alters the co-occurrence/correlation statistics of node features, which incurs an adverse effect on the AT by making the clean view and the adversarial view too distant from each other.\n% we observe that adding feature masking to adversarial view improves the accuracy given the poisoned structure, moreover adding similarity-preserving view also does.\n% \\textcolor{blue}{we observe that adding feature masking to adversarial view improves the accuracy given the poisoned structure, moreover adding similarity-preserving view also does.}\n% both similarity-preserving view and the adversarial view with the feature masking improves the accuracy given the perturbed graph. \n% It implies that the similarity-preserving view and the adversarial feature masking technique are effective to exploit the feature information in the attacked graph.\n% Furthermore, employing the adversarial feature masking performs better than using feature flip, which supports our argument \\textcolor{blue}{that feature flip is not helpful for AT since it alters the co-occurrence/correlation statistics of node features greatly.}\n\n% (i.e., flipping the node features makes the adversarial view too distant from the clean view since it may alter the co-occurrence/correlation statistics of node features)\n\n% To evaluate the importance of each component, we incrementally add one component to the adversarially trained GRACE as shown in Table \\ref{tab:ablation}. We train the baseline model by performing the adversarial training to GRACE \\cite{grace} with an adversarial view, where the adversarial view contains structural attacks by \\cite{clga} and feature perturbations. For feature perturbations, we compare FGSM, feature flip, and feature masking, denoted as FG, FF, and FM in Table \\ref{tab:ablation}, respectively. \n\n% To evaluate the importance of each component, we incrementally add one component to the adversarially trained GRACE as shown in Table \\ref{tab:ablation}. We train the baseline model by performing the adversarial training to GRACE \\cite{grace} with an adversarial view, where the adversarial view contains structural attacks by \\cite{clga} and feature perturbations. For feature perturbations, we compare FGSM, feature flip, and feature masking, denoted as FG, FF, and FM in Table \\ref{tab:ablation}, respectively. \n\n\n\n\n\n% \\begin{figure}[t]\n%     \\centering\n%     \\vspace{1ex}  \n%     \\includegraphics[width=0.99\\linewidth]{figures/sensitivity.pdf}\n%     \\vspace{-2ex}\n%     \\caption{Sensitivity analysis on edge perturbation and feature masking rates. \\textcolor{burntumber}{Red}-white-\\textcolor{airforceblue}{blue} means outperformance, on-par, and underperformance compared with GRACE.}\n%     \\label{fig:sensitivity}\n%     \\vspace{-3ex}\n% \\end{figure}\n\n\n"
                },
                "subsection 6.6": {
                    "name": "Complexity Analyses",
                    "content": "\n\n% \\noindent \\textbf{Parameter Sensitivity.} \\@ We analyze the sensitivity of the hyperparameters for generating the adversarial view (i.e., the edge perturbation and feature masking ratio). In Fig. \\ref{fig:sensitivity}, we report the node classification accuracy while varying these two hyperparameters on attacked Cora and Citeseer datasets. We observe that~\\proposed~is not sensitive to the hyperparameters, consistently outperforming GRACE regardless of their values.\n% \\smallskip\n\n\n\n\n\n\\noindent \\textbf{Analysis on Computational Efficiency} \\@\nWe compare the training time and the attacked view generation time of ARIEL, and \\proposed~ on Co.Physics dataset. For a fair comparison, ARIEL and \\proposed~utilize the same size of subgraphs during training. In Table~\\ref{tab:converge} and Fig.~\\ref{fig:converge}, we observe that \\proposed~is faster than ARIEL in terms of both the training and the view generation. This implies that our proposed adversarial view generation is scalable compared with the PGD attack \\cite{ijacai-19-pgd-topology-attack-defense} used in ARIEL, which creates an adversarial view through repeated iterations and complex optimization. In addition to the fast model training, Fig. \\ref{fig:converge} shows that \\proposed~ converges faster than ARIEL. As a result, \\proposed~is proven to be the most efficient and effective method.\n\n\n\n\n\n\n\n\n\n\\begin{minipage}{.6\\columnwidth}\n\\centering\n\\small\n\\captionof{table}{Averaged running time of 100 duration  over 4000 epochs on Co.Physics dataset.}\n\\label{tab:converge}\n\\scalebox{0.87}{\n\\renewcommand{\\arraystretch}{0.9}\n\\begin{tabular}{c|cc}\n\\noalign{\\smallskip}\\noalign{\\smallskip}\\hline\n &  ARIEL & \\proposed  \\\\\n\\hline\nTime (s) / 100 attacks & 7.5 & \\textbf{1.8} \\\\\nTime (s) / 100 epochs & 12  & \\textbf{7.2} \\\\\n\\hline\n\\end{tabular}\n}\n\\end{minipage}\n\\hfill%\n\\begin{minipage}{.38\\linewidth}\n\\vspace{-2ex}\n\\begin{figure}[H]\n\\centering\n\\includegraphics[width=.80\\linewidth]{figures/converge.pdf}\n\\end{figure}\n\\vspace{-5ex}  \n\\captionof{figure}{Valid. Acc. of node classification on Co.Physics dataset.}\n\\vspace{-2ex}  \n\\label{fig:converge}\n\n\\end{minipage}\n\n\n\n\n\n\n\n% \\begin{figure}[h]\n%   \\includegraphics[width=0.99\\linewidth]{figures/few.pdf}\n%   \\vspace{-1ex}\n%   \\caption{Node classification results with few label.}\n%   \\label{fig:few}\n% \\vspace{-1ex}\n% \\end{figure}\n\n% \\begin{figure}[h]\n%   \\includegraphics[width=0.99\\linewidth]{figures/ablation.pdf}\n%   \\vspace{-1ex}\n%   \\caption{Ablation Study.}\n%   \\label{fig:ablation}\n% \\vspace{-1ex}\n% \\end{figure}\n\n\n\n\n\n\n\n% \\begin{table}\n%     \\centering\n%     \\scalebox{0.8}{\n%     \\begin{tabular}{cc|ccc|ccc}\n%         \\hline\n%         \\multicolumn{2}{c|}{Module} & \\multicolumn{3}{c}{Cora} & \\multicolumn{3}{c}{CiteSeer}  \\\\\n%         \\hline\n%         SP & FM & 0\\% & 15\\% & 25\\% & 0\\% & 15\\% & 25\\% \\\\\n%         \\hline\n%          \\ding{55} & \\ding{55} & 82.9±1.1 & 64.8±1 & 50.6±1 & 70.6±1.1 & 63.3±1.4 & 55.3±2.4\\\\\n%         \\ding{51} & \\ding{55}  & 83.8±0.9 & 68.4±1.2 & 56.4±1.5 & 74.5±0.5 & 68.1±1.3 & 64.9±1 \\\\\n%          \\ding{55} & \\ding{51} & \\textbf{84±1} & 68.8±1.3 & 51±0.7  & 74.4±1 & 70±1.6 & 64.1±0.8\\\\\n%         \\midrule\n%         \\ding{51} & \\ding{51} & 83.9±0.7 & \\textbf{72.3±1.1} &  \\textbf{56.9±0.9} & \\textbf{75.9±0.4} & \\textbf{72.5±1.1} & \\textbf{67.9±0.7}\\\\\n%         \\hline\n%     \\end{tabular}}\n%     \\caption{Ablation Study}\n%     \\label{tab:ablation}\n% \\end{table}\n\n% \\begin{table}\n%     \\centering\n%     \\scalebox{0.8}{\n%     \\begin{tabular}{cc|ccc|ccc}\n%         \\hline\n%         \\multicolumn{2}{c|}{Module} & \\multicolumn{3}{c}{Cora} & \\multicolumn{3}{c}{CiteSeer}  \\\\\n%         \\hline\n%         SP & FP & 0\\% & 15\\% & 25\\% & 0\\% & 15\\% & 25\\% \\\\\n%         \\hline\n%         \\multicolumn{2}{c|}{GRACE} & 82.1±1 & 66.1±1.6 & 51.3±2 & 74.9±0.6 & 71.2±1.3 & 61.2±1.5 \\\\\n%          \\ding{55} & \\ding{55} & 82.9±1.1 & 64.8±1 & 50.6±1 & 70.6±1.1 & 63.3±1.4 & 55.3±2.4\\\\\n%          \\ding{55} & FC  & \\textbf{85.1±0.7} & 65.4±0.7 & 48.7±1.6 & 75.3±0.5 & 67.6±1 & 57.9±1.1 \\\\\n%          \\ding{55} & FF  & 83.4±0.7 & 60.5±1.5 & 48±1.3 & 72.5±1.1 & 63.8±1.3 & 52.6±1.9 \\\\\n%          \\ding{55} & FM  & 82.4±1 & \\textbf{68.3±1.9 & 51.5±3.4} & 74.8±0.8 & 71.6±1.2 &\t64.8±1.7\\\\\n%          \\midrule\n%          \\ding{51} & \\ding{55} & 83.8±0.9 & 68.4±1.2 & 56.4±1.5 & 74.5±0.5 & 68.1±1.3 & 64.9±1.1\\\\\n%         \\ding{51} & FM & 83.9±0.7 & \\textbf{72.3±1.1} &  \\textbf{56.9±0.9} & \\textbf{75.9±0.4} & \\textbf{72.5±1.1} & \\textbf{67.9±0.7}\\\\\n%         \\hline\n%     \\end{tabular}}\n%     \\caption{Ablation Study}\n%     \\label{tab:ablation}\n% \\end{table}\n\n\n\n% \\begin{table}[h]\n%     \\centering\n%     \\begin{minipage}{0.9\\linewidth}{\n\n%     \\renewcommand{\\arraystretch}{0.9}\n%     \\begin{tabular}{cc|ccc|ccc}\n%         \\centering\n%         \\hline\n%         \\multicolumn{2}{c|}{Module} & \\multicolumn{3}{c}{Cora} & \\multicolumn{3}{c}{CiteSeer}  \\\\\n%         \\hline\n%         SP & FM & 0\\% & 15\\% & 25\\% & 0\\% & 15\\% & 25\\% \\\\\n%         \\hline\n%          \\ding{55} & \\ding{55} & 82.9±1.1 & 64.8±1 & 50.6±1 & 70.6±1.1 & 63.3±1.4 & 55.3±2.4\\\\\n%         \\ding{51} & \\ding{55}  & 83.8±0.9 & 68.4±1.2 & 56.4±1.5 & 74.5±0.5 & 68.1±1.3 & 64.9±1 \\\\\n%          \\ding{55} & \\ding{51} & \\textbf{84±1} & 68.8±1.3 & 51±0.7  & 74.4±1 & 70±1.6 & 64.1±0.8\\\\\n%         \\midrule\n%         \\ding{51} & \\ding{51} & 83.9±0.7 & \\textbf{72.3±1.1} &  \\textbf{56.9±0.9} & \\textbf{75.9±0.4} & \\textbf{72.5±1.1} & \\textbf{67.9±0.7}\\\\\n%         \\hline\n%         \\caption{Ablation Study}\n%         \\label{tab:ablation}\n%     \\end{tabular}\n%     \\label{tab:computation}}\n%     \\end{minipage}\n%     \\captionof{table}{Running time (in seconds) averaged over 1000 epochs on Co.Physics dataset.}\n\n% \\end{table}\n\n\n% \\begin{table}[h]\n% \\scalebox{1.1}{\n%     \\begin{tabular}{cc|ccc|ccc}\n%     \\centering\n%     \\hline\n%     \\multicolumn{2}{c|}{Module} & \\multicolumn{3}{c}{Cora} & \\multicolumn{3}{c}{CiteSeer}  \\\\\n%     \\hline\n%     SP & FM & 0\\% & 15\\% & 25\\% & 0\\% & 15\\% & 25\\% \\\\\n%     \\hline\n%      \\ding{55} & \\ding{55} & 82.9±1.1 & 64.8±1 & 50.6±1 & 70.6±1.1 & 63.3±1.4 & 55.3±2.4\\\\\n%     \\ding{51} & \\ding{55}  & 83.8±0.9 & 68.4±1.2 & 56.4±1.5 & 74.5±0.5 & 68.1±1.3 & 64.9±1 \\\\\n%      \\ding{55} & \\ding{51} & \\textbf{84±1} & 68.8±1.3 & 51±0.7  & 74.4±1 & 70±1.6 & 64.1±0.8\\\\\n%     \\midrule\n%     \\ding{51} & \\ding{51} & 83.9±0.7 & \\textbf{72.3±1.1} &  \\textbf{56.9±0.9} & \\textbf{75.9±0.4} & \\textbf{72.5±1.1} & \\textbf{67.9±0.7}\\\\\n%     \\hline\n%     \\caption{Ablation Study}\n%     \\label{tab:ablation}\n%     \\end{tabular}}\n% \\end{table}\n\n\n\n\n% \\begin{table}[h]{cccc|ccc|ccc}\n%     \\centering\n%     \\hline\n%     \\multicolumn{2}{c|}{Module} & \\multicolumn{3}{c}{Cora} & \\multicolumn{3}{c}{CiteSeer}  \\\\\n%     \\hline\n%     EF & FC & FF & FM & 0\\% & 15\\% & 25\\% & 0\\% & 15\\% & 25\\% \\\\\n%     \\hline\n%      \\ding{55} \\ding{55} & & \\ding{55} & \\ding{55} & 82.1±1   & 66.1±1.6 & 51.3±2   & 74.9±0.6 & 71.2±1.3 & 61.2±1.5 \\\\\n%      \\ding{51} \\ding{51} & & \\ding{55} & \\ding{55} & 85.1±0.7 & 65.4±0.7 & 48.7±1.6 & 75.3±0.5 & 67.6±1   & 57.9±1.1 \\\\\n%     \\ding{51} & \\ding{55} & \\ding{51} & \\ding{55}  & 83.4±0.7 & 60.5±1.5 & 48±1.3   & 72.5±1.1 & 63.8±1.3 & 52.6±1.9 \\\\\n%     \\midrule\n%     \\ding{51} & \\ding{55} & \\ding{55} & \\ding{51} & 82.4±1   & 68.3±1.9 & 51.5±3.4 & 74.8±0.8 & 71.6±1.2 & 64.8±1.7\\\\\n%     \\hline\n%     \\caption{Ablation Study}\n%     \\label{tab:ablation}\n% \\end{table}\n\n\n% \\begin{table}\n%     \\centering\n%     \\scalebox{0.7}{\n%     \\begin{tabular}{cccc|ccc|ccc}\n%         \\hline\n%         \\multicolumn{4}{c|}{Module} & \\multicolumn{3}{c}{Cora} & \\multicolumn{3}{c}{CiteSeer}  \\\\\n%         \\hline\n%         EF & FC & FF & FM & 0\\% & 15\\% & 25\\% & 0\\% & 15\\% & 25\\% \\\\\n%         \\hline\n%          \\ding{55} & \\ding{55} & \\ding{55} & \\ding{55} & 82.1±1   & 66.1±1.6 & 51.3±2   & \\textbf{74.9±0.6} & 71.2±1.3 & 61.2±1.5 \\\\\n%      \\ding{51} & \\ding{51} & \\ding{55} & \\ding{55} & \\textbf{85.1±0.7} & 65.4±0.7 & 48.7±1.6 & 75.3±0.5 & 67.6±1   & 57.9±1.1 \\\\\n%     \\ding{51} & \\ding{55} & \\ding{51} & \\ding{55}  & 83.4±0.7 & 60.5±1.5 & 48±1.3   & 72.5±1.1 & 63.8±1.3 & 52.6±1.9 \\\\\n%     \\midrule\n%     \\ding{51} & \\ding{55} & \\ding{55} & \\ding{51} & 82.4±1   & \\textbf{68.3±1.9 }& \\textbf{51.5±3.4} & 74.8±0.8 &\\textbf{ 71.6±1.2} &\\textbf{64.8±1.7}\\\\\n%         \\hline\n%     \\end{tabular}}\n%     \\caption{Ablation Study}\n%     \\label{tab:ablation_2}\n% \\end{table}\n\n\n\n\n% \\begin{figure*}[t]\n\n% \\centering\n\n\n% \\begin{minipage}{0.4\\linewidth}{\n% \\centering\n% \\vspace{-2ex}\n\n% \\includegraphics[width=0.99\\linewidth]{figures/sensitivity.pdf}\n% \\caption{Sensitivity analysis on edge perturbation and feature masking rates: Red-white-blue means outperformance, at-par, and underperformance compared to GRACE.}\n% \\label{fig:sensitivity}\n\n% \\vspace{-1ex}}\n% \\end{minipage}\n% \\hfill\n% \\begin{minipage}{0.58\\linewidth}{\n% \\centering\n% \\vspace{-2ex}\n\n% \\begin{tabular}[t]{cc|ccc|ccc}\n% \\hline\n% \\multicolumn{2}{c|}{Module} & \\multicolumn{3}{c}{Cora} & \\multicolumn{3}{c}{CiteSeer}  \\\\\n% \\hline\n% SP & FM & 0\\% & 15\\% & 25\\% & 0\\% & 15\\% & 25\\% \\\\\n% \\hline\n%  \\ding{55} & \\ding{55} & 82.9±1.1 & 64.8±1 & 50.6±1 & 70.6±1.1 & 63.3±1.4 & 55.3±2.4\\\\\n% \\ding{51} & \\ding{55}  & 83.8±0.9 & 68.4±1.2 & 56.4±1.5 & 74.5±0.5 & 68.1±1.3 & 64.9±1 \\\\\n%  \\ding{55} & \\ding{51} & \\textbf{84±1} & 68.8±1.3 & 51±0.7  & 74.4±1 & 70±1.6 & 64.1±0.8\\\\\n% \\midrule\n% \\ding{51} & \\ding{51} & 83.9±0.7 & \\textbf{72.3±1.1} &  \\textbf{56.9±0.9} & \\textbf{75.9±0.4} & \\textbf{72.5±1.1} & \\textbf{67.9±0.7}\\\\\n% \\hline\n% \\end{tabular}\n% \\caption{Ablation Study}\n% \\label{tab:ablation}\n% \\vspace{-1ex}}\n% \\end{minipage}\n% \\end{figure*}\n\n\n\n"
                }
            },
            "section 7": {
                "name": "Conclusions",
                "content": "\nIn this paper, we discover that adversarial GCL models obtain robustness against adversarial attacks at the expense of not being able to preserve the node feature similarity information through theoretical and empirical studies. Based on our findings, we propose~\\proposed~that learns robust node representations that preserve the node feature similarity by introducing the similarity-preserving view. Moreover, the proposed adversarial feature masking exploits more feature information.\n% \\textcolor{red}{TODO: remarks on feature masking technique}\n% causes the problem that reduces the node similarity information in the node representations, while it obtains robustness against to the graph attack. \n% To alleviate the loss of feature information, we introduce~\\proposed~that learns robust representations and preserves the node feature similarity simultaneously. Based on the similarity-preserving view, adversarial view, and optimizing the cross-view contrastive objective, ~\\proposed~can exploit both the structural and feature information. \nWe verify the effectiveness of~\\proposed~by conducting extensive experiments on thirteen benchmark datasets with multiple attacking scenarios along with several real-world scenarios such as networks with noisy labels and heterophily.\n\n\n"
            },
            "section 8": {
                "name": "Acknowledgements",
                "content": "\n\nThis work was supported by Institute of Information \\& communications Technology Planning \\& Evaluation (IITP) grant funded by the Korea government(MSIT) (No.2022-0-00157 and No.2022-0-00077).\n\n\n\\bibliographystyle{ACM-Reference-Format}\n\\balance\n\\bibliography{refer.bib}\n\n\n\\appendix\n\n\\clearpage\n\n"
            },
            "section 9": {
                "name": "Overall Framework of~\\proposed",
                "content": "\n\\label{app-sec:overall_framework}\n\n\n\n"
            },
            "section 10": {
                "name": "Datasets.",
                "content": "\n\\label{app-sec:dataset}\nWe evaluate~\\proposed~and baselines on \\textbf{thirteen} benchmark datasets, including three citation networks \\cite{metattack, nettack}, two co-purchase networks \\cite{shchur2018pitfalls}, two co-authorship networks \\cite{shchur2018pitfalls}, and six heterophilous networks \\cite{geomgcn}. The statistics of the datasets are shown in Table. \\ref{tab:dataset}.\n\n\n\n\n"
            },
            "section 11": {
                "name": "Details on Experimental Settings.",
                "content": "\n\n",
                "subsection 11.1": {
                    "name": "Baselines.",
                    "content": "\n\\label{app-sec:baseline}\n\nThe baselines include the state-of-the-art unsupervised graph representation learning methods (i.e., GRACE, GCA, BGRL) and defense methods (i.e., DGI-ADV, ARIEL) that adopt adversarial training (AT). \n\n\\begin{itemize}\n    \\item \\noindent\\textbf{GRACE} \\cite{grace} \\@ is an augmentation-based GCL model that pulls the representations of two semantically similar nodes and pushes that of two semantically different nodes.\n\n    \\item \\noindent\\textbf{GCA} \\cite{gca} \\@ is a more advanced method of GRACE that employs various augmentation strategies.\n\n    \\item \\noindent\\textbf{BGRL} \\cite{bgrl} is the state-of-the-art graph representation learning method that minimizes the distance of two node representations from different augmentations without negative samples.\n\n    \\item \\noindent\\textbf{DGI-ADV} \\cite{grv} is trained by alternatively optimizing DGI \\cite{dgi} and AT objective based on the vulnerability of the graph representation.\n    \n    \\item \\noindent\\textbf{ARIEL} \\cite{ariel} is the state-of-the-art adversarial GCL model that adopts AT to GRACE framework with an information regularizer for stabilizing the model training.\n\n    \n\\end{itemize}\n\n"
                },
                "subsection 11.2": {
                    "name": "Implementation Details",
                    "content": "\n\\label{app-sec:imp_detail}\nFor each experiment, we report the average performance of 10 runs with standard deviations. For GRACE, GCA, BGRL, and ARIEL, we use the best hyperparameter settings presented in their papers. For DGI-ADV, we use the default hyperparameter settings in its implementation.\n\nFor \\proposed, we tune the learning rate and weight decay from \\{0.05, 0.01, 0.005, 0.001\\} and \\{0.01, 0.001, 0.0001, 0.00001\\}, respectively. For generating two augmented views, we tune drop edge/feature rates from \\{0.1, 0.2, 0.3, 0.4, 0.5\\}. For generating the adversarial view, we tune edge perturbation budget $\\Delta_{\\mathbf{A}}$ and feature masking ratio  $\\Delta_{\\mathbf{X}}$ from \\{0.1, 0.3, 0.5, 0.7, 0.9\\} and \\{0.0, 0.1, 0.3, 0.5, 0.7, 0.9\\}, respectively. For generating the similarity-preserving view, we tune $k$ of $k$NN graph from \\{5, 10\\}. Moreover, we tune the combination coefficient $\\lambda_1$ and $\\lambda_2$ from \\{0.1, 0.5, 1,2,3,4,5\\}.\n\n\n\n"
                }
            },
            "section 12": {
                "name": "Additional Experimental Results.",
                "content": "\n\nIn this section, we conduct three additional experiments to analyze the sensitivity of~\\proposed~to the hyperparameters including 1) the perturbation budgets of the graph structure and node features $\\Delta_{\\mathbf{A}}$, $\\Delta_{\\mathbf{X}}$, 2) the coefficients of objective $\\lambda_1$, $\\lambda_2$, and 3) $k$ value of the $k$NN algorithm in similarity-preserving view generation.\n\n\n\\vspace{-2ex}\n",
                "subsection 12.1": {
                    "name": "X",
                    "content": "\n\\label{sec:b3}\n\\looseness=-1\nWe analyze the sensitivity of the perturbation budgets for generating the adversarial view. Specifically, we change the edge perturbation ratio $\\Delta_{\\mathbf{A}}$ and the feature masking ratio $\\Delta_{\\mathbf{X}}$ from 0.1 to 0.9 to confirm that the performance of~\\proposed~is insensitive to the perturbation ratio as AT is performed. In Figure \\ref{fig:sensitivity_ptb_bdgt}, we observe that the performance of~\\proposed~is consistently better than that of ARIEL in terms of the accuracy on attacked Cora and Citeseer datasets. This implies that~\\proposed~is not sensitive to the perturbation budgets, showing that both perturbing the graph structure and masking the feature are helpful for enhancing the robustness of~\\proposed.\n\n\n\n"
                },
                "subsection 12.2": {
                    "name": "Sensitivity analysis on $\\lambda_1$ and $\\lambda_2$.",
                    "content": "\n\nWe analyze the sensitivity of the coefficients of the training objective $\\lambda_1$ and $\\lambda_2$ in Eqn (6) of the main paper. Note that $\\lambda_1$ determines the importance of the adversarial view, while $\\lambda_2$ determines the importance of the similarity-preserving view.  We conduct a grid search for the two hyperparameters with the values in $\\{0.1, 0.5, 1, 2, 3, 4, 5\\}$. In Figure \\ref{fig:sensitivity_labmda}, we observe that \\proposed~generally outperforms ARIEL in terms of the accuracy on attacked Cora and Citeseer datasets, showing that ~\\proposed~is not senstivie to the selection of $\\lambda_1$ and $\\lambda_2$. However, when $\\lambda_2$ is relatively small (i.e., $\\lambda_2=0.1,0.5$), ~\\proposed~shows comparable or worse performance than ARIEL. In other words, ~\\proposed~becomes more robust when the similarity-preserving view plays more significant role in the learning objective (i.e., when $\\lambda_2$ is large). This implies that the similarity-preserving view is important for achieving robustness of~\\proposed.\n\n\n\n\n\n% \\vspace{-1ex}\n"
                },
                "subsection 12.3": {
                    "name": "Sensitivity analysis on $k$NN.",
                    "content": "\nWe analyze the sensitivity of~\\proposed~over the number of nearest neighbors (i.e., $k$ value of $k$NN) for generating the similarity-preserving view. To be specific, we increase the value of $k$ from 10 to 50 (i.e., \\{10,15,30,50\\}), and evaluate the accuracy of~\\proposed~and ARIEL. In Figure \\ref{fig:sensitivity_k}, we observe that the performance of~\\proposed~is not only insensitive to $k$ value, but also greatly outperforms ARIEL regardless of the value of $k$ in terms of the accuracy on attacked Cora and Citeseer datasets. Moreover, this implies that employing the node feature similarity is helpful for learning robust representations of GCL models regardless of the $k$ values.\n\n\n\n\n% \\vspace{-4ex}\n"
                }
            },
            "section 13": {
                "name": "eq:diff",
                "content": "\n\\label{eqn:proof}\nWe provide the detailed derivations of Eqn. (\\ref{eq:diff}). Note that the representation $\\mathbf{z}_i$ after 1 layer GCN is applied can be computed as follow: $\\mathbf{z}_i=\\sum_{j\\in\\mathcal{N}_{\\mathbf{A}}^i\\cup\\ \\{i\\}}\\frac{\\mathbf{W}x_j}{\\sqrt{|\\mathcal{N}_{\\mathbf{A}}^i|}{\\sqrt{|\\mathcal{N}_{\\mathbf{A}}^j|}}}$ where $\\mathbf{x}_j$ is the input feature for node $j$, $\\mathcal{N}_{\\mathbf{A}}^i$ is the neighbor set of node $i$ give the adjacency matrix $\\mathbf{A}$, and $|\\cdot|$ counts the number of element in a given set. Then, the difference between the clean representation and attacked representation is given as follows:\n{\\small\n\\begin{align*}\n    & \\mathbf{z}_i^2 - {\\mathbf{z}_i^{\\text{atk}}} = (\\mathbf{z}_i^2 - \\mathbf{z}_i^1) + (\\mathbf{z}_i^1 -{\\mathbf{z}_i^{\\text{atk}}}) \\nonumber \\\\ \n    &= \\mathbf{e}_i \\!+ \\!\\!\\!\\!\\!\\sum_{j\\in\\mathcal{N}_{\\mathbf{A}^1}^i\\cup \\{i\\}} \\frac{{\\mathbf{W}\\mathbf{x}_j}}{\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1}^i|}\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1}^j|}} - \\!\\!\\!\\!\\!\\sum_{j\\in  \\mathcal{N}_{\\mathbf{A}^1+\\delta_{\\mathbf{A}}}^i \\!\\!\\!\\cup \\{i\\}} \\frac{{\\mathbf{W}\\mathbf{x}_j}}{\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1+\\delta_{\\mathbf{A}}}^i|}\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1+\\delta_{A}}^j|}} \\nonumber \\\\\n    &= \\mathbf{e}_i \\!+ \\!\\!\\!\\!\\!\\sum_{j\\in\\mathcal{N}_{\\mathbf{A}^1}^i\\cup \\{i\\}} \\frac{{\\mathbf{W}\\mathbf{x}_j}}{\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1}^i|}\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1}^j|}} \\\\\n    & - \\left(\\sum_{j\\in  \\mathcal{N}_{\\mathbf{A}^1}^i \\!\\!\\!\\cup \\{i\\}} \\frac{{\\mathbf{W}\\mathbf{x}_j}}{\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1}^i|+1}\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1}^j|}} + \\frac{\\mathbf{W}\\mathbf{x}_k}{\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1}^i|+1}\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1}^k|+1}}\\right) \\nonumber \\\\\n    &= \\mathbf{e}_i +  \\sum_{j\\in\\mathcal{N}_{\\mathbf{A}^1}^i\\cup \\{i\\}} \\frac{\\mathbf{W}\\mathbf{x}_j}{\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1}^j|}} \\left( \\frac{\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1}^i|+1}-\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1}^i|}}{\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1}^i|}\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1}^i|+1}}\\right) \n    - \\frac{\\mathbf{W}\\mathbf{x}_k}{\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1}^i|+1}\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1}^k|+1}}\\\\\n    &= \\mathbf{e}_i + \\frac{1}{\\underbrace{\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1}^i|+1}}_{\\text{Degree term}}} \\underbrace{\\left(\\sum_{j\\in\\mathcal{N}_{\\mathbf{A}^1}^i\\cup \\{i\\}} \\frac{\\alpha{\\mathbf{W}\\mathbf{x}_j}}{\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1}^i|}\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1}^j|}} - \\frac{\\mathbf{W}{\\mathbf{x}_k}}{\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1}^k|+1}}\\right)}_{\\text{Feature difference term}}\n    \\label{eq:diff}\n\\end{align*}\n}%\n\n\n\n\n% \\bibliography{refer.bib}\n\\citestyle{acmauthoryear}\n\n"
            }
        },
        "tables": {
            "tab:main_table": "\\begin{table*}[t!]\n% \\small\n% \\centering\n\\caption{Node classification accuracy under non-targeted attack (\\emph{metattack}). (OOM: Out of Memory on 24GB RTX3090).}\n\\vspace{-2ex}\n\\renewcommand{\\arraystretch}{1}\n\\begin{center}\n{\\scriptsize\n\\scalebox{0.85}{%\n\\begin{tabular}{c|l|c|ccccc|ccccc}\n    \\toprule\n    \\multirow{1}{*}{} & \\multirow{1}{*}{Methods}& {} & \\multicolumn{5}{c}{Poisoning (Acc.)} & \\multicolumn{5}{c}{Evasive (Acc.)} \\\\\n    \\hline\n    {Datasets}&{Ptb rate}&{Clean}&{5\\%}& 10\\% & 15\\% & 20\\% & 25\\% & 5\\% & 10\\% & 15\\% & 20\\% & 25\\% \\\\\n    \\midrule\n    %\\hline\n    \\multirow{5}{*}{Cora} & GRACE-MLP & 63.2±1.7 & 63.2±1.7 & 63.2±1.7 & 63.2±1.7 & 63.2±1.7 & 63.2±1.7 & 63.2±1.7 & 63.2±1.7 & 63.2±1.7 & 63.2±1.7 & 63.2±1.7 \\\\ \n    & GRACE   \n    & 82.1±1.0            & 78.4±1.5          & 75.5±1.1          & 66.1±1.6          & 55.2±1.8          & 51.3±2.0            & 78.9±0.9          & 75.7±0.9          & 67.6±1.3          & 56.5±2.3          & 51.5±1.8   \\\\\n    & GCA     \n    & 81.5±0.9          & 79.8±0.8          & 75.8±0.6          & 68.4±1.6          & 53.4±1.7          & 49.5±1.3          & 79.7±1.0            & 76.0±1.1            & 68.0±1.1            & 54.7±1.2          & 49.8±1.3       \\\\\n    & BGRL   \n    & 82.7±1.0            & 78.2±2.1          & 74.3±1.8          & 66.2±1.9          & 53.8±1.7          & 50.2±2.3          & 79.2±1.6          & 75.2±1.5          & 67.2±2.0            & 55.2±1.7          & 51.2±1.7    \\\\\n    & DGI-ADV \n    & 83.7±0.7          & 79.4±0.9          & 73.3±0.6          & 63.5±0.6          & 52.2±0.7          & 48.1±0.7          & 79.4±0.9          & 73.7±0.8          & 62.9±0.9          & 53.0±1.0              & 49.2±1.2          \\\\\n    & ARIEL   \n    & 80.9±0.5          & 79.2±0.4          & 77.7±0.6          & 69.8±0.7          & 57.7±0.7          & 52.8±1.0            & 79.1±0.3          & 77.8±0.6          & 70.3±0.9          & 58.0±1.0              & 53.2±1.2          \\\\\n    \\hline\n    \n    & \\proposed \n    & \\textbf{83.9±0.7} & \\textbf{82.2±0.8} & \\textbf{79.0±0.6} & \\textbf{73.25±0.5} & \\textbf{66.2±2.3} & \\textbf{65.0±1.5} & \\textbf{82.0±0.6}   & \\textbf{78.7±1.2} & \\textbf{73.5±2.8} & \\textbf{61.5±5.0}   & \\textbf{57.1±5.5} \\\\\n    \n    \\midrule\n    \\multirow{5}{*}{Citeseer} \n    & GRACE-MLP & 68.0±1.2 & 68.0±1.2 & 68.0±1.2 & 68.0±1.2 & 68.0±1.2 & 68.0±1.2 & 68.0±1.2 & 68.0±1.2 & 68.0±1.2 & 68.0±1.2 & 68.0±1.2    \\\\\n    & GRACE \n    & 74.9{±0.6}          & 74.1{±0.6}          & 72.5{±0.9}          & 71.2{±1.3}          & 59.2{±1.4}          & 61.2{±1.5}          & 74.0{±0.7}            & 72.4{±1.0}            & 70.4{±1.3}          & 59.1{±1.9}          & 62.3{±1.5}          \\\\\n    & GCA\n    & 74.2{±0.7}          & 73.5{±0.9}          & 73.0{±0.6}            & 71.5{±0.9}          & 60.2{±1.7}          & 60.1{±1.6}          & 73.8{±0.7}          & 73.4{±0.5}          & 72.0{±0.9}            & 59.5{±1.8}          & 61.5{±1.7}          \\\\\n    & BGRL    \n    & 73.4{±1.0}            & 72.1{±1.1}          & 69.1{±1.0}            & 67.5{±1.4}          & 57.7{±1.3}          & 58.2{±2.8}          & 72.5{±1.2}          & 69.7{±1.3}          & 68.1{±1.6}          & 58.5{±1.6}          & 60.3{±2.0}            \\\\\n    & DGI-ADV \n    & 76.6{±0.3}          & 74.8{±0.3}          & 71.0{±0.5}            & 70.1{±0.3}          & 57.9{±0.8}          & 60.6{±1.2}          & 74.8{±0.3}          & 71.3{±0.5}          & 69.7{±0.5}          & 56.1{±0.6}          & 57.4{±1.5}          \\\\\n    & ARIEL   \n    & \\textbf{76.7{±0.5}} & {75.2{±0.4}} & 72.8{±0.5}          & 70.2{±0.5}          & 60.1{±1.1}          & 62.7{±0.5}          & \\textbf{75.3{±0.4}} & 73.3{±0.5}          & 70.8{±0.4}          & 59.8{±0.8}          & 63.6{±1.0}            \\\\\n    \\hline\n    & \\proposed  \n    & 75.9{±0.4}          & \\textbf{75.3±0.5} & \\textbf{73.5±0.6} & \\textbf{72.1±1.1} & \\textbf{66.0±1.5} & \\textbf{69.6±0.9} & 75.0{±1.1}            & \\textbf{73.5{±1.0}}   & \\textbf{72.4{±1.1}} & \\textbf{60.6{±1.1}} & \\textbf{65.6{±0.9}} \\\\\n    \n    \\midrule\n    \\multirow{5}{*}{Pubmed} \n    & GRACE-MLP \n    &  82.4±0.2 & 82.4±0.2 & 82.4±0.2 & 82.4±0.2 & 82.4±0.2 & 82.4±0.2 & 82.4±0.2 & 82.4±0.2 & 82.4±0.2 & 82.4±0.2 & 82.4±0.2      \\\\ \n    & GRACE \n    & 85.9{±0.1}          & 81.3{±0.2}          & 78.2{±0.4}          & 76.1{±1.3}          & 73.9{±1.7}          & 71.3{±2.6}          & 80.7{±0.1}          & 76.8{±0.2}          & 73.5{±0.1}          & 71.4{±0.2}          & 69.0{±0.3}            \\\\\n    & GCA     \n    & \\textbf{86.5±{0.2}} & 81.2{±0.5}          & 78.1{±0.5}          & 75.9{±1.2}          & 74.2{±0.4}          & 72.0{±1.8}            & 80.7{±0.2}          & 76.7{±0.3}          & 73.2{±0.3}          & 70.9{±0.2}          & 68.6{±0.3}          \\\\\n    & BGRL    \n    & 85.1{±0.2}          & 81.3{±0.3}          & 79.0{±0.4}            & 76.6{±0.9}          & 74.8{±0.9}          & 73.0{±0.5}            & 80.6{±0.4}          & 77.5{±0.4}          & 74.5{±0.6}          & 72.4{±0.7}          & 70.3{±0.6}          \\\\\n    & DGI-ADV \n    & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               \\\\\n    & ARIEL   \n    & 81.2{±0.4}          & 77.8{±0.3}          & 75.8{±0.4}          & 74.0{±0.5}            & 72.3{±0.5}          & 70.7{±0.3}          & 77.8{±0.5}          & 75.9{±0.5}          & 74.1{±0.6}          & 72.3{±0.6}          & 70.8{±0.5}\\\\\n    \\hline              \n    & \\proposed  \n    & 85.5{±0.3}          & \\textbf{81.9{±0.2}} & \\textbf{80.2±0.1} & \\textbf{77.9±0.4} & \\textbf{76.5±0.1} & \\textbf{73.3±0.3} & \\textbf{81.9{±0.2}} & \\textbf{79.6{±0.3}} & \\textbf{77.1{±0.4}} & \\textbf{75.1{±0.5}} & \\textbf{72.8{±0.5}} \\\\\n    \n    \\midrule\n    \\multirow{5}{*}{Am.Photo} \n    & GRACE-MLP\n    & 87.2±0.8 & 87.2±0.8 & 87.2±0.8 & 87.2±0.8 & 87.2±0.8 & 87.2±0.8 & 87.2±0.8 & 87.2±0.8 & 87.2±0.8 & 87.2±0.8 & 87.2±0.8 \\\\\n    & GRACE\n    & 92.0{±0.4}          & 89.5{±0.5}          & 88.3{±1.1}          & 87.6{±0.9}          & 87.5{±1.2}          & 87.1{±1.2}          & 88.6{±0.4}          & 87.5{±0.8}          & 87.3{±0.8}          & 86.6{±1.0}          & 85.6{±1.1}          \\\\\n    & GCA     \n    & 92.2{±0.4}          & 89.4{±0.6}          & 88.3{±0.8}          & 87.8{±0.7}          & 87.6{±1.0}          & 87.5{±0.7}          & 88.7{±0.6}          & 88.0{±0.7}          & 87.8{±1.4}          & 87.3{±0.9}          & 86.4{±1.2}          \\\\\n    & BGRL    \n    & 92.1{±0.4}          & 89.2{±0.6}          & 88.7{±0.5}          & 88.8{±0.5}          & 89.0{±0.7}          & 89.2{±0.4}          & 89.4{±0.5}          & 88.3{±0.6}          & 88.2{±0.6}          & 87.6{±0.5}          & 87.3{±0.6}          \\\\\n    & DGI-ADV \n    & 91.6{±0.5}          & 83.5{±0.5}          & 80.7{±0.6}          & 79.3{±0.6}          & 78.1{±0.6}          & 77.3{±0.6}          & 83.6{±0.5}          & 80.8{±0.5}          & 79.5{±0.5}          & 78.0{±0.6}          & 77.4{±0.4}          \\\\\n    & ARIEL   \n    & 92.5{±0.2}          & 90.1{±0.4}          & 89.9{±0.5}          & 89.9±0.5          & 89.9{±0.5}          & \\textbf{89.8{±0.6}} & 89.7{±0.4}          & 89.1{±0.3}          & 88.6{±0.2}          & \\textbf{88.6{±0.4}} & \\textbf{88.4{±0.3}} \\\\\n    \\hline              \n    & \\proposed \n    & \\textbf{93.3{±0.3}} & \\textbf{91.4{±0.5}} & \\textbf{90.6{±0.6}} & \\textbf{90.5{±0.8}} & \\textbf{90.2{±0.9}} & \\textbf{89.8{±1.0}} & \\textbf{90.3{±0.4}} & \\textbf{89.3{±0.3}} & \\textbf{88.7{±0.5}} & 88.2{±0.7} & 87.6{±0.5}\\\\\n    \n    \\midrule\n    \\multirow{5}{*}{Am.Comp} \n    & GRACE-MLP\n    & 82.7±0.4 & 82.7±0.4 & 82.7±0.4 & 82.7±0.4 & 82.7±0.4 & 82.7±0.4 & 82.7±0.4 & 82.7±0.4 & 82.7±0.4 & 82.7±0.4 & 82.7±0.4          \\\\\n    & GRACE \n    & 86.4{±0.5}          & 83.7{±0.3}          & 82.5{±0.6}          & 81.3{±0.5}          & 80.3{±0.7}          & 78.8{±1.0}          & 84.0{±0.3}          & 83.6{±0.4}          & 82.8{±0.3}          & 82.0{±0.9}          & 81.7{±0.6}          \\\\\n    & GCA     \n    & 86.6{±0.4}          & 84.6{±0.4}          & 83.4{±0.3}          & 82.3{±0.4}          & 81.4{±0.4}          & 80.1{±0.5}          & 84.5{±0.3}          & 83.8{±0.4}          & 82.8{±0.2}          & 82.3{±0.8}          & 82.0{±0.4}          \\\\\n    & BGRL    \n    & 88.0{±0.4}          & 85.2{±0.6}          & 84.2{±0.6}          & 83.7{±0.6}          & 83.3{±0.7}          & 83.4{±0.6}          & 85.7{±0.7}          & 85.0{±0.6}          & 84.1{±0.6}          & 83.8{±0.7}          & 83.4{±0.5}          \\\\\n    & DGI-ADV\n    & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               \\\\\n    & ARIEL   \n    & 87.4{±0.4}          & 85.4{±0.5}          & 84.5{±0.4}          & 83.8{±0.4}          & 83.7{±0.5}          & 83.6{±0.5}          & 85.7{±0.3}          & 84.6{±0.4}          & 83.9{±0.5}          & 83.8{±0.4}          & 83.6{±0.5}          \\\\\n    \\hline              \n    & \\proposed  \n    & \\textbf{89.1{±0.4}} & \\textbf{86.9{±0.3}} & \\textbf{85.6{±0.5}} & \\textbf{85.1{±0.4}} & \\textbf{85.0{±0.5}} & \\textbf{84.8{±0.7}} & \\textbf{87.2{±0.3}} & \\textbf{85.9{±0.4}} & \\textbf{85.1{±0.5}} & \\textbf{84.4{±0.4}} & \\textbf{84.1{±0.6}} \\\\\n    \n    \\midrule\n    \\multirow{5}{*}{Co.CS} \n    & GRACE-MLP \n    & 92.1±0.2 & 92.1±0.2 & 92.1±0.2 & 92.1±0.2 & 92.1±0.2 & 92.1±0.2 & 92.1±0.2 & 92.1±0.2 & 92.1±0.2 & 92.1±0.2 & 92.1±0.2  \\\\\n    & GRACE \n    & 92.3{±0.2}          & 91.2{±0.1}          & 90.6{±0.2}          & 90.0{±0.2}          & 89.4{±0.1}          & 88.9{±0.2}          & 91.2{±0.3}          & 90.4{±0.3}          & 89.7{±0.4}          & 89.3{±0.4}          & 88.7{±0.4}          \\\\\n    & GCA     \n    & 92.5{±0.1}          & 91.4{±0.2}          & 90.7{±0.2}          & 90.2{±0.2}          & 89.7{±0.2}          & 89.3{±0.1}          & 91.4{±0.2}          & 90.8{±0.3}          & 90.0{±0.3}          & 89.6{±0.3}          & 89.0{±0.3}          \\\\\n    & BGRL    \n    & 92.4{±0.2}          & 91.3{±0.1}          & 90.5{±0.2}          & 89.9{±0.2}          & 89.3{±0.2}          & 88.7{±0.2}          & 91.3{±0.2}          & 90.5{±0.2}          & 89.8{±0.3}          & 89.4{±0.3}          & 88.8{±0.2}          \\\\\n    & DGI-ADV\n    & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               \\\\\n    & ARIEL   \n    & 92.3{±0.2}          & 91.0{±0.1}          & 90.2{±0.2}          & 89.6{±0.3}          & 88.8{±0.2}          & 88.1{±0.2}          & 90.8{±0.1}          & 90.1{±0.3}          & 89.2{±0.2}          & 88.7{±0.2}          & 87.9{±0.1}          \\\\\n    \\hline              \n    & \\proposed \n    & \\textbf{93.7±0.2} & \\textbf{92.9±0.2} & \\textbf{92.8±0.2} & \\textbf{92.5±0.2} & \\textbf{92.4±0.1} & \\textbf{92.3±0.2} & \\textbf{92.7±0.1} & \\textbf{91.9±0.2} & \\textbf{91.2±0.2} & \\textbf{90.6±0.2} & \\textbf{89.9±0.2} \\\\\n    \n    \\midrule\n    \\multirow{5}{*}{Co.Physics} \n    & GRACE-MLP  \n    & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               \\\\\n    & GRACE  \n    & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               \\\\\n    & GCA  \n    & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               \\\\\n    & BGRL    \n    & 95.2{±0.1}          & 94.1{±0.2}          & 93.2{±0.2}          & 92.5±0.1          & 91.6{±0.2}          & 91.0{±0.1}          & 94.2{±0.1}          & 93.2{±0.2}          & 92.5{±0.1}          & 91.6{±0.1}          & 91.0{±0.2}          \\\\\n    & DGI-ADV \n    & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               & {OOM}               \\\\\n    & ARIEL   \n    & 95.1{±0.1}          & 93.2{±0.2}          & 92.4{±0.2}          & 91.6{±0.2}          & 90.7{±0.3}          & 90.2{±0.2}          & 93.9{±0.1}          & 93.3{±0.1}          & 92.6{±0.2}          & 91.8{±0.2}          & 91.4{±0.2}          \\\\\n    \\hline              \n    & \\proposed  \n    & \\textbf{95.8{±0.1}} & \\textbf{94.9±{0.2}} & \\textbf{94.4{±0.1}} & \\textbf{93.6±{0.1}} & \\textbf{93.0{±0.1}} & \\textbf{92.5±0.1} & \\textbf{95.0{±0.1}} & \\textbf{94.2{±0.1}} & \\textbf{93.3±0.2} & \\textbf{92.4{±0.1}} & \\textbf{91.7{±0.1}}\\\\\n    \\bottomrule\n\\end{tabular}}}\n\\end{center}\n\\vspace{-0ex}\n\\label{tab:main_table}\n\\end{table*}",
            "tab:main_table2": "\\begin{table*}[t]\n% \\small\n% \\centering\n\\caption{Node classification accuracy under targeted attack (\\emph{nettack}). }\n\\vspace{-3ex}\n\\renewcommand{\\arraystretch}{1}\n\\begin{center}\n{\\scriptsize\n\\scalebox{0.85}{\n\\begin{tabular}{c|l|c|ccccc|ccccc}\n    \\toprule\n    \\multirow{1}{*}{} & \\multirow{1}{*}{Methods} & {} & \\multicolumn{5}{c}{Poisoning (Acc.)} & \\multicolumn{5}{c}{Evasive (Acc.)}  \\\\\n    \\hline\n    {Datasets}&{\\# Ptb}&{Clean}&{1}& 2 & 3 & 4 & 5 &{1}& 2 & 3 & 4 & 5\\\\\n    \\midrule\n    %\\hline\n    \\multirow{5}{*}{Cora} & GRACE   & 82.2±2.2          & 76.9±1.5          & 70.2±2.4          & 65.9±3.0          & 64.6±1.5          & 58.9±2.1          & 77.7±2.7          & 71.1±2.5          & 67.1±2.5          & 65.1±2.3          & 60.2±3.3          \\\\\n    & GCA     & 81.3±1.7          & 77.7±2.1          & 71.6±2.2          & 67.2±2.3          & 63.9±2.2          & 59.2±2.0          & 79.2±1.2          & 73.0±0.8          & 69.2±1.2          & 67.1±1.5          & 62.3±3.0          \\\\\n    & BGRL    & \\textbf{83.0±2.3} & 78.6±1.9          & 73.0±3.9          & 69.3±2.9          & 63.7±5.0          & 60.5±3.1          & 79.2±2.8          & 74.5±2.1          & 70.7±3.2          & 66.9±2.8          & 64.1±3.0          \\\\\n    & DGI-ADV & 81.7±0.7          & 78.0±2.3          & 71.1±2.1          & 69.9±1.1          & 65.7±1.8          & 60.7±1.9          & 78.1±1.6          & 73.0±2.1          & 70.6±1.3          & 66.5±1.2          & 63.4±1.5          \\\\\n    & ARIEL   & 76.0±1.7          & 71.9±2.2          & 64.9±1.3          & 63.5±1.6          & 63.0±1.6          & 53.7±1.7          & 71.7±2.0          & 65.4±1.2          & 63.5±1.5          & 64.1±1.3          & 54.6±1.6          \\\\\n    \\hline\n    \n    & \\proposed \n    & 82.5±2.0          & \\textbf{79.5±1.8} & \\textbf{75.3±2.5} & \\textbf{73.4±1.7} & \\textbf{67.4±2.3} & \\textbf{63.6±2.4} & \\textbf{80.2±2.4} & \\textbf{78.7±3.1} & \\textbf{77.1±3.2} & \\textbf{73.5±3.4} & \\textbf{72.8±3.7} \\\\\n    \n    \\midrule\n    \\multirow{5}{*}{Citeseer} \n    & GRACE   & 82.4±0.5          & 81.8±1.1          & 77.6±4.2          & 68.3±4.4          & 64.3±3.0          & 59.1±2.7          & 82.2±0.6          & 81.1±1.3          & 78.1±3.2          & 72.4±4.8          & 66.4±3.9          \\\\\n    & GCA     & \\textbf{82.5±0.0} & 82.4±0.5          & 78.3±2.9          & 69.4±5.9          & 65.9±2.0          & 58.3±4.0          & \\textbf{82.5±0.0} & 81.1±1.5          & 79.2±2.5          & 77.0±2.6          & 71.3±4.4          \\\\\n    & BGRL    & \\textbf{82.5±0.7} & 81.4±1.2          & 79.7±4.6          & 75.1±7.3          & 72.7±7.6          & 67.3±8.5          & 81.6±1.1          & 80.0±3.3          & 78.9±4.0          & 76.7±5.6          & 73.3±6.5          \\\\\n    & DGI-ADV & \\textbf{82.5±0.0} & 81.4±0.7          & 80.2±1.5          & 74.3±3.7          & 68.6±1.2          & 65.6±1.2          & 82.4±0.5          & 81.3±1.0          & 79.7±0.6          & 78.7±1.3          & 76.5±1.6          \\\\\n    & ARIEL   & \\textbf{82.5±0.0} & 81.1±0.9          & 80.6±0.6          & 74.3±3.9          & 66.2±1.6          & 63.2±1.0          & 81.9±0.8          & 81.3±0.6          & 81.0±0.0          & \\textbf{80.2±0.8} & \\textbf{78.6±1.5} \\\\\n    \\hline\n    & \\proposed  \n    & \\textbf{82.5±0.0} & \\textbf{82.5±0.0} & \\textbf{81.6±1.1} & \\textbf{80.0±3.0} & \\textbf{75.4±6.1} & \\textbf{72.7±5.3} & 82.4±0.5          & \\textbf{82.1±1.0} & \\textbf{81.6±1.6} & \\textbf{80.2±4.2} & 78.1±4.9          \\\\\n    \n    \\midrule\n    \\multirow{5}{*}{Pubmed} \n    & GRACE   & 87.9±0.6          & 86.6±0.5          & 84.3±0.8          & 81.7±0.9          & 77.9±1.5          & 73.0±1.3          & 86.3±0.4          & 84.4±0.7          & 81.8±1.0          & 78.3±1.2          & 74.5±1.3          \\\\\n    & GCA     & \\textbf{88.0±0.5} & \\textbf{87.1±0.6} & \\textbf{84.7±0.7} & 82.2±1.5          & 77.7±1.2          & 73.6±1.7          & \\textbf{87,0±0.5} & \\textbf{85.2±0.7} & 82.7±1.1          & 79.2±0.7          & 75.5±1.2          \\\\\n    & BGRL    & 87.4±0.8          & 85.8±0.8          & 83.2±1.0          & 79.3±1.0          & 75.4±1.2          & 70.2±1.2          & 85.8±1.1          & 83.7±1.0          & 80.3±1.2          & 76.1±1.0          & 72.3±1.1          \\\\\n    & DGI-ADV & OOM               & OOM               & OOM               & OOM               & OOM               & OOM               & OOM               & OOM               & OOM               & OOM               & OOM               \\\\\n    & ARIEL   & 83.9±0.8          & 82.0±1.0          & 79.4±1.5          & 75.2±1.4          & 72.0±1.3          & 67.5±2.6          & 81.9±0.7          & 78.8±1.6          & 76.1±1.2          & 72.0±1.2          & 68.2±1.6          \\\\\n    \\hline              \n    & \\proposed  \n    & 87.4±0.8          & 85.9±0.7          & 84.3±1.0          & \\textbf{82.7±1.1} & \\textbf{80.1±1.6} & \\textbf{77.7±2.2} & 86.2±0.5          & 84.5±0.7          & \\textbf{82.9±0.6} & \\textbf{81.0±1.1} & \\textbf{78.1±1.6} \\\\\n    \\bottomrule\n\\end{tabular}}}\n\\end{center}\n\\vspace{-1ex}\n\\label{tab:main_table2}\n\\end{table*}",
            "tab:main_table3": "\\begin{table*}[t!]\n% \\small\n% \\centering\n\\caption{Node classification accuracy under random perturbations.}\n\\vspace{-3ex}\n\\renewcommand{\\arraystretch}{1}\n\\begin{center}\n{\\scriptsize\n\\scalebox{0.85}{\n\\begin{tabular}{c|l|c|ccccc|ccccc}\n    \\toprule\n    \\multirow{1}{*}{} & \\multirow{1}{*}{Methods} & {} & \\multicolumn{5}{c}{Poisoning (Acc.)} & \\multicolumn{5}{c}{Evasive (Acc.)}  \\\\\n    \\hline\n    {Datasets}&{Ptb rate}&{Clean}&{20\\%}& 40\\% & 60\\% & 80\\% & 100\\%&{20\\%}& 40\\% & 60\\% & 80\\% & 100\\% \\\\\n    \\midrule\n    %\\hline\n    \\multirow{5}{*}{Cora} & GRACE   & 82.1±1.0          & 77.5±1.2          & 74.2±0.9          & 70.3±1.2          & 66.9±1.1          & 65.1±0.9          & 78.4±1.9          & 74.8±1.6          & 71.5±1.9          & 68.6±2.9          & 64.1±2.4          \\\\\n    & GCA     & 81.5±0.9          & 76.8±1.0          & 72.0±1.2          & 67.2±1.4          & 61.9±1.8          & 53.4±3.2          & 77.9±1.1          & 75.0±1.3          & 72.7±1.3          & 70.6±1.5          & 67.8±2.3          \\\\\n    & BGRL    & 82.7±1.0          & 77.8±1.2          & 74.8±1.4          & 72.6±1.4          & 69.6±0.8          & 68.0±1.2          & 79.0±0.9          & 76.5±1.3          & 74.2±1.2          & 73.0±0.7          & 70.7±0.8          \\\\\n    & DGI-ADV & 83.7±0.7          & 78.8±1.0          & 76.7±0.7          & 73.8±0.6          & 69.9±1.1          & 68.0±1.4          & 80.6±1.0          & 78.2±1.1          & 75.3±1.8          & 73.2±1.8          & 70.7±2.4          \\\\\n    & ARIEL   & 80.9±0.5          & 75.8±0.8          & 69.8±0.9          & 64.8±1.3          & 60.7±1.5          & 57.6±1.1          & 76.1±1.0          & 70.6±1.1          & 65.4±1.5          & 60.2±1.5          & 53.6±1.7          \\\\\n    \\hline\n    \n    & \\proposed \n    & \\textbf{83.9±0.7} & \\textbf{81.3±1.3} & \\textbf{80.2±0.6} & \\textbf{78.6±0.4} & \\textbf{76.2±1.3} & \\textbf{76.8±0.9} & \\textbf{81.8±1.3} & \\textbf{80.1±1.1} & \\textbf{78.7±1.1} & \\textbf{77.5±1.5} & \\textbf{76.1±1.3} \\\\\n    \n    \\midrule\n    \\multirow{5}{*}{Citeseer} \n    & GRACE   & 74.9±0.6          & 72.0±0.7          & 68.8±0.9          & 66.0±0.6          & 63.6±0.8          & 61.3±0.7          & 72.8±0.9          & 71.4±0.7          & 70.1±0.7          & 68.7±0.8          & 67.7±1.1          \\\\\n    & GCA     & 74.2±0.7          & 70.8±0.9          & 67.0±1.6          & 63.6±1.5          & 61.1±1.2          & 57.5±2.2          & 72.3±0.5          & 70.9±0.9          & 69.6±1.1          & 68.5±0.8          & 67.6±0.9          \\\\\n    & BGRL    & 73.4±1.0          & 70.4±1.2          & 67.7±1.0          & 65.0±2.2          & 63.7±1.4          & 61.4±1.7          & 71.5±0.9          & 69.4±0.9          & 68.1±0.7          & 66.6±1.2          & 65.8±1.0          \\\\\n    & DGI-ADV & 76.6±0.3          & 73.1±0.4          & 70.1±0.9          & 67.4±1.0          & 66.0±0.6          & 64.0±0.5          & 74.7±0.5          & 72.8±0.6          & 71.3±0.8          & 69.6±0.4          & 68.2±1.3          \\\\\n    & ARIEL   & \\textbf{76.7±0.5} & \\textbf{74.2±0.6} & \\textbf{72.8±0.8} & 70.2±0.4          & 69.1±0.4          & 67.6±0.7          & \\textbf{75.0±0.7} & \\textbf{73.7±0.6} & 72.4±0.8          & 71.1±0.8          & \\textbf{70.7±0.9} \\\\\n    \\hline\n    & \\proposed  \n    & 75.9±0.4          & 74.1±0.7          & 72.7±0.6          & \\textbf{70.8±0.8} & \\textbf{69.5±0.4} & \\textbf{68.3±0.6} & 74.8±0.4          & 73.5±0.6          & \\textbf{72.7±0.7} & \\textbf{71.7±0.4} & 70.6±0.8          \\\\\n    \n    \\midrule\n    \\multirow{5}{*}{Pubmed} \n    & GRACE   & 85.9±0.1          & 82.1±0.2          & 80.1±0.3          & 78.3±0.7          & 76.7±0.3          & 75.7±0.2          & 81.2±0.2          & 78.9±0.1          & 77.3±0.3          & 76.2±0.3          & 75.5±0.2          \\\\\n    & GCA     & \\textbf{86.5±0.2} & \\textbf{82.6±0.1} & 80.4±0.6          & 78.6±0.7          & 77.1±0.6          & 76.0±0.3          & 81.2±0.2          & 78.6±0.2          & 76.8±0.2          & 75.6±0.3          & 74.8±0.2          \\\\\n    & BGRL    & 85.1±0.2          & 81.3±0.6          & 79.5±0.8          & 78.3±1.0          & 77.2±1.2          & 76.8±0.7          & 80.6±0.8          & 78.7±0.9          & 77.3±1.0          & 76.3±1.2          & 75.6±1.0          \\\\\n    & DGI-ADV & OOM               & OOM               & OOM               & OOM               & OOM               & OOM               & OOM               & OOM               & OOM               & OOM               & OOM               \\\\\n    & ARIEL   & 83.4±0.1          & 79.0±0.4          & 77.2±0.3          & 76.4±0.3          & 75.5±0.2          & 74.8±0.3          & 78.4±0.5          & 76.8±0.3          & 75.7±0.4          & 74.7±0.2          & 74.0±0.5          \\\\\n    \\hline              \n    & \\proposed  \n    &  85.5±0.3          & 82.3±0.2          & \\textbf{80.7±0.2} & \\textbf{79.9±0.1} & \\textbf{78.6±0.2} & \\textbf{78.0±0.2} & \\textbf{82.1±0.2} & \\textbf{80.1±0.2} & \\textbf{78.7±0.5} & \\textbf{77.9±0.4} & \\textbf{77.2±0.5} \\\\\n    \\bottomrule\n\\end{tabular}}}\n\\end{center}\n\\vspace{-1ex}\n\\label{tab:main_table3}\n\\end{table*}",
            "tab:hetero": "\\begin{table}[h]\n    \\centering\n    \\vspace{-1ex}\n    \\caption{Node classification Acc. on heterophilous graphs.}\n    \\vspace{-2ex}\n    \\centering\n    \\resizebox{0.88\\linewidth}{!}{\n    \\begin{tabular}[b]{l|cccccc}\n    \\hline \n    & Chameleon & Squirrel & Actor & Texas & Wisconsin & Cornell\\\\\n    \\hline\n    GRACE   & 46.6±2.8          & 35.2±1.0            & 29.5±0.5          & 61.1±6.5          & 55.3±5.5 & 61.1±5.0          \\\\\nGCA     & 50.0±3.0              & 37.1±1.8          & 29.3±0.8          & 60.0±6.3            & 55.7±8.0   & 59.5±3.8          \\\\\nBGRL    & 57.1±3.6          & 40.6±1.6          & 31.0±1.2            & 61.6±6.0            & 57.7±5.2 & 57.8±4.7          \\\\\nDGI-ADV & 53.4±2.2          & 40.1±1.6          & 26.5±0.9          & 58.4±6.1          & 57.3±4.9 & 60.5±5.8          \\\\\nARIEL   & 44.3±2.4          & 36.8±1.2          & 29.6±0.3          & 58.4±4.7          & 53.3±7.2 & 57.8±4.4          \\\\\n    \\hline\n    \\proposed         & \\textbf{57.5±2.5} & \\textbf{41.1±1.9} & \\textbf{32.3±1.3} & \\textbf{64.9±6.8} & \\textbf{58.4±5.5}      & \\textbf{64.3±3.6} \\\\ \n    \\hline\n    \\end{tabular}}\n    \\vspace{-1ex}\n    \\label{tab:hetero}\n\\end{table}",
            "tab:ablation": "\\begin{table}\n    \\centering\n    \\caption{Ablation study. \\textit{SP} and \\textit{Feat. Ptb} denote the existence of similarity-preserving view and the type of feature perturbations, respectively.}\n    \\vspace{-2ex}\n    \\scalebox{0.78}{\n    \\renewcommand{\\arraystretch}{0.9}\n    \\begin{tabular}{cc|ccc|ccc}\n        \\hline\n        \\multicolumn{2}{c|}{Component} & \\multicolumn{3}{c}{Cora} & \\multicolumn{3}{c}{Citeseer}  \\\\\n        \\hline\n        SP & Feat. Ptb & 0\\% & 15\\% & 25\\% & 0\\% & 15\\% & 25\\% \\\\\n        \\hline\n        % \\multicolumn{2}{c|}{GRACE} & 82.1±1 & 66.1±1.6 & 51.3±2 & 74.9±0.6 & 71.2±1.3 & 61.2±1.5 \\\\\n         \\ding{55} & \\ding{55} & 82.9±1.1 & 64.8±1.0 & 50.6±1.0 & 70.6±1.1 & 63.3±1.4 & 55.3±2.4\\\\\n        %  \\ding{55} & FG  & \\textbf{85.1±0.7} & 65.4±0.7 & 48.7±1.6 & 75.3±0.5 & 67.6±1 & 57.9±1.1 \\\\\n         \\ding{55} & Flip  & 83.4±0.7 & 60.5±1.5 & 48.0±1.3 & 72.5±1.1 & 63.8±1.3 & 52.6±1.9 \\\\\n         \\ding{55} & Mask  & \\textbf{84.0±1.0} & \\textbf{68.8±1.3} & \\textbf{52.0±0.7} & \\textbf{74.4±1.0} & \\textbf{70.0±1.6} &\t\\textbf{64.1±0.8}\\\\\n         \\midrule\n         \\midrule\n         \\ding{51} & \\ding{55} & 83.8±0.9 & 68.4±1.2 & 64.7±1.4 & 74.5±0.5 & 69.7±0.9 & 68.6±0.9\\\\\n        \\ding{51} & Flip & 82.0±0.5 & 67.5±1.1 &  62.7±2.7 & 73.7±0.5 & 68.0±1.3 & 62.8±0.9\\\\\n        \\ding{51} & Mask & \\textbf{83.9±0.7} & \\textbf{73.3±0.5} &  \\textbf{65.3±1.0} & \\textbf{75.9±0.4} & \\textbf{72.1±1.1} & \\textbf{69.6±0.9}\\\\\n        \\hline\n    \\end{tabular}}\n    \\label{tab:ablation}\n\\vspace{-2ex}\n\\end{table}",
            "tab:dataset": "\\begin{table}[h]\n\\centering\n\\small\n\\caption{Statistics for datasets.}\n\\vspace{-2ex}\n\\renewcommand{\\arraystretch}{0.98}\n{\\small\n\\scalebox{0.9}{\n\\begin{tabular}{c|c|cccc}\n% \\noalign{\\smallskip}{\\smallskip}\n\\hline\n Domain & Dataset & \\# Nodes & \\# Edges & \\# Features & \\# Classes \\\\\n\\hline \n\\multirow{3}{*}{Citation} & Cora     & 2,485          & 5,069         & 1,433      & 7   \\\\  \n& Citeseer   & 2,110        & 3,668         & 3,703      & 6   \\\\\n& Pubmed     & 19,717       & 44,338        & 500        & 3   \\\\\n\\hline \n\\multirow{2}{*}{Co-purchase} & Am.Photo   & 7,650        & 119,081       & 745        & 8   \\\\\n& Am.Comp    & 13,752       & 245,861       & 767        & 10  \\\\\n\\hline \n\\multirow{2}{*}{Co-author}& Co.CS      & 18,333       & 81,894        & 6,805      & 15  \\\\\n& Co.Physics   & 34,493     & 247,962       & 8,415      & 5    \\\\\n \\hline\n\n\\multirow{6}{*}{Heterohpily} & Chameleon   &    2,277      &   36,101        &    2,325 & 5    \\\\\n& Squirrel   &    5,201      &   217,073        &    2,089       &       5    \\\\\n& Actor   &    7,600      &   33,544        &    931       &       5    \\\\\n& Cornell   &    183      &   295        &    1,703       &       5    \\\\\n& Texas   &    183      &   309        &    1,703       &       5    \\\\\n& Wisconsin   &    251      &   499        &    1,703       &       5    \\\\\n\\hline\n\n\\end{tabular}\n}}\n\\label{tab:dataset}\n\\vspace{0ex}\n\\end{table}"
        },
        "figures": {
            "fig:observation": "\\begin{figure*}[t]\n%     \\centering\n%     \\begin{minipage}{.25\\linewidth}{\n%         \\centering\n%     \\includegraphics[width=1\\columnwidth]{figures/gcl-attack.png}\n%     \\vspace{-5ex}\n    \n%     }\\end{minipage}\n% \t\\hfill\n%     \\begin{minipage}{.74\\linewidth}{\n    \\centering\n    \\includegraphics[width=1.75\\columnwidth]{figures/figure1.pdf}\n    % {figures/analysis-figure.pdf}\n    \\vspace{-2ex}\n%     % \\vspace{-11ex}\n% \t}\\end{minipage}\n    \\caption{(a) Gradients of the contrastive loss w.r.t $\\mathbf{A}$. Each point represents an element in the adjacency matrix $\\mathbf{A}$ with the sum of node degrees of two nodes ($x$-axis), and the raw feature similarity ($y$-axis) between two nodes. \\textcolor{red}{Red} points denote edges selected for perturbations. (b) $OL$ scores (in solid lines) with $k=10$, and the difference of the node classification (bar graph) accuracy of GRACE-AT, and \\proposed~ compared with GRACE on Citeseer and Co.CS datasets.}\n    \\label{fig:observation}\n    \\vspace{-2ex}\n\\end{figure*}",
            "fig:low_degree": "\\begin{figure*}[t]\n\\vspace{-1ex}\n  \\includegraphics[width=.6\\linewidth]{figures/low_degree_down.pdf}\n  \\vspace{-1ex}\n  \\caption{Node classification on low-/high-degree nodes under \\emph{metattack}. Cora and Citseer datasets are used.}\n  \\label{fig:low_degree}\n  \\vspace{-2ex}\n\\end{figure*}",
            "fig:noisy": "\\begin{figure}[t]\n    \\centering\n    \\includegraphics[width=0.65\\linewidth]{figures/noisy.pdf}\n    \\vspace{-2ex}\n    \\caption{Node classification accuracy with noisy label.}\n    \\label{fig:noisy}\n    \\vspace{-4ex}\n\\end{figure}",
            "app-fig:architecture": "\\begin{figure}[h]\n    \\includegraphics[width=.8\\columnwidth]{figures/archi_final.pdf}\n    \\vspace{-4ex}\n    \\caption{The overall architecture of~\\proposed.}\n    \\label{app-fig:architecture}\n    \\vspace{-2ex}\n\\end{figure}",
            "fig:sensitivity_ptb_bdgt": "\\begin{figure*}[h]\n    \\centering\n    \\vspace{1ex}  \n    \\includegraphics[width=0.89\\linewidth]{figures/sensitivity1_.pdf}\n    \\vspace{-2ex}\n    \\caption{Sensitivity analysis on edge perturbation and feature masking rates. \\textcolor{burntumber}{Red}-white-\\textcolor{airforceblue}{blue} means outperformance, on-par, and underperformance compared with ARIEL.}\n    \\label{fig:sensitivity_ptb_bdgt}\n    \\vspace{-3ex}\n\\end{figure*}",
            "fig:sensitivity_labmda": "\\begin{figure*}[t]\n    \\centering\n    \\vspace{1ex}  \n    \\includegraphics[width=0.88\\linewidth]{figures/sensitivity2_.pdf}\n    \\vspace{-2ex}\n    \\caption{Sensitivity analysis on the coefficients of objectives $\\lambda_1$ and $\\lambda_2$. \\textcolor{burntumber}{Red}-white-\\textcolor{airforceblue}{blue} means outperformance, on-par, and underperformance compared with ARIEL.}\n    \\label{fig:sensitivity_labmda}\n    \\vspace{-3ex}\n\\end{figure*}",
            "fig:sensitivity_k": "\\begin{figure*}[t]\n    \\centering\n    \\vspace{1ex}  \n    \\includegraphics[width=0.88\\linewidth]{figures/sensitivity3.pdf}\n    \\vspace{-2ex}\n    \\caption{Sensitivity analysis on $k$NN.}\n    \\label{fig:sensitivity_k}\n    \\vspace{-3ex}\n\\end{figure*}"
        },
        "equations": {
            "eq:1": "\\begin{equation}\n\\small\n    \\mathcal{L}(\\mathbf{Z}^1, \\mathbf{Z}^2) = \\frac{1}{2N}\\sum_{i=1}^{N} l(\\mathbf{z}_i^1, \\mathbf{z}_i^2) + l(\\mathbf{z}_i^2, \\mathbf{z}_i^1)\n    \\label{eq:cl_loss}\n    \\vspace{-3ex}\n\\end{equation}",
            "eq:2": "\\begin{equation}\n\\small\n    \\delta_{\\mathbf{A}}^{*}, \\delta_{\\mathbf{X}}^{*} = \\arg\\max_{\\delta_{\\mathbf{A}}, \\delta_{\\mathbf{X}}\\in \\Delta} \\mathbb{E}  \\left[{ \\mathcal{L}( f(\\mathbf{A}^1 +\n    \\delta_{\\mathbf{A}}, \\mathbf{X}^1 + \\delta_{\\mathbf{X}}), f(\\mathbf{A}^2, \\mathbf{X}^2))} \\right]\n    \\label{eq:attack_gcl}\n\\end{equation}",
            "eq:3": "\\begin{equation}\n\\small\n    \\min_{\\Theta}  { \\mathcal{L}(\\mathbf{Z}^1,\\mathbf{Z}^2) + \\lambda_1 \\mathcal{L}(\\mathbf{Z}^1, \\mathbf{Z}^{\\text{adv}})}\n    \\label{eq:at}\n\\end{equation}",
            "eq:4": "\\begin{align}\n\\small\n& \\mathbf{z}_i^2 - {\\mathbf{z}_i^{\\text{atk}}} = (\\mathbf{z}_i^2 - \\mathbf{z}_i^1) + (\\mathbf{z}_i^1 - {\\mathbf{z}_i^{\\text{atk}}}) \\nonumber \\\\ \n&= \\mathbf{e}_i \\!+ \\!\\!\\!\\!\\!\\sum_{j\\in\\mathcal{N}_{\\mathbf{A}^1}^i\\cup \\{i\\}} \\frac{{\\mathbf{W}\\mathbf{x}_j}}{\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1}^i|}\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1}^j|}} - \\!\\!\\!\\!\\!\\sum_{j\\in  \\mathcal{N}_{\\mathbf{A}^1+\\delta_{\\mathbf{A}}}^i \\!\\!\\!\\cup \\{i\\}} \\frac{{\\mathbf{W}\\mathbf{x}_j}}{\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1+\\delta_{\\mathbf{A}}}^i|}\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1+\\delta_{A}}^j|}} \\nonumber \\\\\n&= \\mathbf{e}_i + \\frac{1}{\\underbrace{\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1}^i|+1}}_{\\text{Degree term}}} \\underbrace{\\left(\\sum_{j\\in\\mathcal{N}_{\\mathbf{A}^1}^i\\cup \\{i\\}} \\frac{\\alpha{\\mathbf{W}\\mathbf{x}_j}}{\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1}^i|}\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1}^j|}} - \\frac{\\mathbf{W}{\\mathbf{x}_k}}{\\sqrt{|\\mathcal{N}_{\\mathbf{A}^1}^k|+1}}\\right)}_{\\text{Feature difference term}}\n\\label{eq:diff}\n\\raisetag{20pt}\n\\end{align}",
            "eq:5": "\\begin{equation}\n\\small\nOL(\\mathbf{A}^{k\\text{NN}(\\mathbf{Z})} , \\mathbf{A}^{k\\text{NN}(\\mathbf{X})})=\\frac{|\\mathbf{A}^{k\\text{NN}(\\mathbf{Z})} \\cap \\mathbf{A}^{k\\text{NN}(\\mathbf{X})}|}{|\\mathbf{A}^{k\\text{NN}(\\mathbf{X})}|}\n\\label{eq:ol}\n\\end{equation}",
            "eq:6": "\\begin{equation}\n\\small\n    \\min_{\\Theta} \\mathcal{L}(\\mathbf{Z}^1, \\mathbf{Z}^2) + \\lambda_1 \\mathcal{L}(\\mathbf{Z}^1, \\mathbf{Z}^{\\text{adv}}) + \\lambda_2 \\mathcal{L}(\\mathbf{Z}^1, \\mathbf{Z}^{k\\text{NN}(\\mathbf{X})})\n\\label{final_loss}\n\\end{equation}"
        },
        "git_link": "https://github.com/yeonjun-in/torch-SP-AGCL"
    }
}