{
    "meta_info": {
        "title": "Predicting Opinion Dynamics via Sociologically-Informed Neural Networks",
        "abstract": "Opinion formation and propagation are crucial phenomena in social networks\nand have been extensively studied across several disciplines. Traditionally,\ntheoretical models of opinion dynamics have been proposed to describe the\ninteractions between individuals (i.e., social interaction) and their impact on\nthe evolution of collective opinions. Although these models can incorporate\nsociological and psychological knowledge on the mechanisms of social\ninteraction, they demand extensive calibration with real data to make reliable\npredictions, requiring much time and effort. Recently, the widespread use of\nsocial media platforms provides new paradigms to learn deep learning models\nfrom a large volume of social media data. However, these methods ignore any\nscientific knowledge about the mechanism of social interaction. In this work,\nwe present the first hybrid method called Sociologically-Informed Neural\nNetwork (SINN), which integrates theoretical models and social media data by\ntransporting the concepts of physics-informed neural networks (PINNs) from\nnatural science (i.e., physics) into social science (i.e., sociology and social\npsychology). In particular, we recast theoretical models as ordinary\ndifferential equations (ODEs). Then we train a neural network that\nsimultaneously approximates the data and conforms to the ODEs that represent\nthe social scientific knowledge. In addition, we extend PINNs by integrating\nmatrix factorization and a language model to incorporate rich side information\n(e.g., user profiles) and structural knowledge (e.g., cluster structure of the\nsocial interaction network). Moreover, we develop an end-to-end training\nprocedure for SINN, which involves Gumbel-Softmax approximation to include\nstochastic mechanisms of social interaction. Extensive experiments on\nreal-world and synthetic datasets show SINN outperforms six baseline methods in\npredicting opinion dynamics.",
        "author": "Maya Okawa, Tomoharu Iwata",
        "link": "http://arxiv.org/abs/2207.03990v1",
        "category": [
            "cs.SI",
            "cs.LG",
            "stat.ML"
        ],
        "additionl_info": "Proceedings of the 28th ACM SIGKDD International Conference on  Knowledge Discovery & Data Mining, KDD 2022"
    },
    "latex_extraction": {
        "content": {
            "section 1": {
                "name": "Introduction",
                "content": "\n\nOpinion dynamics is the study of information and evolution of opinions in human society. \nIn society, people exchange opinions on various subjects including political issues, new products, and social events (e.g., sports events). \nAs a result of such interactions (i.e., social interaction), an individual's opinion is likely to change over time. \nUnderstanding the mechanisms of social interaction and predicting the evolution of opinions are essential \nin a broad range of applications such as business marketing \\cite{DBLP:journals/access/Sanchez-NunezCH20,kumar2018detecting}, \npublic voice control \\cite{DBLP:conf/nldb/LaiPRR18}, friend recommendation on social networking sites \\cite{eirinaki2013trust} and social studies \\cite{moussaid2013social}. \nFor example, predicting the evolution of opinion dynamics can help companies design optimal marketing strategies \nthat can guide the market to react more positively to their products.  \n\nTheoretical models called opinion dynamics models have been proposed for modeling opinion dynamics.  \nThe earliest work can be traced back to sociological and social psychological research by French \\cite{french1956formal} and DeGroot \\cite{degroot1974reaching}.  \nThe most representative ones are bounded confidence models \\cite{DBLP:journals/jasss/HegselmannK02,DBLP:journals/advcs/DeffuantNAW00}, \nwhich take into account the psychological phenomenon known as confirmation bias --- \nthe tendency of people to accept only information that confirms prior beliefs. \nThese models specify the underlying mechanism of social interaction in the form of difference equations.  \nTypically, opinion dynamics models are explored and validated by computer simulations such as agent-based models. \nThe theoretical models are highly interpretable; and can utilize the wealth of knowledge from social sciences, especially in social psychology and sociology.\nHowever, to learn predictive models, the computer simulations require calibration with real data, which incurs high manual effort and high computational complexity due to the massive data needed. \n\nNowadays, social media is increasingly popular as means of expressing opinions \\cite{DBLP:conf/icwsm/OConnorBRS10,devi2020literature} and they \nhave become a valuable source of information for analyzing the formation of opinions in social networks.  \nData-driven methods have been applied to exploit large-scale data from social media for predicting the evolution of users' opinions. \nFor instance, De \\textsl{et al.} \\cite{DBLP:conf/cikm/DeBBGC14} developed a simple linear model for modeling the temporal evolution of opinion dynamics.  \nSome studies \\cite{DBLP:conf/nips/DeVGBG16,DBLP:conf/icdm/KulkarniADBG17} proposed probabilistic generative models based on point processes \nthat capture the non-linear dynamics of opinion formation. \nHowever, these models lack flexibility as they use hand-crafted functions to model social interaction.  \nRecent work \\cite{zhu2020neural} developed a deep learning approach that automatically learns \nthe social interaction and underlying evolution of individuals' opinions from social media posts. \nWhile this approach enables flexible modeling of social interaction, \nit is largely agnostic to prior scientific knowledge of the social interaction mechanism. \n\nIn this paper, we propose a radically different approach that integrates both large-scale data and prior scientific knowledge. \nInspired by the recent success of physics-informed neural networks (PINNs) \\cite{raissi2019deep}, \nwe extend them to encompass opinion dynamics modeling. \nTo this end, we first reformulate opinion dynamics models into ordinary differential equations (ODEs). \nWe then approximate the evolution of individuals' opinions by a neural network. \nDuring the training process, by penalizing the loss function with the residual of ODEs that represent the theoretical models of opinion dynamics,  \nthe neural network approximation is made to consider sociological and social psychological knowledge. \n\nWhile PINNs have successfully incorporated the laws of physics into deep learning, \nsome challenges arise when translating this method to opinion dynamics. \nFirst, most of them fail to capture the \\textsl{stochastic nature} of social interaction. \nMany recent opinion dynamics models involve stochastic processes that emulate real-world interactions. \nFor example, several bounded confidence models encode probabilistic relationships between individuals, in which individuals randomly communicate their opinion to others, via stochastic variables. \nSuch stochastic processes require sampling from discrete distributions, which makes backpropagating the error through the neural network impossible.\nSecond, they cannot utilize \\textsl{additional side information} including individuals' profiles, social connections (e.g., follow/following relationship in Twitter), and external influences from mass media, government policy, etc. \nIn real cases, we can obtain rich side information from social media, including \nuser profiles and social media posts (e.g., user profile description and tweet text attributes), \nwhich is described in natural language.  \nFinally, they cannot consider \\textsl{structural knowledge} on social interaction. \nSocial interaction is represented by network structure, and each network has a certain cluster structure. \nPrevious studies have empirically shown real-world social networks\nconsist of different user communities sharing same beliefs \\cite{DBLP:conf/kdd/KumarNT06}. \n\nTo address these challenges, we develop a new framework called \\textsf{SINN} (Sociologically-Informed Neural Network), which is built upon PINNs. \nTo take account of the \\textsl{stochastic nature} of opinion dynamics models, \nwe incorporate the idea of reparameterization into the framework of PINNs.  \nSpecifically, we replace the discrete sampling process with a differentiable function of parameters \nand a stochastic variable with fixed Gumbel-Softmax distribution. \nThis makes the gradients of the loss propagate backward through the sampling operation and thus the whole framework can be trained end-to-end. \nAlso, PINNs are broadened to include \\textsl{rich side information}. \nTo use users' profile descriptions, we combine the framework of PINNs and natural language processing techniques by adding a pre-trained language model.  \nMoreover, building upon \\textsl{structural knowledge} on the social interaction network (i.e., cluster structure), \nwe apply low-rank matrix factorization to the parameters of ODEs. \nThe proposal, \\textsf{SINN}, incorporates the underlying sociology and social psychology, as described by ODEs, into the neural network \nas well as rich side information and structural knowledge, \nwhile at the same time exploiting the large amount of data available from social media.  \n\nTo evaluate our proposed framework we conduct extensive experiments on three synthetic datasets and three real-world datasets from social networks (i.e., Twitter and Reddit).  \nThey demonstrate that \\textsf{SINN} provides better performance for opinion prediction than several existing methods, \nincluding classical theoretical models as well as deep learning-based models. \nTo the best of our knowledge, this work is the first attempt to transpose the concepts of PINNs from natural science (i.e., physics) into social science (i.e., sociology and social psychology).\nTo foster future work in this area, % of multidisciplinary research, \nwe will release our code and sample data on \\path{https://github.com/mayaokawa/opinion_dynamics}. \n\nOur contributions are summarized as follows: \n\\begin{itemize}\n\\item We propose the first hybrid framework called \\textsf{SINN} (Sociologically-Informed Neural Network) that integrates a large amount of data from social media and underlying social science to predict opinion dynamics in a social network. \n\\item \\textsf{SINN} formulates theoretical models of opinion dynamics as ordinary differential equations (ODEs), \nand then incorporates them as constraints on the neural network. It also includes matrix factorization and a language model to incorporate rich side information and structural knowledge on social interaction.  \n\\item We propose an end-to-end training procedure for the proposed framework. To include stochastic opinion dynamics models in our framework, we introduce the reparameterization trick into \\textsf{SINN}, which makes its sampling process differentiable.  \n\\item We conduct extensive experiments on three synthetic datasets and three real-world datasets from social networks. \nThe results show that \\textsf{SINN} outperforms six existing methods in predicting the dynamics of individuals' opinions in social networks. \n\\end{itemize}\n\n\n\n"
            },
            "section 2": {
                "name": "Related Work",
                "content": "\n\n\\textbf{Physics-informed neural networks. }\nFrom a methodological perspective, this paper is related to the emerging paradigm of physics-informed neural networks (PINNs) \n\\cite{raissi2019deep}. \nPINNs incorporate physical knowledge into deep learning \nby enforcing physical constraints on the loss function, which is usually described by systems of partial differential equations (PDEs). These methods have been successfully applied to many physical systems, including  \nfluid mechanics \\cite{sun2020surrogate}, \nchemical kinetic \\cite{ranade2019extended}, \noptics \\cite{chen2020physics}. This paper is the first attempt to import this approach into the field of social science, especially for modeling opinion dynamics.  \nThis poses three major challenges. \nFirst, many common opinion dynamics models involve randomized processes; but most PINNs deal only with deterministic systems.\nVery few works \\cite{yang2020physics,zhang2019quantifying} explore stochastic PDEs with additive noise terms. \nHowever, they still fail to model stochastic terms that contain the model parameters. \nSecond, they do not include rich side information such as profiles of social media users and social media posts.  \nThird, they cannot take into account extra structural knowledge on social interaction.   \n\n\n\\textbf{Opinion dynamics modeling. }\nOpinion dynamics is the study of how opinions emerge and evolve through the exchange of opinions with others (i.e., social interaction). \nIt has been a flourishing topic in various disciplines from social psychology and sociology to statistical physics and computer science. Theoretical models of opinion dynamics have been developed in divergent model settings with different opinion expression formats and interaction mechanisms. \nThe first mathematical models can be traced back to works by sociologists and psychologists. \nIn the 60s, French and John \\cite{french1956formal} proposed the first simple averaging model of opinion dynamics,  \nfollowed by Harary \\cite{acemouglu2013opinion} and DeGroot \\cite{degroot1974reaching}. \nExtensions to this line of work, such as Friedkin and Johnsen (FJ) model \\cite{friedkin1990social}, \nincorporated the tendency of people to cling to their initial opinions. \nBounded confidence models, including Hegselmann-Krause (HK) model \\cite{DBLP:journals/jasss/HegselmannK02} \nand Deffuant-Weisbuch (DW) model \\cite{DBLP:journals/advcs/DeffuantNAW00}, \nconsider confirmation bias: the tendency of individuals to interact those with similar opinions. \nLater studies generalized bounded confidence models to account for multi-dimensional opinion spaces \\cite{lanchier2012axelrod},  \nasymmetric \\cite{zhang2013opinion} and time-varying bounded confidence \\cite{zhang2017opinion}. \nMore recent works \\cite{schweighofer2020agent,leshem2018impact,liu2013social} take into account stochastic interactions among individuals. \nAnother line of work has adopted the concepts and tools of statistical physics to describe the behavior of interacting individuals, \nfor example, the voter model \\cite{DBLP:conf/ita/YildizPOS10}, the Sznajd model \\cite{sznajd2000opinion}, and\nthe majority rule model \\cite{galam1999application}. These physical models are built upon empirical investigations in social psychology and sociology.  \nOpinion dynamics models have been tested by analytical tools as well as simulation models.  \nSome works \\cite{golub2012homophily,como2009scaling} employ differential equations for theoretical analysis. \nHowever, no analytic solutions of the differential equation are possible for most opinion dynamics models. \nMany other studies \\cite{martins2008continuous,jager2005uniformity} adopt agent-based models to explore how the local interactions of individuals cause the emergence of collective public opinion in a simulated population of agents. \nHowever, to make reliable predictions, such simulations demand calibration with real data as done in \\cite{sobkowicz2016quantitative,sun2013framework},  but the cost incurred in terms of time consumed and labor expended are high.  \n\nGiven the advances in machine learning, efforts have been made to utilize rich data collected from social media to model opinion dynamics. \nFor instance, early work proposed a linear regression model, AsLM (asynchronous linear model) \\cite{DBLP:conf/cikm/DeBBGC14}; \nit learns the linear temporal evolution of opinion formation. \nThis model is based on a simple linear assumption regarding social interaction. \nSLANT \\cite{DBLP:conf/nips/DeVGBG16} and its subsequent work, SLANT+ \\cite{DBLP:conf/icdm/KulkarniADBG17}, \napply a generative model based on multi-dimensional point processes to this task to capture the non-linear interaction among individuals. \nUnfortunately, these models still lack flexibility as deriving the point process likelihood demands excessively simple assumptions. \nMonti \\textsl{et al.} \\cite{DBLP:conf/kdd/MontiMB20} translate a classical bounded confidence model into a generative model and \ndevelop an inference algorithm for fitting that model to social media data. \nHowever, this model still relies on which opinion dynamics model is adopted. \nMoreover, it is intended to infer the individuals' opinions \nfrom the aggregated number of posts and discussions among social media users within a fixed time interval.  \nDifferent from this model, this paper focuses on modeling the sequence of labeled opinions observed at different time intervals \ndirectly, without aggregation or inference. \nRecent work \\cite{zhu2020neural} employs a deep learning model to estimate the temporal evolution of users' opinions from social media posts.  \nAlthough this method can learn the influence of the other users' opinions through an attention mechanism, \nit is mostly data-driven and largely ignores prior knowledge about social interaction. \n\n\n\n"
            },
            "section 3": {
                "name": "Preliminaries",
                "content": "\nWe introduce the concept of opinion dynamics models, \nand then define the problem of predicting opinion dynamics. \n\n\n",
                "subsection 3.1": {
                    "name": "Opinion dynamics models",
                    "content": "\nOpinion dynamics models describe the process of opinion formation in human society. \nConventional opinion dynamics models are equation-based, wherein one specifies the underlying mechanism of social interaction \nin the form of difference equations. Starting from DeGroot model \\cite{degroot1974reaching},\nmany opinion dynamics models based upon theories in sociology and social psychology have been proposed with a wide variety of interaction mechanisms.  \nIn the following, we introduce some representative models of opinion dynamics.  \n\n{\\bf DeGroot model. } \nDeGroot model \\cite{degroot1974reaching} is the most simple and basic model of opinion dynamics.  \nIn this model, each user $u$ holds opinion $x_u(t)\\in[-1,1]$ on a specific subject (e.g., politics, product and event) at every time step $t$, \nwhere the extremal values correspond to the strongest negative (-1) and positive (1) opinions. \nThe DeGroot model assumes that their opinions evolve in discrete time steps according to the following rule:\n\\begin{align}\\label{eq:degroot}\nx_u(t+1) = x_u(t) + \\sum_{v\\in\\mathcal{U}\\backslash u} a_{uv} x_v(t), \n\\end{align}\nwhere $\\mathcal{U}$ is the set of users, \n$x_v(t)$ represents user $v$'s previous opinion, and \n$a_{uv}$ is the strength of the interactions between users $u$ and $v$.\nIn the DeGroot model, each user $u$ forms her opinion $x_u(t+1)$ at time step $t+1$ as the weighted sum of all previous opinions\nat the preceding time step $t$. \nThe DeGroot model captures the concepts of \\textsl{assimilation} --- the tendency of individuals to move their opinions towards others.  \nThe continuous-time version of the DeGroot model was proposed by \\cite{abelson1964mathematical}. \n\n{\\bf Friedkin-Johnsen (FJ) model. } Friedkin and Johnsen \\cite{friedkin1990social} extended the Degroot model to allow the users to have different susceptibilities to persuasion (i.e., the tendency to defer to others' opinions).  \nAccording to the FJ model, the opinion at current time step $t$ is updated as the sum of her initial opinion $x_u(0)$ and all the previous opinions, \nwhich is denoted by: \n\\begin{align}\\label{eq:friedkin}\nx_u(t+1) = s_u \\sum_{v\\in\\mathcal{U}\\backslash u} x_v(t) + (1-s_u) x_u(0), \n\\end{align}\nwhere the scaler parameter $s_u\\in[0,1]$ measures user $u$'s susceptibility to persuasion.  \nIf $s_n=0$, user $u$ is maximally stubborn (attached to their initial opinion); on the other hand, $s_1=1$ indicates user $u$ is maximally open-minded. \nA continuous-time counterpart was proposed in \\cite{taylor1968towards}. \n\n{\\bf Bounded confidence model. } \nThe bounded-confidence opinion dynamics model considers a well-known social psychological phenomenon: \\textsl{confirmation bias} \n--- the tendency to focus on information that confirms one's preconceptions.\nThe most popular variant is the Hegselmann-Krause (HK) model.\nThe HK model assumes that individuals tend to interact only if their opinions lie within a bounded confidence interval $\\delta$ of each other.  \nOpinion update with bounded confidence interval $\\delta$ is modeled as: \n\\begin{align}\\label{eq:hegselmann}\n \\begin{aligned}\n    x_u(t+1) &= x_u(t) + \\vert N_u(t) \\vert^{-1} \\sum_{v\\in N_u(t)} \\big(x_v(t)-x_u(t)\\big),\n \\end{aligned}\n\\end{align}\nwith $N_u(t)=\\{v\\in\\mathcal{U} : \\, \\vert x_u(t)-x_v(t)\\vert \\leq \\delta\\}$ being the set of users \nwhose opinions fall within the bounded confidence interval of user $u$ at time step $t$,  \nwhere $\\vert N_u(x)\\vert$ is the number of users with opinions within distance $\\delta$.\nDepending on the confidence parameter $\\delta$ and the initial opinions, the interactions lead to different public opinion formations, \nnamely, consensus (agreement of all individuals), polarization (disagreement between two competing opinions), \nor clustering (fragmentation into multiple opinions).  \n\n\\textbf{Stochastic bounded confidence model (SBCM). }\nRecent works \\cite{schweighofer2020agent,liu2013social,baumann2021emergence} extend the bounded confidence model by incorporating stochastic interactions based on opinion differences. These models define a distribution for the probability of interaction between users as a function of the magnitude of the separation between their opinions, \nand sample interaction $z_{uv}^t$ from it.  \nThe common form \\cite{liu2013social,baumann2021emergence} is given by  \n\\begin{align}\\label{eq:p_uv}\np(z_{uv}^t=1) = \\frac{ \\vert x_u(t)-x_v(t) \\vert^{-\\rho} }{ \\sum_{v'} \\vert x_u(t)-x_{v'}(t) \\vert^{-\\rho} },\n\\end{align}\nwhere $p(z_{uv}^t=1)$ the probability of user $u$ selecting user $v$ as an interaction partner at time step $t$, and  \n$\\rho$ is the exponent parameter that determines the influence of opinion difference on the probabilities; \n$\\rho>0$ means users with similar opinions are more likely to interact and influence each other, and $\\rho<0$ means the opposite.  \n\n\n\n"
                },
                "subsection 3.2": {
                    "name": "Problem Definition",
                    "content": "\nWe consider a social network with a set of users $\\mathcal{U}=\\{1,\\ldots,U\\}$, each of whom has an opinion on a specific subject, \nwhich evolves through social interaction.\nWe are given a collection of social media posts (e.g., tweets) that mention a particular object.  \nEach post includes labeled opinion, either manually labeled or automatically estimated.  \nLet there be $C$ labels, $\\{1,...,C\\}$, one corresponding to each opinion class.  \nAn opinion label can be, for example, an opinion category $y\\in\\{1,2,3\\}$ \nindicating a ``positive'', ``neutral'' and ``negative'' opinion respectively.  \nFormally, a social media post is represented as the triple $(u,t,y)$,\nwhich means user $u$ made a post with opinion $y$, on a given subject matter, at time $t$. \nWe denote $\\mathcal{H}= \\{(u_i,t_i,y_i)\\}_{i=1}^I$ as the sequence of all posts made by the user up to time $T$. \n\nIn addition to the sequence of opinions, we can have \\textsl{additional side information}.  \nFor example, most social media services (e.g., Twitter) offer basic user information, \nsuch as the number of friends (followers) and profile description (i.e., a short bio). \nHere we consider the case of user profile descriptions.\nFormally, such descriptions are represented by a sentence with $\\vert d\\vert$ words $d=\\{w_1,...,w_{|d|}\\}$. \nWe denote a collection of user profiles by $\\mathcal{D}=\\{d^1,...,d^U\\}$. \n\nGiven the sequence of opinions $\\mathcal{H}$ during a given time-window $[0, T)$ and user profiles $\\mathcal{D}$, \nwe aim to predict users' opinions   \nat an arbitrary time $t^{\\ast}$ in the future time window $[T, T+\\Delta T]$. \n\n\n%\n%\n"
                }
            },
            "section 4": {
                "name": "Proposed method",
                "content": "\nIn this work, we propose a deep learning framework, termed \\textsf{SINN} (Sociologically-Informed Neural Network),  \nfor modeling and predicting the evolution of individuals' opinions in a social network. \n\nIn this paper, inspired by recently developed physics-informed neural networks \\cite{raissi2019physics},\nwe develop a deep learning framework that integrates both large-scale data from social media and prior scientific knowledge. \n\\cref{fig:overview} shows the overall architecture of \\textsf{SINN}. \nOpinion dynamics models, in their most common form, are expressed by difference equations (e.g., Equations~\\eqref{eq:degroot}~to~\\eqref{eq:p_uv}). \nWe first reformulate these difference equations of opinion dynamics as ordinary differential equations (ODEs), \nwhich are shown in \\textcolor[RGB]{246,195,28}{yellow} in \\cref{fig:overview}.  \nWe then approximate the evolution of individuals' opinions by a neural network (denoted by \\textcolor[RGB]{136,193,219}{light blue}). \nBy penalizing the loss function with the ODEs, the neural network is informed by a system of ODEs \nthat represent the opinion dynamics models; a concept drawn from theories of sociology and social psychology.  \nThe proposed framework is further combined with a language model (colored \\textcolor[RGB]{133,160,102}{green} in \\cref{fig:overview}) \nto fuse rich side information present in natural language texts (e.g., user profile descriptions).  \nWe also utilize low-rank approximation (\\textcolor[RGB]{0,0,139}{dark blue}) by factorizing the ODE parameters to capture the cluster structure of the social interaction network.\nThe parameters of our model are trained via backpropagation.  \n\nSeveral opinion dynamics models involve stochastic processes,  \nwhich encode random interactions between individuals. \nStochastic sampling poses a challenge for end-to-end training because it would prevent the gradient of the loss from being back-propagated.  \nIn order to back-propagate through the stochastic variables, we leverage the reparametrization trick (\\textcolor[RGB]{216,137,0}{orange} in \\cref{fig:overview}) \ncommonly used for gradient estimation \\cite{kusner2016gans}.  \nThis formulation makes the sampling process differentiable and hence the whole scheme can be trained in an end-to-end manner. \n\nWe elaborate the formulation of \\textsf{SINN} in \\cref{sec:formulation}, \nfollowed by parameter learning in \\cref{sec:learning}. \nThe prediction and optimization procedure is presented in \\cref{sec:app_proposed}. \n\n\n",
                "subsection 4.1": {
                    "name": "Model Formulation",
                    "content": "\\label{sec:formulation}\n\n",
                    "subsubsection 4.1.1": {
                        "name": "ODE constraint. ",
                        "content": "\nTo incorporate social scientific knowledge, we rewrite opinion dynamics models \nas ordinary differential equations (ODEs). \nIn the following, we formulate the ODEs by using some representative opinion dynamics models as guiding examples. \nNote though that our proposed framework can be generalized to any other opinion dynamics model. \nWe use $\\Lambda$ to denote the parameters of ODE. \n\n\\textbf{DeGroot model. } For the DeGroot model \\cite{degroot1974reaching}, \nwe can transform the difference equation of \\cref{eq:degroot} into an ODE as follows: \n\\begin{align}\\label{eq:ode_degroot0}\n\\frac{dx_u(t)}{dt} = \\sum_{v\\in\\mathcal{U}\\backslash u} a_{uv} x_v(t), \n\\end{align}\nwhere $t$ is time and $x_u(t)$ is the user $u$'s latent opinion at time $t$.  \nHigher values of $x_u(t)$ represent more positive opinions towards a given topic. \nHere we replace the discrete index $t$ (representing time step) of \\cref{eq:degroot} by the continuous variable $t$ (representing continuous time).  \nThe weight parameter, $a_{uv}$, indicates how much user $u$ is influenced by the opinion of user $v$. \n\\cref{eq:ode_degroot0} postulates that an individual's opinion evolves over $t$ as a result of being influenced by the opinions of others. \nWe can further modify \\cref{eq:ode_degroot0} to capture \\textsl{structural knowledge} on social interaction (i.e., cluster structure). \nReal-world social networks have been found to contain multiple groups/communities of users sharing a common context \\cite{DBLP:conf/kdd/KumarNT06}.  %sharing same beliefs and opinions\nTo discover the cluster structure of the social interaction network, \nwe apply matrix factorization to the matrix of weight parameter $A=\\{a_{uv}\\}\\in\\mathbb{R}^{U\\times U}$. \nIn particular, we factorize matrix $A$ into the two latent matrices of $M\\in\\mathbb{R}^{U\\times K}$ and $Q\\in\\mathbb{R}^{U\\times K}$: $A \\approx M^{\\top}Q$,\nwhere $K\\ll U$ is the dimension of the latent space. \nBased on this parametrization, \\cref{eq:ode_degroot0} reduces to  \n\\begin{align}\\label{eq:ode_degroot}\n\\frac{dx_u(t)}{dt} = \\sum_{v\\in\\mathcal{U}\\backslash u} \\textbf{m}_u^{\\top} \\textbf{q}_v x_v(t), \n\\end{align}\nwhere $\\textbf{m}_u\\in\\mathbb{R}^{K}$ and $\\textbf{q}_v\\in\\mathbb{R}^{K}$ correspond to \nthe $u$-th column and $v$-th column of $M$ and $Q$. \n\\cref{eq:ode_degroot} accounts for \\textsl{assimilation}, a well-known phenomenon in social psychology.  \n\n\\textbf{Friedkin-Johnsen (FJ) model. } \nFor the FJ model \\cite{friedkin1990social}, \nthe difference equation of \\cref{eq:friedkin} can be transferred \ninto an ODE of the form:  \n\\begin{align}\\label{eq:ode_fj}\n\\frac{x_u(t)}{dt} = s_u \\sum_{v\\in\\mathcal{U}\\backslash u} x_v(t) + (1-s_u) x_u(0)- x_u(t), \n\\end{align}\nwhere $x_u(0)$ is the innate opinion of user $u$ at time $t=0$.  \nIn implementing this, we set the first expressed opinion of each user $u$ as the innate opinion $x_u(0)$. \nThe interaction weight $a_{uv}$ denotes the influence user $u$ puts on $v$. \nThe scaler parameter, $s_u\\in[0,1]$, controls user $u$'s susceptibility to persuasion and so decides the degree of which the user is stubborn or open-minded. \n\n\\textbf{Bounded confidence model (BCM). }\nWe transform the bounded confidence model of Hegselmann and Krause \\cite{DBLP:journals/advcs/DeffuantNAW00} into an ODE as follows. \nSince the original model function (\\cref{eq:hegselmann}) is not differentiable, we replace the threshold function in \\cref{eq:hegselmann} with a sigmoid function.  \nFormally, \n\\begin{align}\\label{eq:ode_bcm}\n\\frac{dx_u(t)}{dt} = \\sum_{v\\in\\mathcal{U}} \\sigma\\big(\\delta-|x_u(t)-x_v(t)|\\big) \\big(x_v(t)-x_u(t)\\big), \n\\end{align}\nwhere $\\sigma(z)=(1+e^{-\\gamma z})^{-1}$ denotes a sigmoid function. \nAs the slope of sigmoid function $\\gamma$ approaches infinity, \\cref{eq:ode_bcm} will approach the thresholding function in the original model (\\cref{eq:hegselmann}).  \nThis model choice draws on the theory of \\textsl{confirmation bias}: Users tend to accept opinions that agree with theirs while discarding others. \nIn \\cref{eq:ode_bcm}, if two users are close enough in their opinions (within confidence threshold $\\delta$), \nthey are likely to interact and develop a closer opinion;  \notherwise, they are not likely to interact, and maintain their original opinions. \n\n\n\\textbf{Stochastic bounded confidence model (SBCM). }\nThe stochastic bounded confidence model (SBCM) involves sampling $z_{uv}^t\\sim p(z_{uv}^t)$ in \\cref{eq:p_uv},  \nwhich emulates stochastic interactions between users.  \nBefore triggering end-to-end training, we have to propagate the gradient through \nthe non-differentiable sampling operation $\\sim$ from a discrete distribution. Notice that as described in \\cref{sec:nn}, latent opinion $x_u(t)$ is modeled by a neural network that involves a set of parameters to be optimized.  \nTo deal with the problem of the gradient flow block, we leverage the reparameterization approach.  \nUsing the Gumbel-Softmax trick \\cite{jang2016categorical}, \nwe can replace the discrete samples ${\\bf z}_u^t=\\{z_{u1}^t,\\ldots,z_{uU}^t\\}$ \nwith differentiable one-hot approximation $\\tilde{\\bf z}_u^t=\\{\\tilde{z}_{u1}^t,\\ldots,\\tilde{z}_{uU}^t\\}\\in\\mathbb{R}^U$ as follows:  \n\\begin{align}\\label{eq:haty_u}\n\\tilde{\\bf z}_{u}^t = \\text{Softmax} \\big( [ \\log{({\\bf p}_{u}^t)} + {\\bf g}_{u} ] / \\tau \\big),  \n\\end{align}\nwhere ${\\bf p}_u^t\\in\\mathbb{R}^U$ consists of probability $p(z_{uv}^t)$ for a set of users $v\\in\\mathcal{U}$ defined in \\cref{eq:p_uv}. \n${\\bf g}_u\\in\\mathbb{R}^U$ is the noise vector whose element is i.i.d and generated from the Gumbel distribution\\footnote{Gumbel(0,1) distribution can be sampled using inverse transform sampling \\cite{jang2016categorical} by drawing $\\mu \\sim\\text{Uniform}(0,1)$ and then computing $g = -\\log(-\\log(\\mu))$}.  \nThis formulation allows randomness $\\textbf{g}_{u}$ to be separated from the deterministic function of the parameters. \nIn \\cref{eq:haty_u}, we relaxed the non-differentiable argmax operation to the continuous softmax function.\n$\\tau$ is a temperature parameter controlling the degree of approximation;   \nwhen $\\tau\\rightarrow 0$, the softmax function in \\cref{eq:haty_u} approaches argmax and ${\\bf z}_u^t$ becomes a one-hot vector. With the above formulation, \nwe can propagate gradients to probabilities $p_{uv}^t$ through the sampling operation. \nFinally, SBCM is rewritten as \n\\begin{align}\\label{eq:ode_sbcm}\n\\frac{dx_u(t)}{dt} = \\sum_{v\\in\\mathcal{U}} \\tilde{z}_{uv}^t \\big(x_v(t)-x_u(t)\\big).  \n\\end{align}\n\n"
                    },
                    "subsubsection 4.1.2": {
                        "name": "Neural network. ",
                        "content": "\\label{sec:nn}\nWe then construct a neural network for approximating the evolution of individuals' opinions. \nIn this paper, we employ a feedforward neural network (i.e., FNN) with $L$ layers. \nThe neural network takes time $t$ and user $u$ as inputs and outputs latent opinion $x_u(t)$ of user $u$ at that time, which is denoted by,  \n$x_u(t) \\approx f(t, {\\bf e}_u; \\theta_f)$, \nwhere $f(\\cdot)$ represents the neural network, ${\\bf e}_u$ is the one-hot encoding of a user index $u$, \nand $\\theta_f$ represents the trainable parameters, namely, a set of weights and biases. \nWe denote the output of neural network as $\\hat{x}_u(t)=f(t, \\textbf{e}_u; \\theta_f)$. \nIn our implementation, we adopt {\\sl tanh} activation for all layers. During training, we enforce the FNN output $\\hat{x}_u(t)$ to (i) reproduce the observed opinions; and \n(ii) satisfy the governing ODEs that represent the theoretical models of opinion dynamics. \n\nThe FNN can be extended to incorporate rich side information.  \nHere we assume that we are given individuals' profile descriptions. \nTo extract meaningful features from the profile descriptions, we adopt natural language processing techniques. \nWe obtain hidden user representation $\\textbf{h}_u=h(d^u,\\theta_h)$, where $h(\\cdot)$ is the language model, $d^u=\\{w_1^u,...,w_{|d^u|}^u\\}$ is the sequence of words, \n$\\theta_h$ is the trainable parameters. \nIn this work, we adopt a pre-trained BERT Transformer \\cite{devlin2018bert} as the language model \nand fine-tune an attention layer built on top of the pre-trained BERT model. \nThe architecture of the language model is detailed in \\cref{sec:app_language}.  \nThe hidden user representation is embedded into the FNN: \n$x_u(t) \\approx f(t, \\textbf{e}_u, \\textbf{h}_u; \\theta_f)$. \nAlthough different types of additional information may be available, \nthe above formulation focuses on user profile descriptions.  \nNotice that our formulation is flexible enough to accept any new information.  \nFor example, the FNN can be further integrated with deep learning models %such as LSTM   \nto capture the influence of mass media (e.g., news websites) from their contents (e.g., news articles).  \n\n%%%%%%%%%%%%%%%%\n{\\small\\begin{table*}[!t]\n\\caption{Statistics of the three real-world datasets used in this paper. }\n\\vspace{-2.5mm}\n\\begin{tabular}{lcccccc} \\toprule\n                 & \\# Users & \\# Posts & \\# Positive & \\# Negative & \\# Classes & Time span \\\\ \\midrule\nTwitter BLM & 1,721 & 16,858 & 12,072 & 4,786 & 4 & August 01, 2020 - March 31, 2021 \\\\\nTwitter Abortion & 2,359 & 24,217 & 8,822 & 15,395 & 4 & June 01, 2018 - April 30, 2021 \\\\\nReddit Politics & 1,335 & 22,563 & 5,724 & 16,839 & 2 & April 30, 2020 - November 03, 2020 \\\\\n\\bottomrule \n\\end{tabular}\\label{tab:stats}\n\\vspace{-2mm}\n\\end{table*}}\n%%%%%%%%%%%%%%%%\n\n\n"
                    }
                },
                "subsection 4.2": {
                    "name": "Parameter Learning",
                    "content": "\\label{sec:learning}\nThe proposed method, \\textsf{SINN}, is trained to approximate the observations of opinions \nwhile satisfying the sociological and social psychological constraints determined by the ODEs. We aim to learn the neural network parameters $\\theta_f$, \nthe language model parameters $\\theta_h$, as well as the ODE parameters $\\Lambda$.  \nThe total loss $\\mathcal{L}$ is thus composed of the data loss $\\mathcal{L}_{\\text{data}}$, \nthe ODE loss $\\mathcal{L}_{\\text{ode}}$,  \nand a regularization term, which is defined by\n{\\small\\begin{align}\\label{eq:totalloss}\n\\mathcal{L}(\\theta_f, \\theta_h, \\Lambda; \\mathcal{H}, \\mathcal{D}) = \n   \\mathcal{L}_{\\text{data}}(\\theta_f,\\theta_h; \\mathcal{H}, \\mathcal{D})  \n   + \\alpha \\mathcal{L}_{\\text{ode}}(\\theta_f,\\theta_h, \\Lambda) \n      + \\beta \\mathcal{R}(\\Lambda),\n\\end{align}}\n\\hspace{-1mm}where $\\mathcal{L}_{\\text{data}}$ measures the discrepancy between the labeled opinion and the neural network output. \nMeanwhile, $\\mathcal{L}_{\\text{ode}}$ measures the residual of ODEs, enforcing given sociological and social psychological constraints described by the ODEs.\nHyperparameter $\\alpha$ controls the balance between observed data $\\mathcal{H}$ and prior scientific knowledge.  \n$\\mathcal{R}(\\Lambda)$ is a regularization term and $\\beta$ is the regularization parameter. \nIn our experiment, the trade-off hyperparameters $\\alpha$ and $\\beta$ were chosen using grid search. \nWe elaborate on each term of the loss function below.  \n\n{\\bf Data Loss. }\nThe data loss term measures the deviation of predicted opinion $\\hat{y}_i$  \nfrom ground truth opinion label $y_i$.  \nWe project latent opinion $\\hat{x}_{u_i}(t_i)$ of user $u_i$ at time $t_i$ to a probability distribution over opinion class labels by: \n$\\hat{y}_i = \\sigma ( \\hat{x}_{u_i}(t_i) \\textbf{w}_{\\sigma} + \\textbf{b}_{\\sigma} )$, \nwhere $\\textbf{w}_{\\sigma}\\in\\mathbb{R}^C$ is the scale parameter, \n$\\textbf{b}_{\\sigma}\\in\\mathbb{R}^C$ is the bias parameter, and  \n$\\sigma$ is a mapping function (softmax or sigmoid activation function for multi-class and two-class opinion labels, respectively).  \nWe adopt cross-entropy loss as the data loss \nto measure the difference between the predicted label distribution $\\hat{y}_i$ with the truth label of opinion $y_i$: \n{\\small\\begin{align}\\label{eq:data_loss}\n\\mathcal{L}_{\\text{data}}(\\theta_f,\\theta_h; \\mathcal{H}, \\mathcal{D}) = \\frac{1}{I}\\sum_{i=1}^{I} L_{\\text{CE}}\\big( \\hat{y}_i, y_i \\big), \n\\end{align}}\n\\hspace{-1mm}where $L_{\\text{CE}}(\\cdot)$ denotes cross-entropy loss. \n\\cref{eq:data_loss} ensures that the neural network output coincides with the ground-truth opinion labels.  \n\n\n{\\bf ODE Loss. }\nThis ODE loss enforces given scientific constraints as described by the ODEs (\\cref{eq:ode_degroot,eq:ode_fj,eq:ode_bcm,eq:haty_u,eq:ode_sbcm}). \nTo ensure the difference between the left side and right side of all ODEs are equal to zero, \nwe minimize the mean squared error between them. \nTaking the DeGroot model in \\cref{eq:ode_degroot} as example, ODE loss is written as  \n{\\small\\begin{align}\\label{eq:loss}\n\\mathcal{L}_{\\text{ode}}(\\theta_f,\\theta_h, \\Lambda) = \\frac{1}{J}\\sum_{j=1}^J \\sum_{u\\in\\mathcal{U}} \n\\left( \\left. \\frac{d\\hat{x}_{u}(t)}{dt} \\right|_{t=\\tau_j} - \\sum_{v\\in\\mathcal{U}\\backslash u} \\textbf{w}_{u}^{\\top} \\textbf{h}_v \\hat{x}_v(\\tau_j) \\right)^2,\n\\end{align}}\n\\hspace{-1mm}where $\\{\\tau_1,...,\\tau_J\\}$ is a set of $J$ collocation points.\nWe randomly generate the collocation points from the time domain $\\tau_j\\in[0,T+\\Delta T]$.  \n$\\mathcal{L}_{\\text{ode}}$ measures the discrepancy of the ODEs at the $J$ collocation points,  \nwhich ensures that the neural network output satisfies the ODE constraints.  \nThe first derivative term $\\frac{d\\hat{x}_{u}(t)}{dt}$ in \\cref{eq:loss} can be easily computed using automatic differentiation \\cite{baydin2018automatic} \nin deep learning packages such as PyTorch \\cite{paszke2017automatic}. \n\n{\\bf Regularizer. }\nWe can use auxiliary constraints as the regularization term $\\mathcal{R}(\\cdot)$ in \\cref{eq:totalloss}. \nFor DeGroot model, to prevent over-fitting, we add the following regularization on the latent matrices: \n$\\mathcal{R}(\\Lambda) =  \\Vert M \\Vert_1 + \\Vert Q \\Vert_1$, \nwhere $\\Vert M \\Vert_1$ denotes the $l_1$-norm of the latent matrix $M$. \n\nThe parameter optimization is described in \\cref{sec:app_opt}. \n\n\n"
                }
            },
            "section 5": {
                "name": "Experiments",
                "content": "\nWe conduct qualitative and quantitative experiments to evaluate the performance of the proposed method, \\textsf{SINN} (Sociology-Informed Neural Network), \non both synthetic and real-world datasets. \nIn this section, we present our experimental settings and results.  \nOur source code and sample data are publicly available\\footnote{\\path{https://github.com/mayaokawa/opinion_dynamics}}. \n\n",
                "subsection 5.1": {
                    "name": "Datasets",
                    "content": "\nExperiments were conducted on three synthetic datasets of different settings and three real-world datasets collected from Twitter and Reddit. \nThe data preprocessing procedure is detailed in \\cref{sec:datasets}.\n\n",
                    "subsubsection 5.1.1": {
                        "name": "Synthetic datasets. ",
                        "content": " \nWe generate synthetic datasets using the stochastic bounded confidence model (SBCM). \nWe simulate the following three scenarios created with three different exponent parameters $\\rho$ of the SBCM in \\cref{eq:p_uv}: \ni) Consensus ($\\rho=-1.0$), \nii) Polarization ($\\rho=0.5$), and iii) Clustering ($\\rho=0.05$).  \nThe bottom panel of \\cref{fig:network_synthetic} shows the simulated opinion evolution for the Consensus dataset.  \nOur simulation involves $U=200$ users whose initial opinions are uniformly distributed. \nAll simulations were run for $T=200$ timesteps. \nFor a fair comparison, we converted the simulated continuous opinion values into five discrete labels and used these labels as the input of the models.  \nPlease refer to \\cref{sec:synthetic_dataset} for details.  \n\n"
                    },
                    "subsubsection 5.1.2": {
                        "name": "Real datasets. ",
                        "content": " \nWe use two Twitter datasets and one Reddit dataset. \n\\cref{tab:stats} shows the statistics of the three real-world datasets. \n\n\\textbf{Twitter datasets. } \nWe construct two \\textsl{Twitter datasets} by collecting tweets related to specific topics, i.e., {\\sl BLM} (BlackLivesMatter) and {\\sl Abortion},  \nthrough the Twitter public API\\footnote{\\label{note:twitter}https://developer.twitter.com/en/docs. Accessed on May 15, 2021.} using hashtags and keywords. \nFor {\\sl BLM}, we crawled tweets containing hashtag \\#BlackLivesMatter from \n%August 1, 2020, to March 1, 2021. \nAugust 1, 2020, to March 31, 2021. \nFor {\\sl Abortion} dataset, tweets were extracted between \nJune 1, 2018, and April 30, 2021, \nusing hashtag \\#Abortion. Each tweet contains date/time, user, and text.\nTo remove bots, and spam users, \nwe filtered the set of users based on the usernames and the number of posts. The preprocessing procedure is presented in \\cref{sec:twitter}. \nAll tweets are manually annotated into highly positive, positive, negative, highly negative towards the corresponding topic. \nAlong with the tweets, we obtained the \\textsl{profile descriptions} (i.e., the user-defined texts describing their Twitter accounts) for all the users.  \nFor each user, the profile description is represented as a collection of words.  \n\n\\textbf{Reddit datasets. } \nFor Reddit dataset, we collect posts from two Reddit communities (i.e., subreddits) for political discussion: \n\\texttt{r/libertarian} and \\texttt{r/conservative}. \nAll submissions were retrieved through the Pushshift API\\footnote{\\label{note:reddit}https://pushshift.io/. Accessed on April 30, 2021. } from April through November 2020, \nand include date/time, user, and subreddit.\nUsers with less than five posts and more than 1,000 posts were discarded, leaving 1,335 users.\nWe label posts in \\texttt{r/libertarian} 0 (negative towards conservatism) and \\texttt{r/conservative} 1 (positive). \n\n\n"
                    }
                },
                "subsection 5.2": {
                    "name": "Comparison methods",
                    "content": "\\label{sec:baselines}\nWe compare the prediction performance of \\textsf{SINN} with the following baselines: \n\\begin{itemize}\n\\item \\textsf{Voter} (Voter model) \\cite{DBLP:conf/ita/YildizPOS10}: \\textsf{Voter} is one of the simplest models of opinion dynamics. \nAt each time step, users select one of the users uniformly at random and copy her opinion. \n\\item \\textsf{DeGroot} (DeGroot model) \\cite{degroot1974reaching}: \\textsf{DeGroot} is a classical opinion dynamics model; it assumes users update their opinions iteratively to the weighted average of the others' opinions. \nWe analytically solve \\cref{eq:ode_degroot0} and fit the model parameter $a_{uv}$.  \n\\item \\textsf{AsLM} (Asynchronous Linear Model) \\cite{DBLP:conf/cikm/DeBBGC14}: \\textsf{AsLM} \nis a linear regression model where each opinion is regressed on the previous opinions. \n\\item \\textsf{SLANT} \\cite{DBLP:conf/nips/DeVGBG16}: \\textsf{SLANT} is a temporal point process model \nthat captures the influence of the other users' opinions. \nIt characterizes a self-exciting mechanism of the interaction between users and its time decay is based on intensity.  \n\\item \\textsf{SLANT+} \\cite{DBLP:conf/icdm/KulkarniADBG17}: \\textsf{SLANT+} is an extension of SLANT, which combines recurrent neural network (RNN) with a point process model.  \nRNN learns the non-linear evolution of users' opinions over time.\n\\item \\textsf{NN}: \\textsf{NN} is the proposed method without ODE loss $\\mathcal{L}_{\\text{ode}}$ in \\cref{eq:totalloss}, \nin which the trade-off hyperparameters are fixed to $\\alpha=0$ and $\\beta=0$. \n\\end{itemize}\n\nDetailed settings for the baselines are specified in \\cref{sec:baseline_settings}. \n\n"
                },
                "subsection 5.3": {
                    "name": "Experimental Setup",
                    "content": "\n\n",
                    "subsubsection 5.3.1": {
                        "name": "Evaluation Protocol. ",
                        "content": "\nFor each synthetic dataset, we split the training, validation, and test set in a proportion of 50\\%, 20\\%, 30\\% in chronological order.  \nWe divide each real-world dataset into train, validation, and test set with ratios of 70\\%, 10\\%, and 20\\%. \nTo evaluate the prediction performance of all models, we measure the accuracy (ACC) and the macro F1 score (F1),\nboth of which assess the agreement between predicted opinion classes and the ground truth. \n\n\n"
                    },
                    "subsubsection 5.3.2": {
                        "name": "Hyperparameters. ",
                        "content": "\nHyperparameters of all methods, including comparison methods and ours, are tuned by grid search on the validation set.\nFor the neural network models, we determine the number of layers $L$ in the range of $\\{3,5,7\\}$\nand the hidden layer dimension in the range of $\\{8,12,16\\}$.  \nFor our \\textsf{SINN}, we search in $\\{0.1,1.0,5.0\\}$ for the trade-off hyperparameters $\\alpha$ and $\\beta$; \n$\\{1,2,3\\}$ is taken as the dimension of the latent space $K$. \nWe test four opinion dynamics models (Equations~\\eqref{eq:ode_degroot}~to~\\eqref{eq:ode_sbcm}) and report the results of the best one. \nWe selected the pre-trained $\\text{BERT}_\\text{BASE–uncased}$ as the language model of our \\textsf{SINN} \n(See \\cref{sec:impl_detail} for the detailed setting). \nWe use the Adam optimizer \\cite{kingma2014adam} with learning rate 0.001 for all experiments.\n\n\n{\\small\\begin{table}[!t]\n\\caption{F1 score (F1) and Accuracy (ACC) \nfor predicting opinions from three synthetic datasets. \nHigher scores indicate better prediction performance.  \nThe best performance is highlighted in bold. % Our \\textsf{SINN} outperforms the six baselines. \n}\n\\vspace{-2.5mm}\n\\begin{tabular}{lcccccc} \\toprule\n                    & \\multicolumn{2}{c}{Consensus} & \\multicolumn{2}{c}{Polarization} & \\multicolumn{2}{c}{Clustering} \\\\ \n\\cmidrule(lr){2-3} \\cmidrule(lr){4-5}  \\cmidrule(lr){6-7}\n                    & ACC & F1 & ACC & F1 & ACC & F1  \\\\ \\midrule\n\\textsf{ Voter    } & 0.457 & 0.197 & 0.248 & 0.204 & 0.274 & 0.202 \\\\\n\\textsf{ DeGroot  } & 0.458 & 0.260 & 0.706 & 0.515 & 0.765 & 0.524 \\\\\n\\textsf{ AsLM     } & 0.155 & 0.264 & 0.113 & 0.079 & 0.477 & 0.325 \\\\\n\\textsf{ SLANT    } & 0.006 & 0.002 & 0.038 & 0.025 & 0.190 & 0.064 \\\\\n\\textsf{ SLANT+   } & 0.008 & 0.003 & 0.113 & 0.041 & 0.386 & 0.111 \\\\\n\\textsf{ NN       } & 0.771 & 0.426 & 0.603 & 0.451 & 0.875 & 0.817 \\\\\n\\textsf{ Proposed } & \\textbf{ 0.794} & \\textbf{ 0.574} & \\textbf{ 0.761} & \\textbf{ 0.738} & \\textbf{ 0.895} & \\textbf{ 0.843} \\\\\n\\bottomrule \n\\end{tabular}\\label{tab:error_syn}\n\\vspace{-2mm}\n\\end{table}}\n\n{\\small\\begin{table}[!t]\n\\caption{F1 score (F1) and Accuracy (ACC) \nfor predicting opinions from three real-world datasets.  \nHigher is better. \nThe best performance is highlighted in bold. % Our \\textsf{SINN} outperforms the six baselines. \n}\n\\vspace{-2.5mm}\n\\begin{tabular}{lcccccc} \\toprule\n                    & \\multicolumn{2}{c}{Twitter BLM} & \\multicolumn{2}{c}{Twitter Abortion} & \\multicolumn{2}{c}{Reddit Politics} \\\\ \n\\cmidrule(lr){2-3} \\cmidrule(lr){4-5}  \\cmidrule(lr){6-7}\n                    & ACC & F1 & ACC & F1 & ACC & F1  \\\\ \\midrule\n\\textsf{ Voter    } & 0.199 & 0.163 & 0.222 & 0.170 & 0.628 & 0.500 \\\\\n\\textsf{ DeGroot  } & 0.203 & 0.131 & 0.358 & 0.203 & 0.807 & 0.389 \\\\\n\\textsf{ AsLM     } & 0.092 & 0.117 & 0.435 & 0.195 & 0.789 & 0.441 \\\\\n\\textsf{ SLANT    } & 0.105 & 0.070 & 0.425 & 0.175 & 0.733 & 0.496 \\\\\n\\textsf{ SLANT+   } & 0.091 & 0.042 & 0.437 & 0.152 & 0.789 & 0.441 \\\\\n\\textsf{ NN       } & 0.336 & 0.237 & 0.441 & 0.369 & 0.875 & 0.824 \\\\\n\\textsf{ Proposed } & \\textbf{ 0.359} & \\textbf{ 0.246} & \\textbf{ 0.467} & \\textbf{ 0.412} & \\textbf{ 0.927} & \\textbf{ 0.884} \\\\\n\\bottomrule \n\\end{tabular}\\label{tab:error_real}\n\\vspace{-2mm}\n\\end{table}}\n\n\n\n"
                    }
                },
                "subsection 5.4": {
                    "name": "Quantitative Evaluation",
                    "content": "\nWe first report the prediction performance of different methods in terms of the two evaluation metrics on the three synthetic datasets in \\cref{tab:error_syn}. \nWe can observe that the proposed \\textsf{SINN} achieves the best results in terms of accuracy (ACC) and F1 score (F1). \nNone of the comparison methods perform robustly across all datasets. \n\\textsf{AsLM} achieves the second best F1 score among the baselines for the Consensus dataset \nbut fails on the Polarization and Clustering datasets. \n\\textsf{DeGroot} outperforms the other baseline methods on the Polarization dataset, \nwhile providing relatively poor performance for the Consensus and Clustering datasets.  \nIt is due to the fact that they depend on the specific choice of opinion dynamics model used.  \nIn contrast, \\textsf{SINN} is general and suits different opinion dynamics models, which yields better performance in all experiments. %all four \nIn an additional experiment (\\cref{sec:choice_odm}), we demonstrated that \\textsf{SINN} can be used to select one of a set of opinion dynamics models \nthat best captures hidden social interaction underlying data.  \n\n\\cref{tab:error_real} shows the results of the existing methods and \\textsf{SINN} on three real-world datasets.  \n\\textsf{SINN} achieves the best prediction performance in all cases.\n\\textsf{AsLM} gives almost the worst performance for Twitter BLM dataset. \nThis is because \\textsf{AsLM} is a linear model and cannot adequately depict the complex interaction between users.  \n\\textsf{SLANT} and \\textsf{SLANT+} have less predictive power since \nthey assume a fixed parametric form for social interaction.  \nCompared with these methods, deep learning-based models (i.e., \\textsf{NN} and \\textsf{SINN}) offer improved performance in terms of accuracy and F1 score. \nThe reason is that the deep learning-based models can learn the complex mechanisms of opinion formation in real-world social networks \ndue to the influence of external factors (e.g., mass media) and random behavior,  \nwhich are not considered in the other methods.  \nImportantly, \\textsf{SINN} yields better prediction performance than \\textsf{NN} across all the datasets.  \nCompared with \\textsf{NN}, \\textsf{SINN} achieves 11.7\\% improvement in terms of F1 for Twitter Abortion dataset. \nFor Reddit dataset, it produces a result of 88.4\\% in F1, which is an 7.3\\% improvement over \\textsf{NN}. \nThis result verifies the effectiveness of incorporating prior scientific knowledge into the deep learning model, \nas well as the advantage of our model design.  \nFrom these results, we can conclude that \\textsf{SINN} can learn from both data and theoretical models. \nWe perform a parameter study in \\cref{sec:sensitivity}.\n\n\n\n\n"
                },
                "subsection 5.5": {
                    "name": "Qualitative Evaluation via Case Studies",
                    "content": "\n% To illustrate the performance of our model intuitively, we compared the real values with the predicted values, shown in Figures 7 and 8, respectively.\n\\cref{fig:network_synthetic} depicts the temporal changes in population opinions and the networks of social interactions for the Consensus dataset. \nIn the Consensus dataset, the population reaches consensus (\\cref{fig:network_synthetic}(b)) \nthrough social interactions between users with opposite opinions (\\cref{fig:network_synthetic}(a) left). \nWe can see in \\cref{fig:network_synthetic}(a) that \\textsf{SINN} (right) can duplicate the actual interactions \nthat frequently occur between opposing users (left). \nAs can be seen from the node colors, \\textsf{SINN} (right) better captures the actual opinion dynamics (left) than \\textsf{NN} (middle). \nIn \\textsf{NN}, a large number of negative samples (light blue nodes) are mislabeled as neutral ones (yellow). \n\\textsf{SINN}, however, misclassifies only a few negative samples as neutral. This result validates the benefit of incorporating prior sociological and social psychological knowledge in the form of the ODEs.  \n\n\n\\cref{fig:hist_real} compares the distribution of opinion classes for Twitter Abortion dataset. \nFor comparison, we show actual and predicted class distributions on November 7, 2020. \nWe can see that \\textsf{SINN} better reproduces the ground-truth label distribution than \\textsf{NN}.  \nOn the other hand, \\textsf{NN} underestimates the number of highly negative samples (red bar).  \nThis further emphasizes the importance of using prior knowledge and the effectiveness of our approach. \n\n\\cref{fig:attention} visualizes the most important words in the profile descriptions identified by the attention mechanisms in \\textsf{NN} and \\textsf{SINN}   \nfor Twitter Abortion dataset.\nAs shown in this figure, NN tends to focus on meaningless or general words (e.g., ’https’, ’co’, ’year’), while SINN selects words (e.g., ’Pro’(-Life/Choice), ’Freedom’, ’Liberty’) that are more relevant to the given topic (i.e., Abortion).\nWith the help of prior scientific knowledge, \\textsf{SINN} can extract meaningful features from rich side information like textual descriptions to better predict opinion evolution. \nTo save space, we only report the results from one dataset in \\cref{fig:network_synthetic,fig:hist_real,fig:attention}. \n\n"
                }
            },
            "section 6": {
                "name": "Conclusion and Future work",
                "content": "\nIn this paper, we tackle the problem of modeling and predicting opinion dynamics in social networks.  \nWe develop a novel method that integrates sociological and social psychological knowledge and a data-driven framework, \nwhich is referred to as \\textsf{SINN} (Sociologically-Informed Neural Network).  \nOur approach is the first attempt to introduce the idea of physics-informed neural networks into opinion dynamics modeling.  \nSpecifically, we first reformulate opinion dynamics models into ordinary differential equations (ODEs). \nFor stochastic opinion dynamics models, we apply the reparameterization trick to enable end-to-end training. \nThen we approximate opinion values by a neural network and train the neural network approximation under the constraints of the ODE. \nThe proposed framework is integrated with matrix factorization and a language model to incorporate rich side information (e.g., user profiles) and structural knowledge (e.g., cluster structure of the social interaction network). \nWe conduct extensive experiments on three synthetic and three real-world datasets from social networks. \nThe experimental results demonstrate that the proposed method outperforms six baselines in predicting opinion dynamics. \n\nFor future work, we try to integrate an opinion mining method \\cite{medhat2014sentiment} into our framework  \nto automatically obtain opinion labels for social media posts.  \nThis avoids expensive annotations. % and time-consuming \nWe also plan to explore other side information such as mass media contents (e.g., news articles) and social graphs (e.g., follow/following relationship).  \nFurthermore, although this paper focuses on four representative opinion dynamics models, our framework can be generalized for any opinion dynamics model. \n\n%%%%%%%%%%%%%%%%\n\n%%%%%%%%%%%%%%%%\n\n%%\n\\bibliographystyle{ACM-Reference-Format}\n\\bibliography{KDD22} \n\n%%\n\\appendix\n%\\clearpage\n"
            },
            "section 7": {
                "name": "Supplemental Material",
                "content": "\n"
            },
            "section 8": {
                "name": "Proposed method",
                "content": "\\label{sec:app_proposed}\n\n",
                "subsection 8.1": {
                    "name": "Language Model",
                    "content": "\\label{sec:app_language}\nThe language model $h(\\cdot, \\theta_h)$ takes as input profile description $d^u$, and infers the hidden user representation $\\textbf{h}_u$.  \nUser profile description $d^u$ consists of a sequence of $|d^u|$ words $d^u=\\{w_1^u,...,w_{|d^u|}^u\\}$.  \nInput sentence $d^u$ is first padded to a fixed length of $N$ words with NULL tokens $d^u=\\{w_{1}^u,...,w_{N}^u\\}$ and tokenized. \nWe pick 25 as the max sentence length (i.e., profile description) $N$.  \nOriginal sentences with over $N=25$ words are truncated at the end. \nThis truncation would not significantly affect the final result,  \nbecause the most of profile descriptions contain no more than 25 words. \n91\\% of users in the Twitter BLM dataset have less than 25 words ($|d^u| < 25$) in their profile descriptions; \nlikewise 89\\% of users in the Twitter Abortion dataset.  \nIn this work, we select a pre-trained BERT Transformer \\cite{devlin2018bert} as the language model. \nThe input tokens $d^u=\\{w_{1}^u,...,w_{N}^u\\}$ are mapped into a sequence of $b$-dimensional word vectors $\\{{\\bf w}_{1}^u,...,{\\bf w}_{N}^u\\}$ \nthrough the pre-trained BERT model. \nWe add an attention layer on top of the last hidden layer of the frozen pre-trained BERT to learn the importance of each word in the sentence.  \nOur attention layer takes as input the word vectors ${\\bf w}_{n}^u$, \nand calculates the attention score for each vector: $e_n = {\\bf w}_n^{\\top} {\\bf E}$, \nwhere $\\textbf{E}\\in\\mathbb{R}^b$ is the context vector.  \nThe corresponding attention weight is defined as $\\tilde{e}_n = \\exp{(e_n)} / \\sum_{n'}\\exp{(e_{n'})}$. \nTo compute the hidden representation of user $u$, we compute the weighted average of the word embeddings of each word in the profile description:  \n$\\textbf{h}_u=\\sum_{n=1}^{N} \\tilde{e}_n {\\bf w}_{n}^u$.  \n\n"
                },
                "subsection 8.2": {
                    "name": "Optimization",
                    "content": "\\label{sec:app_opt}\nWe solve the following minimization problem to find optimal parameters of neural network $\\theta_f$, \nlanguage model $\\theta_h$ and the ODEs $\\Lambda$: \n{\\small\\begin{align}\n\\theta_f^{\\ast}, \\theta_h^{\\ast}, \\Lambda^{\\ast} = \\argmin_{\\{\\theta_f, \\theta_h, {\\bf \\Lambda}\\}} \\,\\,\\, \n\\mathcal{L}(\\theta_f, \\theta_h, \\Lambda; \\mathcal{H}, \\mathcal{D}),  \n\\end{align}}\n\\hspace{-1mm}where $\\{\\theta_f^{\\ast}, \\theta_h^{\\ast}, \\Lambda^{\\ast}\\}$ denote the optimal set of parameters. \nThe loss function can be minimized by using a backpropagation algorithm.  \nFor the stochastic bounded confidence model (SBCM), during the backward pass, we can obtain the gradient of the discrete sample \nby computing the gradient of our continuous approximation $\\tilde{\\bf z}_{u}^t$ in \\cref{eq:haty_u}.  \nThis allows the model to be optimized in an end-to-end manner. \n\n"
                },
                "subsection 8.3": {
                    "name": "Preidiction",
                    "content": "\\label{sec:pred}\nDuring the test phase, we use the trained neural network to predict the future opinion $y^{\\ast}$ of user $u^{\\ast}$ at time $t^{\\ast}$.  \nThe opinion can be predicted by calculating the hidden representation $\\textbf{h}_{u^{\\ast}}$ of user $u^{\\ast}$, and  \nfeeding it into the trained neural network: $y^{\\ast}=f(t^{\\ast}, \\textbf{e}_{u^{\\ast}}, \\textbf{h}_{u^{\\ast}}; \\theta_f^{\\ast})$, \nwhere $\\textbf{e}_{u^{\\ast}}$ is the one-hot encoding of user $u^{\\ast}$.  \n\n\n"
                }
            },
            "section 9": {
                "name": "Experiment",
                "content": "\n\n",
                "subsection 9.1": {
                    "name": "Datasets",
                    "content": "\\label{sec:datasets}\nExperiments were conducted on three synthetic datasets and three real-world datasets.\n\n",
                    "subsubsection 9.1.1": {
                        "name": "Synthetic dataset",
                        "content": "\\label{sec:synthetic_dataset}\nWe generated the syntetic datasets using the SBCM (stochastic opinion dynamics model) in \\cref{eq:hegselmann,eq:p_uv}. \nWe consider a social network with a set of $U=200$ users.  \nFor each dataset, the model was run for $T=200$ consecutive timesteps, resulting in a total of $I=40,000$ data points.  \nAt the first timestamp, initial opinions are randomly drawn from a uniform distribution between 0 and 1. \nIn each timestep from 2 to 200, we randomly choose 15 users who initiate interaction with other users. \nWhen individual $u$ initiates an interaction, a partner $v$ is selected from a set of $U=200$ users with probability $p_{uv}^t$ defined by \\cref{eq:p_uv}.  \nUser $u$ then updates her opinion $x_u(t + 1)$ at time $t + 1$ by weighted averaging her own opinion\n$x_u(t)$ and the chosen partner's opinion $x_v(t)$ at time $t$: \n\\begin{align}\nx_u(t+1) = x_u(t) + \\mu x_v(t),  \n\\end{align}\nwhere parameter $\\mu$ indicates the strength of influence.  \nWe set $\\mu=0.1$ in all the simulations. \nThe three datasets differ in the exponent parameter $\\rho$ that reach different final states:  \n$\\rho=-1.0$ (opinion consensus), $\\rho=0.1$ (opinion clustering), and $\\rho=1.0$ (opinion polarization). \nFinally, we divided the continuous opinion value into five classes according to the range \nas highly negative ($-1.0 \\text{--} -0.6$), negative ($-0.6 \\text{--} -0.2$), neutral ($-0.2 \\text{--} 0.2$), \npositive ($0.2 \\text{--} 0.6$), and highly positive ($0.6\\text{--}1.0$) and used these class labels as the input of the models.  \n\n\n\n\n"
                    },
                    "subsubsection 9.1.2": {
                        "name": "Twitter datasets",
                        "content": "\\label{sec:twitter}\nWe used Twitter API\\footnoteref{note:twitter} to collect English tweets posted by Twitter users, specific to BLM and Abortion.  \nThe replies and retweets are not included in these datasets. \nAll the tweets were pre-processed before annotation. \nFirst, we excluded the URLs, usernames (@user), and email addresses from the original tweets. \nTo remove corporate accounts, bot accounts, and spammers, we excluded users \nwho tweeted more than 30,000 tweets in total and less than three tweets,  \nand those that contain the words ``bot'' and ``news'' in their username.  \nTo filter news tweets, we also excluded the tweet that contained specific keywords \n(i.e., 'news', 'call', 'tell', 'say', 'announce', 'state', 'country', 'city', 'council'). \nMoreover, we eliminated duplicate tweets. \nAnnotators classified them into one of the following opinion classes: highly negative, negative, neutral, positive, highly positive, and not applicable.  \nThe ``not applicable'' label means the annotator could not make any judgment.  \nTweets with ``not applicable'' label were removed from the dataset. \nWe also eliminated the tweets with ``neutral'' label since many of them contain only irrelevant information. \nThe human-annotated labels are considered as the ground truth and the performance of the models is calculated with respect to these labels. \n\nTwitter profile descriptions are preprocessed as follows: \n(i) removing URLs, usernames and email addresses, \n(ii) eliminating stop words (``the'', ``is'', ``an'' etc.), \n(iii) remove extra white space, special characters, \n(iv) lowercasing, and \n(v) tokenization. \nWe employed the BERT basic tokenizer (See \\cref{sec:impl_detail}). \n"
                    },
                    "subsubsection 9.1.3": {
                        "name": "Reddit dataset",
                        "content": "\nThe Reddit dataset was drawn from social media platform Reddit.  Using the Reddit API\\footnoteref{note:reddit}, we collected a total of 70,876 Reddit posts \nbetween April 30th and November 3rd, 2020. \nWe focus on two major communities (subreddits) discussing conservative and libertarian politics: \n\\texttt{r/conservative} and \\texttt{r/libertarian}.  \nThe dataset included anonymous user IDs and subreddits, as well as timestamps. We preserved only those users who had between 5 and 1,000 posts, which resulted in a set of 1,335 users. \nWe assign label 0 (negative to conservative) to each post if it belongs to \\texttt{r/libertarian}, label 1 (positive) if it belongs to \\texttt{r/conservative}.  \n\n\n\n"
                    }
                },
                "subsection 9.2": {
                    "name": "Comparison methods",
                    "content": "\\label{sec:baseline_settings}\nIn this subsection, we describe the settings for the baselines. \n\nSome existing methods (i.e., \\textsf{Voter} and \\textsf{AsLM}) are designed for time series data observed at regular time intervals.  \nTo compare these methods, we treat the most recent opinion value as the one at the previous time step. \n\nMoreover, as the four baselines of \\textsf{DeGroot}, \\textsf{AsLM}, \\textsf{SLANT}, and \\textsf{SLANT+} can handle only continuous opinion values rather than discrete class labels,  \nwe transform discrete opinion labels to continuous values in $[-1,1]$ using linear scaling. \nAt the time of evaluation, we rescale the predicted opinion values back to the discrete opinion labels,  \nby grouping them into sets of discrete labels according to the range \nas highly negative ($-1.0 \\text{--} -0.6$), negative ($-0.6 \\text{--} -0.2$), neutral ($-0.2 \\text{--} 0.2$), \npositive ($0.2 \\text{--} 0.6$), and highly positive ($0.6\\text{--}1.0$). \n\nSince \\textsf{SLANT} and \\textsf{SLANT+} are primarily intended for predicting the opinion of the next post,  \nwe predict the long-term evolution of individuals' opinions during the future time window by iteratively predicting the next post. \nThe predicted opinion values are used as the input of the next time step. \nThis procedure is repeated until time $T+\\Delta T$. \n\n\n"
                },
                "subsection 9.3": {
                    "name": "Implementation details",
                    "content": "\\label{sec:impl_detail}\nAll code was implemented using Python 3.9 and PyTorch \\cite{paszke2017automatic}. \nWe conducted all experiments on a machine with four 2.8GHz Intel Cores and 16GB memory.  \nFor the neural networks (i.e., \\textsf{NN}, the FNN of our \\textsf{SINN}), \nwe used the same number of hidden units $N_u$ in all hidden layers.  \nFor the language model of \\textsf{SINN}, we used the tokenizer and pre-trained BERT from the Python library \n\\texttt{pytorch-pretrained-bert}\\footnote{https://github.com/huggingface/pytorch-pretrainedBERT}.  \nThe hidden size of $\\text{BERT}_\\text{BASE–uncased}$ is set to 768. \nThe input dimension of the attention layer was 768 and the output dimension was equal to the number of hidden units $N_u$ of the FNN $f(\\cdot)$.  \nThe model parameters were trained using the ADAM optimizer \\cite{kingma2014adam} \nwith $\\beta_1=0.9$, $\\beta_2=0.999$ and a learning rate of 0.001. \nBy default, we set 128 as the mini-batch size, 1000 as the number of epochs, and $J=1$ as the number of collocation points. \n\n\n\n\n\n\n"
                },
                "subsection 9.4": {
                    "name": "Additional Results",
                    "content": "\n",
                    "subsubsection 9.4.1": {
                        "name": "Sensitivity Analysis",
                        "content": "\\label{sec:sensitivity}\nWe investigate the sensitivity of \\textsf{SINN} on the core hyperparameters.  \nDue to space limitations, we present only the results on the real-world datasets in \\cref{fig:sensitivity_nn}.  \n\n%\\textbf{Trade-off Hyperparameters $\\alpha$ and $\\beta$. }\n%As the loss function $\\mathcal{L}$ of our proposed method involves multiple components, \n%we conduct several ablation experiments to investigate their individual contributions to the prediction performance.\n\\cref{fig:alpha} shows the prediction performance (in terms of F1) by varying the trade-off hyperparameter $\\alpha$ in \\cref{eq:totalloss}. \n\\textsf{SINN} achieves the best performance when $\\alpha=1.0$ for all the real-world datasets.  \n\nIn \\cref{fig:latent_dimension}, we vary the dimension of latent space $K$. \nOur \\textsf{SINN} gives the best results when $K=1$ for Twitter BLM dataset and Reddit Politics dataset; and $K=3$ for Twitter Abortion dataset.  \n% Further results on parameter study \n\n%\\textbf{Neural Network Architecture. }\n%Here we examine the effects of the hyperparameters for the neural network of \\textsf{SINN}. \nIn \\cref{fig:size_layer,fig:size_unit}, we show the impact of neural network architecture \nby varying the number of layers $L$ and units $N_u$ in the neural network.  \n%Based on the results in \\cref{fig:ablation_nn}, we set the number of layers $L$ as 16 and the number of units $N_u$ as 7 for all experiments.  \nWe can observe that \\textsf{SINN} yields robust performance with respect to the size of the neural network \n(i.e., the number of layers $L$ and the number of units per layer $N_u$). \n\nWe also evaluate the importance of side information (i.e., user profiles) by comparing \\textsf{SINN} with and without profile descriptions.\nFor Twitter Abortion dataset, the use of such information improves the F1 score by 10.2\\%. \nMeanwhile, it does not show improvement in prediction accuracy for Twitter BLM dataset.  \nIn future work, we will explore different choices of the language model. \n\n"
                    },
                    "subsubsection 9.4.2": {
                        "name": "Impact of Opinion Dynamics Models",
                        "content": "\\label{sec:choice_odm}\nWe evaluate different choices of opinion dynamics models on prediction performance.    \n% We evaluate different design choices of our model on classification accuracy. \n\\cref{fig:sensitivity_odm} reports the F1 results of \\textsf{SINN} with four different opinion dynamics models: DeGroot model, FJ model, \nbounded confidence model (BCM), stochastic opinion dynamics model (SBCM). \n%We report the F1 results on the synthetic datasets in \\cref{fig:ablation_odm}. \nFor all the synthetic datasets, the SBCM outperforms all other opinion dynamics models explored in this study. \nThat is, \\textsf{SINN} successfully identifies the original opinion dynamics model that generated the synthetic datasets (i.e., SBCM) from a set of candidates. \n\\textsf{SINN} also gives the best results on the SBCM for the real-world datasets.\nIt suggests the importance of considering the stochastic nature of social interaction.  \n\n\n"
                    }
                }
            }
        },
        "figures": {
            "fig:overview": "\\begin{figure*}[th]\n  \\includegraphics[width=0.73\\linewidth]{SINN_overview.pdf}\n\\vspace{-2mm}\n\\caption{Overall architecture of our proposed method, \\textsf{SINN} (Sociologically-Informed Neural Network). }\\label{fig:overview} \n\\vspace{-3.5mm}\n\\end{figure*}",
            "fig:network_synthetic": "\\begin{figure}[!t]\n  \\includegraphics[width=0.9\\linewidth]{network_estimated.pdf}\n\\vspace{-4mm}\n\\caption{\n(a) Interactions between users at time $t=160$, \nwhich is simulated (left) and predicted by \\textsf{NN} (middle) and \\textsf{SINN} (right). \nNodes represent users where the color indicates their opinion classes.  \nThe left graph illustrates the true social interactions during $t\\in[160,170]$. \nThe middle graph shows the opinion classes predicted by \\textsf{NN}. \nThe right graph visualizes the opinion classes and the interaction parameter $\\tilde{z}_{uv}^t$ of SBCM (\\cref{eq:ode_sbcm}) learned by \\textsf{SINN}. \n(b) Temporal evolution of individuals' opinions simulated in Consensus dataset. \nEach curve represents one individual. \n}\\label{fig:network_synthetic} \n\\vspace{-5mm}\n\\end{figure}",
            "fig:hist_real": "\\begin{figure}[!t]\n  \\includegraphics[width=0.89\\linewidth]{hist_0.85.png}\n\\vspace{-3mm}\n\\caption{Distribution of opinion classes on November 7, 2020 for Twitter Abortion dataset. \n}\\label{fig:hist_real} \n\\vspace{-5mm}\n\\end{figure}",
            "fig:attention": "\\begin{figure}[!t]\n  \\subfigure[\\textsf{NN}]{\\centering\\includegraphics[width=0.43\\linewidth]{attention_NN.png}\\label{fig:attention_NN}}\\hspace{4mm}\n  \\subfigure[Our \\textsf{SINN}]{\\centering\\includegraphics[width=0.43\\linewidth]{attention_Proposed.png}\\label{fig:attention_Proposed}}\n\\vspace{-4mm}\n\\caption{ \nImportant words in profile descriptions identified by attention mechanisms in (a) \\textsf{NN} and (b) \\textsf{SINN} for Twitter Abortion dataset.\n% Words are highlighted according to attention scores.\n}\\label{fig:attention} \n\\vspace{-6.5mm}\n\\end{figure}",
            "fig:sensitivity_nn": "\\begin{figure}[t]\n    \\centering\n    \\subfigure[Trade-off parameter $\\alpha$]{\\includegraphics[width=0.23\\textwidth]{sensitivity_alpha.png}\\label{fig:alpha}\\hspace{1mm}} \n    %\\subfigure[Trade-off parameter $\\beta$]{\\includegraphics[width=0.23\\textwidth]{sensitivity_beta.png}\\label{fig:beta}\\hspace{1mm}} \n    \\subfigure[Dimension of latent space $K$]{\\includegraphics[width=0.23\\textwidth]{sensitivity_latent_dimension.png}\\label{fig:latent_dimension}} \n    \\subfigure[number of layers $l$]{\\includegraphics[width=0.23\\textwidth]{sensitivity_size_layer.png}\\label{fig:size_layer}\\hspace{1mm}} \n    \\subfigure[Number of units $N_u$]{\\includegraphics[width=0.23\\textwidth]{sensitivity_size_unit.png}\\label{fig:size_unit}} \n    \\vspace{-3mm}\n    \\caption{Prediction performance with different values of hyperparameters using F1 score. }\n    \\label{fig:sensitivity_nn}\n\\vspace{-3mm}\n\\end{figure}",
            "fig:sensitivity_odm": "\\begin{figure}[t]\n    \\centering\n    \\subfigure[Synthetic datasets]{\\includegraphics[width=0.23\\textwidth]{sensitivity_odm_synthetic.png}\\label{fig:odm_synthetic}\\hspace{1mm}} \n    \\subfigure[Real-world datasets]{\\includegraphics[width=0.23\\textwidth]{sensitivity_odm_real.png}\\label{fig:odm_real}} \n        \\vspace{-3mm}\n    \\caption{Prediction performance with different opinion dynamics models using F1 score. }\n    \\label{fig:sensitivity_odm}\n\\vspace{-3mm}\n\\end{figure}"
        },
        "equations": {
            "eq:eq:degroot": "\\begin{align}\\label{eq:degroot}\nx_u(t+1) = x_u(t) + \\sum_{v\\in\\mathcal{U}\\backslash u} a_{uv} x_v(t), \n\\end{align}",
            "eq:eq:friedkin": "\\begin{align}\\label{eq:friedkin}\nx_u(t+1) = s_u \\sum_{v\\in\\mathcal{U}\\backslash u} x_v(t) + (1-s_u) x_u(0), \n\\end{align}",
            "eq:eq:hegselmann": "\\begin{align}\\label{eq:hegselmann}\n \\begin{aligned}\n    x_u(t+1) &= x_u(t) + \\vert N_u(t) \\vert^{-1} \\sum_{v\\in N_u(t)} \\big(x_v(t)-x_u(t)\\big),\n \\end{aligned}\n\\end{align}",
            "eq:eq:p_uv": "\\begin{align}\\label{eq:p_uv}\np(z_{uv}^t=1) = \\frac{ \\vert x_u(t)-x_v(t) \\vert^{-\\rho} }{ \\sum_{v'} \\vert x_u(t)-x_{v'}(t) \\vert^{-\\rho} },\n\\end{align}",
            "eq:eq:ode_degroot0": "\\begin{align}\\label{eq:ode_degroot0}\n\\frac{dx_u(t)}{dt} = \\sum_{v\\in\\mathcal{U}\\backslash u} a_{uv} x_v(t), \n\\end{align}",
            "eq:eq:ode_degroot": "\\begin{align}\\label{eq:ode_degroot}\n\\frac{dx_u(t)}{dt} = \\sum_{v\\in\\mathcal{U}\\backslash u} \\textbf{m}_u^{\\top} \\textbf{q}_v x_v(t), \n\\end{align}",
            "eq:eq:ode_fj": "\\begin{align}\\label{eq:ode_fj}\n\\frac{x_u(t)}{dt} = s_u \\sum_{v\\in\\mathcal{U}\\backslash u} x_v(t) + (1-s_u) x_u(0)- x_u(t), \n\\end{align}",
            "eq:eq:ode_bcm": "\\begin{align}\\label{eq:ode_bcm}\n\\frac{dx_u(t)}{dt} = \\sum_{v\\in\\mathcal{U}} \\sigma\\big(\\delta-|x_u(t)-x_v(t)|\\big) \\big(x_v(t)-x_u(t)\\big), \n\\end{align}",
            "eq:eq:haty_u": "\\begin{align}\\label{eq:haty_u}\n\\tilde{\\bf z}_{u}^t = \\text{Softmax} \\big( [ \\log{({\\bf p}_{u}^t)} + {\\bf g}_{u} ] / \\tau \\big),  \n\\end{align}",
            "eq:eq:ode_sbcm": "\\begin{align}\\label{eq:ode_sbcm}\n\\frac{dx_u(t)}{dt} = \\sum_{v\\in\\mathcal{U}} \\tilde{z}_{uv}^t \\big(x_v(t)-x_u(t)\\big).  \n\\end{align}",
            "eq:1": "\\begin{align}\nx_u(t+1) = x_u(t) + \\mu x_v(t),  \n\\end{align}"
        }
    }
}