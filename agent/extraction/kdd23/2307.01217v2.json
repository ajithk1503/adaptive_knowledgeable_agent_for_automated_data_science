{
    "meta_info": {
        "title": "FedCP: Separating Feature Information for Personalized Federated  Learning via Conditional Policy",
        "abstract": "Recently, personalized federated learning (pFL) has attracted increasing\nattention in privacy protection, collaborative learning, and tackling\nstatistical heterogeneity among clients, e.g., hospitals, mobile smartphones,\netc. Most existing pFL methods focus on exploiting the global information and\npersonalized information in the client-level model parameters while neglecting\nthat data is the source of these two kinds of information. To address this, we\npropose the Federated Conditional Policy (FedCP) method, which generates a\nconditional policy for each sample to separate the global information and\npersonalized information in its features and then processes them by a global\nhead and a personalized head, respectively. FedCP is more fine-grained to\nconsider personalization in a sample-specific manner than existing pFL methods.\nExtensive experiments in computer vision and natural language processing\ndomains show that FedCP outperforms eleven state-of-the-art methods by up to\n6.69%. Furthermore, FedCP maintains its superiority when some clients\naccidentally drop out, which frequently happens in mobile settings. Our code is\npublic at https://github.com/TsingZ0/FedCP.",
        "author": "Jianqing Zhang, Yang Hua, Hao Wang, Tao Song, Zhengui Xue, Ruhui Ma, Haibing Guan",
        "link": "http://arxiv.org/abs/2307.01217v2",
        "category": [
            "cs.LG",
            "cs.AI"
        ],
        "additionl_info": "Accepted by KDD 2023"
    },
    "latex_extraction": {
        "content": {
            "section 1": {
                "name": "Introduction",
                "content": "\n\\label{sec:intro}\nNowadays, many web-based services, such as personalized recommendations~\\cite{zhang2019deep, zhang2021tlsan, zhang2023lightfr}, benefit from artificial intelligence (AI) and the huge volume of data generated locally on various clients~\\cite{kairouz2019advances}, \\eg, hospitals, mobile smartphones, internet of things, \\etc. At the same time, legislation endeavors on data privacy protection continue to increase, \\eg, General Data Protection Regulation (GDPR) of Europe~\\cite{regulation2016regulation} and California Consumer Privacy Act (CCPA)~\\cite{de2018guide}. Due to privacy concerns and regulations, centralized AI faces significant challenges~\\cite{nguyen2021federated, yang2020federated}. On the other hand, because of the data sparsity problem, it is hard to learn a reasonable model for a given task independently on each client~\\cite{tan2022towards, kairouz2019advances, li2020federated}. \n\nFederated learning (FL) is proposed as a collaborative learning paradigm~\\cite{mcmahan2017communication, kairouz2019advances, zhang2022fedala, ye2023feddisco} to utilize local data on the participating clients for the global model training without sharing the private data of clients. As one of the famous FL methods, FedAvg conducts four steps in each communication iteration: (1) The server sends the old global model parameters to the selected clients. (2) Each selected client initializes the local model with the received global parameters and trains the local model on local data. (3) The selected clients upload the updated local model parameters to the server. (4) The server generates new global model parameters by aggregating the received client model parameters. However, in practice, the data on the client is typically not independent and identically distributed (non-IID) as well as unbalanced~\\cite{kairouz2019advances, li2020federated, zhang2022fedala, yang2019federated}. With this statistical heterogeneity challenge~\\cite{li2020federated, tan2022towards}, the single global model in traditional FL methods, such as FedAvg, can hardly fit the local data well on each client and achieve good performance~\\cite{huang2021personalized, t2020personalized}. \n\nTo meet the personalized demand of each client and address the challenge of statistical heterogeneity in FL, personalized federated learning (pFL) comes along that focuses on learning personalized models rather than a single global model~\\cite{t2020personalized, li2021fedphp}. Most existing pFL methods consider the global model as a container that stores the global information and enriches the personalized models with the parameters in the global model. \nHowever, they only focus on client-level model parameters, \\ie, the global/personalized model to exploit the global/personalized information. Specifically, the meta-learning-based methods (such as Per-FedAvg~\\cite{NEURIPS2020_24389bfe}) only fine-tune global model parameters to fit local data, and the regularization-based methods (such as pFedMe~\\cite{t2020personalized}, FedAMP~\\cite{huang2021personalized}, and Ditto~\\cite{li2021ditto}) only regularize model parameters during local training. \nAlthough personalized-head-based methods (such as FedPer\\cite{arivazhagan2019federated}, FedRep~\\cite{collins2021exploiting}, and FedRoD~\\cite{chen2021bridging}) explicitly split a backbone into a global part (feature extractor) and a personalized part (head), they still focus on exploiting global and personalized information in model parameters rather than the source of information: \\textbf{\\textit{data}}. \nAs the model is trained on data, \\textbf{the global/personalized information in model parameters is derived from client data}. In other words, the heterogeneous data on clients contains both global and personalized information. As shown in \\Cref{fig:intro}, widely-used colors, \\eg, \\textcolor{blue__}{blue}, and rarely-used colors, \\eg, \\textcolor{purple_}{purple} and \\textcolor{pink_}{pink}, contain global information and personalized information in images, respectively. \n\n\n\nTo exploit the global and personalized information in the data separately, we propose a \\textbf{Federated Conditional Policy (\\Method)} method based on conditional computing techniques~\\cite{guo2019spottune, oreshkin2018tadam}. Since the dimension of raw input data is much larger than the feature vector extracted by the feature extractor, we focus on the feature vector for efficiency. As the proportion of the global and personalized information in the features differ among samples and clients, we propose an auxiliary \\textbf{Conditional Policy Network (\\Policy)} to generate the sample-specific policy for feature information separation. Then, we process the global feature information and personalized feature information by a global head and a personalized head in different routes, respectively, as shown in \\Cref{fig:intro}. We store the personalized information in the personalized head and reserve the global information by freezing the global head without locally training it. \n% We consider the feature information that fits the global head well as the global one and the remaining feature information as the personalized one. \nThrough end-to-end learning, \\Policy automatically learns to generate the sample-specific policy. We visualize six cases in \\Cref{sec:act} to show the effectiveness of the feature information separation ability. \n\nTo evaluate \\Method, we conduct extensive experiments on various datasets in two widely-used scenarios~\\cite{mcmahan2017communication, li2021model}, \\ie, the pathological settings and the practical settings. \\Method outperforms eleven state-of-the-art (SOTA) methods in both scenarios, and we analyze the reasons in \\Cref{sec:main_exp}. \nIn summary, our key contributions are: \n\n\\begin{itemize}\n    \\item To the best of our knowledge, we are the first to consider personalization on the sample-specific feature information in FL. It is more fine-grained than using the client-level model parameters in most existing FL methods. \n    \\item We propose a novel \\Method that generates a sample-specific policy to separate the global information and personalized information in features on each client. It processes these two kinds of feature information through a frozen global head and a personalized head on each client, respectively. \n    \\item We conduct extensive experiments in computer vision (CV) and natural language processing (NLP) domains to show the effectiveness of \\Method. Besides, \\Method keeps its superior performance even when some clients accidentally drop out.\n\\end{itemize}\n\n"
            },
            "section 2": {
                "name": "Related Work",
                "content": "\n\\label{sec:related}\n\n",
                "subsection 2.1": {
                    "name": "Personalized Federated Learning",
                    "content": "\nTo collaboratively learn models among clients on their local private data while protecting privacy, traditional FL methods, such as FedAvg~\\cite{mcmahan2017communication} and FedProx~\\cite{MLSYS2020_38af8613}, come along. Based on FedAvg, FedProx improves the stability of the FL process through a regularization term. However, in practice, statistical heterogeneity widely exists in the FL setting, so it is hard to learn a single global model that fits well with the local data in each client~\\cite{kairouz2019advances, huang2021personalized, t2020personalized}. \n\nRecently, pFL has attracted increasing attention for its ability to tackle statistical heterogeneity in FL~\\cite{kairouz2019advances, hahn2022connecting}. Among \\textbf{meta-learning-based methods}, Per-FedAvg~\\cite{NEURIPS2020_24389bfe} learns an initial shared model as the global model that satisfies the learning trend for each client. \nAmong \\textbf{regularization-based methods}, pFedMe~\\cite{t2020personalized} learns an additional personalized model locally for each client with Moreau envelopes. In addition to learning only one global model for all clients, FedAMP~\\cite{huang2021personalized} generates one server model for one client through the attention-inducing function to find similar clients. In Ditto~\\cite{li2021ditto}, each client learns its personalized model locally with a proximal term to fetch global information from global model parameters. Among \\textbf{personalized-head-based methods}, FedPer\\cite{arivazhagan2019federated} and FedRep~\\cite{collins2021exploiting} learn a global feature extractor and a client-specific head. The former locally trains the head with the feature extractor, while the latter locally fine-tunes the head until convergence before training the feature extractor in each iteration. To bridge traditional FL and pFL, FedRoD~\\cite{chen2021bridging} explicitly learns two prediction tasks with a global feature extractor and two heads. It uses the balanced softmax (BSM) loss~\\cite{ren2020balanced} for the global prediction task and processes the personalized task by the personalized head. Among \\textbf{other pFL methods}, FedFomo~\\cite{zhang2020personalized} calculates the client-specific weights for aggregation on each client using the personalized models from other clients. FedPHP~\\cite{li2021fedphp} locally aggregates the global model and the old personalized model using a moving average to keep the historical personalized information. It also transfers the information in the global feature extractor through the widely-used maximum mean discrepancy (MMD) loss~\\cite{gretton2006kernel, qin2019pointdan}. \nThese above pFL methods only focus on exploiting global and personalized information of model parameters but do not dig deep into data. \n\n\n\n\n"
                },
                "subsection 2.2": {
                    "name": "Conditional Computing",
                    "content": "\n\nConditional computing is a technique that introduces dynamic characteristics into models according to task-dependent conditional inputs~\\cite{liu2018dynamic, guo2019spottune, oreshkin2018tadam}. Formally, given a conditional input $C$ (\\eg, image/text, model parameter vector, or other auxiliary information) and an auxiliary module $AM(\\cdot; \\theta)$, a signal $S$ can be generated by $S = AM(C; \\theta)$ and used to interfere with models, such as dynamic routing and feature adaptation. \n\nTo activate specific parts in a model and process the data in different routes for each input sample, many approaches generate sample-specific policies for route selection. Conditioned on the input image, ConvNet-AIG~\\cite{veit2018convolutional} can decide which layers are needed during inference using Gumbel Softmax~\\cite{jang2016categorical}. \nWith a policy network, SpotTune~\\cite{guo2019spottune} makes decisions for each image to select which blocks in a pre-trained residual network to fine-tune. \n\nInstead of focusing on dynamic model topology, some methods propose adapting the learned features. In the few-shot learning field, TADAM~\\cite{oreshkin2018tadam} adapts the features through an affine transformation conditioned by the extracted task representation. In the video object detection field, TMA~\\cite{hua2021temporal} proposes a learnable affine transformation conditioned by video frames for feature adaptation. \n\nThe above methods use conditional computing techniques but are designed for centralized AI scenarios and specific tasks. Combining the ideas of dynamic routing and feature adaptation, we devise the \\Policy module in our \\Method to separate global feature information and personalized feature information then process them in different routes for pFL scenarios and various tasks. \n\n\n"
                }
            },
            "section 3": {
                "name": "Method",
                "content": "\n\\label{sec:method}\n\n",
                "subsection 3.1": {
                    "name": "Overview",
                    "content": "\nIn statistically heterogeneous pFL settings, non-IID and unbalanced data exist on $N$ clients, who train their personalized models ${\\bm W}_1, \\ldots, {\\bm W}_N$ in a collaborative manner. $N$ clients own private datasets $\\mathcal{D}_1, \\ldots, \\mathcal{D}_N$, respectively, which are sampled from $N$ distinct distributions without overlapping. \n\nSimilar to FedPer\\cite{arivazhagan2019federated},  FedRep~\\cite{collins2021exploiting}, and  FedRoD~\\cite{chen2021bridging}, we split the backbone into a feature extractor $f:\\mathbb{R}^D \\rightarrow \\mathbb{R}^K$, that maps input samples to feature space and a head $g:\\mathbb{R}^K \\rightarrow \\mathbb{R}^C$, which maps from low-dimensional feature space to a label space. Following FedRep, we consider the last fully connected (FC) layer in each given backbone as the head. $D$, $K$, and $C$ are the dimension of the input space, feature space, and label space, respectively. $K$ is determined by the given backbone and typically $D \\gg K$. \n\nDifferent from FedPer, FedRep and FedRoD, on client $i$, we have a global feature extractor (parameterized by ${\\bm W}^{fe}$), a global head (parameterized by ${\\bm W}^{hd}$), a personalized feature extractor (parameterized by ${\\bm W}^{fe}_i$), a personalized head (parameterized by ${\\bm W}^{hd}_i$), and a \\Policy (parameterized by ${\\bm \\Theta}_i$). \nSpecifically, \\textbf{for the feature extractors}, we initialize ${\\bm W}^{fe}_i$ by overwriting it with corresponding global parameters ${\\bm W}^{fe}$ in each iteration, and then locally learn the personalized feature extractor. The feature generated by the changing personalized feature extractor may not fit the frozen global head during local learning. Thus, we freeze the global feature extractor after receiving and align the features outputted by the personalized feature extractor to the ones generated by the global feature extractor through the MMD loss, as shown in \\Cref{fig:cp_a}. \\textbf{For the global head}, we freeze it after it has been initialized by ${\\bm W}^{hd}$ to preserve global information. \nIn short, at the start of each iteration, we overwrite ${\\bm W}^{fe}_i$ by new ${\\bm W}^{fe}$ then freeze ${\\bm W}^{fe}$ and ${\\bm W}^{hd}$. \nAs shown by the non-transparent module in \\Cref{fig:cp_a}, the personalized model used for inference (parameterized by ${\\bm W}_i$) consists of the personalized feature extractor, the global head, the personalized head, and the \\Policy, \\ie, ${\\bm W}_i := \\{{\\bm W}^{fe}_i, {\\bm W}^{hd}, {\\bm W}^{hd}_i, {\\bm \\Theta}_i\\}$. The frozen global feature extractor is only used for local learning and is not part of the personalized model. We omit iteration notation, sample index notation, and biases for simplicity. Given the local loss $\\mathcal{F}_i$ (described later), our objective is\n\\begin{equation}\n    \\{{\\bm W}_1, \\ldots, {\\bm W}_N\\} = \\argmin \\ \\mathcal{G}(\\mathcal{F}_1, \\ldots, \\mathcal{F}_N).\n\\end{equation}\nTypically, $\\mathcal{G}(\\mathcal{F}_1, \\ldots, \\mathcal{F}_N) = \\sum^{N}_{i=1} n_i \\mathcal{F}_i$, $n_i = |\\mathcal{D}_i| / \\sum^{N}_{j=1} |\\mathcal{D}_j|$, and $|\\mathcal{D}_i|$ is the sample amount on client $i$. \n\n\n"
                },
                "subsection 3.2": {
                    "name": "Federated Conditional Policy (\\Method)",
                    "content": "\n\\label{sec:fcp}\n\nWe focus on feature information separation for the feature vector\n\\begin{equation}\n    {\\bm h}_i = f({\\bm x}_i; {\\bm W}^{fe}_i), \\forall ({\\bm x}_i, y_i) \\in \\mathcal{D}_i. \\label{eq:feat}\n\\end{equation}\nDue to statistical heterogeneity, ${\\bm h}_i \\in \\mathbb{R}^K$ contains global and personalized feature information. To separately exploit these two kinds of information, we propose \\textbf{\\Method} that learns sample-specific separation in an end-to-end manner, as shown in \\Cref{fig:cp}. \n\n",
                    "subsubsection 3.2.1": {
                        "name": "Separating feature information",
                        "content": " Guided by the global information in the frozen global head and the personalized information in the personalized head, the \\Policy (the core of \\Method) can learn to generate the sample-specific policy and separate the global and personalized information in ${\\bm h}_i$ automatically. \n\nSpecifically, we devise \\Policy as the concatenation of an FC layer and a layer-normalization layer~\\cite{ba2016layer} followed by the ReLU activation function~\\cite{li2017convergence}, as shown in \\Cref{fig:cp_a}. On client $i$, we generate the sample-specific policy by\n\\begin{equation}\n    \\{{\\bm r}_i, {\\bm s}_i\\} := {\\rm \\Policy}(\\mathcal{C}_i; {\\bm \\Theta}_i), \\label{eq:policy}\n\\end{equation}\nwhere ${\\bm r}_i\\in \\mathbb{R}^K, {\\bm s}_i\\in \\mathbb{R}^K, r^k_{i} + s^k_{i} = 1, \\forall k \\in [K]$, and $\\mathcal{C}_i \\in \\mathbb{R}^K$ is the sample-specific input for \\Policy. We describe the details of the input $\\mathcal{C}_i$ and the output $\\{{\\bm r}_i, {\\bm s}_i\\}$ as follows. \n\n$\\mathcal{C}_i$ is generated to achieve the sample-specific characteristic and introduce personalized (client-specific) information. We can directly obtain the sample-specific vector ${\\bm h}_i$, so we only introduce how to obtain the client-specific information here. \nBased on FedRep and FedRoD, the parameters in the personalized head, \\ie, ${\\bm W}^{hd}_i$, naturally contain client-specific information. However, ${\\bm W}^{hd}_i$ is a matrix, not a vector. Thus, we generate ${\\bm v}_i$ by reducing the dimension of ${\\bm W}^{hd}_i$. \nRecall that a head is an FC layer in \\Method, \\ie, ${\\bm W}^{hd}_i \\in \\mathbb{R}^{C\\times K}$, so the $k$th column of ${\\bm W}^{hd}_i$ corresponds to $k$th feature in ${\\bm h}_i$. We obtain ${\\bm v}_i := \\sum^{C}_{c=1} {\\bm w}^T_c,$ where ${\\bm w}_c$ is the $c$th row in ${\\bm W}^{hd}_i$ and ${\\bm v}_i \\in \\mathbb{R}^{K}$. In this way, we obtain a client-specific vector with the same shape and feature-wise semantics as ${\\bm h}_i$. Then we combine sample-specific ${\\bm h}_i$ and the client-specific ${\\bm v}_i$ via\n$\\mathcal{C}_i:=({\\bm v}_i / ||{\\bm v}_i||_2) \\odot {\\bm h}_i$, where $||{\\bm v}_i||_2$ is the $\\ell_2$-norm~\\cite{perronnin2010improving} of ${\\bm v}_i$ and $\\odot$ is the Hadamard product. We obtain ${\\bm v}_i$ before local learning in each iteration and regard it as a constant during training. During inference, we reuse the latest ${\\bm v}_i$. \n\n\nWe separate information by multiplying the policy $\\{{\\bm r}_i, {\\bm s}_i\\}$ and ${\\bm h}_i$ to obtain the global feature information ${\\bm r}_i \\odot {\\bm h}_i$ and personalized feature information ${\\bm s}_i \\odot {\\bm h}_i$. There are connections among features~\\cite{yu2003feature}, so we output $\\{{\\bm r}_i, {\\bm s}_i\\}$ with real numbers instead of Boolean values, \\ie, $r^k_{i} \\in (0, 1)$ and $s^k_{i} \\in (0, 1)$. Inspired by the Gumbel-Max trick for policy generating~\\cite{guo2019spottune}, we generate the policy with the help of the intermediates and a softmax~\\cite{hinton2015distilling} operation through the following two steps. Firstly, \\Policy generates the intermediates ${\\bm a}_i \\in \\mathbb{R}^{K\\times 2}$, where $a^k_{i} = \\{a^{k}_{i, 1}, a^{k}_{i, 2}\\}, k \\in [K]$, $a^{k}_{i, 1}$ and $a^{k}_{i, 2}$ are scalars without constraint. \nSecondly, we obtain $r^k_{i}$ and $s^k_{i}$ by\n\\begin{equation}\n    r^k_{i} = \\frac{\\exp{(a^{k}_{i, 1})}}{\\sum_{j\\in \\{1, 2\\}}\\exp{(a^{k}_{i, j})}}, \\quad s^k_{i} = \\frac{\\exp{(a^{k}_{i, 2})}}{\\sum_{j\\in \\{1, 2\\}}\\exp{(a^{k}_{i, j})}}.\n\\end{equation}\nNote that, $r^k_{i} \\in (0, 1), s^k_{i} \\in (0, 1), r^k_{i} + s^k_{i} = 1, \\forall k \\in [K]$ still holds. \n\n\\begin{algorithm}[t]\n\t\\caption{The Learning Process in \\Method}\n\t\\begin{algorithmic}[1]\n\t\t\\Require \n\t\t$N$ clients with their local data, \n\t\t${\\bm W}^{fe, 0}$: initial parameters of the global feature extractor, \n\t\t${\\bm W}^{hd, 0}$: initial parameters of the global head, \n\t\t${\\bm \\Theta}^0$: initial parameters of the global \\Policy, \n\t\t$\\eta$: local learning rate, \n\t\t$\\lambda$: hyper-parameter for MMD loss, \n\t\t$\\rho \\in (0, 1]$: client joining ratio in one iteration, \n\t\t$T$: total training iterations. \n\t\t\\Ensure \n\t\tReasonable personalized models $\\{{\\bm W}_1, \\ldots, {\\bm W}_N\\}$.\n\t\t\\State Server sends ${\\bm W}^{fe, 0}$ and ${\\bm W}^{hd, 0}$ to initialize ${\\bm W}^{fe}$, ${\\bm W}^{hd}$, ${\\bm W}^{fe}_i$, \\Statex \\qquad and ${\\bm W}^{hd}_i$ on client $i, \\forall i\\in [N]$. \n\t\t\\State Server sends ${\\bm \\Theta}^0$ to initialize the \\Policy on client $i, \\forall i\\in [N]$. \n\t\t\\For{iteration $t=0, \\ldots, T$}\n\t\t    \\State Server randomly samples a subset $\\mathcal{I}^t$ of clients based on $\\rho$.\n\t\t    \\State Server sends ${\\bm W}^{fe, t}$, ${\\bm W}^{hd, t}$, and ${\\bm \\Theta}^t$ to the selected clients. \n\t\t    \\For{Client $i \\in \\mathcal{I}^t$ in parallel}\n\t\t        \\Statex \\Comment{\\textbf{local initialization}}\n\t\t        \\State Client $i$ overwrites ${\\bm W}^{fe}$ and ${\\bm W}^{fe}_i$ with the parameters \\Statex \\qquad \\qquad \\quad ${\\bm W}^{fe, t}$ and freezes ${\\bm W}^{fe}$.\n\t\t        \\State Client $i$ overwrites ${\\bm W}^{hd}$ with the parameters ${\\bm W}^{hd, t}$ \\Statex \\qquad \\qquad \\quad and freezes ${\\bm W}^{hd}$. \n\t\t        \\State Client $i$ overwrites ${\\bm \\Theta}_i$ with the parameters ${\\bm \\Theta}^t$.\n\t\t        \\State Client $i$ generates the client-specific vector ${\\bm v}_i$.\n\t\t        \\Statex \\Comment{\\textbf{local learning}}\n\t\t        \\State Client $i$ updates ${\\bm W}^{fe}_i$, ${\\bm W}^{hd}_i$ and ${\\bm \\Theta}_i$ simultaneously:\n\t\t            \\State \\qquad ${\\bm W}^{fe}_i \\leftarrow {\\bm W}^{fe}_i - \\eta \\nabla_{{\\bm W}^{fe}_i} \\mathcal{F}_i$; \n\t\t            \\State \\qquad ${\\bm W}^{hd}_i \\leftarrow {\\bm W}^{hd}_i - \\eta \\nabla_{{\\bm W}^{hd}_i} \\mathcal{F}_i$; \n\t\t            \\State \\qquad ${\\bm \\Theta}_i \\leftarrow {\\bm \\Theta}_i - \\eta \\nabla_{{\\bm \\Theta}_i} \\mathcal{F}_i$.\n\t\t        \\State Client $i$ obtains $\\widehat{{\\bm W}}^{hd}_i$ through \\cref{eq:3}. \n\t\t        \\State Client $i$ uploads $\\{{\\bm W}^{fe}_i, \\widehat{{\\bm W}}^{hd}_i, {\\bm \\Theta}_i\\}$ to the server. \n\t\t    \\EndFor\n\t\t    \\Statex \\Comment{\\textbf{Server aggregation}}\n\t\t    \\State Server calculates $n^t = \\sum_{i \\in\n\t\t    \\mathcal{I}^t} n_i$ and obtains \n\t\t        \\State \\qquad ${\\bm W}^{fe, t+1} = \\frac{1}{n^t} \\sum_{i \\in \\mathcal{I}^t} n_i {\\bm W}^{fe}_i$; \n\t\t        \\State \\qquad ${\\bm W}^{hd, t+1} = \\frac{1}{n^t} \\sum_{i \\in \\mathcal{I}^t} n_i \\widehat{{\\bm W}}^{hd}_i$; \n\t\t        \\State \\qquad ${\\bm \\Theta}^{t+1} = \\frac{1}{n^t} \\sum_{i \\in \\mathcal{I}^t} n_i {\\bm \\Theta}_i$.\n\t\t\\EndFor\n\t\t\\\\\n\t\t\\Return $\\{{\\bm W}_1, \\ldots, {\\bm W}_N\\}$\n\t\\end{algorithmic}\n\t\\label{algo}\n\\end{algorithm}\n\n"
                    },
                    "subsubsection 3.2.2": {
                        "name": "Processing feature information",
                        "content": "\n\nThen, we feed ${\\bm r}_i \\odot{\\bm h}_i$ and ${\\bm s}_i \\odot {\\bm h}_i$ to the global head and the personalized head, respectively. The outputs of global head and the personalized head are ${\\bm {out}^r_i} = g({\\bm r}_i \\odot{\\bm h}_i; {\\bm W}^{hd})$ and ${\\bm {out}^s_i} = g({\\bm s}_i \\odot{\\bm h}_i; {\\bm W}^{hd}_i)$, respectively. We define the final output ${\\bm {out}_i} := {\\bm {out}^r_i} + {\\bm {out}^s_i}$. Then the local loss is\n\\begin{equation}\n    \\mathcal{E}_i = \\mathbb{E}_{({\\bm x}_i, y_i) \\sim \\mathcal{D}_i} \\mathcal{L}({\\bm {out}_i}, y_i), \\label{eq:e_loss}\n\\end{equation}\nwhere $\\mathcal{L}$ is the cross-entropy loss function~\\cite{murphy2012machine}. \n\nFrom the view of each sample, the extracted features are processed by both the global head and the personalized head. For simplicity, we aggregate these two heads through averaging to form the upload head $\\widehat{{\\bm W}}^{hd}_i$:\n\\begin{equation}\n    \\widehat{{\\bm W}}^{hd}_i = \\frac{{\\bm W}^{hd} + {\\bm W}^{hd}_i}{2}. \\label{eq:3}\n\\end{equation}\nIn each iteration, we upload $\\{{\\bm W}^{fe}_i, \\widehat{{\\bm W}}^{hd}_i, {\\bm \\Theta}_i\\}$ to the server. \n\n"
                    },
                    "subsubsection 3.2.3": {
                        "name": "Aligning features",
                        "content": "\n\nTo fit the features outputted by the personalized feature extractor with the frozen global head, we align the features outputted by the personalized feature extractor and the global feature extractor through the MMD loss $\\mathcal{E}^{d}_i$,\n\\begin{equation}\n    \\mathcal{E}^{d}_i = ||\\mathbb{E}_{({\\bm x}_i, y_i) \\sim \\mathcal{D}_i} \\phi({\\bm h}_i) - \\mathbb{E}_{({\\bm x}_i, y_i) \\sim \\mathcal{D}_i} \\phi(f({\\bm x}_i; {\\bm W}^{fe}))||_{\\mathcal{H}}^2 ,\n\\end{equation}\n% \\begin{equation}\n%     \\mathcal{E}^{d}_i = \\mathbb{E}_{({\\bm x}_i, y_i) \\sim \\mathcal{D}_i} \\kappa[{\\bm h}_i, f({\\bm x}_i; {\\bm W}^{fe})],\n% \\end{equation}\nwhere $\\mathcal{H}$ is a reproducing kernel Hilbert space (RKHS) and $\\phi$ is induced by a specific kernel function (\\eg, the radial basis function (RBF)), \\ie, $\\kappa({\\bm h}_i, {\\bm h}_j) = \\langle \\phi({\\bm h}_i), \\phi({\\bm h}_j) \\rangle$~\\cite{li2021fedphp}. Finally, we have the local loss $\\mathcal{F}_i = \\mathcal{E}_i + \\lambda \\mathcal{E}^{d}_i$, where $\\lambda$ is a hyper-parameter. Specifically, \n\\begin{equation}\n\\begin{aligned}\n    \\mathcal{F}_i &=\\mathbb{E}_{({\\bm x}_i, y_i) \\sim \\mathcal{D}_i} \\mathcal{L}[g({\\bm r}_i \\odot{\\bm h}_i; {\\bm W}^{hd}) + g({\\bm s}_i \\odot{\\bm h}_i; {\\bm W}^{hd}_i), y_i] \\\\\n    & + \\lambda ||\\mathbb{E}_{({\\bm x}_i, y_i) \\sim \\mathcal{D}_i} \\phi({\\bm h}_i) - \\mathbb{E}_{({\\bm x}_i, y_i) \\sim \\mathcal{D}_i} \\phi(f({\\bm x}_i; {\\bm W}^{fe}))||_{\\mathcal{H}}^2, \\label{eq:final}\n\\end{aligned}\n\\end{equation}\nwhere ${\\bm h}_i$ is the feature vector extracted by \\cref{eq:feat}, and ${\\bm r}_i$ and ${\\bm s}_i$ are obtained through ~\\cref{eq:policy}. We show the entire \\emph{\\textbf{learning}} process in \\Cref{algo} and the model for \\emph{\\textbf{inference}} in \\Cref{fig:cp_a}. \n% For \\emph{\\textbf{inference}}, we use the personalized model as illustrated by the non-gray border modules in \\Cref{fig:cp_a}.\n\n\n"
                    }
                },
                "subsection 3.3": {
                    "name": "Privacy Analysis",
                    "content": "\n\nAccording to \\Cref{fig:cp_b} and \\Cref{algo}, our proposed \\Method shares the parameters of one feature extractor, one head, and one \\Policy. As for the head part, we upload $\\widehat{{\\bm W}}^{hd}_i$ on each client after aggregating ${\\bm W}^{hd}$ and ${\\bm W}^{hd}_i$ by \\cref{eq:3}. This process can be viewed as adding noise (global parameters ${\\bm W}^{hd}$) to ${\\bm W}^{hd}_i$, thus protecting privacy during the uploading and downloading. Besides, the sample-specific characteristic further improves the privacy-preserving ability of \\Method. On the one hand, since $\\mathcal{C}_i$ is dynamically generated without sharing with the server, it is hard to recover the sample-specific policy with the \\Policy or through model inversion attacks~\\cite{al2016reconstruction}. On the other hand, without the sample-specific policy, the connection between the feature extractor and the head is broken, increasing the difficulty of attacks based on shared model parameters. We evaluate the privacy-preserving ability of \\Method in \\Cref{sec:privacy}. \n\n\n"
                }
            },
            "section 4": {
                "name": "Experimental Setup",
                "content": "\n\nWe evaluate \\Method on various image/text classification tasks. \nFor the image classification tasks, we use four famous datasets, including MNIST~\\cite{lecun1998gradient}, Cifar10~\\cite{krizhevsky2009learning}, Cifar100~\\cite{krizhevsky2009learning} and Tiny-ImageNet~\\cite{chrabaszcz2017downsampled} (100K images with 200 classes) using a famous 4-layer CNN~\\cite{mcmahan2017communication, luo2021no, geiping2020inverting}. \nTo evaluate \\Method on a larger backbone model than the 4-layer CNN, we also use ResNet-18~\\cite{he2016deep} on Tiny-ImageNet. We set the local learning rate $\\eta$ = 0.005 for the 4-layer CNN and $\\eta$ = 0.1 for ResNet-18. For the text classification tasks, we use the AG News~\\cite{zhang2015character} dataset with the fastText~\\cite{joulinetal2017bag} and set $\\eta$ = 0.1 for fastText with other settings being the same as image classification tasks. \n\nWe simulate the heterogeneous settings in two widely-used scenarios, \\ie, the pathological setting~\\cite{mcmahan2017communication, pmlrv139shamsian21a} and practical setting~\\cite{NEURIPS2020_18df51b9, li2021model}. For the pathological setting, we sample 2/2/10 classes on MNIST/Cifar10/Cifar100 from a total of 10/10/100 classes for each client with disjoint data. Specifically, similar to FedAvg~\\cite{mcmahan2017communication}, we separate clients into groups that own unbalanced data with the same labels. Following MOON~\\cite{li2021model}, we create the practical setting through the Dirichlet distribution, denoted as $Dir(\\beta)$. Specifically, we sample $q_{c, i} \\sim Dir(\\beta)$ and allocate a $q_{c, i}$ proportion of the samples of class $c$ to client $i$. \nWe set $\\beta$ = 0.1 for the default practical setting~\\cite{NEURIPS2020_18df51b9, NEURIPS2020_564127c0}. Then, we split the data on each client into a training dataset (75\\%) and a test dataset (25\\%). \n\nFollowing FedAvg, we set the local batch size to 10 and the number of local learning epochs to 1. We run all tasks up to 2000 iterations until all methods converge empirically. Based on pFedMe, FedFomo, and FedRoD, we set the total number of clients to 20 and the client joining ratio $\\rho$ = 1 by default. \nFollowing pFedMe, we report the test accuracy of the best global model for traditional FL methods and the average test accuracy of the best personalized models for pFL methods. We run all the experiments five times and report the mean and standard deviation. Besides, we run all experiments on a machine with two Intel Xeon Gold 6140 CPUs (36 cores), 128G memory, eight NVIDIA 2080 Ti GPUs, and CentOS 7.8. For more results and details, please refer to the Appendix. \n\n\n\n\n\n\n\n\n\n\n"
            },
            "section 5": {
                "name": "Ablation Study",
                "content": "\n",
                "subsection 5.1": {
                    "name": "Feature Information Visualization",
                    "content": "\n\\label{sec:act}\n\nTo visualize the separated global and personalized feature information when using ResNet-18, we adopt the Grad-CAM~\\cite{selvaraju2017grad} on the learned personalized model when only the global head or the personalized head is activated. Six cases from Tiny-ImageNet are shown in \\Cref{fig:cam}. \n\nAccording to \\Cref{fig:cam}, with only the global head activated, the personalized model focuses on relatively global information, such as trees (Case 0 and Case 4), grasses (Case 1), or sky (Case 2 and Case 5) in the background. When we only activate the personalized head, the personalized model focuses on the relatively personalized information, such as foreground (Case 2 and Case 5) or objects (Case 0, Case 1, and Case 4). As for Case 3, the rarely-used pink color is more personalized than the widely-used blue color. \n\n\n"
                },
                "subsection 5.2": {
                    "name": "Effectiveness of \\Policy input",
                    "content": " \nTo show the effectiveness of each part of the \\Policy input, we remove them one by one and obtain the variants: without client-specific vector (\\textit{w.o. cs}), without sample-specific vector (\\textit{w.o. ss}), without client-specific and sample-specific vector (\\textit{w.o. cs \\& ss}). For \\textit{w.o. cs \\& ss}, we regard the randomly initialized frozen vector as the \\Policy input, which has the same shape as the sample-specific vector. \n\nIn \\Cref{tab:abl_module}, removing either the client-specific vector or the sample-specific vector causes an accuracy decrease. However, \\textit{w.o. cs} performs better than \\textit{w.o. ss}, so the sample-specific vector is more significant than the client-specific one. According to \\Cref{tab:abl_module} and \\Cref{tab:pathological}, removing these two kinds of information and using the random vector, \\textit{w.o. cs \\& ss} still achieves higher accuracy than all the baselines because \\Policy module can still learn to separate feature information through the end-to-end training. \n\n"
                },
                "subsection 5.3": {
                    "name": "Effectiveness of \\Method modules",
                    "content": " \nTo show the effectiveness of each module in \\Method, we remove them one by one and obtain the variants: without the frozen global feature extractor and the MMD loss (without GFM for short, \\ie, \\textit{w.o. GFM}), without \\Policy (\\textit{w.o. \\Policy}), without \\Policy and GFM (\\textit{w.o. \\Policy \\& GFM}), without \\Policy and the frozen global head (\\textit{w.o. \\Policy \\& GH}), without \\Policy, GFM, and the frozen global head (\\textit{w.o. \\Policy \\& GFM \\& GH}, similar to FedPer), as shown in \\Cref{fig:abl}. It is invalid to keep \\Policy while removing the frozen global head since they are a \\textit{\\textbf{union}} for our feature separating goal. \n\nIn \\Cref{tab:abl_module}, without the GFM to align the features, the accuracy of \\textit{w.o. GFM} decreases by 1.31\\% compared to \\Method, but it still outperforms other baselines (see \\Cref{tab:pathological}). Without \\Policy, the accuracy of \\textit{w.o. \\Policy} decreases by 3.01\\%, so \\Policy is more critical than the GFM when the frozen global head exists. Removing both the \\Policy and the GFM (\\textit{w.o. \\Policy \\& GFM}) degenerates further than removing one of them, which means that these two modules can facilitate each other. The \\Policy and the frozen global head are the key modules in \\Method. Without them, the performance of \\textit{w.o. \\Policy \\& GH} degenerates significantly, with a 8.74\\% drop compared to \\Method. Furthermore, \\textit{w.o. \\Policy \\& GFM \\& GH} (removing all the modules) performs better than \\textit{w.o. \\Policy \\& GH}. It means simply adding the GFM to \\textit{w.o. \\Policy \\& GFM \\& GH} causes performance degeneration. \n\n\n\n\n"
                }
            },
            "section 6": {
                "name": "Evaluation and Analysis",
                "content": "\n\n",
                "subsection 6.1": {
                    "name": "Main Experiments",
                    "content": "\n\\label{sec:main_exp}\nDue to the limited space, we use the ``TINY'' and ``TINY*'' to represent using the 4-layer CNN on Tiny-ImageNet and using ResNet-18 on Tiny-ImageNet, respectively. \\Cref{tab:pathological} shows that \\Method outperforms all the baselines when using either the 4-layer CNN or the ResNet-18, especially on relatively challenging tasks. In the default practical setting on Cifar100, \\Method exceeds the best baseline (Ditto) by \\textbf{6.69\\%}. Our \\Policy only introduces an additional 0.527M (million) parameters on each client, which is 9.25\\% and 4.67\\% of the parameters in the 4-layer CNN (5.695M) and the ResNet-18 (11.279M), respectively. In the following, we analyze \\emph{\\textbf{why}} \\Method outperforms all the baselines. \n\nIn \\Cref{tab:pathological}, FedAvg and FedProx perform poorly, as the global model cannot fit the local data well on all the clients. They directly feed features to the global head, regardless of the personalized information in the features. In contrast, \\Method separates and feeds the global information and the personalized information in the features to the global head and the personalized head, respectively. \n\nPer-FedAvg performs poorly among pFL methods, as the aggregated learning trend can hardly meet the trend of each personalized model. In contrast, \\Method considers personalization in a sample-specific manner conditioned by the client-specific vector, which meets the demand of each client, thus performing better. \n\npFedMe and FedAMP utilize regularization terms to extract information from the local model and the client-specific server model, respectively. However, excessively concentrating on personalization is not beneficial to the collaborative goal of FL. Since Ditto extracts global information from the global model, it performs better than pFedMe and FedAMP. Like Ditto, \\Method also takes advantage of global information for each client. \n\nFedPer and FedRep only share the feature extractor without sharing heads. They ignore some global information in the head part, so they perform worse than \\Method. FedRoD bridges the goal of traditional FL and pFL by learning two heads with two objectives. However, these two goals are competing~\\cite{chen2021bridging}, so FedRoD performs worse than FedRep, which also learns a personalized head but only focuses on the goal of pFL. \nLike FedRep,\n\\Method only focuses on the pFL goal, thus performing the best. \n\nSimilar to FedAMP, FedFomo aggregates client models with client-specific weights, thus losing some global information. FedPHP transfers the global information only in the global feature extractor through the MMD loss. Although it achieves excellent performance, FedPHP loses the global information in the global head during local training, so it performs worse than \\Method. \n\n\n"
                },
                "subsection 6.2": {
                    "name": "Computing and Communication Overhead",
                    "content": "\n\nHere, we focus on the training phase. We report the total time and the number of iterations required for each method to converge and calculate the average time consumption in each iteration, as shown in \\Cref{tab:app}. Ditto and pFedMe cost more time in each iteration than most methods since the additional personalized model training takes much extra time. \nCompared to most baselines, \\eg, Per-FedAvg, pFedMe, Ditto, FedRep, and FedPHP, \\Method costs less training time in each iteration. In \\Method, the parameters in the \\Policy module only require an additional 4.67\\% communication overhead per iteration when using ResNet-18 compared to FedAvg. \n\n\n\n\n\n\n\n"
                },
                "subsection 6.3": {
                    "name": "Different Heterogeneity Degrees",
                    "content": "\n\\label{sec:hete}\n\nIn addition to \\Cref{tab:pathological}, we conduct experiments on the settings with different degrees of heterogeneity on Tiny-ImageNet and AG News by varying $\\beta$. The smaller the $\\beta$ is, the more heterogeneous the setting is. We show the accuracy in \\Cref{tab:beta}, where \\Method still outperforms the baselines. Most pFL methods achieve higher accuracy than traditional FL methods in the more heterogeneous setting. In the setting with a larger $\\beta$, most of them cannot achieve higher accuracy than FedAvg on Tiny-ImageNet. In contrast, the methods that utilize global information during local learning (FedPHP, FedRoD, and \\Method) maintain excellent performance. \nFedRoD performs worse than FedRep, as the latter focuses only on the goal of pFL. \npFedMe and FedAMP perform poorly among pFL methods. Their accuracy is lower than traditional FL methods when $\\beta$ = 1.\n\n"
                },
                "subsection 6.4": {
                    "name": "Scalability with Different Client Amounts",
                    "content": "\n\nFollowing MOON~\\cite{li2021model}, we conduct another six experiments (\\ie, $N$ = 10, $N$ = 30, $N$ = 50, $N$ = 100, $N$ = 200, and $N$ = 500) to study the scalability of \\Method and keep other settings unchanged. Per-FedAvg requires more data than other methods, as meta-learning requires at least two batches of data, which is invalid on some clients in our unbalanced settings when $N$ $\\ge$ 200. Since the total data amount is constant on Cifar100, the local data amount (on average) decreases as the client amount increases. With both $N$ and local data amount changing, it is unreasonable to compare the results among different $N$ in \\Cref{tab:beta}. \nSome pFL methods, including Per-FedAvg and pFedMe, achieve relatively poor performance in the setting with $N$ = 10, where few clients (\\eg, hospitals) participate in FL, and each of them possesses a large data repository. \nWhen $N$ = 500 (\\eg, mobile smartphones), each client only has 90 samples for training on average, which is not enough for the weight calculation in FedFomo, so it performs worse than FedAvg. FedAMP diverges as it is hard to find similar clients when they have little data. According to \\Cref{tab:beta}, \\Method still outperforms all the baselines. \n\n\n\n\nTo simulate a real-world scenario where more clients means more total data amount in FL, we consider the setting Cifar100 ($\\beta$ = 0.1, $\\rho$ = 1, and $N$ = 50) used above as the base setting and randomly sample 10 and 30 clients from existing 50 clients to form the Cifar100 ($\\beta$ = 0.1, $\\rho$ = 1, and $N$ = 10|50) and Cifar100 ($\\beta$ = 0.1, $\\rho$ = 1, and $N$ = 30|50) settings, respectively. When we increase the client amount, the accuracy increases as more data are utilized to train the globally shared modules, which facilitates information transfer among clients. The superior performance of \\Method in \\Cref{tab:scalability*} shows its scalability in this real-world scenario. \n\n"
                },
                "subsection 6.5": {
                    "name": "Large Local Epochs",
                    "content": "\n\n\n\nLarge local epochs can reduce total communication iterations but increase computing overhead per iteration for most of the methods in FL~\\cite{mcmahan2017communication}. \nWith larger local epochs, \\Method can still maintain its superiority as shown in \\Cref{tab:largeE}. Most of the methods perform worse with larger local epochs since more local training aggravates the discrepancy among client models, which is adverse to server aggregation. For example, the accuracy of FedRoD drops by 2.16\\% when the number of local epochs increases from 5 to 40. \n\n\n"
                },
                "subsection 6.6": {
                    "name": "Clients Accidentally Dropping Out",
                    "content": "\n\\label{sec:adapt}\n\n\n\nDue to the changing network connection quality, some clients may accidentally (randomly) drop out at one iteration and become active again at another iteration, which frequently happens in the mobile settings. We compare the performance of pFL methods when some clients accidentally drop out, as shown in \\Cref{tab:drop}. Instead of using the constant $\\rho$, we randomly choose a value within a given range for $\\rho$ in each iteration. The larger the range of $\\rho$ is, the more unstable the setting is. It simulates a more practical setting with a random drop-out rate than the settings used by the SOTA methods, which set a constant drop-out rate in all iterations. \n\nMost pFL methods suffer from an accuracy decrease in unstable settings. pFedMe and FedPHP have up to 6.65\\% and 9.80\\% accuracy decrease, respectively, compared to $\\rho$ = 1 in \\Cref{tab:drop}. Some methods, such as FedRep, and FedRoD, perform worse with a larger range of $\\rho$. The standard deviation of Per-FedAvg, pFedMe, Ditto, and FedRoD is greater than 1\\% when $\\rho \\in [0.1, 1]$, which means their performance is unstable with the random $\\rho$. Since \\Policy separates feature information automatically, \\Method can adapt to the changing environments thus still maintaining superiority and stable performance in these unstable settings. \n\n\n"
                }
            },
            "section 7": {
                "name": "Effect of the Hyper-parameter $\\lambda$",
                "content": "\nTo guide the learned features to fit the frozen global head, we use the hyper-parameter $\\lambda$ to control the importance of MMD loss that aligns the outputs of the personalized feature extractor and the outputs of the global feature extractor. The larger the $\\lambda$ is, the closer these two outputs are. \n\n\n\nFrom \\Cref{tab:lam_tiny}, the accuracy first increases and then decreases as $\\lambda$ increases, which is similar among three settings with different degrees of heterogeneity. By assigning a proper value to $\\lambda$, the personalized feature extractor can learn the information from the local data while guiding the output features to fit the frozen global head. When the value of $\\lambda$ is overlarge (\\eg, $\\lambda=50$), the personalized feature extractor can hardly learn from the local data. Instead, it tends to output similarly to the frozen global feature extractor. To pay more attention to the local data in a more heterogeneous setting (\\eg, $\\beta=0.01$), \\Method requires a relatively smaller $\\lambda$, as the global information plays a less critical role in this situation. \n\n"
            },
            "section 8": {
                "name": "Policy Study",
                "content": "\n\\label{sec:policy}\n\n\n\nWe show the policy change for the training samples and the generated policies for all the test samples during inference in \\Cref{fig:policy}. For clarity, we collect all the sample-specific ${\\bm s}_i$ on each client and average them to obtain $\\overline{{\\bm s}}_i$. Then we further average the elements in $\\overline{{\\bm s}}_i$ to generate one scalar, which is called personalization identification ratio (PIR): ${\\rm PIR}_i:=\\frac{1}{K} \\sum^{K}_k \\overline{s}^k_i, i\\in [N]$, where $\\overline{s}^k_i$ is the $k$th element in the policy $\\overline{{\\bm s}}_i$. \n\nWhen using diverse backbones with different feature extraction abilities, the policies vary in both PIR change and ${\\bm s}_i$ distribution. As shown in \\Cref{fig:policy_a}, on client \\#0, PIR increases from the initial value of 0.50 to around 0.58 in the first 20 iterations and remains almost unchanged using the 4-layer CNN. However, when using ResNet-18, PIR decreases first and then increases rapidly to around 0.61, which means that the features extracted by the feature extractor in ResNet-18 contain more global feature information in early iterations, and our \\Policy can automatically capture this dynamic characteristic during all FL iterations. In \\Cref{fig:policy_b}, the value range of ${\\bm s}_i$ varies among clients, as they contain diverse samples. For example, the ${\\bm s}_i$ range on client \\#10 is the largest among clients. Although the policies are different for the samples, the mean values of ${\\bm s}_i$ are similar among clients when using one specific backbone, as shown in \\Cref{fig:policy_b}. The values of ${\\bm s}_i$ are all larger than 0.5 during inference, which means the learned features contain more personalized feature information than global feature information on clients in these scenarios. \n\n\n"
            },
            "section 9": {
                "name": "Conclusion",
                "content": "\n\\label{sec:conc}\n\nWe propose a Federated Conditional Policy (\\Method) method that generates a policy for each sample to separate its features into the global feature information and the personalized feature information, then processes them by the global head and the personalized head, respectively. \\Method outperforms eleven SOTA methods by up to 6.69\\% under various settings with excellent privacy-preserving ability. Besides, \\Method also maintains excellent performance when some clients accidentally drop out. \n\n\\begin{acks}\n    This work was supported in part by the Shanghai Key Laboratory of Scalable Computing and Systems, National Key R\\&D Program of China (2022YFB4402102), Internet of Things special subject program, China Institute of IoT (Wuxi), Wuxi IoT Innovation Promotion Center (2022SP-T13-C), Industry-university-research Cooperation Funding Project from the Eighth Research Institute in China Aerospace Science and Technology Corporation (Shanghai) (USCAST2022-17), and Intel Corporation (UFunding 12679). The work of H. Wang was supported in part by the NSF grant CRII-OAC-2153502. Ruhui Ma is the corresponding author. \n\\end{acks}\n\n% \\clearpage\n\n%%\n%% The next two lines define the bibliography style to be used, and\n%% the bibliography file.\n\\bibliographystyle{ACM-Reference-Format}\n\\balance\n\\bibliography{main}\n\n%%\n%% If your work has an appendix, this is the place to put it.\n\\clearpage\n\n\\appendix\n\n"
            },
            "section 10": {
                "name": "Convergence Analysis",
                "content": "\n\nRecall that our objective is\n\\begin{equation}\n    \\{{\\bm W}_1, \\ldots, {\\bm W}_N\\} = \\argmin \\ \\mathcal{G}(\\mathcal{F}_1, \\ldots, \\mathcal{F}_N),\n\\end{equation}\nwhere $\\mathcal{F}_i, \\forall i \\in [N]$ is the local loss and $\\mathcal{G}(\\mathcal{F}_1, \\ldots, \\mathcal{F}_N) = \\sum^{N}_{i=1} n_i \\mathcal{F}_i$. During the training phase, the value of $\\mathcal{G}$ is the training loss of \\Method. To study the convergence of \\Method, we denote the loss calculated with the trained personalized models after local learning as $loss_{aft}$ and the loss calculated with the initialized personalized models before local learning as $loss_{bef}$. Except for the loss values, we also evaluate the corresponding test accuracy, calculated by averaging the accuracy of all the personalized models on the corresponding local test datasets of clients. \n\nTo empirically analyze the convergence of \\Method, we draw the training loss curves and test accuracy curves for our \\Method when using ResNet-18, as shown in \\Cref{fig:converge}. On Tiny-ImageNet in the default practical setting, $loss_{aft}$ becomes close to $loss_{bef}$ after 74 iterations, and both of them reach the minimum value meanwhile. In other words, \\Method converges after training around 74 iterations. With the training loss decreasing, the test accuracy increases. Both the loss curve and the accuracy curve fluctuate before iteration 56 when using ResNet-18 due to the policy update, as shown in \\Cref{fig:policy} in the main body of this paper. \n\n\n\n\n"
            },
            "section 11": {
                "name": "Privacy-Preserving Ability",
                "content": "\n\\label{sec:privacy}\n\nHere, following a traditional FL method FedCG~\\cite{wufedcg}, we consider a semi-honest scenario where the server follows the FL protocol but may recover original data from a victim client with its model updates via Deep Leakage from Gradients (DLG) attack~\\cite{zhu2019deep}. \nAmong the baselines in our paper, there are two categories in terms of information transmission between the server and clients. Methods in Category 1 share the parameters in the entire backbone model, such as FedAvg, FedProx, Per-FedAvg, pFedMe, Ditto, FedRoD, FedFomo, and FedPHP. Methods in Category 2 only share the parameters in the feature extractor, such as FedPer and FedRep. Without loss of generality, we select the most famous methods in each category as the representative baselines: FedAvg for Category 1 and FedPer for Category 2. \nAlso following FedCG, we provide the experimental results in \\Cref{tab:dlg} to evaluate the privacy-preserving ability of \\Method with representative baselines in Peak Signal-to-Noise Ratio (PSNR). The lower value of PSNR shows better privacy-preserving ability. The results in \\Cref{tab:dlg} show the superiority of \\Method. \n\n\n\n\n\n"
            },
            "section 12": {
                "name": "Conditional Policy Network Design",
                "content": "\n\nBy default, our \\Policy consists of a fully connected (FC) layer~\\cite{lecun2015deep} and a layer-normalization layer~\\cite{ba2016layer} (LN for short) followed by the ReLU activation function~\\cite{li2017convergence}. Here, we investigate how different designs affect the effectiveness of \\Policys by varying the number of FC layers, the normalization layer, and the activation function, as shown in \\Cref{tab:design}. Since the intermediate outputs ${\\bm a}_i \\in \\mathbb{R}^{K \\times 2}$ have two groups, we set the number of groups to two for the group-normalization~\\cite{wu2018group} (GN for short). We only change the considered component based on \\Method. The accuracy results with an \\underline{underline} are higher than the accuracy of \\Method. \n\n\n\nThe results in \\Cref{tab:design} show that we can further improve \\Method by using other architectures for the \\Policy. Adding more \\textbf{FC layers} to process its input improves the test accuracy for ResNet-18 but causes a slight decrease for the 4-layer CNN. The additional parameters introduced for \\Method with 1 FC, 2 FC, 3 FC, and 4 FC are 0.527M (million), 0.790M, 1.052M, and 1.315M, respectively. However, the additional computing cost in each iteration introduced by additional FC layers is not worth the little accuracy increase. As for the \\textbf{normalization layer}, replacing the LN with the batch-normalization~\\cite{ioffe2015batch} (BN) improves 0.64\\% test accuracy for the 4-layer CNN. However, it decreases around 0.48\\% accuracy for ResNet-18, which also contains BN layers. Similar to LN that normalizes entire ${\\bm a}_i$, GN respectively normalizes ${\\bm a}_{i, 1}$ and ${\\bm a}_{i, 2}$. However, the test accuracy for both the 4-layer CNN and ResNet-18 decreases with the GN layer. As for the activation function, using tanh only increases the accuracy for the 4-layer CNN, while using sigmoid improves the performance for both backbones compared to using ReLU, as the output belongs to $(0, 1)$ is more suitable for outputting a policy. \n\n"
            },
            "section 13": {
                "name": "Hyperparameter Settings",
                "content": "\n\\label{sec:hyper}\n\nWe use the grid search to find the optimal $\\lambda$. Specifically, we perform the grid search in the following search space:\n\\begin{itemize}\n    \\item $\\lambda$: {$0$, $0.1$, $1$, $5$, $10$}\n\\end{itemize}\n\nIn this paper, we set $\\lambda=5$ for the 4-layer CNN and $\\lambda=1$ for the ResNet-18 and the fastText, respectively. \n\n\n"
            },
            "section 14": {
                "name": "Data Distribution Visualization",
                "content": "\n\nHere, we show visualizations of the data distributions (including training and test data) in the image and text tasks.\n\n\n\n\n\n\n\n\n\n\n\n"
            }
        },
        "tables": {
            "tab:abl_module": "\\begin{table*}[h]\n  \\centering\n  \\caption{The accuracy (\\%) on Tiny-ImageNet using ResNet-18 for ablation study.}\n  \\resizebox{\\linewidth}{!}{\n    \\begin{tabular}{c|cccccccc}\n    \\toprule \n     \\Method & \\textit{w.o. cs} & \\textit{w.o. ss} & \\textit{w.o. cs \\& ss} & \\textit{w.o. GFM} & \\textit{w.o. \\Policy} & \\textit{w.o. \\Policy \\& GFM} & \\textit{w.o. \\Policy \\& GH} & \\textit{w.o. \\Policy \\& GFM \\& GH}\\\\\n    \\midrule\n    \\textbf{44.18$\\pm$0.21} & 43.76$\\pm$0.39 & 42.73$\\pm$0.26 & 42.25$\\pm$0.30 & 42.87$\\pm$0.36 & 41.17$\\pm$0.18 & 40.06$\\pm$0.47 & 35.44$\\pm$0.78 & 39.04$\\pm$0.79\\\\\n    \\bottomrule\n    \\end{tabular}}\n  \\label{tab:abl_module}\n\\end{table*}",
            "tab:pathological": "\\begin{table*}[htbp]\n    \\centering\n    \\caption{The accuracy (\\%) of the image/text classification tasks in the main experiments.}\n    \\resizebox{\\linewidth}{!}{\n      \\begin{tabular}{l|ccc|cccccc}\n      \\toprule\n      Settings & \\multicolumn{3}{c|}{Pathological setting} & \\multicolumn{6}{c}{Default practical setting ($\\beta$ = 0.1)} \\\\\n      \\midrule\n       & MNIST & Cifar10 & Cifar100 & MNIST & Cifar10 & Cifar100 & TINY & TINY* & AG News\\\\\n      \\midrule\n      FedAvg~\\cite{mcmahan2017communication} & 97.93$\\pm$0.05 & 55.09$\\pm$0.83 & 25.98$\\pm$0.13 & 98.81$\\pm$0.01 & 59.16$\\pm$0.47 & 31.89$\\pm$0.47 & 19.46$\\pm$0.20 & 19.45$\\pm$0.13 & 79.57$\\pm$0.17 \\\\\n      FedProx~\\cite{MLSYS2020_38af8613} & 98.01$\\pm$0.09 & 55.06$\\pm$0.75 & 25.94$\\pm$0.16 & 98.82$\\pm$0.01 & 59.21$\\pm$0.40 & 31.99$\\pm$0.41 & 19.37$\\pm$0.22 & 19.27$\\pm$0.23 & 79.35$\\pm$0.23 \\\\\n      \\midrule\n      Per-FedAvg~\\cite{NEURIPS2020_24389bfe} & 99.63$\\pm$0.02 & 89.63$\\pm$0.23 & 56.80$\\pm$0.26 & 98.90$\\pm$0.05 & 87.74$\\pm$0.19 & 44.28$\\pm$0.33 & 25.07$\\pm$0.07 & 21.81$\\pm$0.54 & 93.27$\\pm$0.25 \\\\\n      pFedMe~\\cite{t2020personalized} & 99.75$\\pm$0.02 & 90.11$\\pm$0.10 & 58.20$\\pm$0.14 & 99.52$\\pm$0.02 & 88.09$\\pm$0.32 & 47.34$\\pm$0.46 & 26.93$\\pm$0.19 & 33.44$\\pm$0.33 & 91.41$\\pm$0.22 \\\\\n      FedAMP~\\cite{huang2021personalized} & 99.76$\\pm$0.02 & 90.79$\\pm$0.16 & 64.34$\\pm$0.37 & 99.47$\\pm$0.02 & 88.70$\\pm$0.18 & 47.69$\\pm$0.49 & 27.99$\\pm$0.11 & 29.11$\\pm$0.15 & 94.18$\\pm$0.09 \\\\\n      Ditto~\\cite{li2021ditto} & 99.81$\\pm$0.00 & 92.39$\\pm$0.06 & 67.23$\\pm$0.07 & 99.64$\\pm$0.00 & 90.59$\\pm$0.01 & 52.87$\\pm$0.64 & 32.15$\\pm$0.04 & 35.92$\\pm$0.43 & 95.45$\\pm$0.17 \\\\\n      FedPer~\\cite{arivazhagan2019federated} & 99.70$\\pm$0.02 & 91.15$\\pm$0.21 & 63.53$\\pm$0.21 & 99.47$\\pm$0.04 & 89.22$\\pm$0.33 & 49.63$\\pm$0.54 & 33.84$\\pm$0.34 & 38.45$\\pm$0.85 & 95.54$\\pm$0.32 \\\\\n      FedRep~\\cite{collins2021exploiting} & 99.77$\\pm$0.03 & 91.93$\\pm$0.14 & 67.56$\\pm$0.31 & 99.48$\\pm$0.02 & 90.40$\\pm$0.24 & 52.39$\\pm$0.35 & 37.27$\\pm$0.20 & 39.95$\\pm$0.61 & 96.28$\\pm$0.14 \\\\\n      FedRoD~\\cite{chen2021bridging} & 99.90$\\pm$0.00 & 91.98$\\pm$0.03 & 62.30$\\pm$0.02 & 99.66$\\pm$0.00 & 89.93$\\pm$0.01 & 50.94$\\pm$0.11 & 36.43$\\pm$0.05 & 37.99$\\pm$0.26 & 95.99$\\pm$0.08 \\\\\n      FedFomo~\\cite{zhang2020personalized} & 99.83$\\pm$0.00 & 91.85$\\pm$0.02 & 62.49$\\pm$0.22 & 99.33$\\pm$0.04 & 88.06$\\pm$0.02 & 45.39$\\pm$0.45 & 26.33$\\pm$0.22 & 26.84$\\pm$0.11 & 95.84$\\pm$0.15 \\\\\n      FedPHP~\\cite{li2021fedphp} & 99.73$\\pm$0.00 & 90.01$\\pm$0.00 & 63.09$\\pm$0.04 & 99.58$\\pm$0.00 & 88.92$\\pm$0.02 & 50.52$\\pm$0.16 & 35.69$\\pm$3.26 & 29.90$\\pm$0.51 & 94.38$\\pm$0.12 \\\\\n      \\midrule\n      \\Method & {\\bf 99.91$\\pm$0.01} & {\\bf 92.67$\\pm$0.09} & {\\bf 71.80$\\pm$0.16} & {\\bf 99.71$\\pm$0.00} & {\\bf 91.30$\\pm$0.17} & {\\bf 59.56$\\pm$0.08} & {\\bf 43.49$\\pm$0.04} & {\\bf 44.18$\\pm$0.21} & {\\bf 96.78$\\pm$0.09} \\\\\n      \\bottomrule\n      \\end{tabular}}\n    \\label{tab:pathological}\n  \\end{table*}",
            "tab:nlp": "\\begin{table}[h]\n  \\centering\n  \\caption{The computing time and communication iterations on Tiny-ImageNet using ResNet-18.}\n  \\label{tab:nlp}\n  \\resizebox{!}{!}{\n    \\begin{tabular}{l|rrr}\n    \\toprule\n    & Total time & Iterations & Avg. time\\\\\n    \\midrule\n    FedAvg & 365 min & 230 & 1.59 min\\\\\n    FedProx & 325 min & 163 & 1.99 min\\\\\n    \\midrule\n    Per-FedAvg & 121 min & 34 & 3.56 min\\\\\n    pFedMe & 1157 min & 113 & 10.24 min\\\\\n    FedAMP & 92 min & 60 & 1.53 min\\\\\n    Ditto & 318 min & 27 & 11.78 min\\\\\n    FedPer & 83 min & 43 &  1.92 min\\\\\n    FedRep & 471 min & 115 & 4.09 min\\\\\n    FedRoD & 87 min & 50 & 1.74 min\\\\\n    FedFomo & 193 min & 71 & 2.72 min\\\\\n    FedPHP & 264 min & 65 & 4.06 min\\\\\n    \\midrule\n    \\Method & 204 min & 74 & 2.75 min\\\\\n    \\bottomrule\n    \\end{tabular}}\n    \\label{tab:app}\n\\end{table}",
            "tab:app": "\\begin{table}[h]\n  \\centering\n  \\caption{The computing time and communication iterations on Tiny-ImageNet using ResNet-18.}\n  \\label{tab:nlp}\n  \\resizebox{!}{!}{\n    \\begin{tabular}{l|rrr}\n    \\toprule\n    & Total time & Iterations & Avg. time\\\\\n    \\midrule\n    FedAvg & 365 min & 230 & 1.59 min\\\\\n    FedProx & 325 min & 163 & 1.99 min\\\\\n    \\midrule\n    Per-FedAvg & 121 min & 34 & 3.56 min\\\\\n    pFedMe & 1157 min & 113 & 10.24 min\\\\\n    FedAMP & 92 min & 60 & 1.53 min\\\\\n    Ditto & 318 min & 27 & 11.78 min\\\\\n    FedPer & 83 min & 43 &  1.92 min\\\\\n    FedRep & 471 min & 115 & 4.09 min\\\\\n    FedRoD & 87 min & 50 & 1.74 min\\\\\n    FedFomo & 193 min & 71 & 2.72 min\\\\\n    FedPHP & 264 min & 65 & 4.06 min\\\\\n    \\midrule\n    \\Method & 204 min & 74 & 2.75 min\\\\\n    \\bottomrule\n    \\end{tabular}}\n    \\label{tab:app}\n\\end{table}",
            "tab:beta": "\\begin{table*}[ht]\n  \\centering\n  \\caption{The accuracy (\\%) of the image/text classification tasks for heterogeneity and scalability.}\n  \\resizebox{\\linewidth}{!}{\n    \\begin{tabular}{l|ccc|cccccc}\n    \\toprule\n    & \\multicolumn{3}{c|}{Heterogeneity} & \\multicolumn{6}{c}{Scalability}\\\\\n    \\midrule\n    Datasets & \\multicolumn{2}{c}{TINY} & AG News & \\multicolumn{6}{c}{Cifar100}\\\\\n    \\midrule\n     & $\\beta$ = 0.01 & $\\beta$ = 0.5 & $\\beta$ = 1 & $N$ = 10 & $N$ = 30 & $N$ = 50 & $N$ = 100 & $N$ = 200 & $N$ = 500 \\\\\n    \\midrule\n    FedAvg & 15.70$\\pm$0.46 & 21.14$\\pm$0.47 & 87.12$\\pm$0.19 & 31.47$\\pm$0.01 & 31.15$\\pm$0.05 & 31.90$\\pm$0.27 & 31.95$\\pm$0.37 & 31.20$\\pm$0.58 & 29.51$\\pm$0.73 \\\\\n    FedProx & 15.66$\\pm$0.36 & 21.22$\\pm$0.47 & 87.21$\\pm$0.13 & 31.24$\\pm$0.08 & 31.21$\\pm$0.08 & 31.94$\\pm$0.30 & 31.97$\\pm$0.24 & 31.22$\\pm$0.62 & 29.84$\\pm$0.81 \\\\\n    \\midrule\n    Per-FedAvg & 39.39$\\pm$0.30 & 16.36$\\pm$0.13 & 87.08$\\pm$0.26 & 37.24$\\pm$0.12 & 41.57$\\pm$0.21 & 44.31$\\pm$0.20 & 36.07$\\pm$0.24 & --- & --- \\\\\n    pFedMe & 41.45$\\pm$0.14 & 17.48$\\pm$0.61 & 87.08$\\pm$0.18 & 44.06$\\pm$0.29 & 47.04$\\pm$0.28 & 48.36$\\pm$0.64 & 46.45$\\pm$0.18 & 39.55$\\pm$0.61 & 31.30$\\pm$0.89 \\\\\n    FedAMP & 48.42$\\pm$0.06 & 12.48$\\pm$0.21 & 83.35$\\pm$0.05 & 49.23$\\pm$0.18 & 45.33$\\pm$0.04 & 44.39$\\pm$0.35 & 40.43$\\pm$0.17 & 35.40$\\pm$0.70 & \\textit{diverged} \\\\\n    Ditto & 50.62$\\pm$0.02 & 18.98$\\pm$0.05 & 91.89$\\pm$0.17 & 52.32$\\pm$0.19 & 52.53$\\pm$0.42 & 54.22$\\pm$0.04 & 52.89$\\pm$0.22 & 35.18$\\pm$0.53 & 30.24$\\pm$0.72 \\\\\n    FedPer & 51.83$\\pm$0.22 & 17.31$\\pm$0.19 & 91.85$\\pm$0.24 & 50.31$\\pm$0.19 & 44.98$\\pm$0.20 & 44.22$\\pm$0.18 & 40.37$\\pm$0.41 & 34.99$\\pm$0.48 & 30.56$\\pm$0.59 \\\\\n    FedRep & 55.43$\\pm$0.15 & 16.74$\\pm$0.09 & 92.25$\\pm$0.20 & 52.89$\\pm$0.10 & 50.24$\\pm$0.01 & 47.41$\\pm$0.18 & 44.61$\\pm$0.20 & 36.79$\\pm$0.60 & 31.92$\\pm$0.71 \\\\\n    FedRoD & 49.17$\\pm$0.06 & 23.23$\\pm$0.11 & 92.16$\\pm$0.12 & 49.83$\\pm$0.07 & 50.11$\\pm$0.03 & 49.38$\\pm$0.01 & 46.65$\\pm$0.22 & 43.53$\\pm$0.86 & 34.61$\\pm$0.98 \\\\\n    FedFomo & 46.36$\\pm$0.54 & 11.59$\\pm$0.11 & 91.20$\\pm$0.18 & 46.71$\\pm$0.23 & 43.20$\\pm$0.05 & 42.56$\\pm$0.33 & 38.91$\\pm$0.08 & 34.79$\\pm$0.71 & 29.24$\\pm$1.28 \\\\\n    FedPHP & 48.63$\\pm$0.02 & 21.09$\\pm$0.07 & 90.52$\\pm$0.19 & 49.32$\\pm$0.19 & 49.28$\\pm$0.06 & 52.44$\\pm$0.16 & 49.70$\\pm$0.31 & 34.48$\\pm$0.33 & 30.26$\\pm$0.84 \\\\\n    \\midrule\n    \\Method & {\\bf 56.31$\\pm$0.39} & {\\bf 27.66$\\pm$0.16} & {\\bf 92.89$\\pm$0.10} & {\\bf 58.36$\\pm$0.02} & {\\bf 56.93$\\pm$0.19} & {\\bf 55.43$\\pm$0.21} & {\\bf 53.81$\\pm$0.32} & {\\bf 44.86$\\pm$0.87} & {\\bf 35.87$\\pm$0.52} \\\\\n    \\bottomrule\n    \\end{tabular}}\n  \\label{tab:beta}\n\\end{table*}",
            "tab:scalability*": "\\begin{table}[ht]\n  \\centering\n  \\caption{The accuracy (\\%) on Cifar100 for scalability.}\n  \\resizebox{!}{!}{\n    \\begin{tabular}{l|ccc}\n    \\toprule\n    & $N$ = 10|50 & $N$ = 30|50 & $N$ = 50 \\\\\n    \\midrule\n    FedAvg & 25.28$\\pm$0.32 & 29.04$\\pm$0.21 & 31.90$\\pm$0.27 \\\\\n    FedProx & 25.65$\\pm$0.34 & 29.04$\\pm$0.36 & 31.94$\\pm$0.30 \\\\\n    \\midrule\n    Per-FedAvg & 40.20$\\pm$0.21 & 42.96$\\pm$0.42 & 44.31$\\pm$0.20 \\\\\n    pFedMe & 40.27$\\pm$0.54 & 42.19$\\pm$0.38 & 48.36$\\pm$0.64 \\\\\n    FedAMP & 43.57$\\pm$0.30 & 43.18$\\pm$0.31 & 44.39$\\pm$0.35 \\\\\n    Ditto & 48.23$\\pm$0.35 & 50.98$\\pm$0.29 & 54.22$\\pm$0.04 \\\\\n    FedPer & 43.64$\\pm$0.42 & 43.54$\\pm$0.43 & 44.22$\\pm$0.18 \\\\\n    FedRep & 46.85$\\pm$0.12 & 47.63$\\pm$0.26 & 47.41$\\pm$0.18 \\\\\n    FedRoD & 46.32$\\pm$0.02 & 49.15$\\pm$0.12 & 49.38$\\pm$0.01 \\\\\n    FedFomo & 41.53$\\pm$0.45 & 40.69$\\pm$0.41 & 42.56$\\pm$0.33 \\\\\n    FedPHP & 45.71$\\pm$0.21 & 48.65$\\pm$0.24 & 52.44$\\pm$0.16 \\\\\n    \\midrule\n    \\Method & {\\bf 50.93$\\pm$0.34} & {\\bf 54.31$\\pm$0.25} & {\\bf 55.43$\\pm$0.21} \\\\\n    \\bottomrule\n    \\end{tabular}}\n  \\label{tab:scalability*}\n\\end{table}",
            "tab:largeE": "\\begin{table}[ht]\n  \\centering\n  \\caption{The accuracy (\\%) on Cifar10 in the default practical setting with large local epochs.}\n  \\resizebox{\\linewidth}{!}{\n    \\begin{tabular}{l|cccc}\n    \\toprule\n    Local epochs & 5 & 10 & 20 & 40\\\\\n    \\midrule\n    FedAvg & 57.51$\\pm$0.35 & 57.55$\\pm$0.32 & 57.28$\\pm$0.23 & 56.27$\\pm$0.29\\\\\n    FedProx & 57.48$\\pm$0.28 & 57.69$\\pm$0.31 & 57.53$\\pm$0.33 & 56.18$\\pm$0.24\\\\\n    \\midrule\n    Per-FedAvg & 86.13$\\pm$0.12 & 86.09$\\pm$0.19 & 85.57$\\pm$0.15 & 85.45$\\pm$0.16\\\\\n    pFedMe & 88.72$\\pm$0.02 & 88.58$\\pm$0.17 & 88.37$\\pm$0.14 & 88.16$\\pm$0.20\\\\\n    FedAMP & 88.72$\\pm$0.21 & 88.77$\\pm$0.27 & 88.76$\\pm$0.30 & 88.70$\\pm$0.26\\\\\n    Ditto & 90.79$\\pm$0.21 & 90.59$\\pm$0.06 & 90.34$\\pm$0.23 & 90.02$\\pm$0.38\\\\\n    FedPer & 89.62$\\pm$0.12 & 89.73$\\pm$0.31 & 89.79$\\pm$0.35 & 89.49$\\pm$0.55\\\\\n    FedRep & 90.20$\\pm$0.41 & 90.08$\\pm$0.26 & 89.46$\\pm$0.13 & 89.22$\\pm$0.25\\\\\n    FedRoD & 89.71$\\pm$0.32 & 89.11$\\pm$0.33 & 88.13$\\pm$0.21 & 87.55$\\pm$0.28\\\\\n    FedFomo & 88.39$\\pm$0.15 & 88.43$\\pm$0.16 & 88.41$\\pm$0.13 & 88.13$\\pm$0.32\\\\\n    FedPHP & 90.29$\\pm$0.37 & 90.03$\\pm$0.23 & 89.92$\\pm$0.27 & 89.87$\\pm$0.26\\\\\n    \\midrule\n    \\Method & {\\bf 91.13$\\pm$0.34} & {\\bf 91.24$\\pm$0.31} & {\\bf 91.02$\\pm$0.28} & {\\bf 90.86$\\pm$0.37}\\\\\n    \\bottomrule\n    \\end{tabular}}\n    \\label{tab:largeE}\n\\end{table}",
            "tab:drop": "\\begin{table}[ht]\n  \\centering\n  \\caption{The accuracy (\\%) on Cifar100 ($N$ = 50, $\\beta$ = 0.1) when clients accidentally drop out.}\n  \\resizebox{!}{!}{\n    \\begin{tabular}{l|ccc}\n    \\toprule\n    & $\\rho$ = 1 & $\\rho \\in [0.5, 1]$ & $\\rho \\in [0.1, 1]$ \\\\\n    \\midrule\n    Per-FedAvg & 44.31$\\pm$0.20 & 43.66$\\pm$1.38 & 43.63$\\pm$1.07\\\\\n    pFedMe & 48.36$\\pm$0.64 & 43.28$\\pm$0.85 & 41.71$\\pm$1.02\\\\\n    FedAMP & 44.39$\\pm$0.35 & 42.91$\\pm$0.08 & 42.92$\\pm$0.14\\\\\n    Ditto & 50.59$\\pm$0.22 & 49.78$\\pm$0.36 & 48.33$\\pm$3.27\\\\\n    FedPer & 44.22$\\pm$0.18 & 44.12$\\pm$0.21 & 44.07$\\pm$0.27\\\\\n    FedRep & 47.41$\\pm$0.18 & 46.93$\\pm$0.21 & 46.61$\\pm$0.22\\\\\n    FedRoD & 49.38$\\pm$0.01 & 49.07$\\pm$0.43 & 47.80$\\pm$1.35\\\\\n    FedFomo & 42.56$\\pm$0.33 & 40.96$\\pm$0.02 & 40.93$\\pm$0.07\\\\\n    FedPHP & 50.23$\\pm$0.12 & 45.19$\\pm$0.07 & 44.43$\\pm$0.12\\\\\n    \\midrule\n    \\Method & {\\bf 54.81$\\pm$0.20} & {\\bf 54.68$\\pm$0.35} & {\\bf 54.20$\\pm$0.21}\\\\\n    \\bottomrule\n    \\end{tabular}}\n  \\label{tab:drop}\n\\end{table}",
            "tab:lam_tiny": "\\begin{table}[ht]\n  \\centering\n  \\caption{The accuracy (\\%) on Tiny-ImageNet using the 4-layer CNN in three practical settings.}\n  \\resizebox{\\linewidth}{!}{\n    \\begin{tabular}{l|c*{6}{c}}\n    \\toprule & $\\lambda=1$ & $\\lambda=2$ & $\\lambda=5$ & $\\lambda=10$ & $\\lambda=50$\\\\\n    \\midrule\n    $\\beta=0.01$ & 56.56$\\pm$0.35 & \\textbf{56.71$\\pm$0.32} & 56.31$\\pm$0.39 & 54.48$\\pm$0.10 & 9.73$\\pm$0.02\\\\\n    $\\beta$ = 0.1 & 41.67$\\pm$0.17 & 42.75$\\pm$0.03 & \\textbf{43.49$\\pm$0.04} & 42.83$\\pm$0.07 & 8.14$\\pm$0.06\\\\\n    $\\beta=0.5$ & 24.95$\\pm$0.15 & 26.55$\\pm$0.23 & \\textbf{27.66$\\pm$0.16} & 26.95$\\pm$0.27 & 4.54$\\pm$0.04\\\\\n    \\bottomrule\n    \\end{tabular}}\n  \\label{tab:lam_tiny}\n\\end{table}",
            "tab:dlg": "\\begin{table}[h]\n  \\centering\n  \\caption{PSNR on Cifar100 in the default practical setting.}\n  \\resizebox{!}{!}{\n    \\begin{tabular}{l|cc|c}\n    \\toprule\n     & FedAvg & FedPer & \\Method \\\\\n    \\midrule\n    PSNR (dB, $\\downarrow$) & 7.30 & 7.94 & \\textbf{6.94} \\\\\n    \\bottomrule\n    \\end{tabular}}\n    \\label{tab:dlg}\n\\end{table}",
            "tab:design": "\\begin{table}[h]\n  \\centering\n  \\caption{The accuracy (\\%) with various \\Policys on Tiny-ImageNet in the default practical setting.}\n  \\resizebox{\\linewidth}{!}{\n    \\begin{tabular}{l|c|ccc|cc|cc}\n    \\toprule\n     & \\Method & \\multicolumn{3}{c|}{Number of FC layers} & \\multicolumn{2}{c|}{Normalization layer} & \\multicolumn{2}{c}{Activation function}\\\\\n    \\midrule\n    & / & 2 FC & 3 FC & 4 FC & BN & GN & tanh & sigmoid \\\\\n    \\midrule\n    4-layer CNN & 43.49 & 43.22 & 43.29 & 43.31 & \\underline{\\textbf{44.13}} & 43.10 & \\underline{43.89} & \\underline{43.92} \\\\\n    ResNet-18 & 44.18 & \\underline{44.50} & \\underline{44.36} & 44.11 & 43.70 & 43.25 & 43.49 & \\underline{\\textbf{44.69}} \\\\\n    \\bottomrule\n    \\end{tabular}}\n    \\label{tab:design}\n\\end{table}"
        },
        "figures": {
            "fig:intro": "\\begin{figure}[h]\n\t\\centering\n\t\\includegraphics[width=\\linewidth]{figs/fig0.pdf}\n\t\\caption{An example for \\Method. ${\\bm h}_{i/j}$: extracted feature vector, \\Policy $i/j$: Conditional Policy Network, ${\\bm W}^{hd}$: frozen global head, ${\\bm W}^{hd}_{i/j}$: personalized head. Best viewed in color. }\n\t\\label{fig:intro}\n\\end{figure}",
            "fig:cp": "\\begin{figure*}[h]\n\t\\centering\n\t\\subfigure[Forward data flow corresponding to the local learning on client $i$.]{\\includegraphics[width=0.57\\linewidth]{figs/fig1.pdf}\\label{fig:cp_a}}\n    \\hfill\n\t\\subfigure[\\textcolor{upload}{Upload} and \\textcolor{download}{download} streams in \\Method.]{\\includegraphics[width=0.42\\linewidth]{figs/fig2.pdf}\\label{fig:cp_b}}\n\t\\caption{(a) The conditional policy separates information from ${\\bm h}_i$ into ${\\bm r}_i \\odot {\\bm h}_i$ and ${\\bm s}_i \\odot {\\bm h}_i$ in the \\textcolor{red}{red rhomboid}. Except for the feature vectors and vector ${\\bm v}_i$, a standard rectangle and a rounded rectangle represent a layer and a module, respectively. The rounded rectangle with the dashed border is $\\widehat{{\\bm W}}^{hd}_i$ in \\cref{eq:3}. ${\\bm W}^{fe}$ (\\textcolor{gray_}{gray border}) is not a part of the personalized model, where data only flows forward during training. Data flows in all the lines \\emph{during training}, but it only flows in the solid lines \\emph{during inference}. (b) For clarity, we separately show the \\textcolor{upload}{upload} and \\textcolor{download}{download} streams for the feature extractors, the heads, and the \\Policys. Still, we upload or download them as a union between the server and each client in practice. Best viewed in color. }\n\t\\label{fig:cp}\n\\end{figure*}",
            "fig:cam": "\\begin{figure}[!h]\n\t\\centering\n\t\\includegraphics[width=\\linewidth]{figs/cam_3.pdf}\n\t\\caption{The first row shows six samples from Tiny-ImageNet. The second and third rows respectively show the Grad-CAM visualizations of the learned personalized model with only the global head or the personalized head activated. Highlighted areas are the parts the model pays attention to. }\n\t\\label{fig:cam}\n\\end{figure}",
            "fig:abl": "\\begin{figure*}[!ht]\n\t\\centering\n\t\\hfill\n\t\\subfigure[\\textit{w.o. GFM}]{\\includegraphics[width=0.2\\linewidth]{figs/noMMD.pdf}\\label{fig:abl_2}}\n\t\\hfill\n\t\\subfigure[\\textit{w.o. \\Policy}]{\\includegraphics[width=0.14\\linewidth]{figs/noCP.pdf}\\label{fig:abl_3}}\n\t\\hfill\n\t\\subfigure[\\textit{w.o. \\Policy \\& GFM}]{\\includegraphics[width=0.14\\linewidth]{figs/noCPnoMMD.pdf}\\label{fig:abl_4}}\n\t\\hfill\n\t\\subfigure[\\textit{w.o. \\Policy \\& GH}]{\\includegraphics[width=0.14\\linewidth]{figs/noCPnoFGH.pdf}\\label{fig:abl_5}}\n\t\\hfill\n\t\\subfigure[\\textit{w.o. \\Policy \\& GFM \\& GH}]{\\includegraphics[width=0.14\\linewidth]{figs/noCPnoMMDnoFGH.pdf}\\label{fig:abl_6}}\n\t\\hfill\n\t\\hfill\n\t\\caption{Illustration of variants for module ablation study.}\n\t\\label{fig:abl}\n\\end{figure*}",
            "fig:policy": "\\begin{figure}[h]\n\t\\centering\n\t\\subfigure[PIR change on client \\#0.]{\\includegraphics[width=0.39\\linewidth]{figs/lineplot.pdf}\\label{fig:policy_a}}\n    \\hfill\n\t\\subfigure[${\\bm s}_i$ distribution of test samples on all clients.]{\\includegraphics[width=0.6\\linewidth]{figs/kdeplot1.pdf}\\label{fig:policy_b}}\n\t\\caption{Visualizations for PIR and ${\\bm s}_i$ distribution on Tiny-ImageNet in the default practical setting. \\textcolor{blue_}{Blue color} and \\textcolor{orange_}{orange color} represent the figures for the \\textcolor{blue_}{4-layer CNN} and \\textcolor{orange_}{ResNet-18}, respectively. We draw PIR change curves for training samples. Best viewed in color. }\n\t\\label{fig:policy}\n\\end{figure}",
            "fig:converge": "\\begin{figure}[h]\n\t\\centering\n\t\\subfigure[Training loss ($\\mathcal{G}$) curves]{\\includegraphics[width=\\linewidth]{figs/converge_loss.pdf}}\n\t\\subfigure[Test accuracy curves]{\\includegraphics[width=\\linewidth]{figs/converge_acc.pdf}}\n\t\\caption{The training loss curves and test accuracy curves when using ResNet-18 on Tiny-ImageNet in the default practical setting. The \\textcolor{red_}{red circles} and \\textcolor{green_}{green cubes} represent the results evaluated \\textcolor{red_}{before local learning} and \\textcolor{green_}{after local learning}, respectively. Best viewed in color. }\n\t\\label{fig:converge}\n\\end{figure}",
            "fig:dis_tiny": "\\begin{figure}[H]\n\t\\centering\n\t\\subfigure[$\\beta$ = 0.01]{\\includegraphics[width=0.36\\linewidth]{figs/config_tiny-0.01.json.pdf}}\n    \\hfill\n\t\\subfigure[$\\beta$ = 0.1]{\\includegraphics[width=0.31\\linewidth]{figs/config_tiny-0.1.json.pdf}}\n\t\\hfill\n\t\\subfigure[$\\beta$ = 0.5]{\\includegraphics[width=0.31\\linewidth]{figs/config_tiny-0.5.json.pdf}}\n\t\\caption{The data distribution of all clients on Tiny-ImageNet in practical settings with varying $\\beta$. The size of a circle means the number of samples.}\n\t\\label{fig:dis_tiny}\n\\end{figure}",
            "fig:distribution-50100": "\\begin{figure}[H]\n\t\\centering\n\t\\subfigure[10 clients]{\\includegraphics[width=0.34\\linewidth]{figs/config-cifar100_10.json.pdf}}\n\t\\subfigure[30 clients]{\\includegraphics[width=0.64\\linewidth]{figs/config-cifar100_30.json.pdf}}\n\t\\subfigure[50 clients]{\\includegraphics[width=\\linewidth]{figs/config_cifar100_50.json.pdf}}\n\t\\subfigure[100 clients]{\\includegraphics[width=\\linewidth]{figs/config_cifar100_100.json.pdf}}\n\t\\caption{The data distribution of all clients on Cifar100 in practical settings with 10, 30, 50, and 100 clients, respectively. }\n\t\\label{fig:distribution-50100}\n\\end{figure}",
            "fig:distribution-practical": "\\begin{figure}[H]\n\t\\centering\n\t\\subfigure[MNIST (pa)]{\\includegraphics[width=0.32\\linewidth]{figs/config-mnist-patho.json.pdf}}\n    \\hfill\n\t\\subfigure[Cifar10 (pa)]{\\includegraphics[width=0.32\\linewidth]{figs/config-cifar10-patho.json.pdf}}\n\t\\hfill\n\t\\subfigure[Cifar100 (pa)]{\\includegraphics[width=0.32\\linewidth]{figs/config-cifar100-patho.json.pdf}}\n\t\\subfigure[MNIST (pr)]{\\includegraphics[width=0.32\\linewidth]{figs/config-mnist-default.json.pdf}}\n    \\hfill\n\t\\subfigure[Cifar10 (pr)]{\\includegraphics[width=0.32\\linewidth]{figs/config-cifar10-default.json.pdf}}\n\t\\hfill\n\t\\subfigure[Cifar100 (pr)]{\\includegraphics[width=0.32\\linewidth]{figs/config-cifar100-default.json.pdf}}\n\t\\caption{The data distribution of all clients in the pathological (pa) setting and default practical (pr) setting. }\n\t\\label{fig:distribution-practical}\n\\end{figure}",
            "fig:distribution-200500": "\\begin{figure}[H]\n\t\\centering\n\t\\subfigure[200 clients]{\\includegraphics[width=\\linewidth]{figs/config_cifar100_200.json.pdf}}\n\t\\subfigure[500 clients]{\\includegraphics[width=\\linewidth]{figs/config_cifar100_500.json.pdf}}\n\t\\caption{The data distribution of all clients on Cifar100 in default practical setting with 200 and 500 clients, respectively. }\n\t\\label{fig:distribution-200500}\n\\end{figure}",
            "fig:distribution-ag": "\\begin{figure}[H]\n\t\\centering\n\t\\subfigure[$\\beta$ = 0.1]{\\includegraphics[width=0.49\\linewidth]{figs/config_agnews-0.1.json.pdf}}\n\t\\subfigure[$\\beta$ = 1]{\\includegraphics[width=0.49\\linewidth]{figs/config_agnews-1.json.pdf}}\n\t\\caption{The data distribution of all clients on AG News in two heterogeneous settings. }\n\t\\label{fig:distribution-ag}\n\\end{figure}"
        },
        "equations": {
            "eq:1": "\\begin{equation}\n    \\{{\\bm W}_1, \\ldots, {\\bm W}_N\\} = \\argmin \\ \\mathcal{G}(\\mathcal{F}_1, \\ldots, \\mathcal{F}_N).\n\\end{equation}",
            "eq:2": "\\begin{equation}\n    {\\bm h}_i = f({\\bm x}_i; {\\bm W}^{fe}_i), \\forall ({\\bm x}_i, y_i) \\in \\mathcal{D}_i. \\label{eq:feat}\n\\end{equation}",
            "eq:3": "\\begin{equation}\n    \\{{\\bm r}_i, {\\bm s}_i\\} := {\\rm \\Policy}(\\mathcal{C}_i; {\\bm \\Theta}_i), \\label{eq:policy}\n\\end{equation}",
            "eq:4": "\\begin{equation}\n    r^k_{i} = \\frac{\\exp{(a^{k}_{i, 1})}}{\\sum_{j\\in \\{1, 2\\}}\\exp{(a^{k}_{i, j})}}, \\quad s^k_{i} = \\frac{\\exp{(a^{k}_{i, 2})}}{\\sum_{j\\in \\{1, 2\\}}\\exp{(a^{k}_{i, j})}}.\n\\end{equation}",
            "eq:5": "\\begin{equation}\n    \\mathcal{E}_i = \\mathbb{E}_{({\\bm x}_i, y_i) \\sim \\mathcal{D}_i} \\mathcal{L}({\\bm {out}_i}, y_i), \\label{eq:e_loss}\n\\end{equation}",
            "eq:6": "\\begin{equation}\n    \\widehat{{\\bm W}}^{hd}_i = \\frac{{\\bm W}^{hd} + {\\bm W}^{hd}_i}{2}. \\label{eq:3}\n\\end{equation}",
            "eq:7": "\\begin{equation}\n    \\mathcal{E}^{d}_i = ||\\mathbb{E}_{({\\bm x}_i, y_i) \\sim \\mathcal{D}_i} \\phi({\\bm h}_i) - \\mathbb{E}_{({\\bm x}_i, y_i) \\sim \\mathcal{D}_i} \\phi(f({\\bm x}_i; {\\bm W}^{fe}))||_{\\mathcal{H}}^2 ,\n\\end{equation}",
            "eq:8": "\\begin{equation}\n\\begin{aligned}\n    \\mathcal{F}_i &=\\mathbb{E}_{({\\bm x}_i, y_i) \\sim \\mathcal{D}_i} \\mathcal{L}[g({\\bm r}_i \\odot{\\bm h}_i; {\\bm W}^{hd}) + g({\\bm s}_i \\odot{\\bm h}_i; {\\bm W}^{hd}_i), y_i] \\\\\n    & + \\lambda ||\\mathbb{E}_{({\\bm x}_i, y_i) \\sim \\mathcal{D}_i} \\phi({\\bm h}_i) - \\mathbb{E}_{({\\bm x}_i, y_i) \\sim \\mathcal{D}_i} \\phi(f({\\bm x}_i; {\\bm W}^{fe}))||_{\\mathcal{H}}^2, \\label{eq:final}\n\\end{aligned}\n\\end{equation}",
            "eq:9": "\\begin{equation}\n    \\{{\\bm W}_1, \\ldots, {\\bm W}_N\\} = \\argmin \\ \\mathcal{G}(\\mathcal{F}_1, \\ldots, \\mathcal{F}_N),\n\\end{equation}"
        },
        "git_link": "https://github.com/TsingZ0/FedCP"
    }
}