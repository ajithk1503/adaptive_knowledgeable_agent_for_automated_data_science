{
    "meta_info": {
        "title": "Attribute-Enhanced Similarity Ranking for Sparse Link Prediction",
        "abstract": "Link prediction is a fundamental problem in graph data. In its most realistic\nsetting, the problem consists of predicting missing or future links between\nrandom pairs of nodes from the set of disconnected pairs. Graph Neural Networks\n(GNNs) have become the predominant framework for link prediction. GNN-based\nmethods treat link prediction as a binary classification problem and handle the\nextreme class imbalance -- real graphs are very sparse -- by sampling\n(uniformly at random) a balanced number of disconnected pairs not only for\ntraining but also for evaluation. However, we show that the reported\nperformance of GNNs for link prediction in the balanced setting does not\ntranslate to the more realistic imbalanced setting and that simpler\ntopology-based approaches are often better at handling sparsity. These findings\nmotivate Gelato, a similarity-based link-prediction method that applies (1)\ngraph learning based on node attributes to enhance a topological heuristic, (2)\na ranking loss for addressing class imbalance, and (3) a negative sampling\nscheme that efficiently selects hard training pairs via graph partitioning.\nExperiments show that Gelato outperforms existing GNN-based alternatives.",
        "author": "Jo\u00e3o Mattos, Zexi Huang, Mert Kosan, Ambuj Singh, Arlei Silva",
        "link": "http://arxiv.org/abs/2412.00261v1",
        "category": [
            "cs.LG",
            "cs.AI",
            "cs.SI"
        ],
        "additionl_info": "To appear at the 31st SIGKDD Conference on Knowledge Discovery and  Data Mining - Research Track (August 2024 Deadline)"
    },
    "latex_extraction": {
        "content": {
            "section 1": {
                "name": "Introduction",
                "content": "\n\\label{sec::introduction}\n%intro+abstract: 1.5, related: .5, methods 3 (3-4 subsections), results 4 (5 sub-sections), conclusion: .25 \n\n%Graph-structured data is ubiquitous. \n%Graphs are a ubiquitous data structure that abstracts many real-world complex systems into entities (nodes or vertices) and their relationships (edges or links). \n%Machine learning on graphs supports various structured-data applications including social network analysis \\cite{tang2008arnetminer, li2017deepcas, qiu2018deepinf}, recommender systems \\cite{jamali2009trustwalker,monti2017geometric,wang2019kgat}, natural language processing \\cite{sun2018open, sahu2019inter, yao2019graph}, and physics modeling \\cite{sanchez2018graph,ivanovic2019trajectron,da2020combining}. Among the graph-related tasks, one could argue that link prediction \\cite{lu2011link, martinez2016survey} is the most fundamental one as it not only has many concrete application \\cite{qi2006evaluation, liben2007link, koren2009matrix}, but can also be used as a preprocessing step for other tasks \\cite{martin2016structural, bahulkar2018community, wilder2019end} since the observed graph is usually noise and/or incomplete. \n\nMachine learning on graphs supports various structured-data applications including social network analysis \\citep{tang2008arnetminer, li2017deepcas, qiu2018deepinf}, recommender systems \\citep{jamali2009trustwalker,monti2017geometric,wang2019kgat}, natural language processing \\citep{sun2018open, sahu2019inter, yao2019graph}, and physics modeling \\citep{sanchez2018graph,ivanovic2019trajectron,da2020combining}. Among the graph-related tasks, one could argue that link prediction, which consists of predicting missing or future links \\citep{lu2011link, martinez2016survey}, is the most fundamental one. This is because link prediction not only has many concrete applications \\citep{qi2006evaluation, liben2007link} %(e.g. friendship and product recommendation \\cite{liben2007link, koren2009matrix}, uncovering protein-protein interactions \\cite{qi2006evaluation}) \nbut can also be considered an (implicit or explicit) step of the graph-based machine learning pipeline \\citep{martin2016structural, bahulkar2018community, wilder2019end}---as the observed graph is usually noisy and/or incomplete. \n\nGraph Neural Networks (GNNs) \\citep{kipf2016semi, hamilton2017inductive, velivckovic2018graph} have emerged as the predominant paradigm for machine learning on graphs. Similar to their great success in node classification \\citep{klicpera2018predict, wu2019simplifying, zheng2020robust} and graph classification \\citep{ying2018hierarchical, zhang2018end, morris2019weisfeiler}, GNNs have been shown to achieve state-of-the-art link prediction performance \\citep{zhang2018link,liu2020feature,pan2021neural,yun2021neo,chamberlain2022graph, wang2023neural}. Compared to classical approaches that rely on expert-designed heuristics to extract topological information (e.g., Common Neighbors \\citep{newman2001clustering}, Adamic-Adar \\citep{adamic2003friends}, Preferential Attachment \\citep{barabasi2002evolution}), GNNs can naturally incorporate attributes and are believed to be able to learn new effective heuristics directly from data via supervised learning. \\looseness=-1\n\nHowever, we argue that \\textit{the evaluation of GNN-based link prediction methods paints an overly optimistic view of their model performance}. Most real graphs are sparse and have a modular structure \\citep{barabsi2016network,newman2018networks}. In \\textsc{Cora} and \\textsc{Citeseer} (citation networks), less than 0.2\\% of the node pairs are links/positive (see \\autoref{tab::dataset}) and modules arise around research topics. Yet GNN-based link prediction methods are evaluated on an artificially balanced test set that includes every positive pair but only a small sample of the negative ones chosen uniformly at random \\citep{hu2020open}. Due to modularity, the majority of negative pairs sampled are expected to be relatively far from each other (i.e. across different modules) compared to positive pairs. As a consequence, performance metrics reported for this balanced setting, which we call \\textit{biased testing}, differ widely from the ones observed for the more challenging \\textit{unbiased testing}, where the test set includes every disconnected pair of nodes. In particular, we have found that unsupervised topological heuristics are more competitive in the \\emph{unbiased setting}, often outperforming recent GNN-based link prediction methods. This finding has motivated us to rethink the design of link prediction methods for sparse graphs.\n\nA key hypothesis of our work is that effective unbiased link prediction in sparse graphs requires a similarity metric that can distinguish positive pairs from hard negative ones. More specifically, link prediction should be seen as a ``needle in the haystack'' type of problem, where extreme class imbalance makes even the most similar pairs still more likely to be negative. Existing GNN-based approaches fail in this sparse regime due to (1) their use of a binary classification loss that is highly sensitive to class imbalance; (2) their \\emph{biased training} that mimics \\emph{biased testing}; (3) their inability to learn effective topological heuristics directly from data.  \n\n%GNNs perform poorly at the unbiased link prediction due to (1) their inability to learn a similarity metric and (2) their biased training; and (3) their use of a classification loss that is incompatible with the extreme class imbalance of the problem. Similarity metrics are \n\n%However, there is little understanding on what factors contribute to the success of GNNs in link prediction, and whether simpler alternatives can achieve comparable performance, as found for other tasks \\cite{huang2020combining}. Specifically, GNN-based methods approach link prediction as a binary classification problem, and depends on the expressiveness of GNNs to learn arbitrary heuristics directly from the data \\cite{zhang2018link, srinivasan2019equivalence, zhang2021labeling}. Yet different from other classification problems, link prediction deals with extremely class-imbalanced data due to the sparsity of real-world graphs. And it is unclear whether GNNs have properly addressed the class imbalance in their training and evaluation, and whether that affects their generalization capability in practice. In addition, GNNs combine topological and attribute information via message-passing and leverage topology-smoothened attributes (embeddings) for downstream tasks \\cite{li2018deeper}. This attribute-centric mechanism has been proven effective for tasks \\emph{on} the topology such as node classification \\cite{ma2020copulagnn}, but it is unclear whether it also benefits link prediction as it is a task \\emph{for} the topology. \n\n\\begin{comment}\n    \n\\begin{figure}\n    \\captionsetup[subfloat]{position=bottom, captionskip=0pt}\n\t\\centering\n\t\\subfloat[Link prediction with attributes]{\\includegraphics[height=0.076\\textheight]{fig/topology_attribute_lp.pdf}}\n \\hspace{2pt}\n\t\\subfloat[GNN: topology $\\rightarrow$ attributes]{\\includegraphics[height=0.076\\textheight]{fig/message_passing_lp.pdf}}\n\t\\hspace{2pt}\n\t\\subfloat[Gelato: attributes$\\rightarrow$topology\\looseness=-1]{\\includegraphics[height=0.076\\textheight]{fig/graph_learning_lp.pdf}}\n\t\\caption{GNN incorporates topology into attributes via message-passing while our approach (Gelato) leverages graph learning to incorporate attributes into topology. \\looseness=-1}\n %\\caption{GNN incorporates topology into attributes via message-passing, which is effective for tasks \\textbf{\\emph{on}} the topology. %e.g., node classification. \n%\tLink prediction, however, is a task \\textbf{\\emph{for}} the topology, which motivates the design of Gelato---a novel framework that leverages graph learning to incorporate attributes into topology. %\\looseness=-1}\n\t\\label{fig::intro}\n\\end{figure}\n\\end{comment}\n\n%the structure of a graph is \\emph{defined} by its links. % as it is a task on the graph topology (structure) itself. Because most real graphs are dynamic and have missing data, link prediction  \n% Link prediction has many concrete applications  and is a useful .  \n\n%TODO: Consider removing the attributes->topology part.\n%However, there is little understanding of what contributes to the success of GNNs in link prediction, and whether simpler alternatives can achieve comparable performance---as found for node classification \\citep{huang2020combining}. GNN-based methods approach link prediction as a binary classification problem. Yet different from other classification problems, link prediction deals with extremely class-imbalanced data due to the sparsity of real-world graphs. We argue that class imbalance should be accounted for in both training and evaluation of link prediction. In addition, GNNs combine topological and attribute information by learning topology-smoothened attributes (embeddings) via message-passing \\citep{li2018deeper}. This attribute-centric mechanism has been proven effective for tasks \\emph{on} the topology such as node classification \\citep{ma2020copulagnn}, but link prediction is a task \\emph{for} the topology, which naturally motivates topology-centric paradigms (see \\autoref{fig::intro}). \n\n%However, there is little understanding of what contributes to the success of GNNs in link prediction, and whether simpler alternatives can achieve comparable performance---as found for node classification \\citep{huang2020combining}. GNN-based methods approach link prediction as a binary classification problem. Yet different from other classification problems, link prediction deals with extremely class-imbalanced data due to the sparsity of real-world graphs. We argue that class imbalance should be accounted for in both training and evaluation of link prediction. In particular, GNNs combine topological and attribute information by learning topology-smoothened attributes (embeddings) via message-passing, which is more prone to class imbalance due to the large number of parameters to be trained \\citep{li2018deeper}. On the other hand, topology-based link prediction methods are effective at capturing structural similarity in sparse data but cannot account for attribute information. This naturally motivates topology-centric paradigms that leverage attribute data (see \\autoref{fig::intro}). %This attribute-centric mechanism has been proven effective for tasks \\emph{on} the topology such as node classification \\citep{ma2020copulagnn}, but link prediction is a task \\emph{for} the topology, which naturally motivates topology-centric paradigms (see \\autoref{fig::intro}). \n\n\n%they are necessary for good performance.\n% \\begin{figure}\n% \t\\centering\n% \t\\subfloat{\\includegraphics[height=0.14\\textheight, valign=c]{fig/gnn-lp-computation.pdf}}\n% \t\\hspace{0.03\\textwidth}\n% \t\\subfloat{\\includegraphics[height=0.125\\textheight, valign=c]{fig/gnn-lp-nc.pdf}}\n% \t\\hspace{0.04\\textwidth}\n% \t\\subfloat{\\includegraphics[height=0.125\\textheight, valign=c]{fig/gnn-lp-lp.pdf}}\\\\\n% \t\\hspace{0.05\\textwidth}\n% \t{\\footnotesize (a) GNN message-passing}\\hspace{0.16\\textwidth}\n% \t{\\footnotesize (b) Node classification}\\hspace{0.10\\textwidth}\n% \t{\\footnotesize (c) Link prediction}\n% \t\\caption{GNN incorporates topology into attributes via the message-passing mechanism, which has been proven effective for tasks \\textbf{\\emph{on}} the topology, e.g., node classification. Link prediction, however, is a task \\textbf{\\emph{for}} the topology, which motivates the design of Gelato---a novel alternative framework that incorporates attributes into topology.}\n% \t\\label{fig::intro}\n% \\end{figure}\n\n% Specifically, we ask the following questions: (1) Does the formulation of link prediction as a supervised learning problem help solve it? (2) Is the inclusion of node attributes the key for  improved performance? And (3) do GNNs actually learn more effective ways to extract topological information compared to heuristics? \n\n%The goal of this paper is to answer these questions. We first find that the evaluation metrics in GNN-based link predictions provide a overly optimistic measurement of model performance in the imbalanced setting, and their training scheme is designed for those biased metrics. Instead, we propose the use of a rank-based loss for link prediction to address class imbalance, and show its superiority in practice. We then introduce a novel framework, Gelato, to combine topological and attribute information for link prediction as an alternative to GNNs. Our simple model consists of a Multi-Layer Perceptron (MLP) to incorporate node attributes directly into graph structure and a topological heuristic, Autocovariance (AC), for link prediction based on the attribute-enhanced graph. Extensive experiments demonstrate significant improvement of our model over state-of-the-art GNN-based methods in both accuracy and running speed. \n\nThe goal of this paper is to address the key limitations of GNNs for link prediction mentioned above. We present \\emph{Gelato}, a novel similarity-based framework for link prediction that combines a topological heuristic and graph learning to leverage both topological and attribute information. Gelato applies a ranking-based N-pair loss and partitioning-based negative sampling to select hard training node pairs. Extensive experiments demonstrate that our model significantly outperforms state-of-the-art GNNs in both accuracy and scalability. \\autoref{fig::overview} provides an overview of our approach.\n\n\n% As a simpler alternative to GNNs, our model applies a Multi-Layer Perceptron (MLP) to incorporate node attributes directly into the graph structure and leverages a topological heuristic, Autocovariance (AC), for link prediction based on the attribute-enhanced graph.\n\n\n%To summarize, our contributions are: (1) We scrutinize the training and evaluation of supervised link prediction methods and identify their limitations in handling class imbalance; (2) we propose a simple, effective, and efficient framework to combine topological and attribute information for link prediction without using GNNs; (3) we introduce an N-pair link prediction loss combined with an unbiased set of training edges that we show to be more effective at addressing class imbalance. \n\n% \\begin{figure*}[ht!]\n%     \\centering\n%     \\includegraphics[width=1\\linewidth]{iclr2023/fig/overview_iclr_neg_samp.pdf}\n%     \\caption{Gelato applies graph learning to incorporate attribute information into the topology. The learned graph is given to a topological heuristic that predicts edges between node pairs with high Autocovariance similarity. The parameters of the MLP are optimized end-to-end using the N-pair loss over node pairs selected via a partitioning-based negative sampling scheme. Experiments show that Gelato outperforms state-of-the-art GNN-based link prediction methods. \\looseness=-1%, including those based on GNNs. \n%     }\n%     \\label{fig::overview}\n% \\end{figure*}\n\nTo summarize, our contributions are: (1) We scrutinize the evaluation of supervised link prediction methods and identify their limitations in handling class imbalance; (2) we propose a simple, effective, and efficient framework to combine topological and attribute information for link prediction in an innovative fashion;\n(3) we introduce an N-pair link prediction loss that we show to be more effective at addressing class imbalance; and (4) we propose an efficient partitioning-based negative sampling scheme that improves link prediction generalization in the sparse setting.\n\n% While similar questions have been raised in the context of node classification \\cite{huang2020combining, ma2020copulagnn}, we find these questions especially relevant for link prediction for two reasons. First, link prediction deals with extremely class-imbalanced data due to the sparsity of real-world graphs, which brings additional challenges for supervised learning. Second, since link prediction is a task on the topology, the input graph structure should play a more critical role than node attributes. Note that the opposite is usually assumed in node classification when GNNs are applied to generate topology-smoothened attributes (embeddings) via message-passing \\cite{li2018deeper}. \n\n% The goal of this paper is to answer the questions raised above and present a clearer picture on the usefulness of GNNs in link prediction. Specifically, we make the following contributions: (1) We scrutinize the training and evaluation of supervised link prediction methods and identify their limitations in handling class imbalance. (2) We propose a novel framework to combine topological and attribute information for link prediction without using GNNs. Our simple model consists of a Multi-Layer Perceptron (MLP) to incorporate node attributes into graph structure and a topological heuristic, Autocovariance (AC), for link prediction based on the attribute-enhanced graph. Our experiments demonstrate significant improvement of our model over state-of-the-art methods in both performance and efficiency. (3) We introduce a rank-based loss for link prediction and argue for the use of all negative (disconnected) pairs in training to address class imbalance. \n\n%(1) we scrutinize the training and evaluation of supervised link prediction methods and identify their limitations in handling class imbalance; (2) we propose a novel framework to combine topological and attribute information for link prediction without using GNNs.; (3) we introduce a rank-based loss for link prediction and argue for the use of all negative (disconnected) pairs in training to address class imbalance. \n\n% Candidate name: \\underline{G}raph \\underline{e}nhancement for \\underline{l}ink prediction with \\underline{a}u\\underline{to}covariance (Gelato).\n\n% Introduction:\n% \\begin{itemize}\n%     \\item Link prediction is a more fundamental problem compared to e.g., node classification. Hard to solve the problem without the graph. \n%     \\item GNN's the togo solution for link prediciton because GNN's great applications in other area. Advantages of GNN: It naturally captures attributes. \n%     \\item Second question: whether the data-driven supervision guide to learn topological classic algorithms? Whether they generalize to the actual setting of the application. \n%     First question: Where is their gain? Is the gain because of the attributes only? What if old models are also with attributes are very fair. \n%     \\item These questions are specifically relevant for LP because link prediction is imbalanced different from node classification, and how attributes are used. In node classification Correct&Smooth tries to answer already. \n%     \\item And in our paper, we will answer the questions. We look at the way of evaluation and we find they doesn't generalize to the setting, even simple heuristic beat SOTA in imbalanced setting. We look at ways to incorporate attributes into classic heuristics. We also propose the loss to adapt to the imbalance setting. \n%     % \\item Problem of supervised link prediction. Training and testing. \n%     % \\item Connecting to GNN cannot learn simple heuristics? \n%     % \\item Simple model. \n%     % \\item Rank-based loss. \n% \\end{itemize}\n\n% Contributions:\n% \\begin{itemize}\n%     \\item Criticize evaluation and training for supervised link prediction;\n%     \\item Combining topological heuristic and graph learning, simple. GNNs do not perform as well as topological heuristics;\n%     \\item Rank-based loss. We care about one class. Full training.\n% \\end{itemize}\n\n\n\n\n% Please read the instructions below carefully and follow them faithfully.\n\n\n% \\subsection{Style}\n\n\n% Papers to be submitted to NeurIPS 2022 must be prepared according to the\n% instructions presented here. Papers may only be up to {\\bf nine} pages long,\n% including figures. Additional pages \\emph{containing only acknowledgments and\n% references} are allowed. Papers that exceed the page limit will not be\n% reviewed, or in any other way considered for presentation at the conference.\n\n\n% The margins in 2022 are the same as those in 2007, which allow for $\\sim$$15\\%$\n% more words in the paper compared to earlier years.\n\n\n% Authors are required to use the NeurIPS \\LaTeX{} style files obtainable at the\n% NeurIPS website as indicated below. Please make sure you use the current files\n% and not previous versions. Tweaking the style files may be grounds for\n% rejection.\n\n\n% \\subsection{Retrieval of style files}\n\n\n% The style files for NeurIPS and other conference information are available on\n% the World Wide Web at\n% \\begin{center}\n%   \\url{http://www.neurips.cc/}\n% \\end{center}\n% The file \\verb+neurips_2022.pdf+ contains these instructions and illustrates the\n% various formatting requirements your NeurIPS paper must satisfy.\n\n\n% The only supported style file for NeurIPS 2022 is \\verb+neurips_2022.sty+,\n% rewritten for \\LaTeXe{}.  \\textbf{Previous style files for \\LaTeX{} 2.09,\n%   Microsoft Word, and RTF are no longer supported!}\n\n\n% The \\LaTeX{} style file contains three optional arguments: \\verb+final+, which\n% creates a camera-ready copy, \\verb+preprint+, which creates a preprint for\n% submission to, e.g., arXiv, and \\verb+nonatbib+, which will not load the\n% \\verb+natbib+ package for you in case of package clash.\n\n\n% \\paragraph{Preprint option}\n% If you wish to post a preprint of your work online, e.g., on arXiv, using the\n% NeurIPS style, please use the \\verb+preprint+ option. This will create a\n% nonanonymized version of your work with the text ``Preprint. Work in progress.''\n% in the footer. This version may be distributed as you see fit. Please \\textbf{do\n%   not} use the \\verb+final+ option, which should \\textbf{only} be used for\n% papers accepted to NeurIPS.\n\n\n% At submission time, please omit the \\verb+final+ and \\verb+preprint+\n% options. This will anonymize your submission and add line numbers to aid\n% review. Please do \\emph{not} refer to these line numbers in your paper as they\n% will be removed during generation of camera-ready copies.\n\n\n% The file \\verb+neurips_2022.tex+ may be used as a ``shell'' for writing your\n% paper. All you have to do is replace the author, title, abstract, and text of\n% the paper with your own.\n\n\n% The formatting instructions contained in these style files are summarized in\n% Sections \\ref{gen_inst}, \\ref{headings}, and \\ref{others} below.\\looseness=-1\n"
            },
            "section 2": {
                "name": "Limitations in supervised link prediction evaluation",
                "content": "\n\\label{sec::limitations}\nSupervised link prediction is often formulated as binary classification, where the positive (or negative) class includes node pairs connected (or not connected) by a link. A key difference between link prediction and other classification problems is that the two classes in link prediction are \\emph{extremely} imbalanced as most graphs of interest are sparse---e.g. the datasets from \\autoref{tab::dataset} are significantly more imbalanced than those in \\cite{tang2008svms}. However, the class imbalance is not properly addressed in the evaluation of existing approaches. \n\n% that most existing supervised link prediction approaches \\cite{kipf2016variational, zhang2018link, chami2019hyperbolic, zhang2021lorentzian, yan2021link, zhu2021neural, chen2022bscnets, pan2021neural} have not properly addressed class imbalance in their evaluation and training, as discussed below. \n\nExisting link prediction methods \\citep{kipf2016variational, zhang2018link, chami2019hyperbolic, zhang2021lorentzian, cai2021line, yan2021link, zhu2021neural, chen2022bscnets, pan2021neural} are evaluated on a test set containing all positive test pairs and only an equal number of random negative pairs. Similarly, the Open Graph Benchmark (OGB) ranks predicted links against a very small sample of random negative pairs.  We term these approaches \\emph{biased testing} as they highly overestimate the ratio of positive pairs in the graph. This issue is exacerbated in most real graphs, where community structure \\citep{newman2006modularity} causes random negative pairs to be particularly easy to identify \\cite{li2024evaluating}---they likely involve members of different communities. Evaluation metrics based on biased testing provide an overly optimistic assessment of the performance in \\emph{unbiased testing}, where every negative pair is included in the test set. In fact, in real applications where positive test edges are not known a priori, it is impossible to construct those biased test sets to begin with. %Below, we present two illustrative examples of the misleading performance evaluation based on \\emph{biased testing}. \n\n% \\color{black}\n% \\emph{Example}: Suppose a random binary classifier $C$ and a training set of $|E_{pos}|$ positive pairs and $|E_{neg}|$ negative pairs. $C$ classifies every pair $(u, v) \\in E_{pos} \\cup E_{neg}$  randomly following a biased coin with probability $p=\\nicefrac{|E_{pos}|}{(|E_{pos}| + |E_{neg}|)}$\n% % $Ber(p=\\cfrac{|E_{pos}|}{|E_{pos}| + |E_{neg}|})$. \n% Adopting the highly overoptimistic training and evaluation scenarios (\\textit{biased}, $|E_{pos}| = |E_{neg}|$) enables even a random classifier to obtain 50\\% precision. However, we can easily show that the classifier is prone to a drastic decrease in precision in realistic scenarios ($|E_{pos}| \\ll |E_{neg}|$) as the number of negative pairs grows through the expected precision of this classifier can be expressed by $\\mathop{\\mathbb{E}}[\\nicefrac{TP}{(TP + FP)}]=p$.  Our experimental results show that recent classification-based link prediction approaches are subject to the same issue, under-performing in more realistic settings (unbiased and partitioned testing). \n% \\color{black}\n\nRegarding evaluation metrics, Area Under the Receiver Operating Characteristic Curve (AUC) and Average Precision (AP) are the two most popular evaluation metrics for supervised link prediction \\citep{kipf2016variational, zhang2018link, chami2019hyperbolic, zhang2021lorentzian, cai2021line, yan2021link, zhu2021neural, chen2022bscnets, pan2021neural}. We first argue that, as in other imbalanced classification problems \\citep{davis2006relationship, saito2015precision}, AUC is not an effective evaluation metric for link prediction as it is biased towards the majority class (non-edges). On the other hand, AP and other rank-based metrics such as Hits@$k$---used in OGB \\citep{hu2020open}---are effective for imbalanced classification \\emph{but only if evaluated on an unbiased test}. \n\n\n%\\emph{Example 1}: Consider a graph with $10K$ nodes, $100K$ edges, and $99.9M$ disconnected (or negative) pairs. A (bad) model that ranks 1M false positives higher than the true edges achieves $0.99$ AUC and $0.95$ in AP under \\emph{biased testing} with equal negative samples. (See detailed computation in the Supplementary Material.) \\looseness=-1\n\n\\emph{Example}: Consider an instance of Stochastic Block Model (SBM) \\citep{karrer2011stochastic} with $10$ blocks of size 1k, intra-block density $0.9$, and inter-block density $0.1$. The number of inter-block negative pairs is $10\\times 1\\text{k}\\times(10-1)\\times 1\\text{k}\\times (1-0.1)/2=40.5\\text{M}$, while the number of intra-block negative pairs, which have high topological similarities like the ground-truth positive pairs and are much harder to contrast against, is $10\\times 1\\text{k}\\times 1\\text{k} \\times(1-0.9)/2=0.5\\text{M}$. Biased testing would select less than $0.5\\text{M}/(0.5\\text{M}+40.5\\text{M})<2$\\% of the test negative pairs among the (hard) intra-block ones.  In this scenario, even a random classifier \n% (e.g., a biased coin with probability $p=\\nicefrac{\\#pos}{(\\#pos + \\#neg)}$) \nis expected to obtain 50\\% precision. However, the expected precision drops to less than 22\\% (9M positive pairs vs. 41M negative pairs) under \\textit{unbiased testing}. %Our experimental results show that recent supervised link prediction approaches suffer from the same issue, under-performing in more realistic settings (unbiased and partitioned testing). \n\nWe will formalize the argument used in the example above by performing link prediction on a generic instance of the SBM with intra-block density $p$, inter-block density $q$, where $p > q$, and $k$ blocks of size $n$. In particular, we will consider an instance of SBM corresponding to the expected node pattern given the parameters, where a node is connected to $(n-1)p$ other nodes within its block and $(nk-n)q$ nodes outside its block. In this setting, the optimal link prediction algorithm can only distinguish potential links within or across blocks---as pairs within each set are connected with probability $p$ and $q$, respectively.\n\n\\begin{lemma}\nThe ratio $\\alpha$ between inter-cluster and intra-cluster negative node pairs in the SBM is such that:\n\\begin{equation*}\n\\alpha \\geq (k-1)\\frac{1-q}{1-p}\n\\end{equation*}\n\\end{lemma}\n\nThe above lemma follows directly from the definition of the SBM and shows that the set of negative pairs is dominated by (easy) inter-cluster pairs as $p$ increases compared to $q$. %Table \\ref{table::sbm} shows the values of $p$ and $q$ for the datasets considered in this paper where we use the ground-truth partitions (i.e., node labels) to identify the blocks. \n\n\\begin{theorem}\nIn the unbiased setting, the optimal accuracy link prediction method based on binary classification for the SBM predicts no links if $p < 0.5$.\n\\label{thm::unbiased}\n\\end{theorem}\n\nThe proof is given in the Appendix \\ref{ap:proof_unbiased}. Intuitively, even if the classifier has access to the SBM block structure, most within-block pairs are disconnected and thus the accuracy is maximized if no links are predicted. On the other hand, if $p > q$, an effective link prediction method should be able to leverage the SBM block structure to predict within block links. This motivates our formulation of link prediction as a ``needle in the haystack'' type of problem, where even the top candidate links (i.e., within-block pairs) are still more likely to be negative due to the sparsity of the graph. We show datasets considered fit this scenario, as shown in Appendix \\ref{ap::estimated_sbm}.\n\n\\begin{lemma}\n    In the biased setting, there exist non-trivial link prediction methods with optimal accuracy based on binary classification for the SBM with $p < 0.5$. \n    \\label{lemma::biased}\n\\end{lemma}\n\nThe proof is given in the Appendix \\ref{lemma::biased_proof}. The idea is that in the biased setting, a link prediction method that predicts within-block pairs as links can outperform the trivial classifier described in Theorem \\ref{thm::unbiased}. This illustrates how biased testing, which is applied by recent work on supervised link prediction, can be misleading for sparse graphs. More specifically, a model trained under the biased setting might perform poorly if evaluated in the, more realistic, unbiased setting due to possibly unforeseen distribution shifts across the settings. This is a key motivation for our work.\n\n% Before we introduce our method, we want to discuss our concerns on the current schemes of evaluation and training for supervised link prediction approaches.  \n% \\subsection{Link prediction evaluation}\n% \\label{subsec::lp_evaluation}\n% Supervised link prediction is often formulated as a binary classification problem, where the positive (or negative) class include node pairs connected or (not connected) by a link (or not). However, there is one key difference between link prediction and other classification problems (e.g., node classification)---the two classes in link prediction are extremely imbalanced, since most real-world graphs of interest are sparse (see \\autoref{tab::dataset}). \n\n%As with other classification problems, ROC AUC (Receiver Operating Characteristic Area Under Curve) is the most popular evaluation metric for supervised link prediction \\cite{kipf2016variational, zhang2018link, chami2019hyperbolic, zhang2021lorentzian, yan2021link, zhu2021neural, chen2022bscnets, pan2021neural}. \n%Supervised link prediction is often formulated as a binary classification problem, where the positive (or negative) class include node pairs connected or (not connected) by a link (or not). As with other classification problems, ROC AUC (Receiver Operating Characteristic Area Under Curve) is the most popular evaluation metric for supervised link prediction \\cite{kipf2016variational, zhang2018link, chami2019hyperbolic, zhang2021lorentzian, yan2021link, zhu2021neural, chen2022bscnets, pan2021neural}. However, one of the key differences of link prediction compared to other classification problems (e.g., node classification) is that the two classes are extremely imbalanced, since most real-world graphs of interest are sparse (see \\autoref{tab::dataset}). \n%Moreover, in various application scenarios of link prediction, be it friend recommendation in online social networks \\cite{liben2007link} or prediction of protein-protein interactions \\cite{qi2006evaluation}, we are only interested in the precision for the positive class, but not the overall classification accuracy. \n% We argue that, as in other imbalanced classification problems \\cite{saito2015precision}, the AUC is not an effective evaluation metric for link prediction. \n%This raises our concern that AUC may not be an effective evaluation metric for link prediction, as it has been shown to be misleading for imbalanced classification when we focus on the positive class \\cite{saito2015precision}. %For example, consider a toy graph with 10k nodes, 100k edges, and 99.9M negative pairs. A (bad) link prediction model predicts those 100k edges after making 10 times the mistakes (1M false positives). Yet this model enjoys a high AUC score of 0.99, as the false positive rate is only 1M/99.M $\\approx$ 0.01 when the true positive rate reaches 1.0. \n\n%Average precision (AP) is another evaluation metric seen in recent supervised link prediction works \\cite{kipf2016variational, zhang2018link, zhu2021neural, cai2021line}. However, they compute precision on a test set that contains all positive pairs and only an equal number of negative pairs sampled at random. We term this \\emph{biased testing} as it highly overestimates the ratio of positive pairs in the graph. %as the number of negative pairs is much smaller than the actual size of the negative class.\n%Inference in this setting is a significantly easier task compared to \\emph{full testing}, where every negative pair is included in the test set. A random predictor would have a precision of 50\\% at any threshold in \\emph{biased testing}, but one that equals to the density of the graph (0.1\\% for the above example) in \\emph{full testing}.\n\nThe above discussion motivates a more representative evaluation setting for supervised link prediction. We argue for the use of rank-based evaluation metrics---AP, Precision@$k$ \\citep{lu2011link}, and Hits@$k$ \\citep{bordes2013translating}---with \\emph{unbiased testing}, where positive edges are ranked against hard negative node pairs. \n%which measures the proportion of positive edges among the top $k$ predictions against all negative pairs.\nThese metrics have been widely applied in related problems, such as unsupervised link prediction \\citep{lu2011link, ou2016asymmetric, zhang2018arbitrary, random-walk-embedding}, knowledge graph completion \\citep{bordes2013translating, yang2015embedding, sun2018rotate}, and information retrieval \\citep{schutze2008introduction}, where class imbalance is also significant. \n%This metric has been widely applied in information retrieval \\cite{schutze2008introduction}, where relevant/non-relevant item classes are also assumed to be highly imbalanced. In fact, Precision@$k$ has been used in the evaluation of unsupervised link prediction methods as well \\cite{lu2011link, ou2016asymmetric, zhang2018arbitrary, random-walk-embedding}. \nIn our experiments, we will illustrate how these evaluation metrics combined with \\textit{unbiased testing} provide a drastically different and more informative performance evaluation compared to existing approaches. %Notice that for the case of large graphs, evaluating all negative pairs might be infeasible. Thus, we also propose a simple yet effective approach to sample representative negative pairs using graph partitioning.\n\n%\\noindent\\textbf{Link prediction training.} \n%Following the formulation of supervised link prediction as binary classification, most existing models adopt the binary cross entropy loss to optimize their parameters \\citep{kipf2016variational, zhang2018link, chami2019hyperbolic, zhang2021lorentzian, yan2021link, yun2021neo, zhu2021neural, chen2022bscnets}. To deal with class imbalance, these approaches downsample the negative pairs to match the number of positive pairs in the training set (\\emph{biased training}). \\emph{Biased training} is also convenient for computation due to the large number of negative pairs. However, in the same way that \\emph{biased testing} leads to an overoptimistic evaluation, \\emph{biased training} overestimates the probability of positive pairs and discards potentially useful evidence from most negative pairs. In small datasets, we show how these challenges can be addressed using \\emph{unbiased training}, where the ratio of negative pairs in the training set is the same as in the input graph. In the case of large datasets, we propose a graph partitioning scheme for negative sampling.\n\n%We highlight two drawbacks of \\emph{biased training}: (1) it induces the model to overestimate the probability of positive pairs, and (2) it discards potentially useful evidence from most negative pairs. Notice that the first drawback is often hidden by \\textit{biased testing}. Instead, this paper proposes the use of \\emph{unbiased training}, where the ratio of negative pairs in the training set is the same as in the input graph. To train our model in this highly imbalanced setting, we apply the N-pair loss for link prediction instead of the cross entropy loss (Section \\ref{subsec::loss}). \n\n%believe that these settings, which are designed for classification, are not ideal for link prediction when we care about precision at the top. Our argument is that minimizing the cross entropy with \\emph{biased training} may guide the model to distinguish positive edges from \\emph{most} negative pairs, but not \\emph{all} pairs, which is needed for high precision. In addition, the inconsistency of class label distributions between \\emph{biased training} and \\emph{full testing} can also negatively impact the learning process. We will provide our solutions to this in Section \\ref{subsec::loss} and demonstrate its superiority to the vanilla setting in Section \\ref{subsec::exp_loss}. \n\n%2. We will not introduce the loss/full training but we will criticize the \\emph{biased training} as well. Mention why in theory downsampling is bad. Seeing all negative edges + distribution of edges. \\section{Method}\n\n\n\n\n\\label{sec::method}\n\nThe limitations of supervised link prediction methods, including GNNs, to handle \\emph{unbiased testing} in sparse graphs motivate the design of a novel link prediction approach. First, preliminary results (see Table \\ref{tab::performance_ap}) have shown that topological heuristics are not impacted by class imbalance. That is because these heuristics are sensitive to small differences in structural similarity between positive and hard negative pairs while not relying on any learning---and thus not being affected by biased training. However, local structure proximity heuristics, such as Common Neighbors, are known to be less efficient in highly sparse scenarios observed in many real-world applications \\cite{mao2023revisiting}---Table \\ref{tab::dataset} shows the sparsity of our datasets. Further, unlike GNNs, topological heuristics are unable to leverage attribute information. Our approach addresses these limitations by integrating supervision into a powerful topological heuristic to leverage attribute data via graph learning.\n\n\\textbf{Notation and problem.} Consider an attributed graph $G = (V, E, X)$, where $V$ is the set of $n$ nodes, $E$ is the set of $m$ edges (links), and $X = (x_1, ..., x_n)^T \\in \\mathbb{R}^{n\\times r}$ collects $r$-dimensional node attributes. The topological (structural) information of the graph is represented by its adjacency matrix $A \\in \\mathbb{R}^{n\\times n}$, with $A_{uv} > 0$ if an edge of weight $A_{uv}$ connects nodes $u$ and $v$ and $A_{uv} = 0$, otherwise. The (weighted) degree of node $u$ is given as $d_u = \\sum_{v}A_{uv}$ and the corresponding degree vector (matrix) is denoted as $d \\in \\mathbb{R}^n$ ($D \\in \\mathbb{R}^{n\\times n})$. The volume of the graph is $\\vol(G)=\\sum_u d_u$. Our goal is to infer missing links in $G$ based on its topological and attribute information, $A$ and $X$. \\looseness=-1\n%Note that we do not require the graph to be either undirected or unweighted. \n\n\\textbf{Model overview.} \\autoref{fig::overview} provides an overview of our model. It starts by selecting training node pairs using a novel partitioning-based negative sampling scheme. Next, a topology-centric graph learning phase incorporates node attribute information directly into the graph structure via a Multi-layer Perceptron (MLP).  \nWe then apply a topological heuristic, Autocovariance (AC), to the attribute-enhanced graph to obtain a pairwise score matrix. Node pairs with the highest scores are predicted as links. The scores for training pairs are collected to compute an N-pair loss. % that favors the ranking of positive pairs over negative ones.\nFinally, the loss is used to train the MLP parameters in an end-to-end manner. We name our model Gelato (\\underline{G}raph \\underline{e}nhancement for \\underline{l}ink prediction with \\underline{a}u\\underline{to}covariance). Gelato represents a different paradigm in supervised link prediction combining a graph encoding of attributes with a topological heuristic instead of relying on node embeddings. While the building blocks of Gelato have been proposed by previous work, our paper is the first to apply these building blocks to address challenges in supervised link prediction for sparse graphs.\n\n% \\begin{figure}\n%     \\centering\n%     \\includegraphics[width=1\\linewidth]{neurips/fig/attributed-link-prediction.pdf}\n%     \\caption{Overview of OURMETHOD: }\n%     \\label{fig::overview}\n% \\end{figure}\n\n\n\n",
                "subsection 2.1": {
                    "name": "Graph learning",
                    "content": "\n\\label{subsec::graph_learning}\nThe goal of graph learning is to generate an enhanced graph that incorporates node attribute information into the topology. This can be considered as the ``dual'' operation of message-passing in GNNs, which incorporates topological information into attributes (embeddings). We propose graph learning as a more suitable scheme to combine attributes and topology for link prediction since it does not rely on the GNN to learn a topological heuristic, which we have verified empirically to be a challenge. \\looseness=-1\n\n%GNN-based link prediction methods combines topological and attribute information via a trainable neural network. While it has been shown that well-designed GNNs possess enough expressiveness to generalize to arbitrary topological link prediction heuristics in principle \\cite{zhang2018link, zhang2021labeling}, in practice we find that they underperform even the basic ones such as Common Neighbors (see the first two blocks of \\autoref{tab::performance}). Based on this observation, we propose to apply topological heuristics as the main predictor, and instead leverage graph learning to incorporate attribute information into the topology. \n\nSpecifically, our first step of graph learning is to augment the original edges with a set of node pairs based on their (untrained) attribute similarity (i.e., adding an $\\epsilon$-neighborhood graph): \n\\begin{equation}\n    \\widetilde{E} = E + \\{(u, v) \\mid s(x_u, x_v) > \\epsilon_\\eta\\}\n\\end{equation}\nwhere $s(\\cdot)$ can be any similarity function (we use cosine in our experiments) and $\\epsilon_\\eta$ is a threshold that determines the number of added pairs as a ratio $\\eta$ of the original number of edges $m$.\n\nA simple MLP then maps the pairwise node attributes into a trained edge weight for every edge in $\\widetilde{E}$:\n\\begin{equation}\n    w_{uv} = \\mlp([x_u; x_v]; \\theta)\n\\end{equation}\nwhere $[x_u;x_v]$ denotes the concatenation of $x_u$ and $x_v$ and $\\theta$ contains the trainable parameters. For undirected graphs, we instead use the following permutation invariant operator \\citep{chen2014unsupervised}:\n\\begin{equation}\n    w_{uv} = \\mlp([x_u+x_v; |x_u - x_v|]; \\theta)\n\\end{equation}\n\nThe final weights of the enhanced graph are a combination of the topological, untrained, and trained weights:\n\\begin{equation}\n    \\widetilde{A}_{uv} = \\alpha A_{uv} + (1-\\alpha)(\\beta w_{uv} + (1-\\beta) s(x_u, x_v))\n\\end{equation}\nwhere $\\alpha$ and $\\beta$ are hyperparameters. The enhanced adjacency matrix $\\widetilde{A}$ is then fed into a topological heuristic for link prediction introduced in the next section. The MLP is not trained directly to predict the links but instead trained end-to-end to enhance the input graph given to the topological heuristic.\n% translate node attributes into topological information to be exploited by the topological heuristic.\nFurther, the MLP can be easily replaced by a more powerful model such as a GNN (see Appendix \\ref{ap::gnn}), but the goal of this paper is to demonstrate the general effectiveness of our framework and we will show that even a simple MLP leads to significant improvement over the base heuristic. \n\n"
                },
                "subsection 2.2": {
                    "name": "Topological heuristic",
                    "content": "\n\\label{sec:topological-heuristic}\nAssuming that the learned adjacency matrix $\\widetilde{A}$ incorporates structural and attribute information, Gelato applies a topological  %link prediction \nheuristic to $\\widetilde{A}$. %While there are several such heuristics in the literature, \nSpecifically, we generalize Autocovariance, which has been shown to be effective for non-attributed graphs \\citep{random-walk-embedding}, to the attributed setting. \n%From early local and path-based methods \\cite{newman2001clustering, adamic2003friends, zhou2009predicting, katz1953new, page1999pagerank, jeh2002simrank} to more recent embedding-based ones (\\cite{perozzi2014deepwalk, grover2016node2vec, random-walk-embedding}), topological heuristics have been widely used for link prediction in unattributed graphs. As we have already incorporated the attribute information into the graph topology, we can take advantage of any of them.\nAutocovariance is a random-walk-based similarity metric. Intuitively, it measures the difference between the co-visiting probabilities for a pair of nodes in a truncated walk and in an infinitely long walk. \n%We pick Autocovariance (AC) \\cite{random-walk-embedding}, a random-walk based heuristic that has been shown to enable state-of-the-art link prediction in unattributed graphs. \nGiven the enhanced graph $\\widetilde{G}$, the Autocovariance similarity matrix $R \\in \\mathbb{R}^{n\\times n}$ is given as\n\\begin{equation}\n    \\label{eqn:autocov}\n    R = \\frac{\\widetilde{D}}{\\text{vol}(\\widetilde{G})}(\\widetilde{D}^{-1}\\widetilde{A})^t - \\frac{\\Tilde{d}\\Tilde{d}^T}{\\text{vol}^2(\\widetilde{G})}\n\\end{equation}\nwhere $t \\in \\mathbb{N}_0$ is the scaling parameter of the truncated walk. Each entry $R_{uv}$ represents a similarity score for node pair $(u, v)$, and top similarity pairs are predicted as links. Note that $R_{uv}$ only depends on the $t$-hop enclosing subgraph of $(u, v)$ and can be easily differentiated with respect to the edge weights in the subgraph. Gelato could be applied with any differentiable topological heuristics or even a combination of them. In our experiments (Section \\ref{subsec::lp_results}), we will show that Autocovariance alone enables state-of-the-art link prediction without requiring any learning. Moreover, Appendix \\ref{ap::learn_autocov} discusses whether GNNs can learn Autocovariance from data.\n\n\\noindent\\textbf{Autocovariance versus other heuristics.} Following \\cite{mao2023revisiting}, we show that local structural heuristics commonly employed by GNNs, such as Common Neighbors, exhibit reduced efficacy in sparse networks with less informative neighborhood structures. This observation motivates our selection of Autocovariance as our topological heuristic, given its ability to capture global structural patterns through random walks. Further, the parameter $t$ in Autocovariance offers adaptability to varying network sparsity levels\\cite{mao2023revisiting}, ranging from denser (lower $t$ values) to sparser (higher $t$ values) networks.\n\n% Following \\cite{mao2023revisiting}, we verify that local structural heuristics adopted by GNNs, such as Common Neighbors, are less efficient in sparse networks with neighborhood structures that are not information-rich. This motivates us to choose Autocovariance as our topological heuristic due to its capacity to capture global structural patterns through random walks. Additionally, varying values of $t$ provide flexibility to different sparsity levels, from denser (lower values of $t$) to sparser (higher values of $t$) networks \\textcolor{red}{Get revision to this claim.}. \n\n\n\\noindent\\textbf{Autocovariance distinguishes negative pairs.} Autocovariance can be seen as a general case of the Modularity metric $Q$ \\cite{delvenne2010stability}:\n\\begin{equation}\n\\label{eq:modularity}\n    Q=\\cfrac{1}{4m}\\sum_{ij}(A_{ij} - \\cfrac{d_id_j}{2m})s_is_j,\n\\end{equation}\nin which $m=\\text{vol}(G)/2$, $d_i$ and $d_j$ are the degrees of nodes $i$ and $j$, and $s_is_j$ is a product that indicates whether both nodes are in the same partition. More specifically, for $t=1$, Autocovariance expresses the graph partitioning resulting in the optimal Modularity value, which captures the relationship between the expected number of edges between two partitions compared to the probability of any random edge in the graph. This key property directly applies to our scenario, enabling Gelato to distinguish between hard (same partitions) and easy (different partitions) negative pairs and motivating us to adopt Autocovariance as our graph heuristic. Further, as $t$ increases, Autocovariance expresses growing coarser partitions until approximating spectral clustering (for $t \\rightarrow \\infty$), being flexible regarding partition sizes according to different domains.\n\n\\noindent\\textbf{Scaling up Gelato with batching and sparse operations.} Naively implementing Gelato using dense tensors is infeasible, due to the quadratic VRAM requirement ($R \\in \\mathbb{R}^{|V| \\times |V|}$). To address this limitation, we propose storing $\\widetilde{A}$ as a sparse matrix. Then, instead of directly computing $(\\widetilde{D}^{-1}\\widetilde{A})^t$ from \\autoref{eqn:autocov} (resulting on a dense $|V| \\times |V|$ matrix), we compute\n\n\n\\begin{equation}\n\\begin{aligned}\n    \\hspace{25pt} P_{l + 1} = P_l(\\widetilde{D}^{-1}\\widetilde{A}),\\hspace{25pt} l \\in \\{1, 2, ..., t\\}\n\\end{aligned}\n\\end{equation}\n\n\n\n\n\\begin{equation}\n\\begin{aligned}\n    \\hspace{25pt} R = \\frac{\\widetilde{D}}{\\text{vol}(\\widetilde{G})}P_t - \\frac{\\Tilde{d}\\Tilde{d}^T}{\\text{vol}^2(\\widetilde{G})}\n\\end{aligned}\n\\end{equation}\nwhere $P_0=(\\widetilde{D}^{-1}\\widetilde{A})_{ij}$, for all $i \\in V_{batch}$, where $V_{batch}$ consists of the nodes in the current batch. This operation substitution allows us to compute a sequence of $t$ multiplications between a dense $P_k \\in \\mathbb{R}^{|batch| \\times |V|}$ matrix and a sparse matrix $(\\widetilde{D}^{-1}\\widetilde{A}) \\in \\mathbb{R}^{|V| \\times |V|}$ instead of a dense matrix power operation, $(\\widetilde{D}^{-1}\\widetilde{A})^t$. The overall VRAM usage is reduced from $O(|V|^2)$ to $O(|batch| \\cdot |V|)$.\n\n\n\n%Next, we introduce how to train our model parameters with supervised information.  \n\n"
                },
                "subsection 2.3": {
                    "name": "N-pair loss",
                    "content": "\n\\label{subsec::loss}\nSupervised link prediction methods rely on the cross entropy loss (CE) to optimize model parameters. However, CE is known to be sensitive to class imbalance \\citep{byrd2019effect}. Instead, Gelato leverages the N-pair loss \\citep{sohn2016improved} that is inspired by the metric learning and learning-to-rank literature \\citep{mcfee2010metric,cakir2019deep, revaud2019learning, wang2019ranked} to train the parameters of our graph learning model from highly imbalanced \\emph{unbiased training} data. \n\n%, which does not fit the setting of imbalanced classification. Instead, we borrow ideas from the information retrieval and metric learning community and propose to use a rank-based loss, the N-pair loss (NP) \\cite{sohn2016improved}. \n\nThe N-pair loss (NP) contrasts each positive training edge $(u,v)$ against a set of negative pairs $N(u,v)$. It is computed as follows:\n\\begin{equation}\n    L(\\theta) = -\\sum_{(u, v) \\in E} \\log \\frac{\\exp(R_{uv})}{\\exp(R_{uv}) + \\sum_{(p, q) \\in N(u,v)} \\exp(R_{pq})}\n\\end{equation}\n%Intuitively, $L(\\theta)$ is minimized when each positive edge $(u, v)$ is ranked well above all of its negative samples: $R_{uv} \\gg R_{pq}, \\forall (p, q) \\in N(u,v)$. Compared to CE, NP is more sensitive to negative pairs that have comparable similarity to positive pairs and less sensitive to those that do not affect the rank of positive pairs. While NP achieves good performance in our experiments, there are alternative loss functions from the learning-to-rank literature \\cite{freund2003efficient,xia2008listwise,bruch2021alternative}) that could also be applied. %We leave the investigation of those loss functions for link prediction to future research. \n\nIntuitively, $L(\\theta)$ is minimized when each positive edge $(u, v)$ has a much higher similarity than its contrasted negative pairs: $R_{uv} \\gg R_{pq}, \\forall (p, q) \\in N(u,v)$. Compared to CE, NP is more sensitive to negative pairs that have comparable similarities to those of positive pairs---they are more likely to be false positives. While NP achieves good performance in our experiments, alternative losses from the learning-to-rank literature \\citep{freund2003efficient,xia2008listwise,bruch2021alternative} could also be applied. %We leave the investigation of those loss functions for link prediction to future research. \n\n"
                },
                "subsection 2.4": {
                    "name": "Negative sampling",
                    "content": "\n\\label{sec::neg_sampling}\n\n% Supervised methods for link prediction sample a small number of negative pairs uniformly at random but most of these pairs are expected to be easy (see Section \\ref{sec::limitations}). This is due to the inherent property of edge distributions in real-world graphs, which happen to be organized in communities or partitions, in which predicting a link within a partition of nodes is much harder than inter partitions. In the stochastic block model example from Section \\ref\\ref{sec::limitations}, a classification method would requrie\n\n% Joao's Notes: Original Paragraph\n% To minimize distribution shifts between training and test, negative samples $N(u, v)$ must be generated using \\emph{unbiased training}. This means that $N(u, v)$ is a random subset of all disconnected pairs in the training graph, and $|N(u,v)|$ is proportional to the ratio of negative pairs. In this way, we enforce $N(u, v)$ to include hard negative pairs. However, due to graph sparsity (see \\autoref{tab::dataset}, this approach does not scale to large graphs as the total number of negative pairs would be $O(|V|^2 - |E|)$. Supervised methods for link prediction bypass this challenge by sampling a small number of negative pairs uniformly at random but most of these pairs are expected to be easy (see Section \\ref{sec::limitations}).\n\n% Joao's Notes: New paragraph\nSupervised methods for link prediction sample a small number of negative pairs uniformly at random but most of these pairs are expected to be easy (see Section \\ref{sec::limitations}). To minimize distribution shifts between training and test, negative samples $N(u, v)$ should ideally be generated using \\emph{unbiased training} (see additional example in  Appendix \\ref{ap::example}). This means that $N(u, v)$ is a random subset of all disconnected pairs in the training graph, and $|N(u,v)|$ is proportional to the ratio of negative pairs. In this way, we enforce $N(u, v)$ to include hard negative pairs. However, due to graph sparsity (see \\autoref{tab::dataset}), this approach does not scale to large graphs as the total number of negative pairs would be $O(|V|^2 - |E|)$. \n\n\\begin{lemma}\n\\label{lemma:autocov}\nLet a Stochastic Block Model with intra-block density $p$, inter-block density $q$, and $p > q$. Then the expected Autocovariance of intra-block pairs ($R_{intra}$) is greater than the expected Autocovariance of inter-block pairs $R_{inter}$, i.e. $\\mathbb{E}[R_{intra}] > \\mathbb{E}[R_{inter}]$.\\end{lemma}\n\n\\begin{lemma}\n\\label{lemma:increasing_k}\nLet a Stochastic Block Model with intra-block density $p$, inter-block density $q$, and $p > q$. Then, $\\mathbb{E}[R_{intra}]$ monotonically increases as the number of partitions increases.\\end{lemma}\n\nConsidering Lemma \\ref{lemma:autocov} (see proof in the Appendix \\ref{ap::lemma}), we argue that it is unlikely for an inter-block pair to be ranked within the top Autocovariance pairs, implying that removing these pairs from training would not affect the results. To efficiently generate a small number of hard negative pairs, we propose a novel negative sampling scheme for link prediction based on graph partitioning \\citep{fortunato2010community,chiang2019cluster}. The idea is to select negative samples inside partitions (or communities) as they are expected to have similarity values comparable to positive pairs. We adopt METIS \\citep{karypis1998fast} as our graph partitioning method due to its scalability and its flexibility to generate partitions of a size given as a parameter (see Appendix \\ref{ap:clustering}). METIS' partitions are expected to be densely connected inside and sparsely connected across (partitions). We apply METIS to obtain $k$ partitions in which $\\forall i\\in\\{1, 2,...,k\\} : G_i = (V_i, E_i, X_i), V_i \\subset V, E_i \\subset E, X_i \\subset X$, such that $V = \\bigcup_{i=1}^k V_i$ and  $|V_i| \\approx |V|/k$. Then, we apply \\emph{unbiased training} only \\textit{within each partition}, reducing the number of sampled negative pairs to $|E^{-}| = \\sum_i^k |V_i|^2 - |E_i|$.  Following Lemma \\ref{lemma:increasing_k} (see proof on Appendix \\ref{ap::lemma_increasing_k}), the choice of the value of $k$ should consider a trade-off between training speed and link prediction performance (see Appendix \\ref{sec::similarities_non_normalized}). Further, the algorithm proposed by \\cite{newman2006modularity} could be adopted to find the optimal value of $k$ that maximizes the Modularity gain while obtaining the minimal training time. In the remainder of the paper, we refer to this approach as \\textit{partitioned training}. We claim that this procedure filters (easy) pairs consisting of nodes that would be too far away in the network topology from training while maintaining the more informative (hard) pairs that are closer and topologically similar, according to METIS. We include in the Appendix \\ref{sec::similarities_non_normalized} (See \\autoref{fig::ap::partitioned_vs_unbiased}) a performance comparison between Gelato trained using \\emph{unbiased training} against \\emph{partitioned training}.\n\n%In this way, we leverage more information contained in negative pairs compared to \\emph{biased training}. \n\n%Note that, similar to \\emph{unbiased training}, (unsupervised) topological heuristics implicitly use information from all edges and non-edges. \n\n%Also, \\emph{unbiased training} can be combined with adversarial negative sampling methods from next subsection or the knowledge graph embedding literature \\cite{cai-wang-2018-kbgan, wang2018incorporating} to increase the quality of contrasted negative pairs.\n%Thus, %we leverage all information contained in negative pairs\n%Each negative pair is contrasted against exactly one positive pair, maintaining the same distribution of class labels in the training set as in the input graph. Moreover, no information from negative pairs is discarded in the training process. \n% (or even adversarial \\cite{wang2018incorporating})\n%\\looseness=-1\n\n%keep the ratio of negative pairs in the training set same as the input graph. \n\n% Finally, we point out another challenge in training a model that applies topological heuristics and discuss our solution. Since the topological heuristics effectively extract edge existence information, all positive training edges are naturally ranked higher than most negative pairs even before the training starts. To address this problem, we divide the training positive edges into batches and during the training with each batch $E_b$, we only feed in the residual edges $E-E_b$ to the model. This encourages the model to learn to predict $E_b$ with topological information from the rest of the graph, but not from themselves, similar to the testing scenario. We term this trick \\emph{positive masking} and have empirically verified its effectiveness in improving the model generality. Note that a similar trick, \\emph{negative injection}, is proposed in GNN-based link prediction methods \\cite{zhang2018link} but is inappropriate for our setting with topological heuristics and \\emph{full training}. \n\n\n% \n\n% To train our model, we associate a set of training edges $E_b$ to each batch $b$. For each batch, edges in $E_b$ are predicted using residual training edges in $E-E_b$. This setting simulates the testing phase, where the model is expected to predict edges outside of the training set. We term this trick \\textit{positive masking} and have found it to improve model generalization in our experiments.\n\n% Finally, to guarantee that the model takes in the same amount of topological information between training edges and testing edges, for each batch of training positive edges $E_b$, we only feed the residual edges $E-E_b$ into the model. This encourages the model to learn to predict the link without its own link existence information, and increases its genefor our setting withrality in the inference setting. \n\n%\n\n%\\noindent\\textbf{Complexity analysis.} The only trainable component in our model is the graph learning MLP with $O(rh+lh^2)$ parameters---where $r$ is the number of node features, $l$ is the number of hidden layers, and $h$ is the number of neurons per layer. Notice that the number of parameters is independent of the graph size. %The untrained similarities can be efficiently approximated via anchor-based techniques \\cite{chen2020iterative} in $O(n)$. \n%Constructing the $\\epsilon$-neighborhood graph based on cosine similarity can be done efficiently using hashing and pruning \\citep{satuluri2012bayesian, anastasiu2014l2ap}. Computing the enhanced adjacency matrix with the MLP takes $O((1+\\eta)mr)$ time per epoch---where $m=|E|$ and $\\eta$ is the ratio of edges added to $E$ from the $\\epsilon$-neighborhood graph. We apply sparse matrix multiplication to compute $k$ entries of the $t$-step AC in $O(\\max(k, (1+\\eta)mt))$ time. Note that unlike recent GNN-based approaches \\citep{zhang2018link, liu2020feature, pan2021neural} that generate distinctive subgraphs for each link (e.g., via the labeling trick), enclosing subgraphs for links in Gelato share the same information (i.e., learned edge weights), which significantly reduces the computational cost. Our experiments will demonstrate Gelato's efficiency in training and inference. \n%Note that while these operations scale linearly with the graph size, both \\emph{full training} and \\emph{full testing} depend on the entire AC matrix $R$, which has $O(n^2)$ entries. Still, our experiments show that Gelato significantly outperforms the best competing methods based on GNNs in both training and testing times. \n%The latter is unavoidable as it is tied to the application scenario, but we can effectively reduce the cost of the former by downsampling both positive and negative training edges in practice. \n\n\n%\\section{Scalling Gelato to larger networks}\n\n\n\n\n\n%In this section, we propose to \\textbf{(i)} combine sparse data structures with localized matrix products to reduce memory consumption to improve scalability and \\textbf{(ii)} to improve full-training efficiency by adopting a graph-partitioning method to sample more informative negative pairs more efficiently. These procedures enable us to scale to networks with hundreds of thousands of nodes while maintaining performance, as shown in Figure \\ref{fig:sparse_gelato}.\n\n\n%\\paragraph{Sparse Tensors and matrix multiplications} \n%\\label{p:matrix_mul}\n\n%Naively implementing Gelato using dense tensors is infeasible, due to the quadratic VRAM requirement ($R \\in \\mathbb{R}^{|V| \\times |V|}$). To address this first limitation, we store $\\widetilde{A}$ as a sparse matrix, which is achievable due to the low density of matrices $W$ and $S$, also stored as sparse matrices. Then, instead of naively computing $(\\widetilde{D}^{-1}\\widetilde{A})^t$ from Equation \\ref{eqn:autocov} (resulting on a dense $|V| \\times |V|$ matrix), we compute\n\n\n%\\begin{equation}\n%\\begin{aligned}\n%    \\hspace{25pt} P_{k + 1} = P_k(\\widetilde{D}^{-1}\\widetilde{A}),\\hspace{25pt} k \\in \\{1, 2, ..., t\\}\n%\\end{aligned}\n%\\end{equation}\n\n%\\begin{equation}\n%\\begin{aligned}\n%    \\hspace{25pt} R = \\frac{\\widetilde{D}}{\\vol(\\widetilde{G})}P_t - \\frac{\\Tilde{d}\\Tilde{d}^T}{\\vol^2(\\widetilde{G})}\n%\\end{aligned}\n%\\end{equation}\n\n% \\begin{equation}\n%     R = \\frac{\\widetilde{D}}{\\vol(\\widetilde{G})}P - \\frac{\\Tilde{d}\\Tilde{d}^T}{\\vol^2(\\widetilde{G})}\n% \\end{equation}\n\n%with $P_0=(\\widetilde{D}^{-1}\\widetilde{A})_{ij}$, $i \\in V_{batch}$, where $V_{batch}$ consists of the node indexes in the current batch. To put it simply, this operation substitution allows us to compute a sequence of $t$ multiplications between a dense $P_k \\in \\mathbb{R}^{|batch| \\times |V|}$ matrix and a sparse matrix $(\\widetilde{D}^{-1}\\widetilde{A}) \\in \\mathbb{R}^{|V| \\times |V|}$ instead of a dense matrix exponentiation operation ($(\\widetilde{D}^{-1}\\widetilde{A})^t$). This simple trick reduces VRAM consumption from $O(|V|^2)$ to $O(|batch| \\cdot |V|)$, as shown in the Appendix \\textcolor{red}{X}.\n\n\n\n%\\paragraph{Partitioned Negative sampling} The second challenge we address is scaling full training to larger networks. In full training, the number of negative pairs sampled from $G$ is $|E_{neg}| = |V|^2 - |E|$, being impractical for most real-world applications. \n\n\n\n\n% ------------- OLD SCALABILITY SECTION ----------\n% \\subsection{Scalability via graph partitioning}\n\n% In Gelato's graph learning, edge weights from the entire graph can be updated for each training node pair, which requires the $O(n^2)$ autocovariance matrix to be loaded into the GPU memory. Moreover, \\emph{unbiased training} and \\emph{testing} also have quadratic cost, which limits the application of Gelato to large graphs. We address these challenges by proposing \\textit{ClusterGelato}, a scalable alternative to Gelato via graph partitioning. We will show that ClusterGelato can scale to graphs with hundreds of thousands of nodes while maintaining a comparable performance to Gelato. \n\n% \\paragraph{Graph partitioning and memory usage.} ClusterGelato assumes that training node pairs have a local effect on learned edge weights. Thus, our approach partitions the original graph into $p$ partitions $G_i \\in \\{G_1,...,G_p\\}, \\bigcap_{i}^{p} G_i = \\emptyset$, $G = \\bigcup_{i}^{p} G_i$, only requiring one partition to be loaded in GPU memory at a time.\n\n% \\paragraph{Training.} To reduce the quadratic number of negative pairs in unbiased training, ClusterGelato applies the partitions for negative sampling. It selects negative node pairs within each partition $G_i$, which are expected to be more informative for training than random pairs sampled uniformly.\n\n% \\paragraph{Inference.} Instead of evaluating the Autocovariance of every possible negative node pair during inference, ClusterGelato only considers candidate edges within partitions. The assumption is that \\textit{inter-cluster} pairs (i.e. consisting of nodes in different partitions) are less likely to be positive, and thus should automatically receive a low score and be placed at the bottom of the ranking.\n\n% While, to the best of our knowledge, ClusterGelato is the first link prediction method that applies graph partitioning for scalability, we believe that the same scheme can be applied to scale-up other supervised link prediction methods to large graphs. Compared to Gelato, ClusterGelato reduces the memory footprint, training time, and inference time from $O(n^2)$ to $O((n/p)^2)$.\n% ------------- OLD SCALABILITY SECTION ----------\n\n% We apply METIS \\cite{karypis1998fast} as our graph partitioning algorithm, due to its scalability and a balanced number of nodes per partition.\n\n% \\textbf{Limitations. } Note that while these operations scale linearly with the graph size $n$, both \\emph{full training} and \\emph{full testing} depend on the entire AC matrix $R$, which has $O(n^2)$ entries. \n\n% \\label{headings}\n\n\n% All headings should be lower case (except for first word and proper nouns),\n% flush left, and bold.\n\n\n% First-level headings should be in 12-point type.\n\n\n% \\subsection{Headings: second level}\n\n\n% Second-level headings should be in 10-point type.\n\n\n% \\subsubsection{Headings: third level}\n\n\n% Third-level headings should be in 10-point type.\n\n\n% \\paragraph{Paragraphs}\n\n\n% There is also a \\verb+\\paragraph+ command available, which sets the heading in\n% bold, flush left, and inline with the text, with the heading followed by 1\\,em\n% of space.\n\n"
                }
            },
            "section 3": {
                "name": "Experiments",
                "content": "\n\\label{sec::experiments}\n\nIn this section, we provide empirical evidence for our claims regarding supervised link prediction and demonstrate the accuracy and efficiency of Gelato. We present ablation studies in Subsection \\ref{subsec::ablation} and training time comparisons in Appendix \\ref{ap::time_comparison}. Our implementation is available at Anonymous GitHub\\footnote{\\url{https://anonymous.4open.science/r/Gelato/}}. \n\n",
                "subsection 3.1": {
                    "name": "Experiment settings",
                    "content": "\n\\label{subsec::exp_setting}\n\\textbf{Datasets.} Our method is evaluated on four attributed graphs commonly used for link prediction \\citep{chami2019hyperbolic, zhang2021lorentzian, yan2021link, zhu2021neural, chen2022bscnets, pan2021neural,hu2020open}. \\autoref{tab::dataset} shows dataset statistics.\n% ---see Supplementary Material for details.\n\n%\n\n\n\\noindent\\textbf{Baselines.} For GNN-based link prediction, we include four state-of-the-art methods published in the past two years: Neo-GNN \\citep{yun2021neo}, BUDDY \\citep{chamberlain2022graph}, and NCN / NCNC \\citep{wang2023neural}, as well as the pioneering work---SEAL \\citep{zhang2018link}. For topological link prediction heuristics, we consider Common Neighbors (CN) \\citep{newman2001clustering}, Adamic Adar (AA) \\citep{adamic2003friends}, and Autocovariance (AC) \\citep{random-walk-embedding}---the base heuristic in our model. \n\n\\noindent\\textbf{Hyperparameters.} For Gelato, we tune the proportion of added edges $\\eta$ from \\{0.0, 0.25, 0.5, 0.75, 1.0\\}, the topological weight $\\alpha$ from \\{0.0, 0.25, 0.5, 0.75\\}, and the trained weight $\\beta$ from \\{0.25, 0.5, 0.75, 1.0\\}. We present a sensitivity analysis of all hyperparameters in Appendix \\ref{ap::sensitivity_analysis}. All other settings are fixed across datasets: MLP with one hidden layer of 128 neurons, AC scaling parameter $t=3$, Adam optimizer \\citep{kingma2014adam} \nwith a learning rate of 0.001, a dropout rate of 0.5, and \\emph{unbiased training} without downsampling. To maintain fairness in our results, we also tuned the baselines and exposed our procedures in detail in Appendix \\ref{ap::setting}. For all models, including Gelato, the tuning process is done in all datasets, except for \\textsc{ogbl-collab}.\n\n\n\\noindent\\textbf{Data splits for unbiased training and unbiased testing.} \nFollowing \\cite{kipf2016variational, zhang2018link, chami2019hyperbolic, zhang2021lorentzian, chen2022bscnets, pan2021neural}, we adopt 85\\%/5\\%/10\\% ratios for training, validation, and testing. Specifically, for \\emph{unbiased training} and \\emph{unbiased testing}, we first randomly divide the (positive) edges $E$ of the original graph into $E_{train}^+$, $E_{valid}^+$, and $E_{test}^+$ for training, validation, and testing based on the selected ratios. Then, we set the negative pairs in these three sets as (1) $E_{train}^{-} = E^{-} + E_{valid}^+ + E_{test}^+$, (2) $E_{valid}^{-} = E^{-} + E_{test}^+$, and (3) $E_{test}^{-} = E^{-}$, where $E^{-}$ is the set of all negative pairs (excluding self-loops) in the original graph. Notice that the validation and testing \\emph{positive} edges are included in the \\emph{negative} training set, and the testing \\emph{positive} edges are included in the \\emph{negative} validation set. This setting simulates the real-world scenario where the test edges (and the validation edges) are unobserved during validation (training). For \\emph{negative sampling}, we repeat the dividing procedure above for each generated partition $G_i$. %, leading to a collection of $E_{train_i}^{+}, E_{valid_i}^{+}, E_{test_i}^{+}$, $E_{train_i}^{-}, E_{valid_i}^{-}, E_{test_i}^{-}$. \nThe final sets are unions of individual sets for each partition: $E_{train}^{+/-} = \\bigcup_{i=1}^k E_{train_i}^{+/-}$, $E_{valid}^{+/-} = \\bigcup_{i=1}^k E_{valid_i}^{+/-}$, and $E_{test}^{+/-} = \\bigcup_{i=1}^k E_{test_i}^{+/-}$. We notice that these splits do not leak training data to the test, as both positive and negative test pairs are disconnected during training. \n\n%, $E_{train}^- = \\bigcup_{i=0}^p E_{train_i}^{-}$, $E_{valid}^- = \\bigcup_{i=0}^p E_{valid_i}^{-}$, $E_{test}^- = \\bigcup_{i=0}^p E_{test_i}^{-}$. %having its own set of $E_{train_i}^{+}, E_{valid_i}^{+}, E_{test_i}^{+}$ sets, implying in also having one $E_{train_i}^{-}, E_{valid_i}^{-}, E_{test_i}^{-}$ per partition.\n\n\\noindent\\textbf{Evaluation metrics.} \nWe adopt $hits@k$ ---the ratio of positive edges individually ranked above $k$th place against all negative pairs---as our evaluation metric since it represents a good notion of class distinction under heavily imbalanced scenarios in information retrieval, compatible with the intuition of link prediction as a similarity-based ranking task.\n\n"
                },
                "subsection 3.2": {
                    "name": "Partitioned Sampling and Link prediction as a similarity task",
                    "content": "\n\\label{subsec::partitioned_sampling_results}\n\nThis section provides empirical evidence for some of the claims made regarding limitations in the evaluation of supervised link prediction methods (see Section \\ref{sec::limitations}). It also demonstrates the effectiveness of Gelato to distinguish true links from hard negative node pairs in sparse graphs.\n\n\\noindent\\textbf{Negative sampling for harder pairs.} Based on the hardness of negative pairs, the easiest scenario is the \\emph{biased testing}, followed by \\emph{unbiased testing} and \\emph{partitioned testing}---i.e. only negative pairs from inside partitions are sampled. This can be verified by \\autoref{fig::three_regimes}, which compares the predicted scores of NCN against the similarities computed by Gelato on the test set of \\textsc{CiteSeer}. \\emph{Biased testing}, the easiest and most unrealistic scenario, shows a good separation between positive and negative pairs both in NCN and Gelato. For \\emph{unbiased testing}, which is more realistic, Gelato is better at distinguishing positive and negative pairs. Finally, \\emph{partitioned testing} presents a particular challenge but Gelato still ranks most positive pairs above negative ones. Other GNN-based link prediction approaches have shown similar behaviors to NCN.\n\n%While Gelato is consistent in all three scenarios, minimizing the overlap of the predicted similarity between negative and positive pairs even in the hardest scenario, NCN (current state-of-the-art) fails in the more realistic scenario, empirical evidence of a pitfall in the current state of Link Prediction evaluation.\n\n\n\n\n\\noindent\\textbf{Similarity-based link prediction.} \\autoref{fig::three_regimes} shows densities normalized by the size of positive and negative sets, respectively. However, in real-world sparse graphs, the number of negative pairs is much larger than that of positive ones. To better understand the ranking of positive pairs over negative pairs, we also show the same plot with non-normalized densities by the total number of all pairs in \\autoref{fig::ap::mesh1} in the Appendix \\ref{ap::non_normalized_plots}. %The unnormalized version of the same plot is provided in the Appendix (see Figure \\autoref{fig::ap::mesh1}). \nThe results show that for \\emph{unbiased} and \\emph{partitioned testing}, ranking positive pairs over hard negative pairs is especially challenging due to their overwhelming number, \n%The results show that, for unbiased and partitioned testing, negative pairs are more likely than positive ones even for large values of similarity or scores---\ni.e. positive pairs are ``needles in a haystack''. \nThis provides evidence that classifiers, such as GNNs for link prediction, are not suitable for finding decision boundaries in these extremely imbalanced settings, which motivates the design of Gelato as a similarity ranking model trained using an N-pair loss.\n\n%also supports our claim that Link Prediction is a similarity-based problem, instead of a binary classification task. Considering the perspective of NCN, the hard negative pairs from the \\emph{partitioned negative sampling} regime are indistinguishable from the positive pairs (their distributions overlap almost completely), demonstrating our theoretical results presented in Section \\textcolor{red}{X}, that binary classifiers are unable to create a good decision boundary with good separation between both classes. Similarity-based models (such as Gelato), on the other hand, are more expressive than the learned neighborhood heuristics expressed by NCN or BUDDY by being able to capture nuances that gradually distinguish between pairs by ranking them.\n\n\n"
                },
                "subsection 3.3": {
                    "name": "Link prediction performance",
                    "content": "\n\\label{subsec::lp_results}\n\n\\autoref{tab::performance_hits} summarizes the link prediction performance in terms of the mean and standard deviation of $hits@1000$ for all methods. We show the same results for varying values of $k$ in Figure \\ref{fig::hits@k}.  We also include the results of $MRR$ (Mean Reciprocal Rank), $AP$ (Average Precision) (see Tables \\ref{tab::performance_ap} and \\ref{tab::performance_mrr}) and $prec@k$ results for varying values of $k$ (see Figure \\ref{fig::ap::prec@k}) in Appendix \\ref{ap::prec@k}. %\\autoref{fig::precision} and \\autoref{fig::hits} show results based on $prec@k$ ($k$ as a ratio of test edges) and $hits@k$ ($k$ as the rank) for varying $k$. \n\n\n% Commenting the chunk of text below for now. This will be edited in a minute\n\n\nFirst, we want to highlight the drastically different performance of GNN-based methods compared to those found in the original papers \\citep{zhang2018link, yun2021neo,chamberlain2022graph,wang2023neural}. Some of them underperform even the simplest topological heuristics such as Common Neighbors under \\emph{unbiased testing}. Moreover, Autocovariance, which is the base topological heuristic applied by Gelato and does not account for node attributes, outperforms all the GNN-based baselines for the majority of the datasets. These results support our arguments from Section \\ref{sec::limitations} that evaluation metrics based on \\emph{biased testing} can produce misleading results compared to \\emph{unbiased testing}.\n\nThe overall best-performing GNN model is NCNC, which generalizes a pairwise topological heuristic (Common Neighbors) using message-passing. NCNC only outperforms Gelato on \\textsc{OGBL-ddi}, which is consistent with previous results \\cite{mao2023revisiting} showing that local structural heuristics are effective for very dense networks (see Table \\ref{tab::dataset}). Moreover, \\textsc{OGBL-ddi} is the only dataset considered that does not contain natural node features, which explains why our approach achieves the same performance as AC. Gelato also remains superior for different values of $hits@K$, especially for \\textsc{Cora}, \\textsc{CiteSeer} and \\textsc{OGBL-collab}, and being remains competitive for \\textsc{OGBL-ddi} being competitive as shown in Figure \\ref{fig::hits@k}. This characteristic is especially relevant in real-world scenarios where robustness is desired, mainly in more conservative regimes with lower values of $k$. Overall, Gelato outperforms the best GNN-based method by \\textbf{138}\\%, \\textbf{125}\\%, \\textbf{156}\\%, and \\textbf{11}\\% for \\textsc{Cora}, \\textsc{Citeseer}, \\textsc{Pubmed}, and \\textsc{OGBL-collab}, respectively. Further, Gelato outperforms its base topological heuristic (Autocovariance) by \\textbf{48}\\%, \\textbf{39}\\%, \\textbf{10}\\%, and \\textbf{139}\\% for \\textsc{Cora}, \\textsc{Citeseer}, \\textsc{Pubmed}, and \\textsc{OGBL-collab}, respectively. Additional results are provided in Appendices \\ref{ap::prec@k} and \\ref{ap::biased_training}.\n\n\n\n\n\n\n"
                },
                "subsection 3.4": {
                    "name": "Ablation study",
                    "content": "\n%An ablation study of Gelato is included in Appendix \\ref{subsec::ablation}. \n\\label{subsec::ablation}\nHere, we collect the results with the same hyperparameter setting as Gelato and present a comprehensive ablation study in \\autoref{tab::ablation}. Specifically, \\emph{Gelato$-$MLP} (\\emph{AC}) represents Gelato without the MLP (Autocovariance) component, i.e., only using Autocovariance (MLP) for link prediction. %Gelato $-$ E2E removes the end-to-end training and instead directly learns MLP parameters based on the link prediction loss. \n\\emph{Gelato$-$NP} (\\emph{UT}) replaces the proposed N-pair loss (\\emph{unbiased training}) with the cross entropy loss (\\emph{biased training}) applied by the baselines. Finally, \\emph{Gelato$-$NP+UT} replaces both the loss and the training setting. \n\n% \\begin{table}[htbp]\n%     \\setlength\\tabcolsep{7pt}\n%   \\centering\n%   \\caption{Results of the ablation study based on AP scores. Each component of Gelato plays an important role in enabling state-of-the-art link prediction performance. }\n%   \\begin{threeparttable}\n%     \\begin{tabular}{lccccc}\n%     \\toprule\n%           & \\textsc{Cora}  & \\textsc{CiteSeer} & \\textsc{PubMed} \n%           % & \\textsc{Photo} & \\textsc{Computers} \n%           \\\\\n%     \\midrule\n%         \\emph{Gelato$-$MLP} & 2.43 \u00b1 0.00 & 2.65 \u00b1 0.00 & 2.50 \u00b1 0.00 \n%         % & 16.63 \u00b1 0.00 &  11.64 \u00b1 0.00 \n%         \\\\\n%         \\emph{Gelato$-$AC} & 1.94 \u00b1 0.18 & 3.91 \u00b1 0.37 & 0.83 \u00b1 0.05 \n%         % & 7.45 \u00b1 0.44 & 4.09 \u00b1 0.16  \n%         \\\\\n%         % Gelato $-$ E2E & 2.13 \u00b1 0.65 & \\textit{4.69 \u00b1 0.07} & 0.40 \u00b1 0.17 & 4.72 \u00b1 1.35 & 2.72 \u00b1 0.10 \\\\ \n%         \\emph{Gelato$-$NP+UT} & 2.98 \u00b1 0.20 & 1.96 \u00b1 0.11 & 2.35 \u00b1 0.24 \\\\\n%         % & 14.87 \u00b1 1.41 & 9.77 \u00b1 2.67 \\\\\n%         \\emph{Gelato$-$NP} & 1.96 \u00b1 0.01 & 1.77 \u00b1 0.20 & 2.32 \u00b1 0.16 \\\\\n%         % & 19.63 \u00b1 0.38 & 9.84 \u00b1 4.42 \\\\\n%         \\emph{Gelato$-$UT} & 3.07 \u00b1 0.01 & 1.95 \u00b1 0.05 & 2.52 \u00b1 0.09 \\\\\n%         % & 23.66 \u00b1 1.01 & 11.59 \u00b1 0.35  \\\\\n%         \\emph{Gelato} & \\textbf{3.90 \u00b1 0.03} & \\textbf{4.55 \u00b1 0.02} & \\textbf{2.88 \u00b1 0.09} \\\\\n%         % & \\textbf{25.68 \u00b1 0.53} & \\textbf{18.77 \u00b1 0.19} \\\\\n%     \\bottomrule\n%     \\end{tabular}%\n%   \\end{threeparttable}\n%   \\label{tab::ablation}%\n% \\end{table}\n\n\n\nWe observe that removing either MLP or Autocovariance leads to inferior performance, as the corresponding attribute or topology information would be missing. Further, to address the class imbalance problem of link prediction, both the N-pair loss and \\emph{unbiased training} are crucial for the effective training of Gelato.\n\n% While all supervised baselines originally adopt \\emph{biased training}, we also implement the same \\emph{unbiased training} (and N-pair loss) as Gelato for those that are scalable in Appendix \\ref{ap::unbiased}---results are consistent with the ones discussed in Section \\ref{subsec::lp_results}. \n\n\\begin{comment}\n% \\section{Description of datasets}\n% \\label{ap::dataset}\n% We use the following datasets in our experiments (with their statistics in \\autoref{tab::dataset}):\n% \\begin{itemize}\n%     \\item \\textsc{Cora} \\citep{mccallum2000automating} and \\textsc{CiteSeer} \\citep{giles1998citeseer} are citation networks where nodes represent scientific publications (classified into seven and six classes, respectively) and edges represent the citations between them. Attributes of each node is a binary word vector indicating the absence/presence of the corresponding word from a dictionary. \n%     \\item \\textsc{PubMed} \\citep{sen2008collective} is a citation network where nodes represent scientific publications (classified into three classes) and edges represent the citations between them. Attributes of each node is a TF/IDF weighted word vector.\n%     \\item \\textsc{Photo} and \\textsc{Computers} are subgraphs of the Amazon co-purchase graph \\citep{mcauley2015image} where nodes represent products (classified into eight and ten classes, respectively) and edges imply that two products are frequently bought together. Attributes of each node is a bag-of-word vector encoding the product review.\n% \\end{itemize}\n\nWe use the publicly available version of the datasets from the \\texttt{pytorch-geometric} library \\citep{pyg} (under the \\href{https://github.com/pyg-team/pytorch_geometric/blob/master/LICENSE}{MIT licence}) curated by \\citet{yang2016revisiting} and \\citet{shchur2018pitfalls}.\n\n% In fact, Gelato is 50\\% faster than the MLP epochwise. This is because, for an epoch of \\emph{full training}, the vanilla MLP (and other GNN-based methods) is applied to every node pair in the graph ($O(n^2)$) while the graph learning MLP in Gelato is only applied to the (augmented) edges of the graph ($O(m)$). And once the enhanced graph is ready, Gelato only needs simple matrix multiplication to get Autocovariance scores for all pairs. \n\n% \\begin{figure}[htbp]\n%   \\centering\n%   \\includegraphics[width=0.5\\textwidth]{fig/full_training_time.pdf}\n%   \\caption{Training time comparison between supervised link prediction methods for \\textsc{Photo} under \\emph{unbiased training}. Gelato, while achieving the best performance, is also the second most efficient method in terms of total training time, slower only than the vanilla MLP. %It is also faster than MLP epochwise. \n%   }\n%   \\label{fig::full_training_time}\n% \\end{figure}\n\\end{comment}\n\nWe also present results for Gelato using different ranking-based loss functions. In particular, we choose between Precision@k, pairwise hinge, pairwise exponential, and pairwise logistic losses as candidates for replacing the N-pair loss based on \\cite{chen2009ranking}. The results are shown in \\autoref{tab::losses}, demonstrating that there is no clear winner considering the $hits@1000$ metric in the two datasets used  (\\textsc{Cora} and \\textsc{CiteSeer}).\n\n\n\n\n\n% often underperforms AC, a random-walk-based heuristic that needs neither node attributes nor supervision/training. %supervised training (hence zero performance variance).\n\n%We then look at two-stage combinations of AC and models for attribute information. We observe noticeable performance gains from combining attribute cosine similarity and AC in \\textsc{Cora} and \\textsc{CiteSeer} but not for other datasets. Other two-stage approaches achieve similar or worse performance. %, as they are not trained to complement AC. \n\n%Finally, Gelato significantly outperforms the best GNN-based model with an average relative gain of \\textbf{84\\%} and AC with a gain of \\textbf{52.6\\%} in terms of AP---similar results were obtained for $prec@k$ and $hits@k$. This validates our hypothesis that a simple MLP can effectively incorporate node attribute information into the topology when our model is trained end-to-end. \n%we have the proposed OURMETHOD that trains an MLP to enhance the graph for AC in an end-to-end manner. It significantly outperforms the best GNN-based model with an average relative gain of \\textbf{85.4\\%} and AC with a gain of \\textbf{36.3\\%}. \n%Next, we will provide insights behind these improvements and demonstrate the efficiency of Gelato on training and inference. \n\n\n\n% JOAO:\n% PREVIOUS VERSION BELOW\n% ----------------------\n% \\section{Experiments}\n% \\label{sec::experiments}\n\n% We provide empirical evidence for our claims regarding supervised link prediction and demonstrate the accuracy and efficiency of Gelato. Our implementation is anonymously available at \\url{https://anonymous.4open.science/r/Gelato/}. \n\n\n% \\subsection{Experiment settings}\n% \\label{subsec::exp_setting}\n% \\textbf{Datasets.} Our method is evaluated on six attributed graphs commonly used as link prediction benchmark \\citep{chami2019hyperbolic, zhang2021lorentzian, yan2021link, zhu2021neural, chen2022bscnets, pan2021neural,hu2020open}. \\autoref{tab::dataset} shows dataset statistics---see Supplementary Material for dataset details.  \n\n% %\\begin{table}[htbp]\n% %  \\centering\n% %  \\small\n% %  \\caption{A summary of dataset statistics. }\n% %    \\begin{tabular}{ccccccc}\n% %    \\toprule\n% %           & \\#Nodes     & \\#Edges     & \\#Attrs     & Avg. degree & Density\\\\\n% %    \\midrule\n% %    \\textsc{Cora}  & 2,708  & 5,278  & 1,433  & 3.90 & 0.14\\% \\\\\n% %    \\textsc{CiteSeer} & 3,327  & 4,552  & 3,703  & 2.74 & 0.08\\% \\\\\n% %    \\textsc{PubMed} & 19,717 & 44,324 & 500   & 4.50 & 0.02\\% \\\\\n% %    \\textsc{Photo} & 7,650  & 119,081 & 745   & 31.13 & 0.41\\%\\\\\n% %     \\textsc{Computers} & 13,752 & 245,861 & 767   & 35.76 & 0.26\\% \\\\\n% %    \\bottomrule\n% %    \\end{tabular}%\n% %  \\label{tab::dataset}%\n% %\\end{table}%\n\n\n% \\begin{table}[htbp]\n%   \\centering\n%   \\small\n%   \\caption{A summary of dataset statistics. }\n%     \\begin{tabular}{ccccccc}\n%     \\toprule\n%           &       & \\#Nodes     & \\#Edges     & \\#Attributes     & Avg. degree & Density\\\\\n%     \\midrule\n%     \\multirow{3}[1]{*}{Planetoid} & \\textsc{Cora}  & 2,708  & 5,278  & 1,433  & 3.90 & 0.14\\% \\\\\n%           & \\textsc{CiteSeer} & 3,327  & 4,552  & 3,703  & 2.74 & 0.08\\% \\\\\n%           & \\textsc{PubMed} & 19,717 & 44,324 & 500   & 4.50 & 0.02\\% \\\\\n%     \\multirow{2}[1]{*}{Amazon} & \\textsc{Photo} & 7,650  & 119,081 & 745   & 31.13 & 0.41\\%\\\\\n%           & \\textsc{Computers} & 13,752 & 245,861 & 767   & 35.76 & 0.26\\% \\\\\n\n\n%     \\multirow{2}[1]{*}{OGBL} & \\textsc{PPA} & 576,289  & 30,326,273 & 58   & 52.62 & 0.013\\%\\\\\n%           & \\textsc{Citation-2} & 2,927,963 & 30,561,187 & 128   & 10.44 & 0.00035\\% \\\\\n%     \\bottomrule\n%     \\end{tabular}%\n%   \\label{tab::dataset}%\n% \\end{table}%\n\n% \\noindent\\textbf{Baselines.} For GNN-based link prediction, we include ten state-of-the-art methods published in the past two years: LGCN \\citep{zhang2021lorentzian}, TLC-GNN \\citep{yan2021link}, Neo-GNN \\citep{yun2021neo}, NBFNet \\citep{zhu2021neural}, BScNets \\citep{chen2022bscnets}, WalkPool \\citep{pan2021neural}, ELPH \\citep{chamberlain2022graph}, and NCNC \\citep{wang2023neural}, as well as three pioneering works---GAE \\citep{kipf2016variational}, SEAL \\citep{zhang2018link}, and HGCN \\citep{chami2019hyperbolic}. % excluding LGLP \\cite{cai2021line} as it runs out of memory for all datasets. \n% For topological link prediction heuristics, we consider Common Neighbors (CN) \\citep{newman2001clustering}, Adamic Adar (AA) \\citep{adamic2003friends}, Resource Allocation (RA) \\citep{zhou2009predicting}, and Autocovariance (AC) \\citep{random-walk-embedding}---the base heuristic in our model. To demonstrate the superiority of the proposed end-to-end model, we also include an MLP trained directly for link prediction, the cosine similarity (Cos) between node attributes, and AC on top of the respective weighted/augmented graphs (i.e., two-stage approaches where the MLP is trained separately for link prediction rather than trained end-to-end) as baselines.  \n\n% \\noindent\\textbf{Hyperparameters.} For Gelato, we tune the proportion of added edges $\\eta$ from \\{0.0, 0.25, 0.5, 0.75, 1.0\\}, the topological weight $\\alpha$ from \\{0.0, 0.25, 0.5, 0.75\\}, and the trained weight $\\beta$ from \\{0.25, 0.5, 0.75, 1.0\\}, with a sensitivity analysis included in the Supplementary Material. All other settings are fixed across datasets: MLP with one hidden layer of 128 neurons, AC scaling parameter $t=3$, Adam optimizer \\citep{kingma2014adam} \n% with a learning rate of 0.001, a dropout rate of 0.5, and \\emph{unbiased training} without downsampling. For baselines, we use the same hyperparameters as in their papers.\n\n% %, for which we observe gains that do not affect our claims.  \n% %We observe marginal to significant gains across different baselines but they still underperform topological heuristics. \n\n\n% \\noindent\\textbf{Data splits for unbiased training and unbiased testing.} \n% Following \\citet{kipf2016variational, zhang2018link, chami2019hyperbolic, zhang2021lorentzian, chen2022bscnets, pan2021neural}, we adopt 85\\%/5\\%/10\\% ratios for training, validation, and testing. Specifically, for \\emph{unbiased training} and \\emph{testing}, we first randomly divide the (positive) edges $E$ of the original graph into $E_{train}^+$, $E_{valid}^+$, and $E_{test}^+$ for training, validation, and testing based on the selected ratios. Then, we set the negative pairs in these three sets as (1) $E_{train}^{-} = E^{-} + E_{valid}^+ + E_{test}^+$, (2) $E_{valid}^{-} = E^{-} + E_{test}^+$, and (3) $E_{test}^{-} = E^{-}$, where $E^{-}$ is the set of all negative pairs (excluding self-loops) in the original graph. Notice that the validation and testing \\emph{positive} edges are included in the \\emph{negative} training set, and the testing \\emph{positive} edges are included in the \\emph{negative} validation set. This setting simulates the real-world scenario where the test edges (and the validation edges) are unobserved during validation (training). % For large graphs, one can downsample both positive and negative pairs to maintain the same class ratio as the input graph for training and testing. \\looseness=-1\n\n% %Link prediction setting. \n% \\noindent\\textbf{Evaluation metrics.} %Different from the more popular choice, we adopt \\emph{full testing} as we argue that it better reflects the link prediction performance in real-world setting (see Section \\ref{sec::limitations}). This means that instead of sampling one negative pair for each positive test edge, we include all negative pairs in testing. The methods are evaluated by how they rank positive edges against all negative pairs, and quantified by Precision@K ($prec@k$), the proportion of positive edges among the top $k$ ranked pairs, \n%  %without downsampling \n% We adopt Average Precision (AP)---area under the precision-recall curve, Precision@$k$ ($prec@k$)---proportion of positive edges among the top $k$ of all testing pairs, and Hits@$k$ ($hits@k$)---ratio of positive edges individually ranked above $k$th place against all negative pairs as evaluation metrics. %where $k$ is given in terms of the ratio of the number of positive test edges. \n% We report results from 10 runs with random seeds ranging from 1 to 10. \n\n% More detailed experiment settings and additional results can be found in the Supplementary Material. \n\n% \\subsection{Link prediction performance}\n% \\label{subsec::lp_results}\n\n% \\begin{comment}\n% \\begin{table}[htbp]\n%     \\setlength\\tabcolsep{4.65pt}\n%     \\small\n%   \\centering\n%   \\caption{Link prediction performance comparison (mean \u00b1 std AP). Gelato consistently outperforms GNN-based methods, topological heuristics, and two-stage approaches combining attributes/topology. }\n  \n%   \\begin{threeparttable}\n%     \\begin{tabular}{ccccccc}\n%     \\toprule\n%           &       & \\textsc{Cora}  & \\textsc{CiteSeer} & \\textsc{PubMed} & \\textsc{Photo} & \\textsc{Computers} \\\\\n%     \\midrule\n%     \\multirow{9}[2]{*}{GNN} \n%         & GAE & 0.27 \u00b1 0.02 & 0.66 \u00b1 0.11 & 0.26 \u00b1 0.03 & 0.28 \u00b1 0.02 & 0.30 \u00b1 0.02 \\\\\n%         & SEAL & 1.89 \u00b1 0.74 & 0.91 \u00b1 0.66 & *** &  10.49 \u00b1 0.86 & 6.84\\tnote{*} \\\\\n%         & HGCN & 0.82 \u00b1 0.03 & 0.74 \u00b1 0.10 & 0.35 \u00b1 0.01 & 2.11 \u00b1 0.10 & 2.30 \u00b1 0.14 \\\\\n%         & LGCN & 1.14 \u00b1 0.04 & 0.86 \u00b1 0.09 & 0.44 \u00b1 0.01 & 3.53 \u00b1 0.05 & 1.96 \u00b1 0.03 \\\\\n%         & TLC-GNN & 0.29 \u00b1 0.09 & 0.35 \u00b1 0.18 & OOM & 1.77 \u00b1 0.11 & OOM  \\\\\n%         & Neo-GNN & 2.05 \u00b1 0.61 & 1.61 \u00b1 0.36 & 1.21 \u00b1 0.14 & 10.83 \u00b1 1.53 & 6.75\\tnote{*} \\\\ \n%         & NBFNet & 1.36 \u00b1 0.17 & 0.77 \u00b1 0.22 & *** & 11.99 \u00b1 1.60 & *** \\\\\n%         & BScNets & 0.32 \u00b1 0.08 & 0.20 \u00b1 0.06 & 0.22 \u00b1 0.08 & 2.47 \u00b1 0.18 & 1.45 \u00b1 0.10 \\\\\n%         & WalkPool & 2.04 \u00b1 0.07 & 1.39 \u00b1 0.11 & 1.31\\tnote{*} & OOM & OOM  \\\\\n%     \\midrule\n%     \\multicolumn{1}{c}{\\multirow{4}[2]{*}{\\parbox{1.8cm}{\\centering Topological Heuristics}}} \n%         & CN & 1.10 \u00b1 0.00 & 0.74 \u00b1 0.00 & 0.36 \u00b1 0.00 & 7.73 \u00b1 0.00 & 5.09 \u00b1 0.00 \\\\\n%         & AA & 2.07 \u00b1 0.00 & 1.24 \u00b1 0.00 & 0.45 \u00b1 0.00 & 9.67 \u00b1 0.00 & 6.52 \u00b1 0.00 \\\\\n%         & RA & 2.02 \u00b1 0.00 & 1.19 \u00b1 0.00 & 0.33 \u00b1 0.00 & 10.77 \u00b1 0.00 & 7.71 \u00b1 0.00 \\\\\n%         & AC & 2.43 \u00b1 0.00 & 2.65 \u00b1 0.00 & 2.50 \u00b1 0.00 & 16.63 \u00b1 0.00 & 11.64 \u00b1 0.00 \\\\\n%     \\midrule\n%     \\multicolumn{1}{c}{\\multirow{5}[2]{*}{\\parbox{1.8cm}{\\centering Attributes + Topology}}} \n%      & MLP       & 0.30 \u00b1 0.05 & 0.44 \u00b1 0.09 & 0.14 \u00b1 0.06 & 1.01 \u00b1 0.26 & 0.41 \u00b1 0.23 \\\\\n%      & Cos       & 0.42 \u00b1 0.00 & 1.89 \u00b1 0.00 & 0.07 \u00b1 0.00 & 0.11 \u00b1 0.00 & 0.07 \u00b1 0.00 \\\\\n%      & MLP+AC    & 3.24 \u00b1 0.03 & 1.95 \u00b1 0.05 & 2.61 \u00b1 0.06 & 15.99 \u00b1 0.21 & 11.25 \u00b1 0.13 \\\\\n%      & Cos+AC    & 3.60 \u00b1 0.00 & 4.46 \u00b1 0.00 & 0.51 \u00b1 0.00 & 10.01 \u00b1 0.00 & 5.20 \u00b1 0.00 \\\\\n%      & MLP+Cos+AC& 3.39 \u00b1 0.06 & 4.15 \u00b1 0.14 & 0.55 \u00b1 0.03 & 10.88 \u00b1 0.09 & 5.75 \u00b1 0.11 \\\\\n%     \\midrule\n%     \\multicolumn{2}{c}{Gelato} & \\textbf{3.90 \u00b1 0.03} & \\textbf{4.55 \u00b1 0.02} & \\textbf{2.88 \u00b1 0.09}      & \\textbf{25.68 \u00b1 0.53}      & \\textbf{18.77 \u00b1 0.19} \\\\\n%     \\bottomrule\n%     \\end{tabular}%\n% \t\\begin{tablenotes}[para]\n% \t\\item[*] Run only once as each run takes \\textasciitilde 100 hrs; \n% \t\\hspace{5pt} *** Each run takes $>$1000 hrs; \\hspace{5pt} OOM: Out Of Memory.\n%     \\end{tablenotes}\n%   \\end{threeparttable}\n%   \\label{tab::performance_ap}%\n% \\end{table}\n% \\end{comment}\n\n\n% \\autoref{tab::performance_ap} summarizes the link prediction performance in terms of the mean and standard deviation of Average Precision (AP) for all methods, with results based on $prec@k$ and $hits@k$ included in the Supplementary Material.  %\\autoref{fig::precision} and \\autoref{fig::hits} show results based on $prec@k$ ($k$ as a ratio of test edges) and $hits@k$ ($k$ as the rank) for varying $k$. \n\n% \\begin{table}[htbp]\n%     \\setlength\\tabcolsep{4.65pt}\n%     \\small\n%   \\centering\n%   \\caption{Link prediction performance comparison (mean \u00b1 std AP) for five small datasets. Gelato consistently outperforms GNN-based methods, topological heuristics, and two-stage approaches combining attributes/topology. Results for larger datasets are provided in the Supplementary Material.}\n%   \\label{tab::performance_ap}%\n%   \\begin{threeparttable}\n  \n%     \\begin{tabular}{ccccccc}\n%     \\toprule\n%           &       & \\textsc{Cora}  & \\textsc{CiteSeer} & \\textsc{PubMed} & \\textsc{Photo} & \\textsc{Computers} \\\\\n%     \\midrule\n%     \\multirow{9}[2]{*}{GNN} \n%         & GAE & 0.27 \u00b1 0.02 & 0.66 \u00b1 0.11 & 0.26 \u00b1 0.03 & 0.28 \u00b1 0.02 & 0.30 \u00b1 0.02 \\\\\n%         & SEAL & 1.89 \u00b1 0.74 & 0.91 \u00b1 0.66 & *** &  10.49 \u00b1 0.86 & 6.84\\tnote{*} \\\\\n%         & HGCN & 0.82 \u00b1 0.03 & 0.74 \u00b1 0.10 & 0.35 \u00b1 0.01 & 2.11 \u00b1 0.10 & 2.30 \u00b1 0.14 \\\\\n%         & LGCN & 1.14 \u00b1 0.04 & 0.86 \u00b1 0.09 & 0.44 \u00b1 0.01 & 3.53 \u00b1 0.05 & 1.96 \u00b1 0.03 \\\\\n%         & TLC-GNN & 0.29 \u00b1 0.09 & 0.35 \u00b1 0.18 & OOM & 1.77 \u00b1 0.11 & OOM  \\\\\n%         & Neo-GNN & 2.05 \u00b1 0.61 & 1.61 \u00b1 0.36 & 1.21 \u00b1 0.14 & 10.83 \u00b1 1.53 & 6.75\\tnote{*} \\\\ \n%         & NBFNet & 1.36 \u00b1 0.17 & 0.77 \u00b1 0.22 & *** & 11.99 \u00b1 1.60 & *** \\\\\n%         & BScNets & 0.32 \u00b1 0.08 & 0.20 \u00b1 0.06 & 0.22 \u00b1 0.08 & 2.47 \u00b1 0.18 & 1.45 \u00b1 0.10 \\\\\n%         & WalkPool & 2.04 \u00b1 0.07 & 1.39 \u00b1 0.11 & 1.31\\tnote{*} & OOM & OOM  \\\\\n%         & ELPH & 2.09 \u00b1 0.00 & 1.94 \u00b1 0.00 & 0.30 \u00b1 0.00 & 12.11 \u00b1 0.00 & 6.48 \u00b1 0.00  \\\\\n%         & NCNC & 2.51 \u00b1 0.00 & 3.09 \u00b1 0.00 & 1.04 \u00b1 0.00 & 14.86 \u00b1 0.00 & 11.21 \u00b1 0.00  \\\\\n%     \\midrule\n%     \\multicolumn{1}{c}{\\multirow{4}[2]{*}{\\parbox{1.8cm}{\\centering Topological Heuristics}}} \n%         & CN & 1.10 \u00b1 0.00 & 0.74 \u00b1 0.00 & 0.36 \u00b1 0.00 & 7.73 \u00b1 0.00 & 5.09 \u00b1 0.00 \\\\\n%         & AA & 2.07 \u00b1 0.00 & 1.24 \u00b1 0.00 & 0.45 \u00b1 0.00 & 9.67 \u00b1 0.00 & 6.52 \u00b1 0.00 \\\\\n%         & RA & 2.02 \u00b1 0.00 & 1.19 \u00b1 0.00 & 0.33 \u00b1 0.00 & 10.77 \u00b1 0.00 & 7.71 \u00b1 0.00 \\\\\n%         & AC & 2.43 \u00b1 0.00 & 2.65 \u00b1 0.00 & 2.50 \u00b1 0.00 & 16.63 \u00b1 0.00 & 11.64 \u00b1 0.00 \\\\\n%     \\midrule\n%     \\multicolumn{1}{c}{\\multirow{5}[2]{*}{\\parbox{1.8cm}{\\centering Attributes + Topology}}} \n%      & MLP       & 0.30 \u00b1 0.05 & 0.44 \u00b1 0.09 & 0.14 \u00b1 0.06 & 1.01 \u00b1 0.26 & 0.41 \u00b1 0.23 \\\\\n%      & Cos       & 0.42 \u00b1 0.00 & 1.89 \u00b1 0.00 & 0.07 \u00b1 0.00 & 0.11 \u00b1 0.00 & 0.07 \u00b1 0.00 \\\\\n%      & MLP+AC    & 3.24 \u00b1 0.03 & 1.95 \u00b1 0.05 & 2.61 \u00b1 0.06 & 15.99 \u00b1 0.21 & 11.25 \u00b1 0.13 \\\\\n%      & Cos+AC    & 3.60 \u00b1 0.00 & 4.46 \u00b1 0.00 & 0.51 \u00b1 0.00 & 10.01 \u00b1 0.00 & 5.20 \u00b1 0.00 \\\\\n%      & MLP+Cos+AC& 3.39 \u00b1 0.06 & 4.15 \u00b1 0.14 & 0.55 \u00b1 0.03 & 10.88 \u00b1 0.09 & 5.75 \u00b1 0.11 \\\\\n%     \\midrule\n%     %\\multicolumn{2}{c}{Cluster AC} & 2.31 \u00b1 0.00 & 1.54 \u00b1 0.00 & 1.10 \u00b1 0.00     & 6.76 \u00b1 0.00      & 6.09 \u00b1 0.00 \\\\\n%     %\\multicolumn{2}{c}{ClusterGelato} & 2.47 \u00b1 0.13 & 2.77 \u00b1 0.08 & 2.53 \u00b1 0.10     & 17.52 \u00b1 0.78      & 9.46 \u00b1 0.16 \\\\\n%     \\multicolumn{2}{c}{Gelato} & \\textbf{3.90 \u00b1 0.03} & \\textbf{4.55 \u00b1 0.02} & \\textbf{2.88 \u00b1 0.09}      & \\textbf{25.68 \u00b1 0.53}      & \\textbf{18.77 \u00b1 0.19} \\\\\n%     \\bottomrule\n%     \\end{tabular}%\n% \t\\begin{tablenotes}[para]\n% \t\\item[*] Run only once as each run takes \n% \t\\raise.17ex\\hbox{$\\scriptstyle\\sim$}100 hrs; \n% \t\\hspace{5pt} *** Each run takes $>$1000 hrs; \\hspace{5pt} OOM: Out Of Memory.\n%     \\end{tablenotes}\n    \n%   \\end{threeparttable}\n% \\end{table}\n\n% First, we want to highlight the drastically different performance of GNN-based methods compared to those found in the original papers \\citep{zhang2021lorentzian, yan2021link, yun2021neo, zhu2021neural, chen2022bscnets, pan2021neural,chamberlain2022graph,wang2023neural} and reproduced in the Supplementary Material. While they achieve AUC/AP scores of often higher than 90\\% under \\emph{biased testing}, here we see most of them underperform even the simplest topological heuristics such as Common Neighbors under \\emph{unbiased testing}. These results support our arguments from Section \\ref{sec::limitations} that evaluation metrics based on \\emph{biased testing} can produce misleading results compared to \\emph{unbiased testing}.\n% %This confirms our concerns in Section \\ref{sec::limitations} that evaluation metrics in \\emph{biased testing} are not good indicators of the performance under \\emph{full testing}. %The best performing GNN model is Neo-GNN, which directly generalizes over the pairwise topological heuristics, and it is followed by methods based on subgraph classification (SEAL and WalkPool). \n% The overall best performing GNN model is NCNC, which generalizes a pairwise topological heuristic (Common Neighbors) using message-passing. Yet still, it often underperforms AC, a random-walk based heuristic that needs neither node attributes nor supervision/training. %supervised training (hence zero performance variance).\n\n% We then look at two-stage combinations of AC and models for attribute information. We observe noticeable performance gains from combining attribute cosine similarity and AC in \\textsc{Cora} and \\textsc{CiteSeer} but not for other datasets. Other two-stage approaches achieve similar or worse performance. %, as they are not trained to complement AC. \n\n% Finally, Gelato significantly outperforms the best GNN-based model with an average relative gain of \\textbf{84\\%} and AC with a gain of \\textbf{52.6\\%} in terms of AP---similar results were obtained for $prec@k$ and $hits@k$. This validates our hypothesis that a simple MLP can effectively incorporate node attribute information into the topology when our model is trained end-to-end. \n% %we have the proposed OURMETHOD that trains an MLP to enhance the graph for AC in an end-to-end manner. It significantly outperforms the best GNN-based model with an average relative gain of \\textbf{85.4\\%} and AC with a gain of \\textbf{36.3\\%}. \n% Next, we will provide insights behind these improvements and demonstrate the efficiency of Gelato on training and inference. \n\n\n\n\n% % \\begin{table}[tbp]\n% %     \\setlength\\tabcolsep{4.65pt}\n% %     \\small\n% %   \\centering\n% %   \\caption{Link prediction performance (mean \u00b1 std $prec@100\\%$). Gelato consistently outperforms GNN-based methods, topological heuristics, and two-stage approaches combining attributes/topology.}\n% %   %\\caption{Link prediction performance comparison (mean \u00b1 std $prec@100\\%$). Gelato consistently outperforms GNN-based methods, topological heuristics, and various two-stage approaches combining attributes and topology. }\n% %   \\begin{threeparttable}\n% %     \\begin{tabular}{ccccccc}\n% %     \\toprule\n% %           &       & \\textsc{Cora}  & \\textsc{CiteSeer} & \\textsc{PubMed} & \\textsc{Photo} & \\textsc{Computers} \\\\\n% %     \\midrule\n% %     \\multirow{9}[2]{*}{GNN} \n% %         & GAE & 3.33 \u00b1 0.53 & 3.93 \u00b1 0.47 & 2.58 \u00b1 0.19 & 12.76 \u00b1 0.30 & 10.81 \u00b1 0.14 \\\\\n% %         & SEAL & 6.11 \u00b1 1.16 & 3.12 \u00b1 2.03 & *** & 17.11 \u00b1 1.01 & 13.09\\tnote{*} \\\\\n% %         & HGCN & 3.47 \u00b1 0.42 & 3.56 \u00b1 0.59 & 2.39 \u00b1 0.10 & 7.19 \u00b1 0.47 & 5.73 \u00b1 0.27 \\\\\n% %         & LGCN & 4.74 \u00b1 0.31 & 3.47 \u00b1 0.54 & 2.73 \u00b1 0.12 & 8.20 \u00b1 0.26 & 4.74 \u00b1 0.18 \\\\\n% %         & TLC-GNN & 0.78 \u00b1 0.45 & 0.70 \u00b1 0.51 & OOM & 1.80 \u00b1 0.54 & OOM  \\\\\n% %         & Neo-GNN & 6.79 \u00b1 1.79 & 5.67 \u00b1 1.27 & 5.41 \u00b1 0.46 & 19.09 \u00b1 1.62 & 13.93\\tnote{*} \\\\ \n% %         & NBFNet & 4.59 \u00b1 0.67 & 2.29 \u00b1 0.51 & *** & 20.41 \u00b1 1.48 & *** \\\\\n% %         & BScNets & 0.59 \u00b1 0.30 & 0.44 \u00b1 0.33 & 0.58 \u00b1 0.36 & 3.04 \u00b1 0.40 & 1.67 \u00b1 0.19 \\\\\n% %         & WalkPool & 5.29 \u00b1 0.30 & 4.44 \u00b1 0.31 & 4.42\\tnote{*} & OOM & OOM  \\\\\n% %     \\midrule\n% %     \\multicolumn{1}{c}{\\multirow{4}[2]{*}{\\parbox{1.8cm}{\\centering Topological Heuristics}}} \n% %         & CN & 4.36 \u00b1 0.00 & 4.40 \u00b1 0.00 & 2.37 \u00b1 0.00 & 16.04 \u00b1 0.00 & 13.39 \u00b1 0.00 \\\\\n% %         & AA & 7.40 \u00b1 0.00 & 4.40 \u00b1 0.00 & 3.32 \u00b1 0.00 & 18.37 \u00b1 0.00 & 14.71 \u00b1 0.00 \\\\\n% %         & RA & 7.21 \u00b1 0.00 & 4.18 \u00b1 0.00 & 2.10 \u00b1 0.00 & 19.37 \u00b1 0.00 & 15.22 \u00b1 0.00 \\\\\n% %         & AC & 8.16 \u00b1 0.00 & 8.35 \u00b1 0.00 & 8.33 \u00b1 0.00 & 24.40 \u00b1 0.00 & 19.78 \u00b1 0.00 \\\\\n% %     \\midrule\n% %     \\multicolumn{1}{c}{\\multirow{5}[2]{*}{\\parbox{1.8cm}{\\centering Attributes + Topology}}} \n% %      & MLP       & 4.99 \u00b1 1.10 & 3.45 \u00b1 1.16 & 0.95 \u00b1 0.35 & 3.73 \u00b1 0.78 & 1.64 \u00b1 0.76 \\\\\n% %      & Cos       & 3.23 \u00b1 0.00 & 8.35 \u00b1 0.00 & 0.50 \u00b1 0.00 & 0.43 \u00b1 0.00 & 0.33 \u00b1 0.00 \\\\\n% %      & MLP+AC    & 8.60 \u00b1 0.25 & 5.71 \u00b1 0.37 & 8.57 \u00b1 0.13 & 23.62 \u00b1 0.22 & 19.39 \u00b1 0.17 \\\\\n% %      & Cos+AC    & 11.01 \u00b1 0.00 & 12.53 \u00b1 0.00 & 0.65 \u00b1 0.00 & 16.94 \u00b1 0.00 & 8.46 \u00b1 0.00 \\\\\n% %      & MLP+Cos+AC& 8.88 \u00b1 0.23 & 11.67 \u00b1 0.79 & 0.81 \u00b1 0.10 & 18.47 \u00b1 0.16 & 9.65 \u00b1 0.25 \\\\\n% %     \\midrule\n% %     \\multicolumn{2}{c}{Gelato} & \\textbf{11.67 \u00b1 0.30} & \\textbf{13.43 \u00b1 0.22} & \\textbf{9.35 \u00b1 0.16}      & \\textbf{32.13 \u00b1 0.45}      & \\textbf{26.68 \u00b1 0.19} \\\\\n% %     \\bottomrule\n% %     \\end{tabular}%\n% % \t\\begin{tablenotes}[para]\n% % \t\\item[*] Run only once as each run takes \\~{} 100 hrs; \n% % \t\\hspace{5pt} *** Each run takes $>$1000 hrs; \\hspace{5pt} OOM: Out Of Memory.\n% %     \\end{tablenotes}\n% %   \\end{threeparttable}\n% %   \\label{tab::performance}%\n% % \\end{table}\n\n\n% % \\subsection{Visualizing Gelato link prediction process}\n% % \\label{subsec::visualization}\n% % To better understand the performance of Gelato, we visualize the input adjacency matrix and node attributes (in terms of pairwise Euclidean distance), the attribute-enhanced adjacency matrix, and the final prediction scores in \\autoref{fig::learned_edges_gelato}. The results are based on a subgraph of \\textsc{Photo} containing the top 160 nodes belonging to the first class sorted in decreasing order of their (within-class) degree.\n\n% % \\begin{figure}[htbp]\n% %   \\centering\n% %   \\subfloat[Input adj. matrix]{\\label{subfig::trained_adjacency_gelato}\\includegraphics[width=0.5\\columnwidth]{fig/train_adjacency_gelato.pdf}}\n% %   \\subfloat[Attribute distance]{\\label{subfig::euclidean_distance_gelato}\\includegraphics[width=0.5\\columnwidth]{fig/euclidean_distance_gelato.pdf}}\\\\\n% %   \\subfloat[Enhanced adj. matrix]{\\label{subfig::enhanced_adjacency_gelato}\\includegraphics[width=0.5\\columnwidth]{fig/enhanced_adjacency_gelato.pdf}}\n% %   \\subfloat[Gelato prediction ]{\\label{subfig::our_similarity_gelato}\\includegraphics[width=0.5\\columnwidth]{fig/our_similarity_gelato.pdf}}\n% % %   \\vspace{-10pt}\n% %   \\caption{Illustration of the link prediction process of Gelato. Graph learning effectively incorporates node attributes into topology and AC on the enhanced graph enables state-of-the-art link prediction. \\looseness=-1}\n% %   \\label{fig::learned_edges_gelato}\n% % \\end{figure}\n% % % \\begin{figure*}[htbp]\n% % %   \\centering\n% % %   \\subfloat[Input adj. matrix]{\\label{subfig::trained_adjacency_gelato}\\includegraphics[width=0.245\\textwidth]{fig/train_adjacency_gelato.pdf}}\n% % %   \\subfloat[Attribute distance]{\\label{subfig::euclidean_distance_gelato}\\includegraphics[width=0.245\\textwidth]{fig/euclidean_distance_gelato.pdf}}\n% % %   \\subfloat[Enhanced adj. matrix]{\\label{subfig::enhanced_adjacency_gelato}\\includegraphics[width=0.245\\textwidth]{fig/enhanced_adjacency_gelato.pdf}}\n% % %   \\subfloat[Gelato prediction ]{\\label{subfig::our_similarity_gelato}\\includegraphics[width=0.245\\textwidth]{fig/our_similarity_gelato.pdf}}\n% % % %   \\vspace{-10pt}\n% % %   \\caption{Illustration of the link prediction process of Gelato. Graph learning effectively incorporates node attributes into topology and AC on the enhanced graph enables state-of-the-art link prediction. \\looseness=-1}\n% % %   \\label{fig::learned_edges_gelato}\n% % % \\end{figure*}\n\n% % % \\vspace{-15pt}\n\n% % We observe that the graph learning module of Gelato generates a more informative adjacency matrix (\\autoref{subfig::enhanced_adjacency_gelato}) by incorporating node attributes (\\autoref{subfig::euclidean_distance_gelato}) into the input adjacency matrix (\\autoref{subfig::trained_adjacency_gelato}). This can be seen from the down-weighting of the edges connecting the high-degree nodes with larger attribute distances (matrix entries 0-40 and especially 0-10) and the up-weighting of those connecting medium-degree nodes with smaller distances (40-80). Applying the topological heuristic, Autocovariance, to this enhanced adjacency matrix thus leverages the advantages from both worlds (\\autoref{subfig::our_similarity_gelato}). It not only covers most true edges between high-degree nodes as AC captures node degree distributions \\cite{random-walk-embedding} but also avoids false predictions for connections between high-degree and low-degree nodes thanks to the attribute-based edge down-weighting, enabling state-of-the-art link prediction performance for attributed graphs. \n% % A detailed analysis of the improvements of Gelato over the vanilla AC and comparisons with the GNN-based link prediction process is included in Appendix \\ref{ap::visualization}. \\looseness=-1\n\n\n\n\n% % \\begin{figure}[htbp]\n% %   \\centering\n% %   \\subfloat[Training adjacency matrix]{\\label{subfig::trained_adjacency_gelato}\\includegraphics[width=0.32\\textwidth]{fig/train_adjacency.pdf}}\n% %   \\subfloat[Enhanced adjacency matrix]{\\label{subfig::enhanced_adjacency_gelato}\\includegraphics[width=0.32\\textwidth]{fig/enhanced_adjacency.pdf}}\n% % %   \\subfloat[Attribute Euclidean distance]{\\label{subfig::euclidean_distance}\\includegraphics[width=0.32\\textwidth]{fig/euclidean_distance.pdf}}\n% %   \\subfloat[Gelato scores]{\\label{subfig::our_similarity_gelato}\\includegraphics[width=0.32\\textwidth]{fig/our_similarity.pdf}}\n% %   \\caption{Illustration of the link prediction process of Gelato, AC, and %a GNN-based approach (Neo-GNN) \n% %   the best GNN-based approach, Neo-GNN, on a subgraph of \\textsc{Photo}. Gelato effectively incorporates node attributes into the graph structure and leverages topological heuristics to enable state-of-the-art link prediction. }\n% %   \\label{fig::learned_edges_gelato}\n% % \\end{figure}\n\n\n% \\subsection{Loss and training setting}\n% \\label{subsec::exp_loss}\n% In this section, we demonstrate the advantages of the proposed N-pair loss and \\emph{unbiased training} for supervised link prediction. \\autoref{fig::convergence_comparison} shows the training and validation losses and $prec@100\\%$ (our validation metric) in training Gelato based on the cross entropy (CE) and N-pair (NP) losses under \\emph{biased} and \\emph{unbiased training} respectively. The final test AP scores are shown in the titles. % We add a linear layer with the sigmoid activation function to map our prediction score to a probability for training with CE. \n% \\begin{figure*}[htbp]\n%   \\centering\n%   \\includegraphics[width=1\\textwidth]{fig/convergence_comparison_combined_photo_iclr.pdf}\n%   %\\caption{Training processes of Gelato based on different losses and training settings for \\textsc{Photo} with test $prec@100\\%$ (mean \u00b1 std) shown in the titles. Compared with the commonly used cross entropy loss, the N-pair loss with \\emph{full training} is a more consistent proxy for the evaluation objective and leads to better peak performance. }\n% %   \\vspace{-15pt}\n%   \\caption{Training of Gelato based on different losses and training settings for \\textsc{Photo} with test AP (mean \u00b1 std) shown in the titles. Compared with the cross entropy loss, the N-pair loss with \\emph{unbiased training} is a more consistent proxy for \\emph{unbiased testing} metrics and leads to better peak performance. }\n%   \\label{fig::convergence_comparison}\n% \\end{figure*}\n% % \\vspace{-5pt}\n% % \\looseness=-1  % Trick to pack more text. \n\n% In the first column (CE with \\emph{biased training}), different from the training, both loss and precision for (unbiased) validation decrease. This leads to even worse test performance compared to the untrained base model (i.e., AC). In other words, albeit being the most popular loss function for supervised link prediction, CE with \\emph{biased training} does not generalize to \\emph{unbiased testing}. \n% %cannot guide the model to learn anything useful at all under \\emph{full testing}. \n% %The reason is that as a (pointwise) classification loss, cross entropy can be effectively reduced by predicting \\emph{most} negative pairs as negative. However, this does not guarantee that positive edges are ranked above \\emph{all} negative pairs, which is needed for high precision scores. \n% On the contrary, as shown in the second column, the proposed NP loss with \\emph{biased training}---equivalent to the pairwise logistic loss \\citep{burges2005learning}---is a more effective proxy for \\emph{unbiased testing} metrics. % Even without \\emph{unbiased training}, Gelato with NP still leads to superior performance compared to all existing methods as listed in \\autoref{tab::performance_ap}, demonstrating the effectiveness of the framework to combine attributes and topology. \n\n% The right two columns show results with \\emph{unbiased training}, which is better for CE as %improves the results for CE as %significantly alleviates the problem of CE as %\\emph{all}\n% more negative pairs are present in the training set (with the original class ratio). %, also leading to better performance compared to baselines in \\autoref{tab::performance_ap}. \n% %, even though in the beginning epochs precision still decreases with the loss. \n% On the other hand, NP is more consistent with unbiased evaluation metrics, %precision at the top, \n% leading to 8.5\\% better performance. This is because, unlike CE, which optimizes positive and negative pairs independently, NP contrasts negative pairs against positive ones, giving higher importance to negative pairs that are more likely to be false positives. \\looseness=-1 %\\looseness=-1\n\n% %including the loss and training setting discussed here \n\n\n\n% % \\begin{figure}[htbp]\n% %   \\centering\n% %   \\subfloat[Training time until convergence]{\\label{subfig::training_time}\\includegraphics[width=0.5\\textwidth]{fig/training_time.pdf}}\n% %   \\subfloat[Inference time per \\emph{unbiased testing}]{\\label{subfig::testing_time}\\includegraphics[width=0.5\\textwidth]{fig/testing_time.pdf}}\n% %   \\caption{Training and inference time comparison between supervised link prediction methods for \\textsc{Photo}. Gelato has competitive training time (even under \\emph{unbiased training}) and is significantly faster than most baselines in terms of inference, especially compared to the best GNN model, Neo-GNN.  %Our approach outperforms the best GNN-based baseline (Neo-GNN) in both training and inference times.\n% %   }\n% %   \\label{fig::running_time}\n% % \\end{figure}\n\n%Some papers that could be discussed:\n%Some relevant papers:\n%https://arxiv.org/pdf/2006.06830.pdf\n%https://arxiv.org/abs/2202.08871\n\n"
                }
            },
            "section 4": {
                "name": "Related work",
                "content": "\n\\label{sec::relatedwork}\n%\\textbf{Topological heuristics for link prediction.} The early link prediction literature is centered around the design of heuristic methods for extracting graph topological information for the inference of links. This includes methods based on local neighborhood, such as Common Neighbors \\cite{newman2001clustering}, Adamic Adar \\cite{adamic2003friends}, and Resource Allocation \\cite{zhou2009predicting}, and those leveraging higher-order information, such as Katz \\cite{katz1953new}, PageRank \\cite{page1999pagerank}, and SimRank \\cite{jeh2002simrank}. More recently, random-walk based graph embedding approaches, which aim to learn vector representations for graph data \\cite{perozzi2014deepwalk, grover2016node2vec, random-walk-embedding}, have achieved promising results in graph machine learning tasks. Popular embedding methods, such as DeepWalk \\cite{perozzi2014deepwalk} and node2vec \\cite{grover2016node2vec}, have been shown to implicitly approximate the Pointwise Mutual Information similarity \\cite{qiu2018network}, which can also be used as a link prediction heuristic. This has motivated the investigation of alternative similarity metrics %for graph embedding, \n%such as Autocovariance \\cite{delvenne2010stability,random-walk-embedding, pole}. However, these heuristics are unsupervised and cannot take advantage of data beyond the topology, such as node attributes.\n\n\\textbf{Topological heuristics for link prediction.} The early link prediction literature focuses on topology-based heuristics. This includes approaches based on local (e.g., Common Neighbors \\citep{newman2001clustering}, Adamic Adar \\citep{adamic2003friends}, and Resource Allocation \\citep{zhou2009predicting}) and higher-order (e.g., Katz \\citep{katz1953new}, PageRank \\citep{page1999pagerank}, and SimRank \\citep{jeh2002simrank}) information. More recently, random-walk based graph embedding methods, which learn vector representations for nodes \\citep{perozzi2014deepwalk, grover2016node2vec, random-walk-embedding}, have achieved promising results in graph machine learning tasks. Popular embedding approaches, such as DeepWalk \\citep{perozzi2014deepwalk} and node2vec \\citep{grover2016node2vec}, have been shown to implicitly approximate the Pointwise Mutual Information similarity \\citep{qiu2018network}, which can also be used as a link prediction heuristic. This has motivated the investigation of other similarity metrics %for graph embedding, \nsuch as Autocovariance \\citep{delvenne2010stability,random-walk-embedding, pole}. However, these heuristics are unsupervised and cannot take advantage of data beyond the topology. \\looseness=-1\n\n%and more recently, Autocovariance similarity from RW embedding \\cite{random-walk-embedding}  shows promising performance for link prediction \\cite{random-walk-embedding, pole}. However, these heuristics do not have a trainable component to use supervision and cannot leverage additional information on the graph, such as node attributes. \n\n% \\begin{itemize}\n%     \\item Classic local: Common Neighbors \\cite{newman2001clustering}, Adamic Adar \\cite{adamic2003friends}, Resource Allocation \\cite{zhou2009predicting}. \n%     \\item Classic path-based: Katz \\cite{katz1953new}, PageRank \\cite{page1999pagerank}, SimRank \\cite{jeh2002simrank}. \n%     \\item Embedding based: DeepWalk \\cite{perozzi2014deepwalk}, autocovariance (RWE) \\cite{random-walk-embedding}.\n% \\end{itemize}\n% No learning. No features. \n\n%\\textbf{Graph Neural Networks for link prediction.} GNN-based link prediction addresses the limitations of topological heuristics by training a neural network to capture both topological and attribute information. A key motivation for such approaches is to potentially learn new and more effective link prediction heuristics directly from data. GAE \\cite{kipf2016variational} combines a graph convolution network \\cite{kipf2016semi} and an inner product decoder based on node embeddings for link prediction. SEAL \\cite{zhang2018link} proposes to model link prediction as a binary subgraph classification problem (edge/non-edge) by minimizing  cross-entropy. Follow-up work built-upon SEAL (e.g., SHHF \\cite{liu2020feature}, WalkPool \\cite{pan2021neural}) introduce alternative subgraph pooling strategies. Other recent approaches for GNN-based link prediction include learning representations in hyperbolic space (e.g., HGCN \\cite{chami2019hyperbolic}, LGCN \\cite{zhang2021lorentzian}), directly generalizing topological heuristics (e.g., Neo-GNN \\cite{yun2021neo}, NBFNet \\cite{zhu2021neural}), and incorporating additional topological features (e.g., TLC-GNN \\cite{yan2021link}, BScNets \\cite{chen2022bscnets}). Motivated by the growing popularity of GNNs for link prediction, this work investigates key questions regarding their training, evaluation, and ability to learn effective topological heuristics directly from data. We propose Gelato, which is simpler, more accurate, and faster than the  state-of-the-art GNN-based link prediction methods.\n\n\n\\noindent\\textbf{Graph Neural Networks for link prediction.} GNN-based link prediction addresses the limitations of topological heuristics by training a neural network to combine topological and attribute information and potentially learn new heuristics. These works often assume that links are correlated with homophily in node attributes \\cite{di2024link,zhou2022link}, as also is the case for this paper. GAE \\citep{kipf2016variational} combines a graph convolution network \\citep{kipf2016semi} and an inner product decoder based on node embeddings. SEAL \\citep{zhang2018link} models link prediction as a binary subgraph classification problem (edge/non-edge), and follow-up work (e.g., SHHF \\citep{liu2020feature}, WalkPool \\citep{pan2021neural}) investigates different pooling strategies.\nOther recent approaches for GNN-based link prediction include learning representations in hyperbolic space (e.g., HGCN \\citep{chami2019hyperbolic}, LGCN \\citep{zhang2021lorentzian}), generalizing topological heuristics (e.g., Neo-GNN \\citep{yun2021neo}, NBFNet \\citep{zhu2021neural}), and incorporating additional topological features (e.g., TLC-GNN \\citep{yan2021link}, BScNets \\citep{chen2022bscnets}). ELPH and BUDDY \\citep{chamberlain2022graph} apply hashing to efficiently approximate subgraph-based link prediction models, such as SEAL, using a message-passing neural network (MPNN) with distance-based structural features. NCNC \\citep{wang2023neural} combines the Common Neighbors heuristic with an MPNN achieving state-of-the-art results. Motivated by the growing popularity of GNNs for link prediction, this work investigates key questions regarding their training, evaluation, and ability to learn effective topological heuristics directly from data. We propose Gelato, which is simpler, more accurate, and faster than most state-of-the-art GNN-based link prediction methods. \n\n%However, we have shown that these supervised methods are not properly trained and evaluated for link prediction, and they underperform our simple model combining an MLP and Autocovariance heuristic in \\emph{full testing}. \n% \\begin{itemize}\n%     \\item Pioneering: GAE \\cite{kipf2016variational}, SEAL \\cite{zhang2018link}, HGCN \\cite{chami2019hyperbolic},\n%     \\item Recent advancement:   LGCN \\cite{zhang2021lorentzian}, \n%     % LGLP \\cite{cai2021line}, \n%     TLC-GNN \\cite{yan2021link}, Neo-GNN \\cite{yun2021neo}, NBFNet \\cite{zhu2021neural},  BScNets \\cite{chen2022bscnets}, WalkPool \\cite{pan2021neural}\n% \\end{itemize}\n% Another categorization:\n% \\begin{itemize}\n%     \\item Subgraph classification: \n%     \\begin{itemize}\n%         \\item SEAL\n%         \\item WalkPool\n%     \\end{itemize}\n%     \\item Hyperbolic space:\n%     \\begin{itemize}\n%         \\item HGCN\n%         \\item LGCN\n%     \\end{itemize}\n%     \\item Generalizing structural heuristics\n%     \\begin{itemize}\n%         \\item Neo-GNN: local neighborhood heuristics, e.g., CN, AA, RA\n%         \\item NBFNet: path heuristics, e.g., Katz, PageRank\n%     \\end{itemize}\n%     \\item Incorporating other structural features:\n%     \\begin{itemize}\n%         \\item TLC-GNN: topological features from persistence homology. \n%         \\item BSCNets: models high dimensional structure with simplical neural network. \n%     \\end{itemize}\n% \\end{itemize}\n% To add features. To learn arbitrary heuristics. But failed. \n\n\\noindent\\textbf{Graph learning.} Gelato learns a graph that combines topological and attribute information. Our goal differs from generative models \\citep{you2018graphrnn, li2018learning, grover2019graphite}, which learn to sample from a distribution over graphs. \nGraph learning also enables the application of GNNs when the graph is unavailable, noisy, or incomplete \\citep{zhao2022graph}. LDS \\citep{franceschi2019learning} and GAug \\citep{zhao2021data} jointly learn a probability distribution over edges and GNN parameters. %. using bilevel optimization. \nIDGL \\citep{chen2020iterative} and EGLN \\citep{yang2021enhanced} alternate between optimizing the graph and embeddings for node/graph classification and collaborative filtering. %, respectively. %and proposes anchoring to improve scalability. \n\\cite{singh2021edge} proposes two-stage link prediction by augmenting the graph as a preprocessing step. In comparison, Gelato effectively \nlearns a graph in an end-to-end manner by minimizing the loss of a topological heuristic. \\looseness=-1% topological\n% GAT \\cite{velivckovic2018graph}, IDGL \\cite{chen2020iterative}, Edge proposal set \\cite{singh2021edge}, \n\n"
            },
            "section 5": {
                "name": "Conclusion",
                "content": "\n\\label{sec::conclusion}\n\n% This work highlights key limitations in evaluating supervised link prediction methods due to the widespread use of \\emph{biased testing}. These limitations led to a consensus within the graph machine learning research community that (1) GNNs are the most promising approach for link prediction, casting topological heuristics obsolete; and (2) link prediction is now an easy problem due to recent advances in deep learning. Our paper challenges both of these assumptions. We show that, when evaluated properly, link prediction in sparse graphs is still a hard problem. In particular, GNNs for link prediction are not effective at handling sparse graphs due to the extreme class imbalance, motivating the design of Gelato, a novel link prediction framework introduced in this work.\n\n% Gelato is a similarity-based link prediction method that combines graph learning and autocovariance to leverage attribute and topological information. To better handle the class imbalance, Gelato applies an N-pair loss instead of cross-entropy. Finally, to efficiently sample hard negative pairs, we introduce a partitioning-based negative sampling scheme. Extensive experiments show that Gelato is more accurate and scalable than state-of-the-art GNN-based solutions across different datasets.\n\nThis work exposes key limitations in evaluating supervised link prediction methods due to the widespread use of \\emph{biased testing}. These limitations led to a consensus in the graph machine learning community that (1) GNNs are superior for link prediction, casting topological heuristics obsolete; and (2) link prediction is now an easy task due to deep learning advances. We challenge both assumptions, demonstrating that link prediction in sparse graphs remains a hard problem when evaluated properly. GNNs struggle with link prediction in sparse graphs due to extreme class imbalance, motivating Gelato, our novel link prediction framework.\n\nGelato is a similarity-based method that combines graph learning and autocovariance to leverage attribute and topological information. Gelato employs an N-pair loss instead of cross-entropy to address the class imbalance and introduces a partitioning-based negative sampling scheme for efficient hard negative pair sampling. Through extensive experiments, we demonstrate superior accuracy and scalability of Gelato when compared to state-of-the-art GNN-based solutions across various datasets.\n\n%in how GNN-based methods address the task of link prediction. We demonstrated, theoretically and empirically, how \\textit{biased-sampling} is problematic in achieving models that are competent in real-world scenarios and also that, due to the intrinsic nature of graphs, Link Prediction should be seen as a similarity-based problem to counter the existence of very hard negative pairs. We hope our findings instigate new research directions on Link Prediction targeted toward realistic scenarios in order to promote improvements to a wide range of applications. \n\n\n% JOAO: THE ORIGINAL SECTION CAN BE SEEN BELOW\n% -------------\n% \\section{Conclusion}\n% \\label{sec::conclusion}\n% %GNNs have become the go-to solution for most graph-related tasks. Our results suggest that when adapting GNNs to different problems, we should be more attentive to their specific characteristics and explore classic solutions for improving performance. In particular, we have found that taking class imbalance into consideration benefits the training and evaluation of link prediction, and incorporating attribute information directly into topology while leveraging classic heuristics leads to higher precision and better scalability. \n\n% This work sheds light on key limitations in how GNN-based link prediction methods handle the intrinsic class imbalance of the problem and presents more effective and efficient ways to combine attributes and topology. %, both in their training and evaluation. \n% %Addressing these limitations was part of the design of Gelato, a simpler model that incorporates attribute information directly into the graph structure and applies a topological heuristic for link prediction. % to the enhanced graph. \n% %Extensive experiments show that Gelato is more accurate and scalable than state-of-art GNN-based solutions across different datasets.\n% Our findings might open new research directions on machine learning for graph data, including a better understanding of the advantages of increasingly popular and sophisticated deep learning models compared to more traditional and simpler graph-based solutions. \n\n% % \\textbf{Limitations.} Important limitations of our work include: %(1) the $O(n^2)$ running time of our method using full training (testing); \n% % (1) the need for further evaluation of different choices of components of Gelato (graph learning, topological heuristic, and loss function); and (2) the lack of theoretical justification (e.g. in terms of expressive power \\cite{xu2018powerful}) for our strong empirical results.\n\n% % \\textbf{Societal impact.} Link prediction might be used to disclose private user information (e.g. in social and communication networks). Further research is needed to better protect such sensitive information and prevent its misuse by governments, corporations, and other possibly ill-intentioned parties. \n\n% %demonstrates that when adapting GNNs to different problems, we should be more attentive to their specific characteristics and explore classic solutions for improving performance. In particular, we have found that taking class imbalance into consideration benefits the training and evaluation of link prediction, and incorporating attribute information directly into topology while leveraging classic heuristics leads to higher precision and better scalability. \n\n\n\\bibliographystyle{ACM-Reference-Format}\n\\bibliography{main}\n\n\\clearpage\n\\appendix\n\\appendix\n\n% \\begin{comment}\n\n% Joao: Directly from NeurIPS2023 paper\n\n"
            },
            "section 6": {
                "name": "Analysis of link prediction evaluation metrics with different test settings",
                "content": "\n\\label{ap::example}\n\n\\emph{Example}: Consider a graph with $10K$ nodes, $100K$ edges, and $99.9M$ disconnected (or negative) pairs. A (bad) model that ranks 1M false positives higher than the true edges achieves $0.99$ AUC and $0.95$ in AP under \\emph{biased testing} with equal negative samples. \n\n\n\nFigures \\ref{subfig::roc} and \\ref{subfig::pr} show the receiver operating characteristic (ROC) and precision-recall (PR) curves for the model under \\emph{biased testing} with equal number of negative samples. Due to the downsampling, only 100k (out of 99.9M) negative pairs are included in the test set, among which only %$\\frac{100\\text{k}}{99.9\\text{M}} \\times 1\\text{M} \\approx 1\\text{k}$ \n${100\\text{k}}/{99.9\\text{M}} \\times 1\\text{M} \\approx 1\\text{k}$ pairs are ranked higher than the positive edges. In the ROC curve, this means that once the false positive rate reaches ${1\\text{k}}/{100\\text{k}}=0.01$, the true positive rate would reach 1.0, leading to an AUC score of 0.99. Similarly, in the PR curve, when the recall reaches 1.0, the precision is ${100\\text{k}}/({1\\text{k}+100\\text{k}})\\approx 0.99$, leading to an overall AP score of \\raise.17ex\\hbox{$\\scriptstyle\\sim$}0.95. \n\nBy comparison, as shown in \\autoref{subfig::pr_unbiased}, when the recall reaches 1.0, the precision under \\emph{unbiased testing} is only\n${100\\text{k}}/({1\\text{M}+100\\text{k}})\\approx 0.09$, leading to an AP score of \\raise.17ex\\hbox{$\\scriptstyle\\sim$}0.05. \n%the $prec@k$ score under \\emph{unbiased testing} is 0.0 for all $k$ values smaller than 1M, and will peak at $k=1.1\\text{M}$ with a value of $\\frac{100\\text{k}}{1.1\\text{M}}\\approx 0.09$, leading to an AP score of 0.05. \n%This demonstrates that evaluation metrics based on \\emph{unbiased testing} provide a drastically different and more informative performance evaluation for link prediction models. \nThis demonstrates that evaluation metrics based on \\emph{biased testing} provide an overly optimistic measurement of link prediction model performance compared to the more realistic \\emph{unbiased testing} setting.\n\n\n"
            },
            "section 7": {
                "name": "thm::unbiased",
                "content": "\n\\label{ap:proof_unbiased}\n\nThere are only three classifiers that we need to consider in this setting, assuming that the classifier can recover the block structure:\n\\begin{enumerate}\n\\item It predicts every disconnected pair as a link;\n\\item It predicts every disconnected pair as a non-link;\n\\item It predicts within-block pairs as links and across-block pairs as non-links.\n\\end{enumerate}\n\nThe classifier 1 cannot be optimal for sparse graphs---i.e., density lower than $.5$---and thus we will focus on classifiers 2 and 3. We will compute the expected number of True Positives (TP), False Positives (FP), False Negatives (FN), and True Negatives (TN) per node for each of them:\n\n\\paragraph{Classifier 2:} \n\n\\begin{align*}\n    TP &= 0\\\\\n    FN &= 0\\\\\n    FP &= (n-1)p+(nk-n)q\\\\\n    TN &= (n-1)(1-p)+(nk-n)(1-q)\n\\end{align*}\n\n\\paragraph{Classifier 3:} \n\n\\begin{align*}\n    TP &= (n-1)p\\\\\n    FN &= (nk-n)q\\\\\n    FP &= (n-1)p\\\\\n    TN &= (nk-n)(1-q)\n\\end{align*}\n\nThe accuracy of the classifiers is computed as $(TP+TN)/(TP+TN+FP+FN)$. It follows that the difference between accuracy of the classifier 2 and 3 is as follows:\n\\begin{equation*}\n    \\frac{(n-1)(1-p)+(nk-n)(1-q)}{nk-1}-\\frac{(n-1)p+(nk-n)(1-q)}{nk-1}\n\\end{equation*}\n\nAnd thus, classifier 2 outperforms classifier 3 for $p<0.5$.\n\n"
            },
            "section 8": {
                "name": "lemma::biased",
                "content": "\n\\label{lemma::biased_proof}\n\nWe will consider the same classifiers 2 and 3 from the proof of Theorem \\ref{thm::unbiased}. Moreover, we will assume that the number of sampled negative pairs is the same as the number of positive pairs (i.e., balanced sampling). \n\nBy definition, the accuracy of classifier 2 is 0.5, as all predictions for negative pairs will be correct and all those for positive pairs will be incorrect. Thus, we only have to show that there exists an SBM instance for which classifier 3 achieves better accuracy than 2.\n\nThe accuracy of classifier 3 is computed as $a_1+a_2/2$, where:\n\\begin{align*}\n    a_1 &= \\frac{(n-1)p}{(n-1)p+(nk-n)q}\\\\\n    a_2 &= \\frac{(nk-n)(1-q)}{(nk-n)(1-q)+(n-1)(1-p)}\n\\end{align*}\n\nIt follows that, as $q \\to 0$, classifier 3 can achieve an accuracy higher than $0.5$. \n\n"
            },
            "section 9": {
                "name": "lemma:autocov",
                "content": "\n\\label{ap::lemma}\n\n% \\begin{proof}\n    \nLet us initially consider Autocovariance with $t=1$ computed in the Stochastic Block Model described in Lemma \\ref{lemma:autocov}. We will adopt the entry-wise notation of the original Autocovariance definition presented in Section \\ref{sec:topological-heuristic}, using lower-case letters to represent individual entries in matrices and vectors, and for the sake of consistency with the Modularity definition, we adopt $\\text{vol}(G)=2m$. We first obtain the shortened form of Autocovariance for $t=1$:\n\n\\begin{align}\nR_{ij}\n&=\\cfrac{1}{2m}(a_{ij} - \\cfrac{d_id_j}{2m}).\n\\end{align}\n\nWe can obtain the expected expression value for the case where $(i, j)$ is an intra-cluster pair ($\\mathbb{E}[R_{intra}]$):\n\n\\begin{align}\n    \\mathbb{E}[R_{intra}]&=\\cfrac{1}{2m}((1-\\cfrac{d_id_j}{2m})p + (0-\\cfrac{d_id_j}{2m})(1-p))\n    \\\\\n    &=\\cfrac{1}{2m}(p-\\cfrac{d_id_j}{2m}).\n\\end{align}\n\nLikewise, we follow the same procedure for the case where $(i, j)$ is an inter-cluster pair ($\\mathbb{E}[R_{inter}]$): \n\n\\begin{align}\n    \\mathbb{E}[R_{inter}]&=\\cfrac{1}{2m}((1-\\cfrac{d_id_j}{2m})(1-p) + (0-\\cfrac{d_id_j}{2m})p)\n    \\\\\n    &=\\cfrac{1}{2m}(1-p-\\cfrac{d_id_j}{2m})\n    \\\\\n    &=\\cfrac{1}{2m}(q-\\cfrac{d_id_j}{2m}).\n\\end{align}\n\nDue to the reversible property of Markov chains, this holds for larger values of $t$.\n\nSince $p > q \\implies \\mathbb{E}[R_{intra}] > \\mathbb{E}[R_{inter}]$.\n\n% \\end{proof}\n\n"
            },
            "section 10": {
                "name": "lemma:increasing_k",
                "content": "\n\\label{ap::lemma_increasing_k}\n\nFrom Appendix \\ref{ap::lemma}, we have $\\mathbb{E}[R_{intra}]=\\cfrac{1}{2m}(p-\\cfrac{d_id_j}{2m})$ is solely dependent on the value of $p$, since all the other terms are constants. We will denominate $V_{ik}$ and $E_{ik}^+$ the number of nodes and positive pairs in the $i$-th partition of our graph partitioned in $k$ partitions. \n\nConsidering the estimate $p=\\nicefrac{|E_{ik}^+|}{|V_{ik}|^2}$, for simplicity, the number of positive pairs we can lose by increasing $k$ to $k+1$ is \\textit{at most} $|E_{ik+1}^+| \\geq |E_{ik}^+| - (|V_{ik}|^2 - |V_{ik+1}|^2)$, if we consider the extreme scenario in which every pair lost was positive. With this estimate, we can compare with the actual $p$ estimate:\n\n\\begin{align}\n    \\cfrac{|E_{ik+1}^+|}{|V_{ik+1}|^2}&\\geq\\cfrac{|E_{ik}^+| - (|V_{ik}|^2 - |V_{ik+1}|^2)}{|V_{ik+1}|^2}\n    \\\\\n    |V_{ik}|^2 - |V_{ik+1}|^2 &\\geq |E_{ik}^+| - |E_{ik+1}^+|\n\\end{align}\n\nIt follows that, since the number of pairs drops faster than the number of positive edges for a given partition, $\\mathbb{E}[R_{intra}]$ increases when $k$ increases.\n\n\n"
            },
            "section 11": {
                "name": "Can GNNs learn autocovariance?",
                "content": "\n\\label{ap::learn_autocov}\n\n\\textbf{Message-passing Neural Networks:} Classical message-passing neural networks (MPNNs) are known to be as powerful as the 1-WL isomorphism test. Recent papers have shown how this limitation affects link prediction performance \\citep{chamberlain2022graph,you2021identity,zhang2017weisfeiler,srinivasanequivalence}. Node pairs $(u,v)$ and $(u,x)$ are indistinguishable by MPNNs if $v$ and $x$ have the same receptive field (or k-hop neighborhood). Figure \\ref{fig::mpnn_autocov} shows that MPNNs are also unable distinguish node pairs with different values of Autocovariance within a graph $G$. Recently, more powerful GNNs for link prediction have also been proposed \\citep{hu2022two}. These GNNs are as powerful as the 2-WL and 2-FWL isomorphism tests, which are two versions of the 2-dimensional WL test and are more discriminative than 1-WL for link prediction. While 2-WL powerful GNNs are still not able to distinguish pairs $(u,v)$ and $(u,x)$ in Figure \\ref{fig::mpnn_autocov}, 2-FWL powerful GNNs can. This is due to the ability of 2-FWL powerful GNNs to count open and closed triads involving pairs of nodes---$(u,v)$ is part of two triangles while $(u,x)$ is part of none. However, we notice that counting triads is not sufficient to compute probabilities of paths longer than 2 hops connecting a pair of nodes. Moreover, training a GNN based on a 2-dimensional WL test takes $O(n^3)$ time, which prevents their application to large graphs.\n\n\n\n\\textbf{Subgraph Neural Networks:} Subgraph neural networks (SGNNs) differ from MPNNs as they learn representations based on node enclosing subgraphs \\citep{li2020distance,zhang2017weisfeiler,zhang2021labeling,hu2022two, chen2020can}. These subgraphs are augmented with structural features that have been proven to increase their expressive power. However, SGNNs are also known to be computationally intractable \\citep{chamberlain2022graph}. Previous work has shown that SGNNs can count the number of paths of fixed length between pairs of nodes when the aggregation operator is SUM \\cite{you2021identity}. Autocovariance is a function of path counts, node degrees, and the graph volume (constant). Therefore, it is straightforward to design a SGNN that can predict Autocovariance. However, we note that our empirical results show that SEAL and BUDDY are often outperformed by Gelato. This can be explained by the specific design of these GNNs (e.g. aggregation operator) and the sampling complexity of accurately learning Autocovariance directly from data.\n\n\n"
            },
            "section 12": {
                "name": "Estimated Stochastic Block Model Parameters",
                "content": "\n\\label{ap::estimated_sbm}\n\nWe estimate the intra-block ($p$) and inter-block ($q$) parameters of each dataset considered in our experiments using either the node labels as ground-truth partitions (for Cora, CiteSeer, and PubMed) or METIS partitions (for OGBL-DDI and OGBL-Collab) following the values exposed in Table \\ref{tab::ap::clustering_times}. The intra-block parameter is obtained through the ratio between the number of edges of the biggest partition and all the edges in the graph. We argue that Autocovariance-based design leverages the topology of datasets heavily organized as communities (Cora, CiteSeer, and PubMed) or even highly sparse (OGBL-Collab) to obtain state-of-the-art performance. We notice, however, that these benefits diminish in extremely dense networks, such as OGBL-DDI, a challenging scenario for all methods.\n\n\n\n"
            },
            "section 13": {
                "name": "Detailed experiment settings",
                "content": "\n\\label{ap::setting}\n\n% \\textbf{Data splits for unbiased training and unbiased testing.} \n% We first randomly (with seed 0) split the edges $E$ of the original graph into $E_{train}^+$, $E_{valid}^+$, and $E_{test}^+$ for training, validation, and testing. Then, we set the negative pairs in these three sets as (1) $E_{train}^{-} = E^{-} + E_{valid}^+ + E_{test}^+$, (2) $E_{valid}^{-} = E^{-} + E_{test}^+$, and (3) $E_{test}^{-} = E^{-}$, where $E^{-}$ is the set of all negative pairs (excluding self-loops) in the original graph. Notice that the validation and testing \\emph{positive} edges are included in the \\emph{negative} training set, and the testing \\emph{positive} edges are included in the \\emph{negative} validation set. These inclusions simulate the real-world scenario where the testing edges (and the validation edges) are unobserved during validation (training). For large graphs, one can downsample both positive and negative pairs to maintain the same class ratio as the input graph for training and testing. \\looseness=-1\n\n\\noindent\\textbf{Positive masking.} For \\emph{unbiased training}, a trick similar to \\emph{negative injection} \\citep{zhang2018link} in \\emph{biased training} is needed to guarantee model generalizability. Specifically, we divide the training positive edges into batches and during the training with each batch $E_b$, we feed in only the residual edges $E-E_b$ as the structural information to the model. This setting simulates the testing phase, where the model is expected to predict edges without using their own connectivity information. We term this trick \\textit{positive masking}.\n\n%We adopt another trick for training our model. \n% We divide the training positive edges into batches and during the training with each batch $E_b$, we only feed in the residual edges $E-E_b$ to the model. This setting simulates the testing phase, where the model is expected to predict edges without using their own connectivity information. We term this trick \\textit{positive masking} and have found it crucial to improve model generalization in our experiments. Note that a similar trick, \\emph{negative injection}, is proposed in GNN-based link prediction methods \\cite{zhang2018link} but is inappropriate for \\emph{unbiased training}.\n\n\\noindent\\textbf{Other implementation details.} We add self-loops to the enhanced adjacency matrix to ensure that each node has a valid transition probability distribution that is used in computing Autocovariance. The self-loops are added to all isolated nodes in the training graph for all datasets. Following the postprocessing of the Autocovariance matrix for embedding in \\cite{random-walk-embedding}, we standardize Gelato similarity scores before computing the loss. \n% For training with the cross-entropy loss, we further add a linear layer with the sigmoid activation function to map our prediction score to a probability. \nWe optimize our model with gradient descent via \\texttt{autograd} in \\texttt{pytorch} \\citep{pytorch}. We find that the gradients are sometimes invalid when training our model (especially with the cross-entropy loss), and we address this by skipping the parameter updates for batches leading to invalid gradients. Finally, we use $prec@100\\%$ on the (unbiased) validation set as the criteria for selecting the best model from all training epochs. The maximum number of epochs for \\textsc{Cora}/\\textsc{CiteSeer} and \\textsc{OGBL-DDI}/\\textsc{OGBL-Collab} is set to be 100 and 250, respectively. For \\emph{partitioned testing}, we apply METIS \\citep{karypis1998fast} as our graph partitioning algorithm, due to its scalability and a balanced number of nodes per partition.\n\n \n\n\\noindent\\textbf{Experiment environment.} We run our experiments in an \\emph{a2-highgpu-1g} node of the Google Cloud Compute Engine. It has one NVIDIA A100 GPU with 40GB HBM2 GPU memory and 12 Intel Xeon Scalable Processor (Cascade Lake) 2nd Generation vCPUs with 85GB memory. \n\n\\noindent\\textbf{Reference of baselines.} We list link prediction baselines and their reference repositories we use in our experiments in \\autoref{tab::baseline}. Note that we had to implement the batched training and testing for several baselines as their original implementations do not scale to \\emph{unbiased training} and \\emph{unbiased testing} without downsampling. \n\n% We adapted the available codes to full training and testing settings. More specifically, we implemented the batched training/testing versions to make them scalable. %The most challenging baseline to work with was NBFNet, which has flexibility issues for extending the method for different datasets and full training/testing versions.\n\n\n\n\n% \\noindent\\textbf{Number of trainable parameters.} The only trainable component in Gelato is the graph learning MLP, which for \\texttt{Photo} has 208,130 parameters. By comparison, the best performing GNN-based method, Neo-GNN, has more than twice the number of parameters (455,200). \n%By comparison, most GNN-based link prediction methods have more parameters, including GAE (223,872), SEAL (252,610), Neo-GNN (455,200), BScNets (7,130,020), and WalkPool (3,350,801). HGCN, LGCN, TLC-GNN, and NBFNet have less number of parameters (112,000, 60,224, 77,292, 84,897), but they achieve worse performance even compared to simple parameter-free topological heuristics. \n\n\n\n\n"
            },
            "section 14": {
                "name": "Gelato - Unbiased vs Partitioned",
                "content": "\n\\label{sec::similarities_non_normalized}\n\nFigure \\ref{fig::ap::partitioned_vs_unbiased} demonstrates we obtain splits that are both realistic and scalable using \\textit{partitioned sampling} through varying values of K in hits@K metric evaluated on CiteSeer. It is possible to verify that there is almost no performance gap between \\textit{partitioned} and \\textit{unbiased} training, even in a very extreme partitioning scenario. Unbiased training takes $O(V^2 - E)$ for sparse graphs due to a large number of negative samples, while proposed negative sampling significantly reduces the training time to $O(\\sum_i^p |V_i|^2 - |E_i|)$, where $(V_i,E_i)$ are the sets of nodes and edges within partition $i$. We experimented with different values of $p$ and obtained negligible impact on performance, demonstrating that the choice of the parameter $p$ is not critical to the success of the approach.\n\n\n\n\n"
            },
            "section 15": {
                "name": "Additional Link Prediction Model Comparison",
                "content": "\n\\label{ap::prec@k}\n\nDespite its simplicity, Gelato is consistently among the best link prediction models considering $prec@k$. We demonstrate the competitive results of Gelato against the GNN-based models by varying $k$ in Figure \\ref{fig::ap::prec@k}. We also include additional AP and MRR results in Tables \\ref{tab::performance_ap} and \\ref{tab::performance_mrr}.\n\n\n\n\n\n% \n\n"
            },
            "section 16": {
                "name": "Non-normalized Partitioned Sampling Results",
                "content": "\n\\label{ap::non_normalized_plots}\n\nWe recreate Figure \\ref{fig::three_regimes} with non-normalized densities to show the extreme difference in the number of negative and positive pairs. \n\n\n\n\n\n\n"
            },
            "section 17": {
                "name": "Time comparison",
                "content": "\n\\label{ap::time_comparison}\n\nIn \\autoref{tab::ap::time_comparison}, we compare the total training time between Gelato and our two main competitors: BUDDY and NCN (the faster version of NCNC). It is possible to notice a few patterns: Gelato suffers with graphs with a large number of nodes (mainly due to the sparse-tensor operations used in sparse autocovariance), whereas NCN gets worse results in denser networks (due to the Common Neighbors dependency), despite being the fastest. BUDDY relies on storing hashes, which results in an OOM error when running PubMed on the \\textit{unbiased training} scenario and also suffers in datasets with many node features, such as CiteSeer.\n\n\n\n\n\n% In addition, we present results for Gelato trained and evaluated in the \\textbf{biased} setting in Table \\ref{tab::hits_bt_bt}.\n\n\n\n\n\n\n% \\input{iclr2023/results_tables/hits_bt}\n\n\n"
            },
            "section 18": {
                "name": "Clustering times",
                "content": "\n\\label{ap:clustering}\n\nWe chose METIS\\cite{karypis1998fast} as our graph partitioning method due to its scalability and the fact it produces partitions with a similar number of nodes. METIS runs as a pre-processing step in our pipeline to enable \\textit{partitioned} sampling, in which we consider only negative pairs within each partition.  We display in Table \\ref{tab::ap::clustering_times} the clustering time for each dataset and the number of partitions considered using the METIS implementation available in the \\texttt{}{torch-sparse} (\\url{https://github.com/rusty1s/pytorch_sparse}) Python package.\n\n% Please add the following required packages to your document preamble:\n% \\usepackage{booktabs}\n\n\n\n"
            },
            "section 19": {
                "name": "Biased training results",
                "content": "\n\\label{ap::biased_training}\n\n% First\n\\newcommand{\\first}[1]{\\textcolor{blue}{\\textbf{#1}}}\n% Second\n\\newcommand{\\second}[1]{\\textcolor{red}{\\textbf{#1}}}\n% Third \n\\newcommand{\\third}[1]{\\textcolor{brown}{\\textbf{#1}}}\n\n% \\input{iclr2023/results_tables/hits_bt_bt}\n\n% \\input{iclr2023/results_tables/hits_bt}\n\n\n\n\n\n\n \n\n\nWe present results for Gelato trained in the \\textit{biased} setting and evaluated in the \\textit{unbiased} / \\textit{partitioned} setting in Table \\ref{tab::ap::hits_bt} for the small datasets. The results show a performance degradation for most models in almost all datasets, especially for BUDDY and NCN. SEAL, NeoGNN, and Gelato have better robustness, obtaining even better results comparatively in some scenarios. \n\n\nWe also present results for Gelato trained and evaluated in the \\textit{biased} setting in Table \\ref{tab::ap::hits_bt_bt}. The results are overly optimistic, not reflecting the performance in the sparse link prediction scenarios.\n\n\n\n"
            },
            "section 20": {
                "name": "GNN results",
                "content": "\n\\label{ap::gnn}\n\nWe substitute the MLP module of Gelato with a GNN module using GIN \\cite{xu2018powerful} (GelatoGIN). The results are displayed in Figure \\ref{fig::ap::gnn}, depicting an overfitting scenario that is more pronounced in GelatoGIN considering $prec@k$ results.\n\n\n\n"
            },
            "section 21": {
                "name": "Sensitivity Analysis and Learning Hyperparameters",
                "content": "\n\\label{ap::sensitivity_analysis}\n\nWe conduct a sensitivity analysis of the $\\alpha$ and $\\beta$ hyperparameters considering $AP$ on validation as the accuracy metric in Figure \\ref{fig::ap::sensitivity_analysis}. The other two hyperparameters are set to $\\eta=0$ and $T=3$ in both scenarios. We show that there is a smooth transition between the values of AP obtained through different hyperparameters, facilitating hyperparameter search. Similarly, we conduct a sensitivity analysis of $\\eta$, considering both AP and hits@1000 as accuracy metrics in Figure \\ref{fig::ap::eta_experiments}. The transition between values of hits@1000 and AP is smooth, showing that the addition of edges is, in general, beneficial to model performance. For the highest values of $\\eta$, it is possible to see a small performance drop, which can be attributed to noisy edges added by the procedure.\n\nWe also present in \\autoref{fig::ap::learning_params} results treating both $\\alpha$ and $\\beta$ as learnable parameters, showing that this procedure does not improve the $prec@k$ or $hits@k$ results. The values found for the hyperparameters were $\\alpha=0.5670$ and $\\beta=0.4694$ on Cora and $\\alpha=0.5507$ and $\\beta=0.4555$ on CiteSeer.\n\n\n\n\n\n\n\n\n\n\n\n\n"
            }
        },
        "tables": {
            "tab::dataset": "\\begin{table}[htbp]\n \\centering\n \\small\n \\caption{A summary of dataset statistics. }\n   \\begin{tabular}{ccccccc}\n   \\toprule\n          & \\#Nodes     & \\#Edges     & \\#Attrs     & Avg. degree & Density\\\\\n   \\midrule\n   \\textsc{Cora}  & 2,708  & 5,278  & 1,433  & 3.90 & 0.14\\% \\\\\n   \\textsc{CiteSeer} & 3,327  & 4,552  & 3,703  & 2.74 & 0.08\\% \\\\\n  \\textsc{PubMed} & 19,717 & 44,324 & 500   & 4.50 & 0.02\\% \\\\\n   \\textsc{ogbl-ddi} & 4,267 & 1,334,889 & 0 & 500,5 & 7.33\\% \\\\\n   \\textsc{ogbl-collab} & 235,868 & 1,285,465 & 128 &  8.2 & 0.0046\\% \\\\ %fixed\n   \\bottomrule\n   \\end{tabular}%\n \\label{tab::dataset}%\n\\end{table}",
            "tab::ablation": "\\begin{table}[htbp]\n    \\setlength\\tabcolsep{7pt}\n  \\centering\n  \\caption{Results of the ablation study based on hits@1000 scores. Each component of Gelato plays an important role in enabling state-of-the-art link prediction performance. }\n  \\begin{threeparttable}\n    \\begin{tabular}{lccccc}\n    \\toprule\n          & \\textsc{Cora}  & \\textsc{CiteSeer} & \\textsc{PubMed}\n          % & \\textsc{Photo} & \\textsc{Computers} \n          \\\\\n    \\midrule\n        \\emph{Gelato$-$MLP} & 16.13 \u00b1 0.00 & 19.78 \u00b1 0.00 & 3.81 \u00b1 0.0\n        % & 16.63 \u00b1 0.00 &  11.64 \u00b1 0.00 \n        \\\\\n        \\emph{Gelato$-$AC} & 2.66 \u00b1 2.57 & 12.6 \u00b1 0.71 & 0.0 \u00b1 0.0\n        % & 7.45 \u00b1 0.44 & 4.09 \u00b1 0.16  \n        \\\\\n        % Gelato $-$ E2E & 2.13 \u00b1 0.65 & \\textit{4.69 \u00b1 0.07} & 0.40 \u00b1 0.17 & 4.72 \u00b1 1.35 & 2.72 \u00b1 0.10 \\\\ \n        \\emph{Gelato$-$NP+UT} & 16.32 \u00b1 0.19 & 19.41 \u00b1 0.34 & 4.05 \u00b1 0.12\\\\\n        % & 14.87 \u00b1 1.41 & 9.77 \u00b1 2.67 \\\\\n        \\emph{Gelato$-$NP} & 16.51 \u00b1 0.19 & 17.88 \u00b1 0.46 & 1.74 \u00b1 0.14\\\\\n        % & 19.63 \u00b1 0.38 & 9.84 \u00b1 4.42 \\\\\n        % \\emph{Gelato$-$UT} & 16.95 \u00b1 0.29 & 18.9 \u00b1 0.58 \\\\\n        % & 23.66 \u00b1 1.01 & 11.59 \u00b1 0.35  \\\\\n        \\emph{Gelato} & \\textbf{16.62 \u00b1 0.31} & \\textbf{19.89 \u00b1 0.23} & \\textbf{4.18 \u00b1 0.19}\\\\\n        % & \\textbf{25.68 \u00b1 0.53} & \\textbf{18.77 \u00b1 0.19} \\\\\n    \\bottomrule\n    \\end{tabular}%\n  \\end{threeparttable}\n  \\label{tab::ablation}%\n\\end{table}",
            "tab::losses": "\\begin{table}[htbp]\n    \\setlength\\tabcolsep{7pt}\n  \\centering\n  \\caption{Comparison between N-pair loss (Gelato) against the Precision@K (PK), pairwise hinge (PH), pairwise exponential (PE), and pairwise logistic (PL) losses considering the $hits@1000$ metric. }\n  \\begin{threeparttable}\n    \\begin{tabular}{lccccc}\n    \\toprule\n          & \\textsc{Cora}  & \\textsc{CiteSeer}\n          % & \\textsc{Photo} & \\textsc{Computers} \n          \\\\\n    \\midrule\n        \\textit{Gelato-PK} & 16.32 \u00b1 0.19 & 19.19 \u00b1 0.99 \\\\\n        \\textit{Gelato-PH} & \\textbf{18.09 \u00b1 0.48} & 16.56 \u00b1 0.13 \\\\\n        \\textit{Gelato-PE} & 16.82 \u00b1 0.48 & 15.9 \u00b1 0.34 \\\\\n        \\textit{Gelato-PL} & 18.03 \u00b1 0.38 & 17.14 \u00b1 0.66 \\\\\n        \\textit{Gelato} & 16.62 \u00b1 0.31 & \\textbf{19.89 \u00b1 0.24} \\\\\n    \\bottomrule\n    \\end{tabular}%\n  \\end{threeparttable}\n  \\label{tab::losses}%\n\\end{table}",
            "tab::baseline": "\\begin{table}[htbp]\n  \\small\n  \\centering\n  \\setlength{\\tabcolsep}{3pt}\n  \\caption{Reference of baseline code repositories. }\n    \\begin{tabular}{cc}\n    \\toprule\n     Baseline  & Repository \\\\\n    \\midrule\n    % GAE \\citep{kipf2016semi} & \\url{https://github.com/zfjsail/gae-pytorch} %& \\href{https://github.com/zfjsail/gae-pytorch/blob/master/LICENSE}{MIT}  \n    % \\\\\n    SEAL \\citep{zhang2018link}  & \\url{https://github.com/facebookresearch/SEAL_OGB} %& \\href{https://github.com/facebookresearch/SEAL_OGB/blob/main/LICENSE}{MIT} \n    \\\\\n    % HGCN  \\citep{chami2019hyperbolic}  & \\url{https://github.com/HazyResearch/hgcn}  %& --- \n    % \\\\\n    % LGCN  \\citep{zhang2021lorentzian}  & \\url{https://github.com/ydzhang-stormstout/LGCN/}  %& ---  \n    % \\\\\n    % TLC-GNN  \\citep{yan2021link} & \\url{https://github.com/pkuyzy/TLC-GNN/} %& --- \n    % \\\\\n    Neo-GNN  \\citep{yun2021neo}  & \\url{https://github.com/seongjunyun/Neo-GNNs} %& --- \n    \\\\\n    % NBFNet  \\citep{zhu2021neural} & \\url{https://github.com/DeepGraphLearning/NBFNet} %& \\href{https://github.com/DeepGraphLearning/NBFNet/blob/master/LICENSE}{MIT} \n    % \\\\\n    % BScNets  \\citep{chen2022bscnets}  & \\url{https://github.com/BScNets/BScNets} % & --- \n    % \\\\\n    % WalkPool \\citep{pan2021neural}  & \\url{https://github.com/DaDaCheng/WalkPooling} %& ---  \n    % \\\\\n    % AC  \\citep{random-walk-embedding}  & \\url{https://github.com/zexihuang/random-walk-embedding}  %& \\href{https://github.com/zexihuang/random-walk-embedding/blob/master/LICENSE}{GPL 3.0} \n\n    % \\\\\n    BUDDY  \\citep{chamberlain2022graph}  & \\url{https://github.com/melifluos/subgraph-sketching}  %& \\href{https://github.com/zexihuang/random-walk-embedding/blob/master/LICENSE}{GPL 3.0} \n\n    \\\\\n    NCN / NCNC  \\citep{wang2023neural}  & \\url{https://github.com/zexihuang/random-walk-embedding}  %& \\href{https://github.com/GraphPKU/NeuralCommonNeighbor}\n\n    \\\\\n    \\bottomrule\n    \\end{tabular}%\n  \\label{tab::baseline}%\n\\end{table}",
            "tab::ap::time_comparison": "\\begin{table}[h]\n  \\caption{Estimated total training time (in hours).}\n\\label{tab::ap::time_comparison}\n\\centering\n\\begin{tabular}{llll}\n\\hline\n            & BUDDY & NCN  & Gelato \\\\ \\hline\nCora        & 0.02  & 0.14 & 0.08     \\\\\nCiteSeer    & 38.59  & 0.19 & 0.11   \\\\\nPubMed      & OOM   & 0.21 & 2.00    \\\\\nOGBL-DDI    & 30.00  & 1.67  & 0.02   \\\\\nOGBL-Collab & 5.29  & 0.87  & 30.00*  \\\\ \\hline\n\\multicolumn{4}{l}{\\small *Uses sparse autocovariance implementation.} \\\\\n\\end{tabular}\n\n\n\n\n\\end{table}",
            "tab::ap::clustering_times": "\\begin{table}[htbp]\n\\caption{METIS clustering time for each dataset in seconds. METIS executes scalable and fast graph partitioning, adding negligible running time to the pre-processing step.}\n\\label{tab::ap::clustering_times}\n\\centering\n\n\\begin{tabular}{@{}lll@{}}\n\n\\toprule\n            & \\# Partitions & Time (s) \\\\ \\midrule\nCora        & 10            & 0.07     \\\\\nCiteSeer    & 10            & 0.03     \\\\\nPubMed      & 100           & 0.16     \\\\\nOGBL-DDI    & 20            & 0.42     \\\\\nOGBL-Collab & 1300          & 1.91     \\\\ \\bottomrule\n\\end{tabular}\n\\end{table}",
            "tab::ap::hits_bt": "\\begin{table}\n    \\setlength\\tabcolsep{4.65pt}\n    \\small\n  \\caption{We present results (mean $\\pm$ std hits@100) for GNN methods versus Gelato trained in \\textit{biased training} splits and evaluated on \\textit{unbiased} (Cora and CiteSeer) and \\textit{partitioned} (OGBL-DDI) splits.}\n  \\centering\n  \\begin{threeparttable}\n  % \\fontsize{6}{7.2}\n\n    \\begin{tabular}{ccccc}\n    \\toprule\n          &       & \\textsc{Cora}  & \\textsc{CiteSeer} & \\textsc{ogbl-ddi}\\\\\n    \\midrule\n    & SEAL & \\third{1.14} \\tnote{*} & \\second{2.2} \\tnote{*} & \\third{0.05} \\tnote{*} \\\\\n    & NeoGNN & 0.82 \u00b1 0.11 & \\third{1.83 \u00b1 0.34} & \\second{0.066} \\tnote{*} \\\\\n    & BUDDY & \\second{1.52 \u00b1 0.0} & 1.32 \u00b1 0.0 & \\second{0.066 \u00b1 0.0} \\\\\n    & NCN & 0.0 \u00b1 0.0 & 0.11 \u00b1 0.16 & 0.0 \u00b1 0.0 \\\\\n    \\midrule    \n    & Gelato & \\first{3.42 \u00b1 0.33} & \\first{3.44 \u00b1 0.13} & \\first{0.071 \u00b1 0.0} \\\\\n    \\bottomrule\n    \\end{tabular}%\n\t\\begin{tablenotes}[para]\n\t\\item[*] Run only once as each run takes $>$24 hrs.\n\t% \\hspace{5pt} *** Each run takes $>$1000 hrs; \\hspace{5pt} OOM: Out Of Memory.\n    \\end{tablenotes}\n    \n  \\end{threeparttable}\n  \\label{tab::ap::hits_bt}%\n\\end{table}",
            "tab::ap::hits_bt_bt": "\\begin{table}\n    \\setlength\\tabcolsep{4.65pt}\n    \\small\n  \n  \\caption{We present results (mean $\\pm$ std hits@100) for GNN methods versus Gelato, all trained and evaluated in \\textit{biased}  splits. The top three models are colored by \\textcolor{blue}{\\textbf{First}}, \\textcolor{red}{\\textbf{Second}} and \\textcolor{brown}{\\textbf{Third}}.}\n  \\centering\n  \n  \\begin{threeparttable}\n  % \\fontsize{6}{7.2}\n\n    \\begin{tabular}{ccccc}\n    \\toprule\n          &       & \\textsc{Cora}  & \\textsc{CiteSeer} & \\textsc{ogbl-ddi}\\\\\n    \\midrule\n    \n    & SEAL & \\second{89.18}\\tnote{*}& \\third{90.99}\\tnote{*}& \\second{4.66}\\tnote{*}\\\\\n    & NeoGNN & 62.49 \u00b1 9.87 & 89.16 \u00b1 0.83 & \\first{5.22}\\tnote{*} \\\\\n    & BUDDY & \\first{93.36 \u00b1 0.0} & \\first{98.68 \u00b1 0.0} & 0.33 \u00b1 0.0\\\\\n    & NCN & \\first{93.36 \u00b1 0.54} & \\second{95.93 \u00b1 0.47} & 0.76 \u00b1 0.6 \\\\\n    \n    \\midrule    \n    & Gelato & \\third{78.49 \u00b1 0.22} & 84.4 \u00b1 0.0 & \\third{4.18 \u00b1 0.0} \\\\\n    \\bottomrule\n    \\end{tabular}%\n\t\\begin{tablenotes}[para]\n\t\\item[*] Run only once as each run takes $>$24 hrs.\n\t% \\hspace{5pt} *** Each run takes $>$1000 hrs; \\hspace{5pt} OOM: Out Of Memory.\n    \\end{tablenotes}\n    \n  \\end{threeparttable}\n  \\label{tab::ap::hits_bt_bt}%\n\\end{table}"
        },
        "figures": {
            "fig::overview": "\\begin{figure*}\n    \\centering\n    \\includegraphics[width=1\\textwidth]{iclr2023/fig/overview_iclr_neg_samp.pdf}\n    \\caption{Gelato applies graph learning to incorporate attribute information into the topology. The learned graph is given to a topological heuristic that predicts edges between node pairs with high Autocovariance similarity. The parameters of the MLP are optimized end-to-end using the N-pair loss over node pairs selected via a partitioning-based negative sampling scheme. Experiments show that Gelato outperforms state-of-the-art GNN-based link prediction methods. \\looseness=-1%, including those based on GNNs. \n    }\n    \\label{fig::overview}\n\\end{figure*}",
            "fig:sparse_gelato": "\\begin{figure}[t!]\n    \\centering\n    \\includegraphics[width=0.5\\textwidth]{kdd2024/fig/diagram-20240204_cropped.pdf}\n    \\caption{Scaling up Gelato using batching and sparse tensors. We represent sparse tensors (1 and 2) as matrices with blank entries and dense tensors (3 and 4) as color-filled matrices. We extract from the enhanced transition matrix (1) a slice $P_0$ (2) given a batch of node indices $V_{batch}$. Instead of a  matrix exponentiation, we compute $P_0$ $(\\widetilde{D}^{-1}\\widetilde{A})$ repeatedly for $t$ times to obtain $P_k$ (3), a dense tensor. Finally, we use $P_k$ to obtain the autocovariance $R$ (4) for nodes in the batch. This is implemented efficiently using dense-sparse tensor multiplication. }\n    \n    %\\caption{SparseGelato works in the same way as Gelato but saves memory by using only a slice ($P_0$) of the enhanced and normalized adjacency matrix $(\\widetilde{D}^{-1} - \\widetilde{A})$. This slice consists of the rows extracted from the indices of the nodes present in the current batch ($V_{batch}$) and will substitute the matrix power operation, enabling us to save memory by computing a dense-sparse multiplication, instead of a dense-dense matrix exponentiation. The result in the end is a $|V_{batch}| \\times |V|$ matrix that contains the autocovariance values $R_{uv}$ for all pairs $(u, v)$ in the batch. In the figure, sparse matrices are represented with \"empty\" entries in white, as opposed to dense matrices, which have no empty entries.}\n    \\label{fig:sparse_gelato}\n\\end{figure}",
            "fig::three_regimes": "\\begin{figure*}\n    \\centering\n    \\includegraphics[width=1\\textwidth]{iclr2023/fig/three_regimes.pdf}\n    \\caption{We analyze classification-based and similarity-based link prediction approaches through a comparison between the probability density functions of predicted similarities/scores by Gelato and NCN (state-of-the-art GNN), on the test set in three different regimes (biased, unbiased, and partitioned). Negative pairs are represented in \\textcolor{red}{red}, and positive pairs are represented in \\textcolor{blue}{blue}. By treating link prediction as a similarity-based problem, Gelato presents better separation (smaller overlap) between the similarity curves in the harder scenarios, distinguishing between positive and negative pairs across all testing regimes. NCN presents a drastic increase in overlap as negative pairs become harder, struggling to separate positive and negative pairs. }%remains consistent in all three scenarios, while NCN positive and negative score distributions become almost indistinguishable as negative pairs become harder.}\n    \\label{fig::three_regimes}\n\\end{figure*}",
            "fig::hits@k": "\\begin{figure*}\n    \n\n    \\centering\n    \\includegraphics[width=1\\textwidth]{iclr2023/fig/hitsk_four_plots.pdf}\n    \\caption{Link prediction comparison in terms of $hits@k$ varying $k$ using Cora, CiteSeer, OGBL-DDI and OGBL-Collab. All datasets were split using \\textit{unbiased} sampling, except OGBL-Collab, which was split using \\textit{partitioned} sampling. Gelato outperforms the baselines across different values of $k$ and remains competitive on OGBL-DDI, a dataset in which all methods struggle.}\n    \\label{fig::hits@k}\n\\end{figure*}",
            "fig::roc_pr": "\\begin{figure*}[htbp]\n%\\captionsetup[subfloat]{captionskip=-1pt}\n  \\centering\n  \\subfloat[ROC]{\\label{subfig::roc}\\includegraphics[width=0.333\\textwidth]{kdd2024/fig/example_roc_iclr.pdf}}\n%   \\hspace{0.02\\textwidth}\n  \\subfloat[PR under \\textit{biased testing}]{\\label{subfig::pr}\\includegraphics[width=0.333\\textwidth]{kdd2024/fig/example_pr_iclr.pdf}}\n%   \\hspace{0.02\\textwidth}\n  \\subfloat[PR under \\textit{unbiased testing}]{\\label{subfig::pr_unbiased}\\includegraphics[width=0.333\\textwidth]{kdd2024/fig/example_pr_full_iclr.pdf}}\n  \\caption{Receiver operating characteristic and precision-recall curves for the bad link prediction model that ranks 1M false positives higher than the 100k true edges. % While the model ranks 1M false positives higher than the 100k true edges in its prediction, \n%  ranks 10 times the negative pairs above the positive pairs in its prediction, \n  The model achieves 0.99 in AUC and 0.95 AP under \\emph{biased testing}, while the more informative performance evaluation metric, Average Precision (AP) under \\emph{unbiased testing}, is only 0.05. }\n  \\label{fig::roc_pr}\n\\end{figure*}",
            "fig::ap::partitioned_vs_unbiased": "\\begin{figure}\n    \n\n    % \\centering\n    \\includegraphics[width=0.4\\textwidth]{kdd2024/fig/hitsk_partition_performance.pdf}\n    \\caption{Comparison between Gelato trained using \\emph{unbiased} sampling against \\emph{partitioned} sampling on CiteSeer for different values of $K$. We verify that even in extreme partitioning scenarios ($k=50$, $\\approx 66$ nodes per partition), there is only a small performance gap between both models, but the \\textit{partitioned} sampling approach trains almost 6x times faster than the \\textit{unbiased} sampling approach. The speedup increases with the number of partitions.}\n    \\label{fig::ap::partitioned_vs_unbiased}\n\\end{figure}",
            "fig::ap::prec@k": "\\begin{figure*}\n    \n\n    \\centering\n    \\includegraphics[width=1\\textwidth]{iclr2023/fig/preck_four_plots.pdf}\n    \\caption{Link prediction comparison in terms of $prec@k$ using Cora, CiteSeer, OGBL-DDI and OGBL-Collab. All datasets were split using \\textit{unbiased} sampling, except OGBL-Collab, which was split using \\textit{partitioned} sampling. Gelato obtains the best performance on Cora and OGBL-Collab by a large margin and remains competitive on CiteSeer and OGBL-DDI, a dataset in which all methods struggle.}\n    \\label{fig::ap::prec@k}\n\\end{figure*}",
            "fig::ap::mesh1": "\\begin{figure*}\n\n    \\centering\n    \\includegraphics[width=1\\textwidth]{iclr2023/fig/three_regimes_proportion.pdf}\n    \\caption{The non-normalized version of the Figure \\ref{fig::three_regimes}. Negative pairs are represented in \\textcolor{red}{red}, and positive pairs are represented in \\textcolor{blue}{blue}. For unbiased and partitioned testing, negative pairs are significantly more likely than positive ones---due to graph sparsity---even for the largest values of similarity or scores. For this reason, for any decision boundary chosen, distinguishing positive pairs from negative ones is like finding ``needles in a haystack''.}\n    \\label{fig::ap::mesh1}\n\\end{figure*}",
            "fig::ap::gnn": "\\begin{figure*}\n    \\centering\n    \\includegraphics[width=1\\textwidth]{iclr2023/fig/preck_gnn.pdf}\n    \\caption{Performance comparison ($prec@k$) between Gelato (in \\textcolor{blue}{\\textbf{blue}}) against GelatoGIN (in \\textcolor{purple}{\\textbf{green}}), which replaces the MLP module by GIN. The dashed line represents the performance on training, while the full line represents the performance on test. We can see that despite eventually obtaining better results on training (CiteSeer), this performance is not matched by the test results, demonstrating overfitting.}\n    \\label{fig::ap::gnn}\n\\end{figure*}",
            "fig::ap::sensitivity_analysis": "\\begin{figure*}\n    \n    \\centering\n    \\includegraphics[width=0.9\\textwidth]{iclr2023/fig/sensitivity_analysis.pdf}\n    \\caption{Sensitivity analysis of $\\alpha$ and $\\beta$ considering $AP$ metric.}\n    \\label{fig::ap::sensitivity_analysis}\n\\end{figure*}",
            "fig::ap::learning_params": "\\begin{figure*}\n    \n\n    \\centering\n    \\includegraphics[width=0.8\\textwidth]{iclr2023/fig/learned_params.pdf}\n    \\vspace{1em}\n    \\includegraphics[width=0.8\\textwidth]{iclr2023/fig/learned_params_hits.pdf}\n    \\caption{Results of $prec@k$ (top) and $hits@k$ (bottom) of Gelato (in \\textcolor{blue}{\\textbf{blue}}) against Gelato with $\\alpha$ and $\\beta$ as learning parameters (in \\textcolor{purple}\n    {\\textbf{green}}). In both datasets and metrics considered, the learned $\\alpha$ and $\\beta$ obtained worse values than the values found by the grid search hyperparameter tuning strategy.}\n    \\label{fig::ap::learning_params}\n\\end{figure*}",
            "fig::ap::eta_experiments": "\\begin{figure*}\n    \\centering\n    \\includegraphics[width=0.8\\textwidth]{kdd2024/fig/eta_experiments.pdf}\n    \\caption{Performance of Gelato with different values of $\\eta$. We represent hits@1000 in \\textcolor{darkgreen}{\\textbf{green}} and AP in \\textcolor{blue}{\\textbf{blue}}.}\n    \\label{fig::ap::eta_experiments}\n\\end{figure*}"
        },
        "equations": {
            "eq:1": "\\begin{equation}\n    \\widetilde{E} = E + \\{(u, v) \\mid s(x_u, x_v) > \\epsilon_\\eta\\}\n\\end{equation}",
            "eq:2": "\\begin{equation}\n    w_{uv} = \\mlp([x_u; x_v]; \\theta)\n\\end{equation}",
            "eq:3": "\\begin{equation}\n    w_{uv} = \\mlp([x_u+x_v; |x_u - x_v|]; \\theta)\n\\end{equation}",
            "eq:4": "\\begin{equation}\n    \\widetilde{A}_{uv} = \\alpha A_{uv} + (1-\\alpha)(\\beta w_{uv} + (1-\\beta) s(x_u, x_v))\n\\end{equation}",
            "eq:5": "\\begin{equation}\n    \\label{eqn:autocov}\n    R = \\frac{\\widetilde{D}}{\\text{vol}(\\widetilde{G})}(\\widetilde{D}^{-1}\\widetilde{A})^t - \\frac{\\Tilde{d}\\Tilde{d}^T}{\\text{vol}^2(\\widetilde{G})}\n\\end{equation}",
            "eq:6": "\\begin{equation}\n\\label{eq:modularity}\n    Q=\\cfrac{1}{4m}\\sum_{ij}(A_{ij} - \\cfrac{d_id_j}{2m})s_is_j,\n\\end{equation}",
            "eq:7": "\\begin{equation}\n\\begin{aligned}\n    \\hspace{25pt} P_{l + 1} = P_l(\\widetilde{D}^{-1}\\widetilde{A}),\\hspace{25pt} l \\in \\{1, 2, ..., t\\}\n\\end{aligned}\n\\end{equation}",
            "eq:8": "\\begin{equation}\n\\begin{aligned}\n    \\hspace{25pt} R = \\frac{\\widetilde{D}}{\\text{vol}(\\widetilde{G})}P_t - \\frac{\\Tilde{d}\\Tilde{d}^T}{\\text{vol}^2(\\widetilde{G})}\n\\end{aligned}\n\\end{equation}",
            "eq:9": "\\begin{equation}\n    L(\\theta) = -\\sum_{(u, v) \\in E} \\log \\frac{\\exp(R_{uv})}{\\exp(R_{uv}) + \\sum_{(p, q) \\in N(u,v)} \\exp(R_{pq})}\n\\end{equation}",
            "eq:10": "\\begin{align*}\n    TP &= 0\\\\\n    FN &= 0\\\\\n    FP &= (n-1)p+(nk-n)q\\\\\n    TN &= (n-1)(1-p)+(nk-n)(1-q)\n\\end{align*}",
            "eq:11": "\\begin{align*}\n    TP &= (n-1)p\\\\\n    FN &= (nk-n)q\\\\\n    FP &= (n-1)p\\\\\n    TN &= (nk-n)(1-q)\n\\end{align*}",
            "eq:12": "\\begin{equation*}\n    \\frac{(n-1)(1-p)+(nk-n)(1-q)}{nk-1}-\\frac{(n-1)p+(nk-n)(1-q)}{nk-1}\n\\end{equation*}",
            "eq:13": "\\begin{align*}\n    a_1 &= \\frac{(n-1)p}{(n-1)p+(nk-n)q}\\\\\n    a_2 &= \\frac{(nk-n)(1-q)}{(nk-n)(1-q)+(n-1)(1-p)}\n\\end{align*}",
            "eq:14": "\\begin{align}\nR_{ij}\n&=\\cfrac{1}{2m}(a_{ij} - \\cfrac{d_id_j}{2m}).\n\\end{align}",
            "eq:15": "\\begin{align}\n    \\mathbb{E}[R_{intra}]&=\\cfrac{1}{2m}((1-\\cfrac{d_id_j}{2m})p + (0-\\cfrac{d_id_j}{2m})(1-p))\n    \\\\\n    &=\\cfrac{1}{2m}(p-\\cfrac{d_id_j}{2m}).\n\\end{align}",
            "eq:16": "\\begin{align}\n    \\mathbb{E}[R_{inter}]&=\\cfrac{1}{2m}((1-\\cfrac{d_id_j}{2m})(1-p) + (0-\\cfrac{d_id_j}{2m})p)\n    \\\\\n    &=\\cfrac{1}{2m}(1-p-\\cfrac{d_id_j}{2m})\n    \\\\\n    &=\\cfrac{1}{2m}(q-\\cfrac{d_id_j}{2m}).\n\\end{align}",
            "eq:17": "\\begin{align}\n    \\cfrac{|E_{ik+1}^+|}{|V_{ik+1}|^2}&\\geq\\cfrac{|E_{ik}^+| - (|V_{ik}|^2 - |V_{ik+1}|^2)}{|V_{ik+1}|^2}\n    \\\\\n    |V_{ik}|^2 - |V_{ik+1}|^2 &\\geq |E_{ik}^+| - |E_{ik+1}^+|\n\\end{align}"
        },
        "git_link": "https://github.com/pyg-team/pytorch_geometric/"
    }
}