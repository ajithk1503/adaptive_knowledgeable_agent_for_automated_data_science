{
    "meta_info": {
        "title": "Task-Adaptive Few-shot Node Classification",
        "abstract": "Node classification is of great importance among various graph mining tasks.\nIn practice, real-world graphs generally follow the long-tail distribution,\nwhere a large number of classes only consist of limited labeled nodes. Although\nGraph Neural Networks (GNNs) have achieved significant improvements in node\nclassification, their performance decreases substantially in such a few-shot\nscenario. The main reason can be attributed to the vast generalization gap\nbetween meta-training and meta-test due to the task variance caused by\ndifferent node/class distributions in meta-tasks (i.e., node-level and\nclass-level variance). Therefore, to effectively alleviate the impact of task\nvariance, we propose a task-adaptive node classification framework under the\nfew-shot learning setting. Specifically, we first accumulate meta-knowledge\nacross classes with abundant labeled nodes. Then we transfer such knowledge to\nthe classes with limited labeled nodes via our proposed task-adaptive modules.\nIn particular, to accommodate the different node/class distributions among\nmeta-tasks, we propose three essential modules to perform \\emph{node-level},\n\\emph{class-level}, and \\emph{task-level} adaptations in each meta-task,\nrespectively. In this way, our framework can conduct adaptations to different\nmeta-tasks and thus advance the model generalization performance on meta-test\ntasks. Extensive experiments on four prevalent node classification datasets\ndemonstrate the superiority of our framework over the state-of-the-art\nbaselines. Our code is provided at https://github.com/SongW-SW/TENT.",
        "author": "Song Wang, Kaize Ding, Chuxu Zhang, Chen Chen, Jundong Li",
        "link": "http://arxiv.org/abs/2206.11972v1",
        "category": [
            "cs.LG"
        ]
    },
    "latex_extraction": {
        "content": {
            "section 1": {
                "name": "INTRODUCTION",
                "content": "\n\tRecently, extensive research efforts have been devoted to the node classification task, which aims at predicting class labels for unlabeled nodes in a graph. In real-world scenarios, the task of node classification yields an expansive variety of practical applications~\\cite{mcauley2012learning,tang2008arnetminer}. For example, predicting chemical properties for proteins in a protein network is an important problem in bioinformatics~\\cite{szklarczyk2019string}, which can be formulated as the node classification problem.\n\t%in real-world scenarios, graphs can effectively model interactions and connections among real-world entities,\n\t%attributed networks (i.e., attributed graphs) have attracted increasing attention due to their compelling ability in modeling interactions and connections among real-world entities, such as authors in citation networks~\\cite{ding2020inductive} and users in social media networks~\\cite{qi2011exploring,ding2019interactive}. Among tasks that aim at excavating the information in these graphs, node classification, i.e., predicting labels for nodes, plays a crucial role that yields an expansive variety of practical applications~\\cite{mcauley2012learning,tang2008arnetminer}.\n\t%researchers have conducted multiple types of analytical tasks, including node classification, link prediction, and graph classification. Among these tasks, node classification plays a crucial role that yields an expansive variety of practical applications. For example, ...   \n\t%Prevalent \n\tIn recent years, the state-of-the-art approaches for node classification often utilize Graph Neural Networks (GNNs)~\\cite{wu2020comprehensive,velivckovic2017graph,xu2018powerful} in a semi-supervised manner~\\cite{kipf2017semi}. Specifically, for each node, GNNs aim to learn a vector representation for each node by transforming and aggregating information from its neighbors. The learned representations will be further utilized for the classification task in an end-to-end manner. \n\t%are encoded and contribute to the state-of-the-art performance in node classification.\n\tNevertheless, these approaches typically require sufficient labeled nodes for all classes in achieving a decent classification performance~\\cite{zhou2019meta}. \n\tIn practice, although we can access a large number of labeled nodes for certain classes, many other classes may only contain a limited number of labeled nodes. Here we refer to the former classes as \\emph{base classes} and the latter as \\emph{novel classes}.\n% \tOn the one hand, in many real-world applications, there are only a limited number of labeled nodes for certain classes, generally referred to as \\emph{novel classes}~\\cite{ding2020graph,wang21AMM}. \n% \tOn the other hand, we may also have access to a large number of labeled node for a large number of nodes can be labeled at considerable labor cost for specific classes, known as \\emph{base classes}. \n\t%For example, in a citation network, emerging paper topics with limited papers such as \"Explainable AI\" can be considered as novel classes, while canonical topics with abundant papers such as \"Image Classification\" are generally base classes. \n\tFor example, in a protein network~\\cite{hu2020open}, newly discovered chemical properties with limited protein nodes are considered as novel classes, while common properties with abundant protein nodes are considered as base classes.\n\tDue to the widespread existence of novel classes in real-world graphs,\n\t%%%%%%%%%%\\kz{Due to the long-tail property of real-world graphs}, \n\tmany recent studies~\\cite{ding2020graph,wang21AMM,liu2021relative} focus on the problem of classifying nodes in novel classes, known as the \\emph{few-shot node classification} problem.\n\t\n\t\n\t%Therefore, how to utilize information from nodes in base classes and classify nodes in novel classes with limited labeled nodes has become a critical problem, known as \\emph{few-shot node classification}.\n\t\n\t\t\t\t\n\n\t\n\t\n\tTo tackle the few-shot node classification problem, recent works typically\n\t%\\kz{strive to} \n\tstrive to extract transferable knowledge from base classes\n\t%with plentiful labeled samples \n\tand then generalize such knowledge to novel classes~\\cite{zhou2019meta,yao2020graph,ding2020inductive}.\n%\tMore recently, many research efforts have been devoted to few-shot learning (FSL) to solve classification tasks with scarce labeled samples for each class~\\cite{snell2017prototypical,vinyals2016matching,finn2017model}. To conduct classification on novel classes, FSL extracts transferable knowledge from base classes with plentiful labeled samples and then generalizes the learned knowledge to novel classes. \n\tMore specifically, these works learn from base classes across a series of \\emph{meta-training} tasks and evaluate the model on \\emph{meta-test} tasks sampled from novel classes (we refer to both meta-training and meta-test tasks as meta-tasks). In fact, each meta-task \n\t%%%%%during meta-training and meta-test (i.e., meta-task) \n\tcontains a small number of \\emph{support nodes} as references and several \\emph{query nodes} to be classified. \n\t%According to the sampling process, these tasks could be further split into two categories:\n\t%\\emph{meta-training} tasks and \\emph{meta-test} tasks, which are sampled from nodes in base classes and novel classes, respectively. Then the final evaluation of the model is conducted across a certain number of meta-test tasks\\kz{you can make it more concise, right now it is too detailed}.\n\tSince support nodes and query nodes in each meta-task are sampled from nodes on the entire graph,\n\t%%%%%%%%%%%\\kz{be careful about this argument since we cannot say meta-test is supposed to be randomly-sampled, even though we are doing this for evaluation.}\n\tthere could exist large variance among different meta-tasks (i.e., task variance)~\\cite{huang2020graph}. Therefore, the crucial part of few-shot node classification is to ensure that the underlying model has the generalization capability to handle a variety of meta-tasks in the presence of massive task variance~\\cite{lichtenstein2020tafssl,suo2020tadanet}. However, despite much progress has been made in few-shot node classification, recent studies ignore the task variance and treat each meta-task identically~\\cite{ding2020graph,wang21AMM,liu2021relative}. As a result, the task variance significantly jeopardizes the model generalization capability to meta-test tasks even when the performance on meta-training tasks is satisfactory~\\cite{oreshkin2018tadam}.\n\t\n\t\n\t%%%%Despite much progress has been made in few-shot node classification, a vast majority of existing approaches treat each meta-task identically. \n\t%%%%However, there could exist large variances among different meta-tasks (i.e., task variance), which significantly jeopardizes the model generalization to meta-test tasks~\\cite{oreshkin2018tadam}. \n\t%%%%Specifically, since each meta-task only contains a small number of randomly sampled nodes, the support nodes in different meta-tasks could be rather different. Nevertheless, the classification within each meta-task is based on its support nodes~\\cite{finn2017model,snell2017prototypical}. Therefore, without suitable approaches to handle task variance, the model will encounter a severe performance drop on meta-test tasks~\\cite{lichtenstein2020tafssl,suo2020tadanet}.\n\t\n\t\n\t\n\t%%%However, the node/class distributions may vary dramatically across different meta-tasks, since each meta-task only contains a small number of sampled nodes and classes. Specifically, meta-tasks consist of various classes randomly sampled from all classes, and nodes in the same class can be diversely dispersed across the entire graph~\\cite{ding2020graph}. \n\t%In other words, the node and class distributions vary greatly in meta-tasks since each meta-task only consists of limited nodes for several classes.\n\t%, the model is required to tackle a variety of meta-test tasks during evaluation.\n\t\n\t%%%As a result, the variance of node/class distributions lead to the variances among different meta-tasks (i.e., task variance), which jeopardizes the model generalization to meta-test tasks~\\cite{oreshkin2018tadam}. Hence, without suitable adaptations to handle task variance, the model will encounter a significant performance drop on meta-test tasks~\\cite{lichtenstein2020tafssl,suo2020tadanet}.\n\t\n\t%a tremendous generalization gap on the meta-test tasks caused by task variance.\n\t%On the other hand, several recent works for few-shot image classification have explored task-adaptive approaches considering task variance~\\cite{oreshkin2018tadam,suo2020tadanet,lichtenstein2020tafssl}. \n\t\n\t%Since FSL requires conducting classification tasks on unseen novel classes during training, the test process may encounter a tremendous generalization gap caused by task variance. ~\\cite{oreshkin2018tadam}. An accessible approach could be exploring task-adaptive models to handle various tasks~\\cite{lichtenstein2020tafssl,suo2020tadanet}. However, the task adaptations remain undiscovered for few-shot node classification.\n\n\t\n\t%%Nevertheless, real-world graphs consist of complex graph structures and an enormous number of node classes~\\cite{zhou2019meta,ding2020graph}.\n\t%\\kz{same issue, what is the ``variety'' and ``variance''}\n\t%%Hence, it remains non-trivial to reduce the adverse influence of task variance in few-shot node classification considering the unique characteristics of graph data. The essential challenges can be concluded at three levels as illustrated in Fig.~\\ref{fig:intro}.\n\t%we construct connectivity both explicitly and implicitly\n\tDespite the importance of considering task variance, reducing its adverse impact remains non-trivial. In essence, there are two main factors that constitute such task variance. \n\t%%%%%First, \\emph{Node-level Variance} widely exists among meta-tasks that have shared classes, which leads to task variance. Unlike i.i.d. data (e.g., images), node-level variance lies in both node features and graph structure. For example, the red class nodes $A$ and $B$ in Fig.~\\ref{fig:intro}\n\tFirst, the \\emph{Node-level Variance} widely exists among meta-tasks and can lead to task variance. Specifically, node-level variance \n\t%%%%%represents the difference within features and the graph structure of nodes among different meta-tasks.\n\trepresents the differences of node features and local structures of nodes across different meta-tasks.\n\t%Unlike i.i.d. data (e.g., images), node-level variance lies in both node features and graph structure. \n\tFor example, in addition to the common difference in node features, the red class nodes $A$ and $B$ in Fig.~\\ref{fig:intro} also have different connectivity patterns in terms of neighboring nodes (node $A$ is surrounded by blue nodes, while node $B$ is only connected to red nodes). It should be noted that few-shot node classification models generally learn crucial information from the support nodes within each meta-task to perform classification on the query nodes. Therefore, if the variance among the support nodes is too large, it will become difficult to extract decisive information for classification. In other words, it is vital to consider node-level variance for the purpose of handling task variance.\n    Second, \\emph{Class-level Variance} may also cause task variance. Class-level variance denotes the difference in class distributions among meta-tasks. \n    %Specifically, in few-shot node classification, the model conducts classification from a particular class set in each meta-task. \n    In practice, since many real-world graphs contain a large number of node classes, the distribution of classes in each meta-task varies greatly~\\cite{zhou2019meta,wang21AMM}. For example, in Fig.~\\ref{fig:intro}, different meta-tasks consist of a variety of classes (e.g., red and blue classes in $\\mathcal{T}_1$ and dotted blue and green classes in $\\mathcal{T}'_1$). Since the model evaluation is conducted on a vast number of meta-test tasks, the model will encounter many distinct classes during meta-test. That being said, in the presence of massive class-level variance, the resulting task variance will substantially deteriorate the generalization performance on meta-test tasks.\n\t\n\t%%%%Therefore, since novel classes are unseen during training, the model requires more class-specific information to enable better adaptation to these classes. However, due to the large size of novel classes in real-world graphs~\\cite{liu2021relative,hu2020open}, it remains challenging to perform adaptations with respect to different classes. \n\t%The essential challenges can be concluded at three levels \n\t%%%%Second, in addition to the \\emph{Class-level Variance}, \\emph{Node-level Variance} may also exist among meta-tasks that have shared classes, which leads to task variance. %Graph data is unique in a way that the widely accepted i.i.d. assumption becomes invalid among different nodes. \n    %%%%Specifically, unlike other i.i.d. instances (e.g., images), the variance of nodes in the same class lies not only in their features but also their structures. For example, the red class node A and B in Fig.~\\ref{fig:intro} have different connectivity patterns in terms of neighboring nodes. The neighboring nodes of A are mainly blue nodes while B only consists of red neighboring nodes.\n    %Moreover, since meta-tasks are randomly sampled, nodes in the same class can be dispersed diversely across the entire graph or even unconnected~\\cite{ding2020graph}.\n    % in each meta-tasks, the support nodes determine how the \n    % Nevertheless, in each meta-task, the classification regarding a class is dependent on the several labeled nodes. Therefore, the huge node variance can deteriorate the performance since it becomes more difficult to extract decisive information for classification.\n    %%%%However, it remains challenging to mitigate node-level variance due to the vast number of nodes in each class on real-world graphs~\\cite{ding2020graph,huang2020graph}.\n    %%%As a result, the node-level variance can deteriorate the classification performance regarding a specific class. \n    %%%Thus, to reduce the impact of node-level variance, a node-level adaptation is necessary to extract decisive classification information among randomly sampled nodes.\n\t%When learning prototypes (i.e., the centroid of labeled nodes in a class) in each task, the interactions between support nodes (i.e., the set of labeled nodes in a tack) can provide significant information for classification and thus cannot be neglected~\\cite{ding2020graph}. However, existing methods generally ignore such interactions and identically learn class representations. Nevertheless, since support nodes are randomly sampled from the corresponding classes, they could be far away or even disconnected from each other across the graph. Therefore, how to capture such long-distance interactions in each task and perform adaptations to them remains a difficult but also crucial problem.\n\n\t%the model necessitates a fast adaptation to the classes in each meta-test task for better classification performance\n\t%\\kz{the model requires more class-specific information to enable better adaptation to the unseen classes}.\n\n\t%%%(iii) \\emph{Task-level Variance}. Generally, few-shot node classification methods embed all nodes in each meta-task and classify query nodes based on embeddings of support nodes~\\cite{zhou2019meta,wang21AMM,ding2020inductive}. However, in different meta-tasks, the node embedding distributions may vary greatly. For example, node embeddings of a specific class can be centered around a centroid; in contrast, node embeddings of other classes may be distributed more widely (i.e., larger distances to a centroid). \n\t%\\kz{this argument is a bit weak and too detailed. You may think about -- graph few-shot learning is actually performed in a transductive manner, right now existing efforts didn't explicitly consider the test data, so you want to leverage the knowledge of test data to enable better knowledge transfer. You can refer to the paper ``transductive propagation network for few-shot learning''}.\n\t %%%Nevertheless, such variance may detriment the model performance on meta-tasks with a node distribution largely different from other meta-tasks. After all, current studies typically ignore such variance and treat each meta-task identically.Therefore, the classification process in each meta-task should be task-adaptive to handle various distributions of node embeddings.\n %Therefore, to ensure the classification process is suitable for the specific node embedding distribution in each task, the model necessitates task-level adaptations.\n\t%Several FSL methods~\\cite{ding2020graph,snell2017prototypical,ding2020inductive} propose to learn a prototype (i.e., class representation) for each class and classify query samples based on distances to these prototypes.\n\t%\\kz{Not a valid argument, this is only for metric learning based methods, not for MAML like methods}. %Hence, the adaptation to the entire support set\n\t%\\textcolor{red}{Nevertheless, the distribution of support node representations may be dispersed expansively. For example, representations of nodes in a certain class can be centered around the prototype (i.e., smaller distances). In contrast, representations of nodes in other classes may be distributed more widely (i.e., larger distances to the prototype). Hence, using identical distance measurements for all classes while ignoring the distribution of node representations can render deficiency in classification~\\cite{li2020prototypical}.Therefore, the classification process should incorporate the distribution of node representations in the entire support set for task-level adaptation.}\n\t%\\kz{what do you mean by adaptation to the support set? In general, few-shot learning methods have this kind of adaptation, you need to make this argument clear and sharp.} \n\t%in each task can reduce unnecessary information for classification and thus improve the performance. \n\t%%%However, the support set in each meta-task only contains a limited number of nodes, which causes difficulties in capturing distribution patterns of different meta-tasks.\n\t%\\kz{As you want to compute the MI between labeled and unlabeled instances, should you talk about this challenge from how to leverage unlabeled data?}.\n\n\tTo alleviate the adverse impact of task variance resulting from the above two factors (i.e., node-level and class-level variance), we propose a novel \\textbf{\\underline{T}}ask-adaptiv\\textbf{\\underline{E}} few-shot \\textbf{\\underline{N}}ode classifica\\textbf{\\underline{T}}ion framework, named as \\textsc{TENT}. Specifically, we aim to alleviate task variance via performing task adaptations from three perspectives.\n\t%learning transferable knowledge from base classes and then generalizing it to novel classes in a task-adaptive manner. Essentially, to\n\t%address the three challenges of exploiting task-adaptive approaches \n\tFirst, to handle node-level variance, we perform node-level adaptations via constructing a class-ego subgraph for each class in each meta-task. Specifically, such a subgraph explicitly connects nodes in the same class and their neighbors with a virtual class node. \n\t%In this way, the representation learning process for classes will be adapted regarding the nodes in this class. \n\t%%%%%In this way, we can adaptively learn prototypes (i.e., the centroid of nodes in a class) in each meta-task while considering the node-level variance in each class.\n\tIn this way, the neighbors of nodes in the same class are aggregated in this subgraph to reduce the influence of node-level variance.\n\tSecond, to deal with class-level variance, we design a class-specific GNN to leverage information from different classes and perform class-level adaptations. Third, \n\t%%%%%to simultaneously consider both node-level and class-level variance\n\tto reduce the adverse impact of task variance during classification on query nodes, we propose to perform task-level adaptations via maximally preserving the mutual information between query nodes and support nodes in each meta-task. As a result, our proposed framework can conduct classification in a task-adaptive manner to alleviate the adverse impact of task variance. In summary, our main contributions are three-folds:\n\t\\vspace{-0.0in}\n\t\\begin{itemize}\n\t\\setlength{\\itemsep}{0.06in}\n\t    \\item \\textbf{Problem.} We investigate the limitations of existing few-shot node classification methods from the lens of task variance and discuss the importance and necessity of task adaptations for few-shot node classification.\n\t    \\item \\textbf{Method.} We develop a novel task-adaptive few-shot node classification framework with three essential modules: (1) \\emph{node-level adaptation} to mitigate node-level variance; (2) \\emph{class-level adaptation} to alleviate the problem of class-level variance; and\n\t    (3) \\emph{task-level} adaptation to consider task variance during classification on query nodes.\n\t    %\\item We develop a novel few-shot node classification framework with three essential modules: (1) A class-ego constructor which generates class-ego subgraphs to perform node-level adaptations; (2) A class-specific GNN adapter to incorporate information from classes in each task for class-level adaptations; (3) A task-specific classifier regarding the overall distribution of support nodes for task-level adaptations.\n\t    \\item \\textbf{Experiments.} We conduct experiments on four benchmark node classification datasets under the few-shot setting and demonstrate the superiority of our proposed framework.\n\t\\end{itemize}\n\t\n\t\n\t\n\t\t\n\t\t\n\t\n\t\n\t\n\t"
            },
            "section 2": {
                "name": "Preliminaries",
                "content": "\n\t%In this section, we introduce the problem setting of few-shot node classification. \n\t%We further leverage the $N$-way $K$-shot episodic learning strategy for optimization, which has demonstrated promising performance in few-shot learning~\\cite{snell2017prototypical,ding2020graph,finn2017model}.\n\t\n\t",
                "subsection 2.1": {
                    "name": "Problem Statement",
                    "content": "\n\tFormally, let $G=(\\mathcal{V},\\mathcal{E},\\X)$ denote an attributed graph, where $\\mathcal{V}$ is the set of nodes, $\\mathcal{E}$ is the set of edges, and $\\X\\in\\mathbb{R}^{|\\mathcal{V}|\\times d}$ is the feature matrix of nodes with $d$ denoting the feature dimension. Moreover, we denote the entire set of node classes as $\\mathcal{C}$, which can be further divided into two categories: $\\mathcal{C}_b$ and $\\mathcal{C}_n$, where $\\mathcal{C}=\\mathcal{C}_b\\cup\\mathcal{C}_n$ and $\\mathcal{C}_b\\cap\\mathcal{C}_n=\\emptyset$. Here $\\mathcal{C}_b$ and $\\mathcal{C}_n$ denote the sets of base and novel classes, respectively. It is worth mentioning that the number of labeled nodes in $\\mathcal{C}_b$ is sufficient, while it is typically small in $\\mathcal{C}_n$~\\cite{zhou2019meta,ding2020graph,liu2021relative}. Then we can formulate the studied problem of few-shot node classification as follows:\n\t\n\t\\begin{definition}\n\t\\textbf{Few-shot Node Classification:} Given an attributed graph $G=(\\mathcal{V},\\mathcal{E},\\X)$, our goal is to develop a machine learning model such that after training on labeled nodes in $\\mathcal{C}_b$, the model can accurately predict labels for the nodes (i.e., query set $\\mathcal{Q}$) in $\\mathcal{C}_n$ with only a limited number of labeled nodes (i.e., support set $\\mathcal{S}$).\n\t\\end{definition}\n\t\n\tMore specifically, if the support set $\\mathcal{S}$ contains exactly $K$ nodes for each of $N$ classes from $\\mathcal{C}_n$, and the query set $\\mathcal{Q}$ are sampled from these $N$ classes, the problem is called $N$-way $K$-shot node classification. Essentially, the objective of few-shot node classification is to learn a classifier that can be fast adapted to $\\mathcal{C}_n$ with only limited labeled nodes. Thus, the crucial part is to learn transferable knowledge from $\\mathcal{C}_b$ and generalize it to $\\mathcal{C}_n$.\n\t\n\t"
                },
                "subsection 2.2": {
                    "name": "Episodic Learning",
                    "content": "\nIn practice, we adopt the episodic learning framework for both meta-training and meta-test, which has proven to be effective in many areas~\\cite{snell2017prototypical,finn2017model,vinyals2016matching,xiong2018one,ding2020graph}. Specifically, the meta-training and meta-test processes are conducted on a certain number of \\emph{meta-training tasks} and \\emph{meta-test tasks}, respectively. These meta-tasks share a similar structure, except that meta-training tasks are sampled from $\\mathcal{C}_b$, while meta-test tasks are sampled from $\\mathcal{C}_n$. The main idea of few-shot node classification is to keep the consistency between meta-training and meta-test to improve the generalization performance. \n\t \n\tTo construct a meta-training (or meta-test) task $\\mathcal{T}_t$, we first randomly sample $N$ classes from $\\mathcal{C}_b$ (or $\\mathcal{C}_n$). Then we randomly sample $K$ nodes from each of the $N$ classes (i.e., $N$-way $K$-shot) to establish the support set $\\mathcal{S}_t$. Similarly, the query set $\\mathcal{Q}_t$ consists of $Q$ different nodes (distinct from $\\mathcal{S}_t$) from the same $N$ classes. The components of the sampled meta-task $\\mathcal{T}_t$ can be denoted as follows: \n\t\\begin{equation}\n\t    \\begin{aligned}\n\t    \\mathcal{S}_t&=\\{(v_1,y_1),(v_2,y_2),\\dotsc,(v_{N\\times K},y_{N\\times K})\\},\\\\\n\t    \\mathcal{Q}_t&=\\{(q_1,y'_1),(q_2,y'_2),\\dotsc,(q_{Q},y'_{Q})\\},\\\\\n\t    \\mathcal{T}_t&=\\{\\mathcal{S}_t,\\mathcal{Q}_t\\},\n\t    \\end{aligned}\n\t\\end{equation}\n\twhere $v_i$ (or $q_i)$ is a node in $\\mathcal{V}$, and $y_i$ (or $y'_i$) is the corresponding label. In this way, the whole training process is conducted on a set of $T$ meta-training tasks $\\mathcal{T}_{train}=\\{\\mathcal{T}_t\\}_{t=1}^T$. After training, the model has learned the transferable knowledge from $\\mathcal{T}_{train}$ and will generalize it to meta-test tasks $\\mathcal{T}_{test}=\\{\\mathcal{T}'_t\\}_{t=1}^{T_{test}}$ sampled from $\\mathcal{C}_n$.\n\t\n\n\t\n\n"
                }
            },
            "section 3": {
                "name": "Our Proposed Framework",
                "content": "\n\t\nIn this section, we introduce the overall structure of our proposed\nframework \\textsc{TENT} in detail. As illustrated in Fig.~\\ref{fig:model}, we formulate the \\emph{few-shot node classification} problem under the prevailing $N$-way $K$-shot learning framework, which means a meta-task contains $K$ nodes for each of $N$ classes as the support set. In addition, the query set consists of $Q$ unlabeled nodes to be classified from these $N$ classes. Specifically, our framework follows the prevalent three phases for few-shot learning: embedding learning, prototype learning, and query matching. Generally, in each meta-task, we learn embeddings for its nodes and then learn a prototype (i.e., embedding of a class in the support set) based on the node embeddings. Finally, the model matches query nodes with these prototypes via specific matching functions to output classification results. Nevertheless, these three steps ignore the task variance that widely exists among meta-tasks. Therefore, as illustrated in Fig.~\\ref{fig:model}, we propose to perform three levels of adaptations (node-level, class-level, and task-level adaptations) in these three phases, respectively, to alleviate the adverse impact of task variance.\n\n\n%%%%%For each meta-task, our framework first construct a class-ego subgraph for each class in this meta-task to perform node-level adaptations. Then our framework employs a class-specific adapter to learn representations for classes and query nodes with class-level adaptations. Finally, the task-level adaptation is conducted to simultaneously consider node-level and class-level variance. In this way, our framework can further learn the capability of performing fast adaptations to each meta-task to reduce the adverse impact of task variance. Next, we will elaborate on these three crucial modules that perform different levels of adaptations.\n\t    \\vspace{-0.1in}\n\t",
                "subsection 3.1": {
                    "name": "Node-level Adaptation",
                    "content": "\n%%%%%%%%Since the node-level variance widely exists among different meta-tasks, we propose to perform node-level adaptations for each meta-task to alleviate the influence of node-level variance. \nDuring the embedding learning phase, existing methods learn embeddings for nodes in each meta-task from the entire graph~\\cite{zhou2019meta,ding2020graph,wang21AMM}. Since nodes are distributed across the entire graph, the learned node representations can be easily influenced by node-level variance (i.e., have different connectivity patterns in terms of neighboring nodes). Instead, we perform node-level adaptations in each meta-task, which aims to modify the neighbors of support nodes to reduce node-level variance caused by different connectivity patterns. Toward this goal, we explicitly construct a subgraph for each class in each meta-task via a virtual class node, which connects to the $K$ support nodes in that class. In addition, we also include the one-hop neighbors of these $K$ nodes in this subgraph. \n%%%%%%%%In this way, the subgraph also captures important structural information for each node that could be beneficial for classification.\nBy doing the above, we can aggregate local structures of support nodes in the same class into this subgraph, which contains the virtual class node, $K$ support nodes, and one-hop neighbors of these $K$ nodes. Here the virtual class node acts as a bridge to explicitly connect these $K$ support nodes and their one-hop neighbors that can be originally far from each other on the graph. Moreover, its embedding will be used as the prototype of this class since it is the centroid node of the subgraph. As a result, in this subgraph, \n%%%%%%%%%%the neighbors of these $K$ nodes are also support nodes and their neighbors.  \nsupport nodes will share a similar neighbor node set because the neighboring nodes of support nodes are explicitly connected.\nSince the neighbors of support nodes become more similar in this subgraph, we can effectively reduce the node-level variance. %%%%%%%%% caused by different connectivity patterns.\n%%%%%%%%As a result, the node-level variance caused by differences in neighbors will be reduced. The reason is that the virtual class node acts as a bridge to explicitly connect these $K$ support that may be originally far from each other on the graph, \n%%%%%%%%nodes neighbors of each support node are limited to several relevant nodes (i.e., other support nodes in the same class and their neighbors) while still maintaining helpful local structures.\n\t%%%%%each support node can easily absorb information from other support nodes and their neighbors during embedding learning. \n\t%%%%%%In this way, the adverse impact of node-level variance can be reduced, since the neighbors of these nodes are connected via the virtual node. In other words, the neighbors of these $K$ nodes are aggregated as a new subgraph, which reduces the significant difference among neighbors of nodes in the class. \n\t%%%%%%%%In addition, the subgraphs can also explicitly and effectively utilize the interactions among nodes of this class. \n\t We denote the constructed subgraphs in each meta-task as \\emph{class-ego subgraphs}.\n\t%%%%%we propose to construct a class-ego subgraph for each class in each meta-task. In order to learn class representations with node-level adaptations, we propose to utilize the interactions between nodes in the same class. Therefore, we explicitly construct the interactions via a virtual class node, which connects to all nodes in the class. In this way, the nodes in the same classes could interact with each other to propagate useful information for the classification of this class.\n\t%%%%%Moreover, the class-ego subgraph also includes the one-hop neighbors of each node, which means the subgraph maintains the graph structures that encode beneficial information. In consequence, the class-ego subgraphs can explicitly and effectively establish and utilize the interactions between nodes of this class.\n\t\n\tSpecifically, given a meta-task $\\mathcal{T}$ and its support set $\\mathcal{S}$ ($|\\mathcal{S}|=N\\times K$) on a graph $G=(\\mathcal{V},\\mathcal{E},\\X)$, we aim to construct a class-ego subgraph for each of the $N$ classes in $\\mathcal{T}$. Before the construction of class-ego subgraphs, we employ a GNN~\\cite{wu2020comprehensive,kipf2017semi} parameterized by $\\phi$ to perform message propagation on the entire graph $G$ and generate first-step node representations for nodes in $\\mathcal{V}$ as follows:\n\t\\begin{equation}\n\t    \\mathbf{H}=\\text{GNN}_\\phi(\\mathcal{V},\\mathcal{E},\\X),\n\t    \\label{eq:first-step emb}\n\t\\end{equation}\n\twhere $\\mathbf{H}\\in\\mathbb{R}^{|\\mathcal{V}|\\times d_h}$ denotes the first-step representations of nodes in $\\mathcal{V}$ and $d_h$ is the output dimension of $\\text{GNN}_\\phi$. In this way, $\\mathbf{H}$ will act as the input node representations for the class-ego subgraphs. \n\t\n\tLet $\\mathcal{S}_i$ denote the set of nodes belonging to the $i$-th class in $\\mathcal{S}$, which means $|\\mathcal{S}_i|=K$, $i=1,2,\\dotsc,N$. To construct the class-ego subgraph from these nodes, we first create a virtual class node $c_i$ and connect it to all nodes in $\\mathcal{S}_i$. Then to incorporate the local graph structures, we also extract all one-hop neighbors of nodes in $\\mathcal{S}_i$ to establish a neighbor node set $\\mathcal{N}_i=\\bigcup_{j=1}^K\\mathcal{N}_i^j$, where $\\mathcal{N}_i^j$ denotes the set of neighbors of the $j$-th node in $\\mathcal{S}_i$. In this way, the final node set of the class-ego subgraph is aggregated as $\\mathcal{V}_i=\\{c_i\\}\\cup\\mathcal{S}_i\\cup\\mathcal{N}_i$. After that, we accordingly denote the extracted edge set of nodes in $\\mathcal{V}_i$ as $\\mathcal{E}_i$. To obtain the input node features for $\\mathcal{V}_i$, we utilize the corresponding first-step representations from $\\mathbf{H}$. However, we still need to compute the representation of $c_i$ since it is newly created. Here we propose to initiate its representation $\\mathbf{h}_{c_i}$ as follows:\n\t\\begin{equation}\n\t    \\mathbf{h}_{c_i}=\\text{MEAN}(\\mathbf{h}_v|v\\in\\mathcal{S}_i),\n\t\\end{equation}\n\twhere $\\mathbf{h}_{c_i}\\in\\mathbb{R}^{d_h}$ and $\\mathbf{h}_v$ is the first-step node representation of node $v$. $\\text{MEAN}$ denotes the averaging operation.\n\tIn this way, the input node features for $\\mathcal{V}_i$ can be obtained as $\\mathbf{X}_i$. Then the class-ego subgraph can be constructed and denoted as $G_i=(\\mathcal{V}_i,\\mathcal{E}_i,\\X_i)$. \n\t%%%%%%%%%As a result, we can learn representations of the $N$ classes from these class-ego subgraphs via node-level adaptations.\n\tAs a result, we can achieve node-level adaptations by learning node representations on the subgraphs with reduced node-level variance.\n\t\n\t"
                },
                "subsection 3.2": {
                    "name": "Class-level Adaptation",
                    "content": "\n\tTypically, after learning the node representations in $\\mathcal{T}$, existing models learn prototypes for classes in $\\mathcal{T}$ by aggregating node representations in the same class~\\cite{ding2020graph,snell2017prototypical}. However, this strategy can be easily influenced by class-level variance and thus renders suboptimal generalization performance since it treats each class identically.\n\t%%%%%To achieve an overall representation for each class-ego subgraph, we utilize another GNN parameterized by $\\theta$ to perform message propagation on it and generate a graph representation.\n\t%%%%%Nevertheless, directly applying GNN can be easily influenced by class-level variance, since it performs message propagation on each class-ego subgraph identically. \n\tInstead, we propose to perform class-level adaptations, which aim to obtain prototypes for classes in a class-adaptive manner. In particular, we design a class-specific adapter to adjust GNN parameters regarding different classes in $\\mathcal{T}$. In this way, our framework can leverage the %%%%%%class information within each class\n\tdiscriminative information in each class for class-level adaptations and reduce the adverse impact of class-level variance.\n\t%and a class contrastive loss to incorporate information from various classes in the support set-level and the task-level, respectively. \n\t\n\tSpecifically, we use a new $\\text{GNN}_\\theta$ parameterized by $\\theta$ on the class-ego subgraphs to learn prototypes.\n\t%%%%%%%%%class-ego subgraph as $\\text{GNN}_\\theta$ parameterized by $\\theta$, \n\tThen we adapt $\\theta$ according to the first-step representations of nodes in each class (i.e., $\\left\\{\\mathbf{h}_v|v\\in\\mathcal{S}_i\\right\\}, i=1,2,\\dotsc,N$) in meta-task $\\mathcal{T}$. To comprehensively incorporate the information in each class, we leverage the feature-wise linear modulations~\\cite{perez2018film,wen2021meta} to perform class-level adaptations:\n\t\\begin{equation}\n\\alpha_i=\\text{MLP}_\\alpha \\left(\\text{MEAN}\\left(\\left\\{\\mathbf{h}_v|v\\in\\mathcal{S}_i\\right\\}\\right)\\right),\n\t\\end{equation}\n\t\\begin{equation}\n\\beta_i=\\text{MLP}_\\beta \\left(\\text{MEAN}\\left(\\left\\{\\mathbf{h}_v|v\\in\\mathcal{S}_i\\right\\}\\right)\\right),\n\\end{equation}\n\twhere $\\mathcal{S}_i$ is the set of nodes belonging to the $i$-th class in $\\mathcal{S}$. $\\alpha_i\\in\\mathbb{R}^{d_\\theta}$ and $\\beta_i\\in\\mathbb{R}^{d_\\theta}$ are $d_\\theta$-dimensional adaptation parameters, where $d_\\theta$ is the total number of parameters in $\\text{GNN}_\\theta$. With the adaptation parameters $\\alpha_i$ and $\\beta_i$, we can perform an adaptation based on each class to obtain class-specific GNN parameters as follows:\n\t\\begin{equation}\n\t    \\theta_i=(\\alpha_i+\\mathbf{1})\\circ\\theta+\\beta_i,\n\t    \\label{eq:adapt_class}\n\t\\end{equation}\n\twhere $\\circ$ denotes the element-wise multiplication and $\\mathbf{1}$ is a vector of ones to limit the scaling range around one. $\\theta_i$ denotes the adapted GNN parameters for the $i$-th class in $\\mathcal{S}$. Then we perform message propagation on each class-ego subgraph with the adapted $\\theta_i$:\n\t\\begin{equation}\n\t    \\mathbf{s}_i=\\text{Centroid}\\left(\\text{GNN}_{\\theta_i}(\\mathcal{V}_i,\\mathcal{E}_i,\\mathbf{X}_i)\\right),\n\t    \\label{eq:subgraph_representation}\n\t\\end{equation}\n\twhere $\\mathbf{s}_i\\in\\mathbb{R}^{d_s}$ denotes the learned embedding of the virtual class node (i.e., the centroid node) and acts as the prototype of the $i$-th class. $\\text{Centroid}(\\cdot)$ denotes the operation of extracting  the centroid node representation from the GNN output. $d_s$ is the output dimension of $\\text{GNN}_\\theta$.\n\tAs a result, the GNN parameters can absorb the information from each class to reduce the adverse impact of class-level variance.\n\t%%%%%%%%%with class-level adaptations. \n\tSimilarly, for the representations of query nodes, we also apply the proposed class-specific adapter. Since labels of query nodes are unknown during meta-training, we utilize the entire support set $\\mathcal{S}$ to conduct adaptations for query nodes:\n\t\t\\begin{equation}\n\\alpha_q=\\text{MLP}_\\alpha \\left(\\text{MEAN}\\left(\\left\\{\\mathbf{h}_v|v\\in\\mathcal{S}\\right\\}\\right)\\right),\n\t\\end{equation}\n\t\\begin{equation}\n\\beta_q=\\text{MLP}_\\beta \\left(\\text{MEAN}\\left(\\left\\{\\mathbf{h}_v|v\\in\\mathcal{S}\\right\\}\\right)\\right),\n\\end{equation}\n\t\\begin{equation}\n\t    \\theta_q=(\\alpha_q+\\mathbf{1})\\circ\\theta+\\beta_q,\n\t    \\label{eq:adapt}\n\t\\end{equation}\nwhere $\\theta_q$ is the adapted GNN parameters for query nodes. To obtain the representation $\\mathbf{q}_i$ for the $i$-th query node $q_i$ in the query set $\\mathcal{Q}$, we extract the 2-hop neighbors of $q_i$ and obtain the corresponding node set $\\mathcal{V}^q_i$, edge set $\\mathcal{E}^q_i$, and input node features $\\mathbf{X}^q_i$. The reason is that using subgraph structures (e.g., considering 2-hop neighbors) to learn node representations provides a more robust generalization ability~\\cite{huang2020graph}. Then we utilize the adapted $\\text{GNN}_{\\theta_q}$ to compute $\\mathbf{q}_i$:\n\t\\begin{equation}\n\t    \t    \\mathbf{q}_i=\\text{Centroid}\\left(\\text{GNN}_{\\theta_q}(\\mathcal{V}^q_i,\\mathcal{E}^q_i,\\mathbf{X}^q_i)\\right),\n\t\\end{equation}\n\twhere $\\mathbf{q}_i\\in\\mathbb{R}^{d_s}$ is the embedding of $q_i$ (i.e., the centroid node).\n\t\n\t%%%%%%%In this way, we can obtain the class-specific representations for class-ego subgraphs and query nodes with class-level adaptations.\n\t\n\t"
                },
                "subsection 3.3": {
                    "name": "Task-level Adaptation",
                    "content": "\n\t%%%%%Since the classification process is based on the entire support set, the variance of the support set distribution in different tasks can deteriorate the classification performance on novel classes. Nevertheless, prevalent FSL models generally conduct classification via matching query instances and support class prototypes (i.e., representations of classes). Such strategy exhibits deficiency in utilizing the information from the support set distribution and thus renders difficulties in classification~\\cite{finn2017model}. \n\tAlthough we have achieved node-level and class-level adaptations in the embedding learning and prototype learning phases, respectively, the task variance caused by differences in the support set among meta-tasks still exist in the final query matching phase~\\cite{huang2020graph}. Nevertheless, existing methods typically leverage the Euclidean distance metric~\\cite{ding2020graph} or an MLP layer~\\cite{liu2021relative} to classify query nodes, which ignores the task variance. Instead,\n\t%%%%%%Although we have achieved node-level and class-level adaptations via the above two modules, it may still be insufficient when node-level and class-level variance both exists in a meta-task.\n    we propose to perform task-level adaptations in each meta-task, which aim to further reduce the adverse impact of task variance in this phase.\n    %%%%%%%%%, via a task-adaptive matching strategy based on the mutual information. \n    Specifically, we propose a task-adaptive matching strategy\n    %%%%%%%%%%leverage the distribution of the entire support set $\\mathcal{S}$ in each meta-task\n    to maximally preserve the mutual information between learned representations of nodes in the query set $\\mathcal{Q}$ and the support set $\\mathcal{S}$.\n    %%%%%However, it remains challenging to leverage it for classification on query nodes, since the distribution of the query set is unknown during test. Therefore, we propose a novel classifier that aims at maximally preserving the mutual information between the query set $\\mathcal{Q}$ and the support set $\\mathcal{S}$. \n    As a result, the matching phase on query nodes can incorporate information from the entire support set $\\mathcal{S}$ for task-level adaptations.\n    %%%%%%Moreover, we introduce an adaptation parameter in the classification process according to the distribution of nodes in $\\mathcal{S}$ to further reduce the adverse impact of node-level and class-level variance.\n    \n    The optimization problem of maximizing the mutual information can be formulated as follows:\n\t\\begin{equation}\n\t    \\max_{\\widetilde{\\theta}} I(\\mathbf{Q};\\mathbf{S})= \\max_{\\widetilde{\\theta}}\\sum\\limits_{i=1}^Q\\sum\\limits_{j=1}^Np(q_i,s_j;\\widetilde{\\theta})\\log\\frac{p(q_i|s_j;\\widetilde{\\theta})}{p(q_i;\\widetilde{\\theta})},\n\t\\end{equation}\n\twhere $\\mathbf{Q}\\in\\mathbb{R}^{Q\\times d_s}$ and $\\mathbf{S}\\in\\mathbb{R}^{N\\times d_s}$ are learned representations of query nodes in $\\mathcal{Q}$ and classes (i.e., prototypes) in $\\mathcal{S}$, respectively.\n\t%%%%%%\n\t$Q=|\\mathcal{Q}|$ and $N$ is the number of classes in $\\mathcal{S}$. $\\widetilde{\\theta}$ denotes the parameters of our framework to be optimized. $q_i$ is the $i$-th query node in $\\mathcal{Q}$ and $s_j$ is the $j$-th class in $\\mathcal{S}$. Since the mutual information $I(\\mathbf{Q};\\mathbf{S})$ is difficult to obtain and thus infeasible to maximize~\\cite{oord2018representation}, we re-write the function to obtain an accessible form:\n\t\\begin{equation}\n\t    I(\\mathbf{Q};\\mathbf{S})=\\sum\\limits_{i=1}^Q\\sum\\limits_{j=1}^Np(q_i|s_j;\\widetilde{\\theta})p(s_j;\\widetilde{\\theta})\\log\\frac{p(q_i|s_j;\\widetilde{\\theta})}{p(q_i;\\widetilde{\\theta})}.\n\t\\end{equation}\n\t%%%%%We may assume that in a specific meta-task, the distribution of prototypes (i.e., representations of classes) are identical, since the support nodes in each class are randomly sampled.\n\tSince each meta-task contains $N$ classes, we may assume that the prior probability of $p(s_j;\\widetilde{\\theta})$ follows a uniform distribution\n\t%%%%%Therefore, we set the prior probability $p(s_j;\\widetilde{\\theta})$ as $1/N$. \n\tand set it as $p(s_j;\\widetilde{\\theta})=1/N$.\n\tSince $p(s_j;\\widetilde{\\theta})$ is a constant, according to the Bayes' theorem, the objective function becomes:\n\t\\begin{equation}\n\t    \\begin{aligned}\n\t        I(\\mathbf{Q};\\mathbf{S})\n\t        %&=\\frac{1}{N}\\sum\\limits_{i=1}^Q\\sum\\limits_{j=1}^Np(x_i|s_j;\\widetilde{\\theta})\\log\\frac{p(x_i|s_j;\\widetilde{\\theta})}{p(x_i;\\widetilde{\\theta})}\\\\\n\t        &=\\frac{1}{N}\\sum\\limits_{i=1}^Q\\sum\\limits_{j=1}^Np(q_i|s_j;\\widetilde{\\theta})\\log\\frac{p(s_j|q_i;\\widetilde{\\theta})}{p(s_j;\\widetilde{\\theta})}\\\\\n\t        &=\\frac{1}{N}\\sum\\limits_{i=1}^Q\\sum\\limits_{j=1}^Np(q_i|s_j;\\widetilde{\\theta})\\left(\\log(p(s_j|q_i;\\widetilde{\\theta}))-\\log\\left(\\frac{1}{N}\\right)\\right).\n\t    \\end{aligned}\n\t\\end{equation}\n\tTo further estimate $p(q_i|s_j;\\widetilde{\\theta})$, we compute it by $p(q_i|s_j;\\widetilde{\\theta})=\\mathbb{1}(q_i\\in s_j)$, where $\\mathbb{1}(q_i\\in s_j)=1$ if $q_i$ belongs to the class represented by $s_j$; otherwise $\\mathbb{1}(q_i\\in s_j)=0$. In this way, the above objective function is simplified as follows:\n\t\\begin{equation}\n\t    I(\\mathbf{Q};\\mathbf{S})=\\frac{1}{N}\\sum\\limits_{i=1}^Q\\sum\\limits_{j=1}^N\\mathbb{1}(q_i\\in s_j)\\left(\\log(p(s_j|q_i;\\widetilde{\\theta}))-\\log\\left(\\frac{1}{N}\\right)\\right).\n\t\\end{equation}\n\tSince each $q_i$ can only belong to one $s_j$ (i.e., one class), we can further simplify the objective function:\n\t\\begin{equation}\n\t    \\sum\\limits_{i=1}^Q\\sum\\limits_{j=1}^N\\mathbb{1}(q_i\\in s_j)\\log(p(s_j|q_i;\\widetilde{\\theta}))=\\sum\\limits_{i=1}^Q\\log(p(s'_i|q_i;\\widetilde{\\theta})),\n\t\\end{equation}\n\twhere $s'_i$ denotes the specific $s_j$ that $q_i$ belongs to (i.e., $q_i\\in s'_i$). Moreover, since $\\log\\left(1/N\\right)$ is also a constant, we can simplify the objective function as follows:\n\t\\begin{equation}\n\t\\begin{aligned}\n\t    I(\\mathbf{Q};\\mathbf{S})\n\t    &=\\sum\\limits_{i=1}^Q\\log(p(s'_i|q_i;\\widetilde{\\theta})).\n\t\\end{aligned}\n\t\\end{equation}\n\tTo estimate $p(s'_i|q_i;\\widetilde{\\theta})$, we can define the probability of $q_i$ belonging to $s_j$ according to the squared $\\ell_2$ norm of the embedding distance. Specifically, we further assign a weight parameter $\\tau_i$ to each class and normalize the probability with a softmax function:\n    \\begin{equation}\n        \\left.p(s'_i|q_i;\\widetilde{\\theta})=\\frac{\\exp\\left(-(\\mathbf{q}_i- \\mathbf{s}'_i)^2/\\tau_i'\\right)}{\\sum_{j=1}^N\\exp\\left(-(\\mathbf{q}_i-\\mathbf{s}_j)^2/\\tau_j\\right)}\n        \\right.,\n    \\end{equation}\n    where $\\mathbf{q}_i$ and $\\mathbf{s}_j$ denote the representations of the $i$-th query node $x_i$ in $\\mathcal{Q}$ and the $j$-th class-ego subgraph in $\\mathcal{S}$, respectively. $\\tau_i$ is the adaptation parameter of the $i$-th class, and $\\mathbf{s}'_i$ and $\\tau_i'$ denote the specific class-ego subgraph representation and the adaptation parameter of the class that $\\mathbf{q}_i$ belongs to, respectively. Then if we further apply the $\\ell_2$ normalization to both $\\mathbf{q}_i$ and $\\mathbf{s}_i$, we obtain $(\\mathbf{q}_i- \\mathbf{s}_i)^2=2-2\\mathbf{q}_i\\cdot \\mathbf{s}_i$. Combining the above equations, we can present the final optimization problem as follows:\n    \\begin{equation}\n       \\max_{\\widetilde{\\theta}} I(\\mathcal{Q};\\mathcal{S})=\\min_{\\widetilde{\\theta}}\\sum\\limits_{i=1}^Q-\\log\\frac{\\exp(\\mathbf{q}_i\\cdot \\mathbf{s}'_i/\\tau'_i)}{\\sum_{j=1}^N\\exp(\\mathbf{q}_i\\cdot \\mathbf{s}_j/\\tau_j)}.\n       \\label{eq:objective}\n    \\end{equation}\n     %Here $\\tau_i$ acts as an adaptation parameter for each class regarding the entire support set. \n     %\n     Since the distribution of node embeddings in each class $\\mathcal{S}_i$ differs around the class representation $\\mathbf{s}_i$, the node embeddings of specific classes can be scattered in a large distance from $\\mathbf{s}_i$. In this case, the classification process should incorporate the distribution of node embeddings in each class while considering the entire support set $\\mathcal{S}$. Thus, we propose to obtain $\\tau_i'$ as follows:\n\t\\begin{equation}\n\t    \\tau_i=\\frac{N\\sum_k^K\\|\\mathbf{s}_i^k-\\mathbf{s}_i\\|_2}{\\sum_j^N\\sum_k^K\\|\\mathbf{s}_j^k-\\mathbf{s}_j\\|_2},\n\t\\end{equation}\n\twhere $\\{\\mathbf{s}_i^k\\}_{i=1}^K$ denotes the node embeddings in the $i$-th class processed by $\\text{GNN}_{\\theta_i}$. In this way, the classification process is adapted regrading the entire support set to reduce the adverse impact of task variance. Hence, the model is able to incorporate information in the entire support set to achieve task-level adaptations. Then according to Eq.~(\\ref{eq:objective}), we can optimize the following information loss to preserve the mutual information $I(\\mathcal{Q};\\mathcal{S})$:\n\t\\begin{equation}\n\t    \\mathcal{L}_{N}=-\\sum\\limits_{i=1}^Q\\log\\frac{\\exp(\\mathbf{q}_i\\cdot \\mathbf{s}'_i/\\tau'_i)}{\\sum_{j=1}^N\\exp(\\mathbf{q}_i\\cdot \\mathbf{s}_j/\\tau_j)}.\n\t    \\label{eq:Loss_N}\n\t\\end{equation}\n\t\n\tIt is worth mentioning that $\\mathcal{L}_N$ shares a similar expression with the InfoNCE loss~\\cite{oord2018representation,he2020momentum}. Thus, InfoNCE can be considered as a special case where positive and negative pairs are defined by different views of nodes, while in our case, they are defined according to the labels of query nodes. $\\mathcal{L}_N$ also differs from the supervised contrastive loss~\\cite{khosla2020supervised}, which utilizes various views of images and supervised information, as our loss aims at maximally preserving the mutual information between query nodes and support nodes within each meta-task. Moreover, the adaptation parameter acts similarly with the temperature parameter in InfoNCE, while in our framework, it is adjustable and provides task-level adaptations.\n\t\n\t\n\t\\begin{algorithm}[t]\n\t\t\\caption {Detailed learning process of our framework.}\n\t\t\\begin{algorithmic}[1]\n\t\t\t\\REQUIRE A graph $G=(\\mathcal{V},\\mathcal{E},\\X)$, a meta-test task $\\mathcal{T}_{test}=\\{\\mathcal{S},\\mathcal{Q}\\}$, base classes $\\mathcal{C}_b$, meta-training epochs $T$, the number of classes $N$, and the number of labeled nodes for each class $K$.\n\t\t\t\\ENSURE Predicted labels of the query nodes in $\\mathcal{Q}$.\n\t\t\t\n\t\t\t// \\texttt{Meta-training phase}\n\t\t\t%\\STATE $i \\gets 0$\n\t\t\t\\FOR {$i=1,2,\\dotsc,T$}\n\t\t\t\\STATE Sample a meta-training task $\\mathcal{T}_{i}=\\{\\mathcal{S}_i,\\mathcal{Q}_i\\}$ from $\\mathcal{C}_{b}$;\n\t\t\t\\STATE Compute first-step node representations with $\\text{GNN}_\\phi$;\n\t\t\t\\STATE Construct a class-ego subgraphs for each of $N$ classes in $\\mathcal{S}_i$;\n\t\t\t\\STATE Adapt $\\text{GNN}_\\theta$ to $\\mathcal{T}_i$ according to Eq. (\\ref{eq:adapt_class}) and (\\ref{eq:adapt});\n\t\t\t\\STATE Compute the representations for class-ego subgraphs and query nodes with the adapted $\\text{GNN}_{\\theta_i}$ and $\\text{GNN}_{\\theta_q}$;\n\t\t\t\\STATE Update model parameters with the meta-training loss of $\\mathcal{T}_i$ according to Eq. (\\ref{eq:final_loss}) by one gradient descent step;\n\t\t\t%\\STATE $i\\gets i+1$\n\t\t\t\\ENDFOR\n\t\t\t\n\t\t\t// \\texttt{Meta-test phase}\n\t\t\t\\STATE Compute first-step node representations with $\\text{GNN}_\\phi$;\n\t\t\t\\STATE Construct a class-ego subgraphs for each of $N$ classes in $\\mathcal{S}$;\n\t\t\t\\STATE Adapt $\\text{GNN}_\\theta$ to $\\mathcal{T}_{test}$ according to Eq. (\\ref{eq:adapt_class}) and (\\ref{eq:adapt});\n\t\t\t\\STATE Compute the representations for class-ego subgraphs and query nodes with the adapted $\\text{GNN}_{\\theta_i}$ and $\\text{GNN}_{\\theta_q}$;\n\t\t\t\\STATE Predict labels for query nodes in $\\mathcal{Q}$;\n\n\t\t\\end{algorithmic}\n\t\t\t\t\t\\label{algorithm}\n\t\t\t\t\t\n\t\\end{algorithm}\n\n\t"
                },
                "subsection 3.4": {
                    "name": "Few-shot Node Classification",
                    "content": "\n\tSo far, we can train $\\text{GNN}_\\phi$ and $\\text{GNN}_\\theta$ with the proposed loss $\\mathcal{L}_N$ in Eq.~(\\ref{eq:Loss_N}). However, since $\\text{GNN}_\\phi$ provides the first-step representations for nodes from an overview of the entire graph $G$, the supervised information within each meta-task could be insufficient for the optimization of $\\text{GNN}_\\phi$. Thus, we propose to classify query nodes from base classes $\\mathcal{C}_{b}$ to optimize $\\text{GNN}_\\phi$. Specifically, we utilize an MLP layer followed by a softmax function to calculate the cross-entropy classification loss over $\\mathcal{C}_{b}$:\n\t\\begin{equation}\n\t    \\mathbf{p}_i=\\text{Softmax}\\left(\\text{MLP}(\\mathbf{h}_i)   \\right),\n\t\\end{equation}\n\t\\begin{equation}\n\t    \\mathcal{L}_{CE}=-\\sum\\limits_{i=1}^Q\\sum\\limits_{j=1}^{|\\mathcal{C}_b|}y_{i,j}\\log p_{i,j},\n\t\\end{equation}\n\twhere $\\mathbf{p}_i\\in\\mathbb{R}^{|\\mathcal{C}_b|}$ is the probability that the $i$-th query node in $\\mathcal{Q}$ belongs to each class in $\\mathcal{C}_b$. $y_{i,j}=1$ if the $i$-th node belongs to the $j$-th class, and $y_{i,j}=0$, otherwise. $p_{i,j}$ is the $j$-th element in $\\mathbf{p}_i$. In this way, instead of classifying nodes only from classes in a meta-task, we can utilize the supervised information in $\\mathcal{C}_b$\n\t%%%%%%%%from nodes in $\\mathcal{C}_b$ \n\tfrom a global perspective. Then the meta-training loss is defined as follows:\n\t\\begin{equation}\n\t    \\mathcal{L}=\\mathcal{L}_{N}+\\gamma\\mathcal{L}_{CE},\n\t    \\label{eq:final_loss}\n\t\\end{equation}\n\twhere $\\gamma$ is an adjustable weight hyper-parameter.\n\t\n\t%%%%%%During meta-test, since our framework performs fast adaptation to each meta-test task after training, we do not utilize the prevalent fine-tuning strategy~\\cite{finn2017model,wang21AMM}. %Nevertheless, although our framework does not contain a few-shot classification loss within a task, the Euclidean distance or similarity between representations of query nodes and class-ego subgraphs can be utilized to conduct classification. Therefore, \n\tAfter meta-training, the meta-test process is the same as the meta-training process, except that meta-test tasks are sampled from novel classes $\\mathcal{C}_n$. \n\t%%%%%%%We first conduct node-level adaptations and class-level adaptations in each meta-test task. Then we classify each query node with task-level adaptations:\n\tThe labels of query nodes are obtained by $\\hat{y}_i=\\argmax_j\\{\\mathbf{q}_i\\cdot\\mathbf{s}_j/\\tau_i|j=1,2,\\dotsc,N\\}$, where $\\mathbf{q}_i$ and $\\mathbf{s}_j$ are representations of the $i$-th query node and the $j$-th class-ego subgraph, respectively. $\\tau_i$ is the adaptation parameter of the $i$-th class. The detailed process of our framework is demonstrated in Algorithm \\ref{algorithm}.\n\t\n\t\n\t\n\n\t%\\subsection{Unlabeled Class Contrastive Loss}\n\t%Although we have proposed to enhance interactions between %nodes and classes in a task, the overall interactions in the %entire dataset remains undiscovered. Thus, to exploit the %interactions between base classes and novel classes, which %constitute the entire class set of the dataset, we propose an %unlabeled class contrastive loss based on %Theorem~\\ref{theorem}. The main idea is that although the %specific labels of nodes in novel classes are unknown during %training, we can utilize the fact that they do not belong to %the base classes. In other words, although we cannot leverage %the information from novel classes in a supervised manner, we %can still utilize the interactions between base classes and %novel classes. Specifically, in each task $\\mathcal{T}$, we %randomly sample $Q'$ node from novel classes and compute the %unlabeled class contrastive loss as follows:\n\t%\\begin{equation}\n\t%    \\mathcal{L}_{unlabel}=\\sum\\limits_{i=1}^{Q'}-\\log\\frac{1}{%\\sum_{j=1}^N\\exp(v_i\\cdot s_j/\\tau)},\n\t%\\end{equation}\n\t%where $v_i$ denotes the embedding of the $i$-th sampled node %from novel classes. This loss can be seen as the contrastive %loss with all negative pairs, since the sampled nodes do not %belong to any of the $N$ classes in $\\mathcal{T}$. In this %way, our framework explicitly constructs the interactions %between base classes and novel classes via the loss %$\\mathcal{L}_{unlabel}$, which aims at increasing the distance %between node embeddings from base classes and novel classes. %This loss is combined with the other two losses to form the %final loss:\n\t%\\begin{equation}\n\t%    \\mathcal{L}= \\mathcal{L}+ %\\mathcal{L}+\\beta\\mathcal{L}_{unlabel},\n\t%\\end{equation}\n\t%where $\\beta$ denotes the weight for $\\mathcal{L}$.\n\t\n    "
                }
            },
            "section 4": {
                "name": "Experiments",
                "content": "\n    In this section, we conduct experiments to evaluate our framework \\textsc{TENT} on four prevalent few-shot node classification datasets. Furthermore, we conduct experiments to verify the effectiveness of different modules in our framework with ablation study and demonstrate the parameter sensitivity. \n    %%%%%%%%%%First, we present an introduction about the datasets and experimental settings. \n\n",
                "subsection 4.1": {
                    "name": "Datasets",
                    "content": "\nTo evaluate our framework on few-shot node classification tasks, we conduct experiments on four prevalent real-world graph datasets: \\texttt{Amazon-E}~\\cite{mcauley2015inferring}, \\texttt{DBLP}~\\cite{tang2008arnetminer}, \\texttt{Cora-full}~\\cite{bojchevski2018deep}, and \\texttt{OGBN-arxiv}~\\cite{hu2020open}. \n%Few-shot learning typically performs classification with a variety of classes~\\cite{ding2020graph,snell2017prototypical}. Therefore, we ensure that the selected datasets consist of a large number of node classes. \nWe summarize the detailed statistics of these datasets in Table~\\ref{tab:statistics}. Specifically,\n\\# Nodes and \\# Edges denote the number of nodes and edges in the graph, respectively. \\# Features denotes the dimension of node features. \nClass Split denotes the number of classes used for meta-training/validation/meta-test. More details are provided in Appendix \\ref{appendix}.\n\n\t\n\n"
                },
                "subsection 4.2": {
                    "name": "Experimental Settings",
                    "content": "\nTo validate the effectiveness of our proposed framework \\textsc{TENT}, we conduct experiments with the following baseline methods to compare performance:\n\\begin{itemize}\n    \\item \\textbf{Prototypical Networks}~\\cite{snell2017prototypical}: Prototypical Networks learn prototypes for classes for query matching.\n        \\item \\textbf{MAML}~\\cite{finn2017model}: MAML proposes to optimize model parameters based on gradients of support instances across meta-tasks.\n    \\item \\textbf{GCN}~\\cite{kipf2017semi}: GCN performs information propagation based on local structures.\n\n    %%%%%%%%%%\\item \\textbf{Meta-GNN}~\\cite{zhou2019meta}: Meta-GNN combines MAML with GNNs to perform few-shot node classification.\n        \\item \\textbf{G-Meta}~\\cite{huang2020graph}: G-Meta utilizes representations of subgraphs as node embeddings for few-shot learning on graphs.\n    \\item \\textbf{GPN}~\\cite{ding2020graph}: GPN leverages node importance and Prototypical Networks to improve performance.\n    %\\item \\textbf{AMM-GNN}~\\cite{wang21AMM}: AMM-GNN proposes to extend MAML with a attribute matching mechanism.\n\n    \\item \\textbf{RALE}~\\cite{liu2021relative}: RALE proposes to learn node dependencies according to node locations on the graph.\n\\end{itemize}\n\nDuring training, we sample a certain number of meta-training tasks from training classes (i.e., base classes) and train the model with these meta-tasks. Then we evaluate the model based on a series of randomly sampled meta-test tasks from test classes (i.e., novel classes). For consistency, the class splitting is identical for all baseline methods. Then the final result of the average classification accuracy is obtained based on these meta-test tasks. More detailed parameter settings can be found in Appendix~\\ref{appendix:implementation}.\n\n\n\n\n\t\n\t\n\t\n\n\n\n\n"
                },
                "subsection 4.3": {
                    "name": "Overall Evaluation Results",
                    "content": "\nWe first present the performance comparison of our framework and baseline methods on few-shot node classification in Table~\\ref{tab:all_result}. Specifically, to better demonstrate the efficacy of our framework under different few-shot settings, we conduct the experiments under four different settings: 5-way 3-shot, 5-way 5-shot, 10-way 3-shot, and 10-way 5-shot. Moreover, the evaluation metric is the average classification accuracy over ten repetitions. From the overall results, we can obtain the following observations:\n\\begin{itemize}\n    \\item Our proposed framework TENT outperforms all other baselines in all datasets under different few-shot settings, which validates the effectiveness of our task-adaptive framework on few-shot node classification.\n    \\item Conventional few-shot methods such as Prototypical Network~\\cite{snell2017prototypical} and MAML~\\cite{finn2017model} exhibit inferior performance compared with other baselines. The reason is that such methods are proposed in other domains and thus result in unsatisfactory performance on graphs.\n    \\item When increasing the value of $K$ (i.e., more support nodes in each class), all methods gain considerable performance improvements. Moreover, our framework achieves better results due to that the node-level and class-level adaptations benefit more from a larger size of nodes in each class.\n    \\item The performance of all methods significantly decreases when the value of $N$ increases (i.e., more classes in each meta-task). The main reason is that the variety of classes in each meta-task leads to a more complex class distribution and results in classification difficulties. However, by incorporating the class-level and task-level adaptations, our framework is capable of alleviating this problem \n    %%%%%%with a larger $N$.\n    when a larger $N$ is presented.\n\\end{itemize}\n\n\n\t\t\n\n\n"
                },
                "subsection 4.4": {
                    "name": "Ablation Study",
                    "content": "\nIn this part, we conduct an ablation study on four datasets to verify the importance of three crucial components in TENT. First, we remove the node-level adaptation and directly utilize the original graph instead of class-ego subgraphs to learn representations for each class in meta-tasks. In this way, the support nodes of different classes are distributed over the entire graph and thus lack node-level adaptations. We refer to this variant as \\emph{TENT\\textbackslash N}. Second, we remove the class-specific adapter so that the framework identically learns class representations and lacks class-level adaptations, and we refer to this variant as \\emph{TENT\\textbackslash C}. The final variant is to replace the task-level adaptation module with a common Euclidean distance classifier, which means during training, the framework fails to learn task-level adaptations across meta-training tasks, and we refer it to as \\emph{TENT\\textbackslash T}. The overall ablation study results are presented in Fig.~\\ref{fig:ablation}. From the results, we can observe that \nTENT outperforms all variants, which demonstrates the effectiveness of all three types of adaptations. Specifically, removing node-level adaptations results in a large decrease in few-shot node classification performance. Furthermore, integrating class-level adaptations provides a considerable performance improvement, especially when the number of classes increases, which introduces larger class variance. More significantly, without the task-level adaptations, the performance decreases rapidly when the support set size increases. Therefore, the result further demonstrates the importance of task-level adaptations in the presence of a more complex few-shot setting with a large support set.\n\n\n\t\t\n\n\n\n"
                },
                "subsection 4.5": {
                    "name": "Effect of Meta-training Support Set Size",
                    "content": "\nIn this section, we conduct experiments to study the sensitivity of several parameters in TENT. Since TENT provides task adaptations for both meta-training and meta-test tasks, the values of $N$ (i.e., number of classes in a support set) and $K$ (i.e., number of support nodes in each class) are unnecessary to be consistent during meta-training and meta-test. In other words, it differs from the general few-shot learning setting, where the parameters of $N$ and $K$ are consistent during meta-training and meta-test. Therefore, we can adjust these two parameters during meta-training to analyze their effects for better performance. Fig.~\\ref{fig:nk} reports the classification accuracy of TENT when varying the parameters of $N$ and $K$ during meta-training on four datasets, denoted as $N_t$ and $K_t$, respectively. Specifically, we vary the values of $N_t$ and $K_t$ as 3, 5, 10, and 20. Note that during meta-test, the values of $N$ and $K$ are kept invariant as 5 and 5, respectively (i.e., $5$-way $5$-shot). From the results, we observe that increasing $N_t$ and $K_t$ both provide better results on few-shot node classification. The reason is that TENT learns the three types of adaptations from a larger support set during meta-training and thus is more capable of handling \n%%%%%%more various distributions\nnode-level and class-level variance. More specifically, increasing the value of $N$ results in a more significant improvement. The main reason is that the class-level and task-level adaptations benefit from more classes in each meta-task. In addition, incorporating more support nodes in each class (i.e., larger $K_t$) also enhances the interactions \n%%%%%%among more nodes\namong nodes in each class-ego subgraph for more comprehensive node-level adaptations.\n\n\n\t\t\n\n\n\n\n\n"
                },
                "subsection 4.6": {
                    "name": "Effect of Query Set Size",
                    "content": "\nIn this part, we conduct experiments to present how the query set size $|\\mathcal{Q}|$ in each meta-task during meta-training affects the performance of our proposed framework TENT. Fig.~\\ref{fig:Q} reports the results of TENT when varying the value of $|\\mathcal{Q}|$ on four datasets under the 5-way 5-shot setting. Specifically, $|\\mathcal{Q}|$ during meta-training is changed from 3 to 20, while it remains 10 during meta-test for a fair comparison. From the results, we can observe that the few-shot node classification performance increases when $|\\mathcal{Q}|$ becomes larger. The reason is mainly attributed to the fact that involving more\nquery nodes during meta-training (i.e., increasing the value of $|\\mathcal{Q}|$) helps\nalleviate the over-fitting problem. However, as the results suggest, an excessively large query set size may result in a performance drop. The reason is that the optimization process may be more difficult on a large query set. \n\n\n\n\n\n"
                }
            },
            "section 5": {
                "name": "Related Work",
                "content": "\n",
                "subsection 5.1": {
                    "name": "Graph Neural Networks",
                    "content": "\nRecently, many researchers \n%%%%%%have devoted enormous efforts to studying Graph Neural Networks (GNNs) to \nfocus on studying Graph Neural Networks (GNNs) to learn comprehensive node representations in graphs~\\cite{cao2016deep,chang2015heterogeneous,xu2018representation}. In general, GNNs aim at learning node representations through a certain number of information propagation steps in a recurrent manner~\\cite{zhou2020graph,zhang2020deep,hamilton2017inductive}. \n%%%%%%In this way, the information from neighboring nodes will be aggregated and generate representations based on local structures. \nIn this way, GNNs can aggregate information from neighboring nodes to generate node representations based on local structures.\nFor example, Graph Convolutional Networks (GCNs)~\\cite{kipf2017semi} perform convolution operations on graphs based on the graph spectral theory. \n%GraphSAGE~\\cite{hamilton2017inductive} samples certain features from neighbor nodes and conducts aggregation to obtain node representations. \nGraph Attention Networks (GATs)~\\cite{velivckovic2017graph} leverage the attention mechanism to select more important neighboring nodes for aggregation. Moreover, Graph Isomorphism Networks (GINs)~\\cite{xu2018powerful} develop an expressive architecture, which is as powerful as the Weisfeiler-Lehman graph isomorphism test. \n%%%%%%%%%%Nonetheless, most existing GNN models are trained in a semi-supervised manner with a large number of labeled nodes.\nNonetheless, GNNs typically render sub-optimal performance when there are limited labeled nodes for each class~\\cite{ding2020graph,yao2020graph},\n%%%%%%%%%%In addition, GNNs generally render sub-optimal performance when encountering unseen node classes\nwhich further indicates the necessity of few-shot learning on graphs.\n\n"
                },
                "subsection 5.2": {
                    "name": "Few-shot Learning on Graphs",
                    "content": "\nFew-shot Learning (FSL) aims to learn transferable knowledge from tasks with abundant supervised information and generalize it to novel tasks with a limited number of labeled instances. In general, few-shot learning methods can be divided into two categories: \\emph{metric-based} approaches and \\emph{meta-optimizer-based} approaches. Specifically, the metric-based approaches aim at learning generalizable metric functions to match the query set with the support set for classification~\\cite{liu2019learning,sung2018learning}. \n%%%%%%%%%%Moreover, a matching function is also learned to measure the distance between a query instance and a class. \nFor example, Matching Networks~\\cite{vinyals2016matching} conduct predictions based on the similarity between a query instance and each support instance learned by attention networks. Prototypical Networks~\\cite{snell2017prototypical} learn a prototype as the representation for each class and perform classification based on the Euclidean distances between query instances and prototypes. \n%%%%%%%%%%In addition, Relation Networks~\\cite{sung2018learning} propose to learn relations scores for classification in a non-linear manner. \nOn the other hand, meta-optimizer-based approaches aim at optimizing model parameters according to gradients calculated from few-shot instances~\\cite{mishra2018simple,ravi2016optimization}. For example, MAML~\\cite{finn2017model} optimizes model parameters based on gradients on support instances for fast generalization. Moreover, LSTM-based meta-learner~\\cite{ravi2016optimization} proposes to adjust the step size for updating parameters during meta-training. \n%%%%%%%%%%In addition, to obtain an optimal learning strategy, SNAIL~\\cite{mishra2017simple} proposes to combine temporal convolution and the attention mechanism in few-shot learning. In addition, several approaches leverage the memory mechanism to maintain valuable knowledge acquired from meta-training tasks for better generalizations to meta-test tasks. For example, CMN~\\cite{zhu2018compound} proposes to learn an optimal representation for samples in a larger space based on the key-value memory network. Furthermore, MM-net~\\cite{cai2018memory} utilizes the memory slots sequentially to predict the parameters of CNNs based on the memory mechanism.\n\nIn the field of graphs, several recent works propose to conduct graph-based tasks under the few-shot learning scenario~\\cite{chauhan2020few,ma2020adaptive,wang2021reform}. Among them, %Meta-GNN~\\cite{zhou2019meta} combines MAML~\\cite{finn2017model} with GNNs to perform few-shot node classification on graphs. %%%%%%%%%%AMM-GNN~\\cite{wang21AMM} improves Meta-GNN via implementing an attribute-level attention mechanism to distinguish different feature distributions among meta-tasks for a more comprehensive transferable knowledge to meta-test tasks. \nGPN~\\cite{ding2020graph} proposes to leverage node importance based on Prototypical Networks~\\cite{snell2017prototypical} for better performance, where nodes are classified via finding the nearest class prototype. G-Meta~\\cite{huang2020graph} leverages local subgraphs to learn node representations while combining meta-learning~\\cite{finn2017model} for model generalization. More recently, RALE~\\cite{liu2021relative} learns to model node dependencies within each meta-task by assigning relative and absolute locations for nodes with task-level and graph-level dependencies, respectively.\n%%%%%%%%%%These locations capture both the task-level dependency among nodes in each meta-task and the global-level dependency among meta-tasks. \n%%%%%%%%%%For few-shot graph classification tasks, GSM~\\cite{chauhan2020few} proposes to leverage graph spectral measures for generalization, and AS-MAML~\\cite{ma2020adaptive} designs a controller~\\cite{williams1992simple} for the meta-learner.\n\n\n"
                }
            },
            "section 6": {
                "name": "Conclusion",
                "content": "\nIn this paper, we study the problem of few-shot node classification, which \naims at predicting labels for nodes in novel classes with limited labeled nodes. Furthermore, to address the associated challenges caused by insufficient labeled nodes and the variety of novel classes, we propose a novel framework TENT to perform task adaptations for each meta-task from three perspectives: node-level, class-level, and task-level. As a result, our framework can perform these adaptions to each meta-task and advance classification performance with respect to a variety of novel classes during meta-test. Moreover, extensive experiments are conducted on four prevalent few-shot node classification datasets. The experimental results further validate that TENT outperforms other state-of-the-art baselines. In addition, the ablation study also verifies the effectiveness of three different levels of adaptations in our framework. Nevertheless, there still exists a considerable number of difficulties in few-shot node classification. For example, the inductive setting for few-shot node classification is still challenging. Future work may incorporate more sophisticated adaptation methods to handle the novel classes on graphs unseen during meta-training.\n\n\n\n"
            },
            "section 7": {
                "name": "Acknowledgement",
                "content": "\nThis material is supported by the National Science Foundation (NSF) under grant \\#2006844.\n\n\n\n\t\\bibliographystyle{ACM-Reference-Format}\n\n\n\n\n\t\\bibliography{acmart}\n\n\n\t\\clearpage\n\t\\begin{appendices}\n\t\n\t\\section{Appendix}\n\t\\subsection{Notations}\nTo provide better understandings, we present the\nutilized notations in this paper and the corresponding descriptions.\n\n\\begin{table}[htbp]\n\\small\n\\setlength\\tabcolsep{0.5pt}\n\\caption{Notations used in this paper.} \n\\vspace{-0.2cm}\n\\label{tb:symbols}\n\\begin{tabular}{cc}\n\n\\hline\n\n\\textbf{Notations}       & \\textbf{Definitions or Descriptions} \\\\\n\\hline\n\n$G$   &  the input graph\\\\\n$\\mathcal{V}$, $\\mathcal{E}$  & the node set and the edge set of $G$\\\\\n$\\X$ & the input node features of $G$\\\\\n$\\mathcal{C}_b$,$\\mathcal{C}_n$ & the base class set and the novel class set\\\\\n$\\mathcal{T}_i$, $\\mathcal{S}_i$, $\\mathcal{Q}_i$& the $i$-th meta-task and its support set and query set\\\\\n$\\alpha_i$, $\\beta_i$, $\\tau_i$ & adaptation parameters for the $i$-th class\\\\\n$N$&the number of support classes in each meta-task\\\\\n$K$&the number of labeled nodes in each class\\\\\n$N_t$, $K_t$& the value of $N$ and $K$ during meta-training\\\\\n$\\mathbf{s}_i$&the embedding of the $i$-th class in each meta-task\\\\\n$\\mathbf{q}_i$&the embedding of the $i$-th query node in each meta-task\\\\\n$\\mathbf{p}_i$&the classification probabilities of the $i$-th query node over $\\mathcal{C}_b$\\\\\n\\hline\n\\end{tabular}\n\\vspace{-0.4cm}\n\\end{table}\n\n\t\\subsection{Reproducibility}\n\t\nIn this section, we present the details on the reproducibility of our experiments. More specifically, we first elaborate on the implementation setting of our experiments. Then we introduce the required packages with the corresponding versions, followed by the experimental settings of baselines used in our main experiments. Finally, we provide details of datasets used in this paper.\n\t\\subsubsection{Implementation of TENT}\n\t\\label{appendix:implementation}\n\tOur framework TENT is implemented based on PyTorch~\\cite{paszke2017automatic}.\tWe train our model on a single 16GB Nvidia V100 GPU. For the specific implementation setting, we set the number of training epochs $T$ as 500. We implement $\\text{GNN}_\\theta$ and $\\text{GNN}_\\phi$ using two-layer GINs~\\cite{xu2018powerful} with the hidden sizes $d_h$ and $d_s$ both set as 16. To effectively initialize GNNs in our experiments, we utilize the Xavier initialization~\\cite{glorot2010understanding}. The $\\text{READOUT}$ function is implemented as mean-pooling. For the model\noptimization, we adopt Adam~\\cite{kingma2014adam} with the learning rate of 0.05\nand a dropout rate of 0.2. The weight decay rate is set as $10^{-4}$ and the loss weight $\\gamma$ is set as $1$. Finally, the model that achieves the best result on the validation dataset will be saved and used for test. In addition, we randomly sample 500 tasks from novel classes $\\mathcal{C}_n$ (i.e., $T_{test}$=500) for test with a query set size $|\\mathcal{Q}|$ of 10. Furthermore, to keep consistency, the test tasks are identical for all baselines. Our code is provided at \\href{https://github.com/SongW-SW/TENT}{https://github.com/SongW-SW/TENT}.\n\n\n\t\\subsubsection{Required Packages}\nThe more detailed package requirements are listed as below.\n\t\\begin{itemize}\n\t    \\item Python == 3.7.10\n\t    \\item torch == 1.8.1\n\t    \\item torch-cluster == 1.5.9\n\t    \\item torch-scatter == 2.0.6\n\t    \\item torch-sparse == 0.6.9\n\t    \\item torch-geometric == 1.4.1\n\t    \\item torch-spline-conv==1.2.1\n\t    \\item numpy == 1.18.5\n        \\item scipy == 1.5.3\n        \\item cuda == 11.0\n    \\item tensorboard == 2.2.2\n    \\item networkx == 2.5.1\n    \\item scikit-learn == 0.24.1\n    \\item pandas==1.2.3\n\t\\end{itemize}\n\t\n\t\n\t\\subsubsection{Baseline Setting}\n\tHere, we present the detailed parameter setting of baselines. We mainly follow the original setting in the corresponding source code while adopting specific selections of parameters for better performance.\n\t\\begin{itemize}\n\t    \\item\\textbf{Prototypical Network (PN)}~\\cite{snell2017prototypical}: For PN, we set the learning rate as 0.005 with a weight decay of 0.0005. \n\t            \\item \\textbf{MAML}~\\cite{finn2017model}: The meta-learning rate is set as 0.001 and the number of update step is 10 with a learning rate of 0.01.\n    \\item \\textbf{GCN}~\\cite{kipf2017semi}: The learning rate is set as 0.001 and the hidden size of GCN is set as 32.\n    \\item \\textbf{G-Meta}~\\cite{huang2020graph}: For G-Meta, we set the meta-learning rate as 0.001. The number of update step is 10 and the update learning rate is 0.01. The dimension size of GNN is 128.\n\t    \\item \\textbf{GPN}~\\cite{ding2020graph}: For GPN, we follow the setting in the source code and set the learning rate as 0.005 with a weight decay of 0.0005. The dimension sizes of two GNNs used in GPN are set as 32 and 16, respectively.\n        \\item \\textbf{RALE}~\\cite{liu2021relative}: We follow the setting in the source code and set the learning rates for training and fine-tuning as\n0.001 and 0.01, respectively. The dropout rate is set as 0.6. The hidden size of used GNNs is 32.\n\n\t\\end{itemize}\n\t\n\t\\subsubsection{Dataset Description}\n\tIn this section, we describe the detailed dataset settings. Specifically, among the four prevalent datasets used in our experiments, \\texttt{Amazon-E}~\\cite{mcauley2015inferring} and \\texttt{DBLP}~\\cite{tang2008arnetminer} datasets are obtained from~\\cite{ding2020graph}, while \\texttt{Cora-full}~\\cite{bojchevski2018deep} and \\texttt{OGBN-arxiv}~\\cite{hu2020open} are obtained from the corresponding sources and processed by us. The statistics and details are as follows:\n\t\\label{appendix}\n\t\\begin{itemize}\n    \\item \\textbf{Amazon-E}~\\cite{mcauley2015inferring} is a product network, where nodes represent different \"Electronics\" products on Amazon. Moreover, edges are created according to the \"viewed\" relationship and class labels are assigned from the low-level product categories. For this dataset, we use 90/37/40 node classes for training/validation/test.\n    \\item \\textbf{DBLP}~\\cite{tang2008arnetminer} is a citation network. More specifically, each node represents a paper, and links are created according to the citation relations. The attributes are obtained via the paper abstract, and the class labels denote the paper venues. For this dataset, we use 80/27/30 node classes for training/validation/test.\n    \n    \n    \\item \\textbf{Cora-full}~\\cite{bojchevski2018deep} is a prevalent citation network, where nodes are labeled based on the paper topic. This dataset extends the prevalent small dataset via extracting original data from the entire network. For this\ndataset, we use 25/20/25 node classes for training/validation/test.\n    \\item \\textbf{OGBN-arxiv}~\\cite{hu2020open} is a directed citation network of all CS arXiv papers indexed by MAG~\\cite{wang2020microsoft}, where nodes represent arXiv papers and edges indicate citations. The feature of each node is a 128-dimensional feature vector obtained by averaging the embeddings of words in its title and abstract. The labels are assigned according to 40 subject areas of arXiv CS papers. We use 15/5/20 node classes for training/validation/test.\n\\end{itemize}\n\n\n\t\\end{appendices}\n\t\n\t% that's all folks\n"
            }
        },
        "tables": {
            "tab:statistics": "\\begin{table}[htbp]\n\t\n\t\t\\setlength\\tabcolsep{6pt}%\n\t\t\\small\n\t\t\\centering\n\t\t\\renewcommand{\\arraystretch}{1.2}\n\t\t\\caption{Statistics of four node classification datasets. }\n        \\vspace{-0.1in}\n\t\t\\begin{tabular}{c|c|c|c|c}\n\t\t\\hline\n        \\textbf{Dataset}&\\# Nodes & \\# Edges & \\# Features & Class Split\\\\\n        \\hline\n        \\texttt{Amazon-E}&42,318& 43,556&8,669& 90/37/40\\\\\n        \\texttt{DBLP}&40,672&288,270&7,202&80/27/30\\\\\n        \\texttt{Cora-full}&19,793&65,311&8,710&25/20/25\\\\\n        \\texttt{OGBN-arxiv}&169,343&1,166,243&128&15/5/20\\\\\n        \n        \\hline\n\t\t\\end{tabular}\n        \\vspace{-0.1in}\n\t\t\\label{tab:statistics}\n\t\\end{table}",
            "tab:all_result": "\\begin{table*}[htbp]\n\t\t\\small\n\t\t\\centering\n\t\t\\renewcommand{\\arraystretch}{1.2}\n\t\t\\caption{The overall few-shot node classification results (accuracy in \\%) of various models under different few-shot settings.}\n\n\t\t\\begin{tabular}{c||c|c|c|c||c|c|c|c}\n\t\t\t\\hline\n\t\t\t%\\multirow{2}{*}{Model}\n\t\t\tDataset&\\multicolumn{4}{c||}{\\texttt{DBLP}}&\\multicolumn{4}{c}{\\texttt{Amazon-E}}\n\t\t\t\\\\\n\t\t\t\\hline\n\t\t\tSetting&5-way 3-shot&5-way 5-shot&10-way 3-shot& 10-way 5-shot&5-way 3-shot&5-way 5-shot&10-way 3-shot& 10-way 5-shot\\\\\n\t\t\t\\hline\\hline\n\t\t\tPN~\\cite{snell2017prototypical}&$41.51\\pm3.60$&$46.17\\pm3.55$&$28.98\\pm3.87$&$36.71\\pm3.35$&$56.80\\pm3.60$&$62.53\\pm2.80$&$44.26\\pm2.64$&$48.20\\pm3.89$\\\\\\hline\n\t\t\tMAML~\\cite{finn2017model}&$43.06\\pm2.92$&$49.93\\pm2.57$&$34.63\\pm3.91$&$38.44\\pm3.25$&$56.03\\pm2.11$&$63.40\\pm3.33$&$40.80\\pm2.75$&$47.06\\pm3.15$\\\\\\hline\n\t\t\tGCN~\\cite{kipf2017semi}&$62.87\\pm1.44$&$70.51\\pm1.37$&$47.22\\pm2.97$&$53.95\\pm2.49$&$55.33\\pm1.23$&$62.96\\pm2.61$&$45.18\\pm2.61$&$50.89\\pm2.95$\\\\\\hline\n\t\t\tG-Meta~\\cite{huang2020graph}&$73.49\\pm2.82$&$78.56\\pm2.86$&$60.77\\pm3.03$&$66.26\\pm3.47$&$64.56\\pm4.23$&$68.36\\pm4.10$&$59.75\\pm4.90$&$63.02\\pm4.11$\\\\\\hline\n            GPN~\\cite{ding2020graph}&$76.42\\pm3.11$&$80.85\\pm3.68$&$63.14\\pm2.25$&$69.55\\pm2.56$&$65.16\\pm3.17$&$71.89\\pm3.94$&$62.52\\pm3.12$&$63.98\\pm2.04$\\\\\\hline\n            RALE~\\cite{liu2021relative}&$75.38\\pm4.94$&$79.85\\pm4.69$&$62.81\\pm3.48$&$67.61\\pm3.99$&$69.55\\pm4.24$&$74.97\\pm4.66$&$63.27\\pm3.31$&$64.85\\pm3.04$\\\\\\hline\n TENT&\\textbf{79.04} $\\pm$ \\textbf{3.14}&\\textbf{82.84} $\\pm$ \\textbf{3.97}&\\textbf{65.47} $\\pm$ \\textbf{4.21}&\\textbf{72.38} $\\pm$ \\textbf{4.14}&\\textbf{75.76} $\\pm$ \\textbf{3.63}&\\textbf{79.38} $\\pm$ \\textbf{4.98}&\\textbf{67.59} $\\pm$ \\textbf{4.16}&\\textbf{69.77} $\\pm$ \\textbf{3.76}\n\n\\\\\\hline\n\n\t\t\\end{tabular}\n\t\t\\label{tab:all_result}\n\t\t\\vspace{-0.1cm}\n\t\\end{table*}"
        },
        "figures": {
            "fig:intro": "\\begin{figure}[t]\n\t\t\t\t\t\n\t    \\centering\n\t    \\includegraphics[width=0.99\\linewidth]{illustration.pdf}\n\t    \\vspace{-2.5mm}\n\t    %\\caption{An example graph (left) and the overall process of few-shot node classification (right). }\n\t    \\caption{Issues of task variance of existing few-shot node classification frameworks.}\n\t    \\vspace{-5.5mm}\n\t    \\label{fig:intro}\n\t  \n\t\\end{figure}",
            "fig:model": "\\begin{figure*}[htbp]\n\t    \\centering\n\t    \\includegraphics[width=0.95\\textwidth]{model.pdf}\n\t    \\vspace{-0.1in}\n\t    \\caption{An illustration of the overall process of TENT. We first sample a meta-task from the given graph. Then we construct subgraphs for node-level adaptions and utilize node embeddings in each class for class-level adaptations. We further maximize the mutual information between the support set and the query set during query matching for task-level adaptations. }\n\t    %Given a graph, we first sample a support set and a query set from nodes this graph to construct an $N$-way $K$-shot task. Then the subgraphs are constructed according to each class in the support set. The 2-hop neighbors of the query nodes are also extracted for representation learning. After that, we employ a class-specific adapter to obtain class-specific encoders to learn representations for classes and query nodes with class-level adaptations. Finally, the task-level adaptation is conducted to incorporate the distribution of node representations in the support set. The last step is to optimize the model with the proposed contrastive loss and base loss. If the process is during test, we can further obtain the classification result based on similarities. }\n\n\t    \\label{fig:model}\n\t    \t    \\vspace{-0.1in}\n\t\\end{figure*}",
            "fig:ablation": "\\begin{figure}[!t]\n\t\t\\centering\n\\captionsetup[sub]{skip=-1pt}\n\\subcaptionbox{\\texttt{DBLP}}\n{\\includegraphics[width=0.23\\textwidth]{dblp_ablation.png}}\n\\subcaptionbox{\\texttt{Amazon-E}}\n{\\includegraphics[width=0.23\\textwidth]{amazone_ablation.png}}\n\\subcaptionbox{\\texttt{Cora-full}}\n{\\includegraphics[width=0.23\\textwidth]{cora_ablation.png}}\n\\subcaptionbox{\\texttt{OGBN-arxiv}}\n{\\includegraphics[width=0.23\\textwidth]{ogbn_ablation.png}}\n\\vspace{-0.1in}\n\t\t\\caption{Ablation study on our framework in the $N$-way $K$-shot setting.}\n\t\t\\label{fig:ablation}\n\\vspace{-0.12in}\n\t\\end{figure}",
            "fig:nk": "\\begin{figure}[!t]\n\t\t\\centering\n\\captionsetup[sub]{skip=-2pt}\n\\subcaptionbox{\\texttt{DBLP}}\n{\\includegraphics[width=0.23\\textwidth]{nk_dblp.png}}\n\\subcaptionbox{\\texttt{Amazon-E}}\n{\\includegraphics[width=0.23\\textwidth]{nk_amazon.png}}\n\\subcaptionbox{\\texttt{Cora-full}}\n{\\includegraphics[width=0.23\\textwidth]{nk_cora.png}}\n\\subcaptionbox{\\texttt{OGBN-arxiv}}\n{\\includegraphics[width=0.23\\textwidth]{nk_ogbn.png}}\n\\vspace{-0.1in}\n\t\t\\caption{Results of TENT with different $N_t$ and $K_t$.}\n\t\t\\label{fig:nk}\n\\vspace{-0.12in}\n\t\\end{figure}",
            "fig:Q": "\\begin{figure}[!t]\n\t\t\\centering\n\\captionsetup[sub]{skip=-2pt}\n\\subcaptionbox{\\texttt{DBLP}}\n{\\includegraphics[width=0.23\\textwidth]{Q_dblp.png}}\n\\subcaptionbox{\\texttt{Amazon-E}}\n{\\includegraphics[width=0.23\\textwidth]{Q_amazon.png}}\n\\subcaptionbox{\\texttt{Cora-full}}\n{\\includegraphics[width=0.23\\textwidth]{Q_cora.png}}\n\\subcaptionbox{\\texttt{OGBN-arxiv}}\n{\\includegraphics[width=0.23\\textwidth]{Q_ogbn.png}}\n\n\n\t\t\\caption{Results of TENT with different values of $|\\mathcal{Q}|$.}\n\t\t\\label{fig:Q}\n\\vspace{-0.15in}\n\t\\end{figure}"
        },
        "equations": {
            "eq:1": "\\begin{equation}\n\t    \\begin{aligned}\n\t    \\mathcal{S}_t&=\\{(v_1,y_1),(v_2,y_2),\\dotsc,(v_{N\\times K},y_{N\\times K})\\},\\\\\n\t    \\mathcal{Q}_t&=\\{(q_1,y'_1),(q_2,y'_2),\\dotsc,(q_{Q},y'_{Q})\\},\\\\\n\t    \\mathcal{T}_t&=\\{\\mathcal{S}_t,\\mathcal{Q}_t\\},\n\t    \\end{aligned}\n\t\\end{equation}",
            "eq:2": "\\begin{equation}\n\t    \\mathbf{H}=\\text{GNN}_\\phi(\\mathcal{V},\\mathcal{E},\\X),\n\t    \\label{eq:first-step emb}\n\t\\end{equation}",
            "eq:3": "\\begin{equation}\n\t    \\mathbf{h}_{c_i}=\\text{MEAN}(\\mathbf{h}_v|v\\in\\mathcal{S}_i),\n\t\\end{equation}",
            "eq:4": "\\begin{equation}\n\\alpha_i=\\text{MLP}_\\alpha \\left(\\text{MEAN}\\left(\\left\\{\\mathbf{h}_v|v\\in\\mathcal{S}_i\\right\\}\\right)\\right),\n\t\\end{equation}",
            "eq:5": "\\begin{equation}\n\\beta_i=\\text{MLP}_\\beta \\left(\\text{MEAN}\\left(\\left\\{\\mathbf{h}_v|v\\in\\mathcal{S}_i\\right\\}\\right)\\right),\n\\end{equation}",
            "eq:6": "\\begin{equation}\n\t    \\theta_i=(\\alpha_i+\\mathbf{1})\\circ\\theta+\\beta_i,\n\t    \\label{eq:adapt_class}\n\t\\end{equation}",
            "eq:7": "\\begin{equation}\n\t    \\mathbf{s}_i=\\text{Centroid}\\left(\\text{GNN}_{\\theta_i}(\\mathcal{V}_i,\\mathcal{E}_i,\\mathbf{X}_i)\\right),\n\t    \\label{eq:subgraph_representation}\n\t\\end{equation}",
            "eq:8": "\\begin{equation}\n\\alpha_q=\\text{MLP}_\\alpha \\left(\\text{MEAN}\\left(\\left\\{\\mathbf{h}_v|v\\in\\mathcal{S}\\right\\}\\right)\\right),\n\t\\end{equation}",
            "eq:9": "\\begin{equation}\n\\beta_q=\\text{MLP}_\\beta \\left(\\text{MEAN}\\left(\\left\\{\\mathbf{h}_v|v\\in\\mathcal{S}\\right\\}\\right)\\right),\n\\end{equation}",
            "eq:10": "\\begin{equation}\n\t    \\theta_q=(\\alpha_q+\\mathbf{1})\\circ\\theta+\\beta_q,\n\t    \\label{eq:adapt}\n\t\\end{equation}",
            "eq:11": "\\begin{equation}\n\t    \t    \\mathbf{q}_i=\\text{Centroid}\\left(\\text{GNN}_{\\theta_q}(\\mathcal{V}^q_i,\\mathcal{E}^q_i,\\mathbf{X}^q_i)\\right),\n\t\\end{equation}",
            "eq:12": "\\begin{equation}\n\t    \\max_{\\widetilde{\\theta}} I(\\mathbf{Q};\\mathbf{S})= \\max_{\\widetilde{\\theta}}\\sum\\limits_{i=1}^Q\\sum\\limits_{j=1}^Np(q_i,s_j;\\widetilde{\\theta})\\log\\frac{p(q_i|s_j;\\widetilde{\\theta})}{p(q_i;\\widetilde{\\theta})},\n\t\\end{equation}",
            "eq:13": "\\begin{equation}\n\t    I(\\mathbf{Q};\\mathbf{S})=\\sum\\limits_{i=1}^Q\\sum\\limits_{j=1}^Np(q_i|s_j;\\widetilde{\\theta})p(s_j;\\widetilde{\\theta})\\log\\frac{p(q_i|s_j;\\widetilde{\\theta})}{p(q_i;\\widetilde{\\theta})}.\n\t\\end{equation}",
            "eq:14": "\\begin{equation}\n\t    \\begin{aligned}\n\t        I(\\mathbf{Q};\\mathbf{S})\n\t        %&=\\frac{1}{N}\\sum\\limits_{i=1}^Q\\sum\\limits_{j=1}^Np(x_i|s_j;\\widetilde{\\theta})\\log\\frac{p(x_i|s_j;\\widetilde{\\theta})}{p(x_i;\\widetilde{\\theta})}\\\\\n\t        &=\\frac{1}{N}\\sum\\limits_{i=1}^Q\\sum\\limits_{j=1}^Np(q_i|s_j;\\widetilde{\\theta})\\log\\frac{p(s_j|q_i;\\widetilde{\\theta})}{p(s_j;\\widetilde{\\theta})}\\\\\n\t        &=\\frac{1}{N}\\sum\\limits_{i=1}^Q\\sum\\limits_{j=1}^Np(q_i|s_j;\\widetilde{\\theta})\\left(\\log(p(s_j|q_i;\\widetilde{\\theta}))-\\log\\left(\\frac{1}{N}\\right)\\right).\n\t    \\end{aligned}\n\t\\end{equation}",
            "eq:15": "\\begin{equation}\n\t    I(\\mathbf{Q};\\mathbf{S})=\\frac{1}{N}\\sum\\limits_{i=1}^Q\\sum\\limits_{j=1}^N\\mathbb{1}(q_i\\in s_j)\\left(\\log(p(s_j|q_i;\\widetilde{\\theta}))-\\log\\left(\\frac{1}{N}\\right)\\right).\n\t\\end{equation}",
            "eq:16": "\\begin{equation}\n\t    \\sum\\limits_{i=1}^Q\\sum\\limits_{j=1}^N\\mathbb{1}(q_i\\in s_j)\\log(p(s_j|q_i;\\widetilde{\\theta}))=\\sum\\limits_{i=1}^Q\\log(p(s'_i|q_i;\\widetilde{\\theta})),\n\t\\end{equation}",
            "eq:17": "\\begin{equation}\n\t\\begin{aligned}\n\t    I(\\mathbf{Q};\\mathbf{S})\n\t    &=\\sum\\limits_{i=1}^Q\\log(p(s'_i|q_i;\\widetilde{\\theta})).\n\t\\end{aligned}\n\t\\end{equation}",
            "eq:18": "\\begin{equation}\n        \\left.p(s'_i|q_i;\\widetilde{\\theta})=\\frac{\\exp\\left(-(\\mathbf{q}_i- \\mathbf{s}'_i)^2/\\tau_i'\\right)}{\\sum_{j=1}^N\\exp\\left(-(\\mathbf{q}_i-\\mathbf{s}_j)^2/\\tau_j\\right)}\n        \\right.,\n    \\end{equation}",
            "eq:19": "\\begin{equation}\n       \\max_{\\widetilde{\\theta}} I(\\mathcal{Q};\\mathcal{S})=\\min_{\\widetilde{\\theta}}\\sum\\limits_{i=1}^Q-\\log\\frac{\\exp(\\mathbf{q}_i\\cdot \\mathbf{s}'_i/\\tau'_i)}{\\sum_{j=1}^N\\exp(\\mathbf{q}_i\\cdot \\mathbf{s}_j/\\tau_j)}.\n       \\label{eq:objective}\n    \\end{equation}",
            "eq:20": "\\begin{equation}\n\t    \\tau_i=\\frac{N\\sum_k^K\\|\\mathbf{s}_i^k-\\mathbf{s}_i\\|_2}{\\sum_j^N\\sum_k^K\\|\\mathbf{s}_j^k-\\mathbf{s}_j\\|_2},\n\t\\end{equation}",
            "eq:21": "\\begin{equation}\n\t    \\mathcal{L}_{N}=-\\sum\\limits_{i=1}^Q\\log\\frac{\\exp(\\mathbf{q}_i\\cdot \\mathbf{s}'_i/\\tau'_i)}{\\sum_{j=1}^N\\exp(\\mathbf{q}_i\\cdot \\mathbf{s}_j/\\tau_j)}.\n\t    \\label{eq:Loss_N}\n\t\\end{equation}",
            "eq:22": "\\begin{equation}\n\t    \\mathbf{p}_i=\\text{Softmax}\\left(\\text{MLP}(\\mathbf{h}_i)   \\right),\n\t\\end{equation}",
            "eq:23": "\\begin{equation}\n\t    \\mathcal{L}_{CE}=-\\sum\\limits_{i=1}^Q\\sum\\limits_{j=1}^{|\\mathcal{C}_b|}y_{i,j}\\log p_{i,j},\n\t\\end{equation}",
            "eq:24": "\\begin{equation}\n\t    \\mathcal{L}=\\mathcal{L}_{N}+\\gamma\\mathcal{L}_{CE},\n\t    \\label{eq:final_loss}\n\t\\end{equation}"
        },
        "git_link": "https://github.com/SongW-SW/TENT"
    }
}