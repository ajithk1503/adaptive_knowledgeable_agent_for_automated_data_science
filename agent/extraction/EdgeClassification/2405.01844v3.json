{
    "meta_info": {
        "title": "A Survey on Privacy-Preserving Caching at Network Edge: Classification,  Solutions, and Challenges",
        "abstract": "Caching content at the edge network is a popular and effective technique\nwidely deployed to alleviate the burden of network backhaul, shorten service\ndelay and improve service quality. However, there has been some controversy\nover privacy violations in caching content at the edge network. On the one\nhand, the multi-access open edge network provides an ideal entrance or\ninterface for external attackers to obtain private data from edge caches by\nextracting sensitive information. On the other hand, privacy can be infringed\non by curious edge caching providers through caching trace analysis targeting\nthe achievement of better caching performance or higher profits. Therefore, an\nin-depth understanding of privacy issues in edge caching networks is vital and\nindispensable for creating a privacy-preserving caching service at the edge\nnetwork. In this article, we are among the first to fill this gap by examining\nprivacy-preserving techniques for caching content at the edge network. Firstly,\nwe provide an introduction to the background of privacy-preserving edge caching\n(PPEC). Next, we summarize the key privacy issues and present a taxonomy for\ncaching at the edge network from the perspective of private information.\nAdditionally, we conduct a retrospective review of the state-of-the-art\ncountermeasures against privacy leakage from content caching at the edge\nnetwork. Finally, we conclude the survey and envision challenges for future\nresearch.",
        "author": "Xianzhi Zhang, Yipeng Zhou, Di Wu, Quan Z. Sheng, Shazia Riaz, Miao Hu, Linchang Xiao",
        "link": "http://arxiv.org/abs/2405.01844v3",
        "category": [
            "cs.NI",
            "cs.CR",
            "cs.DC"
        ],
        "additionl_info": ""
    },
    "latex_extraction": {
        "content": {
            "section 1": {
                "name": "Introduction",
                "content": "\n%\u9610\u8ff0\u5927\u80cc\u666f\uff0c\u8fb9\u7f18\u7f13\u5b58\u8303\u5f0f\nContent caching at the edge network is driven by two factors. First, the population of networked devices has become astronomical due to advances in intelligent terminals and the broad deployment of the Internet of Things (IoT)~\\cite{Cui2022, Guo2022, Cui2023, Zhao2023}. Second, the Internet content market is blooming due to the proliferation of various multimedia content~\\cite{Zhang2022, Ni2021}. \n\\textcolor{black}{According to the report by Splunk, a Cisco company, there will be approximately 5.44 billion Internet users worldwide in 2024, including 5.07 billion social media users~\\cite{splunk2023internet}.}\n% It was reported by Cisco that\n%the consumer share of the total devices, including both fixed and mobile devices, will be more than 21 billion and account for 74\\% of total devices in 2023. \nAs a result, network-based content delivery services are extremely bandwidth-consuming. \n\\textcolor{black}{At the same time, emerging network technologies, such as Gigabit Ethernet, and 5G and beyond, are expected to provide extremely high data transmission rates and low access delays for terminal devices at the edge network to support time-sensitive services such as autonomous driving, industrial automation, high-quality video streaming, and virtual/enhanced emerging applications.}\n\n%network challenging\nSuch a vast data flow brings two main challenges to the established networks: (1) It brings a heavy communication burden to the Internet core network links. During the peak hours of network usage, a large amount of content transmission will inevitably aggravate the link burden of the core network, causing network congestion and increasing network operating costs; (2) It will also prolong the service delay of content transmission from remote servers to end devices, which will adversely influence users' service Quality-of-Experience (QoE) or even ruin the reliability of delay-sensitive applications.\n%There are two leading solutions to the above problems. One is to alleviate the network burden directly by maintaining a larger network capacity. However, due to the continuous data volume growth and complex resource request patterns changes, this solution has a very high maintenance cost.\n\n%edge cache\n%In order to alleviate the network burden, it is effective to explore and exploit Edge Cache (EC), which is deployed in the proximity of end users, to store requested content beforehand.\n%The edge cache network can serve the user directly if the requested content is available at the edge cache. Yet, if the requested content is missed at the edge, it can be redirected to a remote server (such as a data center).\n\n\\textcolor{black}{Edge Caching is a technique that involves storing content in close proximity to end users, typically at or near the point of user access or ahead of the core network~\\cite{Ni2021}.} Its primary objective is to shorten service latency and enhance content delivery performance by bringing content closer to the users who request it.\nWhen users request content that is available in \\textcolor{black}{edge caches (ECs)}, their requests can be directly served at the edge network with a high Quality-of-Service (QoS). \nHowever, if the requested content is not available in the EC, it can be redirected to a remote server, such as a data center.\n{\\color{black} Here, we make a brief introduction to edge caching from five aspects:}\n\n%the advantage of edge cache \n\\textcolor{black}{\\textit{\\textbf{Benefit of edge caching.}}} Caching content at the edge network is effective in reducing the burden of network backhaul~\\cite{Yang2019, Jiang2017, Qiao2022}, shortening service latency~\\cite{Zhang2022d, Qiao2022, Cui2020c}, and diminishing resource cost~\\cite{Jiang2017, Hassanpour2023}. First,  it is common to cache popular content at the edge network through which the edge network can offload the access of requests and hence reduce the backhaul data flow.\nEven though the caching capability is limited at the edge network, edge caches can offload up to 35\\% of the traffic burden over backhaul links ~\\cite{Ni2021}.  \nSecond,  the service latency can be shortened by caching content on edge devices near end users. In particular, a shortened latency is critical for content delivery of latency-sensitive applications~\\cite{Ni2021}. \nThird, edge networks can make content access inexpensive since caching content at edge devices can avoid the bottleneck. For example, in wireless edge networks, spectral efficiency and energy efficiency can be improved by about 900\\% and 500\\%, respectively, by using edge networks for caching content~\\cite{Liu2016}.\n%Therefore, caching at the edge can make data access less expensive on time, bandwidth, and resource costs.\n\n{\\color{black}\n\\textbf{Where to cache:} Building on the work of Ni~\\emph{et al.}~\\cite{Ni2021}, we further identify three main entities in edge networks for edge caching as follows: \n%i.e., \\textit{end devices}, \\textit{access infrastructures}, and \\textit{edge servers}:\n%In a typical edge network~\\cite{Ni2021}, there are three main entities for edge caching: \\textit{end devices}, \\textit{access networks} and \\textit{edge networks}:\n% \\begin{enumerate}\n    % \\item \n    (1) \\textit{End devices} (e.g., smartphones, laptops, intelligent vehicles, and industrial IoT devices) carried by users will generate requests for downloading content via networks~\\cite{Cui2022, Guo2022}. It is possible that end devices can share content through Device-to-Device (D2D) communications with licensed-band or unlicensed-band protocols.\n    % \\item \n    (2) \\textit{Access infrastructures}, utilizing wired and/or wireless communication technologies, can support end devices in accessing the Internet. These infrastructures include 5G small base stations (SBSs)~\\cite{Xu2019}, WiFi routers, local switches, and roadside units (RSUs) in the Internet of Vehicles (IoV)~\\cite{Cui2020, Zhang2022b}. Popular content can be cached within these access infrastructures to promptly serve user requests.\n    % \\item \n    (3) \\textit{Edge servers} (ESs) positioned ahead of the core network, such as edge nodes (ENs) in the Content Delivery Network (CDN)~\\cite{Cui2020c}, edge routers in the Information-Centric Network (ICN)~\\cite{Sivaraman2021, Xue2019, Xue2018}, and macro base stations operated by Internet service providers (ISPs)~\\cite{Araldo2018}, can be utilized as ECs, a concept known as \\textit{in-network-edge caching}. These ESs, typically maintained by third-party suppliers, are the core points for multi-access edge networks, enhancing various content delivery applications. \n% \\end{enumerate}\n\n\\textbf{What to Cache.} In edge caching systems, determining what content to cache is crucial for optimizing cache space utilization and reducing latency. The content to be cached generally falls into three categories:\n(1) \\textit{User-related popular content:} This includes content that is frequently requested by end users, such as web pages, videos, images, and other multimedia files~\\cite{Cui2020c,Wu2016}. Caching such content at the edge improves user experience by reducing service delay when users access commonly accessed content.\n(2) \\textit{Public and static content:} This category includes high-reuse, non-user-specific content associated with applications~\\cite{Ni2021}, such as JavaScript files, CSS stylesheets, icons, PDF documents, and API responses. Caching these static resources decreases application load times and reduces the burden on central servers.\n(3) \\textit{Edge-computable and storable content:} This includes data that can be computed and stored directly at the edge, such as model parameters for federated learning~\\cite{Liu2022,Qiao2022}, user patterns and content popularity for edge caching decisions~\\cite{Cui2020,Cui2020c}, and IoT sensor data awaiting processing~\\cite{Wang2020,Yu2021b}. Caching such content helps minimize backhaul traffic, enables efficient edge processing, and reduces overall latency by avoiding redundant computations.\n\n\n\\textbf{How to Cache.} Edge caching strategies can be broadly classified into reactive and proactive approaches.\n(1) \\textit{Reactive caching} employs eviction-based methods that decide whether to cache a specific content item only after it has been requested. This approach often relies on empirical formulas and classical caching algorithms, such as LRU (Least Recently Used) and LFU (Least Frequently Used), as well as their variants~\\cite{Famaey2013, Shafiq2014}. While these algorithms are simple and efficient, they frequently encounter challenges in selecting optimal parameter values, which can limit their performance in dynamic and diverse edge environments.\n(2) \\textit{Proactive caching} involves predictive methods to determine what content should be cached before any user requests are made. This approach leverages content popularity predictions and user behaviour profiles to make caching decisions at edge networks in advance. Advanced machine learning models, such as LSTM (Long Short-Term Memory) networks~\\cite{Feng2019}, are often employed to forecast content demand based on historical request patterns in proactive caching. These learning-driven methods generally offer superior caching performance compared to classical algorithms by automatically adjusting model parameters. However, they may require extensive computational capacity and high-quality training data, both of which may be often limited at the edge.} \n\n\n\n%privacy challenge of edge caching\n\\textcolor{black}{\\textit{\\textbf{Privacy concerns of edge caching.}}} \nDespite the enormous benefits brought by caching content at the edge network, there has been some controversy over privacy violations brought by such caching. \nThe concerns can be illustrated from two aspects. \n(1) The first privacy threat comes from external attackers, such as malicious user devices~\\cite{ Sivaraman2021, Liang2019, Acs2019, Qian2020, Cui2020c, Tong2022}. The multi-access open property of the edge network provides an ideal entrance or interface for external attackers to obtain the cached content from the edge cache to extract sensitive information of end users~\\cite{Xu2020}. Adversaries can obtain user-sensitive information by launching cache side-channel attacks~\\cite{Sivaraman2021, Liang2019, Acs2019} and cache tampering attacks~\\cite{Qian2020, Cui2020c, Tong2022}. \nHowever, it is non-trivial to embed advanced privacy protection mechanisms into edge networks due to the limited computing capacity, energy power, and storage space of edge devices.\n(2) Second, user privacy can be infringed by curious edge caching providers by analyzing traces and management records. Due to limited caching space relative to the rapidly growing user population and the scale of content~\\cite{Zhou2019}, edge network providers have a strong motivation to spy on user privacy in order to improve their resource utilization.  In other words, if content popularity can be accurately predicted, the right content can be cached by edge devices just before the surge of requests towards content~\\cite{Zhang2022}. Hence, edge network providers are curious about users' personal interests and confidential information to infer their request behaviours, which can be extracted from users' historical request traces (e.g., request patterns~\\cite{Zhang2022, Cui2020, Cui2020c}, identifiable information~\\cite{Zhang2022b, Zhu2021, Araldo2018, Cui2020, Cui2020c}).\nEdge network providers can implement monitoring attacks~\\cite{Xue2018, Zhang2022b} and inference attacks~\\cite{Qiao2022, Liu2022} in their systems to compromise users' privacy based on collected request information from users.   \nTherefore, an in-depth understanding of privacy risks in privacy-preserving edge caching (PPEC) is crucial for the design of feasible solutions to achieve privacy-preserving content cache at the edge network. \n\n\n\n\\begin{comment}\n \\subsubsection*{\\bf What is privacy information}\n\n\\subsubsection*{\\bf Who have privacy information}\n\n\\subsubsection*{\\bf Who are curious about others' privacy}\n\n\\subsubsection*{\\bf Privacy threat model}\n\n\\subsubsection*{\\bf Mainly mitigation methods}   \n\\end{comment}\n\n\n%\\subsection{Review of Existing Surveys and Overview Literature}\n\n\\textcolor{black}{\\textit{\\textbf{Our contributions.}} Recently, significant progress has been made in enhancing privacy protection for content caching at edge networks.  \nHowever, these works fail to provide a comprehensive discussion of the privacy issues in edge caching systems. For instance, Ren \\emph{et al.}~\\cite{Ren2019} primarily discuss the state-of-the-art researches on caching and privacy, respectively, in emerging edge computing paradigms. Besides, most surveys only discuss privacy issues for particular scenarios, \nsuch as IoT~\\cite{Lidia2023, Kinza2021}, edge intelligence~\\cite{Zhang2021}, the metaverse~\\cite{Yazan2024}, and federated learning (FL)~\\cite{Paolo2021}, while overlooking the distinct aspects of edge caching. The surveys in~\\cite{Ni2021, Xiao2018a} addressed privacy-preserving solutions and countermeasures for edge caching without covering all relevant issues in a thorough manner.\nIn particular, there has been a lack of comprehensive discussion of protection methods targeting different types of private information in PPEC.\nGiven these limitations and the absence of comprehensive literature reviews, this article aims to thoroughly examine and categorize current works on privacy issues in edge caching scenarios.}\n% Some of these papers are surveys related to the privacy of EC, in general, without considering the EC aspect~\\cite{} \n% Although there are existing surveys related to privacy in the context of EC~\\cite{}, \n% There are several published research works aimed at addressing the issues mentioned above. \n%aims to mitigate and overcome these shortcomings. Generally, this article provides a comprehensive literature survey on privacy issues in the context of edge cache. \nThe main contributions of this article are summarized as follows:\n% \\begin{enumerate}\n% \\item \n(1) We make in-depth discussions on sensitive information in edge caching and propose a taxonomy from a private information perspective to classify existing works. \nTo the best of our knowledge, this is the first such comprehensive exposition.\n% \\item  \n(2) We conduct a thorough review of recent high-quality research, diving into the background of privacy attacks and mitigation methods in the realm of edge caching. Our review encompasses the latest solutions proposed for enhancing privacy in edge caching, \\textcolor{black}{which have been published in \n%influential \nleading \nconferences and journals in the fields of computing networks, architecture, and privacy, such as CCS, INFOCOM, ToN, JSAC, TPDS, TIFS, and TDSC, as well as other top venues.} \n%leading publications.}\n%We present the recent efforts through classifications of data threats and mitigated strategies. \nBased on different kinds of privacy information and attacks towards each kind of privacy information, we respectively review countermeasures to defend against attacks for protecting each kind of infringed privacy.\n%\\item We discuss existing works on content caching at the edge network from two perspectives: privacy information that can be leaked by caching content at the edge network and attacks that target to infringe user privacy through edge caching. \n%analyze and summarize edge cache's most prominent privacy issues from three perspectives, including private data, privacy attacks and mitigated methods. We propose the classification methods based on the three critical issues and classify the recent and related efforts as convenient for readers to refer to.\n%Then, we retrospectively review the possible solutions and for alleviating the exposed threats of different private data through classifications of data threats and mitigated strategies. We also summarize some of the most recent research efforts pertaining to privacy in the context of PPEC. Hence, the reader will be provided with an in-depth analysis of what data exposures have surfaced in EC, what countermeasures have been considered in the literature to mitigate them, and which threats still lurk.\n% \\item \n(3) Based on open problems outlined in existing works, we envision privacy-related open challenges in PPEC to provide insights for inspiring future research. \n%provide deep insights into some promising future research directions in the context of the edge-compting-assisted cache paradigm.\n% \\end{enumerate}\n\n\\textcolor{black}{\\textit{\\textbf{Paper outline.}}} The remainder of this article is organized as follows.\nSection~\\ref{sec: Classification for data issues} provides an introduction to the taxonomy of privacy-preserving solutions that are based on the protection of sensitive information data in edge caching.\nSection~\\ref{sec: issues} provides a background discussion on privacy issues in the edge caching paradigm from two plain perspectives, i.e., privacy attacks and mitigation methods. %Additionally, based on these discussions, we give preliminary classifications for privacy-preserving solutions in the edge cache. \nFrom Section~\\ref{sec: user privacy} to Section~\\ref{sec: knowledge privacy}, we describe the possible privacy mitigation solutions for edge caching in correspondence with three main classes of privacy, i.e., user privacy, content privacy and knowledge privacy, respectively. %Taxonomies based on private data and mitigating methods are adopted to review the privacy-aware caching solutions in these three sections.\n%Section \\ref{sec: solution} also gives a comprehensive analysis of privacy issues for edge cache. \nSection~\\ref{sec: Future Directions} provides open challenges and future research directions.\nFinally, we make a summary in Section~\\ref{sec: Conclusion}. To facilitate readability, we have compiled a summary of commonly used abbreviations for the solutions in Table~\\ref{tab:abbreviations} in Appendix.\n%The organization of this article is illustrated in Fig. \\ref{}.\n\n\n\n\n\n\n"
            },
            "section 2": {
                "name": "Overview of Private Information in Edge Caching",
                "content": "\\label{sec: Classification for data issues}\n\n%In the context of edge cache, privacy concerns arise due to users' and edge servers' potential leakage of sensitive information. Users can leak specific individual private information such as personal information, location, content privacy, and browsing record through their requests to the edge server. Specifically, as a generator in mobile social networks~\\cite{Wang2019, Zhou2019}, the content privacy of user data cached and delivered by edge servers is also fragile. On the other hand, edge servers can leak different kinds of private information extracted from aggregated request traces of multiple users, such as machine learning knowledge, content privacy, and content popularity. \n%Therefore, it is crucial to consider privacy concerns from data perspectives in designing and implementing privacy-preserving edge caching solutions.\n%In Fig.~\\ref{fig:Private data in edge cache}, we present the main types of private information that participants in the edge cache can reveal.  There are six types of sensitive information: request traces, personal information, location, machine learning knowledge, content privacy, and content popularity. \n%{\\color{black}\\bf YP: based on fig1, need to explain from a high level that users and edge servers leak different kinds of private information. For example, edge server mainly leaks knowledge extracted from aggregated request traces of multiple users. while  users leak specific individual private information. }\nIn this section, we overview sensitive information that should be protected to avoid privacy leakage in PPEC. \nIn the realm of edge caching, sensitive information can be exposed by either users~\\cite{Acs2019} unconsciously or edge servers~\\cite{Cui2020,Araldo2018}. Specifically, users' sensitive information includes personal information, browsing history, location, and private content data, through their request traces to the ES or other service providers. \n% For example, in mobile social networks, user-generated content, which is sensitive and confidential, can be cached and distributed by edge servers~\\cite{Wang2019, Zhou2019}.\nSimilarly, edge servers can leak their private information and extract knowledge from a collection of users who have interacted with edge servers\\cite{Cui2020,Cui2020c}. \n% For example, edge servers may leak video content popularity (extracted from user request traces) to malicious users~\\cite{Cui2020,Cui2020c}.\nTherefore, to build a privacy-preserving content caching system, the first step is to understand what private information can be exposed by users and edge servers. \nIn Fig.~\\ref{fig: Private data in edge cache}, we outline all kinds of sensitive information that should be protected in PPEC. We will elaborate on each kind of private information in this section.\n\n%For ease of reference, Table~\\ref{Tab: countermeasures} presents a summarized matrix categorization of solutions based on the employed mitigation methods and the types of private data involved.\n\n\n\\begin{comment}\n  \\subsection*{Paper Motivation, Contribution, and Outlines}\n\\begin{enumerate}[1)]\n    \\item Paper Motivation\n    \\item Main Contributions\n    \\item Paper Organization\n\\end{enumerate}  \n\\end{comment}\n\n\n\n",
                "subsection 2.1": {
                    "name": "User Privacy",
                    "content": "\n\nIn PPEC, all information related to users but not directly related to cached content is regarded as user privacy such as users' historical records, age, gender, and location. For our discussion, we classify all user privacy information into three types: \\textit{request trace}, \\textit{personal information} and \\textit{location}. \n\n",
                    "subsubsection 2.1.1": {
                        "name": "Request trace",
                        "content": "\n%\u5b9a\u4e49\n{\\color{black}\nA request trace refers to a sequence of content requests and responses between an end device and ESs or service providers.\nThese traces often contain private information such as request patterns~\\cite{Acs2019, Liang2019}, preferences~\\cite{Cui2020, Qian2020}, and interests~\\cite{Sivaraman2021, Cui2020c}. %movement patterns~\\cite{Zhang2022a}. \nAdvertisers or malicious attackers can exploit such information to make profits or harm.\n%\u4e3a\u4ec0\u4e48\u4f1a\u66b4\u9732\u9690\u79c1\nAdditionally, user request traces are valuable assets to service providers and caching systems. \nService or content providers can analyze these request traces to infer users' behaviour patterns, such as the type of websites or applications they frequently use and the content they prefer to consume. ESs can maintain and analyze request traces to improve caching performance by predicting future requests, allowing for prefetching and caching popular content in advance. \n\n%\u6709\u54ea\u4e9b\u53ef\u80fd\u9014\u5f84\u66b4\u9732\u9690\u79c1\u53ca\u6cc4\u9732\u5371\u5bb3\nThere are primary two risks associated with request traces: \\textit{interception} and \\textit{misuse}. First, request records can be intercepted and sniffed by other users and external attackers. For example, malicious users can use timing attacks~\\cite{Sivaraman2021, Acs2019} to impersonate legitimate users, sending requests to the server. Attackers may then infer user request traces by exploiting the timing difference between cached and non-cached responses~\\cite{Sivaraman2021, Acs2019}, facilitating illegal advertising and cache pollution attacks~\\cite{Wu2016}. \nSecond, edge servers and service providers, curious about user interest patterns, may misuse request traces for their purposes. For example, request traces can be exploited to develop trace-driven content caching algorithms, posing privacy threats from untrusted or profit-driven third-party edge servers~\\cite{Araldo2018, Cui2020, Schlegel2022, Tong2022}. \n%\u56f0\u96be\u6027\n\nHowever, designing methods to preserve user privacy in edge caching systems is non-trivial. Most existing privacy-enhancing approaches fail to effectively address the privacy leakage risks users face in caching systems, as request records cannot be arbitrarily altered or obfuscated by users and must remain visible to service providers and edge caching servers to provide reliable services.\n}\n\n\n\n\n\n\n%Moreover, end users find it difficult to prevent the exposure of their request traces from edge servers that . \n%are used for content delivery. Therefore, ensuring the privacy of request records is essential in edge cache architectures.\n\n\n \n%Therefore, privacy-preserving measures must be adopted in edge caching to ensure efficient caching and content delivery while protecting users' privacy. However, this remains some challenges, as\n %When users retrieve content from edge servers, their request traces are automatically collected by the edge servers.\n%Attackers can obtain user request records through various methods such as timing attacks, through which \n%attackers pretend to be the normal user who sends content requests to the server. Then, attackers may infer user request traces by exploiting the timing difference between cached and non-cached responses~\\cite{Sivaraman2021, Acs2019}. %{\\bf YP:  Can you explain what is timing attack?} \n%It is challenging to accurately distinguish between benign and malicious users' access requests in an open-edge environment.  %, further highlighting the need for adequate privacy protection measures.\n\n%{\\color{black} \\bf YP: why we need to discuss protection methods superficially here? }\n%The methods to protect the user's request records mainly include using differential privacy technology~\\cite{Zhang2018,Wang2019,Zhou2019,Zhang2022a,Sivaraman2021}, record confusion\\cite{Wu2016,Nikolaou2016,Qian2020}, encrypted communication\\cite{Leguay2017,Yuan2016a,Cui2020c,Jiang2020}, and private information retrieval technology\\cite{Tong2022,Yan2021,Kumar2019}.\n\n\n\n\n\n\n\n\n"
                    },
                    "subsubsection 2.1.2": {
                        "name": "Personal information",
                        "content": " \n\n%\u5b9a\u4e49\nPersonal information is a type of private information that can be % compromised in edge caching, which can be \nmined to identify a specific end device or user in the network. % or reflect the activities of a particular entity.\n%\u4e3a\u4ec0\u4e48\u4f1a\u66b4\u9732\u9690\u79c1,\u6709\u54ea\u4e9b\u53ef\u80fd\u9014\u5f84\u66b4\u9732\u9690\u79c1\nEdge caching servers and service providers can obtain various types of personal information from users, depending on the specific context and implementation of the edge caching system. Typical examples of personal information that can be compromised in edge caching include:\n(1) Identifier information such as pseudonyms and IP addresses. %, which are essential personal information related to end devices or users. For example, \nIn particular, through IP addresses, we can identify a user's Internet service provider (ISP), approximate location, and other information, with which the edge cache (EC) can carry out sensitive operations, such as integrity verification~\\cite{Tong2022} and cache admission control~\\cite{Xue2019, Xue2018}. \n(2) Device information such as the operating system, connection type, browser type, and version, which is also essential for edge servers to provide high-performance edge caching and tailored content to users~\\cite{Zhang2022b, Cui2022}. % device.\n(3) Account-related information such as email address, gender, age, payment, and social relation, which can be captured by ECs or service providers when a user logs in or creates an account to access the service, potentially revealing more personal privacy~\\cite{Zhang2022b, Cui2020c}.\n\n%\u6cc4\u9732\u5371\u5bb3\nExcessively exposing personal information by edge caching can result in annoying tracking and profiling. \n%When personal information is collected, edge caching servers and service providers can create detailed profiles of users, including their browsing habits and interests. \n\\textcolor{black}{When personal information is collected, edge caching servers and service providers can create detailed user profiles, encompassing browsing habits and interests. By identifying specific users or user groups, service providers can accurately predict future requests, allowing for content prefetching to reduce latency and improve Quality-of-Service (QoS). Additionally, detailed profiles facilitate targeted advertising and personalized recommendations, potentially increasing revenue. However, these practices raise ethical concerns~\\cite{Zhang2022b, Cui2022}, including the potential for manipulation or discrimination against certain user groups.}\n% This information can be harnessed for making caching decisions, targeted advertising, or even more malicious purposes such as manipulation or discrimination~\\cite{Zhang2022b, Cui2022}. \nIn addition, malicious nodes and attackers can take advantage of excessive disclosure of personal information to gain unauthorized access to user accounts~\\cite{Xue2019, Xue2018} and pull off cache tampering attacks~\\cite{Cui2022, Cui2020c, Tong2022}, resulting in financial losses and other harms.\n\n\n"
                    },
                    "subsubsection 2.1.3": {
                        "name": "Location",
                        "content": "\n%\u5b9a\u4e49\n%Location information is also critical privacy data with a high value, implying moving objects, spatial coordinates, current time, and unique features. There are two fundamental types of location information in edge caching problems. One is the location information~\\cite{} of the user itself, and the other is the location information~\\cite{} of the user's interest, also known as the point of interest (POI). \nLocation information is a critical type of privacy data carrying location,  spatial coordinates, and the current time of moving objects. In edge caching systems, there are two fundamental types of location information: users'  location information and Point of Interests (POIs).\n%\u4e3a\u4ec0\u4e48\u4f1a\u66b4\u9732\u9690\u79c1,\u6709\u54ea\u4e9b\u53ef\u80fd\u9014\u5f84\u66b4\u9732\u9690\u79c1\nWhen users access edge caching systems, they may unconsciously expose private location information in the following processes: (1) A user's geographic location can be exposed to the EC when accessing content or services directly from the EC~\\cite{Cui2020b}; (2) Content providers (CP) and Edge Caching providers can proactively collect users' geographic location information to provide better content distribution services, such as predicting user moving patterns~\\cite{Zhang2022a}; (3) In location-based services (LBS), users may provide their private geographic information and POIs to search for their interests in the EC~\\cite{Amini2011, Cui2020b, GUYi-mingBAIGuang-weiSHENHang, Nisha2022}. This information can be abused, resulting in undesired tracking and profiling or even more severe consequences, such as location-based attacks.\n\n%\u6cc4\u9732\u5371\u5bb3\nLocation information is sensitive and can be utilized to learn an individual's daily routine and movements. Service providers can use this information to deliver more relevant advertisements and cached content to users, potentially boosting profits. Yet, if malicious attackers obtain location information, it can put users at risk of physical harm. Malicious attackers can use location information to track a user's movement trajectories and potentially cause harm, particularly in the case of stalking or other criminal activities. %Therefore, protecting location information is crucial for preserving user privacy in edge caching systems.\n\n%At such,  noise-based methods are mainly introduced to protect location privacy, including geographic differential privacy\\cite{Zhang2022a}, Spatial Confusion\\cite{Amini2011, GUYi-mingBAIGuang-weiSHENHang, Zhang2019b}, Anonymity\\cite{Cui2020b, Nisha2022, Yang2016, Sen2018, Zhang2019b}.\n\n\n\n\n\n\n\n\n\n"
                    }
                },
                "subsection 2.2": {
                    "name": "Content Privacy",
                    "content": "\n\nContent privacy refers to privacy information contained by the content stored and transmitted through edge caching systems, mainly including \\textit{private content} and \\textit{content popularity}. \n\n",
                    "subsubsection 2.2.1": {
                        "name": "Private content",
                        "content": "\n%\u5b9a\u4e49\n%Content privacy in edge cache refers to the privacy of the content stored and transmitted through edge caching systems. Protecting content privacy is crucial if the cached content itself is sensitive, including confidential information such as personal and financial data, confidential business information, and government secrets. % may be transmitted through edge caching systems. \n\n\\textcolor{black}{\nPrivate content refers to sensitive and confidential data that is stored and potentially cached by edge systems. We name such sensitive content data in edge caching systems as \\textit{``private content\"}. Given its sensitive nature, private content requires strict privacy protections to prevent unauthorized access and misuse. This type of content includes but is not limited to, video clips, photos, social media, and textual data from users, copyrighted materials, confidential business documents, and government secrets.}\n% Content cached by the edge system may reveal \n% sensitive and private information, and therefore it is essential to protect the privacy of such content, particularly when it includes confidential information, e.g., personal and financial data, confidential business information, and government secrets. We name such sensitive cached content data as \\textit{``private content\"}.\nFor example, in mobile social networks, each user can be regarded as a content provider who can produce fresh content desiring that their content can be efficiently and accurately delivered to consumers~\\cite{Xu2019, Zhou2019}. In this case,  edge computing is a feasible architecture for caching and delivering the content. Consumers in proximity ~\\cite{Zhang2022a, Xu2020} or with close social relations~\\cite{Wang2019} to a particular user content provider in social networks are more likely to request this content.  Thereby, using an edge server to cache and deliver content in mobile social networks can diminish bandwidth costs, which however raises privacy leakage risks. \n\n%\u4e3a\u4ec0\u4e48\u4f1a\u66b4\u9732\u9690\u79c1,\u6709\u54ea\u4e9b\u53ef\u80fd\u9014\u5f84\u66b4\u9732\u9690\u79c1\nBriefly speaking, private content privacy can be infringed in several ways. \nFirst, edge servers are not trustworthy and can expose cached content to the public. Second,  malicious and unauthorized users at the edge network can access cached content during transmission or processing between end users and the EC or between different ECs.\nFor instance, in cache side-channel attacks~\\cite{Sivaraman2021, Liang2019}, attackers attempt to access cached content by sending targeted requests, potentially allowing them to view sensitive information. For another instance, attackers can lodge cache tampering by injecting malicious content into the cache to exploit vulnerabilities in end-user systems or steal sensitive information~\\cite{Qian2020, Cui2020c, Tong2022}. %These threats to content privacy are severe, requiring robust privacy-preserving or even security measures to protect against privacy leakage.\n\n\n"
                    },
                    "subsubsection 2.2.2": {
                        "name": "Content popularity",
                        "content": "\nContent popularity can be defined as the relative frequency of a particular content to be requested by users.  It indicates the level of popularity of content among users. The popularity information is broadly utilized in improving caching efficiency, and caching the most popular content can effectively lower the content delivery cost. However, the popularity information is sensitive, unveiling the private preference information of users~\\cite{Cui2020c, Yu2021b}.\nBesides, it is possible that content popularity information can reveal sensitive information about content providers, such as their financial success and strategic direction, which should be kept confidentially~\\cite{Araldo2018, Cui2020c}.\n\n\\textcolor{black}{\nThe popularity information is crucial for making effective edge caching decisions but is highly susceptible to leakage. \nFirstly, popularity information may be leaked during cooperative caching decision-making processes among edge caches. For instance, as the number of records owned by a single ES is limited, content providers may need to provide supplementary information~\\cite{Araldo2018}. Additionally, edge caching servers may exchange popularity information to optimize caching decisions across the entire system~\\cite{Yu2021b, Cui2020c}. Privacy leakage can occur because ESs might be untrusted, or the edge environment itself may be vulnerable to attacks~\\cite{Cui2020c}. \nSecondly, popularity information can also be compromised through well-decided caching content. For example, through broadcasting cached content lists~\\cite{Cui2020, Ni2021} or timing attacks~\\cite{Sivaraman2021, Zhang2022b}, malicious entities can infer which content is more popular. This sensitive information, once exposed and tampered with, can be exploited to obtain illegal benefits, manipulate cache performance~\\cite{Cui2020c, Tong2022}, or even launch cache tampering attacks~\\cite{Cui2020c, Xu2020}.\nEspecially, as content popularity can describe specific content attributes and serve as key knowledge to improve caching efficiency, we consider it a unique type of information that intersects both content privacy and knowledge privacy, as shown in Fig.~\\ref{fig: Private data in edge cache}.\n}\n\n% The popularity information is crucial for making effective edge caching decisions. \n% As the number of records owned by a single ES is limited, content providers may need to provide supplementary information. For example, edge caching servers can mutually exchange popularity information to optimize edge caching decisions for the entire caching system~\\cite{Yu2021b, Cui2020c}.  Yet, this practice exposes the relative popularity of different content on edge. Furthermore, when the cache is full, the ES must decide which content to remove to save space, revealing popularity information as well~\\cite{Acs2019}. \n%Therefore, it is critical to protect and balance the interests of all parties involved and improve the cache system's efficiency through further research.\n\n\n\n\\begin{comment}\n\\subsubsection{\\textbf{Classification based on Private Data (From Defense Perspective)}}\n\\begin{enumerate}[1)]\n    \\item Users' trace (users' preference):\\cite{Liang2019}\\cite{Zhong2021}\\cite{Xue2019}\\cite{Zhang2019b}\\cite{Cui2020b}\\cite{Zhang2018}\\cite{Wang2019}\\cite{Zhou2019}\\cite{Cui2020}\\cite{Cui2020c}\\cite{Acs2019}\\cite{Wu2016}\\cite{Nikolaou2016}\\cite{Xue2018}\\cite{Zhang2022a}\\cite{Jiang2020a,Zheng2022,Kumar2019,Hassanpour2023,Schlegel2022,Silva2019,Yan2021,Zhang2022b,Qian2020,Wang2022,Wang2022a,Pu2019,Sivaraman2021}\n    \\item Users' Location:\n\\cite{Zhang2019b}\\cite{Nisha2022}\\cite{Cui2020b}\\cite{Amini2011}\\cite{Sen2018}\\cite{Andreoletti2018}\\cite{Hu2018}\\cite{Ko2020}\\cite{GUYi-mingBAIGuang-weiSHENHang}\\cite{Zhang2022a}\\cite{Yang2016}\n    \\item Users' Identity and other personal Information:\\cite{Kong2019}\\cite{Xue2019}\\cite{Lei2020}\\cite{Vu2019}\\cite{Dai2020}\\cite{Zeng2020}\\cite{Yu2020a}\\cite{Xue2018}\\cite{Zhu2021}\n    \\item Users' Private Data (e.g., Machine Learning Model Parameters):\\cite{Kong2019}\\cite{Wang2022a}\\cite{Cheng2021}\\cite{Pu2019}\\cite{Lei2020}\\cite{Wang2020}\\cite{Yu2018}\\cite{Xu2020}\\cite{Saputra2022}\\cite{Wang2019a}\\cite{Yu2020}\\cite{Qi2020}\\cite{Tong2022}\\cite{Yu2020a}\\cite{Zheng2022}\\cite{Jiang2020a}\\cite{Yu2021}\\cite{Pan2019,Qiao2022,Wu2020,Leguay2017,Liu2022,Li2020a,Xu2019,Shi2018,Zhu2021}\\cite{Yu2021b}\n    \\item Content Popularity:\\cite{Andreoletti2019}\\cite{Araldo2018}\\cite{Wang2019}\\cite{Andreoletti2018}\\cite{Cui2020c}\\cite{Andreoletti2019a}\\cite{Yuan2016a,Yu2021b}\n    \\item Content Information:\n    \\item Others...\n\\end{enumerate}\n\\end{comment}\n\n\n\n \n\n\n\n\n\n\n"
                    }
                },
                "subsection 2.3": {
                    "name": "Knowledge Privacy",
                    "content": "\n%\\subsubsection{\\textbf{Extracted knowledge}} \n%\u5b9a\u4e49\n%The knowledge is represented by model parameters and features learned from the dataset during the training process. \n\\textcolor{black}{\nKnowledge privacy refers to the insights, patterns, and parameters derived from datasets processed by machine learning models, typically owned by ECs or other service providers. Unlike user privacy and content privacy, which focus on data directly linked to users or content, knowledge privacy involves higher-level abstractions extracted from these data sources. In edge caching, service providers are particularly interested in the knowledge extracted from original datasets, as it is valuable for improving caching performance. For example, by leveraging prediction models based on this extracted knowledge, providers can make effective caching decisions in dynamic scenarios~\\cite{Muller2017, Yang2019}, leading to significant improvements in edge caching performance~\\cite{Ma2017b, Dhar2011, Zhang2022, Zhang2022a, Zhang2022b}.\nLearning-based methods offer a feasible framework for making effective edge caching decisions, but they also pose risks of private information leakage during model training and prediction phases. Therefore, it is crucial to carefully consider and mitigate these privacy risks when employing learning-based methods for edge caching.\n% Extracted knowledge refers to the insights and patterns learned by training machine learning models on datasets collected from users. \n% The extracted knowledge is widely used to predict the future request patterns of users in a dynamic system, enabling providers to make effective caching decisions~\\cite{Muller2017, Yang2019}. For instance, video request access patterns are driven by users' interests in different locations~\\cite{Ma2017b, Dhar2011}, and users may move dynamically~\\cite{Zhang2022a, Zhang2022b} with their interests changing over time~\\cite{Zhang2022}. By relying on predictions based on the knowledge extracted from users' historical request records, edge caching performance can be significantly improved. \n}\n%\u4e3a\u4ec0\u4e48\u4f1a\u66b4\u9732\u9690\u79c1,\u6709\u54ea\u4e9b\u53ef\u80fd\u9014\u5f84\u66b4\u9732\u9690\u79c1\n%In the following sections, we dive into the details of solutions designed to protect three classes of private information in the edge cache. \n%The Federated learning\\cite{Qiao2022,Liu2022,Li2020a,Wang2020,Yu2018,Wang2019a,Yu2020,Qi2020,Zheng2021,Yu2020a,Zheng2022,Chen2022,Yu2021b,Cui2022,Wang2022a,Wang2022,Saputra2022,Cheng2021} framework is one of the essential methods to preserve private data in the machine learning process.\n\n\n\n\n"
                }
            },
            "section 3": {
                "name": "Overview of Attack and Defence Methods",
                "content": "\\label{sec: issues}\n\n%In this section, we offer a comprehensive background discussion on privacy concerns within the edge caching paradigm. Building upon these discussions, we present categorizations of private data, privacy attacks, and mitigated countermeasures to develop privacy-preserving solutions for the edge cache. \n\n\\textcolor{black}{\nThis section is divided into two parts: an overview of attack methods targeting each type of sensitive information in edge caching systems and a summary of defense methods against each type of attack. In Figs.~\\ref{fig: relation-attack-information}-\\ref{fig: relation-protection-information}, we present a relational map that illustrates the connections between potential privacy attacks, defense methods, and sensitive information in edge caching systems. In the remainder of this section, we briefly discuss each type of attack and defense methods as depicted in Fig.~\\ref{fig: relation-attack-information} and Fig.~\\ref{fig: relation-protection-information}, respectively.}\n% On the left-hand side of Fig.~\\ref{fig: relation-attack-information},  we overview the types of private information that attack methods can invade. On the right-hand side of Fig.~\\ref{fig: relation}, we overview defence methods that can be used to protect each type of private information. \n% In the rest of this section, we briefly discuss each type of attack and defence method covered by Fig.~\\ref{fig: relation-attack-information} and Fig.~\\ref{fig: relation-protection-information}, respectively. \n\n",
                "subsection 3.1": {
                    "name": "Privacy Attack in Edge Caching Systems",
                    "content": " \n\nThere are mainly four types of privacy attacks in edge caching systems, which are \\textit{monitoring attacks}, \\textit{data mining attacks}, \\textit{cache side-channel attacks} and \\textit{cache tampering attacks}. \nWe introduce these attacks with potential risk entities in this subsection.\n%Table \\ref{Tab: attacks classification} presents an attack method classification matrix based on privacy attack methods and the type of privacy targeted by each attack. \n%We also present a method classification matrix based on the victim entity suffering privacy attacks and types of leaked privacy information in Table \\ref{Tab: risk entities classification} for easy reference.\n\n",
                    "subsubsection 3.1.1": {
                        "name": "Monitoring attack",
                        "content": "\nMonitoring attacks, also known as eavesdropping attacks, can be divided into two main categories:\n(1) The first is sniffing attacks on network communications, i.e., an adversary sniffs on network traffic through the edge caching node to read or intercept private information in network packets~\\cite{Zhang2022b}. \nFor example, the EC can monitor user requests during the caching service process. In other words, the edge caching operator can monitor users' requests intended to responding end users' requests and improve the caching efficiency. \nThrough subsequent data analysis, edge caching managers can improve the caching efficiency and reduce the transmission delay of the requested content. However, a user request may contain private information, such as personal content preference~\\cite{Cui2020, Yuan2016a, Schlegel2022}, location~\\cite{Zhang2022a}, content popularity~\\cite{Cui2020}, and other personal information~\\cite{Kong2019, Xue2019, Xue2018}. \nTherefore, edge caching systems should take both caching efficiency and privacy preservation into account. \nEntities that can implement sniffing attacks in network communications include edge caching managers (e.g., content providers~\\cite{Cui2020}, location service providers~\\cite{Zhang2022a}, Internet services providers or based station~\\cite{Yuan2016a},  edge devices~\\cite{ Zhou2019, Cui2020, Xu2019, Schlegel2022, Tong2022}), malicious end devices~\\cite{Xue2019, Xue2018,  Cui2020, Nikolaou2016}, and external adversaries~\\cite{Zhang2022b}.\n(2) The second type of monitoring attack is supervisory attacks on cached content, i.e.,  attackers conduct improper monitoring, replacement, pollution, and other privacy attack activities on cached content. By leveraging the illegal cache access, adversaries can obtain private data or information such as content popularity~\\cite{Araldo2018, Cui2020c, Andreoletti2019a}, user preferences~\\cite{Qian2020}, and other private information~\\cite{Cui2020c, Tong2022}. If the cached content is not protected prudently, the user's privacy can be seriously compromised by edge caches, which are often deployed by honest but curious third parties (e.g., Internet service providers (ISPs)~\\cite{Andreoletti2019a, Araldo2018}, edge servers~\\cite{Cui2020c, Qian2020, Tong2022}, and end devices~\\cite{Cui2020c, Qian2020}). \n\n% \\begin{figure}[tb]\n% \\centering\n% \\includegraphics[width=\\linewidth]{fig/relation.pdf}\n% \\Description{The possible privacy attacks on different sensitive data and the corresponding defence methods for enhancing privacy in edge caching systems.}\n% \\vspace{-2mm}\n% \\caption{The possible privacy attacks on different sensitive data and the corresponding defence methods for enhancing privacy in edge caching systems.}\n% \\label{fig: relation}\n% \\vspace{-4mm}\n% \\end{figure}\n\n\n\n\n\n\n\n"
                    },
                    "subsubsection 3.1.2": {
                        "name": "Data mining attacks",
                        "content": "\nData mining attacks usually occur when an edge caching entity applies a learning-based caching algorithm to explore sensitive data for making caching decisions. \nDue to the high dynamics and complicated access patterns driven by users' interest~\\cite{Muller2017, Yang2019},  designing an intelligent edge caching algorithm is essential to improve the caching performance. \nCommonly, learning-based methods make caching decisions by exploiting historical information to train a prediction model.  It is necessary to feed the model training  with  private and sensitive data related to users, and thus users may be reluctant to share.\nSince edge caching decisions are generated by learning algorithms, edge caching becomes a trade-off problem between caching performance and privacy protection level.\nAs a consequence, learning-based methods in edge computing-assisted caching are usually vulnerable to two types of privacy risks: (1) \\textit{exploratory}, in which adversaries investigate vulnerabilities (such as the training dataset, model parameters, and gradient data) without changing the training process, and 2) \\textit{causative}, in which attackers manipulate and inject misleading training datasets to alter the machine learning model's training process~\\cite{Tourani2018}. Additionally, previous research has shown that model parameters~\\cite{Shokri2017} and gradients~\\cite{Abadi2016, Zhao2020} of the machine learning model can be utilized to recover original sensitive and private information.\nLearning-based methods provide a practical framework for making edge caching decisions but are susceptible to privacy risks that can compromise user privacy. \n%Learning-based methods in edge computing-assisted caching are usually vulnerable to two types of privacy risks: 1) exploratory, in which adversaries investigate vulnerabilities (e.g., training dataset, model parameter, and gradient data) without changing the training process. 2) causative, in which attackers change the training process of machine learning models by manipulating and injecting misleading training data.\nThe potential adversaries to launch data mining attacks include edge caching managers (e.g., content providers~\\cite{Qiao2022, Cui2020}, Internet services providers~\\cite{Wang2020}, edge devices~\\cite{Qiao2022, Wang2022, Liu2022}) and malicious end devices~\\cite{Wang2019}.\n\n\n%Edge cache meets the trade-off issues for performance and privacy. Due to the highly dynamic and complicated access pattern driven by users' interest~\\cite{Muller2017, Yang2019} in a region, it is essential to design an intelligent edge caching algorithm to improve the caching performance. \n%Learning-based methods provide a feasible framework to evaluate the pattern but exploit the dataset, which may be sensitive for end devices. \n%For example, video request access patterns are driven by users' interest in different locations~\\cite{Ma2017b, Dhar2011}. And the user may keep dynamic moving\\cite{} and its interest change varying the time\\cite{}. Thus, it is indispensable to make edge caching decisions based on the crucial feature which can be learned from localized and private data by machine learning methods.\n%In conclusion, learning-based methods used in edge computing-assisted caching are also vulnerable to two types of privacy risk: 1) exploratory, in which adversaries investigate vulnerabilities (e.g., training dataset, model parameter, and gradient data) without changing the training process. 2) causative, in which attackers change the training process of machine learning models by manipulating and injecting misleading training datasets.\n\n\n\n\n\n\n"
                    },
                    "subsubsection 3.1.3": {
                        "name": "Cache side-channel attacks",
                        "content": "  \nIn cache side-channel attacks, attackers can learn privacy information about users and cached content by observing and measuring activities relevant to edge caches such as response time, power consumption, and return faults~\\cite{Sivaraman2021, Liang2019, Wu2016, Acs2019}.\nThrough the edge caching service, users can conveniently upload their content to edge servers or download requested content from edge servers. \nDue to the open accessibility of edge caches (ECs)~\\cite{Ni2021}, adversaries can easily access content cached by edge servers.  Adversaries can target a particular victim user by identifying content requested by the victim. The attacker may know the victim's content consumption habits or other specific characteristics to distinguish the victim from other users.\nOne of the main types of cache side-channel attacks is \\textit{cache-timing attacks}, which allows attackers to determine whether specific content has been cached by comparing response times.\nPrevious works such as~\\cite{Liang2019, Sivaraman2021, Acs2019} have explored cache-timing attacks in edge caching systems. \nAn attacker can conduct the precise timing measurement to distinguish cache hits from misses, which can identify what content is cached at the ES. A cache hit means that a nearby user has requested the content \n(or has a high caching value), while a cache miss means that the content has not been requested (or has been ejected from the cache). A knowledgeable attacker can further determine whether the request is served by the provider or by a router somewhere along the provider's path~\\cite{Liang2019}.\nThe main risk entities to launch cache side-channel attacks include malicious end devices~\\cite{Liang2019, Acs2019, Wu2016} and external adversaries~\\cite{Sivaraman2021, Zhang2022b}.\n\n\n\n\n\\begin{comment}\n\\begin{table*}[!tbp]\n\\renewcommand\\arraystretch{1.5}\n\\caption{Solution classification matrix based on risk entities and types of private data}\n%\\begin{center}\n%\\renewcommand{\\arraystretch}{1.2}\n%\\rowcolors{2}{white}{gray!25} \n\\begin{tabular}{|m{2cm}<{\\centering}|| m{1.8cm}<{\\centering}| m{1.8cm}<{\\centering}| m{1.8cm}<{\\centering}|m{1.8cm}<{\\centering}|m{1.7cm}<{\\centering}|m{1.5cm}<{\\centering}|}\n\\toprule\n\\hline\n%Notation   & \\multicolumn{1}{c|c|c}{C||}\\\\\nVictim Entity&Request Record&Location&Personal Information&Extracted Knowledge&Content Popularity& Private Content\\\\ \\hline\n\\midrule\nContent / Services Providers\n&\\cite{Cui2020b,Zhang2018,Kumar2019}%Content / Services Providers\n&\\cite{Cui2020b,Hu2018,Sen2018,Nisha2022,Amini2011,Yang2016,GUYi-mingBAIGuang-weiSHENHang,Andreoletti2018}\n&/\n&\\cite{Qiao2022}\n&\\cite{Andreoletti2018}\n&/\n\\\\\\hline\nInternet Services Providers\n&\\cite{Zhang2022a}\n&\\cite{Zhang2022a,Zhang2019b,Andreoletti2018}\n&\\cite{Zeng2020, ZengYi2021}\n&\\cite{Li2020a,Wang2020}\n&\\cite{Andreoletti2019a,Yuan2016a,Araldo2018,Andreoletti2018,Andreoletti2019}\n&\\cite{Leguay2017}\\\\\\hline \nEdge Devices\n&\\cite{Zheng2022,Cui2020,Wang2022,Zhou2019,Schlegel2022,Pu2019,Nisha2022}\n&\\cite{Hu2018, Zhang2023}\n&\\cite{Yu2020a,Lei2020}\n&\\cite{Yu2021b,Nisha2022,Yu2020a,Lei2020,Wu2020,Liu2022,Qi2020,Qiao2022}\n&\\cite{Yu2021b,Wu2020}\n&\\cite{Tong2022,Pan2019,Shi2018}\\\\\\hline \nMalicious End Devices\n&\\cite{Hassanpour2023,Yan2021,Acs2019,Wu2016,Nikolaou2016,Cui2020,Liang2019,Xue2019,Xue2018,Pu2019,Nisha2022, Guo2022}\n&\\cite{Sen2018}\n&\\cite{Xue2019,Xue2018,Dai2020,Zhu2021,Lei2020}\n&\\cite{Nisha2022,Lei2020,Saputra2022,Cheng2021}\n&/\n&/\n\\\\\\hline \nOthers\n&\\cite{Cui2020,Sivaraman2021,Zhang2022b,Wang2019,Cui2020c,Jiang2020}\n&/\n&\\cite{Kong2019}\n&\\cite{Jiang2020,Kong2019}\n&\\cite{Wang2019,Cui2020c}\n&\\cite{Xu2019,Xu2020}\\\\\\hline\n\\bottomrule\n\\end{tabular}\n%\\end{center}\n\\label{Tab: risk entities classification}\n\\end{table*}\n\\end{comment}\n"
                    },
                    "subsubsection 3.1.4": {
                        "name": "Cache tampering attacks",
                        "content": "\nA cache tampering attack is a form of cyber-attack in which an adversary aims to alter content stored at an EC to gain unauthorized access, introduce illicit content and disrupt the caching system's regular operation. Within an edge network, a caching server offers a temporary storage area, holding frequently accessed content to expedite distribution. However, cache tampering attacks can transpire when an attacker modifies content cached in the ES or deceives the user to gain unauthorized content. The main risk entities to implement cache tampering attacks include edge servers~\\cite{Tong2022, Qian2020}, malicious end devices~\\cite{Qian2020, Cui2020c} and external adversary~\\cite{Qian2020, Cui2020c}.\n\nA typical instance of cache tampering attacks is \\textit{cache poisoning}, where an attacker manipulates a Content Delivery Network (CDN) or edge server's cache to store and deliver malicious content or information~\\cite{Zhang2022b,Cui2020c,Tong2022}.\nFor example, an attacker can exploit the vulnerability of the caching system by requesting a legitimate image with a specially crafted HTTP header. This header may contain malicious code that tricks the cache into storing a different image the attacker controls rather than the legitimate one. The next time when a user requests the original image, it will instead receive the attacker's image, which could contain harmful content such as malware or phishing links.\n\nA variant of the cache tampering attack is the \\textit{cache deception attack}, wherein an adversary gains access to private information by misleading and influencing a privileged user~\\cite{gil2017web,Mirheidari2020,Mirheidari2022}. This process consists of two primary steps~\\cite{gil2017web}. Initially, the attacker prompts the privileged user to request sensitive content and cache it in the ES. Subsequently, the adversary submits an identical request to the EC and retrieves the sensitive content.\nFor example, in named data networking~\\cite{Lei2020}, an attacker creates a URL request targeting a victim user's private content by attaching a tag of a widely-used image. The victim is then enticed to make that request using its privilege~\\cite{Mirheidari2020}. \nUpon retrieval, the cloud server disregards the invalid suffix and returns legitimate privacy content. The caching node retains the privacy content as the popular image's content. In this manner, the attacker can make the same request to access the identical privacy content in the EC, enabling them to acquire private content they are not authorized to access, potentially resulting in the victim's private content being leaked~\\cite{Mirheidari2020,Mirheidari2022}.\nThe above kinds of cache tampering attacks give rise to unbearable privacy risks for users in edge caching systems.\n\n\\begin{comment}\n\\begin{table*}[!tbp]\n\\renewcommand\\arraystretch{1.2}\n\\caption{Solution classification matrix based on privacy attacks and types of private data}\n%\\begin{center}\n%\\renewcommand{\\arraystretch}{1.2}\n%\\rowcolors{2}{white}{gray!25} \n\\begin{tabular}{|m{50pt}<{\\centering}|| m{30pt}<{\\centering}| m{44pt}<{\\centering}| m{31pt}<{\\centering}|m{44pt}<{\\centering}|m{31pt}<{\\centering}|m{40pt}<{\\centering}|m{75pt}<{\\centering}|}\n\\toprule\n\\hline\n%Notation   & \\multicolumn{1}{c|c|c}{C||}\\\\\nPrivacy attack&Request Record&Personal Information&Location&Extracted Knowledge&Private Content&Content Popularity&References\\\\ \\hline\n\\midrule\nMonitoring Attack\n&\\Checkmark\n&\\Checkmark\n&\\Checkmark\n&\n&\\Checkmark\n&\\Checkmark\n&\\cite{Araldo2018,Leguay2017,Yuan2016a,Kong2019,Cui2020,Zhang2022a,Hassanpour2023,Nikolaou2016,Qian2020,Tong2022,Yan2021,Kumar2019,Schlegel2022,Cui2020b, Zhang2023,Nguyen2023}\n\\\\\\hline\nData Mining Attack\n&\\Checkmark\n&\\Checkmark\n&\\Checkmark\n&\\Checkmark\n&\n&\\Checkmark\n&\\cite{Qiao2022,Liu2022,Li2020a,Wang2020,Yu2018,Wang2019a,Yu2020,Qi2020,Zheng2021,Yu2020a,Zheng2022,Chen2022,Yu2021b,Cui2022,Wang2022a,Wang2022,Saputra2022,Cheng2021,LuYun2020, NAIR2023, Jiang2023}\n\\\\\\hline \nCache Side-channel Attack\n&\\Checkmark\n&\n&\n&\n&\n&\\Checkmark\n&\\cite{Sivaraman2021,Liang2019,Wu2016,Acs2019, Guo2022}\n\\\\\\hline\nCache Tampering Attack\n&\n&\\Checkmark\n&\n&\n&\\Checkmark\n&\n&\\cite{Qian2020,Cui2020c,Jiang2020,Tong2022, WangHu2022}\n\\\\\\hline \n\\bottomrule\n\\end{tabular}\n%\\end{center}\n\\label{Tab: attacks classification}\n\\end{table*}\n\\end{comment}\n\n\n\n"
                    }
                },
                "subsection 3.2": {
                    "name": "Mitigation Methods to Preserve \n  Privacy in Edge Caching Systems",
                    "content": "\n\nIn the following subsection, we will provide a concise introduction to a range of methods that can effectively mitigate privacy leakage in content caching systems, which can be mainly classified into four types of methods: (1) \\textit{noise-based methods}, (2) \\textit{cryptology-based methods}, (3) \\textit{trusted distributed computing}, and (4) other approaches. The specific solutions corresponding to each privacy mitigation approach are detailed in Section~\\ref{sec: user privacy}-\\ref{sec: knowledge privacy}. For easy reference, we also present a classification matrix for the solutions introduced in this survey based on countermeasures and privacy data in the realm of edge caching in Table~\\ref{Tab: countermeasures} in Appendix.\n\n\n\n\n\n\n\n\n\n",
                    "subsubsection 3.2.1": {
                        "name": "Noise-based methods",
                        "content": "\\\nNoise-based methods represent the most prevalent approaches for preserving privacy within edge caching systems. These methods introduce disturbances to the real and genuine information before its exposure and interaction, effectively safeguarding privacy. Within the domain of edge caching, three specific types of methods are commonly employed: \\textit{differential privacy (DP)}, \\textit{confusion}, and \\textit{anonymization}.\n\n\n{\\bf Differential privacy (DP)} is a data-sharing technique that allows data owners to share only some statistical characteristics of a database while withholding individual-specific information~\\cite{Sivaraman2021,Acs2019}. \n    %A random algorithm $f(x)\\xrightarrow{}Y$  satisfies $\\varepsilon$-differential privacy if and only if for any output $S \\in Y $, $f(x)\\xrightarrow{}Y$ meets the condition:\n    %\\begin{equation}\n%\\operatorname{Pr}[f(D) \\in S] \\leq \\exp (\\varepsilon) \\operatorname{Pr}\\left[f\\left(D^{\\prime}\\right) \\in S\\right],\n%\\end{equation}\n    %where $D$ and $D'$ are an arbitrary pair of ``adjacency\" datasets differing in a single record  and $\\varepsilon$ is the privacy budget.\n    %Intuitively speaking, suppose the effect of randomly modifying a record in the database is small enough, the resulting statistical features cannot be used to infer the content of a single record. \n    %It can be exploited to protect privacy. \n    % As shown in Fig.~\\ref{fig:DP}, \n    There are two ways to add noise in the DP mechanism. The traditional one is to add noise to the public database at the time of data release. However, the data collection agency is not always reliable, and thus local differential privacy (LDP) mechanism is also leveraged by data owners to distort original data before submitting private data. %In contrast, traditional DP only adds noises to obfuscate the query results of a database. \n    The use of DP in edge caching systems can introduce distortion to the actual user or content information during the collection or release of sensitive data.\n    DP is introduced to protect request traces~\\cite{Zhang2018,Wang2019,Zhou2019,Zhang2022a,Sivaraman2021} personal information~\\cite{Zhu2021,Zeng2020}, and machine learning models~\\cite{Yu2021b} in edge caching systems.  \n    \n% \\begin{figure}[h]\n% \\centering\n% \\includegraphics[width=0.5\\linewidth]{fig/DP.pdf}\n% \\vspace{-2mm}\n% \\Description{Two distinct forms of DP exist: the LDP mechanism, which entails data owners injecting noise into their sensitive data prior to submission, and the traditional DP mechanism, which adds noise during the data release process.}\n% \\caption{Two distinct forms of DP exist: the LDP mechanism, which entails data owners injecting noise into their sensitive data prior to submission, and the traditional DP mechanism, which adds noise during the data release process.}\n% \\label{fig:DP}\n% \\vspace{-4mm}\n% \\end{figure}\n    \n{\\bf Confusion} mainly has two ways to enhance privacy in edge caching. The first one is cache obfuscation (such as proactive cache~\\cite{Qian2020,Nikolaou2016}, off-path cache~\\cite{Wu2016}, and request hit delay~\\cite{Liang2019}), which can be used to protect users' requests when retrieving the content from monitoring or timing attacks in an untrusted or semi-trusted network environment. The second one is spatial confusion~\\cite{Amini2011, GUYi-mingBAIGuang-weiSHENHang, Zhang2019b}, which is to protect the location information when users enjoy location-based services. \n    For instance, many pseudo requests for Points of Interest (PoIs) can be attached to the genuine request when retrieving content from the EC.\n    \n    {\\bf Anonymous} methods are the last category of privacy risk mitigation measures.\n    Anonymity is the act of not being named or using an alias, as opposed to the act of having a real identity~\\cite{Cui2020b}. In particular, a set of public data satisfies $K$-anonymity if the information of any entity cannot be distinguished from at least $K-1$ other entities. $K$-anonymity method is often used to enhance geographical~\\cite{Hu2018, Nisha2022, Yang2016} and personal privacy identity information~\\cite{Sen2018, Cui2020b}  in edge caching systems. Besides, the anonymity group technology is also used in protecting users' identity information~\\cite{Zhang2022b, Xue2019, Xue2018, Nguyen2023}.\n\n\n\n\n\n\n"
                    },
                    "subsubsection 3.2.2": {
                        "name": "Trusted distributed computing-based methods",
                        "content": "\nTrusted distributed computing (TDC) methods encompass three primary mitigation frameworks\u2014\\textit{federated learning}, \\textit{secret sharing}, and \\textit{blockchain technology}\u2014to safeguard privacy in the context of edge caching.\n\n{\\bf Federated learning (FL)} is a distributed machine learning technique that trains a learning-based algorithm across multiple decentralized devices or edge servers locally holding data samples without exposure~\\cite{BrendanMcMahan2017}. The FL framework is one of the most essential methods to preserve private data during the machine learning process.\nIt is common that the FL framework~\\cite{Yu2018,Wang2019a,Wang2020,Liu2022,Yu2020,Yu2020a,Li2020a} trains learning models by exposing model parameters or gradients. Instead, traditional machine learning methods need to collect raw data for the learning process. \n%Other than requiring sensitive data to tune the machine learning model during the model training process, the edge caching system may also need private data to make edge caching decisions. Therefore, some previous works~\\cite{Qi2020,Cheng2021,Zheng2022,Wang2022a,Saputra2022} introduced other privacy protection methods into the FL-based framework to enhance data privacy during the interface process.\nHowever, model parameters or gradients are also private assets of users since attackers can infer and recover users' private information from exposed model information. In addition, model information may have significant economic benefits, which will compromise the self-interest of model owners if they are exposed directly. A number of works~\\cite{Yu2021b,Wang2022,Cui2022,Chen2022} have contributed to upgrading the FL framework by injecting noise or other interference to model information prior to exposure. \n\n{\\bf Secret sharing (SS)}, also known as secret splitting, is a kind of secure multi-party computation and storage method in which each party gets a part of the secret, called a \\textit{secret share}. \nThe secretly shared information cannot be recovered unless a sufficient number of secret shares can be collected. A single share cannot restore the original secret. \n\\textcolor{black}{\nFor example, the $(t,n)$-threshold scheme is the most straightforward secret-sharing scheme. In this scheme, there are a total of $n$ players, each receiving only one secret share. The secret can be recovered if at least $t$ players cooperate, where $t$ is the safety threshold parameter. \nIn edge caching scenarios, secret data may include private content generated and stored by users and historical data required for edge caching decisions (e.g., request traces~\\cite{Acs2019}, user preferences~\\cite{Schlegel2022}, and content popularity information~\\cite{Andreoletti2019}). While introducing SS may increase computational load, it significantly raises the cost for attackers attempting to obtain private information from the edge, reducing the risk of data breaches. Moreover, it enhances the fault tolerance of distributed caching systems.}\n% For example, the $(t,n)$-threshold scheme is the most straightforward secret-sharing scheme. \n% In this scheme, there are a total of $n$ players. Each player receives only one secret share. The secret can be recovered if at least $t$ players cooperate, but if fewer than $t$ players cooperate, where $t$ is the safety threshold parameter. \n% In edge caching scenarios, secret can be  \n% SS can be introduced to protect request traces~\\cite{Acs2019, Schlegel2022} and the content popularity information~\\cite{Andreoletti2019} in edge caching systems.  \n    \n{\\bf Blockchain} is a technical solution that does not rely on third parties to carry out network data storage, verification, transmission, and communication through its own distributed nodes. \n%As Fig.~\\ref{fig:blockchain steps} shows, \nThe blockchain mechanism can automate these four steps: (1) When a new blockchain transaction occurs, all participants can competitively record that transaction as a data block. (2) Following the rule of consensus, most participants on the blockchain network must vote for a valid recorded transaction. Depending on the type of network, the consensus mechanism of agreement can vary but is typically established at the start of the network. (3) Once participants have reached a consensus, transactions on the blockchain are written into blocks appended to a cryptographic hash that links blocks together as a chain. (4) The blockchain system finally updates and broadcasts a copy of the latest ledger to all participants. Blockchain can be used to enhance the protection of user preferences~\\cite{Qian2020},  personal information~\\cite{Lei2020,Dai2020,Vu2019, LiuJi2020}, and machine learning data~\\cite{Cui2022} in edge caching systems. \n\n% \\begin{figure}[!tb]\n% \\centering\n% \\includegraphics[width=0.6\\linewidth]{fig/blcokchains.pdf}\n% \\vspace{-2mm}\n% \\caption{A simplified workflow depicting the blockchain mechanism for generating a new block and adding it to the chain.}\n% \\Description{A simplified workflow depicting the blockchain mechanism for generating a new block and adding it to the chain.}\n% \\label{fig:blockchain steps}\n% \\vspace{-5mm}\n% \\end{figure}\n  \n    \n\n\n"
                    },
                    "subsubsection 3.2.3": {
                        "name": "Cryptology-based methods",
                        "content": "\n\nCryptology-based methods, as a vital category of mitigation approaches, play a significant role in preserving privacy within edge caching systems. These methods employ cryptographic techniques to safeguard sensitive content or information, ensuring confidentiality, integrity, and authentication. Within the realm of edge caching, three specific types of methods are leveraged: \\textit{encryption communication}, \\textit{homomorphic encryption (HE)}, and \\textit{private information retrieval (PIR)}.\n\n\n    {\\bf Encryption communication} is divided into two steps to protect the security and privacy of communication data. The first step is to encrypt communication data as follows. The sender encrypts the content by an encryption algorithm and the receiver's public key to obtain the ciphertext. The receiver, once getting the ciphertext, conducts decryption through the decryption algorithm and the private key to recover the original data. \n    Encryption communication is commonly used to protect the security of user request records and other data in Internet communications. \n    There are three main approaches for encryption in edge privacy-enhanced caching systems. One is symmetric encryption, which mainly uses Data Encryption Standard (DES), Advanced Encryption Standard (AES)~\\cite{Pu2019, Yuan2016a}, or Searchable Encryption (SE)~\\cite{Cui2020c}. Second, asymmetric encryption mainly includes Rivest-Shamir-Adleman (RSA)~\\cite{Xu2019}, Attribute-Based Encryption (ABE)~\\cite{Pu2019}, and Elliptic Curve Cryptography (ECC)~\\cite{Zhang2022b, Cui2020}. \n    Finally, there are hashing algorithms~\\cite{Xue2019, Xue2018, Xu2019}, which are sometimes used in blockchain~\\cite{Cui2022, Lei2020}. \n    However, there are also three significant concerns with the use of cryptographic methods in edge caching systems. Firstly, due to the existence of encryption, third-party ECs often cannot directly use encrypted requests to retrieve related content, which may lead to the unavailability of ECs. Secondly, introducing encryption technology may pose computational pressure on the resource-constrained edge and end devices. Lastly, encryption communication may fail to prevent record privacy from content providers or service providers, who have the key to decrypt request information. Therefore, how to introduce cryptology-based techniques into edge caching systems is still a challenging problem.\n    In addition, as a special communication encryption method, the digital signature~\\cite{Kong2019, Chen2022, Jiang2020} is often used in edge caching systems to verify user identity and data reliability. \n    \n    {\\bf Homomorphic encryption (HE)} is a form of encryption by which each party co-computes the result of a specific objective function concerning their private data without a trusted third party (TTP). Each party cannot unveil private data from other parties even if the computation is completed. \n    In other words, it allows a participant to perform operations such as searching and multiplying encrypted data to produce correct results without decrypting it during calculation. HE can be used to protect user preferences~\\cite{Cui2020} and information~\\cite{Kong2019} when searching the EC.\n\n    {\\bf Private information retrieval (PIR)} is mainly used to protect a user's request record information~\\cite{Tong2022, Kumar2019} in the edge caching system. When obtaining sensitive data, request records likely expose important privacy information of users. \n    PIR can help users with query needs to complete private data retrieval from the EC under the condition that the query privacy information is not leaked. In other words, the PIR technology can prevent attackers from obtaining precise query information and content items in cache retrieval or other sensitive queries. At the same time, PIR can let users obtain desired private content.\n\n\\begin{comment}\n\\begin{table*}[!tbp]\n\\caption{Method classification based on countermeasures and privacy attack.}\n%\\begin{center}\n%\\renewcommand\\arraystretch{1.25}\n\\renewcommand{\\arraystretch}{1.2}\n%\\rowcolors{2}{white}{gray!25} \n\\begin{tabular}{|m{1.45cm}<{\\centering}|m{2.1cm}<{\\centering}||m{1.7cm}<{\\centering}|m{2.5cm}<{\\centering}|m{2.5cm}<{\\centering}|m{2.5cm}<{\\centering}|}\n\\toprule\n\\hline\n%Notation   & \\multicolumn{1}{c|c|c}{C||}\\\\   \\multirowcell{2}\nClasses&Methods&Monitoring Attack&Data Mining Attack&Cache Side-channel Attack&Cache Tampering Attack\\\\ \\hline\n\\midrule\n\\multirowcell{3}{Noise-\\\\\nbased}\n    &{DP}&\\cite{Zhang2022a}&/&\\cite{Guo2022}&{~\\cite{WangHu2022}}\\\\    \\cline{2-6}\n    &Obfuscation&\\cite{Nikolaou2016,Nguyen2023}&/&\\cite{Wu2016,Liang2019}&/\\\\   \\cline{2-6}\n\t& Anonymity&\\cite{Cui2020b,Zhang2023}&/&/&/\\\\\n\t \\hline\n\\multirowcell{3}{TDC-based}\n        &{FL}&/&\\cite{Cui2022,Qiao2022,Liu2022,Yu2021b,Zheng2022,Chen2022,Wang2022a,Wang2022,Saputra2022,Cheng2021,Li2020a,Wang2020,Yu2018,Wang2019a,Yu2020,Qi2020,Zheng2021,Yu2020a, LuYun2020, Jiang2023, NAIR2023}&/&/\\\\ \\cline{2-6}\n\t&SS&\\cite{ Schlegel2022}&/&\\cite{Acs2019}&/\\\\\\cline{2-6}\n\t&\\multirowcell{2}{Blockchain}&\\multirowcell{2}{\\cite{Qian2020}}&\\multirowcell{2}{/}&\\multirowcell{2}{/}&\\multirowcell{2}{\\cite{Qian2020}}\\\\\\cline{1-1}\n    &&&&&\\\\\\cline{2-6}\n\\multirowcell{2}{Cryptology\\\\-based}\n\t\t& Encryption  Communication&\\cite{Araldo2018,Leguay2017,Yuan2016a}&/&/&\\cite{Jiang2020}\\\\ \\cline{2-6}\n\t\t& HE&\\cite{Cui2020,Kong2019}&/&/&/\\\\  \\cline{2-6}\n\t\t& PIR&\\cite{Tong2022,Yan2021,Kumar2019}&/&/&\\cite{Tong2022}\\\\   \\hline\n\\multirowcell{3}{Others}\n\t\t& Optimization&\\cite{Hassanpour2023} &/&\\cite{Sivaraman2021}&/\\\\  \n  \\cline{2-6}\n\t    & {Access Control}&/&/&/&\\cite{Cui2020c}\\\\\n         \\hline\n\\bottomrule\n\\end{tabular}\n%\\end{center}\n\\label{Tab: countermeasures-attack}\n\\end{table*} \n\\end{comment}\n\n\n\n"
                    },
                    "subsubsection 3.2.4": {
                        "name": "Other methods",
                        "content": " \\textcolor{black}{Optimization-based methods and access control are two of the main approaches to enhancing the effectiveness of privacy protection in edge caching systems. In {\\bf optimization-based methods}, metrics such as privacy exposure~\\cite{Sivaraman2021,Andreoletti2019a} and credibility~\\cite{Xu2019,Zhong2021,Cao2020} are mathematically modeled. The quantified metrics are then regarded as the objective function or constraint variables of the cache optimization problem. Finally, the optimal privacy protection decisions are deduced by solving the  optimization problem~\\cite{Xu2020,Hassanpour2023,Shi2018,Hassanpour2021}.}\n{\\bf Access control} is an enforcing control method that allows or denies a user's access to a specific network resource, e.g., private content in the EC, based on the user's account or group. \nWithout a defined authorization mechanism, access to system resources will have no restrictions, and thus illegal device operations can be easily launched. \nThe EC can implement strict access control to filter out unauthorized or illegal accesses into the caching space for privacy protection. Access control methods have been applied to protect personal information~\\cite{Lei2020, Cui2020c, Zhang2022b} and content privacy~\\cite{Xue2019, Xue2018} in edge caching systems.\nIn the next section, we dive into the details of defence methods for protecting each type of sensitive information.\n\n\n\n{\\color{black}\n\\subsubsection{Summary}\nIn conclusion, privacy-preserving methods in edge caching systems can be broadly classified into four categories. \\textit{Noise-based methods} are among the most prevalent techniques for safeguarding privacy. These methods are particularly effective in preventing monitoring attacks and cache side-channel attacks but may negatively impact the utility and performance of edge caching systems. For instance, DP is employed to add noises to data before or during its release, protecting user request traces, personal information, and machine learning models from privacy breaches. However, due to the limited privacy budget, strategic account~\\cite{Abadi2016} or allocation mechanisms~\\cite{Xiao2024} are required to mitigate the adverse influence of noises on utility. \\textit{Noise-based methods} typically introduce an acceptable level of computational overhead, providing adaptive protection in real-time edge systems where capacity is limited.\n\n\\textit{Trusted distributed computing-based methods} refer to techniques that organize distributed devices for collaborative computation and storage while ensuring data privacy and security, such as federated learning, secret sharing, and blockchain technology. FL is valuable for protecting the privacy of machine learning models by enabling decentralized training without exposing raw data.  \n%Secret Sharing is another powerful technique that splits sensitive data into multiple shares distributed across different parties, making it difficult for attackers to reconstruct the original data without access to a sufficient number of shares. \nThese methods help mitigate the risk of data mining attacks, where adversaries might otherwise exploit original request traces or model parameters to infer private information.\nHowever, \\textit{trusted distributed computing-based methods},  regarded as a form of adaptive protection, also need integrate with some strict privacy-preserving methods and may introduce communication and computational complexity due to the need for synchronization and consensus across multiple nodes, which can affect scalability and deployability.\n\n\\textit{Cryptology-based methods} utilize cryptographic techniques to ensure the confidentiality and integrity of sensitive information. For example, HE allows computation on encrypted data without needing to decrypt it first, protecting user preferences during data processing. \n% Privacy-preserving Information Retrieval (PIR) is used to allow users to retrieve data from  the edge cache without revealing the nature of their queries, thereby safeguarding request records from external adversaries. \nIn addition to preventing request information from being monitored by external attackers, these methods are crucial for preventing cache tampering attacks, where attackers might alter cached content to gain unauthorized access or disrupt system operations. Despite offering stringent protection, \\textit{cryptology-based methods} generally incur high computational complexity, particularly in scenarios involving encryption and homomorphic encryption, which can become bottlenecks for resource-constrained edge devices.\n\n% Other methods include optimization-based techniques and access control mechanisms. Optimization-based methods mathematically model privacy exposure and credibility, using these metrics as objective functions in cache optimization problems to make decisions that balance privacy and efficiency. Access control, on the other hand, enforces strict permissions on who can access specific resources within the edge cache, thereby preventing unauthorized access to private content and user information. These methods are particularly effective against cache tampering attacks and unauthorized data access by malicious entities.\n\nLastly, \\textit{other methods}, including optimization-based techniques and access control, enhance privacy by mathematical modeling and enforcing access restrictions to sensitive resources. \nThe complexity of privacy-preserving methods in edge caching systems varies significantly depending on the approach.   Optimization-based methods involve solving complex mathematical models, with computational intensity heavily dependent on the formulations and solving algorithms. This complexity may be particularly high when optimizing  multiple privacy metrics simultaneously or under complex constraints. \n% {\\bf YP: why you just mention computation cost? DP harms accuracy, SS incurs heavy communication cost, which are ignored}\nTherefore, selecting appropriate privacy-preserving methods requires a careful balance between the desired level of privacy and the performance cost.\nFor easy reference, we also present a classification matrix for the solutions introduced in this survey based on countermeasures and privacy data in Table~\\ref{Tab: countermeasures} in Appendix.\n}\n\n\n\n\\begin{comment}\n\\begin{figure*}[!t]\n\\centering\n\n\\includegraphics[width=0.75\\linewidth]{fig/classification based on countmeasure.pdf}\n\\caption{classification based on countmeasure}\n\\label{fig_1}\n\\end{figure*}\n\n\n\\begin{table*}[!htbp]\n\\renewcommand\\arraystretch{1.5}\n\\caption{Notations used in the paper}\n%\\begin{center}\n%\\renewcommand{\\arraystretch}{1.2}\n%\\rowcolors{2}{white}{gray!25} \n\\begin{tabular}{|m{2cm}<{\\centering}| m{2.5cm}<{\\centering}| m{1.5cm}<{\\centering}| m{10cm}|}\n\\toprule\n\\hline\n%Notation   & \\multicolumn{1}{c|c|c}{C||}\\\\\nScenario&Method&Reference&\\makecell[c]{Description}\\\\ \\hline\n%\\midrule\n\\multirowcell{8}{Cache on \\\\ Edge devices}\n        &\\multirowcell{2}{Trusted distributed \\\\computing }&\\cite{Wang2022}&Propose a FL-based privacy-preserving content popularity prediction mechanism and WGAN is used to generate high-quality fake samples\\\\\\cline{3-4}\n        &&\\cite{Zheng2022}&Design an unsupervised popularity prediction model with RNN and Federated Learning method to protect user data privacy\\\\\\cline{2-4}\n\t\t& \\multirowcell{1}{Cryptology}&\\cite{Pu2019}&Design a secret sharing based edge data caching strategy with low computational complexity\\\\ \\cline{2-4} \n\t\t&\\multirowcell{2}{Noise-based}&\\cite{Zhou2019}&Propose a privacy-preserving and trusted distributed MC retrieval, where ENs collaboratively make personalized predictions with differential privacy and trust mechanisms\\\\ \\cline{3-4} \n\t\t&&\\cite{Zhang2022a}& Propose\na Q-learning based video caching optimization framework (VC-PPQ) deploying with differential privacy mechanisms to enhancing location and preference privacy.\\\\\\cline{2-4}\n\t\t& \\multirowcell{2}{Others}&\\cite{Kumar2019}& Propose a PIR strategy based on encoding cache with erasure correcting code technique\\\\ \\cline{3-4} \n\t\t&&\\cite{Hassanpour2023}&An optimization scheme to maximize the error when the attacker speculates the request file and requests the cache, while satisfy the privacy degree and minimize the communication cost\\\\\\hline\n\\multirowcell{4}{Cache on \\\\User devices}\n\t\t&\\multirowcell{2}{Noise-based}&\\cite{Wang2019}&The prefecthing problem is modeled as an online optimization problem, and the differential privacy technology is used to protect user request records\\\\ \\cline{3-4} \n\t\t&&\\cite{Cui2020b}&Propose a cache-based privacy-preserving algorithm for LBS service, which protect the user's request and geographic location privacy information at the same time without TTP\\\\ \\cline{2-4}\n\t\t& \\multirowcell{2}{Others}&\\cite{Zhong2021}&Propose a D2D passive cache algorithm, which can update the cache space in real time to ensure cache efficiency and protect user privacy\\\\ \\cline{3-4} \n\t\t&&\\cite{Yan2021}&Propose a coding cache scheme based on private key, where private data in shared cache can only obtain by users with their private key and interests.\\\\  \\hline\n\\multirowcell{6}{Vehicular \\\\ edge cache}\n       &\\multirowcell{2}{Trusted distributed\\\\ computing }&\\cite{Wang2022a}&Propose a private federated learning based cache (PFLC) scheme that utilizes a pseudo rating matrix (PRM) to protect user private data\\\\\\cline{3-4}\n        &&\\cite{Qian2020}&Propose a privacy-aware content caching architecture, where RSU and vehicles can cache and broadcast the content in advance to meet the content requirements of the vehicle.\\\\   \\cline{2-4}\n\t\t& \\multirowcell{3}{Cryptology}&\\cite{Zhang2022b}&\\\\ \\cline{3-4} \n\t\t&&\\cite{Cui2020}& \\\\ \\cline{3-4} \n\t\t&&\\cite{Jiang2020}& \\\\ \\hline\n%\\multirowcell{7}{In-network\\\\ edge cache}\n%\t\t&\\multirowcell{4}{Noise-based}&\\cite{Zhang2018}&\\\\ \\cline{3-4} \n%\t\t&&\\cite{Sivaraman2021}&\\\\ \\cline{3-4} \n%\t\t&&\\cite{Wu2016}&\\\\ \\cline{3-4} \n%\t\t&&\\cite{Nikolaou2016}&\\\\\\cline{2-4}\n%\t\t& \\multirowcell{3}{Cryptology}&\\cite{Xue2019}\\cite{Xue2018}&\\\\ \\cline{3-4} \n%\t\t&&\\cite{Cui2020c}& \\\\ \\cline{3-4} \n%\t\t&&\\cite{Acs2019}& \\\\ \t\t\\cline{2-4} \n%\t\t& \\multirowcell{1}{Others}&\\cite{Liang2019}&\n%\t\t\\\\  \\hline\n\\bottomrule\n\\end{tabular}\n%\\end{center}\n\\label{Major Notations}\n\\end{table*}   \n\\end{comment}\n\n\n\n\n\n\n"
                    }
                }
            },
            "section 4": {
                "name": "Enhancing User Privacy in Edge Caching Systems",
                "content": "\\label{sec: user privacy}\n\nUser privacy is the most important privacy in edge caching systems, which has attracted tremendous research efforts dominating the research on privacy preservation in edge caching systems. We discuss these defence methods based on three types of user privacy, i.e., \\textit{request traces}, \\textit{personal information} and \\textit{location}. \n\n\n",
                "subsection 4.1": {
                    "name": "Privacy of Request Traces in Edge Cache",
                    "content": "\nRequest traces are the most critical privacy information in the edge cache (EC), from which adversaries can obtain user preferences~\\cite{Wang2019}.\nWe summarize methods to protect user request records from four aspects which are \\textit{noise-based methods}, \\textit{cryptology-based methods}, \\textit{trusted distributed computing-based methods} and other methods. A brief timeline of solutions for enhancing the privacy of request traces is presented  in Fig.~\\ref{fig: user privacy}. The solutions for enhancing other user privacy, e.g., personal information and location, are also summarized in  Fig.~\\ref{fig: user privacy} for the sake of brevity.\n%\\enlargethispage*{1cm} \n%On the one hand, analyzing request traces can improve the efficiency of the cache, on the other hand, if obtained by attackers, they can carry out illegal advertising~\\cite{}, cache pollution attack~\\cite{}, and so on. \n%In addition, it is also tough for end devices to prevent the request records from being spayed by adversaries. \n%Privacy request records are often generated between terminal devices and edge terminals.\n%For example,  as users conveniently stream their favored online videos in online video system, video request records will be automatically seized by video content providers, which may leak users' privacy.\\cite{} \n%Unfortunately, most existing privacy-enhancing approaches are not applicable for protecting users' privacy in requests, which cannot be easily altered or distorted by users and must be visible for provider (e.g., content provider or edge cache dispatcher) to stream correct videos. \n%This is a trade-off between efficiency and privacy. When end-users and service providers enjoy the efficient data distribution brought by edge caching, it is difficult to remain invisible to the edge caching entity or caching service provider, that is, it will leave a trace in the edge network. \n\n\n\n%mainly include the use of blockchain technology, secret sharing technology, differential privacy technology, record confusion, encrypted communication, and private information retrieval technology. \n\n\n",
                    "subsubsection 4.1.1": {
                        "name": "Noise-based methods",
                        "content": "\n\\textcolor{black}{The initial class of methods to protect request records are noise-based methods, which can be categorized into two main approaches. The first approach involves adding noises generated by mechanisms such as differential privacy (DP) to protect information~\\cite{Zhang2018,Zhou2019,Wang2019,Zhu2021,Zeng2020, ZengYi2021, Guo2022,Wang2017}. The second approach includes cache obfuscation methods (such as proactive cache~\\cite{Qian2020,Nikolaou2016}, off-path cache~\\cite{Wu2016}, and request hit delay~\\cite{Liang2019}) to protect users' requests from monitoring or timing attacks in untrusted or semi-trusted network environments. We will elaborate on these methods in the following sections.}\n\n\n\n\\textit{\\textbf{Differential privacy (DP).}}\nContent providers (CPs) often utilize edge caching nodes at the edge network and collect users' private access records to predict user preference to improve delivery efficiency. However, directly collecting users' profiles can lead to privacy breaches. Additionally, in highly dynamic scenarios, the entities of edge cache (e.g., edge nodes (ENs)~\\cite{Zhou2019} and edge servers (ESs)~\\cite{Zhu2021}) collect user request records in real-time and make dynamic decisions to improve the efficiency of edge caching. \nThis real-time data collection process also poses a risk of privacy leakage, where DP-based methods can be employed to mitigate the risk. \n%\\textcolor{orange}{\n%Referring to the optimal local hashing method proposed in~\\cite{Wang2017}, Zhang~\\emph{et al.}~\\cite{Zhang2018} adopted the Local Differential Privacy (LDP) protection mechanism to add noises for protecting user profiles, which are then transmitted to the CP side. CP aggregates user preferences to evaluate content popularity. Then, a caching revenue maximization problem is proposed with local privacy preservation, considering the cost of leasing access points, backhaul bandwidth reduction, and the profit of serving users by caching.\n%}\n\nZhou~\\emph{et al.}~\\cite{Zhou2019} proposed a privacy-preserving and online distributed multimedia content retrieval system. Each EN in the system is modelled as an online learner to exploit user requests with a context that includes their background information (e.g., age, gender, location, social profile, and query criteria). The ENs can collaboratively make multimedia content recommendations and cache at the edge network. When an EN needs extra context information to make a retrieval scheme, the TTP sends noisy records to ENs by deploying the DP mechanism. A trust mechanism is also proposed to identify and remove malicious ENs. %The EN learns user preferences based on noisy historical records and selects personalized multimedia content to push to users. \nZhu~\\emph{et al.}~\\cite{Zhu2021} studied the trade-off between privacy protection and caching efficiency in edge caching systems. When a user generates a content rating vector, Gaussian noises are added to the original rating vector, and then the distorted rating vector is transmitted to the ES for privacy protection. In the global aggregation information stage, ES calculates the eigenvalues and eigenvectors of collected data based on the lightweight level calculation algorithm. Then, ES broadcasts the results to all users. %In addition,  Deep Reinforcement Learning (DRL) is utilized for training and inferring cache placement decisions by constructing a Markov decision process.\n\\textcolor{black}{Xiong~\\emph{et al.}~\\cite{Xiong2022} presented a novel network traffic shaping framework for protecting privacy in IoT networks by integrating DP with constrained optimization. They developed a tunable DP model that shapes encrypted IoT traffic to protect against monitoring attacks, particularly eavesdropping on packet sizes and timing. This approach not only safeguards IoT traces from privacy breaches but also enhances the resilience of IoT systems against traffic analysis attacks by dynamically adapting to changing network conditions and heterogeneous user demands.}\n\n\n\n\nIn collaborative edge caching, managers exchange sensitive information, such as user records or preferences~\\cite{Zeng2020, Zhou2019}, and routing records~\\cite{Zeng2020}, to improve caching efficiency. \nHowever, protecting privacy often in collaborative edge caches may rely on a centralized TTP, which is challenging to obtain in practice and places more pressure on network bandwidth. Moreover, if the centralized TTP is attacked, it may pose a more serious privacy breach risk.\nZeng~\\emph{et al.}~\\cite{Zeng2020} proposed a distributed method to develop network caching and routing strategies for small base stations (SBSs). The scheme adds a DP noise in the routing information (i.e., the portion of the requested content served by each SBS) during the exchange process to protect the privacy of SBSs and Mobile Users (MUs). It defines an optimization problem that minimizes the global cost, which is solved by a distributed protocol. % and can be proved that the solution can converge to the optimal solution.\nGuo~\\emph{et al.}~\\cite{Guo2022} introduced a blockchain and DP-based decentralized edge-thing system for privacy preservation and fair utilization of edge computing resources. The proposed system employed blockchain technique to deal with transactions and smart contracts' tempering issues caused by the malicious auctioneer node. Moreover, an exponential mechanism-based DP is applied to the double auction scheme to tackle the inference attack on auction results saved in the blockchain. %Resource allocation and pricing between an IoT device and edge nodes are modelled using a combinatorial resource auction mechanism to make maximum revenue of the edge computing framework.\n\n%Zeng~\\emph{et al.}~\\cite{ZengYi2021} devised a decentralized mechanism to address SBS's caching and routing strategies jointly. LDP is used to make the routing information private of individual SBS since SBS forwards its routing information straight to its adjacent SBS without aggregation.  The developed mechanism targeted the privacy preservation of individual SBS due to the independence between SBSs in a decentralized caching system and suggested that LDP is a more appropriate alternative than standard DP in this caching system.\n\n\nHits on the user's local cache can provide the best service experience for users. However, it is challenging for end devices that rely on a user's personal historical information to make accurate pre-fetching decisions solely.\nCollaborative efforts between users are necessary, but such information exchange is risky, and the recorded history must be protected when disclosed.\nWang~\\emph{et al.}~\\cite{Wang2019} presented a mobile video pre-fetching strategy based on DP and distributed online learning algorithms. They formulated the pre-fetching problem as an online optimization problem considering user preferences, video popularity, and social connections. The problem is then decomposed into two sub-problems, which are solved and swapped at each terminal by a distributed method to obtain the optimal global solution. \nThe DP mechanism is added in exchanging user-sensitive information during each round of iteration to protect user privacy.\n\n%Zeng~\\emph{et al.}~\\cite{Zeng2020} proposed a distributed method to develop network caching and routing strategies simultaneously. The scheme adds a {\\bf DP} mechanism in the routing information exchange process to protect the privacy of all parties in the network. It defined an optimization problem that minimizes the global cost, which was solved by a distributed protocol. It can be proved that the solution can converge to the optimal solution.\n\n\n\\textit{\\textbf{Cache obfuscation.}}\nIn Information-Centric Network (ICN), users can directly access desired content from edge routing nodes. However, edge routing nodes are often vulnerable to cache side-channel attacks, which can result in the exposure of requested record privacy. \nLiang~\\emph{et al.}~\\cite{Liang2019} designed a method to defend against timing attacks in Content-Centric Networks (CCN). According to the privacy protection degree for requested content and the honesty degree of requested nodes, evaluated by the historical information, the caching node calculates the delay in responding to requests to defend against timing attacks.\nFurther, Wu~\\emph{et al.}~\\cite{Wu2016} designed a multi-path caching strategy for ICN based on random linear network coding. The strategy encodes different video chunks into the same block for efficient content delivery. When the block is delivered along the path, it can only serve all routing nodes with related video chunk requests and keep unavailable to irrelevant nodes. It adopts a random forwarding method which increases the diversity of routing paths, thereby increasing the size of anonymity sets and the cost of inferring user privacy.\n\nIn addition, proactive caching of redundant and obfuscated content at the edge can interfere with an attacker's ability to access the user's actual request records.\nQian~\\emph{et al.}~\\cite{Qian2020} proposed a privacy-aware content caching architecture for cognitive Internet of vehicles (CIoV) networks with proactive caching and blockchain technology. \nIn this system, roadside units (RSUs) and smart vehicles can cache content in advance, which can provide the cached content in the form of a broadcast to meet the content needs of other vehicles. \nTherefore, a vehicle only needs to obtain content from broadcast data without further requests, which can reduce user privacy exposure. \nAt the same time, blockchain technology is introduced to ensure a more secure and reliable transaction mode to guarantee the reliability of the content.\nAdditionally, Nikolaou~\\cite{Nikolaou2016} proposed two cache placement strategies for the joint caching of users. The first strategy considers the graph network structure between user terminals, and the second one focuses on the workload change of the server. However, transmitting requested videos between clients will leak privacy for both sides. The requested user proactively fetches and caches obfuscated content. At the same time, the server adds randomly obfuscated addresses when sending  feasible retrieval address lists to reduce the risk of privacy exposure.\n\n\n\n\n"
                    },
                    "subsubsection 4.1.2": {
                        "name": "Trusted distributed computing-based methods",
                        "content": "\n{The second category of trusted distributed computing methods aim at safeguarding request records primarily comprises \\textbf{secret sharing (SS)}, a secure multi-party computation technique, that can effectively prevent attackers from acquiring valued request records.}\nAcs~\\emph{et al.}~\\cite{Acs2019} proposed two timing attack defence methods for the edge router cache in the ICN network. For interactive traffic-type communication, random naming and SS are used for privacy protection to prevent attackers from obtaining specific traffic information.\nIn view of the content distribution traffic, a method of increasing artificial delay is proposed to protect privacy, and a certain delay is added to the private content that is hit by the router cache to prevent adversaries from determining the hit status of private-sensitive content. %This work also defined a privacy model based on $(\\epsilon,\\delta)$-probabilistic indistinguishability metric. \n\n\n"
                    },
                    "subsubsection 4.1.3": {
                        "name": "Cryptology-based methods",
                        "content": "\nCryptology-based methods have been widely used to protect the security and privacy of user request records and other information in Internet communications. \nHowever, there are also three challenging problems when using cryptographic methods to protect the privacy of request records in edge caching systems. Firstly, due to the existence of encryption, third-party edge caches probably cannot directly use encrypted requests to retrieve related content, leading to the unavailability of edge caches~\\cite{Yuan2016a, Leguay2017}. Secondly, introducing encryption technology may pose heavy computational pressure on the resource-constrained edge and end devices. Lastly, cryptology-based methods fail to prevent the leakage of record privacy from content providers or service providers, who have the key to decrypt requests. Therefore, how to apply cryptology-based techniques to edge caching systems is still a challenging problem.\n\n\\textit{\\textbf{Encryption communication.}}\nTo prevent the monitoring of users' request records by Internet service providers (ISPs), efforts have been made to encrypt request records and the corresponding transmitted data using encryption algorithms while ensuring the availability of the cache within the ISP.\nYuan~\\emph{et al.}~\\cite{Yuan2016a} designed a system to achieve efficient encrypted video delivery in the ISP network. The content cached in the network is encrypted and distributed in the ISP network. This system can efficiently and safely locate and retrieve related content from the ISP network with a proposed encrypted content fingerprint index for a given encrypted request.\n\n%Leguay~\\emph{et al.}~\\cite{Leguay2017} designed an encrypted caching protocol called CryptoCache that allows encrypted content to be cached and reused on untrusted caching entities. Content providers associate content with pseudo-identifiers and symmetrically encrypt the content. To enable the reuse of cached content, the pair of pseudo-identifiers and encrypted content remains the same across requests from different clients.\n\n\nIn order to improve privacy in the Content Delivery Network (CDN), Cui~\\emph{et al.}~\\cite{Cui2020c} proposed a novel encrypted method that combines searchable encryption (SE) and a multi-CDN strategy to achieve both content delivery performance and security in edge CDN nodes.\nThe work introduces the SE method to realize content security and searchability. In addition, a semantically secure algorithm is used to encrypt user requests so that the same query can correspond to different request content.\n%Besides, CDN nodes in adjacent geographical locations will be assigned to the same node cluster, though they may belong to different CDN providers. When the requested content hits, the content will be passed between CDN node clusters. Thus, various providers cannot wholly record the content information, assuming no collusion among CDN providers.\nTo further protect user preference privacy, a one-time nonce will also be used for secondary encryption, which will be transmitted together with the content transferred between CDN node clusters. For each request, the node must receive the nonce to search, and after the search hits, the nonce must be regenerated and re-encrypted before continuing to deliver the content.\n\n%Jiang ~\\emph{et al.}~\\cite{Jiang2020} designed a double-layer encryption scheme to solve two problems for content delivery in the Internet of Vehicles (IoV). The first layer proposes a safe and efficient admission control mechanism for IoV. The second layer protects user request privacy while enabling efficient content delivery among vehicles.  Specifically, the CP will group all vehicles according to their subscriptions, encrypt all content with different group keys, and send encrypted content to caching vehicles. All vehicles in the corresponding subscribed group accept the secret information. When a car sends a request of interest that hits on surrounding vehicles, the caching vehicle will secondary-encrypt the requested content with the help of ENs and send it back to the requested car. Then, the vehicle needs to perform a secondary decryption of the acquired content with the secret information and the help of ENs. In this way, the double-layer encryption scheme ensures the security control of content acquisition, and the privacy of user requests is guaranteed.\n\n\n\\textit{\\textbf{Homomorphic encryption (HE).}}\n{\nIn previous works, HE has been introduced to protect the privacy of vehicles' request records in IoV while collaborating with RSUs to improve the efficiency of edge caching.\n}\nCui~\\emph{et al.}~\\cite{Cui2020} proposed a cooperative download scheme in the IoV network, considering the security and privacy protection of request traces. This scheme uses edge computing architecture to reduce transmission delay. It uses lightweight encryption methods, such as elliptic-curve cryptography, the Tesla broadcast authentication, and additive HE, to protect user privacy and content security.\nThe strategy proposed in this work is composed of two phases: the \\textit{non-accelerated phase} and the \\textit{accelerated phase}, the details of which can be found in~\\cite{Cui2020}.\n%1) During the \\textit{non-acceleration phase}, the CP periodically broadcasts a content list mentioning the content provided. If a vehicle requests to download the content contained in the list, it establishes session keys with CP, sends elliptic-curve-based encrypted requests to the CP and RSUs, and downloads the content through the RSUs;\n%2) After collecting a certain number of encrypted requests, the system enters the \\textit{acceleration phase}. At this stage, the RSU analyzes the encrypted requests by an additive HE algorithm to obtain request frequency information. Then, it selects a proper edge caching vehicle to cache the frequently requested content. A vehicle near the edge caching vehicles can download popular content directly from them.\n\n\nKong~\\emph{et al.}~\\cite{Kong2019} utilized an invertible matrix to construct multiple content requests sent by different vehicles such that the RSUs can recover each request without being associated with a specific car. Specifically, when a vehicle needs to initiate a request, it will first generate a $k*k$ random invertible matrix and send secret information required for HE to $k$ vehicle users within a unified range. Then, in the response,  a collaborative request group is randomly selected for the requested vehicle. Other vehicles in the group first generate the requested information according to the Paillier HE algorithm and send it to the RSU, returning the HE information to the requested vehicle. That vehicle completes the corresponding HE according to the returned information and the invertible matrix. Finally, it sends the encrypted request to the RSU to retrieve the private content without exposing its privacy.\n\n\n\\textit{\\textbf{Private information retrieval (PIR).}}\nBy utilizing PIR methods, users are able to obtain the content they desire while preventing potential leaks of their private interests.\nKumar~\\emph{et al.}~\\cite{Kumar2019} were the first to introduce a PIR strategy based on encoding cache into wireless edge caching. Erasure-correcting codes are used to encode cached content, and different bit rates can be selected for videos with varying popularity to conserve backhaul bandwidth usage. Additionally, the scheme is based on general Reed-Solomon coding to safeguard user privacy from SBSs that may collude with one another.\n%Yan~\\emph{et al.}~\\cite{Yan2021} proposed an encoding caching scheme based on private keys. During the encoding caching process, each user simultaneously caches a private key. The coding block then passes through multiple users to improve caching efficiency. Users can only decode the content they require by utilizing their demand vector and private key but are unable to access other users' requested content within the cache block. \n%Moreover, since edges are typically owned by individuals or small organizations with limited operational capabilities, content stored in edge cache is vulnerable to break, such as cache tampering attacks and internal hardware failures. \nFurthermore, ensuring the integrity of content in the edge cache is essential for maintaining a stable edge caching system. This is particularly important because edge devices owned by individuals or small organizations are susceptible to cache tampering attacks and internal hardware failures. However, verifying the integrity of the content can compromise its privacy, especially when third-party verifiers are involved. To address this issue, Tong~\\emph{et al.}~\\cite{Tong2022} proposed an integrity-checking protocol for edge storage based on provable data possession to verify the integrity of cached content on a single EN. The protocol employs a PIR scheme and homomorphic verifiable tags to prevent the disclosure of sensitive information (e.g., user request traces, edge download schemes, and private content) to verifiers. %Furthermore, the authors proposed a batch-based strategy for the simultaneous verification of multiple ENs, which reduces the communication and computational complexity of multi-edge node verification. %Similarly, when users migrate sequentially from different ENs, the required tag cache for verification is optimized to reduce transmission costs further.\n%{\\bf YP: what is ICE-basic? what is label? not very clear with the relation between checking data integrity and  edge caching}\n\n\n%{\\bf YP: what is  `` the content distribution traffic article\"}\n\n%To solve the problem of performing a distributed inference with private data (e.g., preference information), Schlegel~\\emph{et al.}~\\cite{Schlegel2022} used the Reed-Solomon (RS) code to realize the secret sharing scheme during the computation and cache in ENs. The algorithm can be divided into the following steps:\n%1) Convert the user preference vector $\\bm{x}$ into $n$ secret shares through the RS code;\n%2) Split the collaborative filtering matrix {\\bf YP: what is the matrix? storing user-item iterations? or user-content request records?} into sub-matrices of the same size;\n%3) The secret share of step 1 and the sub-matrix of step 2 are allocated to edge nodes based on the arrangement rule of the cyclic group so that the secret share and sub-matrix assigned by each EN are duplicated with other nodes. \n%(4) The allocation rule of cyclic groups can be dynamically adjusted according to $z$, where $z$ is the privacy budget implying that it can  prevent $z$ edge nodes from jointly inferring user preferences;\n%(5) Operate the sub-matrix and the secret share, and record the operation as an intermediate result;\n%(6) The EN calculates enough intermediate results and transmits the results back to the user node, and the user node can restore $\\bm{W}\\cdot\\bm{x}$ through secret sharing.\n%{\\bf YP: what is x? better do not user notations}\n\n\n\n"
                    },
                    "subsubsection 4.1.4": {
                        "name": "Other methods",
                        "content": "\nOther methods, such as \\textbf{Optimization-based methods}, are also introduced to enhance the privacy of request traces or user preferences in EC.\nSivaraman~\\emph{et al.}~\\cite{Sivaraman2021} used game theory to formulate an off-path and cooperative caching problem in the edge of ICN, where users can choose their optimal routers at the edge network to cache content. Constraints in the problem include network latency, caching cost, and the amount of exposed user privacy. \n\\textcolor{black}{Two different privacy measures (i.e., mutual information and differential privacy) are used as constraints in the work.}\nFinally, it is proved that a Nash equilibrium point exists in the game, which can be solved by an iterative method. \n\\textcolor{black}{\nIn addition, to mislead adversaries eavesdropping on edge caches (EC), Hassanpour~\\emph{et al.}~\\cite{Hassanpour2023,Hassanpour2021} proposed caching approaches aimed at enhancing privacy and reducing communication costs in edge networks. The solution presented in~\\cite{Hassanpour2021} employs an $\\epsilon$-constraint optimization approach to balance the trade-off between minimizing the average delivery load and maximizing context-oriented privacy. By optimizing cache placement probabilities, the approach in~\\cite{Hassanpour2023} utilizes chunk-based joint probabilistic caching (JPC) to increase adversarial errors while maintaining the desired privacy levels. Furthermore, to address the exponential growth of the feasible solution set in the JPC optimization problem, they proposed a scalable JPC strategy to solve the linear programming optimization problem efficiently.\n}\n%{\\bf YP: what is BS and MU? Always use full name first}\n\nFurthermore, Cao~\\emph{et al.}~\\cite{Cao2020} studied the reliable and efficient performance of multimedia transmission services between base stations (BS) and MUs through a two-stage joint optimization. In the first stage of optimization, a service reliability evaluation mechanism is designed to evaluate the credibility of BS to ensure the security of user privacy information. Then, the price and reliability competition among BSes and the strategic interaction of all players are modelled by the Stackelberg game~\\cite{He2007}. A resource allocation problem is further proposed in the second stage to coordinate multiple MUs serving on the same BS. The potential game model is used to improve the transmission service performance. \nAdditionally, Shi~\\emph{et al.}~\\cite{Shi2018} proposed a model for the cache placement problem in wireless edge caching, considering a multi-attacker scenario where both benign users' and attackers' locations follow a homogeneous Poisson Point Process (PPP). An optimization problem is formulated to determine the probability of each caching file, considering the average probability of successful eavesdropper attacks and transmissions at the wireless edge network. Finally, the genetic algorithm is used to maximize the secure transmission performance of the system.\n\n\n%Zhong~\\emph{et al.} ~\\cite{Zhong2021} proposes a Device-to-Device (D2D) caching algorithm based on proactive caching. Each user only caches the video requested to reduce privacy exposure. Besides, the work designs a caching strategy and D2D link strategy for each device based on importance and social trust. Devices with a highly important and reliable level will cache highly popular videos without performing additional encoding operations to reduce the computational cost. Otherwise, devices will cache less popular videos to increase the diversity of cached content and perform encoding operations to lower caching space usage.\n\n\n\n\n"
                    }
                },
                "subsection 4.2": {
                    "name": "Privacy of Personal Information in Edge Cache",
                    "content": "\n%\u4e2a\u4eba\u8eab\u4efd\u4fe1\u606f\u4e5f\u662f\u4e00\u4e2a\u654f\u611f\u4fe1\u606f\uff0c\u5e94\u7528\u8be5\u4fe1\u606f\u8fb9\u7f18\u7f13\u5b58\u53ef\u4ee5\u8fdb\u884c\u6743\u9650\u63a7\u5236\uff0c\u7f13\u5b58\u51c6\u5165\u63a7\u5236\u7b49\u654f\u611f\u64cd\u4f5c\u3002\u4f46\u662f\u8fc7\u5206\u7684\u7528\u6237\u4e2a\u4eba\u4fe1\u606f\u66b4\u9732\u5f80\u5f80\u4f1a\u7ed9\u6076\u610f\u8282\u70b9\u548c\u653b\u51fb\u8005\u53ef\u4e58\u4e4b\u673a\uff0c\u6bd4\u5982\u8fdb\u884c\u5e7f\u544a\u63a8\u8350\u3001\u7f13\u5b58\u5185\u5bb9\u6c61\u67d3\u7b49\u653b\u51fb\u3002\u73b0\u5728\u5de5\u4f5c\u4e3b\u8981\u91c7\u7528\u533a\u5757\u94fe\u6280\u672f\u4fdd\u62a4\u7528\u6237\u4e2a\u4eba\u8eab\u4efd\u4fe1\u606f\u3002\nPersonal identity information is also sensitive in the network, which can be used by edge cache for carrying out sensitive operations such as permission control and cache admission control. However, excessive disclosure of users' personal identity information makes it convenient for malicious nodes and attackers to spam users with advertisements and recommendations and attack edge servers by polluting cached content. \n\n%{\\bf Blockchain-based method:}\n\n",
                    "subsubsection 4.2.1": {
                        "name": "Blockchain-based methods",
                        "content": "\n\nPrevious works mainly employ blockchain to protect users' identity information~\\cite{Lei2020, Dai2020, Vu2019, LiuJi2020}.\nSpecifically, Vu~\\emph{et al.}~\\cite{Vu2019} proposed a blockchain-based CDN (B-CDN) architecture for content delivery, which enables anonymous operations on users. The B-CDN leverages intelligent contracts to maintain the blockchain and provide CPs with users' registration and subscription functions while ensuring user privacy. Additionally, the B-CDN can reduce the cost of CP management by utilizing a public database of requested traces, which allows CPs to estimate users' preferences with virtual identities and maximize the efficiency of their caching services.\n\nNamed Data Network (NDN) is a variant of the ICN, where content can be retrieved by the content name. \nLei~\\emph{et al.}~\\cite{Lei2020} introduced a blockchain-based security architecture for improving the security and privacy of NDN-based vehicular edge computing systems. This work deploys blockchain nodes in edge servers and ISP nodes, where a delegated consensus algorithm is designed to enhance the efficiency of the blockchain. A three-layer management framework and an access control strategy are proposed for key management based on blockchain verification and vehicle attributes, respectively. A resource requester needs to prove to blockchain consensus nodes that it satisfies the access condition according to the access policy of the resource owner.\nDai~\\emph{et al.}~\\cite{Dai2020} designed a content caching mechanism based on the permissioned blockchain technology to address the problem of privacy and security in the vehicle edge computing network. A new block validator selection method is proposed to achieve a fast and efficient blockchain consensus mechanism. In addition, this work presents a deep reinforcement learning-based vehicle content caching algorithm. \n%This work formulates content caching as a problem to maximize the content caching utility subjecting to vehicle mobility, which can be solved by the deep reinforcement learning algorithm.\nLiu~\\emph{et al.}~\\cite{LiuJi2020} designed a decentralized caching framework empowered with blockchain credentials to tackle the challenges of content data verification and edge device authentication. In the designed system, it is possible to trace each transaction at an active edge network without a central manager. A cache order matching technique is devised to use the cache resources efficiently. Further, data integrity verification is done with the help of a content trading mechanism which helps data sharing among the edge devices of the edge network and ensures the efficiency of trading in the edge cashing system. \n    \n\n\n\n"
                    },
                    "subsubsection 4.2.2": {
                        "name": "Other methods",
                        "content": "\nThe \\textbf{access control} is also exploited to protect users' identity information~\\cite{Nguyen2023, Zhang2022b, Xue2019, Xue2018}.\nIn~\\cite{Xue2019, Xue2018}, Xue~\\emph{et al.} proposed a secure and efficient network access framework (SEAF) for cache resources at the edge of ICN. \nThe SEAF provides several security and privacy features, including content confidentiality, user privacy protection, user privilege revocation, countability, and efficiency. \nIn SEAF, routers at the edge network authenticate user requests to separate access control from content provisioning. Only authenticated requests can enter the network; thus, authorized users can only access the bandwidth and cache resources inside the ICN. Meanwhile, to protect privacy, users can verify their identity to the edge router by generating a valid group signature, thereby maintaining users' anonymity to the edge router.\nZhang~\\emph{et al. }~\\cite{Zhang2022b} focused on the security issues of cache-based software-defined networks, using the Tesla protocol to achieve fast authentication of the cache of vehicles and fog nodes. Besides, the Pedersen commitment mechanism is used to directly authenticate vehicles and fog nodes without exposing user identity privacy. Considering the limited computing power and delay-sensitive characteristics of the IoV, the author designed a set of cryptographic mechanisms supporting batch verification.\n\n%{\\color{orange}\n%Nguyen~\\emph{et al.}~\\cite{Nguyen2023} introduced a novel distributed game-theoretic technique for privacy-preserved mobile edge content sharing. This technique exhibits collaborations among CP and mobile ENs as a non-cooperative game, where a mobile EN presents its unused resources for content caching. The local information is shared only among the adjacent ENs, which helps to calculate Nash Equilibrium (NE), thereby preserving private information.\n%}\n\n"
                    }
                },
                "subsection 4.3": {
                    "name": "Privacy of Location in Edge Cache",
                    "content": "\n\n%\u7528\u6237\u7684\u5730\u7406\u4f4d\u7f6e\u4fe1\u606f\u4e5f\u662f\u91cd\u8981\u7684\u9690\u79c1\u4fe1\u606f\u4e4b\u4e00\uff0c\u4e3b\u8981\u5305\u62ec\u4e24\u7c7b\u5730\u7406\u4f4d\u7f6e\u4fe1\u606f\uff0c\u4e00\u4e2a\u662f\u7528\u6237\u672c\u8eab\u7684\u5730\u7406\u4f4d\u7f6e\u4fe1\u606f\\cite{}\uff0c\u53e6\u4e00\u4e2a\u662f\u7528\u6237\u611f\u5174\u8da3\u7684\u5730\u7406\u4f4d\u7f6e\u4fe1\u606f\\cite{}\uff0c\u4e5f\u79f0\u4e3a\u5174\u8da3\u70b9\u3002\u7528\u6237\u63a5\u53d7\u8fb9\u7f18\u7f13\u5b58\u670d\u52a1\u65f6\uff0c\u901a\u5e38\u53ef\u80fd\u5728\u4ee5\u4e0b\u8fc7\u7a0b\u4e2d\u66b4\u9732\u9690\u79c1\u5730\u7406\u4f4d\u7f6e\u4fe1\u606f\uff1a1\u3001\u4ece\u8fb9\u7f18\u7f13\u5b58\u4e2d\u76f4\u63a5\u53d6\u56de\u547d\u4e2d\u5185\u5bb9\u65f6\u53ef\u80fd\u4f1a\u5411\u8fb9\u7f18\u7f13\u5b58\u66b4\u9732\u7528\u6237\u7684\u771f\u5b9e\u5730\u7406\u4fe1\u606f\uff0c2\u3001\u5728\u63a5\u53d7\u4e00\u4e9b\u5185\u5bb9\u670d\u52a1\u65f6\u5019\uff0cCP\u548cEC\u53ef\u80fd\u4f1a\u9700\u8981\u7528\u6237\u7684\u5730\u7406\u4f4d\u7f6e\u4fe1\u606f\u4ee5\u66f4\u597d\u7684\u63d0\u4f9b\u5185\u5bb9\u670d\u52a1\uff0c3\u3001\u7528\u6237\u8bf7\u6c42\u548c\u7f13\u5b58location-based\u670d\u52a1\u7684\u65f6\u5019\u53ef\u80fd\u4f1a\u5411\u901a\u5e38\u4f1a\u670d\u52a1\u63d0\u4f9b\u5546\u63d0\u4f9b\u81ea\u5df1\u7684\u9690\u79c1\u5730\u7406\u4f4d\u7f6e\u548c\u5174\u8da3\u70b9\u7684\u5730\u7406\u4f4d\u7f6e\u4fe1\u606f\u3002\u4e4b\u524d\u6587\u7ae0\u4e2d\u4fdd\u62a4\u5730\u7406\u4f4d\u7f6e\u9690\u79c1\u7684\u65b9\u6cd5\u4e3b\u8981\u5305\u62ec\uff1a\u5730\u7406\u5dee\u5206\u9690\u79c1\u3001 Spatial Confusion, K-Anonymity\u7b49\u65b9\u6cd5\n\nThe location information is a kind of critical privacy of a high value,  including moving trajectory~\\cite{Wu2023, Li2023, Zhang2022a}, spatial coordinates~\\cite{Zhang2019b}, and other unique features~\\cite{Zhang2022a}. Noise-based methods comprise the primary class of techniques employed to enhance location privacy as illustrated in Fig.~\\ref{fig: user privacy}.\n%There are mainly two fundamental types of location information, which are the location information of a user herself~\\cite{Zhang2019b, Cui2020b, Andreoletti2018, Sen2018, Hu2018, Zhang2022a, GUYi-mingBAIGuang-weiSHENHang} and  the location information of a user's interest (as known as the Point of Interest, i.e., POI)~\\cite{Nisha2022, Amini2011, Hu2018, Yang2016}.\n%When a user enjoys edge caching services, she may expose private location information during  the following processes: 1) The user's actual geographic location may be exposed to the edge cache when retrieving the hit directly from the edge~\\cite{Cui2020b}; 2) CP and EC may need to collect the user's geographic location information to provide better content distribution services, such as predicting the mobility pattern of users~\\cite{Zhang2022a}; 3) In Location Based Service (LBS), users may provide their private geographic information and POI to search content of their interest~\\cite{Amini2011,Cui2020b,GUYi-mingBAIGuang-weiSHENHang,Nisha2022}. \n\n",
                    "subsubsection 4.3.1": {
                        "name": "Noise-based methods",
                        "content": "\nAs such,  noise-based methods are mainly introduced to protect location privacy, including geographic differential privacy~\\cite{Zhang2022a}, Spatial Confusion~\\cite{Amini2011,GUYi-mingBAIGuang-weiSHENHang,Zhang2019b}, $k$-anonymity~\\cite{Cui2020b,Nisha2022,Yang2016,Sen2018,Zhang2019b}, etc.\n\n\\textit{\\textbf{Differential privacy.}}\n{\nWith the increasing mobility of users and the constant threat of malicious attacks from third parties, there is a growing risk of privacy breaches in mobile edge caching. In order to address this issue, Zhang~\\emph{et al.}~\\cite{Zhang2022a} proposed a DP-based method for improving the video Quality of Experience (VQoE) for mobile users while protecting their location and preference privacy in mobile edge caching.\nThe proposed scheme utilizes a privacy-preserving approach for computing the location transfer model and aggregating user preferences, achieving a balance between caching service efficiency and privacy protection at mobile edge networks. Specifically, the Laplacian perturbation model is employed to protect users' location and preferences when submitting their information.\nBased on the perturbed information, mobile edge caching nodes can evaluate the popularity of videos in the user's area, and Q-learning~\\cite{Sutton1998} is employed to achieve cache optimization goals combined with transcoding technologies. \n%{\\bf Why you talk about model aggregation? which and why need to train a model? what the relation to cache?}\n}\n\n\n\\textit{\\textbf{Spatial obfuscation.}}\nAmini~\\emph{et al.}~\\cite{Amini2011} were one of the first to utilize devices' cache to protect users' location information, where location-based content can be periodically prefetched to devices in large geographic blocks before they are actually consumed. When content has been cached in a user's local area, the user can access it directly on their device without needing external network services. This can effectively reduce privacy exposure risks for the user.\n\nAdditionally, privacy protection can be achieved through a distributed collaborative cache that forms anonymous user groups within the vicinity.\nZhang~\\emph{et al.}~\\cite{Zhang2019b} proposed a multi-level caching strategy to reduce the number of users directly requesting LBS from the local service provider (LSP). In turn, users can obtain the required services from the local cache, surrounding neighbour caches, and trusted anonymizers. In this way, the interaction with untrusted LBS is reduced, and privacy exposure is mitigated. When the request is lost, it has to request the LSP by generating a stealth zone and making a request to the LSP. The anonymizer will select the optimal K-space anonymity to request content according to the prediction result (considering a user's future geographic location, the caching contribution rate of each unit, and the freshness of the content in the unit).\nHowever, the high communication overhead and computational energy consumption of users collaborating as a group pose problems in protecting privacy. Moreover, the introduction of centralized anonymizers is vulnerable to attacks, and if breached, all users' private information may be compromised.\nTo address these limitations, Ming~\\emph{et al.}~\\cite{GUYi-mingBAIGuang-weiSHENHang} proposed a method that employs the trusted ESs to preprocess user requests and blur their location information during the snapshot query (i.e., one-shot query) of their POI. The ESs cache the requested POI for further query, thus minimizing the number of queries exposed to LBS providers and potential attackers. Additionally, in continuous queries, fuzzy prediction queries are generated and correlated with the actual query to enhance the queries' utility while interfering with attackers.  \n\n\n\n\\textit{\\textbf{Anonymity.}}\nThe utilization of cache in edge devices, such as user devices~\\cite{Yang2016, Cui2020b, Nisha2022}, ESs~\\cite{Sen2018} and RSUs~\\cite{Hu2018}, can keep users' transparency from LBS providers by reusing the users' POI within a specific region. This approach allows users to access the cached POI directly at the edge network instead of relying on remote LBS service providers. \nAdditional privacy protections (e.g., $k$-anonymity~\\cite{Yang2016, Hu2018, Zhang2023}, $l$-diversity~\\cite{Cui2020b}, anonymity groups~\\cite{Sen2018, Nisha2022}) are exploited when resources have to be obtained from LBS providers.\nAs a result, the likelihood of exposing sensitive location information to the service provider is reduced.\n\n%{\\color{orange}\n%Yang~\\emph{et al.}~\\cite{Yang2016} designed a distributed multi-level caching architecture with the $k$-anonymity method to improve caching efficiency and protect users' personal and geographic information. When a user requests a geographically sensitive POI, the system will retrieve it from both the local user and surrounding users. If the quality of service requirements cannot be met, the Cloaking Region Generating Algorithm (CRGA) will be used to request content from the remote LBS provider based on the spatial $k$-anonymity algorithm. At the same time, the system will consider two characteristics, i.e., request strength and content freshness, to select the spatial location to cache the content.}\nZhang~\\emph{et al.}~\\cite{Zhang2023} devised a Caching-based Dual $k$-Anonymous (CDKA) mechanism to preserve location privacy. CDKA uses double anonymity and multilevel caching to reduce communication overhead while providing location privacy. For this, an edge server is used to intervene between the user and the LBS server, and location privacy is ensured by making mobile clients and edge servers anonymous. The proposed mechanism is assessed for computational efficiency, communication overhead, and cache hit ratio.\nAdditionally, dealing with vehicles' high-speed movement characteristics in vehicular networks, Hu~\\emph{et al.}~\\cite{Hu2018} designed a privacy protection algorithm combining proactive caching and the $k$-anonymity method. When a vehicle user requests a specific POI, it needs to send $k-1$ obfuscated requests simultaneously. Besides, the corresponding request content will be obtained through multiple passing RSUs to protect the user's location information, including factual geographic and POI. \n\n\n%Besides, Cui~\\emph{et al.}~\\cite{Cui2020b} proposed a cache-based privacy protection (CBPP) algorithm for LBS. CBPP combines the peer-to-peer (P2P) caching technique and the $l$-diversity technique to effectively protect users' geographic location information and request records containing personal privacy simultaneously. \n%The user devices cache POI obtained from the LBS server or its neighbours and leverage the cached content to respond to queries from other users later. \n%If the user cannot acquire the required service information from its neighbours, it adopts the $l$-diversity method to generate $l-1$ requests by mixing the user's own set of historically missed requests with the actual requests to obtain information from the LBS. This approach reduces the number of queries sent to the LBS server, thereby hiding the user from the LBS server. \n%The P2P caching technique can reduce service delays and prevent the interaction between users and LBS providers, which may cause privacy leakage.\n%To avoid privacy leakage due to P2P caching, the  method .... {\\bf YP:  how it prevent privacy leakage should be explained.}. \n\nMoreover, at the edge of the wireless network, Sen~\\emph{et al.}~\\cite{Sen2018} proposed a double cache strategy to deploy a pair of caches for each region. Cache $A$ records previous request results of users in the region, and cache $B$ caches all user requests and maintains cooperation between users. When querying private content, a user queries cache $A$ first. If it is not hit, the request will be redirected to cache $B$ for conversion. Finally, the converted request is sent to other users within the region to request LBS together, and the received results may be maintained in cache $A$ for further queries.\n\nTo further prevent users' location and personal information from being accessed by untrustworthy EC and malicious users,\nNisha~\\emph{et al.}~\\cite{Nisha2022} proposed a caching scheme called Group Collaboration Scheme (GCS) to request POI combining with spatial obfuscation. In this scheme, users who need to find POI in a specific area will modify the requested area according to the proposed random area obfuscation algorithm and then register with the group authenticator to obtain virtual group identity information and cooperative anonymous user groups. The collaboration is one-time, and the anonymous group changes as the user moves. Users with request requirements will cooperate with nearby users to query whether the cache of other users in the anonymous group meets the request requirements. If the request POI is unavailable in the user group, the required content will be requested in the name of the anonymous group. %Once the required content is returned, the cache of users in the anonymous group will be updated according to group rules.\n\n"
                    },
                    "subsubsection 4.3.2": {
                        "name": "Trusted distributed computing",
                        "content": "\nTo enhance the Quality of Service (QoS), CPs collaborate with ISPs to deploy edge caching resources as close to the users as possible. ISPs can support edge cache by placing Virtual Servers (VSes) at the network's edge and assigning them to CPs. However, CPs only possess the request records of users, while ISPs only have access to their geographic location information. In the caching process, CPs do not want to disclose all the requested information to the ISPs, and vice versa. \n%Thus, efficiently integrating the two parties for edge caching service deployment is a challenge worth exploring.\nTo deal with this challenge, Andreoletti~\\emph{et al.}~\\cite{Andreoletti2018} proposed a secure multi-party computation protocol to facilitate cooperation between ISPs and CPs without requiring either party to disclose sensitive information. The protocol enables ISPs to obtain the number of requests for specific video content in a given area at a low computational cost. Once the ISP has this information, it can deploy VSes efficiently, and the CP can use these VSes to place the edge cache, thereby minimizing the number of hops for content delivery and reducing communication delays.\n\n\\textcolor{black}{Despite the comprehensive introduction of major solutions, our discussion is not exhaustive. Thus, we provide a supplementary introduction Table~\\ref{Tab: user privacy} in Appendix, briefly introducing  other solutions to protect user privacy in edge caching systems that have  not been discussed in detail in Section~\\ref{sec: user privacy}. }\n\n\n\n\n\n"
                    }
                }
            },
            "section 5": {
                "name": "Enhancing Content Privacy in Edge Caching Systems",
                "content": "\\label{sec: content privacy}\nIn this section, we move on to discuss defence methods that can preserve the second type of sensitive information, i.e., content privacy, in edge caching systems. \nWe present a timeline, as depicted in Fig.~\\ref{fig: content privacy}, summarizing the methods employed to safeguard content privacy, encompassing private content data and content popularity.\n\n\n\n\n",
                "subsection 5.1": {
                    "name": "Privacy of Content Data in Edge Cache",
                    "content": "\n%\u6b64\u5916\uff0c\u8fb9\u7f18\u8282\u70b9\u6709\u65f6\u4e5f\u4f1a\u7f13\u5b58\u7528\u6237\u81ea\u8eab\u4ea7\u751f\u7684\u9690\u79c1\u6570\u636e\uff0c\u6bd4\u5982\u5728\u793e\u4ea4\u5185\u5bb9\u7f51\u7edc\u4e2d\uff0c\u6bcf\u4e2a\u7528\u6237\u90fd\u53ef\u4ee5\u88ab\u770b\u4f5c\u4e00\u4e2a\u5185\u5bb9\u4f9b\u5e94\u5546\u3002\u5185\u5bb9\u5206\u53d1\u5e73\u53f0\u548c\u7528\u6237\u90fd\u5e0c\u671b\u4ea7\u751f\u7684\u65b0\u5185\u5bb9\u80fd\u88ab\u9ad8\u6548\u51c6\u786e\u5730\u5206\u53d1\u5230\u611f\u5174\u8da3\u7684\u6d88\u8d39\u8005\u8bbe\u5907\u4e0a\uff0c\u6b64\u65f6\u91c7\u7528\u8fb9\u7f18\u7f13\u5b58\u67b6\u6784\u4e0d\u5931\u4e3a\u4e00\u4e2a\u5f88\u597d\u7684\u9009\u62e9\u3002\u8fd9\u662f\u56e0\u4e3a\u540c\u533a\u57df\u7684\u7528\u6237\\cite{}\u6216\u8005\u793e\u4ea4\u5173\u7cfb\u7d27\u5bc6\u7684\u7528\u6237\\cite{}\u53ef\u80fd\u5bf9\u5468\u8fb9\u5185\u5bb9\u751f\u4ea7\u8005\u7684\u6570\u636e\u66f4\u52a0\u611f\u5174\u8da3\u3002\u56e0\u6b64\uff0c\u8fb9\u7f18\u7f13\u5b58\u4e0d\u4ec5\u53ef\u4ee5\u964d\u4f4e\u6838\u5fc3\u7f51\u7edc\u7684\u5e26\u5bbd\u6d88\u8017\uff0c\u8fd8\u53ef\u4ee5\u964d\u4f4e\u5ef6\u65f6\u3002\u4f46\u662f\uff0c\u7531\u4e8e\u8fb9\u7f18\u7f51\u7edc\u4e2d\u53ef\u80fd\u5b58\u5728\u4e0d\u5b8c\u5168\u53ef\u4fe1\u7684\u8fb9\u7f18\u8282\u70b9\u6216\u8005\u6076\u610f\u7684\u3001\u65e0\u6743\u9650\u7684\u7528\u6237\uff0c\u8fd9\u7c7b\u9690\u79c1\u6570\u636e\u53ef\u80fd\u4f1a\u5b58\u5728\u6cc4\u9732\u7684\u98ce\u9669\u3002\n\nOther than caching content for CPs, edge servers are also able to cache private content generated by users. %For example, in social content networks, each user can be regarded as a content provider\\cite{Nikolaou2016, Xu2020}. Both content distribution platforms and users desire that content generated by users can be efficiently and accurately delivered to the right consumers. In this case, the edge caching architecture is a feasible solution because users in the same area~\\cite{Ma2017b} or users with solid social relations~\\cite{Wang2019} are more likely interested in content generated by surrounding users. With edge caching for content delivery, the bandwidth consumption of the core network and the transmission latency can be lowered.\nHowever, due to the presence of incompletely trusted ESs~\\cite{Pu2019, Xu2019} or malicious and unauthorized users~\\cite{Xu2019, Xu2020} at the edge network, stored content in EC may face privacy leakage risks.\n\n\\textbf{DP-based methods}\nare used to upload local data in the network cache while preserving its privacy. For example, Wang~\\emph{et al.}~\\cite{WangHu2022} proposed a Differential Privacy-Preserving Peep Learning Caching Framework (DP-DLCF) to deal with the privacy leakage problem of private content in edge caching networks. The privacy budget is utilized adaptively to strike a trade-off between the privacy and accuracy of the  prediction. In the proposed technique, users upload their data after perturbing it with a randomized response technique based on LDP to preserve the privacy of their local data. Next, the neighboring BS accumulates the uploaded data and transfers it to the deep model for training. Moreover, the prediction accuracy of the model training is improved by the bootstrap aggregation algorithm.\n\n\\textbf{Crytology-based methods} can also be leveraged in protecting the private content in the edge cache.\nPu~\\emph{et al.}~\\cite{Pu2019} proposed a secure and privacy-aware content-sharing strategy to protect sharing data stored and delivered by incompletely trusted ESs. To ensure the secure sharing of content, the content generator first encrypts the content using the Ciphertext-Policy Attribute-Based Encryption (CP-ABE) algorithm and calculates its signature based on its private key. Additionally, by utilizing the public key cached at the nearest ES, the generator performs secondary encryption of the content to the nearest ES.\nWhen the ES receives the encrypted content from the content generator, it will first decrypt the content with its private key and check the security of the content. According to the secret sharing (SS) scheme, ES randomly divides the content into $n$ parts and distributes the content parts to other $n-1$ ESs to store the content. The proposed scheme can effectively ensure the integrity and recovery ability of the content in case any edge cache node becomes offline.\n\\textcolor{black}{\nThe SS method was also integrated by Xiong~\\emph{et al.}~\\cite{Xiong2020} to design an edge-assisted privacy-preserving data-sharing framework for autonomous vehicles. This approach encrypts raw data into two ciphertexts, which are processed by two edge servers. Additionally, a privacy-preserving convolutional neural network (P-CNN) was developed to ensure that the classification results are identical to those of the original CNN model, without any data leakage. The framework effectively addresses threats such as potential data leakage and unauthorized access to private content by malicious vehicles or edge servers.\n}\n\n\n\\textbf{\nOptimization-based methods} are introduced to enhance the privacy of content caching in edge servers.\nTo prevent private content from leaking to the unreliable edges and make optimal caching decisions for MUs, Xu~\\emph{et al.}~\\cite{Xu2019} used the multi-leader and multi-follower Stackelberg game to model a multi-link cache scenario at the mobile edge network. \nIn the scenario, Edge Computing small base stations (ECSBS) act as leaders and, firstly, set pricing strategies in a non-cooperative game. Then, a trust mechanism is proposed to evaluate the reliability of each ECSBS, which consists of two parts: \\textit{direct trust degree} and \\textit{indirect trust degree}. Based on the caching reliability and pricing offered by ECSBS, MUs can make their optimal caching decisions as followers.\n%Furthermore, a Chinese Remainder Theorem (CRT) based content encryption protocol is proposed to protect mobile users' privacy and the content's integrity.\nAdditionally, Xu~\\emph{et al.}~\\cite{Xu2020} proposed a Stackelberg game model to encourage edge cache devices (ECDs) to provide secure caching services in both static and dynamic scenarios. The model takes into account the selfish and open nature of ECDs and employs a zero-payment mechanism to penalize ECDs that provide poor services. The optimal strategies for the CP and ECDs in a static game are analyzed, proving the existence of a unique equilibrium in the Stackelberg game. Besides, in dynamic games with incomplete information, the Q-learning algorithm is used to solve the problem. %This work aims to incentivize ECDs to provide high-security caching services and improve the overall efficiency of the edge caching system.\n\n\n\n"
                },
                "subsection 5.2": {
                    "name": "Privacy of Content Popularity in Edge Cache",
                    "content": "\nContent popularity, which can be used as the key knowledge to improve caching efficiency, is business-critical information for the CPs and edge caching managers (e.g., ISP). \nDue to the limited number of records in the service scope of edge cache (e.g., serving a specific geographical location range or a particular network level), edge caching suppliers may require content providers and other edge caching entities to provide the critical content popularity information so that they can judiciously make caching decisions so as to shrink bandwidth consumption of the core network. \n\n{\nAndreoletti~\\emph{et al.}~\\cite{Andreoletti2019a} improved the solution proposed in~\\cite{Yuan2016a} by allowing CPs to encrypt content and associate them with pseudonyms to prevent privacy leakage to edge caching managers. ISPs only count the occurrences of these pseudonyms to infer content popularity without examining the original content. The authors introduced the mathematical definition of privacy and studied the trade-off relationship between privacy and hit rate, retrieval latency, and traffic load metrics.\nAdditionally, Andreoletti~\\emph{et al.}~\\cite{Andreoletti2019} proposed a protocol for spatial partitioning of ISP caches based on the popularity of different CPs' content, which aims to improve the quality of service (QoS) of edge caching services while protecting CPs' privacy of popularity information. The protocol employs the Shamir secret sharing scheme for CPs to share the popularity information between the ISP and the regulator authority, which guarantees a fair subdivision of the cache storage and the preservation of privacy. The ISP can calculate the caching space requirement for each CP using the secret information, thus protecting CPs' privacy.\n%{\\bf YP: what is supervisor?}\n\n\n\n\nSimilarly, Araldo~\\emph{et al.}~\\cite{Araldo2018} proposed a caching space partitioning method that protects the popularity information of CPs while ensuring the efficiency of edge caching. The method divides the ISP's caching space into multiple slices and assigns each slice to different CPs using the stochastic dynamic cache partitioning algorithm. The algorithm takes an initial slice allocation as input and iteratively optimizes the slice allocation scheme by testing the Cache Miss rate of the allocation scheme in each round. However, unlike the partitioning method proposed by Andreoletti~\\emph{et al.}~\\cite{Andreoletti2019}, this method does not depend on the private information of CPs' popularity. Additionally, this architecture also supports a transparent cache of encrypted content deployed at the edge of the ISP network.\n}\n\n\n\n\n\n"
                }
            },
            "section 6": {
                "name": "Enhancing Knowledge Privacy in Edge Caching Systems",
                "content": " \\label{sec: knowledge privacy}\n\nIn this section, we discuss defence methods that can preserve privacy for the last type of privacy, i.e., knowledge privacy, in edge caching systems. \nAll edge caching service providers have the motivation to extract knowledge for improving caching performance, which gives rise to the  trade-off between caching performance and privacy protection. Due to the high dynamics and complicated access patterns driven by users' interest~\\cite{Muller2017, Yang2019}, it is essential to come up with intelligent edge caching algorithms to improve the caching performance. \nMachine learning-based methods provide a feasible framework to extract user access patterns by exploiting collected datasets related to users, which may contain sensitive information. \nFor example, video request access patterns are driven by users' interest in different locations~\\cite{Ma2017b, Dhar2011}. Users may keep dynamic moving~\\cite{Dai2020}, and their interests evolve over time~\\cite{Zhang2022}. Thus, it is necessary to make edge caching decisions based on features which can be extracted from localized and private user information by machine learning methods.\n%Machine learning based methods used in edge caching are also vulnerable to two types of privacy risk: 1) exploratory, in which adversaries investigate vulnerabilities (e.g., training dataset, model parameter, and gradient data) without changing the training process. 2) causative, in which attackers change the training process of machine learning models by manipulating and injecting misleading training dataset.\n\n\\textbf{Federated learning (FL)} as a distributed machine learning framework is the  most popular method to preserve knowledge privacy. FL trains a learning-based algorithm across multiple decentralized devices or edge servers holding local data samples without exposing them.\nAdditionally, we provide a comprehensive summary of the FL-based methods employed to safeguard knowledge privacy, presented in a timeline illustrated in Fig.~\\ref{fig: Knowledge privacy}. Besides, Table~\\ref{tab: solutions for knowledge privacy} in Appendix offers a detailed classification of these solutions based on the combination of methods used.\n\n\n\n\n\n",
                "subsection 6.1": {
                    "name": "Enhacing Knowledge Privacy with FL Frameworks",
                    "content": "\nThe most common approach is to use an FL framework to train prediction models.\nUnlike traditional machine learning methods, FL does not collect raw data for model training~\\cite{Yu2018, Yu2020, Yu2020a}.  This framework encourages models to be trained on local data, and all training works upload model parameters or gradients rather than sensitive raw data.\nYu~\\emph{et al.}~\\cite{Yu2018} were probably the first to propose a learning-based proactive content caching method following the FL framework. This work proposes a hybrid filtering method based on the autoencoder to calculate the user-content similarity and predict the content of a user's interest. \nYu~\\emph{et al.}~\\cite{Yu2020} also designed an FL-based proactive caching method for vehicular networks. Considering the high mobility of vehicles and dynamic content popularity in vehicular networks, RSUs integrate the mobility-aware cache replacement policy to make proactive caching decisions. \n%\\textcolor{orange}{\n%Yu~\\emph{et al.}~\\cite{Yu2020a} proposed an active caching strategy based on peer-to-peer FL to alleviate the problem of privacy exposure during model training. At the same time, mobile vehicles, instead of edge caching nodes, are used as model aggregation servers to alleviate the impact of the high mobility of vehicles. \nFollowing the FL framework, the above three works enable users to train machine learning models (e.g., autoencoder model) with their private datasets, locally and distributively, and upload trained models to the corresponding parameter server for aggregation.\n\n\nReinforcement learning can be realized in the FL framework to solve the complex dynamic control problem and mitigate the privacy leakage problem in edge caching systems~\\cite{Wang2019a, Li2020a, Wang2020, Liu2022, Abadi2016, Qiao2022, Xiao2018a}\nto improve the caching performance and privacy protection simultaneously.\nWang~\\emph{et al.}~\\cite{Wang2019a} proposed an ``In-EDGE AI\" system with deep reinforcement learning in FL. It delegates the reinforcement learning training task to the device side to protect the private dataset and brings more intelligence to edge systems.\n% Li~\\emph{et al.}~\\cite{Li2020a} proposed a weighted distributed deep reinforcement learning-based method to find the optimal cache replacement algorithm in D2D networks.\n%\u8be5\u6587\u7ae0\u4e0e\u4fdd\u62a4\u9690\u79c1\u4e0d\u592a\u76f8\u5173\uff0c\u4e3b\u8981\u662f\u63d0\u4f9b\u7f13\u5b58\u547d\u4e2d\u7387\u7684\n%\\textcolor{orange}{Wang~\\emph{et al.}~\\cite{Wang2020} proposed a federation-deep-reinforcement-learning-based cooperative edge caching framework. The work formulates the content replacement problem by a Markov Decision Process (MDP) and introduces the double deep Q-network to solve the data sample problem in a huge discontinuous space.}\nLiu~\\emph{et al.}~\\cite{Liu2022} \n%and Zheng~\\emph{et al.}~\\cite{Zheng2021} \nproposed a privacy-preserving distributed deep deterministic policy gradient scheme to make caching decisions for EC. \nAt the same time, to preserve user privacy, the model only predicts content popularity by avoiding mining sensitive historical information. The model training process is completed by FL in order to prevent users from leaking privacy to ESes. \nQiao~\\emph{et al.}~\\cite{Qiao2022} proposed an FL-based proactive content caching scheme to shorten content retrieval latency and protect users' private datasets. Firstly, the edge computing architecture reduces energy consumption and transmission overhead. The problems of client selection and local iteration round selection in the FL process are modeled as an MDP, which is solved by the deep reinforcement learning algorithm. The solution can alleviate the non-independent and independent distributed (Non-IID) data distribution problem and limited resources for end users.\n\n\n\nIn vehicular networks, privacy-preserving edge caching nodes, such as at RSUs, can also be effectively achieved by combining FL and DRL frameworks. However, the high mobility of vehicles introduces additional challenges to edge caching efficiency and privacy security. To tackle these challenges, Wu~\\emph{et al.}~\\cite{Wu2023} designed an asynchronous federated learning model to evaluate regional content popularity, taking into account vehicle movement speed, RSU coverage, and network channel conditions. They modified the selection of training vehicles and the aggregation function's weight, assigning different weights to vehicles with varying dwell times and channel conditions. They proposed a joint content placement strategy based on dueling DRL to overcome the caching efficiency degradation caused by high vehicle mobility. This strategy further reduces content transmission delay while ensuring user data privacy and RSU joint caching efficiency in edge vehicle computing scenarios.\nLi~\\emph{et al.}~\\cite{Li2023} tackled the privacy and long-term training delay issues in high-precision map caching in intelligent connected vehicles (ICV) by formulating a framework called \\textit{federated deep reinforcement learning} (F-DRL). F-DRL is an MDP-based edge cooperative caching technique in which Dueling-Deep-Q-Network (Dueling-DQN) is employed to optimize the adaptive edge caching scheme with an improved FL approach to preserve the privacy of ICV. For FL, resource provision and member vehicle selection are made using joint optimization to minimize the delays in training and load in the edge cache.\n\n\n%\u4f20\u539f\u59cb\u6a21\u578b\u6570\u636e\uff0c\u5e76\u8f85\u4ee5\u5176\u4ed6\u4fdd\u62a4\u65b9\u6cd5\uff0c\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u548c\u673a\u5668\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u4ea7\u751f\u7684\u5176\u4ed6\u7684\u6570\u636e\u3001\u6bd4\u5982\u7279\u5f81\u3001\u534f\u540c\u8fc7\u6ee4\u77e9\u9635\u7b49\u5173\u952e\n"
                },
                "subsection 6.2": {
                    "name": "Combining FL with Other Methods",
                    "content": "\n\nOther than requiring sensitive data to train machine learning models, the edge caching system may also need private information to make edge caching decisions. Therefore, some works~\\cite{Qi2020, Cheng2021, Zheng2022, Wang2022a} have introduced additional privacy protection methods into the FL framework to enhance data privacy during the model training process.\n%\\textcolor{orange}{\n%Cheng~\\emph{et al.}~\\cite{Cheng2021} formulated the D2D caching problem as a multi-agent MDP problem. Furthermore, to ensure the performance and security of model training, this work proposed a two-layer blockchain structure. The first blockchain layer uses the Raft consensus mechanism to encourage users in the same region to participate in model aggregation. The main blockchain aggregates models in each area using the Practical Byzantine Fault Tolerance (PBFT) consensus mechanism. In this way, the reliability of model aggregation is ensured.}\nZheng~\\emph{et al.}~\\cite{Zheng2022} proposed a privacy-preserving FL model to predict popularity in an unsupervised manner. The prediction method introduces two concepts: local and global popularity, considering both efficiency and privacy. Local popularity can be evaluated by historical information by the Long Short-Term Memory (LSTM) model on users. In contrast, global popularity can only be predicted by the information at the current moment, which will be erased immediately at the next moment. \nFL is applied to perform offline training and online popularity evaluation with distributed information to avoid exposing privacy.\nWang~\\emph{et al.}~\\cite{Wang2022a} proposed a private FL-based caching scheme, which utilizes an FL framework and a pseudo rating matrix to collect statistical characteristics of user groups. With this distorted information, the server can predict the popularity of content and make caching decisions. The scheme also protects the privacy of individual users from being accessed by servers and other users.\n%\\textcolor{orange}{\n%Qi~\\emph{et al.}~\\cite{Qi2020} used the FL method to predict content popularity. The Neural Network-based model for prediction is trained by users' local historical request information, and the model will be uploaded to the EN for aggregation. Besides, to protect privacy, MUs upload a weighted sum of user preferences, file popularity, and the total number of requests for all files to the base station to aid in making caching decisions.}\nSaputra~\\emph{et al.}~\\cite{Saputra2022} introduced the HE method into the FL framework to protect the privacy of MUs with constrained computing resources. The scheme allows MUs to upload encrypted training data to ESs, which can perform additional training processes. The portions of the encrypted decision problem are modeled as a multi-objective profit maximization problem considering both privacy and training costs. The optimization problem is proved to be a concave function that can be solved by the interior point method. At the same time, the training data cached at the EN or the cloud node is HE based on the Brakerski Fan Vercauteren (BFV) method.\n\n%\u4f20\u52a0\u566a\u6a21\u578b\u6570\u636e\uff0c\u540c\u65f6\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u548c\u6a21\u578b\u9690\u79c1\n%\u4f20\u52a0\u566a\u6570\u636e\uff0c\u5e76\u8f85\u52a9\u4ee5\u5176\u4ed6\u65b9\u5f0f\u4fdd\u62a4\u9690\u79c1\n"
                },
                "subsection 6.3": {
                    "name": "Combining  Noise-based FL with Other Methods",
                    "content": "\nMore parameters or gradients (representing knowledge extracted from user-related data) can expose user privacy because attackers can probably infer and restore user information from exposed model information. In addition, model parameters may have a huge economic value, and directly uploading model parameters will compromise the self-interest of model owners. Therefore, there are works dedicated to upgrading the FL framework by adding noises~\\cite{LuYun2020, Yu2021b, Jiang2023, NAIR2023} or other interference~\\cite{Wang2022, Chen2022, Cui2022} to model information prior to exposure. \n\nThe FL framework has further employed DP-based noise to safeguard the parameters or gradients in previous works.\nLu~\\emph{et al.}~\\cite{LuYun2020} designed a differentially private asynchronous federated learning scheme to share resources in vehicular networks. The proposed scheme uses LDP to perturb the local model parameters with noise drawn from the Gaussian distribution. Moreover, a distributed random update method is used to preserve the privacy of the global ML model during the update process.\nYu~\\emph{et al.}~\\cite{Yu2021b} proposed an FL framework based on privacy protection so that the user dataset is always kept locally. Further, the LDP mechanism is added while exchanging model parameters for aggregation to protect user privacy. In addition, this work proposes a hierarchical joint caching mechanism to combine the characteristics of local caching and global caching. A weighted aggregation method is used to solve the data imbalance problem. \nJiang~\\emph{et al.}~\\cite{Jiang2023} developed a privacy-preserving FL framework for industrial data processing. This framework works by compressing adaptive gradients in the first place during model training at the edge terminal. Afterwards, hybrid DP is applied to optimize the FL framework, and the privacy-preserved gradients are transferred in the industrial environment.\n\nFurthermore, some efforts try to enhance privacy protection in edge caching systems by integrating the Generative Adversarial Network (GAN) technique with FL.\nWang~\\emph{et al.}~\\cite{Wang2022} combined FL and Wasserstein Generative Adversarial Network  (WGAN) to improve further the efficiency of model training and accuracy of the popularity prediction model. With the fake data generated by WGAN, the privacy of users' real preferences can be enhanced.  Besides, gradient clipping and model parameter restriction are applied at the training time to protect model privacy and security.\n\n\nPrivacy preservation in vehicular edge computing is demanded since new attack types are developed continuously. To cope with the situation, Chen~\\emph{et al.}~\\cite{Chen2022} proposed a novel edge computing approach that utilizes unmanned aerial vehicle swarms as edge computing nodes to aggregate model parameters and caches the model parameters, thereby reducing the communication cost of the core network and protecting users' dataset. To enhance the security and privacy protection of cached model parameters, the authors designed a comprehensive protocol for model aggregation, storage, and transmission, which can effectively prevent potential security threats, such as poisoning attacks, man-in-the-middle attacks, and eavesdropping attacks.\nMeanwhile, to defend against pollution attacks, the cosine similarity between local parameters and its edge aggregation parameters is calculated to exclude parameters uploaded by malicious nodes. Then, parameters are re-aggregated, and the aggregated parameters are sent to the cloud servers for the final process. Schnorr signature is also added before uploading the aggregated model parameters to ensure the reliability of the parameters.\n\n\nIn the Internet of Things (IoT) realm, edge computing architectures can expedite data processing, while edge caching can accelerate file delivery speeds for IoT devices. To ensure the reliability and privacy of data in IoT networks, Cui~\\emph{et al.}~\\cite{Cui2022} proposed a blockchain system comprising four contracts to predict content popularity, cache, and deliver sensitive content.\nMeanwhile, to improve the security and throughput of the system, the Proof of Stake (PoS) consensus mechanism based on reputation is modified and applied to reach consensus more efficiently. Besides, the FL algorithm based on compressed gradients is used to protect the privacy information of ESs and reduce communication overhead. The K-means algorithm filters important gradients that must be uploaded accurately. \nThese gradients are then quantified using a clustering-based quantization algorithm to reduce the amount of data uploaded. \nMeanwhile, an averaged gradient value is uploaded to the server for other gradients with a small value. \n%Additionally, some nodes may upload forged gradients to disturb the model training process when uploading compressed gradients. \nBlockchain technique is also used to verify uploaded data.\nRecently, the Internet of Medical Things (IoMT) is becoming popular. However, it is also prone to privacy threats like other edge computing-based approaches. To tackle these challenges for IoMT-based big data analytics, Nair~\\emph{et al.}~\\cite{NAIR2023} proposed an edge computing-based FL scheme called \\textit{Fed\\_select}, which ensures privacy and provides load reduction at the central FL server by introducing an edge server. To ensure privacy, \\textit{Fed\\_select} performs user anonymity at the edge server by employing hybrid encryption techniques with client and attribute selection performed at the edge server. Moreover, DP with Laplace noise is applied to the shared gradients to make them private during transfer.\n\n\\textcolor{black}{Due to limited space, we briefly present  an overview of additional solutions for safeguarding knowledge privacy in edge caching systems in Table~\\ref{Tab: knowledge privacy} in Appendix, which covers methods not fully discussed in Section~\\ref{sec: knowledge privacy}.}\n\n\n\n\n"
                }
            },
            "section 7": {
                "name": "Open Challenges and Future Research Directions",
                "content": "\\label{sec: Future Directions}\n\n\\textcolor{black}{In this section, we discuss open challenges and future research directions worth exploring in privacy-preserving edge caching (PPEC). As shown in Fig.~\\ref{fig: future work}, we elaborate on the challenges and open issues from three major perspectives in PPEC: collaboration, efficiency, and efficacy.}\n\n\n",
                "subsection 7.1": {
                    "name": "Trade-off Between Collaboration and Privacy in PPEC",
                    "content": "\n\n\nDue to the large scale of network applications, %it is impossible to provide content caching services by a single edge server. I\nit is common to deploy multiple edge servers for collaboratively caching content. To enable collaborations between edge servers, critical information such as cached content or other private information will be exchanged between edge servers, which can expose user privacy and raise privacy concerns. \n%Collaborative edge caching refers to a distributed caching mechanism in which multiple edge devices work together to store and share cached content or make the joint caching decisions with the exchange of critical information. This approach reduces transmission overhead and improves content delivery efficiency.However, collaborative edge caching also raises privacy concerns. The collaboration between edge devices involves the sharing content or other private data, which can potentially reveal privacy of users or edge servers. Therefore, privacy protection is a critical consideration in collaborative edge caching.\nWe outline two open privacy concerns when multiple edge servers share sensitive information. \n\n",
                    "subsubsection 7.1.1": {
                        "name": "Content-right confirmation",
                        "content": "\n\nDigital content can be easily copied and distributed, which is a double-edged sword making content-right confirmation difficult.\nFor instance, when social media content cached on a particular edge server is accessed by other edge servers, the edge server completely loses control of cached social media content because other edge servers can easily copy and redistribute this social media content~\\cite{Araldo2018, Cui2020c, Yuan2016a}. \n%Some encryption-based methods can mitigate such risks but may also result in a reduced availability of the cache, for which further research is needed~\\cite{Araldo2018, Cui2020c, Yuan2016a}. \n%using their phone, the content provider automatically collects the user's request trace.\nContent-right confirmation is essential for content owners to maintain availability and accountability when using edge caching services to preserve content privacy. \nOn the one hand, with content-right confirmation, it is easy to determine content ownership. Privacy strategies can be implemented to ensure that only authorized parties can access the content cached in an edge server. \nOn the other hand, content-right confirmation is the basis of content accountability. With content-right confirmation, the content right can be authenticated when the content is used once, with the right changed accordingly.\n%Content accountability provides an analytical basis for economics, incentive mechanisms and data misuse of edge caching\n\n\\textcolor{black}{\\textit{\\textbf{Challenges.}}}\nHowever, realizing content-right confirmation in edge caching systems is non-trivial due to several challenges. First, the distributed nature of edge caching systems makes it difficult to maintain a centralized and trusted authority for content ownership verification. \nSecond, edge devices' dynamic and heterogeneous nature introduces complexity in implementing content-right confirmation mechanisms, which must be scalable and adaptable to different devices.\nFurthermore, the use of encryption and privacy-enhancing technologies in edge caching systems further complicates content-right confirmation. While these technologies are essential for protecting the privacy of cached content, they may also prevent content owners from verifying the use of their content in the cache.\n\n\\textcolor{black}{\\textit{\\textbf{Future directions.}}} The challenges of realizing content-right confirmation in edge caching systems call for future work in several directions. Firstly, new verification mechanisms are needed that can handle the distributed nature, dynamics, and heterogeneity of edge devices. To overcome these challenges, several approaches have been proposed in the literature, such as blockchain-based solutions~\\cite{Lei2020, Vu2019}. However, these mechanisms are short in scalability and the ability to adapt to different edge devices. \nAdditionally, privacy-preserving verification methods that can coexist with encryption and other privacy-enhancing techniques should be explored. One possible solution is to leverage secure multi-party computation~\\cite{Andreoletti2018} to enable verification while preserving the privacy of cached content. Finally, standardization efforts are needed to ensure interoperability between different edge caching systems and content providers. For example, the trust management mechanisms~\\cite{Zhong2021, Xu2019} are proposed to enable content-right confirmation in ISP and D2D edge caching. Thus, promoting the adoption of content-right confirmation mechanisms and facilitating the collaboration between different stakeholders in different edge caching scenarios need to be further discussed.  \n\n%In collaborative edge caching, privacy protection is a key driver, with a focus on data rights confirmation and protection. This includes determining who can access and use various types of private data, such as request records, personal and location information, machine learning knowledge, and private content (as discussed in Section \\ref{sec: data issues}), as it streams along the cache and diffusion path.\n\n\n\n%For instance, when a user accesses social media content using their phone, the content provider automatically collects the user's request trace. Although this type of private data may be meaningless to the user, it can be valuable to a media company. Request traces can be used to study user interests, enabling companies to make informed analyses and judgments for edge caching or advertisement. \n\n\n%However, determining ``whose data is it\" is not a straightforward issue. Once data is sent, copied, transferred, and used, the user loses complete control over it. One significant difference between data and oil resources is that oil is not renewable or replicable. While one barrel of oil cannot be turned into two, it is easy to create multiple copies of private data during the caching process. Therefore,\n\n%Besides, the limited data rights poses new constraints for edge cache operators when analyzing and mining the dataset for caching decisions. Data analysis need to maximize the value of private data while ensuring privacy protection. This can be achieved through various techniques, including data anonymization, aggregation, and differential privacy. It is important to strike a balance between the need for data analysis and the requirement for privacy protection.\n\n\n\n"
                    },
                    "subsubsection 7.1.2": {
                        "name": "Coalition mechanism design",
                        "content": "\n\nCollaborative edge caching is essential for enhancing QoS. However, many edge caches are deployed on leased nodes provided by profit-oriented third-party providers, which are often decentralized~\\cite{Cui2020c}, unreliable~\\cite{Leguay2017} or self-interested~\\cite{Cui2020c}. For instance, edge caching routers can be unreliable~\\cite{Leguay2017, Cui2020c} in CDN, while RSUs and vehicles can be semi-trust~\\cite{Qian2020, Zhang2022b, Hu2018, Jiang2020} or self-interested~\\cite{Dai2020, Cui2020, Kong2019} in the edge IoV caching network. Similarly, in social media networks,  edge servers can be self-interested~\\cite{Xu2019, Xu2020}.\nTo enable privacy-preserving applications and technology cooperation among  edge caching systems, coalition mechanisms are required. These mechanisms involve designing an incentive and allocation model that encourages participants in edge caching systems to join the coalition and maximize their benefits through a reasonable selection. %A more equitable distribution within the coalition leads to a larger size, while a more self-interested coalition would shrink in size. \nAdditionally, punishment mechanisms should also be considered when there are untrustworthy or dishonest nodes in the system.\nHence, incentive and allocation mechanisms can be designed in a thoughtful manner to foster participation and cooperation among edge caching systems.\n\n\\textcolor{black}{\\textit{\\textbf{Challenges.}}}  However, designing coalition mechanisms for PPEC is complicated  because it is necessary to balance several conflicting objectives. On the one hand, the mechanisms should encourage participants to contribute their resources to the coalition, ensuring that the costs and benefits of participants are distributed fairly~\\cite{Andreoletti2018}. %Additionally, the allocation mechanism must be designed to allocate the cache resources optimizing the overall performance of the coalition while taking into account the dynamic and heterogeneous nature of edge devices. \nOn the other hand, they must incentivize participants to prioritize the interests of the coalition over their individual interests and punish illegal strategies~\\cite{Xu2020}, which is challenging when  participants are profit-oriented with conflicting goals~\\cite{Xu2019}. \n\n\\textcolor{black}{\\textit{\\textbf{Future directions.}}} Game theory is a powerful mathematical framework for investigating decision-making processes, and interactions among rational individuals or entities in coalition mechanisms. Its applications can optimize edge caching, capturing interactions between content providers, network operators and end users. Various game-theoretic models such as the non-cooperative game~\\cite{Sivaraman2021}, Stackelberg game~\\cite{Xu2019, Xu2020, Cao2020}, coalition games and potential games~\\cite{Cao2020} can analyze the interaction among participants in edge caching systems. For instance, in a Stackelberg game, one player acts as the leader while the others follow. In the context of edge caching, the content provider can be modelled as the leader, while network caching operators are the followers~\\cite{Xu2020}. % in a Stackelberg game\n Similarly, the edge cache can act as the leader, followed by end users~\\cite{Xu2019}. \n%One common game-theoretic approach in edge caching is the Stackelberg game\\cite{Xu2019, Xu2020, Cao2020}. \n%Another game-theoretic approach in edge caching is the non-cooperative game\\cite{Sivaraman2021}. In a non-cooperative game, each player makes decisions independently without considering the decisions of the other players. \n%In addition to Stackelberg and non-cooperative games, other game-theoretic approaches have been proposed for edge caching, including cooperative games, auction-based games, and potential games\\cite{Cao2020}. \n%By modeling interactions between content providers, network operators, and end users through game theory, game-theoretic approaches can provide insights for designing the best strategies, e.g., price strategies, caching decisions, and request decisions,  for each player, and can ensure that the system as a whole operates efficiently and effectively.\nNevertheless, game theory-based approaches with complete information~\\cite{Xu2019, Xu2020} can not be directly applied in privacy-preserving scenarios since the information is likely incomplete to players in edge caching systems.  Besides, it is impractical to assume that every player is benign at an open-access edge network. There may exist semi-honest and even malicious players. \nTherefore, it is necessary to conduct further investigations into the coalition mechanisms when analyzing the complex interactions between different kinds of players in  collaborative PPEC.\n\n\n\n"
                    }
                },
                "subsection 7.2": {
                    "name": "Limited Capacity for Running Privacy-enhancing Caching Algorithms",
                    "content": "\n\n\\textcolor{black}{\\textit{\\textbf{Challenges.}}}  Edge devices are becoming increasingly crucial in edge caching networks. However, these devices are typically limited in processing power, memory, caching space, and energy capacity, which present challenges for running privacy-enhancing algorithms: \n% \\begin{enumerate}\n%     \\item \n    (1) Limited computing power and memory pose a significant challenge on implementing complex privacy-preserving algorithms on edge devices~\\cite{Ni2021}. \n    To address this challenge, the development of lightweight privacy-preserving algorithms is desired to protect user privacy without compromising caching performance. \n    Lightweight homomorphic encryption~\\cite{Cui2020}, identity authentication~\\cite{Xue2019, Xue2018, Zhang2022b, Tong2022}, and differential privacy~\\cite{Sivaraman2021, Acs2019} are prospective approaches that can reconcile privacy protection and computational efficiency. Additionally, it is vital to ensure that the developed algorithms are robust and productive, meeting the needs of edge devices. \n    % \\item\n    (2) Energy constraints: Edge devices such as autonomous vehicles and smartphones are often battery-powered~\\cite{Mao2017}, which can limit the ability of caching~\\cite{Saputra2022} and communication~\\cite{Cui2022}, and hence lower the performance of privacy-preserving algorithms~\\cite{Qiao2022, Saputra2022}. To address this challenge, energy-efficient caching management techniques should be developed to minimize the energy consumption of PPEC approaches. Techniques such as data compression~\\cite{Cui2022} and optimization models~\\cite{Qiao2022} can be adopted to reduce the consumption of caching and communication to minimize energy usage. For instance, an energy-aware client selection and communication method for FL was proposed in~\\cite{Qiao2022} that reduced energy consumption by up to 50\\% compared to traditional FL methods when protecting the privacy of data sources. \n    % \\item \n    (3) Cache space is another significant constraint for edge caching systems due to the limited storage capacity compared to the vast amount of content that can be cached. However, research has shown that only a small fraction of content is popular, while the majority of users concentrate their access on popular content, implying a long tail distribution of content popularity~\\cite{Ma2017b, Wang2019}. Therefore, it is crucial to determine which content should be cached based on popularity and user preferences while considering privacy concerns. PPEC approaches need to trade-off between privacy protection and caching performance. \n    %The next subsection will further discuss the challenges and potential solutions for addressing this trade-off.\n% \\end{enumerate}\n\n\\textcolor{black}{\\textit{\\textbf{Future directions.}}} Implementing privacy-preserving algorithms can complicate the system, which adversely impacts caching performance~\\cite{Liang2019}. Conversely, simplifying the system may increase the risk of privacy breaches. Challenges associated with PPEC include balancing the complexity of protection algorithms with caching performance~\\cite{Xue2019, Xue2018, Zhu2021} or limited resources~\\cite{Sivaraman2021, Tong2022, Cui2022}, and ensuring user privacy while enabling efficient content distribution~\\cite{Cui2020, Yuan2016a}. \nTo sum up, an in-depth understanding of the limitations of edge devices and designing practical and feasible solutions are vital in enhancing PPEC.\n\n"
                },
                "subsection 7.3": {
                    "name": "Trade-off between Efficacy and Privacy in PPEC",
                    "content": "\n\n{\n\\subsubsection{\\textcolor{black}{\\textbf{Privacy-enhancing intelligent edge cache}}}\nMachine learning-based methods have become a powerful tool for optimizing edge caching performance and developing intelligent caching algorithms~\\cite{Qiao2022, Liu2022}. However, there has been some controversy regarding privacy violations in edge caching. Privacy concerns arise when edge caching providers analyze and manage content in their cache since the storage spaces of edge cache are limited, and the content scale is growing rapidly~\\cite{Wang2019}. To provide intelligent edge caching, providers may be curious about the content stored in their cache (e.g., popular content~\\cite{Araldo2018, Cui2020, Cui2020c}) and the confidential information about consumers (e.g., request record~\\cite{Wu2016, Yuan2016a, Nikolaou2016}, identifiable information~\\cite{Nguyen2023, Zhang2022b, Xue2019, Xue2018}). Providers may use monitoring and inference attacks to compromise consumers' privacy to improve caching efficiency and gain economic benefits. \n\\textcolor{black}{Additionally, the rise of generative AI applications can further complicate this landscape. Generative AI can be leveraged to design more sophisticated caching algorithms that model user behavior and more accurately anticipate content popularity~\\cite{Tang2022}. Furthermore, by caching pretrained foundation models (PFMs) at the edge network~\\cite{Xu2023}, various multimedia enhancement techniques, such as super-resolution, can be deployed to effectively improve user QoE and reduce transport delays. \nHowever, these improvements may also come with increased privacy risks, as these models might require more granular user data for fine-tuning at edge servers, potentially exposing sensitive information.\n}\nTherefore, developing effective privacy-preserving mechanisms in intelligent edge caching algorithms is crucial to address these problems. \n\n\n\n\n\n\\textcolor{black}{\\textit{\\textbf{Challenges.}}}  However, the open-edge network provides an ideal entrance or interface for attackers to obtain private data or knowledge from machine learning methods designed for edge caching systems. \nTherefore, reconciling privacy and efficiency in intelligent caching methods at the open-edge network is challenging for several reasons. \nFirstly, the diversity of user requirements and content in machine learning-based edge networks can be more significant than traditional caching systems~\\cite{Zhou2019}, which makes it difficult to apply traditional privacy-enhancing mechanisms directly. \nSecondly, the edge network is usually open, and multi-access~\\cite{Xu2019}, implying that it is difficult to control the access of the cache so as to preserve privacy. \nFinally, the semi-trust or unreliable third-party caching service providers exacerbate the challenge to the design of protection method~\\cite{Xue2019, Xue2018, Qiao2022, Araldo2018, Liu2022}.\n\\textcolor{black}{For instance, the introduction of generative AI models could intensify these challenges, as these models may require ongoing access to real-time data for training content-specific generative models~\\cite{Xu2023}, thereby creating new vectors for privacy breaches.}\nTherefore, designing intelligent caching methods that can well balance privacy and efficiency is challenging. \n\n\n% Thirdly, traditional edge caching algorithms often rely on pre-determined and non-optimal edge caching policies in dynamic network environments where network conditions~\\cite{Zhang2022d} and user behaviour~\\cite{Ma2017b} can change rapidly over time. Besides, in a real network system, the access pattern of resources is highly dynamic~\\cite{Zhang2022,Zhou2023,Krishnendu2022}. Some existing works proposed to spend a high cost to train the machine learning model, which may not be acceptable for resource-constrained edge or terminal devices~\\cite{Cui2023,Chen2022a}. \n%Other information, such as, user interests, geographical locations, or IoT device connectivity in edge scenarios may be also highly dynamic, where one-time trained models may not adapt well to such scenarios~\\cite{Chen2022a}. \n%requires careful consideration of the privacy risks and implementing appropriate privacy-enhancing mechanisms.\n\n\\textit{\\textbf{Future directions.}}} The FL framework is one of the essential methods to preserve private data in the machine learning process~\\cite{Wang2020, Wang2019a}.\nBased on the FL framework, different parties may distributedly predict the critical information, e.g., content population~\\cite{Qiao2022, Liu2022, Zheng2022} or user location migratory pattern~\\cite{Wu2023}, for intelligent caching decisions at the edge network. However, some parties may be dishonest and malicious. In particular, malicious users in FL may bring poisoned data to affect the overall computing of the global model. For example, dishonest parties may back-infer their partners' model by collecting their gradients to infer private information~\\cite{Cui2022, Yu2021b}. These attacks can lead to the disclosure of critical privacy information or destroy caching performance. \nAdditionally, some adversaries even deliberately provide incorrect model parameters during lateral FL to disrupt the overall computation and impact model performance~\\cite{Wang2022}. \nThe security of private computing in the FL framework is also a challenging open topic for edge caching.\n\\textcolor{black}{\nFurthermore, generative AI could introduce new methods for obfuscating or anonymizing data before it is cached~\\cite{Wang2022}, thereby adding an additional layer of privacy protection. Similarly, with federated learning or other distributed learning frameworks, a lightweight generative model can be fine-tuned or trained with local data, stored, and run on edge devices, providing personalized and customized AIGC services in real time while maintaining user privacy~\\cite{Xu2024}.\n}\n\n\n\n",
                    "subsubsection 7.3.1": {
                        "name": "Reconcile efficacy and privacy in advanced edge networks",
                        "content": "\n{\\color{black}\nTraditional edge caching algorithms often rely on pre-determined and suboptimal caching policies, which may not be effective in dynamic network environments where conditions~\\cite{Zhang2022d} and user behavior~\\cite{Ma2017b} can change rapidly over time. In modern network systems, resource access patterns are highly dynamic and complex~\\cite{Zhang2022,Zhao2024}. Additionally, factors such as user interests, geographical locations, and IoT device connectivity in edge scenarios are also highly dynamic, making one-time trained models less adaptable to these evolving conditions~\\cite{Chen2022a}. Some existing works propose high-cost training of machine learning models, which may not be feasible for resource-constrained edge or terminal devices~\\cite{Cui2023}. Furthermore, advanced network infrastructures, such as Named Data Networks (NDN) and Information-Centric Networks (ICN), are becoming more prevalent in edge networks, introducing new challenges for privacy preservation.\n}\n\n\\textcolor{black}{\\textit{\\textbf{Challenges.}}}\nSeveral open challenges exist in designing privacy-preserving algorithms for advanced network systems. One challenge is to balance the privacy protection strength and the accuracy of the model prediction. The decision-making process in online scenarios is already highly challenging, and the introduction of privacy protection methods, such as noise perturbation, can further compromise the algorithm's performance or even make it unusable. Another challenge is to develop privacy-preserving algorithms that are computationally efficient and can be easily deployed in dynamic network environments. \n\\textcolor{black}{Moreover, advanced network architectures inherently focus on data rather than specific endpoints, leading to new vulnerabilities. For instance, in NDN and ICN, content is named and cached throughout the network, which could increase privacy risks if sensitive data is cached without proper safeguards~\\cite{Sivaraman2021,Xue2019,Cui2020c}. The ability to cache and retrieve data based on content names rather than IP addresses can expose more granular user preferences and access patterns, making it easier for adversaries to infer sensitive information. Additionally, these architectures may complicate the implementation of privacy-preserving caching strategies, as they require more sophisticated mechanisms to control data access and ensure data integrity across distributed caches.}\n\n\\textcolor{black}{\\textit{\\textbf{Future directions.}} Online learning algorithms, such as reinforcement learning~\\cite{Xiao2018a} and continuous learning, has become increasingly popular for solving complex problems in various fields, including edge caching in dynamic network environments~\\cite{Krishnendu2022, Zhang2022d, Chen2022a, Cui2023}.} However, online learning algorithms can also pose a risk to user privacy when collecting and processing sensitive user data. \nTherefore, how to safely use the latest historical information to make efficient online caching decisions is a problem worthy of discussion. There are little efforts to address the privacy concerns associated with online learning algorithms. The FL may be a possible framework to allow multiple parties to process data jointly without revealing their raw datasets in dynamic scenarios~\\cite{Krishnendu2022}. Additionally, differential privacy techniques can be used to add random noises to the data in advanced caching systems to obscure individual information~\\cite{Zhou2023}.\n\n\n\n\n\n"
                    },
                    "subsubsection 7.3.2": {
                        "name": "Privacy quantification for PPEC",
                        "content": "\nPrivacy quantification is a critical aspect of PPEC systems as it allows for the measurement and assessment of privacy protection levels provided by these systems~\\cite{Sivaraman2021, Yan2021, Wu2016, Acs2019}. However, most current work on privacy-enhanced intelligent edge caching lacks specific privacy metrics. Rather than developing clear and effective privacy metrics, researchers often combine existing privacy protection schemes and claim that their works can protect privacy. Unfortunately, without clear quantification of the privacy protection effect, it fails to identify weaknesses for improving privacy protection~\\cite{Acs2019, Yan2021}. %The development of effective privacy metrics for PPEC systems is therefore an important research topic.\n\n\n\\textcolor{black}{\\textit{\\textbf{Challenges.}}}  One of the primary challenges in privacy quantification is developing an accurate and consistent metric for measuring privacy protection levels. It is a complicated task to propose a universal method to measure different types of data leakage in the edge cache. Therefore, an appropriate privacy quantification method with a formalized definition should be established to guide the design of PPEC systems. For instance, in intelligent caching algorithms based on reinforcement learning models, a good privacy exposure quantitative index can guide the model's reward design and help the agent make better caching decisions~\\cite{Xu2020}. Various privacy metrics have been proposed in the literature, such as the information-theoretic converse bound~\\cite{Yan2021} and the size of the anonymity set~\\cite{Wu2016}. However, each metric has its limitations and may not be suitable for general PPEC systems. \nEvaluating the privacy protection degree in dynamic network environments is another challenge in PPEC. Edge caching systems operate in a constantly changing environment, and various factors can impact privacy protection levels, which makes it challenging to determine an accurate and consistent privacy metric that can be applied in a dynamic environment. \n\n\\textcolor{black}{\\textit{\\textbf{Future directions.}}} To address these challenges, researchers can explore the use of online algorithms~\\cite{Pang2022, Li2021} to predict privacy protection levels in real time based on network traffic patterns and user behaviour. \nThis approach can help to dynamically adjust privacy protection levels in response to changes in the network environment and improve the effectiveness of PPEC.\n{\\color{black}\nFuture work for designing privacy metrics (similar to the privacy budget in differential privacy~\\cite{Sivaraman2021, Acs2019} and mutual information in information theory~\\cite{Sivaraman2021}) is desired.\nAn innovative definition of privacy measurement applicable in intelligent edge caching scenarios~\\cite{Zhang2022a} should be designed to guide PPEC. Finally, exploring the integration of blockchain technology in PPEC could offer new avenues for ensuring data integrity and transparency~\\cite{Qian2020,Cui2022}. Blockchain can be used to create an immutable record of data access and modifications, thus providing a reliable audit trail that enhances trust and accountability in edge caching systems.}\n\n\\begin{comment}\n    \n\n\\subsection{Standard Protocol for PPEC}\n \nThe increasing amount of content generated by the Internet of Things (IoT) and mobile devices has put a strain on centralized cloud storage systems. \nEdge caching is an approach that involves storing content closer to the source of the content, such as at the edge of a network, to reduce the latency and bandwidth costs associated with accessing content from a central repository. \nHowever, edge caching can also pose privacy risks, as sensitive content may be stored on untrusted devices.\nTo address these privacy concerns, it is also essential to design standard protocols for edge caching systems to preserve the privacy of the stored content. \nSeveral open issues should be considered in the standard protocol design for PPEC:\n\\begin{enumerate}\n    \\item content Confidentiality: Ensuring the confidentiality of the stored content is crucial for protecting user privacy. There is a need for privacy-preserving encryption to secure the content stored at the edge without introducing significant overhead.\n    \\item Privacy-preserving Access Control: Edge caching systems must have access control mecha-place to ensure only authorized users can access the stored content. However, these access control mechanisms should also preserve the users' privacy during identity verification.\n    \\item Scalability: A critical requirement for edge caching systems to support the growing volume of content generated by IoT and mobile devices. Achieving scalability requires the development of new algorithms and data structures that can efficiently store and manage large amounts of content while preserving the privacy of sensitive content.\n    \\item Trust Management: Edge caching systems must have a trust management system in place to ensure that the content is stored on trusted devices and that the content transmission is secure. This requests secure protocols and cryptographic techniques to establish trust between the devices.\n\\end{enumerate}\n\n\nIn conclusion, privacy-preserving edge caching is a crucial research area that has the potential to revolutionize the way content is stored and accessed. Addressing the challenges outlined above will require the development of new privacy-preserving algorithms and protocols that can ensure the confidentiality, integrity, and privacy of the stored content. It is an exciting time to be involved in this field, with much room for further research and development.\n\\end{comment}\n\n\n\n\n"
                    }
                }
            },
            "section 8": {
                "name": "Conclusion",
                "content": "\\label{sec: Conclusion}\nEdge caching has shown significant potential for improving network performance and resource utilization, but privacy concerns must be considered when deploying edge caches. \\textcolor{black}{This article has analyzed and summarized the most prominent privacy issues in edge caching systems from a \\textit{sensitive information} perspective, based on which a comprehensive classification has been proposed.} The recent countermeasures for alleviating the exposed threats of different private information have been retrospectively reviewed. The article concludes with lessons learned and highlights open challenges for future research in the PPEC. Further investigations are needed to ensure the privacy and performance of edge caching while also reconciling the trade-off between privacy protection and caching performance optimization.\n\n\\begin{acks}\nThis work was supported in part by Shenzhen Science and Technology Program under Grant KJZD20230923113901004, in part by the Science and Technology Planning Project of Guangdong Province under Grant 2023A0505020006, in part by Science and Technology Development Fund, Macau SAR under Grant 0008/2022/AGJ, in part by the National Natural Science Foundation of China under Grant U2001209 and Grant 62072486. (Corresponding author: Di Wu.)\n\\end{acks}\n\n\n\n\n\\bibliographystyle{ACM-Reference-Format.bst}\n\\bibliography{ref}\n\n\\newpage\n\\appendix\n\n{\\color{black}\n\\section*{Appendix}\nAs supplementary information, we present total five comprehensive tables to facilitate readability. All information is referenced in the main text. We first have compiled a summary of commonly used abbreviations for the solutions in Table~\\ref{tab:abbreviations}.\n\\begin{table}[h]\n    \\caption{List of Common Abbreviations in this Paper.}\n    % \\vspace{-2mm}\n    \\label{tab:abbreviations}\n    \\rowcolors{2}{white}{gray!25} \n    \\begin{tabular}{p{2.5cm}<{\\centering}p{4cm}||p{2.5cm}<{\\centering}p{4.5cm}}\n        \\toprule\n        \\textbf{Abbreviation} &\n        \\textbf{Meaning}&%\\multicolumn{1}{>{\\centering}p{4cm}}{\\textbf{Meaning}} ||\n        \\textbf{Abbreviation} &\n        \\textbf{Meaning}\\\\%\\multicolumn{1}{>{\\centering}p{4.5cm}}{\\textbf{Meaning}}\\\\% \\\\\n        \\midrule\n        CDN & Content Delivery Network & CP(s) & Content Provider(s) \\\\\n        EC(s) & Edge Cache(s) & ES(s) & Edge Server(s) \\\\\n        EN(s) & Edge Node(s) & D2D & Device-to-Device \\\\\n        (L)DP & (Local) Differential Privacy & \n        DL & Deep Learning \\\\\n        FL &  Federated Learning&\n        HE & Homomorphic Encryption \\\\\n        ICN & Information-Centric Network&\n        IoV & Internet of Vehicles \\\\\n        ISP(s) & Internet Service Provider(s)&\n        LBS & Location-Based Services \\\\\n        ML & Machine Learning&\n        PIR & Private Information Retrieval \\\\\n        POI(s) & Point of Interest(s)  &\n        PPEC & Privacy-Preserving Edge Caching \\\\\n        RSU(s) & Roadside Unit(s)  &\n        (D)RL & (Deep) Reinforcement Learning \\\\\n        (S)BS(s) & (Small) Base Station(s)&\n        SS & Secret Sharing \\\\\n        TTP & Trusted Third Party&\n        TDC & Trusted Distributed Computing \\\\\n        \\bottomrule\n    \\end{tabular}\n    % \\vspace{-3mm}\n\\end{table}\n\nFor easy reference, we also present a classification matrix for the solutions introduced in this survey based on countermeasures and privacy data in the realm of edge caching in Table~\\ref{Tab: countermeasures}.\n\n\\begin{table}[h]\n\\caption{Method classification based on countermeasures and privacy types.}\n% % \\vspace{-2mm}\n%\\begin{center}\n%\\renewcommand\\arraystretch{1.25}\n\\renewcommand{\\arraystretch}{1.1}\n\\resizebox{1\\linewidth}{!}{\n%\\rowcolors{2}{white}{gray!25} \n\\begin{tabular}{|m{1.5cm}<{\\centering}|m{2.1cm}<{\\centering}||m{3cm}<{\\centering}|m{1.9cm}<{\\centering}|m{1.9cm}<{\\centering}|m{1.7cm}<{\\centering}|m{1.5cm}<{\\centering}|m{1.6cm}<{\\centering}|}\n\\toprule\n\\hline\n%Notation   & \\multicolumn{1}{c|c|c}{C||}\\\\   \\multirowcell{2}\n\\textbf{Classes}&\\textbf{Methods}&\\textbf{Request Record}&\\textbf{Personal Information}&\\textbf{Location}&\\textbf{Extracted Knowledge}&\\textbf{Private Content}&\\textbf{Content Popularity}\\\\ \\hline\n\\midrule\n\\multirowcell{3}{Noise-\\\\\nbased}\n    &{DP}&\\cite{Zhang2018, Wang2019, Zhou2019, Guo2022,Zhang2022a,Sivaraman2021,Xiong2022, zhang2024}&{\\cite{Zhu2021,Zeng2020, ZengYi2021}}&{\\cite{Zhang2022a}}&{\\cite{Yu2021b, LuYun2020, Jiang2023, NAIR2023}}&{\\cite{WangHu2022}}&{\\cite{Yu2021b}}\\\\    \\cline{2-8}\n    &Obfuscation&\\cite{Wu2016,Nikolaou2016,Qian2020,zhang2024,zhang2023a}&\\cite{Wang2022}&\\cite{Zhang2019b,Amini2011,GUYi-mingBAIGuang-weiSHENHang}&\\cite{Wang2022a,Wang2022}&/&/\\\\   \\cline{2-8}\n\t& Anonymity&\\cite{Cui2020b}&\\cite{Zhang2022b, Xue2019, Xue2018, Nguyen2023}&\\cite{Nisha2022,Cui2020b,Sen2018,Hu2018,Yang2016, Zhang2023}&/&/&/\\\\\n\t \\hline\n\\multirowcell{3}{TDC-based}\n        &{FL}&/&{\\cite{Qiao2022,Wang2022}}&/&\\cite{Cui2022,Qiao2022,Liu2022,Yu2021b,Zheng2022,Chen2022,Wang2022a,Wang2022,Saputra2022,Cheng2021,Li2020a,Wang2020,Yu2018,Wang2019a,Yu2020,Qi2020,Yu2020a, LuYun2020, Jiang2023, NAIR2023}&/&{\\cite{Li2020a}}\\\\ \\cline{2-8}\n\t&SS&\\cite{Acs2019, Schlegel2022}&/&/&/&\\cite{Pu2019}&\\cite{Andreoletti2019}\\\\\\cline{2-8}\n\t&\\multirowcell{2}{Blockchain}&\\multirowcell{2}{\\cite{Qian2020}}&\\multirowcell{2}{\\cite{Lei2020,Dai2020,Vu2019, LiuJi2020}}&\\multirowcell{2}{/}&\\multirowcell{2}{\\cite{Cui2022}}&\\multirowcell{2}{/}&\\multirowcell{2}{/}\\\\\\cline{1-1}\n    &&&&&&&\\\\\\cline{2-8}\n\\multirowcell{2}{Cryptology\\\\-based}\n\t\t& Encryption  Communication&\\cite{Leguay2017,Yuan2016a,Cui2020c,Jiang2020}&{\\cite{Xue2019,Xue2018,Zhang2022b}}&/&{\\cite{Chen2022}}&{\\cite{Xu2019,Pu2019}}&{\\cite{Cui2020,Araldo2018}}\\\\ \\cline{2-8}\n\t\t& HE&\\cite{Kong2019,Cui2020}&\\cite{Kong2019}&/&\\cite{Saputra2022}&/&/\\\\  \\cline{2-8}\n\t\t& PIR&\\cite{Tong2022,Yan2021,Kumar2019}&/&/&/&\\cite{Tong2022}&/\\\\   \\hline\n\\multirowcell{2}{Others}\n\t\t& Optimization&\\cite{Sivaraman2021,Xiong2022,Hassanpour2023,Hassanpour2021}&/&/&/&\\cite{Xu2019,Xu2020,Shi2018}&\\cite{Andreoletti2019a}\\\\  \n  \\cline{2-8}\n\t    & {Access Control}&{\\cite{Cui2020c,Jiang2020}}&{\\cite{Lei2020, Zhang2022b, Cui2020c, Nguyen2023}}&/&/&{\\cite{Xue2019,Xue2018,Cui2020c}}&/\\\\\n         \\hline\n\\bottomrule\n\\end{tabular}\n}\n%\\end{center}\n\\label{Tab: countermeasures}\n% \\vspace{-3mm}\n\\end{table}\n\nIn addition to the comprehensive introduction of major solutions for protecting user privacy in Section~\\ref{sec: user privacy}, we also provide a supplementary introduction in Table~\\ref{Tab: user privacy}. This table briefly outlines other solutions for safeguarding user privacy in edge caching systems that were not discussed in detail in Section~\\ref{sec: user privacy}.\n\n\n\\begin{table*}[h]\n\\renewcommand\\arraystretch{1.3}\n\\caption{A brief supplement of solutions to protect user privacy in the edge caching systems.}\n% \\vspace{-3mm}\n%\\begin{center}\n%\\renewcommand{\\arraystretch}{1.2}\n%\\rowcolors{2}{white}{gray!25} \n\\resizebox{1\\linewidth}{!}{\n\\begin{tabular}{|m{60pt}<{\\centering}| m{20pt}<{\\centering}| m{50pt}<{\\centering}| m{60pt}<{\\centering}|m{225pt}<{\\centering}|m{45pt}<{\\centering}|}\n\\hline\n%Notation   & \\multicolumn{1}{c|c|c}{C||}\\\\\n\\textbf{User Privacy}&\\textbf{Refs.}&\\textbf{Edge Cache Entities}&\\textbf{Mitigation Methods}&\\textbf{Key Ideas}&\\textbf{Potential Attackers}\\\\ \\hline\n\\midrule\n\\multirowcell{10}{Request Traces}\n&\\cite{Zhang2018}\n&APs\n&LDP\n&Add LDP noise to the users' preference content information.\n&CP\n\\\\\\cline{2-6}\n\n&\\cite{zhang2024}\n&ESs\n&LDP / Obfuscation\n&Integrate the obfuscation and correlated differential privacy methods to generate content fetching and caching strategy.\n&CP\n\\\\\\cline{2-6}\n\n&\\cite{ZengYi2021}\n&SBSs\n&LDP\n& Add LDP noise to the caching policy when the spread of the caching policy is needed.\n&Other SBSs\n\\\\\\cline{2-6}\n\n\n\n&\\cite{zhang2023a}\n& ESs / Users Devices \n& Obfuscation / Opt.-based\n& Develop a Stackelberg game to optimize the redundant request and caching strategy.\n& CP / ESs / Other Users\n\\\\\\cline{2-6}\n\n\n\n&\\cite{Leguay2017}\n&ESs\n&Encrypt. Comm. / Pseudonyms\n&Cache symmetrically encrypted content with pseudo-identifiers.\n&ESs\n\\\\\\cline{2-6}\n\n&\\cite{Yan2021}\n&Users Devices\n&PIR\n&Propose a collaborating caching scheme with encoding methods based on PIR.\n&Other Users\n\\\\\\cline{1-6}\n\n\\multirowcell{3}{Request Traces /\\\\ Personal\\\\ Information}\n&\\cite{Jiang2020}\n&ESs / Vehicles \n&Encrypt. Comm. / Access Control\n&Design a double-layer encryption scheme to achieve access control and data integrity verification in the edge cache of IoV.\n&Other Vehicles\n\\\\\\cline{2-6}\n\n&\\cite{Nguyen2023}\n&ESs\n&Opt.-based\n&Introduce a novel distributed game-theoretic technique for collaborations among CP and ESs.\n&CP\n\\\\\\cline{1-6}\n\n\\multirowcell{3}{Location}\n&\\cite{Yang2016}\n&User Devices\n&Anonymity \n&Disturb the real POI with $k$-anonymity method during interaction with LBS.\n&LBS\n\\\\\\cline{2-6}\n\n&\\cite{Cui2020b}\n&User Devices\n&Anonymity \n&Combine peer-to-peer caching technique and $l$-diversity to reduce privacy exposure during interaction with LBS.\n&LBS\n% \\\\\\cline{1-6}\n% Request Traces / Location \n% &\\cite{Sen2018}\n% &ISP\n% &Anonymity / Spatial Obf.\n% &Proposed a double cache strategy with a pair of caches for users in a specific region to jointly request their POIs.\n% &LBS / Other Users\n\\\\\\hline \n\\bottomrule\n\\end{tabular}}\n%\\end{center}\n\\label{Tab: user privacy}\n% \\vspace{-5mm}\n\\end{table*}\n\nAdditionally, Table~\\ref{tab: solutions for knowledge privacy} provides a detailed classification of protection methods used to safeguard knowledge privacy in federated learning (FL) systems. The table highlights the effectiveness of various approaches in protecting different types of data, including the training dataset, model or gradient data, and other machine learning data. These methods encompass the original FL framework, combinations of FL with additional privacy protection techniques, and the use of noise-adding frameworks. By outlining these approaches, the table offers a comprehensive overview of the techniques applied to safeguard privacy in extracted knowledge, ensuring robust protection in FL environments.\n\n\n\n\\begin{table*}[h]\n\\renewcommand\\arraystretch{1.5}\n\\caption{Protection methods of private information in extracted knowledge.}\n% \\vspace{-2mm}\n\\resizebox{1\\linewidth}{!}{\n\\centering\n\\begin{tabular}{|m{5.1cm}||m{3.5cm}<{\\centering}|m{1.8cm}<{\\centering}|m{2cm}<{\\centering}|m{2.5cm}<{\\centering}|}\n\\toprule\n\\hline\n%Notation   & \\multicolumn{1}{c|c|c}{C||}\\\\\n%\\diagbox{Methods}{ Data}\n\\centering\\textbf{Methods}&\\centering\\textbf{References}&\\textbf{Training Dataset}&\\textbf{Model or Gradient Data}&\\textbf{Other Machine Learning Data}\\\\ \\hline\n\\midrule\n%Traditional distributed machine learning framework\n%&\\XSolid\n%&\\XSolid  \n%&\\XSolid \n%&\n%\\\\\\hline\nOrigin FL framework \n&\\cite{Yu2018,Wang2019a,Wang2020,Liu2022,Yu2020,Yu2020a,Li2020a}\n&\\Checkmark\n&\\XSolid  \n&\\XSolid \n\\\\\\hline \nCombination of origin FL framework and other privacy protection methods\n&\\cite{Qi2020,Cheng2021,Zheng2022,Wang2022a,Saputra2022}\n&\\Checkmark\n&\\XSolid \n&\\Checkmark\n\\\\\\hline\nNoising FL framework \n&\\cite{Yu2021b}\n&\\Checkmark\n&\\Checkmark\n&\\XSolid \n\\\\\\hline \nCombination of noising FL framework and other privacy protection methods\n&\\cite{Wang2022,Cui2022,Chen2022}\n&\\Checkmark\n&\\Checkmark\n&\\Checkmark\n\\\\\\hline\n\\bottomrule\n\\end{tabular}\n}\n%\\end{center}\n% \\vspace{-0.3cm}\n\\label{tab: solutions for knowledge privacy}\n\\end{table*} \n\n\nLastly, we provide a supplementary overview of solutions for safeguarding knowledge privacy in edge caching systems in Table~\\ref{Tab: knowledge privacy}. This table briefly summarizes additional solutions that were not discussed in detail in Section~\\ref{sec: knowledge privacy}, offering a broader perspective on the various approaches used to protect knowledge privacy in edge caching environments.\n\n\\begin{table*}[h]\n\\renewcommand\\arraystretch{1.5}\n\\caption{A brief supplement of solutions to protect knowledge privacy in the edge caching systems.}\n% \\vspace{-3mm}\n%\\begin{center}\n%\\renewcommand{\\arraystretch}{1.2}\n%\\rowcolors{2}{white}{gray!25} \n\\resizebox{1\\linewidth}{!}{\n\\begin{tabular}{|m{38pt}<{\\centering}| m{20pt}<{\\centering}| m{50pt}<{\\centering}| m{42pt}<{\\centering}|m{245pt}<{\\centering}|m{40pt}<{\\centering}|}\n\\toprule\n\\hline\n%Notation   & \\multicolumn{1}{c|c|c}{C||}\\\\\n\\textbf{Protected Entities}&\\textbf{Refs.}&\\textbf{Edge Cache Entities}&\\textbf{Mitigation Methods}&\\textbf{Key Ideas}&\\textbf{Potential Attackers}\\\\ \\hline\n\\midrule\nUsers\n&\\cite{Li2020a}\n&BSs / User Devices\n&Distributed ML\n&Proposed a weighted distributed DRL model for edge caching replacement in D2D networks.\n&BSs\n\\\\\\cline{1-6}\nVehicle Devices\n&\\cite{Yu2020a}\n&RSUs / Vehicles\n&FL\n&Designed a peer-to-peer-based FL framework for proactive caching in vehicular edge networks.\n&BS / RSUs \n\\\\\\cline{1-6}\nIoT Devices \n&\\cite{Wang2020}\n&BSs\n&FL\n&Proposed an FL-based cooperative edge caching framework with the DRL technique.\n&BSs\n\\\\\\cline{1-6}\nUsers \n&\\cite{ZengYi2021}\n&User Devices\n&FL / Blockchain\n& Proposed a privacy-preserving D2D caching method with the combination of FL framework and a two-layer blockchain structure.\n&User Devices\n\\\\\\cline{1-6}\nUsers\n&\\cite{Qi2020}\n&BSs\n&Noised-based FL\n& Proposed FL-based method to predict content popularity with obfuscated feature information.\n&BSs\n\\\\\\hline \n\\bottomrule\n\\end{tabular}}\n% \\vspace{-5mm}\n%\\end{center}\n\\label{Tab: knowledge privacy}\n\\end{table*}\n}\n%\\printbibliography\n"
            }
        },
        "figures": {
            "fig: Private data in edge cache": "\\begin{figure}[!tb]\n\\centering\n\\includegraphics[width=0.85\\linewidth]{fig/classification_based_on_private_data.pdf}\n\\Description{The framework for PPEC encompasses six distinct types of data concerns: request traces, personal information, location data, machine learning knowledge, private content, and content popularity. These concerns can be primarily classified into three categories of private information: \\textit{user privacy}, \\textit{content privacy}, and \\textit{knowledge privacy}.}\n\\vspace{-2mm}\n\\caption{The framework for PPEC encompasses six distinct types of data concerns, which can be primarily classified into three categories of private information: \\textit{user privacy}, \\textit{content privacy}, and \\textit{knowledge privacy}.}\n\\vspace{-4mm}\n\\label{fig: Private data in edge cache}\n\\end{figure}",
            "fig: relation-attack-information": "\\begin{figure}[tb]\n\\centering\n\\includegraphics[width=0.8\\linewidth]{fig/relation-attack-information.pdf}\n\\vspace{-3mm}\n\\Description{The possible privacy attacks on different sensitive information and the corresponding defence methods for enhancing privacy in edge caching systems.}\n\\caption{\\textcolor{black}{The possible privacy attacks on different sensitive information in edge caching systems.}}\n\\label{fig: relation-attack-information}\n\\vspace{-4mm}\n\\end{figure}",
            "fig: relation-protection-information": "\\begin{figure}[tb]\n\\centering\n\\includegraphics[width=0.8\\linewidth]{fig/relation-protection-information.pdf}\n\\vspace{-4mm}\n\\Description{The possible privacy attacks on different sensitive data and the corresponding defence methods for enhancing privacy in edge caching systems.}\n\\caption{\\textcolor{black}{The corresponding defence methods for enhancing different private information in edge caching systems.}}\n\\label{fig: relation-protection-information}\n\\vspace{-4mm}\n\\end{figure}",
            "fig: user privacy": "\\begin{figure}[tb]\n\\centering\n\\includegraphics[width=0.75\\linewidth]{fig/user_privacy.pdf}\n\\vspace{-3mm}\n\\Description{A brief timeline of solutions aimed at enhancing user privacy, including request traces, personal information and location, in the edge cache. Each solution is accompanied by its main mitigation approach.}\n\\caption{A brief timeline of solutions aimed at enhancing user privacy, including request traces, personal information and location, in the edge cache. Each solution is accompanied by its main mitigation approach.}\n\\label{fig: user privacy}\n\\vspace{-4mm}\n\\end{figure}",
            "fig: content privacy": "\\begin{figure}[t]\n\\includegraphics[width=0.82\\linewidth]{fig/content_privacy.pdf}\n\\Description{A brief timeline of solutions for enhancing content privacy, including private content data and content popularity.}\n\\vspace{-3mm}\n\\caption{A brief timeline of solutions for enhancing content privacy, including private content data and content popularity.}\n\\label{fig: content privacy}\n\\vspace{-4mm}\n\\end{figure}",
            "fig: Knowledge privacy": "\\begin{figure}[tb]\n\\centering\n\\includegraphics[width=0.95\\linewidth]{fig/Knowledge_privacy.pdf}\n\\Description{A brief timeline of solutions for enhancing knowledge privacy.}\n\\vspace{-3mm}\n\\caption{A brief timeline of solutions for enhancing knowledge privacy.}\n\\label{fig: Knowledge privacy}\n\\vspace{-4mm}\n\\end{figure}",
            "fig: future work": "\\begin{figure}[tb]\n\\centering\n\\includegraphics[width=0.70\\linewidth]{fig/future_work.pdf}\n\\vspace{-4mm}\n\\Description{A outline for challenges and open issues section.}\n\\caption{A outline for challenges and open issues section.}\n\\label{fig: future work}\n\\vspace{-4mm}\n\\end{figure}"
        }
    }
}